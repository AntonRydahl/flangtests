*** IR Dump After Annotation2MetadataPass on [module] ***
; ModuleID = 'FIRModule'
source_filename = "FIRModule"
target datalayout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128"
target triple = "x86_64-unknown-linux-gnu"

%struct.ident_t = type { i32, i32, i32, i32, ptr }

@_QFEarr = internal global { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } { ptr null, i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), i32 20180515, i8 1, i8 28, i8 2, i8 0, [1 x [3 x i64]] [[3 x i64] [i64 1, i64 0, i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64)]] }
@_QQcl.60ea5a38555821a77357f87d16df9a0f = internal constant [62 x i8] c"/g/g92/rydahl1/flangtests/src/duplicate_array_descriptors.f90\00"
@_QQcl.28612C69372C612C6531332E36653229 = internal constant [16 x i8] c"(a,i7,a,e13.6e2)"
@_QQcl.54686520726573756C74206F6620286172722831292B61727228 = internal constant [26 x i8] c"The result of (arr(1)+arr("
@_QQcl.2920697320 = internal constant [5 x i8] c") is "
@_QQEnvironmentDefaults = constant ptr null
@0 = private unnamed_addr constant [23 x i8] c";unknown;unknown;0;0;;\00", align 1
@1 = private unnamed_addr constant %struct.ident_t { i32 0, i32 2, i32 0, i32 22, ptr @0 }, align 8
@2 = private unnamed_addr constant %struct.ident_t { i32 0, i32 66, i32 0, i32 22, ptr @0 }, align 8

declare ptr @malloc(i64)

declare void @free(ptr)

define void @_QQmain() {
  %structArg = alloca { ptr, ptr, ptr }, align 8
  %1 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %2 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %3 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %4 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %5 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %6 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %7 = alloca i32, i64 1, align 4
  %8 = alloca i32, i64 1, align 4
  %9 = alloca double, i64 1, align 8
  store i32 1048576, ptr %8, align 4, !tbaa !4
  %10 = load i32, ptr %8, align 4, !tbaa !4
  %11 = sext i32 %10 to i64
  %12 = icmp sgt i64 %11, 0
  %13 = select i1 %12, i64 %11, i64 0
  %14 = mul i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), %13
  %15 = call ptr @malloc(i64 %14)
  %16 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } { ptr undef, i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), i32 20180515, i8 1, i8 28, i8 2, i8 0, [1 x [3 x i64]] [[3 x i64] [i64 1, i64 undef, i64 undef]] }, i64 %13, 7, 0, 1
  %17 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %16, i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), 7, 0, 2
  %18 = mul i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), %13
  %19 = mul i64 1, %13
  %20 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %17, ptr %15, 0
  store { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %20, ptr %6, align 8, !tbaa !8
  %21 = load { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %6, align 8, !tbaa !8
  store { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %21, ptr @_QFEarr, align 8, !tbaa !8
  br label %entry

entry:                                            ; preds = %0
  %omp_global_thread_num = call i32 @__kmpc_global_thread_num(ptr @1)
  br label %omp_parallel

omp_parallel:                                     ; preds = %entry
  %gep_ = getelementptr { ptr, ptr, ptr }, ptr %structArg, i32 0, i32 0
  store ptr %8, ptr %gep_, align 8
  %gep_5 = getelementptr { ptr, ptr, ptr }, ptr %structArg, i32 0, i32 1
  store ptr %5, ptr %gep_5, align 8
  %gep_6 = getelementptr { ptr, ptr, ptr }, ptr %structArg, i32 0, i32 2
  store ptr %4, ptr %gep_6, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr @1, i32 1, ptr @_QQmain..omp_par, ptr %structArg)
  br label %omp.par.outlined.exit

omp.par.outlined.exit:                            ; preds = %omp_parallel
  br label %omp.par.exit.split

omp.par.exit.split:                               ; preds = %omp.par.outlined.exit
  %22 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr @_QQcl.60ea5a38555821a77357f87d16df9a0f, i32 21)
  %23 = call i1 @_FortranAioOutputAscii(ptr %22, ptr @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %24 = load i32, ptr %8, align 4, !tbaa !4
  %25 = call i1 @_FortranAioOutputInteger32(ptr %22, i32 %24)
  %26 = call i1 @_FortranAioOutputAscii(ptr %22, ptr @_QQcl.2920697320, i64 5)
  %27 = load { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, align 8, !tbaa !8
  store { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %27, ptr %3, align 8, !tbaa !8
  %28 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i32 0, i32 7, i64 0, i32 0
  %29 = load i64, ptr %28, align 8, !tbaa !8
  %30 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i32 0, i32 7, i64 0, i32 1
  %31 = load i64, ptr %30, align 8, !tbaa !8
  %32 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i32 0, i32 7, i64 0, i32 2
  %33 = load i64, ptr %32, align 8, !tbaa !8
  %34 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i32 0, i32 0
  %35 = load ptr, ptr %34, align 8, !tbaa !8
  %36 = sub i64 1, %29
  %37 = getelementptr double, ptr %35, i64 %36
  %38 = load double, ptr %37, align 8, !tbaa !4
  %39 = load i32, ptr %8, align 4, !tbaa !4
  %40 = sext i32 %39 to i64
  %41 = sub i64 %40, %29
  %42 = getelementptr double, ptr %35, i64 %41
  %43 = load double, ptr %42, align 8, !tbaa !4
  %44 = fadd contract double %38, %43
  %45 = call i1 @_FortranAioOutputReal64(ptr %22, double %44)
  %46 = call i32 @_FortranAioEndIoStatement(ptr %22)
  %47 = load { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, align 8, !tbaa !8
  store { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %47, ptr %2, align 8, !tbaa !8
  %48 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %2, i32 0, i32 0
  %49 = load ptr, ptr %48, align 8, !tbaa !8
  call void @free(ptr %49)
  store { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } { ptr null, i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), i32 20180515, i8 1, i8 28, i8 2, i8 0, [1 x [3 x i64]] [[3 x i64] [i64 1, i64 0, i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64)]] }, ptr %1, align 8, !tbaa !8
  %50 = load { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %1, align 8, !tbaa !8
  store { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %50, ptr @_QFEarr, align 8, !tbaa !8
  ret void
}

; Function Attrs: norecurse nounwind
define internal void @_QQmain..omp_par(ptr noalias %tid.addr, ptr noalias %zero.addr, ptr %0) #0 {
omp.par.entry:
  %gep_ = getelementptr { ptr, ptr, ptr }, ptr %0, i32 0, i32 0
  %loadgep_ = load ptr, ptr %gep_, align 8
  %gep_1 = getelementptr { ptr, ptr, ptr }, ptr %0, i32 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %gep_3 = getelementptr { ptr, ptr, ptr }, ptr %0, i32 0, i32 2
  %loadgep_4 = load ptr, ptr %gep_3, align 8
  %tid.addr.local = alloca i32, align 4
  %1 = load i32, ptr %tid.addr, align 4
  store i32 %1, ptr %tid.addr.local, align 4
  %tid = load i32, ptr %tid.addr.local, align 4
  %p.lastiter = alloca i32, align 4
  %p.lowerbound = alloca i32, align 4
  %p.upperbound = alloca i32, align 4
  %p.stride = alloca i32, align 4
  br label %omp.par.region

omp.par.region:                                   ; preds = %omp.par.entry
  br label %omp.par.region1

omp.par.region1:                                  ; preds = %omp.par.region
  %2 = alloca double, i64 1, align 8
  %3 = alloca i32, i64 1, align 4
  %4 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %5 = select i1 false, i32 %4, i32 1
  %6 = select i1 false, i32 1, i32 %4
  %7 = sub nsw i32 %6, %5
  %8 = icmp slt i32 %6, %5
  %9 = udiv i32 %7, 1
  %10 = add i32 %9, 1
  %omp_loop.tripcount = select i1 %8, i32 0, i32 %10
  br label %omp_loop.preheader

omp_loop.preheader:                               ; preds = %omp.par.region1
  store i32 0, ptr %p.lowerbound, align 4
  %11 = sub i32 %omp_loop.tripcount, 1
  store i32 %11, ptr %p.upperbound, align 4
  store i32 1, ptr %p.stride, align 4
  %omp_global_thread_num3 = call i32 @__kmpc_global_thread_num(ptr @1)
  call void @__kmpc_for_static_init_4u(ptr @1, i32 %omp_global_thread_num3, i32 34, ptr %p.lastiter, ptr %p.lowerbound, ptr %p.upperbound, ptr %p.stride, i32 1, i32 0)
  %12 = load i32, ptr %p.lowerbound, align 4
  %13 = load i32, ptr %p.upperbound, align 4
  %14 = sub i32 %13, %12
  %15 = add i32 %14, 1
  br label %omp_loop.header

omp_loop.header:                                  ; preds = %omp_loop.inc, %omp_loop.preheader
  %omp_loop.iv = phi i32 [ 0, %omp_loop.preheader ], [ %omp_loop.next, %omp_loop.inc ]
  br label %omp_loop.cond

omp_loop.cond:                                    ; preds = %omp_loop.header
  %omp_loop.cmp = icmp ult i32 %omp_loop.iv, %15
  br i1 %omp_loop.cmp, label %omp_loop.body, label %omp_loop.exit

omp_loop.exit:                                    ; preds = %omp_loop.cond
  call void @__kmpc_for_static_fini(ptr @1, i32 %omp_global_thread_num3)
  %omp_global_thread_num4 = call i32 @__kmpc_global_thread_num(ptr @1)
  call void @__kmpc_barrier(ptr @2, i32 %omp_global_thread_num4)
  br label %omp_loop.after

omp_loop.after:                                   ; preds = %omp_loop.exit
  br label %omp.region.cont

omp.region.cont:                                  ; preds = %omp_loop.after
  br label %omp.par.pre_finalize

omp.par.pre_finalize:                             ; preds = %omp.region.cont
  br label %omp.par.outlined.exit.exitStub

omp_loop.body:                                    ; preds = %omp_loop.cond
  %16 = add i32 %omp_loop.iv, %12
  %17 = mul i32 %16, 1
  %18 = add i32 %17, 1
  br label %omp.wsloop.region

omp.wsloop.region:                                ; preds = %omp_loop.body
  store i32 %18, ptr %3, align 4, !tbaa !4
  %19 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %20 = sitofp i32 %19 to float
  %21 = fdiv contract float 1.000000e+00, %20
  %22 = fpext float %21 to double
  %23 = load { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, align 8, !tbaa !8
  store { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %23, ptr %loadgep_2, align 8, !tbaa !8
  %24 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i32 0, i32 7, i64 0, i32 0
  %25 = load i64, ptr %24, align 8, !tbaa !8
  %26 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i32 0, i32 7, i64 0, i32 1
  %27 = load i64, ptr %26, align 8, !tbaa !8
  %28 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i32 0, i32 7, i64 0, i32 2
  %29 = load i64, ptr %28, align 8, !tbaa !8
  %30 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i32 0, i32 0
  %31 = load ptr, ptr %30, align 8, !tbaa !8
  %32 = load i32, ptr %3, align 4, !tbaa !4
  %33 = sext i32 %32 to i64
  %34 = sub i64 %33, %25
  %35 = getelementptr double, ptr %31, i64 %34
  store double %22, ptr %35, align 8, !tbaa !4
  %36 = load { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, align 8, !tbaa !8
  store { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %36, ptr %loadgep_4, align 8, !tbaa !8
  %37 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i32 0, i32 7, i64 0, i32 0
  %38 = load i64, ptr %37, align 8, !tbaa !8
  %39 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i32 0, i32 7, i64 0, i32 1
  %40 = load i64, ptr %39, align 8, !tbaa !8
  %41 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i32 0, i32 7, i64 0, i32 2
  %42 = load i64, ptr %41, align 8, !tbaa !8
  %43 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i32 0, i32 0
  %44 = load ptr, ptr %43, align 8, !tbaa !8
  %45 = load i32, ptr %3, align 4, !tbaa !4
  %46 = sext i32 %45 to i64
  %47 = sub i64 %46, %38
  %48 = getelementptr double, ptr %44, i64 %47
  %49 = load double, ptr %48, align 8, !tbaa !4
  store double %49, ptr %2, align 8, !tbaa !4
  br label %omp.region.cont2

omp.region.cont2:                                 ; preds = %omp.wsloop.region
  br label %omp_loop.inc

omp_loop.inc:                                     ; preds = %omp.region.cont2
  %omp_loop.next = add nuw i32 %omp_loop.iv, 1
  br label %omp_loop.header

omp.par.outlined.exit.exitStub:                   ; preds = %omp.par.pre_finalize
  ret void
}

declare ptr @_FortranAioBeginExternalFormattedOutput(ptr, i64, ptr, i32, ptr, i32)

declare zeroext i1 @_FortranAioOutputAscii(ptr, ptr, i64)

declare zeroext i1 @_FortranAioOutputInteger32(ptr, i32)

declare zeroext i1 @_FortranAioOutputReal64(ptr, double)

declare i32 @_FortranAioEndIoStatement(ptr)

; Function Attrs: nocallback nofree nosync nounwind willreturn
declare ptr @llvm.stacksave() #1

; Function Attrs: nocallback nofree nosync nounwind willreturn
declare void @llvm.stackrestore(ptr) #1

; Function Attrs: nounwind
declare i32 @__kmpc_global_thread_num(ptr) #2

; Function Attrs: nounwind
declare void @__kmpc_for_static_init_4u(ptr, i32, i32, ptr, ptr, ptr, ptr, i32, i32) #2

; Function Attrs: nounwind
declare void @__kmpc_for_static_fini(ptr, i32) #2

; Function Attrs: convergent nounwind
declare void @__kmpc_barrier(ptr, i32) #3

; Function Attrs: nounwind
declare !callback !10 void @__kmpc_fork_call(ptr, i32, ptr, ...) #2

attributes #0 = { norecurse nounwind }
attributes #1 = { nocallback nofree nosync nounwind willreturn }
attributes #2 = { nounwind }
attributes #3 = { convergent nounwind }

!llvm.module.flags = !{!0, !1, !2, !3}

!0 = !{i32 2, !"Debug Info Version", i32 3}
!1 = !{i32 7, !"openmp", i32 11}
!2 = !{i32 8, !"PIC Level", i32 2}
!3 = !{i32 7, !"PIE Level", i32 2}
!4 = !{!5, !5, i64 0}
!5 = !{!"any data access", !6, i64 0}
!6 = !{!"any access", !7, i64 0}
!7 = !{!"Flang Type TBAA Root"}
!8 = !{!9, !9, i64 0}
!9 = !{!"descriptor member", !6, i64 0}
!10 = !{!11}
!11 = !{i64 2, i64 -1, i64 -1, i1 true}
*** IR Dump After ForceFunctionAttrsPass on [module] ***
; ModuleID = 'FIRModule'
source_filename = "FIRModule"
target datalayout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128"
target triple = "x86_64-unknown-linux-gnu"

%struct.ident_t = type { i32, i32, i32, i32, ptr }

@_QFEarr = internal global { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } { ptr null, i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), i32 20180515, i8 1, i8 28, i8 2, i8 0, [1 x [3 x i64]] [[3 x i64] [i64 1, i64 0, i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64)]] }
@_QQcl.60ea5a38555821a77357f87d16df9a0f = internal constant [62 x i8] c"/g/g92/rydahl1/flangtests/src/duplicate_array_descriptors.f90\00"
@_QQcl.28612C69372C612C6531332E36653229 = internal constant [16 x i8] c"(a,i7,a,e13.6e2)"
@_QQcl.54686520726573756C74206F6620286172722831292B61727228 = internal constant [26 x i8] c"The result of (arr(1)+arr("
@_QQcl.2920697320 = internal constant [5 x i8] c") is "
@_QQEnvironmentDefaults = constant ptr null
@0 = private unnamed_addr constant [23 x i8] c";unknown;unknown;0;0;;\00", align 1
@1 = private unnamed_addr constant %struct.ident_t { i32 0, i32 2, i32 0, i32 22, ptr @0 }, align 8
@2 = private unnamed_addr constant %struct.ident_t { i32 0, i32 66, i32 0, i32 22, ptr @0 }, align 8

declare ptr @malloc(i64)

declare void @free(ptr)

define void @_QQmain() {
  %structArg = alloca { ptr, ptr, ptr }, align 8
  %1 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %2 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %3 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %4 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %5 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %6 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %7 = alloca i32, i64 1, align 4
  %8 = alloca i32, i64 1, align 4
  %9 = alloca double, i64 1, align 8
  store i32 1048576, ptr %8, align 4, !tbaa !4
  %10 = load i32, ptr %8, align 4, !tbaa !4
  %11 = sext i32 %10 to i64
  %12 = icmp sgt i64 %11, 0
  %13 = select i1 %12, i64 %11, i64 0
  %14 = mul i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), %13
  %15 = call ptr @malloc(i64 %14)
  %16 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } { ptr undef, i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), i32 20180515, i8 1, i8 28, i8 2, i8 0, [1 x [3 x i64]] [[3 x i64] [i64 1, i64 undef, i64 undef]] }, i64 %13, 7, 0, 1
  %17 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %16, i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), 7, 0, 2
  %18 = mul i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), %13
  %19 = mul i64 1, %13
  %20 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %17, ptr %15, 0
  store { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %20, ptr %6, align 8, !tbaa !8
  %21 = load { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %6, align 8, !tbaa !8
  store { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %21, ptr @_QFEarr, align 8, !tbaa !8
  br label %entry

entry:                                            ; preds = %0
  %omp_global_thread_num = call i32 @__kmpc_global_thread_num(ptr @1)
  br label %omp_parallel

omp_parallel:                                     ; preds = %entry
  %gep_ = getelementptr { ptr, ptr, ptr }, ptr %structArg, i32 0, i32 0
  store ptr %8, ptr %gep_, align 8
  %gep_5 = getelementptr { ptr, ptr, ptr }, ptr %structArg, i32 0, i32 1
  store ptr %5, ptr %gep_5, align 8
  %gep_6 = getelementptr { ptr, ptr, ptr }, ptr %structArg, i32 0, i32 2
  store ptr %4, ptr %gep_6, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr @1, i32 1, ptr @_QQmain..omp_par, ptr %structArg)
  br label %omp.par.outlined.exit

omp.par.outlined.exit:                            ; preds = %omp_parallel
  br label %omp.par.exit.split

omp.par.exit.split:                               ; preds = %omp.par.outlined.exit
  %22 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr @_QQcl.60ea5a38555821a77357f87d16df9a0f, i32 21)
  %23 = call i1 @_FortranAioOutputAscii(ptr %22, ptr @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %24 = load i32, ptr %8, align 4, !tbaa !4
  %25 = call i1 @_FortranAioOutputInteger32(ptr %22, i32 %24)
  %26 = call i1 @_FortranAioOutputAscii(ptr %22, ptr @_QQcl.2920697320, i64 5)
  %27 = load { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, align 8, !tbaa !8
  store { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %27, ptr %3, align 8, !tbaa !8
  %28 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i32 0, i32 7, i64 0, i32 0
  %29 = load i64, ptr %28, align 8, !tbaa !8
  %30 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i32 0, i32 7, i64 0, i32 1
  %31 = load i64, ptr %30, align 8, !tbaa !8
  %32 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i32 0, i32 7, i64 0, i32 2
  %33 = load i64, ptr %32, align 8, !tbaa !8
  %34 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i32 0, i32 0
  %35 = load ptr, ptr %34, align 8, !tbaa !8
  %36 = sub i64 1, %29
  %37 = getelementptr double, ptr %35, i64 %36
  %38 = load double, ptr %37, align 8, !tbaa !4
  %39 = load i32, ptr %8, align 4, !tbaa !4
  %40 = sext i32 %39 to i64
  %41 = sub i64 %40, %29
  %42 = getelementptr double, ptr %35, i64 %41
  %43 = load double, ptr %42, align 8, !tbaa !4
  %44 = fadd contract double %38, %43
  %45 = call i1 @_FortranAioOutputReal64(ptr %22, double %44)
  %46 = call i32 @_FortranAioEndIoStatement(ptr %22)
  %47 = load { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, align 8, !tbaa !8
  store { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %47, ptr %2, align 8, !tbaa !8
  %48 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %2, i32 0, i32 0
  %49 = load ptr, ptr %48, align 8, !tbaa !8
  call void @free(ptr %49)
  store { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } { ptr null, i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), i32 20180515, i8 1, i8 28, i8 2, i8 0, [1 x [3 x i64]] [[3 x i64] [i64 1, i64 0, i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64)]] }, ptr %1, align 8, !tbaa !8
  %50 = load { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %1, align 8, !tbaa !8
  store { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %50, ptr @_QFEarr, align 8, !tbaa !8
  ret void
}

; Function Attrs: norecurse nounwind
define internal void @_QQmain..omp_par(ptr noalias %tid.addr, ptr noalias %zero.addr, ptr %0) #0 {
omp.par.entry:
  %gep_ = getelementptr { ptr, ptr, ptr }, ptr %0, i32 0, i32 0
  %loadgep_ = load ptr, ptr %gep_, align 8
  %gep_1 = getelementptr { ptr, ptr, ptr }, ptr %0, i32 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %gep_3 = getelementptr { ptr, ptr, ptr }, ptr %0, i32 0, i32 2
  %loadgep_4 = load ptr, ptr %gep_3, align 8
  %tid.addr.local = alloca i32, align 4
  %1 = load i32, ptr %tid.addr, align 4
  store i32 %1, ptr %tid.addr.local, align 4
  %tid = load i32, ptr %tid.addr.local, align 4
  %p.lastiter = alloca i32, align 4
  %p.lowerbound = alloca i32, align 4
  %p.upperbound = alloca i32, align 4
  %p.stride = alloca i32, align 4
  br label %omp.par.region

omp.par.region:                                   ; preds = %omp.par.entry
  br label %omp.par.region1

omp.par.region1:                                  ; preds = %omp.par.region
  %2 = alloca double, i64 1, align 8
  %3 = alloca i32, i64 1, align 4
  %4 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %5 = select i1 false, i32 %4, i32 1
  %6 = select i1 false, i32 1, i32 %4
  %7 = sub nsw i32 %6, %5
  %8 = icmp slt i32 %6, %5
  %9 = udiv i32 %7, 1
  %10 = add i32 %9, 1
  %omp_loop.tripcount = select i1 %8, i32 0, i32 %10
  br label %omp_loop.preheader

omp_loop.preheader:                               ; preds = %omp.par.region1
  store i32 0, ptr %p.lowerbound, align 4
  %11 = sub i32 %omp_loop.tripcount, 1
  store i32 %11, ptr %p.upperbound, align 4
  store i32 1, ptr %p.stride, align 4
  %omp_global_thread_num3 = call i32 @__kmpc_global_thread_num(ptr @1)
  call void @__kmpc_for_static_init_4u(ptr @1, i32 %omp_global_thread_num3, i32 34, ptr %p.lastiter, ptr %p.lowerbound, ptr %p.upperbound, ptr %p.stride, i32 1, i32 0)
  %12 = load i32, ptr %p.lowerbound, align 4
  %13 = load i32, ptr %p.upperbound, align 4
  %14 = sub i32 %13, %12
  %15 = add i32 %14, 1
  br label %omp_loop.header

omp_loop.header:                                  ; preds = %omp_loop.inc, %omp_loop.preheader
  %omp_loop.iv = phi i32 [ 0, %omp_loop.preheader ], [ %omp_loop.next, %omp_loop.inc ]
  br label %omp_loop.cond

omp_loop.cond:                                    ; preds = %omp_loop.header
  %omp_loop.cmp = icmp ult i32 %omp_loop.iv, %15
  br i1 %omp_loop.cmp, label %omp_loop.body, label %omp_loop.exit

omp_loop.exit:                                    ; preds = %omp_loop.cond
  call void @__kmpc_for_static_fini(ptr @1, i32 %omp_global_thread_num3)
  %omp_global_thread_num4 = call i32 @__kmpc_global_thread_num(ptr @1)
  call void @__kmpc_barrier(ptr @2, i32 %omp_global_thread_num4)
  br label %omp_loop.after

omp_loop.after:                                   ; preds = %omp_loop.exit
  br label %omp.region.cont

omp.region.cont:                                  ; preds = %omp_loop.after
  br label %omp.par.pre_finalize

omp.par.pre_finalize:                             ; preds = %omp.region.cont
  br label %omp.par.outlined.exit.exitStub

omp_loop.body:                                    ; preds = %omp_loop.cond
  %16 = add i32 %omp_loop.iv, %12
  %17 = mul i32 %16, 1
  %18 = add i32 %17, 1
  br label %omp.wsloop.region

omp.wsloop.region:                                ; preds = %omp_loop.body
  store i32 %18, ptr %3, align 4, !tbaa !4
  %19 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %20 = sitofp i32 %19 to float
  %21 = fdiv contract float 1.000000e+00, %20
  %22 = fpext float %21 to double
  %23 = load { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, align 8, !tbaa !8
  store { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %23, ptr %loadgep_2, align 8, !tbaa !8
  %24 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i32 0, i32 7, i64 0, i32 0
  %25 = load i64, ptr %24, align 8, !tbaa !8
  %26 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i32 0, i32 7, i64 0, i32 1
  %27 = load i64, ptr %26, align 8, !tbaa !8
  %28 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i32 0, i32 7, i64 0, i32 2
  %29 = load i64, ptr %28, align 8, !tbaa !8
  %30 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i32 0, i32 0
  %31 = load ptr, ptr %30, align 8, !tbaa !8
  %32 = load i32, ptr %3, align 4, !tbaa !4
  %33 = sext i32 %32 to i64
  %34 = sub i64 %33, %25
  %35 = getelementptr double, ptr %31, i64 %34
  store double %22, ptr %35, align 8, !tbaa !4
  %36 = load { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, align 8, !tbaa !8
  store { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %36, ptr %loadgep_4, align 8, !tbaa !8
  %37 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i32 0, i32 7, i64 0, i32 0
  %38 = load i64, ptr %37, align 8, !tbaa !8
  %39 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i32 0, i32 7, i64 0, i32 1
  %40 = load i64, ptr %39, align 8, !tbaa !8
  %41 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i32 0, i32 7, i64 0, i32 2
  %42 = load i64, ptr %41, align 8, !tbaa !8
  %43 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i32 0, i32 0
  %44 = load ptr, ptr %43, align 8, !tbaa !8
  %45 = load i32, ptr %3, align 4, !tbaa !4
  %46 = sext i32 %45 to i64
  %47 = sub i64 %46, %38
  %48 = getelementptr double, ptr %44, i64 %47
  %49 = load double, ptr %48, align 8, !tbaa !4
  store double %49, ptr %2, align 8, !tbaa !4
  br label %omp.region.cont2

omp.region.cont2:                                 ; preds = %omp.wsloop.region
  br label %omp_loop.inc

omp_loop.inc:                                     ; preds = %omp.region.cont2
  %omp_loop.next = add nuw i32 %omp_loop.iv, 1
  br label %omp_loop.header

omp.par.outlined.exit.exitStub:                   ; preds = %omp.par.pre_finalize
  ret void
}

declare ptr @_FortranAioBeginExternalFormattedOutput(ptr, i64, ptr, i32, ptr, i32)

declare zeroext i1 @_FortranAioOutputAscii(ptr, ptr, i64)

declare zeroext i1 @_FortranAioOutputInteger32(ptr, i32)

declare zeroext i1 @_FortranAioOutputReal64(ptr, double)

declare i32 @_FortranAioEndIoStatement(ptr)

; Function Attrs: nocallback nofree nosync nounwind willreturn
declare ptr @llvm.stacksave() #1

; Function Attrs: nocallback nofree nosync nounwind willreturn
declare void @llvm.stackrestore(ptr) #1

; Function Attrs: nounwind
declare i32 @__kmpc_global_thread_num(ptr) #2

; Function Attrs: nounwind
declare void @__kmpc_for_static_init_4u(ptr, i32, i32, ptr, ptr, ptr, ptr, i32, i32) #2

; Function Attrs: nounwind
declare void @__kmpc_for_static_fini(ptr, i32) #2

; Function Attrs: convergent nounwind
declare void @__kmpc_barrier(ptr, i32) #3

; Function Attrs: nounwind
declare !callback !10 void @__kmpc_fork_call(ptr, i32, ptr, ...) #2

attributes #0 = { norecurse nounwind }
attributes #1 = { nocallback nofree nosync nounwind willreturn }
attributes #2 = { nounwind }
attributes #3 = { convergent nounwind }

!llvm.module.flags = !{!0, !1, !2, !3}

!0 = !{i32 2, !"Debug Info Version", i32 3}
!1 = !{i32 7, !"openmp", i32 11}
!2 = !{i32 8, !"PIC Level", i32 2}
!3 = !{i32 7, !"PIE Level", i32 2}
!4 = !{!5, !5, i64 0}
!5 = !{!"any data access", !6, i64 0}
!6 = !{!"any access", !7, i64 0}
!7 = !{!"Flang Type TBAA Root"}
!8 = !{!9, !9, i64 0}
!9 = !{!"descriptor member", !6, i64 0}
!10 = !{!11}
!11 = !{i64 2, i64 -1, i64 -1, i1 true}
*** IR Dump After InferFunctionAttrsPass on [module] ***
; ModuleID = 'FIRModule'
source_filename = "FIRModule"
target datalayout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128"
target triple = "x86_64-unknown-linux-gnu"

%struct.ident_t = type { i32, i32, i32, i32, ptr }

@_QFEarr = internal global { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } { ptr null, i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), i32 20180515, i8 1, i8 28, i8 2, i8 0, [1 x [3 x i64]] [[3 x i64] [i64 1, i64 0, i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64)]] }
@_QQcl.60ea5a38555821a77357f87d16df9a0f = internal constant [62 x i8] c"/g/g92/rydahl1/flangtests/src/duplicate_array_descriptors.f90\00"
@_QQcl.28612C69372C612C6531332E36653229 = internal constant [16 x i8] c"(a,i7,a,e13.6e2)"
@_QQcl.54686520726573756C74206F6620286172722831292B61727228 = internal constant [26 x i8] c"The result of (arr(1)+arr("
@_QQcl.2920697320 = internal constant [5 x i8] c") is "
@_QQEnvironmentDefaults = constant ptr null
@0 = private unnamed_addr constant [23 x i8] c";unknown;unknown;0;0;;\00", align 1
@1 = private unnamed_addr constant %struct.ident_t { i32 0, i32 2, i32 0, i32 22, ptr @0 }, align 8
@2 = private unnamed_addr constant %struct.ident_t { i32 0, i32 66, i32 0, i32 22, ptr @0 }, align 8

; Function Attrs: mustprogress nofree nounwind willreturn allockind("alloc,uninitialized") allocsize(0) memory(inaccessiblemem: readwrite)
declare noalias noundef ptr @malloc(i64 noundef) #0

; Function Attrs: mustprogress nounwind willreturn allockind("free") memory(argmem: readwrite, inaccessiblemem: readwrite)
declare void @free(ptr allocptr nocapture noundef) #1

define void @_QQmain() {
  %structArg = alloca { ptr, ptr, ptr }, align 8
  %1 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %2 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %3 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %4 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %5 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %6 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %7 = alloca i32, i64 1, align 4
  %8 = alloca i32, i64 1, align 4
  %9 = alloca double, i64 1, align 8
  store i32 1048576, ptr %8, align 4, !tbaa !4
  %10 = load i32, ptr %8, align 4, !tbaa !4
  %11 = sext i32 %10 to i64
  %12 = icmp sgt i64 %11, 0
  %13 = select i1 %12, i64 %11, i64 0
  %14 = mul i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), %13
  %15 = call ptr @malloc(i64 %14)
  %16 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } { ptr undef, i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), i32 20180515, i8 1, i8 28, i8 2, i8 0, [1 x [3 x i64]] [[3 x i64] [i64 1, i64 undef, i64 undef]] }, i64 %13, 7, 0, 1
  %17 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %16, i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), 7, 0, 2
  %18 = mul i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), %13
  %19 = mul i64 1, %13
  %20 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %17, ptr %15, 0
  store { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %20, ptr %6, align 8, !tbaa !8
  %21 = load { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %6, align 8, !tbaa !8
  store { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %21, ptr @_QFEarr, align 8, !tbaa !8
  br label %entry

entry:                                            ; preds = %0
  %omp_global_thread_num = call i32 @__kmpc_global_thread_num(ptr @1)
  br label %omp_parallel

omp_parallel:                                     ; preds = %entry
  %gep_ = getelementptr { ptr, ptr, ptr }, ptr %structArg, i32 0, i32 0
  store ptr %8, ptr %gep_, align 8
  %gep_5 = getelementptr { ptr, ptr, ptr }, ptr %structArg, i32 0, i32 1
  store ptr %5, ptr %gep_5, align 8
  %gep_6 = getelementptr { ptr, ptr, ptr }, ptr %structArg, i32 0, i32 2
  store ptr %4, ptr %gep_6, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr @1, i32 1, ptr @_QQmain..omp_par, ptr %structArg)
  br label %omp.par.outlined.exit

omp.par.outlined.exit:                            ; preds = %omp_parallel
  br label %omp.par.exit.split

omp.par.exit.split:                               ; preds = %omp.par.outlined.exit
  %22 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr @_QQcl.60ea5a38555821a77357f87d16df9a0f, i32 21)
  %23 = call i1 @_FortranAioOutputAscii(ptr %22, ptr @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %24 = load i32, ptr %8, align 4, !tbaa !4
  %25 = call i1 @_FortranAioOutputInteger32(ptr %22, i32 %24)
  %26 = call i1 @_FortranAioOutputAscii(ptr %22, ptr @_QQcl.2920697320, i64 5)
  %27 = load { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, align 8, !tbaa !8
  store { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %27, ptr %3, align 8, !tbaa !8
  %28 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i32 0, i32 7, i64 0, i32 0
  %29 = load i64, ptr %28, align 8, !tbaa !8
  %30 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i32 0, i32 7, i64 0, i32 1
  %31 = load i64, ptr %30, align 8, !tbaa !8
  %32 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i32 0, i32 7, i64 0, i32 2
  %33 = load i64, ptr %32, align 8, !tbaa !8
  %34 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i32 0, i32 0
  %35 = load ptr, ptr %34, align 8, !tbaa !8
  %36 = sub i64 1, %29
  %37 = getelementptr double, ptr %35, i64 %36
  %38 = load double, ptr %37, align 8, !tbaa !4
  %39 = load i32, ptr %8, align 4, !tbaa !4
  %40 = sext i32 %39 to i64
  %41 = sub i64 %40, %29
  %42 = getelementptr double, ptr %35, i64 %41
  %43 = load double, ptr %42, align 8, !tbaa !4
  %44 = fadd contract double %38, %43
  %45 = call i1 @_FortranAioOutputReal64(ptr %22, double %44)
  %46 = call i32 @_FortranAioEndIoStatement(ptr %22)
  %47 = load { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, align 8, !tbaa !8
  store { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %47, ptr %2, align 8, !tbaa !8
  %48 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %2, i32 0, i32 0
  %49 = load ptr, ptr %48, align 8, !tbaa !8
  call void @free(ptr %49)
  store { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } { ptr null, i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), i32 20180515, i8 1, i8 28, i8 2, i8 0, [1 x [3 x i64]] [[3 x i64] [i64 1, i64 0, i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64)]] }, ptr %1, align 8, !tbaa !8
  %50 = load { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %1, align 8, !tbaa !8
  store { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %50, ptr @_QFEarr, align 8, !tbaa !8
  ret void
}

; Function Attrs: norecurse nounwind
define internal void @_QQmain..omp_par(ptr noalias %tid.addr, ptr noalias %zero.addr, ptr %0) #2 {
omp.par.entry:
  %gep_ = getelementptr { ptr, ptr, ptr }, ptr %0, i32 0, i32 0
  %loadgep_ = load ptr, ptr %gep_, align 8
  %gep_1 = getelementptr { ptr, ptr, ptr }, ptr %0, i32 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %gep_3 = getelementptr { ptr, ptr, ptr }, ptr %0, i32 0, i32 2
  %loadgep_4 = load ptr, ptr %gep_3, align 8
  %tid.addr.local = alloca i32, align 4
  %1 = load i32, ptr %tid.addr, align 4
  store i32 %1, ptr %tid.addr.local, align 4
  %tid = load i32, ptr %tid.addr.local, align 4
  %p.lastiter = alloca i32, align 4
  %p.lowerbound = alloca i32, align 4
  %p.upperbound = alloca i32, align 4
  %p.stride = alloca i32, align 4
  br label %omp.par.region

omp.par.region:                                   ; preds = %omp.par.entry
  br label %omp.par.region1

omp.par.region1:                                  ; preds = %omp.par.region
  %2 = alloca double, i64 1, align 8
  %3 = alloca i32, i64 1, align 4
  %4 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %5 = select i1 false, i32 %4, i32 1
  %6 = select i1 false, i32 1, i32 %4
  %7 = sub nsw i32 %6, %5
  %8 = icmp slt i32 %6, %5
  %9 = udiv i32 %7, 1
  %10 = add i32 %9, 1
  %omp_loop.tripcount = select i1 %8, i32 0, i32 %10
  br label %omp_loop.preheader

omp_loop.preheader:                               ; preds = %omp.par.region1
  store i32 0, ptr %p.lowerbound, align 4
  %11 = sub i32 %omp_loop.tripcount, 1
  store i32 %11, ptr %p.upperbound, align 4
  store i32 1, ptr %p.stride, align 4
  %omp_global_thread_num3 = call i32 @__kmpc_global_thread_num(ptr @1)
  call void @__kmpc_for_static_init_4u(ptr @1, i32 %omp_global_thread_num3, i32 34, ptr %p.lastiter, ptr %p.lowerbound, ptr %p.upperbound, ptr %p.stride, i32 1, i32 0)
  %12 = load i32, ptr %p.lowerbound, align 4
  %13 = load i32, ptr %p.upperbound, align 4
  %14 = sub i32 %13, %12
  %15 = add i32 %14, 1
  br label %omp_loop.header

omp_loop.header:                                  ; preds = %omp_loop.inc, %omp_loop.preheader
  %omp_loop.iv = phi i32 [ 0, %omp_loop.preheader ], [ %omp_loop.next, %omp_loop.inc ]
  br label %omp_loop.cond

omp_loop.cond:                                    ; preds = %omp_loop.header
  %omp_loop.cmp = icmp ult i32 %omp_loop.iv, %15
  br i1 %omp_loop.cmp, label %omp_loop.body, label %omp_loop.exit

omp_loop.exit:                                    ; preds = %omp_loop.cond
  call void @__kmpc_for_static_fini(ptr @1, i32 %omp_global_thread_num3)
  %omp_global_thread_num4 = call i32 @__kmpc_global_thread_num(ptr @1)
  call void @__kmpc_barrier(ptr @2, i32 %omp_global_thread_num4)
  br label %omp_loop.after

omp_loop.after:                                   ; preds = %omp_loop.exit
  br label %omp.region.cont

omp.region.cont:                                  ; preds = %omp_loop.after
  br label %omp.par.pre_finalize

omp.par.pre_finalize:                             ; preds = %omp.region.cont
  br label %omp.par.outlined.exit.exitStub

omp_loop.body:                                    ; preds = %omp_loop.cond
  %16 = add i32 %omp_loop.iv, %12
  %17 = mul i32 %16, 1
  %18 = add i32 %17, 1
  br label %omp.wsloop.region

omp.wsloop.region:                                ; preds = %omp_loop.body
  store i32 %18, ptr %3, align 4, !tbaa !4
  %19 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %20 = sitofp i32 %19 to float
  %21 = fdiv contract float 1.000000e+00, %20
  %22 = fpext float %21 to double
  %23 = load { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, align 8, !tbaa !8
  store { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %23, ptr %loadgep_2, align 8, !tbaa !8
  %24 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i32 0, i32 7, i64 0, i32 0
  %25 = load i64, ptr %24, align 8, !tbaa !8
  %26 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i32 0, i32 7, i64 0, i32 1
  %27 = load i64, ptr %26, align 8, !tbaa !8
  %28 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i32 0, i32 7, i64 0, i32 2
  %29 = load i64, ptr %28, align 8, !tbaa !8
  %30 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i32 0, i32 0
  %31 = load ptr, ptr %30, align 8, !tbaa !8
  %32 = load i32, ptr %3, align 4, !tbaa !4
  %33 = sext i32 %32 to i64
  %34 = sub i64 %33, %25
  %35 = getelementptr double, ptr %31, i64 %34
  store double %22, ptr %35, align 8, !tbaa !4
  %36 = load { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, align 8, !tbaa !8
  store { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %36, ptr %loadgep_4, align 8, !tbaa !8
  %37 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i32 0, i32 7, i64 0, i32 0
  %38 = load i64, ptr %37, align 8, !tbaa !8
  %39 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i32 0, i32 7, i64 0, i32 1
  %40 = load i64, ptr %39, align 8, !tbaa !8
  %41 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i32 0, i32 7, i64 0, i32 2
  %42 = load i64, ptr %41, align 8, !tbaa !8
  %43 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i32 0, i32 0
  %44 = load ptr, ptr %43, align 8, !tbaa !8
  %45 = load i32, ptr %3, align 4, !tbaa !4
  %46 = sext i32 %45 to i64
  %47 = sub i64 %46, %38
  %48 = getelementptr double, ptr %44, i64 %47
  %49 = load double, ptr %48, align 8, !tbaa !4
  store double %49, ptr %2, align 8, !tbaa !4
  br label %omp.region.cont2

omp.region.cont2:                                 ; preds = %omp.wsloop.region
  br label %omp_loop.inc

omp_loop.inc:                                     ; preds = %omp.region.cont2
  %omp_loop.next = add nuw i32 %omp_loop.iv, 1
  br label %omp_loop.header

omp.par.outlined.exit.exitStub:                   ; preds = %omp.par.pre_finalize
  ret void
}

declare ptr @_FortranAioBeginExternalFormattedOutput(ptr, i64, ptr, i32, ptr, i32)

declare zeroext i1 @_FortranAioOutputAscii(ptr, ptr, i64)

declare zeroext i1 @_FortranAioOutputInteger32(ptr, i32)

declare zeroext i1 @_FortranAioOutputReal64(ptr, double)

declare i32 @_FortranAioEndIoStatement(ptr)

; Function Attrs: mustprogress nocallback nofree nosync nounwind willreturn
declare ptr @llvm.stacksave() #3

; Function Attrs: mustprogress nocallback nofree nosync nounwind willreturn
declare void @llvm.stackrestore(ptr) #3

; Function Attrs: nounwind
declare i32 @__kmpc_global_thread_num(ptr) #4

; Function Attrs: nounwind
declare void @__kmpc_for_static_init_4u(ptr, i32, i32, ptr, ptr, ptr, ptr, i32, i32) #4

; Function Attrs: nounwind
declare void @__kmpc_for_static_fini(ptr, i32) #4

; Function Attrs: convergent nounwind
declare void @__kmpc_barrier(ptr, i32) #5

; Function Attrs: nounwind
declare !callback !10 void @__kmpc_fork_call(ptr, i32, ptr, ...) #4

attributes #0 = { mustprogress nofree nounwind willreturn allockind("alloc,uninitialized") allocsize(0) memory(inaccessiblemem: readwrite) "alloc-family"="malloc" }
attributes #1 = { mustprogress nounwind willreturn allockind("free") memory(argmem: readwrite, inaccessiblemem: readwrite) "alloc-family"="malloc" }
attributes #2 = { norecurse nounwind }
attributes #3 = { mustprogress nocallback nofree nosync nounwind willreturn }
attributes #4 = { nounwind }
attributes #5 = { convergent nounwind }

!llvm.module.flags = !{!0, !1, !2, !3}

!0 = !{i32 2, !"Debug Info Version", i32 3}
!1 = !{i32 7, !"openmp", i32 11}
!2 = !{i32 8, !"PIC Level", i32 2}
!3 = !{i32 7, !"PIE Level", i32 2}
!4 = !{!5, !5, i64 0}
!5 = !{!"any data access", !6, i64 0}
!6 = !{!"any access", !7, i64 0}
!7 = !{!"Flang Type TBAA Root"}
!8 = !{!9, !9, i64 0}
!9 = !{!"descriptor member", !6, i64 0}
!10 = !{!11}
!11 = !{i64 2, i64 -1, i64 -1, i1 true}
*** IR Dump After CoroEarlyPass on [module] ***
; ModuleID = 'FIRModule'
source_filename = "FIRModule"
target datalayout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128"
target triple = "x86_64-unknown-linux-gnu"

%struct.ident_t = type { i32, i32, i32, i32, ptr }

@_QFEarr = internal global { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } { ptr null, i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), i32 20180515, i8 1, i8 28, i8 2, i8 0, [1 x [3 x i64]] [[3 x i64] [i64 1, i64 0, i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64)]] }
@_QQcl.60ea5a38555821a77357f87d16df9a0f = internal constant [62 x i8] c"/g/g92/rydahl1/flangtests/src/duplicate_array_descriptors.f90\00"
@_QQcl.28612C69372C612C6531332E36653229 = internal constant [16 x i8] c"(a,i7,a,e13.6e2)"
@_QQcl.54686520726573756C74206F6620286172722831292B61727228 = internal constant [26 x i8] c"The result of (arr(1)+arr("
@_QQcl.2920697320 = internal constant [5 x i8] c") is "
@_QQEnvironmentDefaults = constant ptr null
@0 = private unnamed_addr constant [23 x i8] c";unknown;unknown;0;0;;\00", align 1
@1 = private unnamed_addr constant %struct.ident_t { i32 0, i32 2, i32 0, i32 22, ptr @0 }, align 8
@2 = private unnamed_addr constant %struct.ident_t { i32 0, i32 66, i32 0, i32 22, ptr @0 }, align 8

; Function Attrs: mustprogress nofree nounwind willreturn allockind("alloc,uninitialized") allocsize(0) memory(inaccessiblemem: readwrite)
declare noalias noundef ptr @malloc(i64 noundef) #0

; Function Attrs: mustprogress nounwind willreturn allockind("free") memory(argmem: readwrite, inaccessiblemem: readwrite)
declare void @free(ptr allocptr nocapture noundef) #1

define void @_QQmain() {
  %structArg = alloca { ptr, ptr, ptr }, align 8
  %1 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %2 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %3 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %4 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %5 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %6 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %7 = alloca i32, i64 1, align 4
  %8 = alloca i32, i64 1, align 4
  %9 = alloca double, i64 1, align 8
  store i32 1048576, ptr %8, align 4, !tbaa !4
  %10 = load i32, ptr %8, align 4, !tbaa !4
  %11 = sext i32 %10 to i64
  %12 = icmp sgt i64 %11, 0
  %13 = select i1 %12, i64 %11, i64 0
  %14 = mul i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), %13
  %15 = call ptr @malloc(i64 %14)
  %16 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } { ptr undef, i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), i32 20180515, i8 1, i8 28, i8 2, i8 0, [1 x [3 x i64]] [[3 x i64] [i64 1, i64 undef, i64 undef]] }, i64 %13, 7, 0, 1
  %17 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %16, i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), 7, 0, 2
  %18 = mul i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), %13
  %19 = mul i64 1, %13
  %20 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %17, ptr %15, 0
  store { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %20, ptr %6, align 8, !tbaa !8
  %21 = load { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %6, align 8, !tbaa !8
  store { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %21, ptr @_QFEarr, align 8, !tbaa !8
  br label %entry

entry:                                            ; preds = %0
  %omp_global_thread_num = call i32 @__kmpc_global_thread_num(ptr @1)
  br label %omp_parallel

omp_parallel:                                     ; preds = %entry
  %gep_ = getelementptr { ptr, ptr, ptr }, ptr %structArg, i32 0, i32 0
  store ptr %8, ptr %gep_, align 8
  %gep_5 = getelementptr { ptr, ptr, ptr }, ptr %structArg, i32 0, i32 1
  store ptr %5, ptr %gep_5, align 8
  %gep_6 = getelementptr { ptr, ptr, ptr }, ptr %structArg, i32 0, i32 2
  store ptr %4, ptr %gep_6, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr @1, i32 1, ptr @_QQmain..omp_par, ptr %structArg)
  br label %omp.par.outlined.exit

omp.par.outlined.exit:                            ; preds = %omp_parallel
  br label %omp.par.exit.split

omp.par.exit.split:                               ; preds = %omp.par.outlined.exit
  %22 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr @_QQcl.60ea5a38555821a77357f87d16df9a0f, i32 21)
  %23 = call i1 @_FortranAioOutputAscii(ptr %22, ptr @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %24 = load i32, ptr %8, align 4, !tbaa !4
  %25 = call i1 @_FortranAioOutputInteger32(ptr %22, i32 %24)
  %26 = call i1 @_FortranAioOutputAscii(ptr %22, ptr @_QQcl.2920697320, i64 5)
  %27 = load { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, align 8, !tbaa !8
  store { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %27, ptr %3, align 8, !tbaa !8
  %28 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i32 0, i32 7, i64 0, i32 0
  %29 = load i64, ptr %28, align 8, !tbaa !8
  %30 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i32 0, i32 7, i64 0, i32 1
  %31 = load i64, ptr %30, align 8, !tbaa !8
  %32 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i32 0, i32 7, i64 0, i32 2
  %33 = load i64, ptr %32, align 8, !tbaa !8
  %34 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i32 0, i32 0
  %35 = load ptr, ptr %34, align 8, !tbaa !8
  %36 = sub i64 1, %29
  %37 = getelementptr double, ptr %35, i64 %36
  %38 = load double, ptr %37, align 8, !tbaa !4
  %39 = load i32, ptr %8, align 4, !tbaa !4
  %40 = sext i32 %39 to i64
  %41 = sub i64 %40, %29
  %42 = getelementptr double, ptr %35, i64 %41
  %43 = load double, ptr %42, align 8, !tbaa !4
  %44 = fadd contract double %38, %43
  %45 = call i1 @_FortranAioOutputReal64(ptr %22, double %44)
  %46 = call i32 @_FortranAioEndIoStatement(ptr %22)
  %47 = load { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, align 8, !tbaa !8
  store { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %47, ptr %2, align 8, !tbaa !8
  %48 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %2, i32 0, i32 0
  %49 = load ptr, ptr %48, align 8, !tbaa !8
  call void @free(ptr %49)
  store { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } { ptr null, i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), i32 20180515, i8 1, i8 28, i8 2, i8 0, [1 x [3 x i64]] [[3 x i64] [i64 1, i64 0, i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64)]] }, ptr %1, align 8, !tbaa !8
  %50 = load { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %1, align 8, !tbaa !8
  store { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %50, ptr @_QFEarr, align 8, !tbaa !8
  ret void
}

; Function Attrs: norecurse nounwind
define internal void @_QQmain..omp_par(ptr noalias %tid.addr, ptr noalias %zero.addr, ptr %0) #2 {
omp.par.entry:
  %gep_ = getelementptr { ptr, ptr, ptr }, ptr %0, i32 0, i32 0
  %loadgep_ = load ptr, ptr %gep_, align 8
  %gep_1 = getelementptr { ptr, ptr, ptr }, ptr %0, i32 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %gep_3 = getelementptr { ptr, ptr, ptr }, ptr %0, i32 0, i32 2
  %loadgep_4 = load ptr, ptr %gep_3, align 8
  %tid.addr.local = alloca i32, align 4
  %1 = load i32, ptr %tid.addr, align 4
  store i32 %1, ptr %tid.addr.local, align 4
  %tid = load i32, ptr %tid.addr.local, align 4
  %p.lastiter = alloca i32, align 4
  %p.lowerbound = alloca i32, align 4
  %p.upperbound = alloca i32, align 4
  %p.stride = alloca i32, align 4
  br label %omp.par.region

omp.par.region:                                   ; preds = %omp.par.entry
  br label %omp.par.region1

omp.par.region1:                                  ; preds = %omp.par.region
  %2 = alloca double, i64 1, align 8
  %3 = alloca i32, i64 1, align 4
  %4 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %5 = select i1 false, i32 %4, i32 1
  %6 = select i1 false, i32 1, i32 %4
  %7 = sub nsw i32 %6, %5
  %8 = icmp slt i32 %6, %5
  %9 = udiv i32 %7, 1
  %10 = add i32 %9, 1
  %omp_loop.tripcount = select i1 %8, i32 0, i32 %10
  br label %omp_loop.preheader

omp_loop.preheader:                               ; preds = %omp.par.region1
  store i32 0, ptr %p.lowerbound, align 4
  %11 = sub i32 %omp_loop.tripcount, 1
  store i32 %11, ptr %p.upperbound, align 4
  store i32 1, ptr %p.stride, align 4
  %omp_global_thread_num3 = call i32 @__kmpc_global_thread_num(ptr @1)
  call void @__kmpc_for_static_init_4u(ptr @1, i32 %omp_global_thread_num3, i32 34, ptr %p.lastiter, ptr %p.lowerbound, ptr %p.upperbound, ptr %p.stride, i32 1, i32 0)
  %12 = load i32, ptr %p.lowerbound, align 4
  %13 = load i32, ptr %p.upperbound, align 4
  %14 = sub i32 %13, %12
  %15 = add i32 %14, 1
  br label %omp_loop.header

omp_loop.header:                                  ; preds = %omp_loop.inc, %omp_loop.preheader
  %omp_loop.iv = phi i32 [ 0, %omp_loop.preheader ], [ %omp_loop.next, %omp_loop.inc ]
  br label %omp_loop.cond

omp_loop.cond:                                    ; preds = %omp_loop.header
  %omp_loop.cmp = icmp ult i32 %omp_loop.iv, %15
  br i1 %omp_loop.cmp, label %omp_loop.body, label %omp_loop.exit

omp_loop.exit:                                    ; preds = %omp_loop.cond
  call void @__kmpc_for_static_fini(ptr @1, i32 %omp_global_thread_num3)
  %omp_global_thread_num4 = call i32 @__kmpc_global_thread_num(ptr @1)
  call void @__kmpc_barrier(ptr @2, i32 %omp_global_thread_num4)
  br label %omp_loop.after

omp_loop.after:                                   ; preds = %omp_loop.exit
  br label %omp.region.cont

omp.region.cont:                                  ; preds = %omp_loop.after
  br label %omp.par.pre_finalize

omp.par.pre_finalize:                             ; preds = %omp.region.cont
  br label %omp.par.outlined.exit.exitStub

omp_loop.body:                                    ; preds = %omp_loop.cond
  %16 = add i32 %omp_loop.iv, %12
  %17 = mul i32 %16, 1
  %18 = add i32 %17, 1
  br label %omp.wsloop.region

omp.wsloop.region:                                ; preds = %omp_loop.body
  store i32 %18, ptr %3, align 4, !tbaa !4
  %19 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %20 = sitofp i32 %19 to float
  %21 = fdiv contract float 1.000000e+00, %20
  %22 = fpext float %21 to double
  %23 = load { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, align 8, !tbaa !8
  store { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %23, ptr %loadgep_2, align 8, !tbaa !8
  %24 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i32 0, i32 7, i64 0, i32 0
  %25 = load i64, ptr %24, align 8, !tbaa !8
  %26 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i32 0, i32 7, i64 0, i32 1
  %27 = load i64, ptr %26, align 8, !tbaa !8
  %28 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i32 0, i32 7, i64 0, i32 2
  %29 = load i64, ptr %28, align 8, !tbaa !8
  %30 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i32 0, i32 0
  %31 = load ptr, ptr %30, align 8, !tbaa !8
  %32 = load i32, ptr %3, align 4, !tbaa !4
  %33 = sext i32 %32 to i64
  %34 = sub i64 %33, %25
  %35 = getelementptr double, ptr %31, i64 %34
  store double %22, ptr %35, align 8, !tbaa !4
  %36 = load { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, align 8, !tbaa !8
  store { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %36, ptr %loadgep_4, align 8, !tbaa !8
  %37 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i32 0, i32 7, i64 0, i32 0
  %38 = load i64, ptr %37, align 8, !tbaa !8
  %39 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i32 0, i32 7, i64 0, i32 1
  %40 = load i64, ptr %39, align 8, !tbaa !8
  %41 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i32 0, i32 7, i64 0, i32 2
  %42 = load i64, ptr %41, align 8, !tbaa !8
  %43 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i32 0, i32 0
  %44 = load ptr, ptr %43, align 8, !tbaa !8
  %45 = load i32, ptr %3, align 4, !tbaa !4
  %46 = sext i32 %45 to i64
  %47 = sub i64 %46, %38
  %48 = getelementptr double, ptr %44, i64 %47
  %49 = load double, ptr %48, align 8, !tbaa !4
  store double %49, ptr %2, align 8, !tbaa !4
  br label %omp.region.cont2

omp.region.cont2:                                 ; preds = %omp.wsloop.region
  br label %omp_loop.inc

omp_loop.inc:                                     ; preds = %omp.region.cont2
  %omp_loop.next = add nuw i32 %omp_loop.iv, 1
  br label %omp_loop.header

omp.par.outlined.exit.exitStub:                   ; preds = %omp.par.pre_finalize
  ret void
}

declare ptr @_FortranAioBeginExternalFormattedOutput(ptr, i64, ptr, i32, ptr, i32)

declare zeroext i1 @_FortranAioOutputAscii(ptr, ptr, i64)

declare zeroext i1 @_FortranAioOutputInteger32(ptr, i32)

declare zeroext i1 @_FortranAioOutputReal64(ptr, double)

declare i32 @_FortranAioEndIoStatement(ptr)

; Function Attrs: mustprogress nocallback nofree nosync nounwind willreturn
declare ptr @llvm.stacksave() #3

; Function Attrs: mustprogress nocallback nofree nosync nounwind willreturn
declare void @llvm.stackrestore(ptr) #3

; Function Attrs: nounwind
declare i32 @__kmpc_global_thread_num(ptr) #4

; Function Attrs: nounwind
declare void @__kmpc_for_static_init_4u(ptr, i32, i32, ptr, ptr, ptr, ptr, i32, i32) #4

; Function Attrs: nounwind
declare void @__kmpc_for_static_fini(ptr, i32) #4

; Function Attrs: convergent nounwind
declare void @__kmpc_barrier(ptr, i32) #5

; Function Attrs: nounwind
declare !callback !10 void @__kmpc_fork_call(ptr, i32, ptr, ...) #4

attributes #0 = { mustprogress nofree nounwind willreturn allockind("alloc,uninitialized") allocsize(0) memory(inaccessiblemem: readwrite) "alloc-family"="malloc" }
attributes #1 = { mustprogress nounwind willreturn allockind("free") memory(argmem: readwrite, inaccessiblemem: readwrite) "alloc-family"="malloc" }
attributes #2 = { norecurse nounwind }
attributes #3 = { mustprogress nocallback nofree nosync nounwind willreturn }
attributes #4 = { nounwind }
attributes #5 = { convergent nounwind }

!llvm.module.flags = !{!0, !1, !2, !3}

!0 = !{i32 2, !"Debug Info Version", i32 3}
!1 = !{i32 7, !"openmp", i32 11}
!2 = !{i32 8, !"PIC Level", i32 2}
!3 = !{i32 7, !"PIE Level", i32 2}
!4 = !{!5, !5, i64 0}
!5 = !{!"any data access", !6, i64 0}
!6 = !{!"any access", !7, i64 0}
!7 = !{!"Flang Type TBAA Root"}
!8 = !{!9, !9, i64 0}
!9 = !{!"descriptor member", !6, i64 0}
!10 = !{!11}
!11 = !{i64 2, i64 -1, i64 -1, i1 true}
*** IR Dump After LowerExpectIntrinsicPass on _QQmain ***
define void @_QQmain() {
  %structArg = alloca { ptr, ptr, ptr }, align 8
  %1 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %2 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %3 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %4 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %5 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %6 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %7 = alloca i32, i64 1, align 4
  %8 = alloca i32, i64 1, align 4
  %9 = alloca double, i64 1, align 8
  store i32 1048576, ptr %8, align 4, !tbaa !4
  %10 = load i32, ptr %8, align 4, !tbaa !4
  %11 = sext i32 %10 to i64
  %12 = icmp sgt i64 %11, 0
  %13 = select i1 %12, i64 %11, i64 0
  %14 = mul i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), %13
  %15 = call ptr @malloc(i64 %14)
  %16 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } { ptr undef, i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), i32 20180515, i8 1, i8 28, i8 2, i8 0, [1 x [3 x i64]] [[3 x i64] [i64 1, i64 undef, i64 undef]] }, i64 %13, 7, 0, 1
  %17 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %16, i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), 7, 0, 2
  %18 = mul i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), %13
  %19 = mul i64 1, %13
  %20 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %17, ptr %15, 0
  store { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %20, ptr %6, align 8, !tbaa !8
  %21 = load { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %6, align 8, !tbaa !8
  store { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %21, ptr @_QFEarr, align 8, !tbaa !8
  br label %entry

entry:                                            ; preds = %0
  %omp_global_thread_num = call i32 @__kmpc_global_thread_num(ptr @1)
  br label %omp_parallel

omp_parallel:                                     ; preds = %entry
  %gep_ = getelementptr { ptr, ptr, ptr }, ptr %structArg, i32 0, i32 0
  store ptr %8, ptr %gep_, align 8
  %gep_5 = getelementptr { ptr, ptr, ptr }, ptr %structArg, i32 0, i32 1
  store ptr %5, ptr %gep_5, align 8
  %gep_6 = getelementptr { ptr, ptr, ptr }, ptr %structArg, i32 0, i32 2
  store ptr %4, ptr %gep_6, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr @1, i32 1, ptr @_QQmain..omp_par, ptr %structArg)
  br label %omp.par.outlined.exit

omp.par.outlined.exit:                            ; preds = %omp_parallel
  br label %omp.par.exit.split

omp.par.exit.split:                               ; preds = %omp.par.outlined.exit
  %22 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr @_QQcl.60ea5a38555821a77357f87d16df9a0f, i32 21)
  %23 = call i1 @_FortranAioOutputAscii(ptr %22, ptr @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %24 = load i32, ptr %8, align 4, !tbaa !4
  %25 = call i1 @_FortranAioOutputInteger32(ptr %22, i32 %24)
  %26 = call i1 @_FortranAioOutputAscii(ptr %22, ptr @_QQcl.2920697320, i64 5)
  %27 = load { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, align 8, !tbaa !8
  store { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %27, ptr %3, align 8, !tbaa !8
  %28 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i32 0, i32 7, i64 0, i32 0
  %29 = load i64, ptr %28, align 8, !tbaa !8
  %30 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i32 0, i32 7, i64 0, i32 1
  %31 = load i64, ptr %30, align 8, !tbaa !8
  %32 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i32 0, i32 7, i64 0, i32 2
  %33 = load i64, ptr %32, align 8, !tbaa !8
  %34 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i32 0, i32 0
  %35 = load ptr, ptr %34, align 8, !tbaa !8
  %36 = sub i64 1, %29
  %37 = getelementptr double, ptr %35, i64 %36
  %38 = load double, ptr %37, align 8, !tbaa !4
  %39 = load i32, ptr %8, align 4, !tbaa !4
  %40 = sext i32 %39 to i64
  %41 = sub i64 %40, %29
  %42 = getelementptr double, ptr %35, i64 %41
  %43 = load double, ptr %42, align 8, !tbaa !4
  %44 = fadd contract double %38, %43
  %45 = call i1 @_FortranAioOutputReal64(ptr %22, double %44)
  %46 = call i32 @_FortranAioEndIoStatement(ptr %22)
  %47 = load { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, align 8, !tbaa !8
  store { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %47, ptr %2, align 8, !tbaa !8
  %48 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %2, i32 0, i32 0
  %49 = load ptr, ptr %48, align 8, !tbaa !8
  call void @free(ptr %49)
  store { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } { ptr null, i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), i32 20180515, i8 1, i8 28, i8 2, i8 0, [1 x [3 x i64]] [[3 x i64] [i64 1, i64 0, i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64)]] }, ptr %1, align 8, !tbaa !8
  %50 = load { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %1, align 8, !tbaa !8
  store { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %50, ptr @_QFEarr, align 8, !tbaa !8
  ret void
}
*** IR Dump After SimplifyCFGPass on _QQmain ***
define void @_QQmain() {
entry:
  %structArg = alloca { ptr, ptr, ptr }, align 8
  %0 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %1 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %2 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %3 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %4 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %5 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %6 = alloca i32, i64 1, align 4
  %7 = alloca i32, i64 1, align 4
  %8 = alloca double, i64 1, align 8
  store i32 1048576, ptr %7, align 4, !tbaa !4
  %9 = load i32, ptr %7, align 4, !tbaa !4
  %10 = sext i32 %9 to i64
  %11 = icmp sgt i64 %10, 0
  %12 = select i1 %11, i64 %10, i64 0
  %13 = mul i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), %12
  %14 = call ptr @malloc(i64 %13)
  %15 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } { ptr undef, i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), i32 20180515, i8 1, i8 28, i8 2, i8 0, [1 x [3 x i64]] [[3 x i64] [i64 1, i64 undef, i64 undef]] }, i64 %12, 7, 0, 1
  %16 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %15, i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), 7, 0, 2
  %17 = mul i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), %12
  %18 = mul i64 1, %12
  %19 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %16, ptr %14, 0
  store { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %19, ptr %5, align 8, !tbaa !8
  %20 = load { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, align 8, !tbaa !8
  store { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %20, ptr @_QFEarr, align 8, !tbaa !8
  %omp_global_thread_num = call i32 @__kmpc_global_thread_num(ptr @1)
  %gep_ = getelementptr { ptr, ptr, ptr }, ptr %structArg, i32 0, i32 0
  store ptr %7, ptr %gep_, align 8
  %gep_5 = getelementptr { ptr, ptr, ptr }, ptr %structArg, i32 0, i32 1
  store ptr %4, ptr %gep_5, align 8
  %gep_6 = getelementptr { ptr, ptr, ptr }, ptr %structArg, i32 0, i32 2
  store ptr %3, ptr %gep_6, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr @1, i32 1, ptr @_QQmain..omp_par, ptr %structArg)
  %21 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr @_QQcl.60ea5a38555821a77357f87d16df9a0f, i32 21)
  %22 = call i1 @_FortranAioOutputAscii(ptr %21, ptr @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %23 = load i32, ptr %7, align 4, !tbaa !4
  %24 = call i1 @_FortranAioOutputInteger32(ptr %21, i32 %23)
  %25 = call i1 @_FortranAioOutputAscii(ptr %21, ptr @_QQcl.2920697320, i64 5)
  %26 = load { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, align 8, !tbaa !8
  store { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %26, ptr %2, align 8, !tbaa !8
  %27 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %2, i32 0, i32 7, i64 0, i32 0
  %28 = load i64, ptr %27, align 8, !tbaa !8
  %29 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %2, i32 0, i32 7, i64 0, i32 1
  %30 = load i64, ptr %29, align 8, !tbaa !8
  %31 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %2, i32 0, i32 7, i64 0, i32 2
  %32 = load i64, ptr %31, align 8, !tbaa !8
  %33 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %2, i32 0, i32 0
  %34 = load ptr, ptr %33, align 8, !tbaa !8
  %35 = sub i64 1, %28
  %36 = getelementptr double, ptr %34, i64 %35
  %37 = load double, ptr %36, align 8, !tbaa !4
  %38 = load i32, ptr %7, align 4, !tbaa !4
  %39 = sext i32 %38 to i64
  %40 = sub i64 %39, %28
  %41 = getelementptr double, ptr %34, i64 %40
  %42 = load double, ptr %41, align 8, !tbaa !4
  %43 = fadd contract double %37, %42
  %44 = call i1 @_FortranAioOutputReal64(ptr %21, double %43)
  %45 = call i32 @_FortranAioEndIoStatement(ptr %21)
  %46 = load { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, align 8, !tbaa !8
  store { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %46, ptr %1, align 8, !tbaa !8
  %47 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %1, i32 0, i32 0
  %48 = load ptr, ptr %47, align 8, !tbaa !8
  call void @free(ptr %48)
  store { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } { ptr null, i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), i32 20180515, i8 1, i8 28, i8 2, i8 0, [1 x [3 x i64]] [[3 x i64] [i64 1, i64 0, i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64)]] }, ptr %0, align 8, !tbaa !8
  %49 = load { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %0, align 8, !tbaa !8
  store { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %49, ptr @_QFEarr, align 8, !tbaa !8
  ret void
}
*** IR Dump After SROAPass on _QQmain ***
define void @_QQmain() {
entry:
  %structArg = alloca { ptr, ptr, ptr }, align 8
  %0 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %1 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %2 = alloca i32, i64 1, align 4
  store i32 1048576, ptr %2, align 4, !tbaa !4
  %3 = load i32, ptr %2, align 4, !tbaa !4
  %4 = sext i32 %3 to i64
  %5 = icmp sgt i64 %4, 0
  %6 = select i1 %5, i64 %4, i64 0
  %7 = mul i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), %6
  %8 = call ptr @malloc(i64 %7)
  %9 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } { ptr undef, i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), i32 20180515, i8 1, i8 28, i8 2, i8 0, [1 x [3 x i64]] [[3 x i64] [i64 1, i64 undef, i64 undef]] }, i64 %6, 7, 0, 1
  %10 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %9, i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), 7, 0, 2
  %11 = mul i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), %6
  %12 = mul i64 1, %6
  %13 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %10, ptr %8, 0
  %.fca.0.extract = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %13, 0
  %.fca.1.extract = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %13, 1
  %.fca.2.extract = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %13, 2
  %.fca.3.extract = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %13, 3
  %.fca.4.extract = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %13, 4
  %.fca.5.extract = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %13, 5
  %.fca.6.extract = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %13, 6
  %.fca.7.0.0.extract = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %13, 7, 0, 0
  %.fca.7.0.1.extract = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %13, 7, 0, 1
  %.fca.7.0.2.extract = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %13, 7, 0, 2
  %.fca.0.insert = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } poison, ptr %.fca.0.extract, 0
  %.fca.1.insert = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.0.insert, i64 %.fca.1.extract, 1
  %.fca.2.insert = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.1.insert, i32 %.fca.2.extract, 2
  %.fca.3.insert = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.2.insert, i8 %.fca.3.extract, 3
  %.fca.4.insert = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.3.insert, i8 %.fca.4.extract, 4
  %.fca.5.insert = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.4.insert, i8 %.fca.5.extract, 5
  %.fca.6.insert = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.5.insert, i8 %.fca.6.extract, 6
  %.fca.7.0.0.insert = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.6.insert, i64 %.fca.7.0.0.extract, 7, 0, 0
  %.fca.7.0.1.insert = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.7.0.0.insert, i64 %.fca.7.0.1.extract, 7, 0, 1
  %.fca.7.0.2.insert = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.7.0.1.insert, i64 %.fca.7.0.2.extract, 7, 0, 2
  store { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.7.0.2.insert, ptr @_QFEarr, align 8, !tbaa !8
  %omp_global_thread_num = call i32 @__kmpc_global_thread_num(ptr @1)
  %gep_ = getelementptr { ptr, ptr, ptr }, ptr %structArg, i32 0, i32 0
  store ptr %2, ptr %gep_, align 8
  %gep_5 = getelementptr { ptr, ptr, ptr }, ptr %structArg, i32 0, i32 1
  store ptr %1, ptr %gep_5, align 8
  %gep_6 = getelementptr { ptr, ptr, ptr }, ptr %structArg, i32 0, i32 2
  store ptr %0, ptr %gep_6, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr @1, i32 1, ptr @_QQmain..omp_par, ptr %structArg)
  %14 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr @_QQcl.60ea5a38555821a77357f87d16df9a0f, i32 21)
  %15 = call i1 @_FortranAioOutputAscii(ptr %14, ptr @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %16 = load i32, ptr %2, align 4, !tbaa !4
  %17 = call i1 @_FortranAioOutputInteger32(ptr %14, i32 %16)
  %18 = call i1 @_FortranAioOutputAscii(ptr %14, ptr @_QQcl.2920697320, i64 5)
  %19 = load { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, align 8, !tbaa !8
  %.fca.0.extract17 = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %19, 0
  %.fca.1.extract18 = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %19, 1
  %.fca.2.extract19 = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %19, 2
  %.fca.3.extract20 = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %19, 3
  %.fca.4.extract21 = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %19, 4
  %.fca.5.extract22 = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %19, 5
  %.fca.6.extract23 = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %19, 6
  %.fca.7.0.0.extract24 = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %19, 7, 0, 0
  %.fca.7.0.1.extract25 = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %19, 7, 0, 1
  %.fca.7.0.2.extract26 = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %19, 7, 0, 2
  %20 = sub i64 1, %.fca.7.0.0.extract24
  %21 = getelementptr double, ptr %.fca.0.extract17, i64 %20
  %22 = load double, ptr %21, align 8, !tbaa !4
  %23 = load i32, ptr %2, align 4, !tbaa !4
  %24 = sext i32 %23 to i64
  %25 = sub i64 %24, %.fca.7.0.0.extract24
  %26 = getelementptr double, ptr %.fca.0.extract17, i64 %25
  %27 = load double, ptr %26, align 8, !tbaa !4
  %28 = fadd contract double %22, %27
  %29 = call i1 @_FortranAioOutputReal64(ptr %14, double %28)
  %30 = call i32 @_FortranAioEndIoStatement(ptr %14)
  %31 = load { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, align 8, !tbaa !8
  %.fca.0.extract34 = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %31, 0
  %.fca.1.extract35 = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %31, 1
  %.fca.2.extract36 = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %31, 2
  %.fca.3.extract37 = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %31, 3
  %.fca.4.extract38 = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %31, 4
  %.fca.5.extract39 = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %31, 5
  %.fca.6.extract40 = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %31, 6
  %.fca.7.0.0.extract41 = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %31, 7, 0, 0
  %.fca.7.0.1.extract42 = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %31, 7, 0, 1
  %.fca.7.0.2.extract43 = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %31, 7, 0, 2
  call void @free(ptr %.fca.0.extract34)
  %.fca.0.insert54 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } poison, ptr null, 0
  %.fca.1.insert56 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.0.insert54, i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), 1
  %.fca.2.insert58 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.1.insert56, i32 20180515, 2
  %.fca.3.insert60 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.2.insert58, i8 1, 3
  %.fca.4.insert62 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.3.insert60, i8 28, 4
  %.fca.5.insert64 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.4.insert62, i8 2, 5
  %.fca.6.insert66 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.5.insert64, i8 0, 6
  %.fca.7.0.0.insert68 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.6.insert66, i64 1, 7, 0, 0
  %.fca.7.0.1.insert70 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.7.0.0.insert68, i64 0, 7, 0, 1
  %.fca.7.0.2.insert72 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.7.0.1.insert70, i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), 7, 0, 2
  store { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.7.0.2.insert72, ptr @_QFEarr, align 8, !tbaa !8
  ret void
}
*** IR Dump After EarlyCSEPass on _QQmain ***
define void @_QQmain() {
entry:
  %structArg = alloca { ptr, ptr, ptr }, align 8
  %0 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %1 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %2 = alloca i32, i64 1, align 4
  store i32 1048576, ptr %2, align 4, !tbaa !4
  %3 = call ptr @malloc(i64 mul (i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), i64 1048576))
  %4 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } { ptr undef, i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), i32 20180515, i8 1, i8 28, i8 2, i8 0, [1 x [3 x i64]] [[3 x i64] [i64 1, i64 1048576, i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64)]] }, ptr %3, 0
  %.fca.1.extract = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %4, 1
  %.fca.2.extract = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %4, 2
  %.fca.3.extract = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %4, 3
  %.fca.4.extract = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %4, 4
  %.fca.5.extract = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %4, 5
  %.fca.6.extract = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %4, 6
  %.fca.7.0.0.extract = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %4, 7, 0, 0
  %.fca.7.0.1.extract = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %4, 7, 0, 1
  %.fca.7.0.2.extract = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %4, 7, 0, 2
  %.fca.0.insert = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } poison, ptr %3, 0
  %.fca.1.insert = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.0.insert, i64 %.fca.1.extract, 1
  %.fca.2.insert = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.1.insert, i32 %.fca.2.extract, 2
  %.fca.3.insert = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.2.insert, i8 %.fca.3.extract, 3
  %.fca.4.insert = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.3.insert, i8 %.fca.4.extract, 4
  %.fca.5.insert = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.4.insert, i8 %.fca.5.extract, 5
  %.fca.6.insert = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.5.insert, i8 %.fca.6.extract, 6
  %.fca.7.0.0.insert = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.6.insert, i64 %.fca.7.0.0.extract, 7, 0, 0
  %.fca.7.0.1.insert = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.7.0.0.insert, i64 %.fca.7.0.1.extract, 7, 0, 1
  %.fca.7.0.2.insert = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.7.0.1.insert, i64 %.fca.7.0.2.extract, 7, 0, 2
  store { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.7.0.2.insert, ptr @_QFEarr, align 8, !tbaa !8
  %omp_global_thread_num = call i32 @__kmpc_global_thread_num(ptr @1)
  store ptr %2, ptr %structArg, align 8
  %gep_5 = getelementptr { ptr, ptr, ptr }, ptr %structArg, i32 0, i32 1
  store ptr %1, ptr %gep_5, align 8
  %gep_6 = getelementptr { ptr, ptr, ptr }, ptr %structArg, i32 0, i32 2
  store ptr %0, ptr %gep_6, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr @1, i32 1, ptr @_QQmain..omp_par, ptr %structArg)
  %5 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr @_QQcl.60ea5a38555821a77357f87d16df9a0f, i32 21)
  %6 = call i1 @_FortranAioOutputAscii(ptr %5, ptr @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %7 = load i32, ptr %2, align 4, !tbaa !4
  %8 = call i1 @_FortranAioOutputInteger32(ptr %5, i32 %7)
  %9 = call i1 @_FortranAioOutputAscii(ptr %5, ptr @_QQcl.2920697320, i64 5)
  %10 = load { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, align 8, !tbaa !8
  %.fca.0.extract17 = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %10, 0
  %.fca.7.0.0.extract24 = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %10, 7, 0, 0
  %11 = sub i64 1, %.fca.7.0.0.extract24
  %12 = getelementptr double, ptr %.fca.0.extract17, i64 %11
  %13 = load double, ptr %12, align 8, !tbaa !4
  %14 = load i32, ptr %2, align 4, !tbaa !4
  %15 = sext i32 %14 to i64
  %16 = sub i64 %15, %.fca.7.0.0.extract24
  %17 = getelementptr double, ptr %.fca.0.extract17, i64 %16
  %18 = load double, ptr %17, align 8, !tbaa !4
  %19 = fadd contract double %13, %18
  %20 = call i1 @_FortranAioOutputReal64(ptr %5, double %19)
  %21 = call i32 @_FortranAioEndIoStatement(ptr %5)
  %22 = load { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, align 8, !tbaa !8
  %.fca.0.extract34 = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %22, 0
  call void @free(ptr %.fca.0.extract34)
  store { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } { ptr null, i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), i32 20180515, i8 1, i8 28, i8 2, i8 0, [1 x [3 x i64]] [[3 x i64] [i64 1, i64 0, i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64)]] }, ptr @_QFEarr, align 8, !tbaa !8
  ret void
}
*** IR Dump After CallSiteSplittingPass on _QQmain ***
define void @_QQmain() {
entry:
  %structArg = alloca { ptr, ptr, ptr }, align 8
  %0 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %1 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %2 = alloca i32, i64 1, align 4
  store i32 1048576, ptr %2, align 4, !tbaa !4
  %3 = call ptr @malloc(i64 mul (i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), i64 1048576))
  %4 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } { ptr undef, i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), i32 20180515, i8 1, i8 28, i8 2, i8 0, [1 x [3 x i64]] [[3 x i64] [i64 1, i64 1048576, i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64)]] }, ptr %3, 0
  %.fca.1.extract = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %4, 1
  %.fca.2.extract = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %4, 2
  %.fca.3.extract = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %4, 3
  %.fca.4.extract = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %4, 4
  %.fca.5.extract = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %4, 5
  %.fca.6.extract = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %4, 6
  %.fca.7.0.0.extract = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %4, 7, 0, 0
  %.fca.7.0.1.extract = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %4, 7, 0, 1
  %.fca.7.0.2.extract = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %4, 7, 0, 2
  %.fca.0.insert = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } poison, ptr %3, 0
  %.fca.1.insert = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.0.insert, i64 %.fca.1.extract, 1
  %.fca.2.insert = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.1.insert, i32 %.fca.2.extract, 2
  %.fca.3.insert = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.2.insert, i8 %.fca.3.extract, 3
  %.fca.4.insert = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.3.insert, i8 %.fca.4.extract, 4
  %.fca.5.insert = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.4.insert, i8 %.fca.5.extract, 5
  %.fca.6.insert = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.5.insert, i8 %.fca.6.extract, 6
  %.fca.7.0.0.insert = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.6.insert, i64 %.fca.7.0.0.extract, 7, 0, 0
  %.fca.7.0.1.insert = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.7.0.0.insert, i64 %.fca.7.0.1.extract, 7, 0, 1
  %.fca.7.0.2.insert = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.7.0.1.insert, i64 %.fca.7.0.2.extract, 7, 0, 2
  store { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.7.0.2.insert, ptr @_QFEarr, align 8, !tbaa !8
  %omp_global_thread_num = call i32 @__kmpc_global_thread_num(ptr @1)
  store ptr %2, ptr %structArg, align 8
  %gep_5 = getelementptr { ptr, ptr, ptr }, ptr %structArg, i32 0, i32 1
  store ptr %1, ptr %gep_5, align 8
  %gep_6 = getelementptr { ptr, ptr, ptr }, ptr %structArg, i32 0, i32 2
  store ptr %0, ptr %gep_6, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr @1, i32 1, ptr @_QQmain..omp_par, ptr %structArg)
  %5 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr @_QQcl.60ea5a38555821a77357f87d16df9a0f, i32 21)
  %6 = call i1 @_FortranAioOutputAscii(ptr %5, ptr @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %7 = load i32, ptr %2, align 4, !tbaa !4
  %8 = call i1 @_FortranAioOutputInteger32(ptr %5, i32 %7)
  %9 = call i1 @_FortranAioOutputAscii(ptr %5, ptr @_QQcl.2920697320, i64 5)
  %10 = load { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, align 8, !tbaa !8
  %.fca.0.extract17 = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %10, 0
  %.fca.7.0.0.extract24 = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %10, 7, 0, 0
  %11 = sub i64 1, %.fca.7.0.0.extract24
  %12 = getelementptr double, ptr %.fca.0.extract17, i64 %11
  %13 = load double, ptr %12, align 8, !tbaa !4
  %14 = load i32, ptr %2, align 4, !tbaa !4
  %15 = sext i32 %14 to i64
  %16 = sub i64 %15, %.fca.7.0.0.extract24
  %17 = getelementptr double, ptr %.fca.0.extract17, i64 %16
  %18 = load double, ptr %17, align 8, !tbaa !4
  %19 = fadd contract double %13, %18
  %20 = call i1 @_FortranAioOutputReal64(ptr %5, double %19)
  %21 = call i32 @_FortranAioEndIoStatement(ptr %5)
  %22 = load { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, align 8, !tbaa !8
  %.fca.0.extract34 = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %22, 0
  call void @free(ptr %.fca.0.extract34)
  store { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } { ptr null, i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), i32 20180515, i8 1, i8 28, i8 2, i8 0, [1 x [3 x i64]] [[3 x i64] [i64 1, i64 0, i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64)]] }, ptr @_QFEarr, align 8, !tbaa !8
  ret void
}
*** IR Dump After LowerExpectIntrinsicPass on _QQmain..omp_par ***
; Function Attrs: norecurse nounwind
define internal void @_QQmain..omp_par(ptr noalias %tid.addr, ptr noalias %zero.addr, ptr %0) #2 {
omp.par.entry:
  %gep_ = getelementptr { ptr, ptr, ptr }, ptr %0, i32 0, i32 0
  %loadgep_ = load ptr, ptr %gep_, align 8
  %gep_1 = getelementptr { ptr, ptr, ptr }, ptr %0, i32 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %gep_3 = getelementptr { ptr, ptr, ptr }, ptr %0, i32 0, i32 2
  %loadgep_4 = load ptr, ptr %gep_3, align 8
  %tid.addr.local = alloca i32, align 4
  %1 = load i32, ptr %tid.addr, align 4
  store i32 %1, ptr %tid.addr.local, align 4
  %tid = load i32, ptr %tid.addr.local, align 4
  %p.lastiter = alloca i32, align 4
  %p.lowerbound = alloca i32, align 4
  %p.upperbound = alloca i32, align 4
  %p.stride = alloca i32, align 4
  br label %omp.par.region

omp.par.region:                                   ; preds = %omp.par.entry
  br label %omp.par.region1

omp.par.region1:                                  ; preds = %omp.par.region
  %2 = alloca double, i64 1, align 8
  %3 = alloca i32, i64 1, align 4
  %4 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %5 = select i1 false, i32 %4, i32 1
  %6 = select i1 false, i32 1, i32 %4
  %7 = sub nsw i32 %6, %5
  %8 = icmp slt i32 %6, %5
  %9 = udiv i32 %7, 1
  %10 = add i32 %9, 1
  %omp_loop.tripcount = select i1 %8, i32 0, i32 %10
  br label %omp_loop.preheader

omp_loop.preheader:                               ; preds = %omp.par.region1
  store i32 0, ptr %p.lowerbound, align 4
  %11 = sub i32 %omp_loop.tripcount, 1
  store i32 %11, ptr %p.upperbound, align 4
  store i32 1, ptr %p.stride, align 4
  %omp_global_thread_num3 = call i32 @__kmpc_global_thread_num(ptr @1)
  call void @__kmpc_for_static_init_4u(ptr @1, i32 %omp_global_thread_num3, i32 34, ptr %p.lastiter, ptr %p.lowerbound, ptr %p.upperbound, ptr %p.stride, i32 1, i32 0)
  %12 = load i32, ptr %p.lowerbound, align 4
  %13 = load i32, ptr %p.upperbound, align 4
  %14 = sub i32 %13, %12
  %15 = add i32 %14, 1
  br label %omp_loop.header

omp_loop.header:                                  ; preds = %omp_loop.inc, %omp_loop.preheader
  %omp_loop.iv = phi i32 [ 0, %omp_loop.preheader ], [ %omp_loop.next, %omp_loop.inc ]
  br label %omp_loop.cond

omp_loop.cond:                                    ; preds = %omp_loop.header
  %omp_loop.cmp = icmp ult i32 %omp_loop.iv, %15
  br i1 %omp_loop.cmp, label %omp_loop.body, label %omp_loop.exit

omp_loop.exit:                                    ; preds = %omp_loop.cond
  call void @__kmpc_for_static_fini(ptr @1, i32 %omp_global_thread_num3)
  %omp_global_thread_num4 = call i32 @__kmpc_global_thread_num(ptr @1)
  call void @__kmpc_barrier(ptr @2, i32 %omp_global_thread_num4)
  br label %omp_loop.after

omp_loop.after:                                   ; preds = %omp_loop.exit
  br label %omp.region.cont

omp.region.cont:                                  ; preds = %omp_loop.after
  br label %omp.par.pre_finalize

omp.par.pre_finalize:                             ; preds = %omp.region.cont
  br label %omp.par.outlined.exit.exitStub

omp_loop.body:                                    ; preds = %omp_loop.cond
  %16 = add i32 %omp_loop.iv, %12
  %17 = mul i32 %16, 1
  %18 = add i32 %17, 1
  br label %omp.wsloop.region

omp.wsloop.region:                                ; preds = %omp_loop.body
  store i32 %18, ptr %3, align 4, !tbaa !4
  %19 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %20 = sitofp i32 %19 to float
  %21 = fdiv contract float 1.000000e+00, %20
  %22 = fpext float %21 to double
  %23 = load { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, align 8, !tbaa !8
  store { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %23, ptr %loadgep_2, align 8, !tbaa !8
  %24 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i32 0, i32 7, i64 0, i32 0
  %25 = load i64, ptr %24, align 8, !tbaa !8
  %26 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i32 0, i32 7, i64 0, i32 1
  %27 = load i64, ptr %26, align 8, !tbaa !8
  %28 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i32 0, i32 7, i64 0, i32 2
  %29 = load i64, ptr %28, align 8, !tbaa !8
  %30 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i32 0, i32 0
  %31 = load ptr, ptr %30, align 8, !tbaa !8
  %32 = load i32, ptr %3, align 4, !tbaa !4
  %33 = sext i32 %32 to i64
  %34 = sub i64 %33, %25
  %35 = getelementptr double, ptr %31, i64 %34
  store double %22, ptr %35, align 8, !tbaa !4
  %36 = load { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, align 8, !tbaa !8
  store { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %36, ptr %loadgep_4, align 8, !tbaa !8
  %37 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i32 0, i32 7, i64 0, i32 0
  %38 = load i64, ptr %37, align 8, !tbaa !8
  %39 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i32 0, i32 7, i64 0, i32 1
  %40 = load i64, ptr %39, align 8, !tbaa !8
  %41 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i32 0, i32 7, i64 0, i32 2
  %42 = load i64, ptr %41, align 8, !tbaa !8
  %43 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i32 0, i32 0
  %44 = load ptr, ptr %43, align 8, !tbaa !8
  %45 = load i32, ptr %3, align 4, !tbaa !4
  %46 = sext i32 %45 to i64
  %47 = sub i64 %46, %38
  %48 = getelementptr double, ptr %44, i64 %47
  %49 = load double, ptr %48, align 8, !tbaa !4
  store double %49, ptr %2, align 8, !tbaa !4
  br label %omp.region.cont2

omp.region.cont2:                                 ; preds = %omp.wsloop.region
  br label %omp_loop.inc

omp_loop.inc:                                     ; preds = %omp.region.cont2
  %omp_loop.next = add nuw i32 %omp_loop.iv, 1
  br label %omp_loop.header

omp.par.outlined.exit.exitStub:                   ; preds = %omp.par.pre_finalize
  ret void
}
*** IR Dump After SimplifyCFGPass on _QQmain..omp_par ***
; Function Attrs: norecurse nounwind
define internal void @_QQmain..omp_par(ptr noalias %tid.addr, ptr noalias %zero.addr, ptr %0) #2 {
omp.par.entry:
  %gep_ = getelementptr { ptr, ptr, ptr }, ptr %0, i32 0, i32 0
  %loadgep_ = load ptr, ptr %gep_, align 8
  %gep_1 = getelementptr { ptr, ptr, ptr }, ptr %0, i32 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %gep_3 = getelementptr { ptr, ptr, ptr }, ptr %0, i32 0, i32 2
  %loadgep_4 = load ptr, ptr %gep_3, align 8
  %tid.addr.local = alloca i32, align 4
  %1 = load i32, ptr %tid.addr, align 4
  store i32 %1, ptr %tid.addr.local, align 4
  %tid = load i32, ptr %tid.addr.local, align 4
  %p.lastiter = alloca i32, align 4
  %p.lowerbound = alloca i32, align 4
  %p.upperbound = alloca i32, align 4
  %p.stride = alloca i32, align 4
  %2 = alloca double, i64 1, align 8
  %3 = alloca i32, i64 1, align 4
  %4 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %5 = select i1 false, i32 %4, i32 1
  %6 = select i1 false, i32 1, i32 %4
  %7 = sub nsw i32 %6, %5
  %8 = icmp slt i32 %6, %5
  %9 = udiv i32 %7, 1
  %10 = add i32 %9, 1
  %omp_loop.tripcount = select i1 %8, i32 0, i32 %10
  store i32 0, ptr %p.lowerbound, align 4
  %11 = sub i32 %omp_loop.tripcount, 1
  store i32 %11, ptr %p.upperbound, align 4
  store i32 1, ptr %p.stride, align 4
  %omp_global_thread_num3 = call i32 @__kmpc_global_thread_num(ptr @1)
  call void @__kmpc_for_static_init_4u(ptr @1, i32 %omp_global_thread_num3, i32 34, ptr %p.lastiter, ptr %p.lowerbound, ptr %p.upperbound, ptr %p.stride, i32 1, i32 0)
  %12 = load i32, ptr %p.lowerbound, align 4
  %13 = load i32, ptr %p.upperbound, align 4
  %14 = sub i32 %13, %12
  %15 = add i32 %14, 1
  br label %omp_loop.header

omp_loop.header:                                  ; preds = %omp_loop.body, %omp.par.entry
  %omp_loop.iv = phi i32 [ 0, %omp.par.entry ], [ %omp_loop.next, %omp_loop.body ]
  %omp_loop.cmp = icmp ult i32 %omp_loop.iv, %15
  br i1 %omp_loop.cmp, label %omp_loop.body, label %omp_loop.exit

omp_loop.exit:                                    ; preds = %omp_loop.header
  call void @__kmpc_for_static_fini(ptr @1, i32 %omp_global_thread_num3)
  %omp_global_thread_num4 = call i32 @__kmpc_global_thread_num(ptr @1)
  call void @__kmpc_barrier(ptr @2, i32 %omp_global_thread_num4)
  ret void

omp_loop.body:                                    ; preds = %omp_loop.header
  %16 = add i32 %omp_loop.iv, %12
  %17 = mul i32 %16, 1
  %18 = add i32 %17, 1
  store i32 %18, ptr %3, align 4, !tbaa !4
  %19 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %20 = sitofp i32 %19 to float
  %21 = fdiv contract float 1.000000e+00, %20
  %22 = fpext float %21 to double
  %23 = load { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, align 8, !tbaa !8
  store { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %23, ptr %loadgep_2, align 8, !tbaa !8
  %24 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i32 0, i32 7, i64 0, i32 0
  %25 = load i64, ptr %24, align 8, !tbaa !8
  %26 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i32 0, i32 7, i64 0, i32 1
  %27 = load i64, ptr %26, align 8, !tbaa !8
  %28 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i32 0, i32 7, i64 0, i32 2
  %29 = load i64, ptr %28, align 8, !tbaa !8
  %30 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i32 0, i32 0
  %31 = load ptr, ptr %30, align 8, !tbaa !8
  %32 = load i32, ptr %3, align 4, !tbaa !4
  %33 = sext i32 %32 to i64
  %34 = sub i64 %33, %25
  %35 = getelementptr double, ptr %31, i64 %34
  store double %22, ptr %35, align 8, !tbaa !4
  %36 = load { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, align 8, !tbaa !8
  store { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %36, ptr %loadgep_4, align 8, !tbaa !8
  %37 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i32 0, i32 7, i64 0, i32 0
  %38 = load i64, ptr %37, align 8, !tbaa !8
  %39 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i32 0, i32 7, i64 0, i32 1
  %40 = load i64, ptr %39, align 8, !tbaa !8
  %41 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i32 0, i32 7, i64 0, i32 2
  %42 = load i64, ptr %41, align 8, !tbaa !8
  %43 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i32 0, i32 0
  %44 = load ptr, ptr %43, align 8, !tbaa !8
  %45 = load i32, ptr %3, align 4, !tbaa !4
  %46 = sext i32 %45 to i64
  %47 = sub i64 %46, %38
  %48 = getelementptr double, ptr %44, i64 %47
  %49 = load double, ptr %48, align 8, !tbaa !4
  store double %49, ptr %2, align 8, !tbaa !4
  %omp_loop.next = add nuw i32 %omp_loop.iv, 1
  br label %omp_loop.header
}
*** IR Dump After SROAPass on _QQmain..omp_par ***
; Function Attrs: norecurse nounwind
define internal void @_QQmain..omp_par(ptr noalias %tid.addr, ptr noalias %zero.addr, ptr %0) #2 {
omp.par.entry:
  %gep_ = getelementptr { ptr, ptr, ptr }, ptr %0, i32 0, i32 0
  %loadgep_ = load ptr, ptr %gep_, align 8
  %gep_1 = getelementptr { ptr, ptr, ptr }, ptr %0, i32 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %gep_3 = getelementptr { ptr, ptr, ptr }, ptr %0, i32 0, i32 2
  %loadgep_4 = load ptr, ptr %gep_3, align 8
  %1 = load i32, ptr %tid.addr, align 4
  %p.lastiter = alloca i32, align 4
  %p.lowerbound = alloca i32, align 4
  %p.upperbound = alloca i32, align 4
  %p.stride = alloca i32, align 4
  %2 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %3 = select i1 false, i32 %2, i32 1
  %4 = select i1 false, i32 1, i32 %2
  %5 = sub nsw i32 %4, %3
  %6 = icmp slt i32 %4, %3
  %7 = udiv i32 %5, 1
  %8 = add i32 %7, 1
  %omp_loop.tripcount = select i1 %6, i32 0, i32 %8
  store i32 0, ptr %p.lowerbound, align 4
  %9 = sub i32 %omp_loop.tripcount, 1
  store i32 %9, ptr %p.upperbound, align 4
  store i32 1, ptr %p.stride, align 4
  %omp_global_thread_num3 = call i32 @__kmpc_global_thread_num(ptr @1)
  call void @__kmpc_for_static_init_4u(ptr @1, i32 %omp_global_thread_num3, i32 34, ptr %p.lastiter, ptr %p.lowerbound, ptr %p.upperbound, ptr %p.stride, i32 1, i32 0)
  %10 = load i32, ptr %p.lowerbound, align 4
  %11 = load i32, ptr %p.upperbound, align 4
  %12 = sub i32 %11, %10
  %13 = add i32 %12, 1
  br label %omp_loop.header

omp_loop.header:                                  ; preds = %omp_loop.body, %omp.par.entry
  %omp_loop.iv = phi i32 [ 0, %omp.par.entry ], [ %omp_loop.next, %omp_loop.body ]
  %omp_loop.cmp = icmp ult i32 %omp_loop.iv, %13
  br i1 %omp_loop.cmp, label %omp_loop.body, label %omp_loop.exit

omp_loop.exit:                                    ; preds = %omp_loop.header
  call void @__kmpc_for_static_fini(ptr @1, i32 %omp_global_thread_num3)
  %omp_global_thread_num4 = call i32 @__kmpc_global_thread_num(ptr @1)
  call void @__kmpc_barrier(ptr @2, i32 %omp_global_thread_num4)
  ret void

omp_loop.body:                                    ; preds = %omp_loop.header
  %14 = add i32 %omp_loop.iv, %10
  %15 = mul i32 %14, 1
  %16 = add i32 %15, 1
  %17 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %18 = sitofp i32 %17 to float
  %19 = fdiv contract float 1.000000e+00, %18
  %20 = fpext float %19 to double
  %21 = load { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, align 8, !tbaa !8
  store { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %21, ptr %loadgep_2, align 8, !tbaa !8
  %22 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i32 0, i32 7, i64 0, i32 0
  %23 = load i64, ptr %22, align 8, !tbaa !8
  %24 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i32 0, i32 7, i64 0, i32 1
  %25 = load i64, ptr %24, align 8, !tbaa !8
  %26 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i32 0, i32 7, i64 0, i32 2
  %27 = load i64, ptr %26, align 8, !tbaa !8
  %28 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i32 0, i32 0
  %29 = load ptr, ptr %28, align 8, !tbaa !8
  %30 = sext i32 %16 to i64
  %31 = sub i64 %30, %23
  %32 = getelementptr double, ptr %29, i64 %31
  store double %20, ptr %32, align 8, !tbaa !4
  %33 = load { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, align 8, !tbaa !8
  store { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %33, ptr %loadgep_4, align 8, !tbaa !8
  %34 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i32 0, i32 7, i64 0, i32 0
  %35 = load i64, ptr %34, align 8, !tbaa !8
  %36 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i32 0, i32 7, i64 0, i32 1
  %37 = load i64, ptr %36, align 8, !tbaa !8
  %38 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i32 0, i32 7, i64 0, i32 2
  %39 = load i64, ptr %38, align 8, !tbaa !8
  %40 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i32 0, i32 0
  %41 = load ptr, ptr %40, align 8, !tbaa !8
  %42 = sext i32 %16 to i64
  %43 = sub i64 %42, %35
  %44 = getelementptr double, ptr %41, i64 %43
  %45 = load double, ptr %44, align 8, !tbaa !4
  %omp_loop.next = add nuw i32 %omp_loop.iv, 1
  br label %omp_loop.header
}
*** IR Dump After EarlyCSEPass on _QQmain..omp_par ***
; Function Attrs: norecurse nounwind
define internal void @_QQmain..omp_par(ptr noalias %tid.addr, ptr noalias %zero.addr, ptr %0) #2 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr, ptr }, ptr %0, i32 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %gep_3 = getelementptr { ptr, ptr, ptr }, ptr %0, i32 0, i32 2
  %loadgep_4 = load ptr, ptr %gep_3, align 8
  %p.lastiter = alloca i32, align 4
  %p.lowerbound = alloca i32, align 4
  %p.upperbound = alloca i32, align 4
  %p.stride = alloca i32, align 4
  %1 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %2 = sub nsw i32 %1, 1
  %3 = icmp slt i32 %1, 1
  %omp_loop.tripcount = select i1 %3, i32 0, i32 %1
  store i32 0, ptr %p.lowerbound, align 4
  %4 = sub i32 %omp_loop.tripcount, 1
  store i32 %4, ptr %p.upperbound, align 4
  store i32 1, ptr %p.stride, align 4
  %omp_global_thread_num3 = call i32 @__kmpc_global_thread_num(ptr @1)
  call void @__kmpc_for_static_init_4u(ptr @1, i32 %omp_global_thread_num3, i32 34, ptr %p.lastiter, ptr %p.lowerbound, ptr %p.upperbound, ptr %p.stride, i32 1, i32 0)
  %5 = load i32, ptr %p.lowerbound, align 4
  %6 = load i32, ptr %p.upperbound, align 4
  %7 = sub i32 %6, %5
  %8 = add i32 %7, 1
  br label %omp_loop.header

omp_loop.header:                                  ; preds = %omp_loop.body, %omp.par.entry
  %omp_loop.iv = phi i32 [ 0, %omp.par.entry ], [ %omp_loop.next, %omp_loop.body ]
  %omp_loop.cmp = icmp ult i32 %omp_loop.iv, %8
  br i1 %omp_loop.cmp, label %omp_loop.body, label %omp_loop.exit

omp_loop.exit:                                    ; preds = %omp_loop.header
  call void @__kmpc_for_static_fini(ptr @1, i32 %omp_global_thread_num3)
  %omp_global_thread_num4 = call i32 @__kmpc_global_thread_num(ptr @1)
  call void @__kmpc_barrier(ptr @2, i32 %omp_global_thread_num4)
  ret void

omp_loop.body:                                    ; preds = %omp_loop.header
  %9 = add i32 %omp_loop.iv, %5
  %10 = add i32 %9, 1
  %11 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %12 = sitofp i32 %11 to float
  %13 = fdiv contract float 1.000000e+00, %12
  %14 = fpext float %13 to double
  %15 = load { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, align 8, !tbaa !8
  store { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %15, ptr %loadgep_2, align 8, !tbaa !8
  %16 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i32 0, i32 7, i64 0, i32 0
  %17 = load i64, ptr %16, align 8, !tbaa !8
  %18 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i32 0, i32 7, i64 0, i32 1
  %19 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i32 0, i32 7, i64 0, i32 2
  %20 = load ptr, ptr %loadgep_2, align 8, !tbaa !8
  %21 = sext i32 %10 to i64
  %22 = sub i64 %21, %17
  %23 = getelementptr double, ptr %20, i64 %22
  store double %14, ptr %23, align 8, !tbaa !4
  %24 = load { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, align 8, !tbaa !8
  store { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %24, ptr %loadgep_4, align 8, !tbaa !8
  %25 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i32 0, i32 7, i64 0, i32 0
  %26 = load i64, ptr %25, align 8, !tbaa !8
  %27 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i32 0, i32 7, i64 0, i32 1
  %28 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i32 0, i32 7, i64 0, i32 2
  %29 = load ptr, ptr %loadgep_4, align 8, !tbaa !8
  %30 = sub i64 %21, %26
  %31 = getelementptr double, ptr %29, i64 %30
  %omp_loop.next = add nuw i32 %omp_loop.iv, 1
  br label %omp_loop.header
}
*** IR Dump After CallSiteSplittingPass on _QQmain..omp_par ***
; Function Attrs: norecurse nounwind
define internal void @_QQmain..omp_par(ptr noalias %tid.addr, ptr noalias %zero.addr, ptr %0) #2 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr, ptr }, ptr %0, i32 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %gep_3 = getelementptr { ptr, ptr, ptr }, ptr %0, i32 0, i32 2
  %loadgep_4 = load ptr, ptr %gep_3, align 8
  %p.lastiter = alloca i32, align 4
  %p.lowerbound = alloca i32, align 4
  %p.upperbound = alloca i32, align 4
  %p.stride = alloca i32, align 4
  %1 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %2 = sub nsw i32 %1, 1
  %3 = icmp slt i32 %1, 1
  %omp_loop.tripcount = select i1 %3, i32 0, i32 %1
  store i32 0, ptr %p.lowerbound, align 4
  %4 = sub i32 %omp_loop.tripcount, 1
  store i32 %4, ptr %p.upperbound, align 4
  store i32 1, ptr %p.stride, align 4
  %omp_global_thread_num3 = call i32 @__kmpc_global_thread_num(ptr @1)
  call void @__kmpc_for_static_init_4u(ptr @1, i32 %omp_global_thread_num3, i32 34, ptr %p.lastiter, ptr %p.lowerbound, ptr %p.upperbound, ptr %p.stride, i32 1, i32 0)
  %5 = load i32, ptr %p.lowerbound, align 4
  %6 = load i32, ptr %p.upperbound, align 4
  %7 = sub i32 %6, %5
  %8 = add i32 %7, 1
  br label %omp_loop.header

omp_loop.header:                                  ; preds = %omp_loop.body, %omp.par.entry
  %omp_loop.iv = phi i32 [ 0, %omp.par.entry ], [ %omp_loop.next, %omp_loop.body ]
  %omp_loop.cmp = icmp ult i32 %omp_loop.iv, %8
  br i1 %omp_loop.cmp, label %omp_loop.body, label %omp_loop.exit

omp_loop.exit:                                    ; preds = %omp_loop.header
  call void @__kmpc_for_static_fini(ptr @1, i32 %omp_global_thread_num3)
  %omp_global_thread_num4 = call i32 @__kmpc_global_thread_num(ptr @1)
  call void @__kmpc_barrier(ptr @2, i32 %omp_global_thread_num4)
  ret void

omp_loop.body:                                    ; preds = %omp_loop.header
  %9 = add i32 %omp_loop.iv, %5
  %10 = add i32 %9, 1
  %11 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %12 = sitofp i32 %11 to float
  %13 = fdiv contract float 1.000000e+00, %12
  %14 = fpext float %13 to double
  %15 = load { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, align 8, !tbaa !8
  store { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %15, ptr %loadgep_2, align 8, !tbaa !8
  %16 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i32 0, i32 7, i64 0, i32 0
  %17 = load i64, ptr %16, align 8, !tbaa !8
  %18 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i32 0, i32 7, i64 0, i32 1
  %19 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i32 0, i32 7, i64 0, i32 2
  %20 = load ptr, ptr %loadgep_2, align 8, !tbaa !8
  %21 = sext i32 %10 to i64
  %22 = sub i64 %21, %17
  %23 = getelementptr double, ptr %20, i64 %22
  store double %14, ptr %23, align 8, !tbaa !4
  %24 = load { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, align 8, !tbaa !8
  store { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %24, ptr %loadgep_4, align 8, !tbaa !8
  %25 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i32 0, i32 7, i64 0, i32 0
  %26 = load i64, ptr %25, align 8, !tbaa !8
  %27 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i32 0, i32 7, i64 0, i32 1
  %28 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i32 0, i32 7, i64 0, i32 2
  %29 = load ptr, ptr %loadgep_4, align 8, !tbaa !8
  %30 = sub i64 %21, %26
  %31 = getelementptr double, ptr %29, i64 %30
  %omp_loop.next = add nuw i32 %omp_loop.iv, 1
  br label %omp_loop.header
}
*** IR Dump After OpenMPOptPass on [module] ***
; ModuleID = 'FIRModule'
source_filename = "FIRModule"
target datalayout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128"
target triple = "x86_64-unknown-linux-gnu"

%struct.ident_t = type { i32, i32, i32, i32, ptr }

@_QFEarr = internal global { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } { ptr null, i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), i32 20180515, i8 1, i8 28, i8 2, i8 0, [1 x [3 x i64]] [[3 x i64] [i64 1, i64 0, i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64)]] }
@_QQcl.60ea5a38555821a77357f87d16df9a0f = internal constant [62 x i8] c"/g/g92/rydahl1/flangtests/src/duplicate_array_descriptors.f90\00"
@_QQcl.28612C69372C612C6531332E36653229 = internal constant [16 x i8] c"(a,i7,a,e13.6e2)"
@_QQcl.54686520726573756C74206F6620286172722831292B61727228 = internal constant [26 x i8] c"The result of (arr(1)+arr("
@_QQcl.2920697320 = internal constant [5 x i8] c") is "
@_QQEnvironmentDefaults = constant ptr null
@0 = private unnamed_addr constant [23 x i8] c";unknown;unknown;0;0;;\00", align 1
@1 = private unnamed_addr constant %struct.ident_t { i32 0, i32 2, i32 0, i32 22, ptr @0 }, align 8
@2 = private unnamed_addr constant %struct.ident_t { i32 0, i32 66, i32 0, i32 22, ptr @0 }, align 8

; Function Attrs: mustprogress nofree nounwind willreturn allockind("alloc,uninitialized") allocsize(0) memory(inaccessiblemem: readwrite)
declare noalias noundef ptr @malloc(i64 noundef) #0

; Function Attrs: mustprogress nounwind willreturn allockind("free") memory(argmem: readwrite, inaccessiblemem: readwrite)
declare void @free(ptr allocptr nocapture noundef) #1

define void @_QQmain() {
entry:
  %structArg = alloca { ptr, ptr, ptr }, align 8
  %0 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %1 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %2 = alloca i32, i64 1, align 4
  store i32 1048576, ptr %2, align 4, !tbaa !4
  %3 = call ptr @malloc(i64 mul (i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), i64 1048576))
  %4 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } { ptr undef, i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), i32 20180515, i8 1, i8 28, i8 2, i8 0, [1 x [3 x i64]] [[3 x i64] [i64 1, i64 1048576, i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64)]] }, ptr %3, 0
  %.fca.1.extract = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %4, 1
  %.fca.2.extract = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %4, 2
  %.fca.3.extract = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %4, 3
  %.fca.4.extract = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %4, 4
  %.fca.5.extract = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %4, 5
  %.fca.6.extract = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %4, 6
  %.fca.7.0.0.extract = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %4, 7, 0, 0
  %.fca.7.0.1.extract = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %4, 7, 0, 1
  %.fca.7.0.2.extract = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %4, 7, 0, 2
  %.fca.0.insert = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } poison, ptr %3, 0
  %.fca.1.insert = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.0.insert, i64 %.fca.1.extract, 1
  %.fca.2.insert = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.1.insert, i32 %.fca.2.extract, 2
  %.fca.3.insert = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.2.insert, i8 %.fca.3.extract, 3
  %.fca.4.insert = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.3.insert, i8 %.fca.4.extract, 4
  %.fca.5.insert = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.4.insert, i8 %.fca.5.extract, 5
  %.fca.6.insert = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.5.insert, i8 %.fca.6.extract, 6
  %.fca.7.0.0.insert = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.6.insert, i64 %.fca.7.0.0.extract, 7, 0, 0
  %.fca.7.0.1.insert = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.7.0.0.insert, i64 %.fca.7.0.1.extract, 7, 0, 1
  %.fca.7.0.2.insert = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.7.0.1.insert, i64 %.fca.7.0.2.extract, 7, 0, 2
  store { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.7.0.2.insert, ptr @_QFEarr, align 8, !tbaa !8
  %omp_global_thread_num = call i32 @__kmpc_global_thread_num(ptr @1)
  store ptr %2, ptr %structArg, align 8
  %gep_5 = getelementptr { ptr, ptr, ptr }, ptr %structArg, i32 0, i32 1
  store ptr %1, ptr %gep_5, align 8
  %gep_6 = getelementptr { ptr, ptr, ptr }, ptr %structArg, i32 0, i32 2
  store ptr %0, ptr %gep_6, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr @1, i32 1, ptr @_QQmain..omp_par, ptr %structArg)
  %5 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr @_QQcl.60ea5a38555821a77357f87d16df9a0f, i32 21)
  %6 = call i1 @_FortranAioOutputAscii(ptr %5, ptr @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %7 = load i32, ptr %2, align 4, !tbaa !4
  %8 = call i1 @_FortranAioOutputInteger32(ptr %5, i32 %7)
  %9 = call i1 @_FortranAioOutputAscii(ptr %5, ptr @_QQcl.2920697320, i64 5)
  %10 = load { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, align 8, !tbaa !8
  %.fca.0.extract17 = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %10, 0
  %.fca.7.0.0.extract24 = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %10, 7, 0, 0
  %11 = sub i64 1, %.fca.7.0.0.extract24
  %12 = getelementptr double, ptr %.fca.0.extract17, i64 %11
  %13 = load double, ptr %12, align 8, !tbaa !4
  %14 = load i32, ptr %2, align 4, !tbaa !4
  %15 = sext i32 %14 to i64
  %16 = sub i64 %15, %.fca.7.0.0.extract24
  %17 = getelementptr double, ptr %.fca.0.extract17, i64 %16
  %18 = load double, ptr %17, align 8, !tbaa !4
  %19 = fadd contract double %13, %18
  %20 = call i1 @_FortranAioOutputReal64(ptr %5, double %19)
  %21 = call i32 @_FortranAioEndIoStatement(ptr %5)
  %22 = load { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, align 8, !tbaa !8
  %.fca.0.extract34 = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %22, 0
  call void @free(ptr %.fca.0.extract34)
  store { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } { ptr null, i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), i32 20180515, i8 1, i8 28, i8 2, i8 0, [1 x [3 x i64]] [[3 x i64] [i64 1, i64 0, i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64)]] }, ptr @_QFEarr, align 8, !tbaa !8
  ret void
}

; Function Attrs: norecurse nounwind
define internal void @_QQmain..omp_par(ptr noalias %tid.addr, ptr noalias %zero.addr, ptr %0) #2 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr, ptr }, ptr %0, i32 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %gep_3 = getelementptr { ptr, ptr, ptr }, ptr %0, i32 0, i32 2
  %loadgep_4 = load ptr, ptr %gep_3, align 8
  %p.lastiter = alloca i32, align 4
  %p.lowerbound = alloca i32, align 4
  %p.upperbound = alloca i32, align 4
  %p.stride = alloca i32, align 4
  %1 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %2 = sub nsw i32 %1, 1
  %3 = icmp slt i32 %1, 1
  %omp_loop.tripcount = select i1 %3, i32 0, i32 %1
  store i32 0, ptr %p.lowerbound, align 4
  %4 = sub i32 %omp_loop.tripcount, 1
  store i32 %4, ptr %p.upperbound, align 4
  store i32 1, ptr %p.stride, align 4
  %omp_global_thread_num3 = call i32 @__kmpc_global_thread_num(ptr @1)
  call void @__kmpc_for_static_init_4u(ptr @1, i32 %omp_global_thread_num3, i32 34, ptr %p.lastiter, ptr %p.lowerbound, ptr %p.upperbound, ptr %p.stride, i32 1, i32 0)
  %5 = load i32, ptr %p.lowerbound, align 4
  %6 = load i32, ptr %p.upperbound, align 4
  %7 = sub i32 %6, %5
  %8 = add i32 %7, 1
  br label %omp_loop.header

omp_loop.header:                                  ; preds = %omp_loop.body, %omp.par.entry
  %omp_loop.iv = phi i32 [ 0, %omp.par.entry ], [ %omp_loop.next, %omp_loop.body ]
  %omp_loop.cmp = icmp ult i32 %omp_loop.iv, %8
  br i1 %omp_loop.cmp, label %omp_loop.body, label %omp_loop.exit

omp_loop.exit:                                    ; preds = %omp_loop.header
  call void @__kmpc_for_static_fini(ptr @1, i32 %omp_global_thread_num3)
  %omp_global_thread_num4 = call i32 @__kmpc_global_thread_num(ptr @1)
  call void @__kmpc_barrier(ptr @2, i32 %omp_global_thread_num4)
  ret void

omp_loop.body:                                    ; preds = %omp_loop.header
  %9 = add i32 %omp_loop.iv, %5
  %10 = add i32 %9, 1
  %11 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %12 = sitofp i32 %11 to float
  %13 = fdiv contract float 1.000000e+00, %12
  %14 = fpext float %13 to double
  %15 = load { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, align 8, !tbaa !8
  store { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %15, ptr %loadgep_2, align 8, !tbaa !8
  %16 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i32 0, i32 7, i64 0, i32 0
  %17 = load i64, ptr %16, align 8, !tbaa !8
  %18 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i32 0, i32 7, i64 0, i32 1
  %19 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i32 0, i32 7, i64 0, i32 2
  %20 = load ptr, ptr %loadgep_2, align 8, !tbaa !8
  %21 = sext i32 %10 to i64
  %22 = sub i64 %21, %17
  %23 = getelementptr double, ptr %20, i64 %22
  store double %14, ptr %23, align 8, !tbaa !4
  %24 = load { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, align 8, !tbaa !8
  store { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %24, ptr %loadgep_4, align 8, !tbaa !8
  %25 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i32 0, i32 7, i64 0, i32 0
  %26 = load i64, ptr %25, align 8, !tbaa !8
  %27 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i32 0, i32 7, i64 0, i32 1
  %28 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i32 0, i32 7, i64 0, i32 2
  %29 = load ptr, ptr %loadgep_4, align 8, !tbaa !8
  %30 = sub i64 %21, %26
  %31 = getelementptr double, ptr %29, i64 %30
  %omp_loop.next = add nuw i32 %omp_loop.iv, 1
  br label %omp_loop.header
}

declare ptr @_FortranAioBeginExternalFormattedOutput(ptr, i64, ptr, i32, ptr, i32)

declare zeroext i1 @_FortranAioOutputAscii(ptr, ptr, i64)

declare zeroext i1 @_FortranAioOutputInteger32(ptr, i32)

declare zeroext i1 @_FortranAioOutputReal64(ptr, double)

declare i32 @_FortranAioEndIoStatement(ptr)

; Function Attrs: mustprogress nocallback nofree nosync nounwind willreturn
declare ptr @llvm.stacksave() #3

; Function Attrs: mustprogress nocallback nofree nosync nounwind willreturn
declare void @llvm.stackrestore(ptr) #3

; Function Attrs: nounwind
declare i32 @__kmpc_global_thread_num(ptr) #4

; Function Attrs: nounwind
declare void @__kmpc_for_static_init_4u(ptr, i32, i32, ptr, ptr, ptr, ptr, i32, i32) #4

; Function Attrs: nounwind
declare void @__kmpc_for_static_fini(ptr, i32) #4

; Function Attrs: convergent nounwind
declare void @__kmpc_barrier(ptr, i32) #5

; Function Attrs: nounwind
declare !callback !10 void @__kmpc_fork_call(ptr, i32, ptr, ...) #4

attributes #0 = { mustprogress nofree nounwind willreturn allockind("alloc,uninitialized") allocsize(0) memory(inaccessiblemem: readwrite) "alloc-family"="malloc" }
attributes #1 = { mustprogress nounwind willreturn allockind("free") memory(argmem: readwrite, inaccessiblemem: readwrite) "alloc-family"="malloc" }
attributes #2 = { norecurse nounwind }
attributes #3 = { mustprogress nocallback nofree nosync nounwind willreturn }
attributes #4 = { nounwind }
attributes #5 = { convergent nounwind }

!llvm.module.flags = !{!0, !1, !2, !3}

!0 = !{i32 2, !"Debug Info Version", i32 3}
!1 = !{i32 7, !"openmp", i32 11}
!2 = !{i32 8, !"PIC Level", i32 2}
!3 = !{i32 7, !"PIE Level", i32 2}
!4 = !{!5, !5, i64 0}
!5 = !{!"any data access", !6, i64 0}
!6 = !{!"any access", !7, i64 0}
!7 = !{!"Flang Type TBAA Root"}
!8 = !{!9, !9, i64 0}
!9 = !{!"descriptor member", !6, i64 0}
!10 = !{!11}
!11 = !{i64 2, i64 -1, i64 -1, i1 true}
*** IR Dump After IPSCCPPass on [module] ***
; ModuleID = 'FIRModule'
source_filename = "FIRModule"
target datalayout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128"
target triple = "x86_64-unknown-linux-gnu"

%struct.ident_t = type { i32, i32, i32, i32, ptr }

@_QFEarr = internal global { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } { ptr null, i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), i32 20180515, i8 1, i8 28, i8 2, i8 0, [1 x [3 x i64]] [[3 x i64] [i64 1, i64 0, i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64)]] }
@_QQcl.60ea5a38555821a77357f87d16df9a0f = internal constant [62 x i8] c"/g/g92/rydahl1/flangtests/src/duplicate_array_descriptors.f90\00"
@_QQcl.28612C69372C612C6531332E36653229 = internal constant [16 x i8] c"(a,i7,a,e13.6e2)"
@_QQcl.54686520726573756C74206F6620286172722831292B61727228 = internal constant [26 x i8] c"The result of (arr(1)+arr("
@_QQcl.2920697320 = internal constant [5 x i8] c") is "
@_QQEnvironmentDefaults = constant ptr null
@0 = private unnamed_addr constant [23 x i8] c";unknown;unknown;0;0;;\00", align 1
@1 = private unnamed_addr constant %struct.ident_t { i32 0, i32 2, i32 0, i32 22, ptr @0 }, align 8
@2 = private unnamed_addr constant %struct.ident_t { i32 0, i32 66, i32 0, i32 22, ptr @0 }, align 8

; Function Attrs: mustprogress nofree nounwind willreturn allockind("alloc,uninitialized") allocsize(0) memory(inaccessiblemem: readwrite)
declare noalias noundef ptr @malloc(i64 noundef) #0

; Function Attrs: mustprogress nounwind willreturn allockind("free") memory(argmem: readwrite, inaccessiblemem: readwrite)
declare void @free(ptr allocptr nocapture noundef) #1

define void @_QQmain() {
entry:
  %structArg = alloca { ptr, ptr, ptr }, align 8
  %0 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %1 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %2 = alloca i32, i64 1, align 4
  store i32 1048576, ptr %2, align 4, !tbaa !4
  %3 = call ptr @malloc(i64 mul (i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), i64 1048576))
  %4 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } { ptr undef, i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), i32 20180515, i8 1, i8 28, i8 2, i8 0, [1 x [3 x i64]] [[3 x i64] [i64 1, i64 1048576, i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64)]] }, ptr %3, 0
  %.fca.7.0.0.extract = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %4, 7, 0, 0
  %.fca.7.0.1.extract = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %4, 7, 0, 1
  %.fca.7.0.2.extract = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %4, 7, 0, 2
  %.fca.0.insert = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } poison, ptr %3, 0
  %.fca.1.insert = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.0.insert, i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), 1
  %.fca.2.insert = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.1.insert, i32 20180515, 2
  %.fca.3.insert = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.2.insert, i8 1, 3
  %.fca.4.insert = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.3.insert, i8 28, 4
  %.fca.5.insert = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.4.insert, i8 2, 5
  %.fca.6.insert = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.5.insert, i8 0, 6
  %.fca.7.0.0.insert = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.6.insert, i64 %.fca.7.0.0.extract, 7, 0, 0
  %.fca.7.0.1.insert = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.7.0.0.insert, i64 %.fca.7.0.1.extract, 7, 0, 1
  %.fca.7.0.2.insert = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.7.0.1.insert, i64 %.fca.7.0.2.extract, 7, 0, 2
  store { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.7.0.2.insert, ptr @_QFEarr, align 8, !tbaa !8
  %omp_global_thread_num = call i32 @__kmpc_global_thread_num(ptr @1)
  store ptr %2, ptr %structArg, align 8
  %gep_5 = getelementptr { ptr, ptr, ptr }, ptr %structArg, i32 0, i32 1
  store ptr %1, ptr %gep_5, align 8
  %gep_6 = getelementptr { ptr, ptr, ptr }, ptr %structArg, i32 0, i32 2
  store ptr %0, ptr %gep_6, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr @1, i32 1, ptr @_QQmain..omp_par, ptr %structArg)
  %5 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr @_QQcl.60ea5a38555821a77357f87d16df9a0f, i32 21)
  %6 = call i1 @_FortranAioOutputAscii(ptr %5, ptr @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %7 = load i32, ptr %2, align 4, !tbaa !4
  %8 = call i1 @_FortranAioOutputInteger32(ptr %5, i32 %7)
  %9 = call i1 @_FortranAioOutputAscii(ptr %5, ptr @_QQcl.2920697320, i64 5)
  %10 = load { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, align 8, !tbaa !8
  %.fca.0.extract17 = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %10, 0
  %.fca.7.0.0.extract24 = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %10, 7, 0, 0
  %11 = sub i64 1, %.fca.7.0.0.extract24
  %12 = getelementptr double, ptr %.fca.0.extract17, i64 %11
  %13 = load double, ptr %12, align 8, !tbaa !4
  %14 = load i32, ptr %2, align 4, !tbaa !4
  %15 = sext i32 %14 to i64
  %16 = sub i64 %15, %.fca.7.0.0.extract24
  %17 = getelementptr double, ptr %.fca.0.extract17, i64 %16
  %18 = load double, ptr %17, align 8, !tbaa !4
  %19 = fadd contract double %13, %18
  %20 = call i1 @_FortranAioOutputReal64(ptr %5, double %19)
  %21 = call i32 @_FortranAioEndIoStatement(ptr %5)
  %22 = load { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, align 8, !tbaa !8
  %.fca.0.extract34 = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %22, 0
  call void @free(ptr %.fca.0.extract34)
  store { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } { ptr null, i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), i32 20180515, i8 1, i8 28, i8 2, i8 0, [1 x [3 x i64]] [[3 x i64] [i64 1, i64 0, i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64)]] }, ptr @_QFEarr, align 8, !tbaa !8
  ret void
}

; Function Attrs: norecurse nounwind
define internal void @_QQmain..omp_par(ptr noalias %tid.addr, ptr noalias %zero.addr, ptr %0) #2 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr, ptr }, ptr %0, i32 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %gep_3 = getelementptr { ptr, ptr, ptr }, ptr %0, i32 0, i32 2
  %loadgep_4 = load ptr, ptr %gep_3, align 8
  %p.lastiter = alloca i32, align 4
  %p.lowerbound = alloca i32, align 4
  %p.upperbound = alloca i32, align 4
  %p.stride = alloca i32, align 4
  %1 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %2 = sub nsw i32 %1, 1
  %3 = icmp slt i32 %1, 1
  %omp_loop.tripcount = select i1 %3, i32 0, i32 %1
  store i32 0, ptr %p.lowerbound, align 4
  %4 = sub i32 %omp_loop.tripcount, 1
  store i32 %4, ptr %p.upperbound, align 4
  store i32 1, ptr %p.stride, align 4
  %omp_global_thread_num3 = call i32 @__kmpc_global_thread_num(ptr @1)
  call void @__kmpc_for_static_init_4u(ptr @1, i32 %omp_global_thread_num3, i32 34, ptr %p.lastiter, ptr %p.lowerbound, ptr %p.upperbound, ptr %p.stride, i32 1, i32 0)
  %5 = load i32, ptr %p.lowerbound, align 4
  %6 = load i32, ptr %p.upperbound, align 4
  %7 = sub i32 %6, %5
  %8 = add i32 %7, 1
  br label %omp_loop.header

omp_loop.header:                                  ; preds = %omp_loop.body, %omp.par.entry
  %omp_loop.iv = phi i32 [ 0, %omp.par.entry ], [ %omp_loop.next, %omp_loop.body ]
  %omp_loop.cmp = icmp ult i32 %omp_loop.iv, %8
  br i1 %omp_loop.cmp, label %omp_loop.body, label %omp_loop.exit

omp_loop.exit:                                    ; preds = %omp_loop.header
  call void @__kmpc_for_static_fini(ptr @1, i32 %omp_global_thread_num3)
  %omp_global_thread_num4 = call i32 @__kmpc_global_thread_num(ptr @1)
  call void @__kmpc_barrier(ptr @2, i32 %omp_global_thread_num4)
  ret void

omp_loop.body:                                    ; preds = %omp_loop.header
  %9 = add i32 %omp_loop.iv, %5
  %10 = add i32 %9, 1
  %11 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %12 = sitofp i32 %11 to float
  %13 = fdiv contract float 1.000000e+00, %12
  %14 = fpext float %13 to double
  %15 = load { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, align 8, !tbaa !8
  store { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %15, ptr %loadgep_2, align 8, !tbaa !8
  %16 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i32 0, i32 7, i64 0, i32 0
  %17 = load i64, ptr %16, align 8, !tbaa !8
  %18 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i32 0, i32 7, i64 0, i32 1
  %19 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i32 0, i32 7, i64 0, i32 2
  %20 = load ptr, ptr %loadgep_2, align 8, !tbaa !8
  %21 = sext i32 %10 to i64
  %22 = sub i64 %21, %17
  %23 = getelementptr double, ptr %20, i64 %22
  store double %14, ptr %23, align 8, !tbaa !4
  %24 = load { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, align 8, !tbaa !8
  store { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %24, ptr %loadgep_4, align 8, !tbaa !8
  %25 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i32 0, i32 7, i64 0, i32 0
  %26 = load i64, ptr %25, align 8, !tbaa !8
  %27 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i32 0, i32 7, i64 0, i32 1
  %28 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i32 0, i32 7, i64 0, i32 2
  %29 = load ptr, ptr %loadgep_4, align 8, !tbaa !8
  %30 = sub i64 %21, %26
  %31 = getelementptr double, ptr %29, i64 %30
  %omp_loop.next = add nuw i32 %omp_loop.iv, 1
  br label %omp_loop.header
}

declare ptr @_FortranAioBeginExternalFormattedOutput(ptr, i64, ptr, i32, ptr, i32)

declare zeroext i1 @_FortranAioOutputAscii(ptr, ptr, i64)

declare zeroext i1 @_FortranAioOutputInteger32(ptr, i32)

declare zeroext i1 @_FortranAioOutputReal64(ptr, double)

declare i32 @_FortranAioEndIoStatement(ptr)

; Function Attrs: mustprogress nocallback nofree nosync nounwind willreturn
declare ptr @llvm.stacksave() #3

; Function Attrs: mustprogress nocallback nofree nosync nounwind willreturn
declare void @llvm.stackrestore(ptr) #3

; Function Attrs: nounwind
declare i32 @__kmpc_global_thread_num(ptr) #4

; Function Attrs: nounwind
declare void @__kmpc_for_static_init_4u(ptr, i32, i32, ptr, ptr, ptr, ptr, i32, i32) #4

; Function Attrs: nounwind
declare void @__kmpc_for_static_fini(ptr, i32) #4

; Function Attrs: convergent nounwind
declare void @__kmpc_barrier(ptr, i32) #5

; Function Attrs: nounwind
declare !callback !10 void @__kmpc_fork_call(ptr, i32, ptr, ...) #4

attributes #0 = { mustprogress nofree nounwind willreturn allockind("alloc,uninitialized") allocsize(0) memory(inaccessiblemem: readwrite) "alloc-family"="malloc" }
attributes #1 = { mustprogress nounwind willreturn allockind("free") memory(argmem: readwrite, inaccessiblemem: readwrite) "alloc-family"="malloc" }
attributes #2 = { norecurse nounwind }
attributes #3 = { mustprogress nocallback nofree nosync nounwind willreturn }
attributes #4 = { nounwind }
attributes #5 = { convergent nounwind }

!llvm.module.flags = !{!0, !1, !2, !3}

!0 = !{i32 2, !"Debug Info Version", i32 3}
!1 = !{i32 7, !"openmp", i32 11}
!2 = !{i32 8, !"PIC Level", i32 2}
!3 = !{i32 7, !"PIE Level", i32 2}
!4 = !{!5, !5, i64 0}
!5 = !{!"any data access", !6, i64 0}
!6 = !{!"any access", !7, i64 0}
!7 = !{!"Flang Type TBAA Root"}
!8 = !{!9, !9, i64 0}
!9 = !{!"descriptor member", !6, i64 0}
!10 = !{!11}
!11 = !{i64 2, i64 -1, i64 -1, i1 true}
*** IR Dump After CalledValuePropagationPass on [module] ***
; ModuleID = 'FIRModule'
source_filename = "FIRModule"
target datalayout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128"
target triple = "x86_64-unknown-linux-gnu"

%struct.ident_t = type { i32, i32, i32, i32, ptr }

@_QFEarr = internal global { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } { ptr null, i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), i32 20180515, i8 1, i8 28, i8 2, i8 0, [1 x [3 x i64]] [[3 x i64] [i64 1, i64 0, i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64)]] }
@_QQcl.60ea5a38555821a77357f87d16df9a0f = internal constant [62 x i8] c"/g/g92/rydahl1/flangtests/src/duplicate_array_descriptors.f90\00"
@_QQcl.28612C69372C612C6531332E36653229 = internal constant [16 x i8] c"(a,i7,a,e13.6e2)"
@_QQcl.54686520726573756C74206F6620286172722831292B61727228 = internal constant [26 x i8] c"The result of (arr(1)+arr("
@_QQcl.2920697320 = internal constant [5 x i8] c") is "
@_QQEnvironmentDefaults = constant ptr null
@0 = private unnamed_addr constant [23 x i8] c";unknown;unknown;0;0;;\00", align 1
@1 = private unnamed_addr constant %struct.ident_t { i32 0, i32 2, i32 0, i32 22, ptr @0 }, align 8
@2 = private unnamed_addr constant %struct.ident_t { i32 0, i32 66, i32 0, i32 22, ptr @0 }, align 8

; Function Attrs: mustprogress nofree nounwind willreturn allockind("alloc,uninitialized") allocsize(0) memory(inaccessiblemem: readwrite)
declare noalias noundef ptr @malloc(i64 noundef) #0

; Function Attrs: mustprogress nounwind willreturn allockind("free") memory(argmem: readwrite, inaccessiblemem: readwrite)
declare void @free(ptr allocptr nocapture noundef) #1

define void @_QQmain() {
entry:
  %structArg = alloca { ptr, ptr, ptr }, align 8
  %0 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %1 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %2 = alloca i32, i64 1, align 4
  store i32 1048576, ptr %2, align 4, !tbaa !4
  %3 = call ptr @malloc(i64 mul (i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), i64 1048576))
  %4 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } { ptr undef, i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), i32 20180515, i8 1, i8 28, i8 2, i8 0, [1 x [3 x i64]] [[3 x i64] [i64 1, i64 1048576, i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64)]] }, ptr %3, 0
  %.fca.7.0.0.extract = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %4, 7, 0, 0
  %.fca.7.0.1.extract = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %4, 7, 0, 1
  %.fca.7.0.2.extract = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %4, 7, 0, 2
  %.fca.0.insert = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } poison, ptr %3, 0
  %.fca.1.insert = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.0.insert, i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), 1
  %.fca.2.insert = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.1.insert, i32 20180515, 2
  %.fca.3.insert = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.2.insert, i8 1, 3
  %.fca.4.insert = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.3.insert, i8 28, 4
  %.fca.5.insert = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.4.insert, i8 2, 5
  %.fca.6.insert = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.5.insert, i8 0, 6
  %.fca.7.0.0.insert = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.6.insert, i64 %.fca.7.0.0.extract, 7, 0, 0
  %.fca.7.0.1.insert = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.7.0.0.insert, i64 %.fca.7.0.1.extract, 7, 0, 1
  %.fca.7.0.2.insert = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.7.0.1.insert, i64 %.fca.7.0.2.extract, 7, 0, 2
  store { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.7.0.2.insert, ptr @_QFEarr, align 8, !tbaa !8
  %omp_global_thread_num = call i32 @__kmpc_global_thread_num(ptr @1)
  store ptr %2, ptr %structArg, align 8
  %gep_5 = getelementptr { ptr, ptr, ptr }, ptr %structArg, i32 0, i32 1
  store ptr %1, ptr %gep_5, align 8
  %gep_6 = getelementptr { ptr, ptr, ptr }, ptr %structArg, i32 0, i32 2
  store ptr %0, ptr %gep_6, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr @1, i32 1, ptr @_QQmain..omp_par, ptr %structArg)
  %5 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr @_QQcl.60ea5a38555821a77357f87d16df9a0f, i32 21)
  %6 = call i1 @_FortranAioOutputAscii(ptr %5, ptr @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %7 = load i32, ptr %2, align 4, !tbaa !4
  %8 = call i1 @_FortranAioOutputInteger32(ptr %5, i32 %7)
  %9 = call i1 @_FortranAioOutputAscii(ptr %5, ptr @_QQcl.2920697320, i64 5)
  %10 = load { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, align 8, !tbaa !8
  %.fca.0.extract17 = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %10, 0
  %.fca.7.0.0.extract24 = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %10, 7, 0, 0
  %11 = sub i64 1, %.fca.7.0.0.extract24
  %12 = getelementptr double, ptr %.fca.0.extract17, i64 %11
  %13 = load double, ptr %12, align 8, !tbaa !4
  %14 = load i32, ptr %2, align 4, !tbaa !4
  %15 = sext i32 %14 to i64
  %16 = sub i64 %15, %.fca.7.0.0.extract24
  %17 = getelementptr double, ptr %.fca.0.extract17, i64 %16
  %18 = load double, ptr %17, align 8, !tbaa !4
  %19 = fadd contract double %13, %18
  %20 = call i1 @_FortranAioOutputReal64(ptr %5, double %19)
  %21 = call i32 @_FortranAioEndIoStatement(ptr %5)
  %22 = load { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, align 8, !tbaa !8
  %.fca.0.extract34 = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %22, 0
  call void @free(ptr %.fca.0.extract34)
  store { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } { ptr null, i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), i32 20180515, i8 1, i8 28, i8 2, i8 0, [1 x [3 x i64]] [[3 x i64] [i64 1, i64 0, i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64)]] }, ptr @_QFEarr, align 8, !tbaa !8
  ret void
}

; Function Attrs: norecurse nounwind
define internal void @_QQmain..omp_par(ptr noalias %tid.addr, ptr noalias %zero.addr, ptr %0) #2 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr, ptr }, ptr %0, i32 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %gep_3 = getelementptr { ptr, ptr, ptr }, ptr %0, i32 0, i32 2
  %loadgep_4 = load ptr, ptr %gep_3, align 8
  %p.lastiter = alloca i32, align 4
  %p.lowerbound = alloca i32, align 4
  %p.upperbound = alloca i32, align 4
  %p.stride = alloca i32, align 4
  %1 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %2 = sub nsw i32 %1, 1
  %3 = icmp slt i32 %1, 1
  %omp_loop.tripcount = select i1 %3, i32 0, i32 %1
  store i32 0, ptr %p.lowerbound, align 4
  %4 = sub i32 %omp_loop.tripcount, 1
  store i32 %4, ptr %p.upperbound, align 4
  store i32 1, ptr %p.stride, align 4
  %omp_global_thread_num3 = call i32 @__kmpc_global_thread_num(ptr @1)
  call void @__kmpc_for_static_init_4u(ptr @1, i32 %omp_global_thread_num3, i32 34, ptr %p.lastiter, ptr %p.lowerbound, ptr %p.upperbound, ptr %p.stride, i32 1, i32 0)
  %5 = load i32, ptr %p.lowerbound, align 4
  %6 = load i32, ptr %p.upperbound, align 4
  %7 = sub i32 %6, %5
  %8 = add i32 %7, 1
  br label %omp_loop.header

omp_loop.header:                                  ; preds = %omp_loop.body, %omp.par.entry
  %omp_loop.iv = phi i32 [ 0, %omp.par.entry ], [ %omp_loop.next, %omp_loop.body ]
  %omp_loop.cmp = icmp ult i32 %omp_loop.iv, %8
  br i1 %omp_loop.cmp, label %omp_loop.body, label %omp_loop.exit

omp_loop.exit:                                    ; preds = %omp_loop.header
  call void @__kmpc_for_static_fini(ptr @1, i32 %omp_global_thread_num3)
  %omp_global_thread_num4 = call i32 @__kmpc_global_thread_num(ptr @1)
  call void @__kmpc_barrier(ptr @2, i32 %omp_global_thread_num4)
  ret void

omp_loop.body:                                    ; preds = %omp_loop.header
  %9 = add i32 %omp_loop.iv, %5
  %10 = add i32 %9, 1
  %11 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %12 = sitofp i32 %11 to float
  %13 = fdiv contract float 1.000000e+00, %12
  %14 = fpext float %13 to double
  %15 = load { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, align 8, !tbaa !8
  store { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %15, ptr %loadgep_2, align 8, !tbaa !8
  %16 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i32 0, i32 7, i64 0, i32 0
  %17 = load i64, ptr %16, align 8, !tbaa !8
  %18 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i32 0, i32 7, i64 0, i32 1
  %19 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i32 0, i32 7, i64 0, i32 2
  %20 = load ptr, ptr %loadgep_2, align 8, !tbaa !8
  %21 = sext i32 %10 to i64
  %22 = sub i64 %21, %17
  %23 = getelementptr double, ptr %20, i64 %22
  store double %14, ptr %23, align 8, !tbaa !4
  %24 = load { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, align 8, !tbaa !8
  store { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %24, ptr %loadgep_4, align 8, !tbaa !8
  %25 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i32 0, i32 7, i64 0, i32 0
  %26 = load i64, ptr %25, align 8, !tbaa !8
  %27 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i32 0, i32 7, i64 0, i32 1
  %28 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i32 0, i32 7, i64 0, i32 2
  %29 = load ptr, ptr %loadgep_4, align 8, !tbaa !8
  %30 = sub i64 %21, %26
  %31 = getelementptr double, ptr %29, i64 %30
  %omp_loop.next = add nuw i32 %omp_loop.iv, 1
  br label %omp_loop.header
}

declare ptr @_FortranAioBeginExternalFormattedOutput(ptr, i64, ptr, i32, ptr, i32)

declare zeroext i1 @_FortranAioOutputAscii(ptr, ptr, i64)

declare zeroext i1 @_FortranAioOutputInteger32(ptr, i32)

declare zeroext i1 @_FortranAioOutputReal64(ptr, double)

declare i32 @_FortranAioEndIoStatement(ptr)

; Function Attrs: mustprogress nocallback nofree nosync nounwind willreturn
declare ptr @llvm.stacksave() #3

; Function Attrs: mustprogress nocallback nofree nosync nounwind willreturn
declare void @llvm.stackrestore(ptr) #3

; Function Attrs: nounwind
declare i32 @__kmpc_global_thread_num(ptr) #4

; Function Attrs: nounwind
declare void @__kmpc_for_static_init_4u(ptr, i32, i32, ptr, ptr, ptr, ptr, i32, i32) #4

; Function Attrs: nounwind
declare void @__kmpc_for_static_fini(ptr, i32) #4

; Function Attrs: convergent nounwind
declare void @__kmpc_barrier(ptr, i32) #5

; Function Attrs: nounwind
declare !callback !10 void @__kmpc_fork_call(ptr, i32, ptr, ...) #4

attributes #0 = { mustprogress nofree nounwind willreturn allockind("alloc,uninitialized") allocsize(0) memory(inaccessiblemem: readwrite) "alloc-family"="malloc" }
attributes #1 = { mustprogress nounwind willreturn allockind("free") memory(argmem: readwrite, inaccessiblemem: readwrite) "alloc-family"="malloc" }
attributes #2 = { norecurse nounwind }
attributes #3 = { mustprogress nocallback nofree nosync nounwind willreturn }
attributes #4 = { nounwind }
attributes #5 = { convergent nounwind }

!llvm.module.flags = !{!0, !1, !2, !3}

!0 = !{i32 2, !"Debug Info Version", i32 3}
!1 = !{i32 7, !"openmp", i32 11}
!2 = !{i32 8, !"PIC Level", i32 2}
!3 = !{i32 7, !"PIE Level", i32 2}
!4 = !{!5, !5, i64 0}
!5 = !{!"any data access", !6, i64 0}
!6 = !{!"any access", !7, i64 0}
!7 = !{!"Flang Type TBAA Root"}
!8 = !{!9, !9, i64 0}
!9 = !{!"descriptor member", !6, i64 0}
!10 = !{!11}
!11 = !{i64 2, i64 -1, i64 -1, i1 true}
*** IR Dump After GlobalOptPass on [module] ***
; ModuleID = 'FIRModule'
source_filename = "FIRModule"
target datalayout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128"
target triple = "x86_64-unknown-linux-gnu"

%struct.ident_t = type { i32, i32, i32, i32, ptr }

@_QFEarr = internal unnamed_addr global { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } { ptr null, i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), i32 20180515, i8 1, i8 28, i8 2, i8 0, [1 x [3 x i64]] [[3 x i64] [i64 1, i64 0, i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64)]] }
@_QQcl.60ea5a38555821a77357f87d16df9a0f = internal constant [62 x i8] c"/g/g92/rydahl1/flangtests/src/duplicate_array_descriptors.f90\00"
@_QQcl.28612C69372C612C6531332E36653229 = internal constant [16 x i8] c"(a,i7,a,e13.6e2)"
@_QQcl.54686520726573756C74206F6620286172722831292B61727228 = internal constant [26 x i8] c"The result of (arr(1)+arr("
@_QQcl.2920697320 = internal constant [5 x i8] c") is "
@_QQEnvironmentDefaults = local_unnamed_addr constant ptr null
@0 = private unnamed_addr constant [23 x i8] c";unknown;unknown;0;0;;\00", align 1
@1 = private unnamed_addr constant %struct.ident_t { i32 0, i32 2, i32 0, i32 22, ptr @0 }, align 8
@2 = private unnamed_addr constant %struct.ident_t { i32 0, i32 66, i32 0, i32 22, ptr @0 }, align 8

; Function Attrs: mustprogress nofree nounwind willreturn allockind("alloc,uninitialized") allocsize(0) memory(inaccessiblemem: readwrite)
declare noalias noundef ptr @malloc(i64 noundef) local_unnamed_addr #0

; Function Attrs: mustprogress nounwind willreturn allockind("free") memory(argmem: readwrite, inaccessiblemem: readwrite)
declare void @free(ptr allocptr nocapture noundef) local_unnamed_addr #1

define void @_QQmain() local_unnamed_addr {
entry:
  %structArg = alloca { ptr, ptr, ptr }, align 8
  %0 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %1 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %2 = alloca i32, i64 1, align 4
  store i32 1048576, ptr %2, align 4, !tbaa !4
  %3 = call ptr @malloc(i64 mul (i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), i64 1048576))
  %4 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } { ptr undef, i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), i32 20180515, i8 1, i8 28, i8 2, i8 0, [1 x [3 x i64]] [[3 x i64] [i64 1, i64 1048576, i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64)]] }, ptr %3, 0
  %.fca.7.0.0.extract = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %4, 7, 0, 0
  %.fca.7.0.1.extract = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %4, 7, 0, 1
  %.fca.7.0.2.extract = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %4, 7, 0, 2
  %.fca.0.insert = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } poison, ptr %3, 0
  %.fca.1.insert = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.0.insert, i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), 1
  %.fca.2.insert = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.1.insert, i32 20180515, 2
  %.fca.3.insert = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.2.insert, i8 1, 3
  %.fca.4.insert = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.3.insert, i8 28, 4
  %.fca.5.insert = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.4.insert, i8 2, 5
  %.fca.6.insert = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.5.insert, i8 0, 6
  %.fca.7.0.0.insert = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.6.insert, i64 %.fca.7.0.0.extract, 7, 0, 0
  %.fca.7.0.1.insert = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.7.0.0.insert, i64 %.fca.7.0.1.extract, 7, 0, 1
  %.fca.7.0.2.insert = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.7.0.1.insert, i64 %.fca.7.0.2.extract, 7, 0, 2
  store { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.7.0.2.insert, ptr @_QFEarr, align 8, !tbaa !8
  %omp_global_thread_num = call i32 @__kmpc_global_thread_num(ptr @1)
  store ptr %2, ptr %structArg, align 8
  %gep_5 = getelementptr { ptr, ptr, ptr }, ptr %structArg, i32 0, i32 1
  store ptr %1, ptr %gep_5, align 8
  %gep_6 = getelementptr { ptr, ptr, ptr }, ptr %structArg, i32 0, i32 2
  store ptr %0, ptr %gep_6, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr @1, i32 1, ptr @_QQmain..omp_par, ptr %structArg)
  %5 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr @_QQcl.60ea5a38555821a77357f87d16df9a0f, i32 21)
  %6 = call i1 @_FortranAioOutputAscii(ptr %5, ptr @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %7 = load i32, ptr %2, align 4, !tbaa !4
  %8 = call i1 @_FortranAioOutputInteger32(ptr %5, i32 %7)
  %9 = call i1 @_FortranAioOutputAscii(ptr %5, ptr @_QQcl.2920697320, i64 5)
  %10 = load { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, align 8, !tbaa !8
  %.fca.0.extract17 = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %10, 0
  %.fca.7.0.0.extract24 = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %10, 7, 0, 0
  %11 = sub i64 1, %.fca.7.0.0.extract24
  %12 = getelementptr double, ptr %.fca.0.extract17, i64 %11
  %13 = load double, ptr %12, align 8, !tbaa !4
  %14 = load i32, ptr %2, align 4, !tbaa !4
  %15 = sext i32 %14 to i64
  %16 = sub i64 %15, %.fca.7.0.0.extract24
  %17 = getelementptr double, ptr %.fca.0.extract17, i64 %16
  %18 = load double, ptr %17, align 8, !tbaa !4
  %19 = fadd contract double %13, %18
  %20 = call i1 @_FortranAioOutputReal64(ptr %5, double %19)
  %21 = call i32 @_FortranAioEndIoStatement(ptr %5)
  %22 = load { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, align 8, !tbaa !8
  %.fca.0.extract34 = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %22, 0
  call void @free(ptr %.fca.0.extract34)
  store { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } { ptr null, i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), i32 20180515, i8 1, i8 28, i8 2, i8 0, [1 x [3 x i64]] [[3 x i64] [i64 1, i64 0, i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64)]] }, ptr @_QFEarr, align 8, !tbaa !8
  ret void
}

; Function Attrs: norecurse nounwind
define internal void @_QQmain..omp_par(ptr noalias %tid.addr, ptr noalias %zero.addr, ptr %0) #2 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr, ptr }, ptr %0, i32 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %gep_3 = getelementptr { ptr, ptr, ptr }, ptr %0, i32 0, i32 2
  %loadgep_4 = load ptr, ptr %gep_3, align 8
  %p.lastiter = alloca i32, align 4
  %p.lowerbound = alloca i32, align 4
  %p.upperbound = alloca i32, align 4
  %p.stride = alloca i32, align 4
  %1 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %2 = sub nsw i32 %1, 1
  %3 = icmp slt i32 %1, 1
  %omp_loop.tripcount = select i1 %3, i32 0, i32 %1
  store i32 0, ptr %p.lowerbound, align 4
  %4 = sub i32 %omp_loop.tripcount, 1
  store i32 %4, ptr %p.upperbound, align 4
  store i32 1, ptr %p.stride, align 4
  %omp_global_thread_num3 = call i32 @__kmpc_global_thread_num(ptr @1)
  call void @__kmpc_for_static_init_4u(ptr @1, i32 %omp_global_thread_num3, i32 34, ptr %p.lastiter, ptr %p.lowerbound, ptr %p.upperbound, ptr %p.stride, i32 1, i32 0)
  %5 = load i32, ptr %p.lowerbound, align 4
  %6 = load i32, ptr %p.upperbound, align 4
  %7 = sub i32 %6, %5
  %8 = add i32 %7, 1
  br label %omp_loop.header

omp_loop.header:                                  ; preds = %omp_loop.body, %omp.par.entry
  %omp_loop.iv = phi i32 [ 0, %omp.par.entry ], [ %omp_loop.next, %omp_loop.body ]
  %omp_loop.cmp = icmp ult i32 %omp_loop.iv, %8
  br i1 %omp_loop.cmp, label %omp_loop.body, label %omp_loop.exit

omp_loop.exit:                                    ; preds = %omp_loop.header
  call void @__kmpc_for_static_fini(ptr @1, i32 %omp_global_thread_num3)
  %omp_global_thread_num4 = call i32 @__kmpc_global_thread_num(ptr @1)
  call void @__kmpc_barrier(ptr @2, i32 %omp_global_thread_num4)
  ret void

omp_loop.body:                                    ; preds = %omp_loop.header
  %9 = add i32 %omp_loop.iv, %5
  %10 = add i32 %9, 1
  %11 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %12 = sitofp i32 %11 to float
  %13 = fdiv contract float 1.000000e+00, %12
  %14 = fpext float %13 to double
  %15 = load { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, align 8, !tbaa !8
  store { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %15, ptr %loadgep_2, align 8, !tbaa !8
  %16 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i32 0, i32 7, i64 0, i32 0
  %17 = load i64, ptr %16, align 8, !tbaa !8
  %18 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i32 0, i32 7, i64 0, i32 1
  %19 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i32 0, i32 7, i64 0, i32 2
  %20 = load ptr, ptr %loadgep_2, align 8, !tbaa !8
  %21 = sext i32 %10 to i64
  %22 = sub i64 %21, %17
  %23 = getelementptr double, ptr %20, i64 %22
  store double %14, ptr %23, align 8, !tbaa !4
  %24 = load { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, align 8, !tbaa !8
  store { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %24, ptr %loadgep_4, align 8, !tbaa !8
  %25 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i32 0, i32 7, i64 0, i32 0
  %26 = load i64, ptr %25, align 8, !tbaa !8
  %27 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i32 0, i32 7, i64 0, i32 1
  %28 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i32 0, i32 7, i64 0, i32 2
  %29 = load ptr, ptr %loadgep_4, align 8, !tbaa !8
  %30 = sub i64 %21, %26
  %31 = getelementptr double, ptr %29, i64 %30
  %omp_loop.next = add nuw i32 %omp_loop.iv, 1
  br label %omp_loop.header
}

declare ptr @_FortranAioBeginExternalFormattedOutput(ptr, i64, ptr, i32, ptr, i32) local_unnamed_addr

declare zeroext i1 @_FortranAioOutputAscii(ptr, ptr, i64) local_unnamed_addr

declare zeroext i1 @_FortranAioOutputInteger32(ptr, i32) local_unnamed_addr

declare zeroext i1 @_FortranAioOutputReal64(ptr, double) local_unnamed_addr

declare i32 @_FortranAioEndIoStatement(ptr) local_unnamed_addr

; Function Attrs: nounwind
declare i32 @__kmpc_global_thread_num(ptr) local_unnamed_addr #3

; Function Attrs: nounwind
declare void @__kmpc_for_static_init_4u(ptr, i32, i32, ptr, ptr, ptr, ptr, i32, i32) local_unnamed_addr #3

; Function Attrs: nounwind
declare void @__kmpc_for_static_fini(ptr, i32) local_unnamed_addr #3

; Function Attrs: convergent nounwind
declare void @__kmpc_barrier(ptr, i32) local_unnamed_addr #4

; Function Attrs: nounwind
declare !callback !10 void @__kmpc_fork_call(ptr, i32, ptr, ...) local_unnamed_addr #3

attributes #0 = { mustprogress nofree nounwind willreturn allockind("alloc,uninitialized") allocsize(0) memory(inaccessiblemem: readwrite) "alloc-family"="malloc" }
attributes #1 = { mustprogress nounwind willreturn allockind("free") memory(argmem: readwrite, inaccessiblemem: readwrite) "alloc-family"="malloc" }
attributes #2 = { norecurse nounwind }
attributes #3 = { nounwind }
attributes #4 = { convergent nounwind }

!llvm.module.flags = !{!0, !1, !2, !3}

!0 = !{i32 2, !"Debug Info Version", i32 3}
!1 = !{i32 7, !"openmp", i32 11}
!2 = !{i32 8, !"PIC Level", i32 2}
!3 = !{i32 7, !"PIE Level", i32 2}
!4 = !{!5, !5, i64 0}
!5 = !{!"any data access", !6, i64 0}
!6 = !{!"any access", !7, i64 0}
!7 = !{!"Flang Type TBAA Root"}
!8 = !{!9, !9, i64 0}
!9 = !{!"descriptor member", !6, i64 0}
!10 = !{!11}
!11 = !{i64 2, i64 -1, i64 -1, i1 true}
*** IR Dump After PromotePass on _QQmain ***
define void @_QQmain() local_unnamed_addr {
entry:
  %structArg = alloca { ptr, ptr, ptr }, align 8
  %0 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %1 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %2 = alloca i32, i64 1, align 4
  store i32 1048576, ptr %2, align 4, !tbaa !4
  %3 = call ptr @malloc(i64 mul (i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), i64 1048576))
  %4 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } { ptr undef, i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), i32 20180515, i8 1, i8 28, i8 2, i8 0, [1 x [3 x i64]] [[3 x i64] [i64 1, i64 1048576, i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64)]] }, ptr %3, 0
  %.fca.7.0.0.extract = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %4, 7, 0, 0
  %.fca.7.0.1.extract = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %4, 7, 0, 1
  %.fca.7.0.2.extract = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %4, 7, 0, 2
  %.fca.0.insert = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } poison, ptr %3, 0
  %.fca.1.insert = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.0.insert, i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), 1
  %.fca.2.insert = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.1.insert, i32 20180515, 2
  %.fca.3.insert = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.2.insert, i8 1, 3
  %.fca.4.insert = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.3.insert, i8 28, 4
  %.fca.5.insert = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.4.insert, i8 2, 5
  %.fca.6.insert = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.5.insert, i8 0, 6
  %.fca.7.0.0.insert = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.6.insert, i64 %.fca.7.0.0.extract, 7, 0, 0
  %.fca.7.0.1.insert = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.7.0.0.insert, i64 %.fca.7.0.1.extract, 7, 0, 1
  %.fca.7.0.2.insert = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.7.0.1.insert, i64 %.fca.7.0.2.extract, 7, 0, 2
  store { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.7.0.2.insert, ptr @_QFEarr, align 8, !tbaa !8
  %omp_global_thread_num = call i32 @__kmpc_global_thread_num(ptr @1)
  store ptr %2, ptr %structArg, align 8
  %gep_5 = getelementptr { ptr, ptr, ptr }, ptr %structArg, i32 0, i32 1
  store ptr %1, ptr %gep_5, align 8
  %gep_6 = getelementptr { ptr, ptr, ptr }, ptr %structArg, i32 0, i32 2
  store ptr %0, ptr %gep_6, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr @1, i32 1, ptr @_QQmain..omp_par, ptr %structArg)
  %5 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr @_QQcl.60ea5a38555821a77357f87d16df9a0f, i32 21)
  %6 = call i1 @_FortranAioOutputAscii(ptr %5, ptr @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %7 = load i32, ptr %2, align 4, !tbaa !4
  %8 = call i1 @_FortranAioOutputInteger32(ptr %5, i32 %7)
  %9 = call i1 @_FortranAioOutputAscii(ptr %5, ptr @_QQcl.2920697320, i64 5)
  %10 = load { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, align 8, !tbaa !8
  %.fca.0.extract17 = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %10, 0
  %.fca.7.0.0.extract24 = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %10, 7, 0, 0
  %11 = sub i64 1, %.fca.7.0.0.extract24
  %12 = getelementptr double, ptr %.fca.0.extract17, i64 %11
  %13 = load double, ptr %12, align 8, !tbaa !4
  %14 = load i32, ptr %2, align 4, !tbaa !4
  %15 = sext i32 %14 to i64
  %16 = sub i64 %15, %.fca.7.0.0.extract24
  %17 = getelementptr double, ptr %.fca.0.extract17, i64 %16
  %18 = load double, ptr %17, align 8, !tbaa !4
  %19 = fadd contract double %13, %18
  %20 = call i1 @_FortranAioOutputReal64(ptr %5, double %19)
  %21 = call i32 @_FortranAioEndIoStatement(ptr %5)
  %22 = load { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, align 8, !tbaa !8
  %.fca.0.extract34 = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %22, 0
  call void @free(ptr %.fca.0.extract34)
  store { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } { ptr null, i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), i32 20180515, i8 1, i8 28, i8 2, i8 0, [1 x [3 x i64]] [[3 x i64] [i64 1, i64 0, i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64)]] }, ptr @_QFEarr, align 8, !tbaa !8
  ret void
}
*** IR Dump After InstCombinePass on _QQmain ***
define void @_QQmain() local_unnamed_addr {
entry:
  %structArg = alloca { ptr, ptr, ptr }, align 8
  %0 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %1 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %2 = alloca i32, align 4
  store i32 1048576, ptr %2, align 4, !tbaa !4
  %3 = call dereferenceable_or_null(8388608) ptr @malloc(i64 8388608)
  store ptr %3, ptr @_QFEarr, align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  store i32 20180515, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  store i8 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  store i8 28, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  store i8 2, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  store i8 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  store i64 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  store i64 1048576, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  %omp_global_thread_num = call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %2, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %1, ptr %gep_5, align 8
  %gep_6 = getelementptr inbounds { ptr, ptr, ptr }, ptr %structArg, i64 0, i32 2
  store ptr %0, ptr %gep_6, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QQmain..omp_par, ptr nonnull %structArg)
  %4 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.60ea5a38555821a77357f87d16df9a0f, i32 21)
  %5 = call i1 @_FortranAioOutputAscii(ptr %4, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %6 = load i32, ptr %2, align 4, !tbaa !4
  %7 = call i1 @_FortranAioOutputInteger32(ptr %4, i32 %6)
  %8 = call i1 @_FortranAioOutputAscii(ptr %4, ptr nonnull @_QQcl.2920697320, i64 5)
  %.unpack = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  %.unpack96.unpack.unpack = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  %9 = sub i64 1, %.unpack96.unpack.unpack
  %10 = getelementptr double, ptr %.unpack, i64 %9
  %11 = load double, ptr %10, align 8, !tbaa !4
  %12 = load i32, ptr %2, align 4, !tbaa !4
  %13 = sext i32 %12 to i64
  %14 = sub i64 %13, %.unpack96.unpack.unpack
  %15 = getelementptr double, ptr %.unpack, i64 %14
  %16 = load double, ptr %15, align 8, !tbaa !4
  %17 = fadd contract double %11, %16
  %18 = call i1 @_FortranAioOutputReal64(ptr %4, double %17)
  %19 = call i32 @_FortranAioEndIoStatement(ptr %4)
  %.unpack101 = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  call void @free(ptr %.unpack101)
  store ptr null, ptr @_QFEarr, align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  store i32 20180515, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  store i8 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  store i8 28, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  store i8 2, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  store i8 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  store i64 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  store i64 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  ret void
}
*** IR Dump After SimplifyCFGPass on _QQmain ***
define void @_QQmain() local_unnamed_addr {
entry:
  %structArg = alloca { ptr, ptr, ptr }, align 8
  %0 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %1 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %2 = alloca i32, align 4
  store i32 1048576, ptr %2, align 4, !tbaa !4
  %3 = call dereferenceable_or_null(8388608) ptr @malloc(i64 8388608)
  store ptr %3, ptr @_QFEarr, align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  store i32 20180515, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  store i8 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  store i8 28, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  store i8 2, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  store i8 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  store i64 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  store i64 1048576, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  %omp_global_thread_num = call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %2, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %1, ptr %gep_5, align 8
  %gep_6 = getelementptr inbounds { ptr, ptr, ptr }, ptr %structArg, i64 0, i32 2
  store ptr %0, ptr %gep_6, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QQmain..omp_par, ptr nonnull %structArg)
  %4 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.60ea5a38555821a77357f87d16df9a0f, i32 21)
  %5 = call i1 @_FortranAioOutputAscii(ptr %4, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %6 = load i32, ptr %2, align 4, !tbaa !4
  %7 = call i1 @_FortranAioOutputInteger32(ptr %4, i32 %6)
  %8 = call i1 @_FortranAioOutputAscii(ptr %4, ptr nonnull @_QQcl.2920697320, i64 5)
  %.unpack = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  %.unpack96.unpack.unpack = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  %9 = sub i64 1, %.unpack96.unpack.unpack
  %10 = getelementptr double, ptr %.unpack, i64 %9
  %11 = load double, ptr %10, align 8, !tbaa !4
  %12 = load i32, ptr %2, align 4, !tbaa !4
  %13 = sext i32 %12 to i64
  %14 = sub i64 %13, %.unpack96.unpack.unpack
  %15 = getelementptr double, ptr %.unpack, i64 %14
  %16 = load double, ptr %15, align 8, !tbaa !4
  %17 = fadd contract double %11, %16
  %18 = call i1 @_FortranAioOutputReal64(ptr %4, double %17)
  %19 = call i32 @_FortranAioEndIoStatement(ptr %4)
  %.unpack101 = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  call void @free(ptr %.unpack101)
  store ptr null, ptr @_QFEarr, align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  store i32 20180515, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  store i8 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  store i8 28, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  store i8 2, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  store i8 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  store i64 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  store i64 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  ret void
}
*** IR Dump After PromotePass on _QQmain..omp_par ***
; Function Attrs: norecurse nounwind
define internal void @_QQmain..omp_par(ptr noalias %tid.addr, ptr noalias %zero.addr, ptr %0) #2 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr, ptr }, ptr %0, i32 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %gep_3 = getelementptr { ptr, ptr, ptr }, ptr %0, i32 0, i32 2
  %loadgep_4 = load ptr, ptr %gep_3, align 8
  %p.lastiter = alloca i32, align 4
  %p.lowerbound = alloca i32, align 4
  %p.upperbound = alloca i32, align 4
  %p.stride = alloca i32, align 4
  %1 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %2 = sub nsw i32 %1, 1
  %3 = icmp slt i32 %1, 1
  %omp_loop.tripcount = select i1 %3, i32 0, i32 %1
  store i32 0, ptr %p.lowerbound, align 4
  %4 = sub i32 %omp_loop.tripcount, 1
  store i32 %4, ptr %p.upperbound, align 4
  store i32 1, ptr %p.stride, align 4
  %omp_global_thread_num3 = call i32 @__kmpc_global_thread_num(ptr @1)
  call void @__kmpc_for_static_init_4u(ptr @1, i32 %omp_global_thread_num3, i32 34, ptr %p.lastiter, ptr %p.lowerbound, ptr %p.upperbound, ptr %p.stride, i32 1, i32 0)
  %5 = load i32, ptr %p.lowerbound, align 4
  %6 = load i32, ptr %p.upperbound, align 4
  %7 = sub i32 %6, %5
  %8 = add i32 %7, 1
  br label %omp_loop.header

omp_loop.header:                                  ; preds = %omp_loop.body, %omp.par.entry
  %omp_loop.iv = phi i32 [ 0, %omp.par.entry ], [ %omp_loop.next, %omp_loop.body ]
  %omp_loop.cmp = icmp ult i32 %omp_loop.iv, %8
  br i1 %omp_loop.cmp, label %omp_loop.body, label %omp_loop.exit

omp_loop.exit:                                    ; preds = %omp_loop.header
  call void @__kmpc_for_static_fini(ptr @1, i32 %omp_global_thread_num3)
  %omp_global_thread_num4 = call i32 @__kmpc_global_thread_num(ptr @1)
  call void @__kmpc_barrier(ptr @2, i32 %omp_global_thread_num4)
  ret void

omp_loop.body:                                    ; preds = %omp_loop.header
  %9 = add i32 %omp_loop.iv, %5
  %10 = add i32 %9, 1
  %11 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %12 = sitofp i32 %11 to float
  %13 = fdiv contract float 1.000000e+00, %12
  %14 = fpext float %13 to double
  %15 = load { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, align 8, !tbaa !8
  store { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %15, ptr %loadgep_2, align 8, !tbaa !8
  %16 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i32 0, i32 7, i64 0, i32 0
  %17 = load i64, ptr %16, align 8, !tbaa !8
  %18 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i32 0, i32 7, i64 0, i32 1
  %19 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i32 0, i32 7, i64 0, i32 2
  %20 = load ptr, ptr %loadgep_2, align 8, !tbaa !8
  %21 = sext i32 %10 to i64
  %22 = sub i64 %21, %17
  %23 = getelementptr double, ptr %20, i64 %22
  store double %14, ptr %23, align 8, !tbaa !4
  %24 = load { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, align 8, !tbaa !8
  store { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %24, ptr %loadgep_4, align 8, !tbaa !8
  %25 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i32 0, i32 7, i64 0, i32 0
  %26 = load i64, ptr %25, align 8, !tbaa !8
  %27 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i32 0, i32 7, i64 0, i32 1
  %28 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i32 0, i32 7, i64 0, i32 2
  %29 = load ptr, ptr %loadgep_4, align 8, !tbaa !8
  %30 = sub i64 %21, %26
  %31 = getelementptr double, ptr %29, i64 %30
  %omp_loop.next = add nuw i32 %omp_loop.iv, 1
  br label %omp_loop.header
}
*** IR Dump After InstCombinePass on _QQmain..omp_par ***
; Function Attrs: norecurse nounwind
define internal void @_QQmain..omp_par(ptr noalias %tid.addr, ptr noalias %zero.addr, ptr %0) #2 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %gep_3 = getelementptr { ptr, ptr, ptr }, ptr %0, i64 0, i32 2
  %loadgep_4 = load ptr, ptr %gep_3, align 8
  %p.lastiter = alloca i32, align 4
  %p.lowerbound = alloca i32, align 4
  %p.upperbound = alloca i32, align 4
  %p.stride = alloca i32, align 4
  %1 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %omp_loop.tripcount = call i32 @llvm.smax.i32(i32 %1, i32 0)
  store i32 0, ptr %p.lowerbound, align 4
  %2 = add nsw i32 %omp_loop.tripcount, -1
  store i32 %2, ptr %p.upperbound, align 4
  store i32 1, ptr %p.stride, align 4
  %omp_global_thread_num3 = call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  call void @__kmpc_for_static_init_4u(ptr nonnull @1, i32 %omp_global_thread_num3, i32 34, ptr nonnull %p.lastiter, ptr nonnull %p.lowerbound, ptr nonnull %p.upperbound, ptr nonnull %p.stride, i32 1, i32 0)
  %3 = load i32, ptr %p.lowerbound, align 4
  %4 = load i32, ptr %p.upperbound, align 4
  %5 = sub i32 %4, %3
  %6 = add i32 %5, 1
  br label %omp_loop.header

omp_loop.header:                                  ; preds = %omp_loop.body, %omp.par.entry
  %omp_loop.iv = phi i32 [ 0, %omp.par.entry ], [ %omp_loop.next, %omp_loop.body ]
  %omp_loop.cmp = icmp ult i32 %omp_loop.iv, %6
  br i1 %omp_loop.cmp, label %omp_loop.body, label %omp_loop.exit

omp_loop.exit:                                    ; preds = %omp_loop.header
  call void @__kmpc_for_static_fini(ptr nonnull @1, i32 %omp_global_thread_num3)
  %omp_global_thread_num4 = call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  call void @__kmpc_barrier(ptr nonnull @2, i32 %omp_global_thread_num4)
  ret void

omp_loop.body:                                    ; preds = %omp_loop.header
  %7 = add i32 %omp_loop.iv, %3
  %8 = add i32 %7, 1
  %9 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %10 = sitofp i32 %9 to float
  %11 = fdiv contract float 1.000000e+00, %10
  %12 = fpext float %11 to double
  %.unpack = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  %.unpack6 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  %.unpack7 = load i32, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  %.unpack8 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  %.unpack9 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  %.unpack10 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  %.unpack11 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  %.unpack12.unpack.unpack = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  %.unpack12.unpack.unpack14 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  %.unpack12.unpack.unpack15 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  store ptr %.unpack, ptr %loadgep_2, align 8, !tbaa !8
  %loadgep_2.repack17 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  store i64 %.unpack6, ptr %loadgep_2.repack17, align 8, !tbaa !8
  %loadgep_2.repack19 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  store i32 %.unpack7, ptr %loadgep_2.repack19, align 8, !tbaa !8
  %loadgep_2.repack21 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  store i8 %.unpack8, ptr %loadgep_2.repack21, align 4, !tbaa !8
  %loadgep_2.repack23 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  store i8 %.unpack9, ptr %loadgep_2.repack23, align 1, !tbaa !8
  %loadgep_2.repack25 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  store i8 %.unpack10, ptr %loadgep_2.repack25, align 2, !tbaa !8
  %loadgep_2.repack27 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  store i8 %.unpack11, ptr %loadgep_2.repack27, align 1, !tbaa !8
  %loadgep_2.repack29 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  store i64 %.unpack12.unpack.unpack, ptr %loadgep_2.repack29, align 8, !tbaa !8
  %loadgep_2.repack29.repack31 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack12.unpack.unpack14, ptr %loadgep_2.repack29.repack31, align 8, !tbaa !8
  %loadgep_2.repack29.repack33 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  store i64 %.unpack12.unpack.unpack15, ptr %loadgep_2.repack29.repack33, align 8, !tbaa !8
  %13 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 0
  %14 = load i64, ptr %13, align 8, !tbaa !8
  %15 = load ptr, ptr %loadgep_2, align 8, !tbaa !8
  %16 = sext i32 %8 to i64
  %17 = sub i64 %16, %14
  %18 = getelementptr double, ptr %15, i64 %17
  store double %12, ptr %18, align 8, !tbaa !4
  %.unpack35 = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  %.unpack36 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  %.unpack37 = load i32, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  %.unpack38 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  %.unpack39 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  %.unpack40 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  %.unpack41 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  %.unpack42.unpack.unpack = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  %.unpack42.unpack.unpack44 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  %.unpack42.unpack.unpack45 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  store ptr %.unpack35, ptr %loadgep_4, align 8, !tbaa !8
  %loadgep_4.repack47 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 1
  store i64 %.unpack36, ptr %loadgep_4.repack47, align 8, !tbaa !8
  %loadgep_4.repack49 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 2
  store i32 %.unpack37, ptr %loadgep_4.repack49, align 8, !tbaa !8
  %loadgep_4.repack51 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 3
  store i8 %.unpack38, ptr %loadgep_4.repack51, align 4, !tbaa !8
  %loadgep_4.repack53 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 4
  store i8 %.unpack39, ptr %loadgep_4.repack53, align 1, !tbaa !8
  %loadgep_4.repack55 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 5
  store i8 %.unpack40, ptr %loadgep_4.repack55, align 2, !tbaa !8
  %loadgep_4.repack57 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 6
  store i8 %.unpack41, ptr %loadgep_4.repack57, align 1, !tbaa !8
  %loadgep_4.repack59 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7
  store i64 %.unpack42.unpack.unpack, ptr %loadgep_4.repack59, align 8, !tbaa !8
  %loadgep_4.repack59.repack61 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack42.unpack.unpack44, ptr %loadgep_4.repack59.repack61, align 8, !tbaa !8
  %loadgep_4.repack59.repack63 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 2
  store i64 %.unpack42.unpack.unpack45, ptr %loadgep_4.repack59.repack63, align 8, !tbaa !8
  %omp_loop.next = add nuw i32 %omp_loop.iv, 1
  br label %omp_loop.header
}
*** IR Dump After SimplifyCFGPass on _QQmain..omp_par ***
; Function Attrs: norecurse nounwind
define internal void @_QQmain..omp_par(ptr noalias %tid.addr, ptr noalias %zero.addr, ptr %0) #2 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %gep_3 = getelementptr { ptr, ptr, ptr }, ptr %0, i64 0, i32 2
  %loadgep_4 = load ptr, ptr %gep_3, align 8
  %p.lastiter = alloca i32, align 4
  %p.lowerbound = alloca i32, align 4
  %p.upperbound = alloca i32, align 4
  %p.stride = alloca i32, align 4
  %1 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %omp_loop.tripcount = call i32 @llvm.smax.i32(i32 %1, i32 0)
  store i32 0, ptr %p.lowerbound, align 4
  %2 = add nsw i32 %omp_loop.tripcount, -1
  store i32 %2, ptr %p.upperbound, align 4
  store i32 1, ptr %p.stride, align 4
  %omp_global_thread_num3 = call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  call void @__kmpc_for_static_init_4u(ptr nonnull @1, i32 %omp_global_thread_num3, i32 34, ptr nonnull %p.lastiter, ptr nonnull %p.lowerbound, ptr nonnull %p.upperbound, ptr nonnull %p.stride, i32 1, i32 0)
  %3 = load i32, ptr %p.lowerbound, align 4
  %4 = load i32, ptr %p.upperbound, align 4
  %5 = sub i32 %4, %3
  %6 = add i32 %5, 1
  br label %omp_loop.header

omp_loop.header:                                  ; preds = %omp_loop.body, %omp.par.entry
  %omp_loop.iv = phi i32 [ 0, %omp.par.entry ], [ %omp_loop.next, %omp_loop.body ]
  %omp_loop.cmp = icmp ult i32 %omp_loop.iv, %6
  br i1 %omp_loop.cmp, label %omp_loop.body, label %omp_loop.exit

omp_loop.exit:                                    ; preds = %omp_loop.header
  call void @__kmpc_for_static_fini(ptr nonnull @1, i32 %omp_global_thread_num3)
  %omp_global_thread_num4 = call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  call void @__kmpc_barrier(ptr nonnull @2, i32 %omp_global_thread_num4)
  ret void

omp_loop.body:                                    ; preds = %omp_loop.header
  %7 = add i32 %omp_loop.iv, %3
  %8 = add i32 %7, 1
  %9 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %10 = sitofp i32 %9 to float
  %11 = fdiv contract float 1.000000e+00, %10
  %12 = fpext float %11 to double
  %.unpack = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  %.unpack6 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  %.unpack7 = load i32, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  %.unpack8 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  %.unpack9 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  %.unpack10 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  %.unpack11 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  %.unpack12.unpack.unpack = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  %.unpack12.unpack.unpack14 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  %.unpack12.unpack.unpack15 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  store ptr %.unpack, ptr %loadgep_2, align 8, !tbaa !8
  %loadgep_2.repack17 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  store i64 %.unpack6, ptr %loadgep_2.repack17, align 8, !tbaa !8
  %loadgep_2.repack19 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  store i32 %.unpack7, ptr %loadgep_2.repack19, align 8, !tbaa !8
  %loadgep_2.repack21 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  store i8 %.unpack8, ptr %loadgep_2.repack21, align 4, !tbaa !8
  %loadgep_2.repack23 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  store i8 %.unpack9, ptr %loadgep_2.repack23, align 1, !tbaa !8
  %loadgep_2.repack25 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  store i8 %.unpack10, ptr %loadgep_2.repack25, align 2, !tbaa !8
  %loadgep_2.repack27 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  store i8 %.unpack11, ptr %loadgep_2.repack27, align 1, !tbaa !8
  %loadgep_2.repack29 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  store i64 %.unpack12.unpack.unpack, ptr %loadgep_2.repack29, align 8, !tbaa !8
  %loadgep_2.repack29.repack31 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack12.unpack.unpack14, ptr %loadgep_2.repack29.repack31, align 8, !tbaa !8
  %loadgep_2.repack29.repack33 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  store i64 %.unpack12.unpack.unpack15, ptr %loadgep_2.repack29.repack33, align 8, !tbaa !8
  %13 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 0
  %14 = load i64, ptr %13, align 8, !tbaa !8
  %15 = load ptr, ptr %loadgep_2, align 8, !tbaa !8
  %16 = sext i32 %8 to i64
  %17 = sub i64 %16, %14
  %18 = getelementptr double, ptr %15, i64 %17
  store double %12, ptr %18, align 8, !tbaa !4
  %.unpack35 = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  %.unpack36 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  %.unpack37 = load i32, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  %.unpack38 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  %.unpack39 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  %.unpack40 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  %.unpack41 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  %.unpack42.unpack.unpack = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  %.unpack42.unpack.unpack44 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  %.unpack42.unpack.unpack45 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  store ptr %.unpack35, ptr %loadgep_4, align 8, !tbaa !8
  %loadgep_4.repack47 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 1
  store i64 %.unpack36, ptr %loadgep_4.repack47, align 8, !tbaa !8
  %loadgep_4.repack49 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 2
  store i32 %.unpack37, ptr %loadgep_4.repack49, align 8, !tbaa !8
  %loadgep_4.repack51 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 3
  store i8 %.unpack38, ptr %loadgep_4.repack51, align 4, !tbaa !8
  %loadgep_4.repack53 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 4
  store i8 %.unpack39, ptr %loadgep_4.repack53, align 1, !tbaa !8
  %loadgep_4.repack55 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 5
  store i8 %.unpack40, ptr %loadgep_4.repack55, align 2, !tbaa !8
  %loadgep_4.repack57 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 6
  store i8 %.unpack41, ptr %loadgep_4.repack57, align 1, !tbaa !8
  %loadgep_4.repack59 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7
  store i64 %.unpack42.unpack.unpack, ptr %loadgep_4.repack59, align 8, !tbaa !8
  %loadgep_4.repack59.repack61 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack42.unpack.unpack44, ptr %loadgep_4.repack59.repack61, align 8, !tbaa !8
  %loadgep_4.repack59.repack63 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 2
  store i64 %.unpack42.unpack.unpack45, ptr %loadgep_4.repack59.repack63, align 8, !tbaa !8
  %omp_loop.next = add nuw i32 %omp_loop.iv, 1
  br label %omp_loop.header
}
*** IR Dump After RequireAnalysisPass<llvm::GlobalsAA, llvm::Module> on [module] ***
; ModuleID = 'FIRModule'
source_filename = "FIRModule"
target datalayout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128"
target triple = "x86_64-unknown-linux-gnu"

%struct.ident_t = type { i32, i32, i32, i32, ptr }

@_QFEarr = internal unnamed_addr global { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } { ptr null, i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), i32 20180515, i8 1, i8 28, i8 2, i8 0, [1 x [3 x i64]] [[3 x i64] [i64 1, i64 0, i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64)]] }
@_QQcl.60ea5a38555821a77357f87d16df9a0f = internal constant [62 x i8] c"/g/g92/rydahl1/flangtests/src/duplicate_array_descriptors.f90\00"
@_QQcl.28612C69372C612C6531332E36653229 = internal constant [16 x i8] c"(a,i7,a,e13.6e2)"
@_QQcl.54686520726573756C74206F6620286172722831292B61727228 = internal constant [26 x i8] c"The result of (arr(1)+arr("
@_QQcl.2920697320 = internal constant [5 x i8] c") is "
@_QQEnvironmentDefaults = local_unnamed_addr constant ptr null
@0 = private unnamed_addr constant [23 x i8] c";unknown;unknown;0;0;;\00", align 1
@1 = private unnamed_addr constant %struct.ident_t { i32 0, i32 2, i32 0, i32 22, ptr @0 }, align 8
@2 = private unnamed_addr constant %struct.ident_t { i32 0, i32 66, i32 0, i32 22, ptr @0 }, align 8

; Function Attrs: mustprogress nofree nounwind willreturn allockind("alloc,uninitialized") allocsize(0) memory(inaccessiblemem: readwrite)
declare noalias noundef ptr @malloc(i64 noundef) local_unnamed_addr #0

; Function Attrs: mustprogress nounwind willreturn allockind("free") memory(argmem: readwrite, inaccessiblemem: readwrite)
declare void @free(ptr allocptr nocapture noundef) local_unnamed_addr #1

define void @_QQmain() local_unnamed_addr {
entry:
  %structArg = alloca { ptr, ptr, ptr }, align 8
  %0 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %1 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %2 = alloca i32, align 4
  store i32 1048576, ptr %2, align 4, !tbaa !4
  %3 = call dereferenceable_or_null(8388608) ptr @malloc(i64 8388608)
  store ptr %3, ptr @_QFEarr, align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  store i32 20180515, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  store i8 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  store i8 28, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  store i8 2, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  store i8 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  store i64 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  store i64 1048576, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  %omp_global_thread_num = call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %2, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %1, ptr %gep_5, align 8
  %gep_6 = getelementptr inbounds { ptr, ptr, ptr }, ptr %structArg, i64 0, i32 2
  store ptr %0, ptr %gep_6, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QQmain..omp_par, ptr nonnull %structArg)
  %4 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.60ea5a38555821a77357f87d16df9a0f, i32 21)
  %5 = call i1 @_FortranAioOutputAscii(ptr %4, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %6 = load i32, ptr %2, align 4, !tbaa !4
  %7 = call i1 @_FortranAioOutputInteger32(ptr %4, i32 %6)
  %8 = call i1 @_FortranAioOutputAscii(ptr %4, ptr nonnull @_QQcl.2920697320, i64 5)
  %.unpack = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  %.unpack96.unpack.unpack = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  %9 = sub i64 1, %.unpack96.unpack.unpack
  %10 = getelementptr double, ptr %.unpack, i64 %9
  %11 = load double, ptr %10, align 8, !tbaa !4
  %12 = load i32, ptr %2, align 4, !tbaa !4
  %13 = sext i32 %12 to i64
  %14 = sub i64 %13, %.unpack96.unpack.unpack
  %15 = getelementptr double, ptr %.unpack, i64 %14
  %16 = load double, ptr %15, align 8, !tbaa !4
  %17 = fadd contract double %11, %16
  %18 = call i1 @_FortranAioOutputReal64(ptr %4, double %17)
  %19 = call i32 @_FortranAioEndIoStatement(ptr %4)
  %.unpack101 = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  call void @free(ptr %.unpack101)
  store ptr null, ptr @_QFEarr, align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  store i32 20180515, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  store i8 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  store i8 28, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  store i8 2, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  store i8 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  store i64 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  store i64 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  ret void
}

; Function Attrs: norecurse nounwind
define internal void @_QQmain..omp_par(ptr noalias %tid.addr, ptr noalias %zero.addr, ptr %0) #2 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %gep_3 = getelementptr { ptr, ptr, ptr }, ptr %0, i64 0, i32 2
  %loadgep_4 = load ptr, ptr %gep_3, align 8
  %p.lastiter = alloca i32, align 4
  %p.lowerbound = alloca i32, align 4
  %p.upperbound = alloca i32, align 4
  %p.stride = alloca i32, align 4
  %1 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %omp_loop.tripcount = call i32 @llvm.smax.i32(i32 %1, i32 0)
  store i32 0, ptr %p.lowerbound, align 4
  %2 = add nsw i32 %omp_loop.tripcount, -1
  store i32 %2, ptr %p.upperbound, align 4
  store i32 1, ptr %p.stride, align 4
  %omp_global_thread_num3 = call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  call void @__kmpc_for_static_init_4u(ptr nonnull @1, i32 %omp_global_thread_num3, i32 34, ptr nonnull %p.lastiter, ptr nonnull %p.lowerbound, ptr nonnull %p.upperbound, ptr nonnull %p.stride, i32 1, i32 0)
  %3 = load i32, ptr %p.lowerbound, align 4
  %4 = load i32, ptr %p.upperbound, align 4
  %5 = sub i32 %4, %3
  %6 = add i32 %5, 1
  br label %omp_loop.header

omp_loop.header:                                  ; preds = %omp_loop.body, %omp.par.entry
  %omp_loop.iv = phi i32 [ 0, %omp.par.entry ], [ %omp_loop.next, %omp_loop.body ]
  %omp_loop.cmp = icmp ult i32 %omp_loop.iv, %6
  br i1 %omp_loop.cmp, label %omp_loop.body, label %omp_loop.exit

omp_loop.exit:                                    ; preds = %omp_loop.header
  call void @__kmpc_for_static_fini(ptr nonnull @1, i32 %omp_global_thread_num3)
  %omp_global_thread_num4 = call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  call void @__kmpc_barrier(ptr nonnull @2, i32 %omp_global_thread_num4)
  ret void

omp_loop.body:                                    ; preds = %omp_loop.header
  %7 = add i32 %omp_loop.iv, %3
  %8 = add i32 %7, 1
  %9 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %10 = sitofp i32 %9 to float
  %11 = fdiv contract float 1.000000e+00, %10
  %12 = fpext float %11 to double
  %.unpack = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  %.unpack6 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  %.unpack7 = load i32, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  %.unpack8 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  %.unpack9 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  %.unpack10 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  %.unpack11 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  %.unpack12.unpack.unpack = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  %.unpack12.unpack.unpack14 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  %.unpack12.unpack.unpack15 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  store ptr %.unpack, ptr %loadgep_2, align 8, !tbaa !8
  %loadgep_2.repack17 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  store i64 %.unpack6, ptr %loadgep_2.repack17, align 8, !tbaa !8
  %loadgep_2.repack19 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  store i32 %.unpack7, ptr %loadgep_2.repack19, align 8, !tbaa !8
  %loadgep_2.repack21 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  store i8 %.unpack8, ptr %loadgep_2.repack21, align 4, !tbaa !8
  %loadgep_2.repack23 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  store i8 %.unpack9, ptr %loadgep_2.repack23, align 1, !tbaa !8
  %loadgep_2.repack25 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  store i8 %.unpack10, ptr %loadgep_2.repack25, align 2, !tbaa !8
  %loadgep_2.repack27 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  store i8 %.unpack11, ptr %loadgep_2.repack27, align 1, !tbaa !8
  %loadgep_2.repack29 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  store i64 %.unpack12.unpack.unpack, ptr %loadgep_2.repack29, align 8, !tbaa !8
  %loadgep_2.repack29.repack31 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack12.unpack.unpack14, ptr %loadgep_2.repack29.repack31, align 8, !tbaa !8
  %loadgep_2.repack29.repack33 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  store i64 %.unpack12.unpack.unpack15, ptr %loadgep_2.repack29.repack33, align 8, !tbaa !8
  %13 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 0
  %14 = load i64, ptr %13, align 8, !tbaa !8
  %15 = load ptr, ptr %loadgep_2, align 8, !tbaa !8
  %16 = sext i32 %8 to i64
  %17 = sub i64 %16, %14
  %18 = getelementptr double, ptr %15, i64 %17
  store double %12, ptr %18, align 8, !tbaa !4
  %.unpack35 = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  %.unpack36 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  %.unpack37 = load i32, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  %.unpack38 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  %.unpack39 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  %.unpack40 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  %.unpack41 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  %.unpack42.unpack.unpack = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  %.unpack42.unpack.unpack44 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  %.unpack42.unpack.unpack45 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  store ptr %.unpack35, ptr %loadgep_4, align 8, !tbaa !8
  %loadgep_4.repack47 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 1
  store i64 %.unpack36, ptr %loadgep_4.repack47, align 8, !tbaa !8
  %loadgep_4.repack49 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 2
  store i32 %.unpack37, ptr %loadgep_4.repack49, align 8, !tbaa !8
  %loadgep_4.repack51 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 3
  store i8 %.unpack38, ptr %loadgep_4.repack51, align 4, !tbaa !8
  %loadgep_4.repack53 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 4
  store i8 %.unpack39, ptr %loadgep_4.repack53, align 1, !tbaa !8
  %loadgep_4.repack55 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 5
  store i8 %.unpack40, ptr %loadgep_4.repack55, align 2, !tbaa !8
  %loadgep_4.repack57 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 6
  store i8 %.unpack41, ptr %loadgep_4.repack57, align 1, !tbaa !8
  %loadgep_4.repack59 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7
  store i64 %.unpack42.unpack.unpack, ptr %loadgep_4.repack59, align 8, !tbaa !8
  %loadgep_4.repack59.repack61 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack42.unpack.unpack44, ptr %loadgep_4.repack59.repack61, align 8, !tbaa !8
  %loadgep_4.repack59.repack63 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 2
  store i64 %.unpack42.unpack.unpack45, ptr %loadgep_4.repack59.repack63, align 8, !tbaa !8
  %omp_loop.next = add nuw i32 %omp_loop.iv, 1
  br label %omp_loop.header
}

declare ptr @_FortranAioBeginExternalFormattedOutput(ptr, i64, ptr, i32, ptr, i32) local_unnamed_addr

declare zeroext i1 @_FortranAioOutputAscii(ptr, ptr, i64) local_unnamed_addr

declare zeroext i1 @_FortranAioOutputInteger32(ptr, i32) local_unnamed_addr

declare zeroext i1 @_FortranAioOutputReal64(ptr, double) local_unnamed_addr

declare i32 @_FortranAioEndIoStatement(ptr) local_unnamed_addr

; Function Attrs: nounwind
declare i32 @__kmpc_global_thread_num(ptr) local_unnamed_addr #3

; Function Attrs: nounwind
declare void @__kmpc_for_static_init_4u(ptr, i32, i32, ptr, ptr, ptr, ptr, i32, i32) local_unnamed_addr #3

; Function Attrs: nounwind
declare void @__kmpc_for_static_fini(ptr, i32) local_unnamed_addr #3

; Function Attrs: convergent nounwind
declare void @__kmpc_barrier(ptr, i32) local_unnamed_addr #4

; Function Attrs: nounwind
declare !callback !10 void @__kmpc_fork_call(ptr, i32, ptr, ...) local_unnamed_addr #3

; Function Attrs: nocallback nofree nosync nounwind speculatable willreturn memory(none)
declare i32 @llvm.smax.i32(i32, i32) #5

attributes #0 = { mustprogress nofree nounwind willreturn allockind("alloc,uninitialized") allocsize(0) memory(inaccessiblemem: readwrite) "alloc-family"="malloc" }
attributes #1 = { mustprogress nounwind willreturn allockind("free") memory(argmem: readwrite, inaccessiblemem: readwrite) "alloc-family"="malloc" }
attributes #2 = { norecurse nounwind }
attributes #3 = { nounwind }
attributes #4 = { convergent nounwind }
attributes #5 = { nocallback nofree nosync nounwind speculatable willreturn memory(none) }

!llvm.module.flags = !{!0, !1, !2, !3}

!0 = !{i32 2, !"Debug Info Version", i32 3}
!1 = !{i32 7, !"openmp", i32 11}
!2 = !{i32 8, !"PIC Level", i32 2}
!3 = !{i32 7, !"PIE Level", i32 2}
!4 = !{!5, !5, i64 0}
!5 = !{!"any data access", !6, i64 0}
!6 = !{!"any access", !7, i64 0}
!7 = !{!"Flang Type TBAA Root"}
!8 = !{!9, !9, i64 0}
!9 = !{!"descriptor member", !6, i64 0}
!10 = !{!11}
!11 = !{i64 2, i64 -1, i64 -1, i1 true}
*** IR Dump After InvalidateAnalysisPass<llvm::AAManager> on _QQmain ***
define void @_QQmain() local_unnamed_addr {
entry:
  %structArg = alloca { ptr, ptr, ptr }, align 8
  %0 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %1 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %2 = alloca i32, align 4
  store i32 1048576, ptr %2, align 4, !tbaa !4
  %3 = call dereferenceable_or_null(8388608) ptr @malloc(i64 8388608)
  store ptr %3, ptr @_QFEarr, align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  store i32 20180515, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  store i8 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  store i8 28, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  store i8 2, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  store i8 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  store i64 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  store i64 1048576, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  %omp_global_thread_num = call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %2, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %1, ptr %gep_5, align 8
  %gep_6 = getelementptr inbounds { ptr, ptr, ptr }, ptr %structArg, i64 0, i32 2
  store ptr %0, ptr %gep_6, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QQmain..omp_par, ptr nonnull %structArg)
  %4 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.60ea5a38555821a77357f87d16df9a0f, i32 21)
  %5 = call i1 @_FortranAioOutputAscii(ptr %4, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %6 = load i32, ptr %2, align 4, !tbaa !4
  %7 = call i1 @_FortranAioOutputInteger32(ptr %4, i32 %6)
  %8 = call i1 @_FortranAioOutputAscii(ptr %4, ptr nonnull @_QQcl.2920697320, i64 5)
  %.unpack = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  %.unpack96.unpack.unpack = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  %9 = sub i64 1, %.unpack96.unpack.unpack
  %10 = getelementptr double, ptr %.unpack, i64 %9
  %11 = load double, ptr %10, align 8, !tbaa !4
  %12 = load i32, ptr %2, align 4, !tbaa !4
  %13 = sext i32 %12 to i64
  %14 = sub i64 %13, %.unpack96.unpack.unpack
  %15 = getelementptr double, ptr %.unpack, i64 %14
  %16 = load double, ptr %15, align 8, !tbaa !4
  %17 = fadd contract double %11, %16
  %18 = call i1 @_FortranAioOutputReal64(ptr %4, double %17)
  %19 = call i32 @_FortranAioEndIoStatement(ptr %4)
  %.unpack101 = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  call void @free(ptr %.unpack101)
  store ptr null, ptr @_QFEarr, align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  store i32 20180515, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  store i8 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  store i8 28, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  store i8 2, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  store i8 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  store i64 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  store i64 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  ret void
}
*** IR Dump After InvalidateAnalysisPass<llvm::AAManager> on _QQmain..omp_par ***
; Function Attrs: norecurse nounwind
define internal void @_QQmain..omp_par(ptr noalias %tid.addr, ptr noalias %zero.addr, ptr %0) #2 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %gep_3 = getelementptr { ptr, ptr, ptr }, ptr %0, i64 0, i32 2
  %loadgep_4 = load ptr, ptr %gep_3, align 8
  %p.lastiter = alloca i32, align 4
  %p.lowerbound = alloca i32, align 4
  %p.upperbound = alloca i32, align 4
  %p.stride = alloca i32, align 4
  %1 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %omp_loop.tripcount = call i32 @llvm.smax.i32(i32 %1, i32 0)
  store i32 0, ptr %p.lowerbound, align 4
  %2 = add nsw i32 %omp_loop.tripcount, -1
  store i32 %2, ptr %p.upperbound, align 4
  store i32 1, ptr %p.stride, align 4
  %omp_global_thread_num3 = call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  call void @__kmpc_for_static_init_4u(ptr nonnull @1, i32 %omp_global_thread_num3, i32 34, ptr nonnull %p.lastiter, ptr nonnull %p.lowerbound, ptr nonnull %p.upperbound, ptr nonnull %p.stride, i32 1, i32 0)
  %3 = load i32, ptr %p.lowerbound, align 4
  %4 = load i32, ptr %p.upperbound, align 4
  %5 = sub i32 %4, %3
  %6 = add i32 %5, 1
  br label %omp_loop.header

omp_loop.header:                                  ; preds = %omp_loop.body, %omp.par.entry
  %omp_loop.iv = phi i32 [ 0, %omp.par.entry ], [ %omp_loop.next, %omp_loop.body ]
  %omp_loop.cmp = icmp ult i32 %omp_loop.iv, %6
  br i1 %omp_loop.cmp, label %omp_loop.body, label %omp_loop.exit

omp_loop.exit:                                    ; preds = %omp_loop.header
  call void @__kmpc_for_static_fini(ptr nonnull @1, i32 %omp_global_thread_num3)
  %omp_global_thread_num4 = call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  call void @__kmpc_barrier(ptr nonnull @2, i32 %omp_global_thread_num4)
  ret void

omp_loop.body:                                    ; preds = %omp_loop.header
  %7 = add i32 %omp_loop.iv, %3
  %8 = add i32 %7, 1
  %9 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %10 = sitofp i32 %9 to float
  %11 = fdiv contract float 1.000000e+00, %10
  %12 = fpext float %11 to double
  %.unpack = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  %.unpack6 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  %.unpack7 = load i32, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  %.unpack8 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  %.unpack9 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  %.unpack10 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  %.unpack11 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  %.unpack12.unpack.unpack = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  %.unpack12.unpack.unpack14 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  %.unpack12.unpack.unpack15 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  store ptr %.unpack, ptr %loadgep_2, align 8, !tbaa !8
  %loadgep_2.repack17 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  store i64 %.unpack6, ptr %loadgep_2.repack17, align 8, !tbaa !8
  %loadgep_2.repack19 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  store i32 %.unpack7, ptr %loadgep_2.repack19, align 8, !tbaa !8
  %loadgep_2.repack21 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  store i8 %.unpack8, ptr %loadgep_2.repack21, align 4, !tbaa !8
  %loadgep_2.repack23 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  store i8 %.unpack9, ptr %loadgep_2.repack23, align 1, !tbaa !8
  %loadgep_2.repack25 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  store i8 %.unpack10, ptr %loadgep_2.repack25, align 2, !tbaa !8
  %loadgep_2.repack27 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  store i8 %.unpack11, ptr %loadgep_2.repack27, align 1, !tbaa !8
  %loadgep_2.repack29 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  store i64 %.unpack12.unpack.unpack, ptr %loadgep_2.repack29, align 8, !tbaa !8
  %loadgep_2.repack29.repack31 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack12.unpack.unpack14, ptr %loadgep_2.repack29.repack31, align 8, !tbaa !8
  %loadgep_2.repack29.repack33 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  store i64 %.unpack12.unpack.unpack15, ptr %loadgep_2.repack29.repack33, align 8, !tbaa !8
  %13 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 0
  %14 = load i64, ptr %13, align 8, !tbaa !8
  %15 = load ptr, ptr %loadgep_2, align 8, !tbaa !8
  %16 = sext i32 %8 to i64
  %17 = sub i64 %16, %14
  %18 = getelementptr double, ptr %15, i64 %17
  store double %12, ptr %18, align 8, !tbaa !4
  %.unpack35 = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  %.unpack36 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  %.unpack37 = load i32, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  %.unpack38 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  %.unpack39 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  %.unpack40 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  %.unpack41 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  %.unpack42.unpack.unpack = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  %.unpack42.unpack.unpack44 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  %.unpack42.unpack.unpack45 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  store ptr %.unpack35, ptr %loadgep_4, align 8, !tbaa !8
  %loadgep_4.repack47 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 1
  store i64 %.unpack36, ptr %loadgep_4.repack47, align 8, !tbaa !8
  %loadgep_4.repack49 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 2
  store i32 %.unpack37, ptr %loadgep_4.repack49, align 8, !tbaa !8
  %loadgep_4.repack51 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 3
  store i8 %.unpack38, ptr %loadgep_4.repack51, align 4, !tbaa !8
  %loadgep_4.repack53 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 4
  store i8 %.unpack39, ptr %loadgep_4.repack53, align 1, !tbaa !8
  %loadgep_4.repack55 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 5
  store i8 %.unpack40, ptr %loadgep_4.repack55, align 2, !tbaa !8
  %loadgep_4.repack57 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 6
  store i8 %.unpack41, ptr %loadgep_4.repack57, align 1, !tbaa !8
  %loadgep_4.repack59 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7
  store i64 %.unpack42.unpack.unpack, ptr %loadgep_4.repack59, align 8, !tbaa !8
  %loadgep_4.repack59.repack61 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack42.unpack.unpack44, ptr %loadgep_4.repack59.repack61, align 8, !tbaa !8
  %loadgep_4.repack59.repack63 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 2
  store i64 %.unpack42.unpack.unpack45, ptr %loadgep_4.repack59.repack63, align 8, !tbaa !8
  %omp_loop.next = add nuw i32 %omp_loop.iv, 1
  br label %omp_loop.header
}
*** IR Dump After RequireAnalysisPass<llvm::ProfileSummaryAnalysis, llvm::Module> on [module] ***
; ModuleID = 'FIRModule'
source_filename = "FIRModule"
target datalayout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128"
target triple = "x86_64-unknown-linux-gnu"

%struct.ident_t = type { i32, i32, i32, i32, ptr }

@_QFEarr = internal unnamed_addr global { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } { ptr null, i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), i32 20180515, i8 1, i8 28, i8 2, i8 0, [1 x [3 x i64]] [[3 x i64] [i64 1, i64 0, i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64)]] }
@_QQcl.60ea5a38555821a77357f87d16df9a0f = internal constant [62 x i8] c"/g/g92/rydahl1/flangtests/src/duplicate_array_descriptors.f90\00"
@_QQcl.28612C69372C612C6531332E36653229 = internal constant [16 x i8] c"(a,i7,a,e13.6e2)"
@_QQcl.54686520726573756C74206F6620286172722831292B61727228 = internal constant [26 x i8] c"The result of (arr(1)+arr("
@_QQcl.2920697320 = internal constant [5 x i8] c") is "
@_QQEnvironmentDefaults = local_unnamed_addr constant ptr null
@0 = private unnamed_addr constant [23 x i8] c";unknown;unknown;0;0;;\00", align 1
@1 = private unnamed_addr constant %struct.ident_t { i32 0, i32 2, i32 0, i32 22, ptr @0 }, align 8
@2 = private unnamed_addr constant %struct.ident_t { i32 0, i32 66, i32 0, i32 22, ptr @0 }, align 8

; Function Attrs: mustprogress nofree nounwind willreturn allockind("alloc,uninitialized") allocsize(0) memory(inaccessiblemem: readwrite)
declare noalias noundef ptr @malloc(i64 noundef) local_unnamed_addr #0

; Function Attrs: mustprogress nounwind willreturn allockind("free") memory(argmem: readwrite, inaccessiblemem: readwrite)
declare void @free(ptr allocptr nocapture noundef) local_unnamed_addr #1

define void @_QQmain() local_unnamed_addr {
entry:
  %structArg = alloca { ptr, ptr, ptr }, align 8
  %0 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %1 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %2 = alloca i32, align 4
  store i32 1048576, ptr %2, align 4, !tbaa !4
  %3 = call dereferenceable_or_null(8388608) ptr @malloc(i64 8388608)
  store ptr %3, ptr @_QFEarr, align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  store i32 20180515, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  store i8 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  store i8 28, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  store i8 2, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  store i8 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  store i64 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  store i64 1048576, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  %omp_global_thread_num = call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %2, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %1, ptr %gep_5, align 8
  %gep_6 = getelementptr inbounds { ptr, ptr, ptr }, ptr %structArg, i64 0, i32 2
  store ptr %0, ptr %gep_6, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QQmain..omp_par, ptr nonnull %structArg)
  %4 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.60ea5a38555821a77357f87d16df9a0f, i32 21)
  %5 = call i1 @_FortranAioOutputAscii(ptr %4, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %6 = load i32, ptr %2, align 4, !tbaa !4
  %7 = call i1 @_FortranAioOutputInteger32(ptr %4, i32 %6)
  %8 = call i1 @_FortranAioOutputAscii(ptr %4, ptr nonnull @_QQcl.2920697320, i64 5)
  %.unpack = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  %.unpack96.unpack.unpack = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  %9 = sub i64 1, %.unpack96.unpack.unpack
  %10 = getelementptr double, ptr %.unpack, i64 %9
  %11 = load double, ptr %10, align 8, !tbaa !4
  %12 = load i32, ptr %2, align 4, !tbaa !4
  %13 = sext i32 %12 to i64
  %14 = sub i64 %13, %.unpack96.unpack.unpack
  %15 = getelementptr double, ptr %.unpack, i64 %14
  %16 = load double, ptr %15, align 8, !tbaa !4
  %17 = fadd contract double %11, %16
  %18 = call i1 @_FortranAioOutputReal64(ptr %4, double %17)
  %19 = call i32 @_FortranAioEndIoStatement(ptr %4)
  %.unpack101 = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  call void @free(ptr %.unpack101)
  store ptr null, ptr @_QFEarr, align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  store i32 20180515, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  store i8 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  store i8 28, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  store i8 2, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  store i8 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  store i64 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  store i64 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  ret void
}

; Function Attrs: norecurse nounwind
define internal void @_QQmain..omp_par(ptr noalias %tid.addr, ptr noalias %zero.addr, ptr %0) #2 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %gep_3 = getelementptr { ptr, ptr, ptr }, ptr %0, i64 0, i32 2
  %loadgep_4 = load ptr, ptr %gep_3, align 8
  %p.lastiter = alloca i32, align 4
  %p.lowerbound = alloca i32, align 4
  %p.upperbound = alloca i32, align 4
  %p.stride = alloca i32, align 4
  %1 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %omp_loop.tripcount = call i32 @llvm.smax.i32(i32 %1, i32 0)
  store i32 0, ptr %p.lowerbound, align 4
  %2 = add nsw i32 %omp_loop.tripcount, -1
  store i32 %2, ptr %p.upperbound, align 4
  store i32 1, ptr %p.stride, align 4
  %omp_global_thread_num3 = call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  call void @__kmpc_for_static_init_4u(ptr nonnull @1, i32 %omp_global_thread_num3, i32 34, ptr nonnull %p.lastiter, ptr nonnull %p.lowerbound, ptr nonnull %p.upperbound, ptr nonnull %p.stride, i32 1, i32 0)
  %3 = load i32, ptr %p.lowerbound, align 4
  %4 = load i32, ptr %p.upperbound, align 4
  %5 = sub i32 %4, %3
  %6 = add i32 %5, 1
  br label %omp_loop.header

omp_loop.header:                                  ; preds = %omp_loop.body, %omp.par.entry
  %omp_loop.iv = phi i32 [ 0, %omp.par.entry ], [ %omp_loop.next, %omp_loop.body ]
  %omp_loop.cmp = icmp ult i32 %omp_loop.iv, %6
  br i1 %omp_loop.cmp, label %omp_loop.body, label %omp_loop.exit

omp_loop.exit:                                    ; preds = %omp_loop.header
  call void @__kmpc_for_static_fini(ptr nonnull @1, i32 %omp_global_thread_num3)
  %omp_global_thread_num4 = call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  call void @__kmpc_barrier(ptr nonnull @2, i32 %omp_global_thread_num4)
  ret void

omp_loop.body:                                    ; preds = %omp_loop.header
  %7 = add i32 %omp_loop.iv, %3
  %8 = add i32 %7, 1
  %9 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %10 = sitofp i32 %9 to float
  %11 = fdiv contract float 1.000000e+00, %10
  %12 = fpext float %11 to double
  %.unpack = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  %.unpack6 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  %.unpack7 = load i32, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  %.unpack8 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  %.unpack9 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  %.unpack10 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  %.unpack11 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  %.unpack12.unpack.unpack = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  %.unpack12.unpack.unpack14 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  %.unpack12.unpack.unpack15 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  store ptr %.unpack, ptr %loadgep_2, align 8, !tbaa !8
  %loadgep_2.repack17 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  store i64 %.unpack6, ptr %loadgep_2.repack17, align 8, !tbaa !8
  %loadgep_2.repack19 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  store i32 %.unpack7, ptr %loadgep_2.repack19, align 8, !tbaa !8
  %loadgep_2.repack21 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  store i8 %.unpack8, ptr %loadgep_2.repack21, align 4, !tbaa !8
  %loadgep_2.repack23 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  store i8 %.unpack9, ptr %loadgep_2.repack23, align 1, !tbaa !8
  %loadgep_2.repack25 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  store i8 %.unpack10, ptr %loadgep_2.repack25, align 2, !tbaa !8
  %loadgep_2.repack27 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  store i8 %.unpack11, ptr %loadgep_2.repack27, align 1, !tbaa !8
  %loadgep_2.repack29 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  store i64 %.unpack12.unpack.unpack, ptr %loadgep_2.repack29, align 8, !tbaa !8
  %loadgep_2.repack29.repack31 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack12.unpack.unpack14, ptr %loadgep_2.repack29.repack31, align 8, !tbaa !8
  %loadgep_2.repack29.repack33 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  store i64 %.unpack12.unpack.unpack15, ptr %loadgep_2.repack29.repack33, align 8, !tbaa !8
  %13 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 0
  %14 = load i64, ptr %13, align 8, !tbaa !8
  %15 = load ptr, ptr %loadgep_2, align 8, !tbaa !8
  %16 = sext i32 %8 to i64
  %17 = sub i64 %16, %14
  %18 = getelementptr double, ptr %15, i64 %17
  store double %12, ptr %18, align 8, !tbaa !4
  %.unpack35 = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  %.unpack36 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  %.unpack37 = load i32, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  %.unpack38 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  %.unpack39 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  %.unpack40 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  %.unpack41 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  %.unpack42.unpack.unpack = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  %.unpack42.unpack.unpack44 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  %.unpack42.unpack.unpack45 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  store ptr %.unpack35, ptr %loadgep_4, align 8, !tbaa !8
  %loadgep_4.repack47 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 1
  store i64 %.unpack36, ptr %loadgep_4.repack47, align 8, !tbaa !8
  %loadgep_4.repack49 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 2
  store i32 %.unpack37, ptr %loadgep_4.repack49, align 8, !tbaa !8
  %loadgep_4.repack51 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 3
  store i8 %.unpack38, ptr %loadgep_4.repack51, align 4, !tbaa !8
  %loadgep_4.repack53 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 4
  store i8 %.unpack39, ptr %loadgep_4.repack53, align 1, !tbaa !8
  %loadgep_4.repack55 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 5
  store i8 %.unpack40, ptr %loadgep_4.repack55, align 2, !tbaa !8
  %loadgep_4.repack57 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 6
  store i8 %.unpack41, ptr %loadgep_4.repack57, align 1, !tbaa !8
  %loadgep_4.repack59 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7
  store i64 %.unpack42.unpack.unpack, ptr %loadgep_4.repack59, align 8, !tbaa !8
  %loadgep_4.repack59.repack61 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack42.unpack.unpack44, ptr %loadgep_4.repack59.repack61, align 8, !tbaa !8
  %loadgep_4.repack59.repack63 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 2
  store i64 %.unpack42.unpack.unpack45, ptr %loadgep_4.repack59.repack63, align 8, !tbaa !8
  %omp_loop.next = add nuw i32 %omp_loop.iv, 1
  br label %omp_loop.header
}

declare ptr @_FortranAioBeginExternalFormattedOutput(ptr, i64, ptr, i32, ptr, i32) local_unnamed_addr

declare zeroext i1 @_FortranAioOutputAscii(ptr, ptr, i64) local_unnamed_addr

declare zeroext i1 @_FortranAioOutputInteger32(ptr, i32) local_unnamed_addr

declare zeroext i1 @_FortranAioOutputReal64(ptr, double) local_unnamed_addr

declare i32 @_FortranAioEndIoStatement(ptr) local_unnamed_addr

; Function Attrs: nounwind
declare i32 @__kmpc_global_thread_num(ptr) local_unnamed_addr #3

; Function Attrs: nounwind
declare void @__kmpc_for_static_init_4u(ptr, i32, i32, ptr, ptr, ptr, ptr, i32, i32) local_unnamed_addr #3

; Function Attrs: nounwind
declare void @__kmpc_for_static_fini(ptr, i32) local_unnamed_addr #3

; Function Attrs: convergent nounwind
declare void @__kmpc_barrier(ptr, i32) local_unnamed_addr #4

; Function Attrs: nounwind
declare !callback !10 void @__kmpc_fork_call(ptr, i32, ptr, ...) local_unnamed_addr #3

; Function Attrs: nocallback nofree nosync nounwind speculatable willreturn memory(none)
declare i32 @llvm.smax.i32(i32, i32) #5

attributes #0 = { mustprogress nofree nounwind willreturn allockind("alloc,uninitialized") allocsize(0) memory(inaccessiblemem: readwrite) "alloc-family"="malloc" }
attributes #1 = { mustprogress nounwind willreturn allockind("free") memory(argmem: readwrite, inaccessiblemem: readwrite) "alloc-family"="malloc" }
attributes #2 = { norecurse nounwind }
attributes #3 = { nounwind }
attributes #4 = { convergent nounwind }
attributes #5 = { nocallback nofree nosync nounwind speculatable willreturn memory(none) }

!llvm.module.flags = !{!0, !1, !2, !3}

!0 = !{i32 2, !"Debug Info Version", i32 3}
!1 = !{i32 7, !"openmp", i32 11}
!2 = !{i32 8, !"PIC Level", i32 2}
!3 = !{i32 7, !"PIE Level", i32 2}
!4 = !{!5, !5, i64 0}
!5 = !{!"any data access", !6, i64 0}
!6 = !{!"any access", !7, i64 0}
!7 = !{!"Flang Type TBAA Root"}
!8 = !{!9, !9, i64 0}
!9 = !{!"descriptor member", !6, i64 0}
!10 = !{!11}
!11 = !{i64 2, i64 -1, i64 -1, i1 true}
*** IR Dump After InlinerPass on (_QQmain..omp_par) ***
; Function Attrs: norecurse nounwind
define internal void @_QQmain..omp_par(ptr noalias %tid.addr, ptr noalias %zero.addr, ptr %0) #2 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %gep_3 = getelementptr { ptr, ptr, ptr }, ptr %0, i64 0, i32 2
  %loadgep_4 = load ptr, ptr %gep_3, align 8
  %p.lastiter = alloca i32, align 4
  %p.lowerbound = alloca i32, align 4
  %p.upperbound = alloca i32, align 4
  %p.stride = alloca i32, align 4
  %1 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %omp_loop.tripcount = call i32 @llvm.smax.i32(i32 %1, i32 0)
  store i32 0, ptr %p.lowerbound, align 4
  %2 = add nsw i32 %omp_loop.tripcount, -1
  store i32 %2, ptr %p.upperbound, align 4
  store i32 1, ptr %p.stride, align 4
  %omp_global_thread_num3 = call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  call void @__kmpc_for_static_init_4u(ptr nonnull @1, i32 %omp_global_thread_num3, i32 34, ptr nonnull %p.lastiter, ptr nonnull %p.lowerbound, ptr nonnull %p.upperbound, ptr nonnull %p.stride, i32 1, i32 0)
  %3 = load i32, ptr %p.lowerbound, align 4
  %4 = load i32, ptr %p.upperbound, align 4
  %5 = sub i32 %4, %3
  %6 = add i32 %5, 1
  br label %omp_loop.header

omp_loop.header:                                  ; preds = %omp_loop.body, %omp.par.entry
  %omp_loop.iv = phi i32 [ 0, %omp.par.entry ], [ %omp_loop.next, %omp_loop.body ]
  %omp_loop.cmp = icmp ult i32 %omp_loop.iv, %6
  br i1 %omp_loop.cmp, label %omp_loop.body, label %omp_loop.exit

omp_loop.exit:                                    ; preds = %omp_loop.header
  call void @__kmpc_for_static_fini(ptr nonnull @1, i32 %omp_global_thread_num3)
  %omp_global_thread_num4 = call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  call void @__kmpc_barrier(ptr nonnull @2, i32 %omp_global_thread_num4)
  ret void

omp_loop.body:                                    ; preds = %omp_loop.header
  %7 = add i32 %omp_loop.iv, %3
  %8 = add i32 %7, 1
  %9 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %10 = sitofp i32 %9 to float
  %11 = fdiv contract float 1.000000e+00, %10
  %12 = fpext float %11 to double
  %.unpack = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  %.unpack6 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  %.unpack7 = load i32, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  %.unpack8 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  %.unpack9 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  %.unpack10 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  %.unpack11 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  %.unpack12.unpack.unpack = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  %.unpack12.unpack.unpack14 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  %.unpack12.unpack.unpack15 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  store ptr %.unpack, ptr %loadgep_2, align 8, !tbaa !8
  %loadgep_2.repack17 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  store i64 %.unpack6, ptr %loadgep_2.repack17, align 8, !tbaa !8
  %loadgep_2.repack19 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  store i32 %.unpack7, ptr %loadgep_2.repack19, align 8, !tbaa !8
  %loadgep_2.repack21 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  store i8 %.unpack8, ptr %loadgep_2.repack21, align 4, !tbaa !8
  %loadgep_2.repack23 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  store i8 %.unpack9, ptr %loadgep_2.repack23, align 1, !tbaa !8
  %loadgep_2.repack25 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  store i8 %.unpack10, ptr %loadgep_2.repack25, align 2, !tbaa !8
  %loadgep_2.repack27 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  store i8 %.unpack11, ptr %loadgep_2.repack27, align 1, !tbaa !8
  %loadgep_2.repack29 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  store i64 %.unpack12.unpack.unpack, ptr %loadgep_2.repack29, align 8, !tbaa !8
  %loadgep_2.repack29.repack31 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack12.unpack.unpack14, ptr %loadgep_2.repack29.repack31, align 8, !tbaa !8
  %loadgep_2.repack29.repack33 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  store i64 %.unpack12.unpack.unpack15, ptr %loadgep_2.repack29.repack33, align 8, !tbaa !8
  %13 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 0
  %14 = load i64, ptr %13, align 8, !tbaa !8
  %15 = load ptr, ptr %loadgep_2, align 8, !tbaa !8
  %16 = sext i32 %8 to i64
  %17 = sub i64 %16, %14
  %18 = getelementptr double, ptr %15, i64 %17
  store double %12, ptr %18, align 8, !tbaa !4
  %.unpack35 = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  %.unpack36 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  %.unpack37 = load i32, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  %.unpack38 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  %.unpack39 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  %.unpack40 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  %.unpack41 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  %.unpack42.unpack.unpack = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  %.unpack42.unpack.unpack44 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  %.unpack42.unpack.unpack45 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  store ptr %.unpack35, ptr %loadgep_4, align 8, !tbaa !8
  %loadgep_4.repack47 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 1
  store i64 %.unpack36, ptr %loadgep_4.repack47, align 8, !tbaa !8
  %loadgep_4.repack49 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 2
  store i32 %.unpack37, ptr %loadgep_4.repack49, align 8, !tbaa !8
  %loadgep_4.repack51 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 3
  store i8 %.unpack38, ptr %loadgep_4.repack51, align 4, !tbaa !8
  %loadgep_4.repack53 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 4
  store i8 %.unpack39, ptr %loadgep_4.repack53, align 1, !tbaa !8
  %loadgep_4.repack55 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 5
  store i8 %.unpack40, ptr %loadgep_4.repack55, align 2, !tbaa !8
  %loadgep_4.repack57 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 6
  store i8 %.unpack41, ptr %loadgep_4.repack57, align 1, !tbaa !8
  %loadgep_4.repack59 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7
  store i64 %.unpack42.unpack.unpack, ptr %loadgep_4.repack59, align 8, !tbaa !8
  %loadgep_4.repack59.repack61 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack42.unpack.unpack44, ptr %loadgep_4.repack59.repack61, align 8, !tbaa !8
  %loadgep_4.repack59.repack63 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 2
  store i64 %.unpack42.unpack.unpack45, ptr %loadgep_4.repack59.repack63, align 8, !tbaa !8
  %omp_loop.next = add nuw i32 %omp_loop.iv, 1
  br label %omp_loop.header
}
*** IR Dump After InlinerPass on (_QQmain..omp_par) ***
; Function Attrs: norecurse nounwind
define internal void @_QQmain..omp_par(ptr noalias %tid.addr, ptr noalias %zero.addr, ptr %0) #2 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %gep_3 = getelementptr { ptr, ptr, ptr }, ptr %0, i64 0, i32 2
  %loadgep_4 = load ptr, ptr %gep_3, align 8
  %p.lastiter = alloca i32, align 4
  %p.lowerbound = alloca i32, align 4
  %p.upperbound = alloca i32, align 4
  %p.stride = alloca i32, align 4
  %1 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %omp_loop.tripcount = call i32 @llvm.smax.i32(i32 %1, i32 0)
  store i32 0, ptr %p.lowerbound, align 4
  %2 = add nsw i32 %omp_loop.tripcount, -1
  store i32 %2, ptr %p.upperbound, align 4
  store i32 1, ptr %p.stride, align 4
  %omp_global_thread_num3 = call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  call void @__kmpc_for_static_init_4u(ptr nonnull @1, i32 %omp_global_thread_num3, i32 34, ptr nonnull %p.lastiter, ptr nonnull %p.lowerbound, ptr nonnull %p.upperbound, ptr nonnull %p.stride, i32 1, i32 0)
  %3 = load i32, ptr %p.lowerbound, align 4
  %4 = load i32, ptr %p.upperbound, align 4
  %5 = sub i32 %4, %3
  %6 = add i32 %5, 1
  br label %omp_loop.header

omp_loop.header:                                  ; preds = %omp_loop.body, %omp.par.entry
  %omp_loop.iv = phi i32 [ 0, %omp.par.entry ], [ %omp_loop.next, %omp_loop.body ]
  %omp_loop.cmp = icmp ult i32 %omp_loop.iv, %6
  br i1 %omp_loop.cmp, label %omp_loop.body, label %omp_loop.exit

omp_loop.exit:                                    ; preds = %omp_loop.header
  call void @__kmpc_for_static_fini(ptr nonnull @1, i32 %omp_global_thread_num3)
  %omp_global_thread_num4 = call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  call void @__kmpc_barrier(ptr nonnull @2, i32 %omp_global_thread_num4)
  ret void

omp_loop.body:                                    ; preds = %omp_loop.header
  %7 = add i32 %omp_loop.iv, %3
  %8 = add i32 %7, 1
  %9 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %10 = sitofp i32 %9 to float
  %11 = fdiv contract float 1.000000e+00, %10
  %12 = fpext float %11 to double
  %.unpack = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  %.unpack6 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  %.unpack7 = load i32, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  %.unpack8 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  %.unpack9 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  %.unpack10 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  %.unpack11 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  %.unpack12.unpack.unpack = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  %.unpack12.unpack.unpack14 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  %.unpack12.unpack.unpack15 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  store ptr %.unpack, ptr %loadgep_2, align 8, !tbaa !8
  %loadgep_2.repack17 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  store i64 %.unpack6, ptr %loadgep_2.repack17, align 8, !tbaa !8
  %loadgep_2.repack19 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  store i32 %.unpack7, ptr %loadgep_2.repack19, align 8, !tbaa !8
  %loadgep_2.repack21 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  store i8 %.unpack8, ptr %loadgep_2.repack21, align 4, !tbaa !8
  %loadgep_2.repack23 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  store i8 %.unpack9, ptr %loadgep_2.repack23, align 1, !tbaa !8
  %loadgep_2.repack25 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  store i8 %.unpack10, ptr %loadgep_2.repack25, align 2, !tbaa !8
  %loadgep_2.repack27 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  store i8 %.unpack11, ptr %loadgep_2.repack27, align 1, !tbaa !8
  %loadgep_2.repack29 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  store i64 %.unpack12.unpack.unpack, ptr %loadgep_2.repack29, align 8, !tbaa !8
  %loadgep_2.repack29.repack31 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack12.unpack.unpack14, ptr %loadgep_2.repack29.repack31, align 8, !tbaa !8
  %loadgep_2.repack29.repack33 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  store i64 %.unpack12.unpack.unpack15, ptr %loadgep_2.repack29.repack33, align 8, !tbaa !8
  %13 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 0
  %14 = load i64, ptr %13, align 8, !tbaa !8
  %15 = load ptr, ptr %loadgep_2, align 8, !tbaa !8
  %16 = sext i32 %8 to i64
  %17 = sub i64 %16, %14
  %18 = getelementptr double, ptr %15, i64 %17
  store double %12, ptr %18, align 8, !tbaa !4
  %.unpack35 = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  %.unpack36 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  %.unpack37 = load i32, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  %.unpack38 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  %.unpack39 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  %.unpack40 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  %.unpack41 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  %.unpack42.unpack.unpack = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  %.unpack42.unpack.unpack44 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  %.unpack42.unpack.unpack45 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  store ptr %.unpack35, ptr %loadgep_4, align 8, !tbaa !8
  %loadgep_4.repack47 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 1
  store i64 %.unpack36, ptr %loadgep_4.repack47, align 8, !tbaa !8
  %loadgep_4.repack49 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 2
  store i32 %.unpack37, ptr %loadgep_4.repack49, align 8, !tbaa !8
  %loadgep_4.repack51 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 3
  store i8 %.unpack38, ptr %loadgep_4.repack51, align 4, !tbaa !8
  %loadgep_4.repack53 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 4
  store i8 %.unpack39, ptr %loadgep_4.repack53, align 1, !tbaa !8
  %loadgep_4.repack55 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 5
  store i8 %.unpack40, ptr %loadgep_4.repack55, align 2, !tbaa !8
  %loadgep_4.repack57 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 6
  store i8 %.unpack41, ptr %loadgep_4.repack57, align 1, !tbaa !8
  %loadgep_4.repack59 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7
  store i64 %.unpack42.unpack.unpack, ptr %loadgep_4.repack59, align 8, !tbaa !8
  %loadgep_4.repack59.repack61 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack42.unpack.unpack44, ptr %loadgep_4.repack59.repack61, align 8, !tbaa !8
  %loadgep_4.repack59.repack63 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 2
  store i64 %.unpack42.unpack.unpack45, ptr %loadgep_4.repack59.repack63, align 8, !tbaa !8
  %omp_loop.next = add nuw i32 %omp_loop.iv, 1
  br label %omp_loop.header
}
*** IR Dump After PostOrderFunctionAttrsPass on (_QQmain..omp_par) ***
; Function Attrs: norecurse nounwind
define internal void @_QQmain..omp_par(ptr noalias %tid.addr, ptr noalias %zero.addr, ptr %0) #2 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %gep_3 = getelementptr { ptr, ptr, ptr }, ptr %0, i64 0, i32 2
  %loadgep_4 = load ptr, ptr %gep_3, align 8
  %p.lastiter = alloca i32, align 4
  %p.lowerbound = alloca i32, align 4
  %p.upperbound = alloca i32, align 4
  %p.stride = alloca i32, align 4
  %1 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %omp_loop.tripcount = call i32 @llvm.smax.i32(i32 %1, i32 0)
  store i32 0, ptr %p.lowerbound, align 4
  %2 = add nsw i32 %omp_loop.tripcount, -1
  store i32 %2, ptr %p.upperbound, align 4
  store i32 1, ptr %p.stride, align 4
  %omp_global_thread_num3 = call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  call void @__kmpc_for_static_init_4u(ptr nonnull @1, i32 %omp_global_thread_num3, i32 34, ptr nonnull %p.lastiter, ptr nonnull %p.lowerbound, ptr nonnull %p.upperbound, ptr nonnull %p.stride, i32 1, i32 0)
  %3 = load i32, ptr %p.lowerbound, align 4
  %4 = load i32, ptr %p.upperbound, align 4
  %5 = sub i32 %4, %3
  %6 = add i32 %5, 1
  br label %omp_loop.header

omp_loop.header:                                  ; preds = %omp_loop.body, %omp.par.entry
  %omp_loop.iv = phi i32 [ 0, %omp.par.entry ], [ %omp_loop.next, %omp_loop.body ]
  %omp_loop.cmp = icmp ult i32 %omp_loop.iv, %6
  br i1 %omp_loop.cmp, label %omp_loop.body, label %omp_loop.exit

omp_loop.exit:                                    ; preds = %omp_loop.header
  call void @__kmpc_for_static_fini(ptr nonnull @1, i32 %omp_global_thread_num3)
  %omp_global_thread_num4 = call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  call void @__kmpc_barrier(ptr nonnull @2, i32 %omp_global_thread_num4)
  ret void

omp_loop.body:                                    ; preds = %omp_loop.header
  %7 = add i32 %omp_loop.iv, %3
  %8 = add i32 %7, 1
  %9 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %10 = sitofp i32 %9 to float
  %11 = fdiv contract float 1.000000e+00, %10
  %12 = fpext float %11 to double
  %.unpack = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  %.unpack6 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  %.unpack7 = load i32, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  %.unpack8 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  %.unpack9 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  %.unpack10 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  %.unpack11 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  %.unpack12.unpack.unpack = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  %.unpack12.unpack.unpack14 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  %.unpack12.unpack.unpack15 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  store ptr %.unpack, ptr %loadgep_2, align 8, !tbaa !8
  %loadgep_2.repack17 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  store i64 %.unpack6, ptr %loadgep_2.repack17, align 8, !tbaa !8
  %loadgep_2.repack19 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  store i32 %.unpack7, ptr %loadgep_2.repack19, align 8, !tbaa !8
  %loadgep_2.repack21 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  store i8 %.unpack8, ptr %loadgep_2.repack21, align 4, !tbaa !8
  %loadgep_2.repack23 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  store i8 %.unpack9, ptr %loadgep_2.repack23, align 1, !tbaa !8
  %loadgep_2.repack25 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  store i8 %.unpack10, ptr %loadgep_2.repack25, align 2, !tbaa !8
  %loadgep_2.repack27 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  store i8 %.unpack11, ptr %loadgep_2.repack27, align 1, !tbaa !8
  %loadgep_2.repack29 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  store i64 %.unpack12.unpack.unpack, ptr %loadgep_2.repack29, align 8, !tbaa !8
  %loadgep_2.repack29.repack31 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack12.unpack.unpack14, ptr %loadgep_2.repack29.repack31, align 8, !tbaa !8
  %loadgep_2.repack29.repack33 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  store i64 %.unpack12.unpack.unpack15, ptr %loadgep_2.repack29.repack33, align 8, !tbaa !8
  %13 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 0
  %14 = load i64, ptr %13, align 8, !tbaa !8
  %15 = load ptr, ptr %loadgep_2, align 8, !tbaa !8
  %16 = sext i32 %8 to i64
  %17 = sub i64 %16, %14
  %18 = getelementptr double, ptr %15, i64 %17
  store double %12, ptr %18, align 8, !tbaa !4
  %.unpack35 = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  %.unpack36 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  %.unpack37 = load i32, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  %.unpack38 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  %.unpack39 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  %.unpack40 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  %.unpack41 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  %.unpack42.unpack.unpack = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  %.unpack42.unpack.unpack44 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  %.unpack42.unpack.unpack45 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  store ptr %.unpack35, ptr %loadgep_4, align 8, !tbaa !8
  %loadgep_4.repack47 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 1
  store i64 %.unpack36, ptr %loadgep_4.repack47, align 8, !tbaa !8
  %loadgep_4.repack49 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 2
  store i32 %.unpack37, ptr %loadgep_4.repack49, align 8, !tbaa !8
  %loadgep_4.repack51 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 3
  store i8 %.unpack38, ptr %loadgep_4.repack51, align 4, !tbaa !8
  %loadgep_4.repack53 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 4
  store i8 %.unpack39, ptr %loadgep_4.repack53, align 1, !tbaa !8
  %loadgep_4.repack55 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 5
  store i8 %.unpack40, ptr %loadgep_4.repack55, align 2, !tbaa !8
  %loadgep_4.repack57 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 6
  store i8 %.unpack41, ptr %loadgep_4.repack57, align 1, !tbaa !8
  %loadgep_4.repack59 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7
  store i64 %.unpack42.unpack.unpack, ptr %loadgep_4.repack59, align 8, !tbaa !8
  %loadgep_4.repack59.repack61 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack42.unpack.unpack44, ptr %loadgep_4.repack59.repack61, align 8, !tbaa !8
  %loadgep_4.repack59.repack63 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 2
  store i64 %.unpack42.unpack.unpack45, ptr %loadgep_4.repack59.repack63, align 8, !tbaa !8
  %omp_loop.next = add nuw i32 %omp_loop.iv, 1
  br label %omp_loop.header
}
*** IR Dump After ArgumentPromotionPass on (_QQmain..omp_par) ***
; Function Attrs: norecurse nounwind
define internal void @_QQmain..omp_par(ptr noalias %tid.addr, ptr noalias %zero.addr, ptr %0) #2 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %gep_3 = getelementptr { ptr, ptr, ptr }, ptr %0, i64 0, i32 2
  %loadgep_4 = load ptr, ptr %gep_3, align 8
  %p.lastiter = alloca i32, align 4
  %p.lowerbound = alloca i32, align 4
  %p.upperbound = alloca i32, align 4
  %p.stride = alloca i32, align 4
  %1 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %omp_loop.tripcount = call i32 @llvm.smax.i32(i32 %1, i32 0)
  store i32 0, ptr %p.lowerbound, align 4
  %2 = add nsw i32 %omp_loop.tripcount, -1
  store i32 %2, ptr %p.upperbound, align 4
  store i32 1, ptr %p.stride, align 4
  %omp_global_thread_num3 = call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  call void @__kmpc_for_static_init_4u(ptr nonnull @1, i32 %omp_global_thread_num3, i32 34, ptr nonnull %p.lastiter, ptr nonnull %p.lowerbound, ptr nonnull %p.upperbound, ptr nonnull %p.stride, i32 1, i32 0)
  %3 = load i32, ptr %p.lowerbound, align 4
  %4 = load i32, ptr %p.upperbound, align 4
  %5 = sub i32 %4, %3
  %6 = add i32 %5, 1
  br label %omp_loop.header

omp_loop.header:                                  ; preds = %omp_loop.body, %omp.par.entry
  %omp_loop.iv = phi i32 [ 0, %omp.par.entry ], [ %omp_loop.next, %omp_loop.body ]
  %omp_loop.cmp = icmp ult i32 %omp_loop.iv, %6
  br i1 %omp_loop.cmp, label %omp_loop.body, label %omp_loop.exit

omp_loop.exit:                                    ; preds = %omp_loop.header
  call void @__kmpc_for_static_fini(ptr nonnull @1, i32 %omp_global_thread_num3)
  %omp_global_thread_num4 = call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  call void @__kmpc_barrier(ptr nonnull @2, i32 %omp_global_thread_num4)
  ret void

omp_loop.body:                                    ; preds = %omp_loop.header
  %7 = add i32 %omp_loop.iv, %3
  %8 = add i32 %7, 1
  %9 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %10 = sitofp i32 %9 to float
  %11 = fdiv contract float 1.000000e+00, %10
  %12 = fpext float %11 to double
  %.unpack = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  %.unpack6 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  %.unpack7 = load i32, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  %.unpack8 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  %.unpack9 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  %.unpack10 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  %.unpack11 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  %.unpack12.unpack.unpack = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  %.unpack12.unpack.unpack14 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  %.unpack12.unpack.unpack15 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  store ptr %.unpack, ptr %loadgep_2, align 8, !tbaa !8
  %loadgep_2.repack17 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  store i64 %.unpack6, ptr %loadgep_2.repack17, align 8, !tbaa !8
  %loadgep_2.repack19 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  store i32 %.unpack7, ptr %loadgep_2.repack19, align 8, !tbaa !8
  %loadgep_2.repack21 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  store i8 %.unpack8, ptr %loadgep_2.repack21, align 4, !tbaa !8
  %loadgep_2.repack23 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  store i8 %.unpack9, ptr %loadgep_2.repack23, align 1, !tbaa !8
  %loadgep_2.repack25 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  store i8 %.unpack10, ptr %loadgep_2.repack25, align 2, !tbaa !8
  %loadgep_2.repack27 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  store i8 %.unpack11, ptr %loadgep_2.repack27, align 1, !tbaa !8
  %loadgep_2.repack29 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  store i64 %.unpack12.unpack.unpack, ptr %loadgep_2.repack29, align 8, !tbaa !8
  %loadgep_2.repack29.repack31 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack12.unpack.unpack14, ptr %loadgep_2.repack29.repack31, align 8, !tbaa !8
  %loadgep_2.repack29.repack33 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  store i64 %.unpack12.unpack.unpack15, ptr %loadgep_2.repack29.repack33, align 8, !tbaa !8
  %13 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 0
  %14 = load i64, ptr %13, align 8, !tbaa !8
  %15 = load ptr, ptr %loadgep_2, align 8, !tbaa !8
  %16 = sext i32 %8 to i64
  %17 = sub i64 %16, %14
  %18 = getelementptr double, ptr %15, i64 %17
  store double %12, ptr %18, align 8, !tbaa !4
  %.unpack35 = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  %.unpack36 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  %.unpack37 = load i32, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  %.unpack38 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  %.unpack39 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  %.unpack40 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  %.unpack41 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  %.unpack42.unpack.unpack = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  %.unpack42.unpack.unpack44 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  %.unpack42.unpack.unpack45 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  store ptr %.unpack35, ptr %loadgep_4, align 8, !tbaa !8
  %loadgep_4.repack47 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 1
  store i64 %.unpack36, ptr %loadgep_4.repack47, align 8, !tbaa !8
  %loadgep_4.repack49 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 2
  store i32 %.unpack37, ptr %loadgep_4.repack49, align 8, !tbaa !8
  %loadgep_4.repack51 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 3
  store i8 %.unpack38, ptr %loadgep_4.repack51, align 4, !tbaa !8
  %loadgep_4.repack53 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 4
  store i8 %.unpack39, ptr %loadgep_4.repack53, align 1, !tbaa !8
  %loadgep_4.repack55 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 5
  store i8 %.unpack40, ptr %loadgep_4.repack55, align 2, !tbaa !8
  %loadgep_4.repack57 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 6
  store i8 %.unpack41, ptr %loadgep_4.repack57, align 1, !tbaa !8
  %loadgep_4.repack59 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7
  store i64 %.unpack42.unpack.unpack, ptr %loadgep_4.repack59, align 8, !tbaa !8
  %loadgep_4.repack59.repack61 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack42.unpack.unpack44, ptr %loadgep_4.repack59.repack61, align 8, !tbaa !8
  %loadgep_4.repack59.repack63 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 2
  store i64 %.unpack42.unpack.unpack45, ptr %loadgep_4.repack59.repack63, align 8, !tbaa !8
  %omp_loop.next = add nuw i32 %omp_loop.iv, 1
  br label %omp_loop.header
}
*** IR Dump After OpenMPOptCGSCCPass on (_QQmain..omp_par) ***
; Function Attrs: norecurse nounwind
define internal void @_QQmain..omp_par(ptr noalias %tid.addr, ptr noalias %zero.addr, ptr %0) #2 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %gep_3 = getelementptr { ptr, ptr, ptr }, ptr %0, i64 0, i32 2
  %loadgep_4 = load ptr, ptr %gep_3, align 8
  %p.lastiter = alloca i32, align 4
  %p.lowerbound = alloca i32, align 4
  %p.upperbound = alloca i32, align 4
  %p.stride = alloca i32, align 4
  %1 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %omp_loop.tripcount = call i32 @llvm.smax.i32(i32 %1, i32 0)
  store i32 0, ptr %p.lowerbound, align 4
  %2 = add nsw i32 %omp_loop.tripcount, -1
  store i32 %2, ptr %p.upperbound, align 4
  store i32 1, ptr %p.stride, align 4
  %omp_global_thread_num4 = call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  call void @__kmpc_for_static_init_4u(ptr nonnull @1, i32 %omp_global_thread_num4, i32 34, ptr nonnull %p.lastiter, ptr nonnull %p.lowerbound, ptr nonnull %p.upperbound, ptr nonnull %p.stride, i32 1, i32 0)
  %3 = load i32, ptr %p.lowerbound, align 4
  %4 = load i32, ptr %p.upperbound, align 4
  %5 = sub i32 %4, %3
  %6 = add i32 %5, 1
  br label %omp_loop.header

omp_loop.header:                                  ; preds = %omp_loop.body, %omp.par.entry
  %omp_loop.iv = phi i32 [ 0, %omp.par.entry ], [ %omp_loop.next, %omp_loop.body ]
  %omp_loop.cmp = icmp ult i32 %omp_loop.iv, %6
  br i1 %omp_loop.cmp, label %omp_loop.body, label %omp_loop.exit

omp_loop.exit:                                    ; preds = %omp_loop.header
  call void @__kmpc_for_static_fini(ptr nonnull @1, i32 %omp_global_thread_num4)
  call void @__kmpc_barrier(ptr nonnull @2, i32 %omp_global_thread_num4)
  ret void

omp_loop.body:                                    ; preds = %omp_loop.header
  %7 = add i32 %omp_loop.iv, %3
  %8 = add i32 %7, 1
  %9 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %10 = sitofp i32 %9 to float
  %11 = fdiv contract float 1.000000e+00, %10
  %12 = fpext float %11 to double
  %.unpack = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  %.unpack6 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  %.unpack7 = load i32, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  %.unpack8 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  %.unpack9 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  %.unpack10 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  %.unpack11 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  %.unpack12.unpack.unpack = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  %.unpack12.unpack.unpack14 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  %.unpack12.unpack.unpack15 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  store ptr %.unpack, ptr %loadgep_2, align 8, !tbaa !8
  %loadgep_2.repack17 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  store i64 %.unpack6, ptr %loadgep_2.repack17, align 8, !tbaa !8
  %loadgep_2.repack19 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  store i32 %.unpack7, ptr %loadgep_2.repack19, align 8, !tbaa !8
  %loadgep_2.repack21 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  store i8 %.unpack8, ptr %loadgep_2.repack21, align 4, !tbaa !8
  %loadgep_2.repack23 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  store i8 %.unpack9, ptr %loadgep_2.repack23, align 1, !tbaa !8
  %loadgep_2.repack25 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  store i8 %.unpack10, ptr %loadgep_2.repack25, align 2, !tbaa !8
  %loadgep_2.repack27 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  store i8 %.unpack11, ptr %loadgep_2.repack27, align 1, !tbaa !8
  %loadgep_2.repack29 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  store i64 %.unpack12.unpack.unpack, ptr %loadgep_2.repack29, align 8, !tbaa !8
  %loadgep_2.repack29.repack31 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack12.unpack.unpack14, ptr %loadgep_2.repack29.repack31, align 8, !tbaa !8
  %loadgep_2.repack29.repack33 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  store i64 %.unpack12.unpack.unpack15, ptr %loadgep_2.repack29.repack33, align 8, !tbaa !8
  %13 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 0
  %14 = load i64, ptr %13, align 8, !tbaa !8
  %15 = load ptr, ptr %loadgep_2, align 8, !tbaa !8
  %16 = sext i32 %8 to i64
  %17 = sub i64 %16, %14
  %18 = getelementptr double, ptr %15, i64 %17
  store double %12, ptr %18, align 8, !tbaa !4
  %.unpack35 = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  %.unpack36 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  %.unpack37 = load i32, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  %.unpack38 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  %.unpack39 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  %.unpack40 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  %.unpack41 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  %.unpack42.unpack.unpack = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  %.unpack42.unpack.unpack44 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  %.unpack42.unpack.unpack45 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  store ptr %.unpack35, ptr %loadgep_4, align 8, !tbaa !8
  %loadgep_4.repack47 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 1
  store i64 %.unpack36, ptr %loadgep_4.repack47, align 8, !tbaa !8
  %loadgep_4.repack49 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 2
  store i32 %.unpack37, ptr %loadgep_4.repack49, align 8, !tbaa !8
  %loadgep_4.repack51 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 3
  store i8 %.unpack38, ptr %loadgep_4.repack51, align 4, !tbaa !8
  %loadgep_4.repack53 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 4
  store i8 %.unpack39, ptr %loadgep_4.repack53, align 1, !tbaa !8
  %loadgep_4.repack55 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 5
  store i8 %.unpack40, ptr %loadgep_4.repack55, align 2, !tbaa !8
  %loadgep_4.repack57 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 6
  store i8 %.unpack41, ptr %loadgep_4.repack57, align 1, !tbaa !8
  %loadgep_4.repack59 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7
  store i64 %.unpack42.unpack.unpack, ptr %loadgep_4.repack59, align 8, !tbaa !8
  %loadgep_4.repack59.repack61 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack42.unpack.unpack44, ptr %loadgep_4.repack59.repack61, align 8, !tbaa !8
  %loadgep_4.repack59.repack63 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 2
  store i64 %.unpack42.unpack.unpack45, ptr %loadgep_4.repack59.repack63, align 8, !tbaa !8
  %omp_loop.next = add nuw i32 %omp_loop.iv, 1
  br label %omp_loop.header
}
*** IR Dump After SROAPass on _QQmain..omp_par ***
; Function Attrs: norecurse nounwind
define internal void @_QQmain..omp_par(ptr noalias %tid.addr, ptr noalias %zero.addr, ptr %0) #2 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %gep_3 = getelementptr { ptr, ptr, ptr }, ptr %0, i64 0, i32 2
  %loadgep_4 = load ptr, ptr %gep_3, align 8
  %p.lastiter = alloca i32, align 4
  %p.lowerbound = alloca i32, align 4
  %p.upperbound = alloca i32, align 4
  %p.stride = alloca i32, align 4
  %1 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %omp_loop.tripcount = call i32 @llvm.smax.i32(i32 %1, i32 0)
  store i32 0, ptr %p.lowerbound, align 4
  %2 = add nsw i32 %omp_loop.tripcount, -1
  store i32 %2, ptr %p.upperbound, align 4
  store i32 1, ptr %p.stride, align 4
  %omp_global_thread_num4 = call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  call void @__kmpc_for_static_init_4u(ptr nonnull @1, i32 %omp_global_thread_num4, i32 34, ptr nonnull %p.lastiter, ptr nonnull %p.lowerbound, ptr nonnull %p.upperbound, ptr nonnull %p.stride, i32 1, i32 0)
  %3 = load i32, ptr %p.lowerbound, align 4
  %4 = load i32, ptr %p.upperbound, align 4
  %5 = sub i32 %4, %3
  %6 = add i32 %5, 1
  br label %omp_loop.header

omp_loop.header:                                  ; preds = %omp_loop.body, %omp.par.entry
  %omp_loop.iv = phi i32 [ 0, %omp.par.entry ], [ %omp_loop.next, %omp_loop.body ]
  %omp_loop.cmp = icmp ult i32 %omp_loop.iv, %6
  br i1 %omp_loop.cmp, label %omp_loop.body, label %omp_loop.exit

omp_loop.exit:                                    ; preds = %omp_loop.header
  call void @__kmpc_for_static_fini(ptr nonnull @1, i32 %omp_global_thread_num4)
  call void @__kmpc_barrier(ptr nonnull @2, i32 %omp_global_thread_num4)
  ret void

omp_loop.body:                                    ; preds = %omp_loop.header
  %7 = add i32 %omp_loop.iv, %3
  %8 = add i32 %7, 1
  %9 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %10 = sitofp i32 %9 to float
  %11 = fdiv contract float 1.000000e+00, %10
  %12 = fpext float %11 to double
  %.unpack = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  %.unpack6 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  %.unpack7 = load i32, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  %.unpack8 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  %.unpack9 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  %.unpack10 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  %.unpack11 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  %.unpack12.unpack.unpack = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  %.unpack12.unpack.unpack14 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  %.unpack12.unpack.unpack15 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  store ptr %.unpack, ptr %loadgep_2, align 8, !tbaa !8
  %loadgep_2.repack17 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  store i64 %.unpack6, ptr %loadgep_2.repack17, align 8, !tbaa !8
  %loadgep_2.repack19 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  store i32 %.unpack7, ptr %loadgep_2.repack19, align 8, !tbaa !8
  %loadgep_2.repack21 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  store i8 %.unpack8, ptr %loadgep_2.repack21, align 4, !tbaa !8
  %loadgep_2.repack23 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  store i8 %.unpack9, ptr %loadgep_2.repack23, align 1, !tbaa !8
  %loadgep_2.repack25 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  store i8 %.unpack10, ptr %loadgep_2.repack25, align 2, !tbaa !8
  %loadgep_2.repack27 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  store i8 %.unpack11, ptr %loadgep_2.repack27, align 1, !tbaa !8
  %loadgep_2.repack29 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  store i64 %.unpack12.unpack.unpack, ptr %loadgep_2.repack29, align 8, !tbaa !8
  %loadgep_2.repack29.repack31 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack12.unpack.unpack14, ptr %loadgep_2.repack29.repack31, align 8, !tbaa !8
  %loadgep_2.repack29.repack33 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  store i64 %.unpack12.unpack.unpack15, ptr %loadgep_2.repack29.repack33, align 8, !tbaa !8
  %13 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 0
  %14 = load i64, ptr %13, align 8, !tbaa !8
  %15 = load ptr, ptr %loadgep_2, align 8, !tbaa !8
  %16 = sext i32 %8 to i64
  %17 = sub i64 %16, %14
  %18 = getelementptr double, ptr %15, i64 %17
  store double %12, ptr %18, align 8, !tbaa !4
  %.unpack35 = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  %.unpack36 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  %.unpack37 = load i32, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  %.unpack38 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  %.unpack39 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  %.unpack40 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  %.unpack41 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  %.unpack42.unpack.unpack = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  %.unpack42.unpack.unpack44 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  %.unpack42.unpack.unpack45 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  store ptr %.unpack35, ptr %loadgep_4, align 8, !tbaa !8
  %loadgep_4.repack47 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 1
  store i64 %.unpack36, ptr %loadgep_4.repack47, align 8, !tbaa !8
  %loadgep_4.repack49 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 2
  store i32 %.unpack37, ptr %loadgep_4.repack49, align 8, !tbaa !8
  %loadgep_4.repack51 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 3
  store i8 %.unpack38, ptr %loadgep_4.repack51, align 4, !tbaa !8
  %loadgep_4.repack53 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 4
  store i8 %.unpack39, ptr %loadgep_4.repack53, align 1, !tbaa !8
  %loadgep_4.repack55 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 5
  store i8 %.unpack40, ptr %loadgep_4.repack55, align 2, !tbaa !8
  %loadgep_4.repack57 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 6
  store i8 %.unpack41, ptr %loadgep_4.repack57, align 1, !tbaa !8
  %loadgep_4.repack59 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7
  store i64 %.unpack42.unpack.unpack, ptr %loadgep_4.repack59, align 8, !tbaa !8
  %loadgep_4.repack59.repack61 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack42.unpack.unpack44, ptr %loadgep_4.repack59.repack61, align 8, !tbaa !8
  %loadgep_4.repack59.repack63 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 2
  store i64 %.unpack42.unpack.unpack45, ptr %loadgep_4.repack59.repack63, align 8, !tbaa !8
  %omp_loop.next = add nuw i32 %omp_loop.iv, 1
  br label %omp_loop.header
}
*** IR Dump After EarlyCSEPass on _QQmain..omp_par ***
; Function Attrs: norecurse nounwind
define internal void @_QQmain..omp_par(ptr noalias %tid.addr, ptr noalias %zero.addr, ptr %0) #2 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %gep_3 = getelementptr { ptr, ptr, ptr }, ptr %0, i64 0, i32 2
  %loadgep_4 = load ptr, ptr %gep_3, align 8
  %p.lastiter = alloca i32, align 4
  %p.lowerbound = alloca i32, align 4
  %p.upperbound = alloca i32, align 4
  %p.stride = alloca i32, align 4
  %1 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %omp_loop.tripcount = call i32 @llvm.smax.i32(i32 %1, i32 0)
  store i32 0, ptr %p.lowerbound, align 4
  %2 = add nsw i32 %omp_loop.tripcount, -1
  store i32 %2, ptr %p.upperbound, align 4
  store i32 1, ptr %p.stride, align 4
  %omp_global_thread_num4 = call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  call void @__kmpc_for_static_init_4u(ptr nonnull @1, i32 %omp_global_thread_num4, i32 34, ptr nonnull %p.lastiter, ptr nonnull %p.lowerbound, ptr nonnull %p.upperbound, ptr nonnull %p.stride, i32 1, i32 0)
  %3 = load i32, ptr %p.lowerbound, align 4
  %4 = load i32, ptr %p.upperbound, align 4
  %5 = sub i32 %4, %3
  %6 = add i32 %5, 1
  br label %omp_loop.header

omp_loop.header:                                  ; preds = %omp_loop.body, %omp.par.entry
  %omp_loop.iv = phi i32 [ 0, %omp.par.entry ], [ %omp_loop.next, %omp_loop.body ]
  %omp_loop.cmp = icmp ult i32 %omp_loop.iv, %6
  br i1 %omp_loop.cmp, label %omp_loop.body, label %omp_loop.exit

omp_loop.exit:                                    ; preds = %omp_loop.header
  call void @__kmpc_for_static_fini(ptr nonnull @1, i32 %omp_global_thread_num4)
  call void @__kmpc_barrier(ptr nonnull @2, i32 %omp_global_thread_num4)
  ret void

omp_loop.body:                                    ; preds = %omp_loop.header
  %7 = add i32 %omp_loop.iv, %3
  %8 = add i32 %7, 1
  %9 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %10 = sitofp i32 %9 to float
  %11 = fdiv contract float 1.000000e+00, %10
  %12 = fpext float %11 to double
  %.unpack = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  %.unpack6 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  %.unpack7 = load i32, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  %.unpack8 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  %.unpack9 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  %.unpack10 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  %.unpack11 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  %.unpack12.unpack.unpack = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  %.unpack12.unpack.unpack14 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  %.unpack12.unpack.unpack15 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  store ptr %.unpack, ptr %loadgep_2, align 8, !tbaa !8
  %loadgep_2.repack17 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  store i64 %.unpack6, ptr %loadgep_2.repack17, align 8, !tbaa !8
  %loadgep_2.repack19 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  store i32 %.unpack7, ptr %loadgep_2.repack19, align 8, !tbaa !8
  %loadgep_2.repack21 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  store i8 %.unpack8, ptr %loadgep_2.repack21, align 4, !tbaa !8
  %loadgep_2.repack23 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  store i8 %.unpack9, ptr %loadgep_2.repack23, align 1, !tbaa !8
  %loadgep_2.repack25 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  store i8 %.unpack10, ptr %loadgep_2.repack25, align 2, !tbaa !8
  %loadgep_2.repack27 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  store i8 %.unpack11, ptr %loadgep_2.repack27, align 1, !tbaa !8
  %loadgep_2.repack29 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  store i64 %.unpack12.unpack.unpack, ptr %loadgep_2.repack29, align 8, !tbaa !8
  %loadgep_2.repack29.repack31 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack12.unpack.unpack14, ptr %loadgep_2.repack29.repack31, align 8, !tbaa !8
  %loadgep_2.repack29.repack33 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  store i64 %.unpack12.unpack.unpack15, ptr %loadgep_2.repack29.repack33, align 8, !tbaa !8
  %13 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 0
  %14 = load i64, ptr %13, align 8, !tbaa !8
  %15 = sext i32 %8 to i64
  %16 = sub i64 %15, %14
  %17 = getelementptr double, ptr %.unpack, i64 %16
  store double %12, ptr %17, align 8, !tbaa !4
  store ptr %.unpack, ptr %loadgep_4, align 8, !tbaa !8
  %loadgep_4.repack47 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 1
  store i64 %.unpack6, ptr %loadgep_4.repack47, align 8, !tbaa !8
  %loadgep_4.repack49 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 2
  store i32 %.unpack7, ptr %loadgep_4.repack49, align 8, !tbaa !8
  %loadgep_4.repack51 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 3
  store i8 %.unpack8, ptr %loadgep_4.repack51, align 4, !tbaa !8
  %loadgep_4.repack53 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 4
  store i8 %.unpack9, ptr %loadgep_4.repack53, align 1, !tbaa !8
  %loadgep_4.repack55 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 5
  store i8 %.unpack10, ptr %loadgep_4.repack55, align 2, !tbaa !8
  %loadgep_4.repack57 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 6
  store i8 %.unpack11, ptr %loadgep_4.repack57, align 1, !tbaa !8
  %loadgep_4.repack59 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7
  store i64 %.unpack12.unpack.unpack, ptr %loadgep_4.repack59, align 8, !tbaa !8
  %loadgep_4.repack59.repack61 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack12.unpack.unpack14, ptr %loadgep_4.repack59.repack61, align 8, !tbaa !8
  %loadgep_4.repack59.repack63 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 2
  store i64 %.unpack12.unpack.unpack15, ptr %loadgep_4.repack59.repack63, align 8, !tbaa !8
  %omp_loop.next = add nuw i32 %omp_loop.iv, 1
  br label %omp_loop.header
}
*** IR Dump After SpeculativeExecutionPass on _QQmain..omp_par ***
; Function Attrs: norecurse nounwind
define internal void @_QQmain..omp_par(ptr noalias %tid.addr, ptr noalias %zero.addr, ptr %0) #2 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %gep_3 = getelementptr { ptr, ptr, ptr }, ptr %0, i64 0, i32 2
  %loadgep_4 = load ptr, ptr %gep_3, align 8
  %p.lastiter = alloca i32, align 4
  %p.lowerbound = alloca i32, align 4
  %p.upperbound = alloca i32, align 4
  %p.stride = alloca i32, align 4
  %1 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %omp_loop.tripcount = call i32 @llvm.smax.i32(i32 %1, i32 0)
  store i32 0, ptr %p.lowerbound, align 4
  %2 = add nsw i32 %omp_loop.tripcount, -1
  store i32 %2, ptr %p.upperbound, align 4
  store i32 1, ptr %p.stride, align 4
  %omp_global_thread_num4 = call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  call void @__kmpc_for_static_init_4u(ptr nonnull @1, i32 %omp_global_thread_num4, i32 34, ptr nonnull %p.lastiter, ptr nonnull %p.lowerbound, ptr nonnull %p.upperbound, ptr nonnull %p.stride, i32 1, i32 0)
  %3 = load i32, ptr %p.lowerbound, align 4
  %4 = load i32, ptr %p.upperbound, align 4
  %5 = sub i32 %4, %3
  %6 = add i32 %5, 1
  br label %omp_loop.header

omp_loop.header:                                  ; preds = %omp_loop.body, %omp.par.entry
  %omp_loop.iv = phi i32 [ 0, %omp.par.entry ], [ %omp_loop.next, %omp_loop.body ]
  %omp_loop.cmp = icmp ult i32 %omp_loop.iv, %6
  br i1 %omp_loop.cmp, label %omp_loop.body, label %omp_loop.exit

omp_loop.exit:                                    ; preds = %omp_loop.header
  call void @__kmpc_for_static_fini(ptr nonnull @1, i32 %omp_global_thread_num4)
  call void @__kmpc_barrier(ptr nonnull @2, i32 %omp_global_thread_num4)
  ret void

omp_loop.body:                                    ; preds = %omp_loop.header
  %7 = add i32 %omp_loop.iv, %3
  %8 = add i32 %7, 1
  %9 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %10 = sitofp i32 %9 to float
  %11 = fdiv contract float 1.000000e+00, %10
  %12 = fpext float %11 to double
  %.unpack = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  %.unpack6 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  %.unpack7 = load i32, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  %.unpack8 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  %.unpack9 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  %.unpack10 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  %.unpack11 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  %.unpack12.unpack.unpack = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  %.unpack12.unpack.unpack14 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  %.unpack12.unpack.unpack15 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  store ptr %.unpack, ptr %loadgep_2, align 8, !tbaa !8
  %loadgep_2.repack17 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  store i64 %.unpack6, ptr %loadgep_2.repack17, align 8, !tbaa !8
  %loadgep_2.repack19 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  store i32 %.unpack7, ptr %loadgep_2.repack19, align 8, !tbaa !8
  %loadgep_2.repack21 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  store i8 %.unpack8, ptr %loadgep_2.repack21, align 4, !tbaa !8
  %loadgep_2.repack23 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  store i8 %.unpack9, ptr %loadgep_2.repack23, align 1, !tbaa !8
  %loadgep_2.repack25 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  store i8 %.unpack10, ptr %loadgep_2.repack25, align 2, !tbaa !8
  %loadgep_2.repack27 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  store i8 %.unpack11, ptr %loadgep_2.repack27, align 1, !tbaa !8
  %loadgep_2.repack29 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  store i64 %.unpack12.unpack.unpack, ptr %loadgep_2.repack29, align 8, !tbaa !8
  %loadgep_2.repack29.repack31 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack12.unpack.unpack14, ptr %loadgep_2.repack29.repack31, align 8, !tbaa !8
  %loadgep_2.repack29.repack33 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  store i64 %.unpack12.unpack.unpack15, ptr %loadgep_2.repack29.repack33, align 8, !tbaa !8
  %13 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 0
  %14 = load i64, ptr %13, align 8, !tbaa !8
  %15 = sext i32 %8 to i64
  %16 = sub i64 %15, %14
  %17 = getelementptr double, ptr %.unpack, i64 %16
  store double %12, ptr %17, align 8, !tbaa !4
  store ptr %.unpack, ptr %loadgep_4, align 8, !tbaa !8
  %loadgep_4.repack47 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 1
  store i64 %.unpack6, ptr %loadgep_4.repack47, align 8, !tbaa !8
  %loadgep_4.repack49 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 2
  store i32 %.unpack7, ptr %loadgep_4.repack49, align 8, !tbaa !8
  %loadgep_4.repack51 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 3
  store i8 %.unpack8, ptr %loadgep_4.repack51, align 4, !tbaa !8
  %loadgep_4.repack53 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 4
  store i8 %.unpack9, ptr %loadgep_4.repack53, align 1, !tbaa !8
  %loadgep_4.repack55 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 5
  store i8 %.unpack10, ptr %loadgep_4.repack55, align 2, !tbaa !8
  %loadgep_4.repack57 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 6
  store i8 %.unpack11, ptr %loadgep_4.repack57, align 1, !tbaa !8
  %loadgep_4.repack59 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7
  store i64 %.unpack12.unpack.unpack, ptr %loadgep_4.repack59, align 8, !tbaa !8
  %loadgep_4.repack59.repack61 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack12.unpack.unpack14, ptr %loadgep_4.repack59.repack61, align 8, !tbaa !8
  %loadgep_4.repack59.repack63 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 2
  store i64 %.unpack12.unpack.unpack15, ptr %loadgep_4.repack59.repack63, align 8, !tbaa !8
  %omp_loop.next = add nuw i32 %omp_loop.iv, 1
  br label %omp_loop.header
}
*** IR Dump After JumpThreadingPass on _QQmain..omp_par ***
; Function Attrs: norecurse nounwind
define internal void @_QQmain..omp_par(ptr noalias %tid.addr, ptr noalias %zero.addr, ptr %0) #2 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %gep_3 = getelementptr { ptr, ptr, ptr }, ptr %0, i64 0, i32 2
  %loadgep_4 = load ptr, ptr %gep_3, align 8
  %p.lastiter = alloca i32, align 4
  %p.lowerbound = alloca i32, align 4
  %p.upperbound = alloca i32, align 4
  %p.stride = alloca i32, align 4
  %1 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %omp_loop.tripcount = call i32 @llvm.smax.i32(i32 %1, i32 0)
  store i32 0, ptr %p.lowerbound, align 4
  %2 = add nsw i32 %omp_loop.tripcount, -1
  store i32 %2, ptr %p.upperbound, align 4
  store i32 1, ptr %p.stride, align 4
  %omp_global_thread_num4 = call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  call void @__kmpc_for_static_init_4u(ptr nonnull @1, i32 %omp_global_thread_num4, i32 34, ptr nonnull %p.lastiter, ptr nonnull %p.lowerbound, ptr nonnull %p.upperbound, ptr nonnull %p.stride, i32 1, i32 0)
  %3 = load i32, ptr %p.lowerbound, align 4
  %4 = load i32, ptr %p.upperbound, align 4
  %5 = sub i32 %4, %3
  %6 = add i32 %5, 1
  br label %omp_loop.header

omp_loop.header:                                  ; preds = %omp_loop.body, %omp.par.entry
  %omp_loop.iv = phi i32 [ 0, %omp.par.entry ], [ %omp_loop.next, %omp_loop.body ]
  %omp_loop.cmp = icmp ult i32 %omp_loop.iv, %6
  br i1 %omp_loop.cmp, label %omp_loop.body, label %omp_loop.exit

omp_loop.exit:                                    ; preds = %omp_loop.header
  call void @__kmpc_for_static_fini(ptr nonnull @1, i32 %omp_global_thread_num4)
  call void @__kmpc_barrier(ptr nonnull @2, i32 %omp_global_thread_num4)
  ret void

omp_loop.body:                                    ; preds = %omp_loop.header
  %7 = add i32 %omp_loop.iv, %3
  %8 = add i32 %7, 1
  %9 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %10 = sitofp i32 %9 to float
  %11 = fdiv contract float 1.000000e+00, %10
  %12 = fpext float %11 to double
  %.unpack = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  %.unpack6 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  %.unpack7 = load i32, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  %.unpack8 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  %.unpack9 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  %.unpack10 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  %.unpack11 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  %.unpack12.unpack.unpack = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  %.unpack12.unpack.unpack14 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  %.unpack12.unpack.unpack15 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  store ptr %.unpack, ptr %loadgep_2, align 8, !tbaa !8
  %loadgep_2.repack17 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  store i64 %.unpack6, ptr %loadgep_2.repack17, align 8, !tbaa !8
  %loadgep_2.repack19 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  store i32 %.unpack7, ptr %loadgep_2.repack19, align 8, !tbaa !8
  %loadgep_2.repack21 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  store i8 %.unpack8, ptr %loadgep_2.repack21, align 4, !tbaa !8
  %loadgep_2.repack23 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  store i8 %.unpack9, ptr %loadgep_2.repack23, align 1, !tbaa !8
  %loadgep_2.repack25 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  store i8 %.unpack10, ptr %loadgep_2.repack25, align 2, !tbaa !8
  %loadgep_2.repack27 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  store i8 %.unpack11, ptr %loadgep_2.repack27, align 1, !tbaa !8
  %loadgep_2.repack29 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  store i64 %.unpack12.unpack.unpack, ptr %loadgep_2.repack29, align 8, !tbaa !8
  %loadgep_2.repack29.repack31 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack12.unpack.unpack14, ptr %loadgep_2.repack29.repack31, align 8, !tbaa !8
  %loadgep_2.repack29.repack33 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  store i64 %.unpack12.unpack.unpack15, ptr %loadgep_2.repack29.repack33, align 8, !tbaa !8
  %13 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 0
  %14 = load i64, ptr %13, align 8, !tbaa !8
  %15 = sext i32 %8 to i64
  %16 = sub i64 %15, %14
  %17 = getelementptr double, ptr %.unpack, i64 %16
  store double %12, ptr %17, align 8, !tbaa !4
  store ptr %.unpack, ptr %loadgep_4, align 8, !tbaa !8
  %loadgep_4.repack47 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 1
  store i64 %.unpack6, ptr %loadgep_4.repack47, align 8, !tbaa !8
  %loadgep_4.repack49 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 2
  store i32 %.unpack7, ptr %loadgep_4.repack49, align 8, !tbaa !8
  %loadgep_4.repack51 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 3
  store i8 %.unpack8, ptr %loadgep_4.repack51, align 4, !tbaa !8
  %loadgep_4.repack53 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 4
  store i8 %.unpack9, ptr %loadgep_4.repack53, align 1, !tbaa !8
  %loadgep_4.repack55 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 5
  store i8 %.unpack10, ptr %loadgep_4.repack55, align 2, !tbaa !8
  %loadgep_4.repack57 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 6
  store i8 %.unpack11, ptr %loadgep_4.repack57, align 1, !tbaa !8
  %loadgep_4.repack59 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7
  store i64 %.unpack12.unpack.unpack, ptr %loadgep_4.repack59, align 8, !tbaa !8
  %loadgep_4.repack59.repack61 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack12.unpack.unpack14, ptr %loadgep_4.repack59.repack61, align 8, !tbaa !8
  %loadgep_4.repack59.repack63 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 2
  store i64 %.unpack12.unpack.unpack15, ptr %loadgep_4.repack59.repack63, align 8, !tbaa !8
  %omp_loop.next = add nuw i32 %omp_loop.iv, 1
  br label %omp_loop.header
}
*** IR Dump After CorrelatedValuePropagationPass on _QQmain..omp_par ***
; Function Attrs: norecurse nounwind
define internal void @_QQmain..omp_par(ptr noalias %tid.addr, ptr noalias %zero.addr, ptr %0) #2 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %gep_3 = getelementptr { ptr, ptr, ptr }, ptr %0, i64 0, i32 2
  %loadgep_4 = load ptr, ptr %gep_3, align 8
  %p.lastiter = alloca i32, align 4
  %p.lowerbound = alloca i32, align 4
  %p.upperbound = alloca i32, align 4
  %p.stride = alloca i32, align 4
  %1 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %omp_loop.tripcount = call i32 @llvm.smax.i32(i32 %1, i32 0)
  store i32 0, ptr %p.lowerbound, align 4
  %2 = add nsw i32 %omp_loop.tripcount, -1
  store i32 %2, ptr %p.upperbound, align 4
  store i32 1, ptr %p.stride, align 4
  %omp_global_thread_num4 = call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  call void @__kmpc_for_static_init_4u(ptr nonnull @1, i32 %omp_global_thread_num4, i32 34, ptr nonnull %p.lastiter, ptr nonnull %p.lowerbound, ptr nonnull %p.upperbound, ptr nonnull %p.stride, i32 1, i32 0)
  %3 = load i32, ptr %p.lowerbound, align 4
  %4 = load i32, ptr %p.upperbound, align 4
  %5 = sub i32 %4, %3
  %6 = add i32 %5, 1
  br label %omp_loop.header

omp_loop.header:                                  ; preds = %omp_loop.body, %omp.par.entry
  %omp_loop.iv = phi i32 [ 0, %omp.par.entry ], [ %omp_loop.next, %omp_loop.body ]
  %omp_loop.cmp = icmp ult i32 %omp_loop.iv, %6
  br i1 %omp_loop.cmp, label %omp_loop.body, label %omp_loop.exit

omp_loop.exit:                                    ; preds = %omp_loop.header
  call void @__kmpc_for_static_fini(ptr nonnull @1, i32 %omp_global_thread_num4)
  call void @__kmpc_barrier(ptr nonnull @2, i32 %omp_global_thread_num4)
  ret void

omp_loop.body:                                    ; preds = %omp_loop.header
  %7 = add i32 %omp_loop.iv, %3
  %8 = add i32 %7, 1
  %9 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %10 = sitofp i32 %9 to float
  %11 = fdiv contract float 1.000000e+00, %10
  %12 = fpext float %11 to double
  %.unpack = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  %.unpack6 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  %.unpack7 = load i32, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  %.unpack8 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  %.unpack9 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  %.unpack10 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  %.unpack11 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  %.unpack12.unpack.unpack = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  %.unpack12.unpack.unpack14 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  %.unpack12.unpack.unpack15 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  store ptr %.unpack, ptr %loadgep_2, align 8, !tbaa !8
  %loadgep_2.repack17 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  store i64 %.unpack6, ptr %loadgep_2.repack17, align 8, !tbaa !8
  %loadgep_2.repack19 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  store i32 %.unpack7, ptr %loadgep_2.repack19, align 8, !tbaa !8
  %loadgep_2.repack21 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  store i8 %.unpack8, ptr %loadgep_2.repack21, align 4, !tbaa !8
  %loadgep_2.repack23 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  store i8 %.unpack9, ptr %loadgep_2.repack23, align 1, !tbaa !8
  %loadgep_2.repack25 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  store i8 %.unpack10, ptr %loadgep_2.repack25, align 2, !tbaa !8
  %loadgep_2.repack27 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  store i8 %.unpack11, ptr %loadgep_2.repack27, align 1, !tbaa !8
  %loadgep_2.repack29 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  store i64 %.unpack12.unpack.unpack, ptr %loadgep_2.repack29, align 8, !tbaa !8
  %loadgep_2.repack29.repack31 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack12.unpack.unpack14, ptr %loadgep_2.repack29.repack31, align 8, !tbaa !8
  %loadgep_2.repack29.repack33 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  store i64 %.unpack12.unpack.unpack15, ptr %loadgep_2.repack29.repack33, align 8, !tbaa !8
  %13 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 0
  %14 = load i64, ptr %13, align 8, !tbaa !8
  %15 = sext i32 %8 to i64
  %16 = sub i64 %15, %14
  %17 = getelementptr double, ptr %.unpack, i64 %16
  store double %12, ptr %17, align 8, !tbaa !4
  store ptr %.unpack, ptr %loadgep_4, align 8, !tbaa !8
  %loadgep_4.repack47 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 1
  store i64 %.unpack6, ptr %loadgep_4.repack47, align 8, !tbaa !8
  %loadgep_4.repack49 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 2
  store i32 %.unpack7, ptr %loadgep_4.repack49, align 8, !tbaa !8
  %loadgep_4.repack51 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 3
  store i8 %.unpack8, ptr %loadgep_4.repack51, align 4, !tbaa !8
  %loadgep_4.repack53 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 4
  store i8 %.unpack9, ptr %loadgep_4.repack53, align 1, !tbaa !8
  %loadgep_4.repack55 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 5
  store i8 %.unpack10, ptr %loadgep_4.repack55, align 2, !tbaa !8
  %loadgep_4.repack57 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 6
  store i8 %.unpack11, ptr %loadgep_4.repack57, align 1, !tbaa !8
  %loadgep_4.repack59 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7
  store i64 %.unpack12.unpack.unpack, ptr %loadgep_4.repack59, align 8, !tbaa !8
  %loadgep_4.repack59.repack61 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack12.unpack.unpack14, ptr %loadgep_4.repack59.repack61, align 8, !tbaa !8
  %loadgep_4.repack59.repack63 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 2
  store i64 %.unpack12.unpack.unpack15, ptr %loadgep_4.repack59.repack63, align 8, !tbaa !8
  %omp_loop.next = add nuw i32 %omp_loop.iv, 1
  br label %omp_loop.header
}
*** IR Dump After SimplifyCFGPass on _QQmain..omp_par ***
; Function Attrs: norecurse nounwind
define internal void @_QQmain..omp_par(ptr noalias %tid.addr, ptr noalias %zero.addr, ptr %0) #2 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %gep_3 = getelementptr { ptr, ptr, ptr }, ptr %0, i64 0, i32 2
  %loadgep_4 = load ptr, ptr %gep_3, align 8
  %p.lastiter = alloca i32, align 4
  %p.lowerbound = alloca i32, align 4
  %p.upperbound = alloca i32, align 4
  %p.stride = alloca i32, align 4
  %1 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %omp_loop.tripcount = call i32 @llvm.smax.i32(i32 %1, i32 0)
  store i32 0, ptr %p.lowerbound, align 4
  %2 = add nsw i32 %omp_loop.tripcount, -1
  store i32 %2, ptr %p.upperbound, align 4
  store i32 1, ptr %p.stride, align 4
  %omp_global_thread_num4 = call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  call void @__kmpc_for_static_init_4u(ptr nonnull @1, i32 %omp_global_thread_num4, i32 34, ptr nonnull %p.lastiter, ptr nonnull %p.lowerbound, ptr nonnull %p.upperbound, ptr nonnull %p.stride, i32 1, i32 0)
  %3 = load i32, ptr %p.lowerbound, align 4
  %4 = load i32, ptr %p.upperbound, align 4
  %5 = sub i32 %4, %3
  %6 = add i32 %5, 1
  br label %omp_loop.header

omp_loop.header:                                  ; preds = %omp_loop.body, %omp.par.entry
  %omp_loop.iv = phi i32 [ 0, %omp.par.entry ], [ %omp_loop.next, %omp_loop.body ]
  %omp_loop.cmp = icmp ult i32 %omp_loop.iv, %6
  br i1 %omp_loop.cmp, label %omp_loop.body, label %omp_loop.exit

omp_loop.exit:                                    ; preds = %omp_loop.header
  call void @__kmpc_for_static_fini(ptr nonnull @1, i32 %omp_global_thread_num4)
  call void @__kmpc_barrier(ptr nonnull @2, i32 %omp_global_thread_num4)
  ret void

omp_loop.body:                                    ; preds = %omp_loop.header
  %7 = add i32 %omp_loop.iv, %3
  %8 = add i32 %7, 1
  %9 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %10 = sitofp i32 %9 to float
  %11 = fdiv contract float 1.000000e+00, %10
  %12 = fpext float %11 to double
  %.unpack = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  %.unpack6 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  %.unpack7 = load i32, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  %.unpack8 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  %.unpack9 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  %.unpack10 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  %.unpack11 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  %.unpack12.unpack.unpack = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  %.unpack12.unpack.unpack14 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  %.unpack12.unpack.unpack15 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  store ptr %.unpack, ptr %loadgep_2, align 8, !tbaa !8
  %loadgep_2.repack17 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  store i64 %.unpack6, ptr %loadgep_2.repack17, align 8, !tbaa !8
  %loadgep_2.repack19 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  store i32 %.unpack7, ptr %loadgep_2.repack19, align 8, !tbaa !8
  %loadgep_2.repack21 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  store i8 %.unpack8, ptr %loadgep_2.repack21, align 4, !tbaa !8
  %loadgep_2.repack23 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  store i8 %.unpack9, ptr %loadgep_2.repack23, align 1, !tbaa !8
  %loadgep_2.repack25 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  store i8 %.unpack10, ptr %loadgep_2.repack25, align 2, !tbaa !8
  %loadgep_2.repack27 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  store i8 %.unpack11, ptr %loadgep_2.repack27, align 1, !tbaa !8
  %loadgep_2.repack29 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  store i64 %.unpack12.unpack.unpack, ptr %loadgep_2.repack29, align 8, !tbaa !8
  %loadgep_2.repack29.repack31 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack12.unpack.unpack14, ptr %loadgep_2.repack29.repack31, align 8, !tbaa !8
  %loadgep_2.repack29.repack33 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  store i64 %.unpack12.unpack.unpack15, ptr %loadgep_2.repack29.repack33, align 8, !tbaa !8
  %13 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 0
  %14 = load i64, ptr %13, align 8, !tbaa !8
  %15 = sext i32 %8 to i64
  %16 = sub i64 %15, %14
  %17 = getelementptr double, ptr %.unpack, i64 %16
  store double %12, ptr %17, align 8, !tbaa !4
  store ptr %.unpack, ptr %loadgep_4, align 8, !tbaa !8
  %loadgep_4.repack47 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 1
  store i64 %.unpack6, ptr %loadgep_4.repack47, align 8, !tbaa !8
  %loadgep_4.repack49 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 2
  store i32 %.unpack7, ptr %loadgep_4.repack49, align 8, !tbaa !8
  %loadgep_4.repack51 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 3
  store i8 %.unpack8, ptr %loadgep_4.repack51, align 4, !tbaa !8
  %loadgep_4.repack53 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 4
  store i8 %.unpack9, ptr %loadgep_4.repack53, align 1, !tbaa !8
  %loadgep_4.repack55 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 5
  store i8 %.unpack10, ptr %loadgep_4.repack55, align 2, !tbaa !8
  %loadgep_4.repack57 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 6
  store i8 %.unpack11, ptr %loadgep_4.repack57, align 1, !tbaa !8
  %loadgep_4.repack59 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7
  store i64 %.unpack12.unpack.unpack, ptr %loadgep_4.repack59, align 8, !tbaa !8
  %loadgep_4.repack59.repack61 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack12.unpack.unpack14, ptr %loadgep_4.repack59.repack61, align 8, !tbaa !8
  %loadgep_4.repack59.repack63 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 2
  store i64 %.unpack12.unpack.unpack15, ptr %loadgep_4.repack59.repack63, align 8, !tbaa !8
  %omp_loop.next = add nuw i32 %omp_loop.iv, 1
  br label %omp_loop.header
}
*** IR Dump After InstCombinePass on _QQmain..omp_par ***
; Function Attrs: norecurse nounwind
define internal void @_QQmain..omp_par(ptr noalias %tid.addr, ptr noalias %zero.addr, ptr %0) #2 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %gep_3 = getelementptr { ptr, ptr, ptr }, ptr %0, i64 0, i32 2
  %loadgep_4 = load ptr, ptr %gep_3, align 8
  %p.lastiter = alloca i32, align 4
  %p.lowerbound = alloca i32, align 4
  %p.upperbound = alloca i32, align 4
  %p.stride = alloca i32, align 4
  %1 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %omp_loop.tripcount = call i32 @llvm.smax.i32(i32 %1, i32 0)
  store i32 0, ptr %p.lowerbound, align 4
  %2 = add nsw i32 %omp_loop.tripcount, -1
  store i32 %2, ptr %p.upperbound, align 4
  store i32 1, ptr %p.stride, align 4
  %omp_global_thread_num4 = call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  call void @__kmpc_for_static_init_4u(ptr nonnull @1, i32 %omp_global_thread_num4, i32 34, ptr nonnull %p.lastiter, ptr nonnull %p.lowerbound, ptr nonnull %p.upperbound, ptr nonnull %p.stride, i32 1, i32 0)
  %3 = load i32, ptr %p.lowerbound, align 4
  %4 = load i32, ptr %p.upperbound, align 4
  %5 = sub i32 %4, %3
  %6 = add i32 %5, 1
  br label %omp_loop.header

omp_loop.header:                                  ; preds = %omp_loop.body, %omp.par.entry
  %omp_loop.iv = phi i32 [ 0, %omp.par.entry ], [ %omp_loop.next, %omp_loop.body ]
  %omp_loop.cmp = icmp ult i32 %omp_loop.iv, %6
  br i1 %omp_loop.cmp, label %omp_loop.body, label %omp_loop.exit

omp_loop.exit:                                    ; preds = %omp_loop.header
  call void @__kmpc_for_static_fini(ptr nonnull @1, i32 %omp_global_thread_num4)
  call void @__kmpc_barrier(ptr nonnull @2, i32 %omp_global_thread_num4)
  ret void

omp_loop.body:                                    ; preds = %omp_loop.header
  %7 = add i32 %omp_loop.iv, %3
  %8 = add i32 %7, 1
  %9 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %10 = sitofp i32 %9 to float
  %11 = fdiv contract float 1.000000e+00, %10
  %12 = fpext float %11 to double
  %.unpack = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  %.unpack6 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  %.unpack7 = load i32, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  %.unpack8 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  %.unpack9 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  %.unpack10 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  %.unpack11 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  %.unpack12.unpack.unpack = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  %.unpack12.unpack.unpack14 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  %.unpack12.unpack.unpack15 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  store ptr %.unpack, ptr %loadgep_2, align 8, !tbaa !8
  %loadgep_2.repack17 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  store i64 %.unpack6, ptr %loadgep_2.repack17, align 8, !tbaa !8
  %loadgep_2.repack19 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  store i32 %.unpack7, ptr %loadgep_2.repack19, align 8, !tbaa !8
  %loadgep_2.repack21 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  store i8 %.unpack8, ptr %loadgep_2.repack21, align 4, !tbaa !8
  %loadgep_2.repack23 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  store i8 %.unpack9, ptr %loadgep_2.repack23, align 1, !tbaa !8
  %loadgep_2.repack25 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  store i8 %.unpack10, ptr %loadgep_2.repack25, align 2, !tbaa !8
  %loadgep_2.repack27 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  store i8 %.unpack11, ptr %loadgep_2.repack27, align 1, !tbaa !8
  %loadgep_2.repack29 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  store i64 %.unpack12.unpack.unpack, ptr %loadgep_2.repack29, align 8, !tbaa !8
  %loadgep_2.repack29.repack31 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack12.unpack.unpack14, ptr %loadgep_2.repack29.repack31, align 8, !tbaa !8
  %loadgep_2.repack29.repack33 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  store i64 %.unpack12.unpack.unpack15, ptr %loadgep_2.repack29.repack33, align 8, !tbaa !8
  %13 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 0
  %14 = load i64, ptr %13, align 8, !tbaa !8
  %15 = sext i32 %8 to i64
  %16 = sub i64 %15, %14
  %17 = getelementptr double, ptr %.unpack, i64 %16
  store double %12, ptr %17, align 8, !tbaa !4
  store ptr %.unpack, ptr %loadgep_4, align 8, !tbaa !8
  %loadgep_4.repack47 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 1
  store i64 %.unpack6, ptr %loadgep_4.repack47, align 8, !tbaa !8
  %loadgep_4.repack49 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 2
  store i32 %.unpack7, ptr %loadgep_4.repack49, align 8, !tbaa !8
  %loadgep_4.repack51 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 3
  store i8 %.unpack8, ptr %loadgep_4.repack51, align 4, !tbaa !8
  %loadgep_4.repack53 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 4
  store i8 %.unpack9, ptr %loadgep_4.repack53, align 1, !tbaa !8
  %loadgep_4.repack55 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 5
  store i8 %.unpack10, ptr %loadgep_4.repack55, align 2, !tbaa !8
  %loadgep_4.repack57 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 6
  store i8 %.unpack11, ptr %loadgep_4.repack57, align 1, !tbaa !8
  %loadgep_4.repack59 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7
  store i64 %.unpack12.unpack.unpack, ptr %loadgep_4.repack59, align 8, !tbaa !8
  %loadgep_4.repack59.repack61 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack12.unpack.unpack14, ptr %loadgep_4.repack59.repack61, align 8, !tbaa !8
  %loadgep_4.repack59.repack63 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 2
  store i64 %.unpack12.unpack.unpack15, ptr %loadgep_4.repack59.repack63, align 8, !tbaa !8
  %omp_loop.next = add nuw i32 %omp_loop.iv, 1
  br label %omp_loop.header
}
*** IR Dump After AggressiveInstCombinePass on _QQmain..omp_par ***
; Function Attrs: norecurse nounwind
define internal void @_QQmain..omp_par(ptr noalias %tid.addr, ptr noalias %zero.addr, ptr %0) #2 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %gep_3 = getelementptr { ptr, ptr, ptr }, ptr %0, i64 0, i32 2
  %loadgep_4 = load ptr, ptr %gep_3, align 8
  %p.lastiter = alloca i32, align 4
  %p.lowerbound = alloca i32, align 4
  %p.upperbound = alloca i32, align 4
  %p.stride = alloca i32, align 4
  %1 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %omp_loop.tripcount = call i32 @llvm.smax.i32(i32 %1, i32 0)
  store i32 0, ptr %p.lowerbound, align 4
  %2 = add nsw i32 %omp_loop.tripcount, -1
  store i32 %2, ptr %p.upperbound, align 4
  store i32 1, ptr %p.stride, align 4
  %omp_global_thread_num4 = call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  call void @__kmpc_for_static_init_4u(ptr nonnull @1, i32 %omp_global_thread_num4, i32 34, ptr nonnull %p.lastiter, ptr nonnull %p.lowerbound, ptr nonnull %p.upperbound, ptr nonnull %p.stride, i32 1, i32 0)
  %3 = load i32, ptr %p.lowerbound, align 4
  %4 = load i32, ptr %p.upperbound, align 4
  %5 = sub i32 %4, %3
  %6 = add i32 %5, 1
  br label %omp_loop.header

omp_loop.header:                                  ; preds = %omp_loop.body, %omp.par.entry
  %omp_loop.iv = phi i32 [ 0, %omp.par.entry ], [ %omp_loop.next, %omp_loop.body ]
  %omp_loop.cmp = icmp ult i32 %omp_loop.iv, %6
  br i1 %omp_loop.cmp, label %omp_loop.body, label %omp_loop.exit

omp_loop.exit:                                    ; preds = %omp_loop.header
  call void @__kmpc_for_static_fini(ptr nonnull @1, i32 %omp_global_thread_num4)
  call void @__kmpc_barrier(ptr nonnull @2, i32 %omp_global_thread_num4)
  ret void

omp_loop.body:                                    ; preds = %omp_loop.header
  %7 = add i32 %omp_loop.iv, %3
  %8 = add i32 %7, 1
  %9 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %10 = sitofp i32 %9 to float
  %11 = fdiv contract float 1.000000e+00, %10
  %12 = fpext float %11 to double
  %.unpack = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  %.unpack6 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  %.unpack7 = load i32, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  %.unpack8 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  %.unpack9 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  %.unpack10 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  %.unpack11 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  %.unpack12.unpack.unpack = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  %.unpack12.unpack.unpack14 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  %.unpack12.unpack.unpack15 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  store ptr %.unpack, ptr %loadgep_2, align 8, !tbaa !8
  %loadgep_2.repack17 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  store i64 %.unpack6, ptr %loadgep_2.repack17, align 8, !tbaa !8
  %loadgep_2.repack19 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  store i32 %.unpack7, ptr %loadgep_2.repack19, align 8, !tbaa !8
  %loadgep_2.repack21 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  store i8 %.unpack8, ptr %loadgep_2.repack21, align 4, !tbaa !8
  %loadgep_2.repack23 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  store i8 %.unpack9, ptr %loadgep_2.repack23, align 1, !tbaa !8
  %loadgep_2.repack25 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  store i8 %.unpack10, ptr %loadgep_2.repack25, align 2, !tbaa !8
  %loadgep_2.repack27 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  store i8 %.unpack11, ptr %loadgep_2.repack27, align 1, !tbaa !8
  %loadgep_2.repack29 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  store i64 %.unpack12.unpack.unpack, ptr %loadgep_2.repack29, align 8, !tbaa !8
  %loadgep_2.repack29.repack31 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack12.unpack.unpack14, ptr %loadgep_2.repack29.repack31, align 8, !tbaa !8
  %loadgep_2.repack29.repack33 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  store i64 %.unpack12.unpack.unpack15, ptr %loadgep_2.repack29.repack33, align 8, !tbaa !8
  %13 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 0
  %14 = load i64, ptr %13, align 8, !tbaa !8
  %15 = sext i32 %8 to i64
  %16 = sub i64 %15, %14
  %17 = getelementptr double, ptr %.unpack, i64 %16
  store double %12, ptr %17, align 8, !tbaa !4
  store ptr %.unpack, ptr %loadgep_4, align 8, !tbaa !8
  %loadgep_4.repack47 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 1
  store i64 %.unpack6, ptr %loadgep_4.repack47, align 8, !tbaa !8
  %loadgep_4.repack49 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 2
  store i32 %.unpack7, ptr %loadgep_4.repack49, align 8, !tbaa !8
  %loadgep_4.repack51 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 3
  store i8 %.unpack8, ptr %loadgep_4.repack51, align 4, !tbaa !8
  %loadgep_4.repack53 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 4
  store i8 %.unpack9, ptr %loadgep_4.repack53, align 1, !tbaa !8
  %loadgep_4.repack55 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 5
  store i8 %.unpack10, ptr %loadgep_4.repack55, align 2, !tbaa !8
  %loadgep_4.repack57 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 6
  store i8 %.unpack11, ptr %loadgep_4.repack57, align 1, !tbaa !8
  %loadgep_4.repack59 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7
  store i64 %.unpack12.unpack.unpack, ptr %loadgep_4.repack59, align 8, !tbaa !8
  %loadgep_4.repack59.repack61 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack12.unpack.unpack14, ptr %loadgep_4.repack59.repack61, align 8, !tbaa !8
  %loadgep_4.repack59.repack63 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 2
  store i64 %.unpack12.unpack.unpack15, ptr %loadgep_4.repack59.repack63, align 8, !tbaa !8
  %omp_loop.next = add nuw i32 %omp_loop.iv, 1
  br label %omp_loop.header
}
*** IR Dump After ConstraintEliminationPass on _QQmain..omp_par ***
; Function Attrs: norecurse nounwind
define internal void @_QQmain..omp_par(ptr noalias %tid.addr, ptr noalias %zero.addr, ptr %0) #2 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %gep_3 = getelementptr { ptr, ptr, ptr }, ptr %0, i64 0, i32 2
  %loadgep_4 = load ptr, ptr %gep_3, align 8
  %p.lastiter = alloca i32, align 4
  %p.lowerbound = alloca i32, align 4
  %p.upperbound = alloca i32, align 4
  %p.stride = alloca i32, align 4
  %1 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %omp_loop.tripcount = call i32 @llvm.smax.i32(i32 %1, i32 0)
  store i32 0, ptr %p.lowerbound, align 4
  %2 = add nsw i32 %omp_loop.tripcount, -1
  store i32 %2, ptr %p.upperbound, align 4
  store i32 1, ptr %p.stride, align 4
  %omp_global_thread_num4 = call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  call void @__kmpc_for_static_init_4u(ptr nonnull @1, i32 %omp_global_thread_num4, i32 34, ptr nonnull %p.lastiter, ptr nonnull %p.lowerbound, ptr nonnull %p.upperbound, ptr nonnull %p.stride, i32 1, i32 0)
  %3 = load i32, ptr %p.lowerbound, align 4
  %4 = load i32, ptr %p.upperbound, align 4
  %5 = sub i32 %4, %3
  %6 = add i32 %5, 1
  br label %omp_loop.header

omp_loop.header:                                  ; preds = %omp_loop.body, %omp.par.entry
  %omp_loop.iv = phi i32 [ 0, %omp.par.entry ], [ %omp_loop.next, %omp_loop.body ]
  %omp_loop.cmp = icmp ult i32 %omp_loop.iv, %6
  br i1 %omp_loop.cmp, label %omp_loop.body, label %omp_loop.exit

omp_loop.exit:                                    ; preds = %omp_loop.header
  call void @__kmpc_for_static_fini(ptr nonnull @1, i32 %omp_global_thread_num4)
  call void @__kmpc_barrier(ptr nonnull @2, i32 %omp_global_thread_num4)
  ret void

omp_loop.body:                                    ; preds = %omp_loop.header
  %7 = add i32 %omp_loop.iv, %3
  %8 = add i32 %7, 1
  %9 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %10 = sitofp i32 %9 to float
  %11 = fdiv contract float 1.000000e+00, %10
  %12 = fpext float %11 to double
  %.unpack = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  %.unpack6 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  %.unpack7 = load i32, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  %.unpack8 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  %.unpack9 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  %.unpack10 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  %.unpack11 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  %.unpack12.unpack.unpack = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  %.unpack12.unpack.unpack14 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  %.unpack12.unpack.unpack15 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  store ptr %.unpack, ptr %loadgep_2, align 8, !tbaa !8
  %loadgep_2.repack17 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  store i64 %.unpack6, ptr %loadgep_2.repack17, align 8, !tbaa !8
  %loadgep_2.repack19 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  store i32 %.unpack7, ptr %loadgep_2.repack19, align 8, !tbaa !8
  %loadgep_2.repack21 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  store i8 %.unpack8, ptr %loadgep_2.repack21, align 4, !tbaa !8
  %loadgep_2.repack23 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  store i8 %.unpack9, ptr %loadgep_2.repack23, align 1, !tbaa !8
  %loadgep_2.repack25 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  store i8 %.unpack10, ptr %loadgep_2.repack25, align 2, !tbaa !8
  %loadgep_2.repack27 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  store i8 %.unpack11, ptr %loadgep_2.repack27, align 1, !tbaa !8
  %loadgep_2.repack29 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  store i64 %.unpack12.unpack.unpack, ptr %loadgep_2.repack29, align 8, !tbaa !8
  %loadgep_2.repack29.repack31 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack12.unpack.unpack14, ptr %loadgep_2.repack29.repack31, align 8, !tbaa !8
  %loadgep_2.repack29.repack33 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  store i64 %.unpack12.unpack.unpack15, ptr %loadgep_2.repack29.repack33, align 8, !tbaa !8
  %13 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 0
  %14 = load i64, ptr %13, align 8, !tbaa !8
  %15 = sext i32 %8 to i64
  %16 = sub i64 %15, %14
  %17 = getelementptr double, ptr %.unpack, i64 %16
  store double %12, ptr %17, align 8, !tbaa !4
  store ptr %.unpack, ptr %loadgep_4, align 8, !tbaa !8
  %loadgep_4.repack47 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 1
  store i64 %.unpack6, ptr %loadgep_4.repack47, align 8, !tbaa !8
  %loadgep_4.repack49 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 2
  store i32 %.unpack7, ptr %loadgep_4.repack49, align 8, !tbaa !8
  %loadgep_4.repack51 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 3
  store i8 %.unpack8, ptr %loadgep_4.repack51, align 4, !tbaa !8
  %loadgep_4.repack53 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 4
  store i8 %.unpack9, ptr %loadgep_4.repack53, align 1, !tbaa !8
  %loadgep_4.repack55 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 5
  store i8 %.unpack10, ptr %loadgep_4.repack55, align 2, !tbaa !8
  %loadgep_4.repack57 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 6
  store i8 %.unpack11, ptr %loadgep_4.repack57, align 1, !tbaa !8
  %loadgep_4.repack59 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7
  store i64 %.unpack12.unpack.unpack, ptr %loadgep_4.repack59, align 8, !tbaa !8
  %loadgep_4.repack59.repack61 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack12.unpack.unpack14, ptr %loadgep_4.repack59.repack61, align 8, !tbaa !8
  %loadgep_4.repack59.repack63 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 2
  store i64 %.unpack12.unpack.unpack15, ptr %loadgep_4.repack59.repack63, align 8, !tbaa !8
  %omp_loop.next = add nuw i32 %omp_loop.iv, 1
  br label %omp_loop.header
}
*** IR Dump After LibCallsShrinkWrapPass on _QQmain..omp_par ***
; Function Attrs: norecurse nounwind
define internal void @_QQmain..omp_par(ptr noalias %tid.addr, ptr noalias %zero.addr, ptr %0) #2 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %gep_3 = getelementptr { ptr, ptr, ptr }, ptr %0, i64 0, i32 2
  %loadgep_4 = load ptr, ptr %gep_3, align 8
  %p.lastiter = alloca i32, align 4
  %p.lowerbound = alloca i32, align 4
  %p.upperbound = alloca i32, align 4
  %p.stride = alloca i32, align 4
  %1 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %omp_loop.tripcount = call i32 @llvm.smax.i32(i32 %1, i32 0)
  store i32 0, ptr %p.lowerbound, align 4
  %2 = add nsw i32 %omp_loop.tripcount, -1
  store i32 %2, ptr %p.upperbound, align 4
  store i32 1, ptr %p.stride, align 4
  %omp_global_thread_num4 = call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  call void @__kmpc_for_static_init_4u(ptr nonnull @1, i32 %omp_global_thread_num4, i32 34, ptr nonnull %p.lastiter, ptr nonnull %p.lowerbound, ptr nonnull %p.upperbound, ptr nonnull %p.stride, i32 1, i32 0)
  %3 = load i32, ptr %p.lowerbound, align 4
  %4 = load i32, ptr %p.upperbound, align 4
  %5 = sub i32 %4, %3
  %6 = add i32 %5, 1
  br label %omp_loop.header

omp_loop.header:                                  ; preds = %omp_loop.body, %omp.par.entry
  %omp_loop.iv = phi i32 [ 0, %omp.par.entry ], [ %omp_loop.next, %omp_loop.body ]
  %omp_loop.cmp = icmp ult i32 %omp_loop.iv, %6
  br i1 %omp_loop.cmp, label %omp_loop.body, label %omp_loop.exit

omp_loop.exit:                                    ; preds = %omp_loop.header
  call void @__kmpc_for_static_fini(ptr nonnull @1, i32 %omp_global_thread_num4)
  call void @__kmpc_barrier(ptr nonnull @2, i32 %omp_global_thread_num4)
  ret void

omp_loop.body:                                    ; preds = %omp_loop.header
  %7 = add i32 %omp_loop.iv, %3
  %8 = add i32 %7, 1
  %9 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %10 = sitofp i32 %9 to float
  %11 = fdiv contract float 1.000000e+00, %10
  %12 = fpext float %11 to double
  %.unpack = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  %.unpack6 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  %.unpack7 = load i32, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  %.unpack8 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  %.unpack9 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  %.unpack10 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  %.unpack11 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  %.unpack12.unpack.unpack = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  %.unpack12.unpack.unpack14 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  %.unpack12.unpack.unpack15 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  store ptr %.unpack, ptr %loadgep_2, align 8, !tbaa !8
  %loadgep_2.repack17 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  store i64 %.unpack6, ptr %loadgep_2.repack17, align 8, !tbaa !8
  %loadgep_2.repack19 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  store i32 %.unpack7, ptr %loadgep_2.repack19, align 8, !tbaa !8
  %loadgep_2.repack21 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  store i8 %.unpack8, ptr %loadgep_2.repack21, align 4, !tbaa !8
  %loadgep_2.repack23 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  store i8 %.unpack9, ptr %loadgep_2.repack23, align 1, !tbaa !8
  %loadgep_2.repack25 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  store i8 %.unpack10, ptr %loadgep_2.repack25, align 2, !tbaa !8
  %loadgep_2.repack27 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  store i8 %.unpack11, ptr %loadgep_2.repack27, align 1, !tbaa !8
  %loadgep_2.repack29 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  store i64 %.unpack12.unpack.unpack, ptr %loadgep_2.repack29, align 8, !tbaa !8
  %loadgep_2.repack29.repack31 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack12.unpack.unpack14, ptr %loadgep_2.repack29.repack31, align 8, !tbaa !8
  %loadgep_2.repack29.repack33 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  store i64 %.unpack12.unpack.unpack15, ptr %loadgep_2.repack29.repack33, align 8, !tbaa !8
  %13 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 0
  %14 = load i64, ptr %13, align 8, !tbaa !8
  %15 = sext i32 %8 to i64
  %16 = sub i64 %15, %14
  %17 = getelementptr double, ptr %.unpack, i64 %16
  store double %12, ptr %17, align 8, !tbaa !4
  store ptr %.unpack, ptr %loadgep_4, align 8, !tbaa !8
  %loadgep_4.repack47 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 1
  store i64 %.unpack6, ptr %loadgep_4.repack47, align 8, !tbaa !8
  %loadgep_4.repack49 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 2
  store i32 %.unpack7, ptr %loadgep_4.repack49, align 8, !tbaa !8
  %loadgep_4.repack51 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 3
  store i8 %.unpack8, ptr %loadgep_4.repack51, align 4, !tbaa !8
  %loadgep_4.repack53 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 4
  store i8 %.unpack9, ptr %loadgep_4.repack53, align 1, !tbaa !8
  %loadgep_4.repack55 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 5
  store i8 %.unpack10, ptr %loadgep_4.repack55, align 2, !tbaa !8
  %loadgep_4.repack57 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 6
  store i8 %.unpack11, ptr %loadgep_4.repack57, align 1, !tbaa !8
  %loadgep_4.repack59 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7
  store i64 %.unpack12.unpack.unpack, ptr %loadgep_4.repack59, align 8, !tbaa !8
  %loadgep_4.repack59.repack61 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack12.unpack.unpack14, ptr %loadgep_4.repack59.repack61, align 8, !tbaa !8
  %loadgep_4.repack59.repack63 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 2
  store i64 %.unpack12.unpack.unpack15, ptr %loadgep_4.repack59.repack63, align 8, !tbaa !8
  %omp_loop.next = add nuw i32 %omp_loop.iv, 1
  br label %omp_loop.header
}
*** IR Dump After TailCallElimPass on _QQmain..omp_par ***
; Function Attrs: norecurse nounwind
define internal void @_QQmain..omp_par(ptr noalias %tid.addr, ptr noalias %zero.addr, ptr %0) #2 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %gep_3 = getelementptr { ptr, ptr, ptr }, ptr %0, i64 0, i32 2
  %loadgep_4 = load ptr, ptr %gep_3, align 8
  %p.lastiter = alloca i32, align 4
  %p.lowerbound = alloca i32, align 4
  %p.upperbound = alloca i32, align 4
  %p.stride = alloca i32, align 4
  %1 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %omp_loop.tripcount = tail call i32 @llvm.smax.i32(i32 %1, i32 0)
  store i32 0, ptr %p.lowerbound, align 4
  %2 = add nsw i32 %omp_loop.tripcount, -1
  store i32 %2, ptr %p.upperbound, align 4
  store i32 1, ptr %p.stride, align 4
  %omp_global_thread_num4 = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  call void @__kmpc_for_static_init_4u(ptr nonnull @1, i32 %omp_global_thread_num4, i32 34, ptr nonnull %p.lastiter, ptr nonnull %p.lowerbound, ptr nonnull %p.upperbound, ptr nonnull %p.stride, i32 1, i32 0)
  %3 = load i32, ptr %p.lowerbound, align 4
  %4 = load i32, ptr %p.upperbound, align 4
  %5 = sub i32 %4, %3
  %6 = add i32 %5, 1
  br label %omp_loop.header

omp_loop.header:                                  ; preds = %omp_loop.body, %omp.par.entry
  %omp_loop.iv = phi i32 [ 0, %omp.par.entry ], [ %omp_loop.next, %omp_loop.body ]
  %omp_loop.cmp = icmp ult i32 %omp_loop.iv, %6
  br i1 %omp_loop.cmp, label %omp_loop.body, label %omp_loop.exit

omp_loop.exit:                                    ; preds = %omp_loop.header
  call void @__kmpc_for_static_fini(ptr nonnull @1, i32 %omp_global_thread_num4)
  call void @__kmpc_barrier(ptr nonnull @2, i32 %omp_global_thread_num4)
  ret void

omp_loop.body:                                    ; preds = %omp_loop.header
  %7 = add i32 %omp_loop.iv, %3
  %8 = add i32 %7, 1
  %9 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %10 = sitofp i32 %9 to float
  %11 = fdiv contract float 1.000000e+00, %10
  %12 = fpext float %11 to double
  %.unpack = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  %.unpack6 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  %.unpack7 = load i32, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  %.unpack8 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  %.unpack9 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  %.unpack10 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  %.unpack11 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  %.unpack12.unpack.unpack = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  %.unpack12.unpack.unpack14 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  %.unpack12.unpack.unpack15 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  store ptr %.unpack, ptr %loadgep_2, align 8, !tbaa !8
  %loadgep_2.repack17 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  store i64 %.unpack6, ptr %loadgep_2.repack17, align 8, !tbaa !8
  %loadgep_2.repack19 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  store i32 %.unpack7, ptr %loadgep_2.repack19, align 8, !tbaa !8
  %loadgep_2.repack21 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  store i8 %.unpack8, ptr %loadgep_2.repack21, align 4, !tbaa !8
  %loadgep_2.repack23 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  store i8 %.unpack9, ptr %loadgep_2.repack23, align 1, !tbaa !8
  %loadgep_2.repack25 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  store i8 %.unpack10, ptr %loadgep_2.repack25, align 2, !tbaa !8
  %loadgep_2.repack27 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  store i8 %.unpack11, ptr %loadgep_2.repack27, align 1, !tbaa !8
  %loadgep_2.repack29 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  store i64 %.unpack12.unpack.unpack, ptr %loadgep_2.repack29, align 8, !tbaa !8
  %loadgep_2.repack29.repack31 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack12.unpack.unpack14, ptr %loadgep_2.repack29.repack31, align 8, !tbaa !8
  %loadgep_2.repack29.repack33 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  store i64 %.unpack12.unpack.unpack15, ptr %loadgep_2.repack29.repack33, align 8, !tbaa !8
  %13 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 0
  %14 = load i64, ptr %13, align 8, !tbaa !8
  %15 = sext i32 %8 to i64
  %16 = sub i64 %15, %14
  %17 = getelementptr double, ptr %.unpack, i64 %16
  store double %12, ptr %17, align 8, !tbaa !4
  store ptr %.unpack, ptr %loadgep_4, align 8, !tbaa !8
  %loadgep_4.repack47 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 1
  store i64 %.unpack6, ptr %loadgep_4.repack47, align 8, !tbaa !8
  %loadgep_4.repack49 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 2
  store i32 %.unpack7, ptr %loadgep_4.repack49, align 8, !tbaa !8
  %loadgep_4.repack51 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 3
  store i8 %.unpack8, ptr %loadgep_4.repack51, align 4, !tbaa !8
  %loadgep_4.repack53 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 4
  store i8 %.unpack9, ptr %loadgep_4.repack53, align 1, !tbaa !8
  %loadgep_4.repack55 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 5
  store i8 %.unpack10, ptr %loadgep_4.repack55, align 2, !tbaa !8
  %loadgep_4.repack57 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 6
  store i8 %.unpack11, ptr %loadgep_4.repack57, align 1, !tbaa !8
  %loadgep_4.repack59 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7
  store i64 %.unpack12.unpack.unpack, ptr %loadgep_4.repack59, align 8, !tbaa !8
  %loadgep_4.repack59.repack61 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack12.unpack.unpack14, ptr %loadgep_4.repack59.repack61, align 8, !tbaa !8
  %loadgep_4.repack59.repack63 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 2
  store i64 %.unpack12.unpack.unpack15, ptr %loadgep_4.repack59.repack63, align 8, !tbaa !8
  %omp_loop.next = add nuw i32 %omp_loop.iv, 1
  br label %omp_loop.header
}
*** IR Dump After SimplifyCFGPass on _QQmain..omp_par ***
; Function Attrs: norecurse nounwind
define internal void @_QQmain..omp_par(ptr noalias %tid.addr, ptr noalias %zero.addr, ptr %0) #2 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %gep_3 = getelementptr { ptr, ptr, ptr }, ptr %0, i64 0, i32 2
  %loadgep_4 = load ptr, ptr %gep_3, align 8
  %p.lastiter = alloca i32, align 4
  %p.lowerbound = alloca i32, align 4
  %p.upperbound = alloca i32, align 4
  %p.stride = alloca i32, align 4
  %1 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %omp_loop.tripcount = tail call i32 @llvm.smax.i32(i32 %1, i32 0)
  store i32 0, ptr %p.lowerbound, align 4
  %2 = add nsw i32 %omp_loop.tripcount, -1
  store i32 %2, ptr %p.upperbound, align 4
  store i32 1, ptr %p.stride, align 4
  %omp_global_thread_num4 = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  call void @__kmpc_for_static_init_4u(ptr nonnull @1, i32 %omp_global_thread_num4, i32 34, ptr nonnull %p.lastiter, ptr nonnull %p.lowerbound, ptr nonnull %p.upperbound, ptr nonnull %p.stride, i32 1, i32 0)
  %3 = load i32, ptr %p.lowerbound, align 4
  %4 = load i32, ptr %p.upperbound, align 4
  %5 = sub i32 %4, %3
  %6 = add i32 %5, 1
  br label %omp_loop.header

omp_loop.header:                                  ; preds = %omp_loop.body, %omp.par.entry
  %omp_loop.iv = phi i32 [ 0, %omp.par.entry ], [ %omp_loop.next, %omp_loop.body ]
  %omp_loop.cmp = icmp ult i32 %omp_loop.iv, %6
  br i1 %omp_loop.cmp, label %omp_loop.body, label %omp_loop.exit

omp_loop.exit:                                    ; preds = %omp_loop.header
  call void @__kmpc_for_static_fini(ptr nonnull @1, i32 %omp_global_thread_num4)
  call void @__kmpc_barrier(ptr nonnull @2, i32 %omp_global_thread_num4)
  ret void

omp_loop.body:                                    ; preds = %omp_loop.header
  %7 = add i32 %omp_loop.iv, %3
  %8 = add i32 %7, 1
  %9 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %10 = sitofp i32 %9 to float
  %11 = fdiv contract float 1.000000e+00, %10
  %12 = fpext float %11 to double
  %.unpack = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  %.unpack6 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  %.unpack7 = load i32, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  %.unpack8 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  %.unpack9 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  %.unpack10 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  %.unpack11 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  %.unpack12.unpack.unpack = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  %.unpack12.unpack.unpack14 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  %.unpack12.unpack.unpack15 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  store ptr %.unpack, ptr %loadgep_2, align 8, !tbaa !8
  %loadgep_2.repack17 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  store i64 %.unpack6, ptr %loadgep_2.repack17, align 8, !tbaa !8
  %loadgep_2.repack19 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  store i32 %.unpack7, ptr %loadgep_2.repack19, align 8, !tbaa !8
  %loadgep_2.repack21 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  store i8 %.unpack8, ptr %loadgep_2.repack21, align 4, !tbaa !8
  %loadgep_2.repack23 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  store i8 %.unpack9, ptr %loadgep_2.repack23, align 1, !tbaa !8
  %loadgep_2.repack25 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  store i8 %.unpack10, ptr %loadgep_2.repack25, align 2, !tbaa !8
  %loadgep_2.repack27 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  store i8 %.unpack11, ptr %loadgep_2.repack27, align 1, !tbaa !8
  %loadgep_2.repack29 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  store i64 %.unpack12.unpack.unpack, ptr %loadgep_2.repack29, align 8, !tbaa !8
  %loadgep_2.repack29.repack31 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack12.unpack.unpack14, ptr %loadgep_2.repack29.repack31, align 8, !tbaa !8
  %loadgep_2.repack29.repack33 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  store i64 %.unpack12.unpack.unpack15, ptr %loadgep_2.repack29.repack33, align 8, !tbaa !8
  %13 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 0
  %14 = load i64, ptr %13, align 8, !tbaa !8
  %15 = sext i32 %8 to i64
  %16 = sub i64 %15, %14
  %17 = getelementptr double, ptr %.unpack, i64 %16
  store double %12, ptr %17, align 8, !tbaa !4
  store ptr %.unpack, ptr %loadgep_4, align 8, !tbaa !8
  %loadgep_4.repack47 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 1
  store i64 %.unpack6, ptr %loadgep_4.repack47, align 8, !tbaa !8
  %loadgep_4.repack49 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 2
  store i32 %.unpack7, ptr %loadgep_4.repack49, align 8, !tbaa !8
  %loadgep_4.repack51 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 3
  store i8 %.unpack8, ptr %loadgep_4.repack51, align 4, !tbaa !8
  %loadgep_4.repack53 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 4
  store i8 %.unpack9, ptr %loadgep_4.repack53, align 1, !tbaa !8
  %loadgep_4.repack55 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 5
  store i8 %.unpack10, ptr %loadgep_4.repack55, align 2, !tbaa !8
  %loadgep_4.repack57 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 6
  store i8 %.unpack11, ptr %loadgep_4.repack57, align 1, !tbaa !8
  %loadgep_4.repack59 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7
  store i64 %.unpack12.unpack.unpack, ptr %loadgep_4.repack59, align 8, !tbaa !8
  %loadgep_4.repack59.repack61 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack12.unpack.unpack14, ptr %loadgep_4.repack59.repack61, align 8, !tbaa !8
  %loadgep_4.repack59.repack63 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 2
  store i64 %.unpack12.unpack.unpack15, ptr %loadgep_4.repack59.repack63, align 8, !tbaa !8
  %omp_loop.next = add nuw i32 %omp_loop.iv, 1
  br label %omp_loop.header
}
*** IR Dump After ReassociatePass on _QQmain..omp_par ***
; Function Attrs: norecurse nounwind
define internal void @_QQmain..omp_par(ptr noalias %tid.addr, ptr noalias %zero.addr, ptr %0) #2 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %gep_3 = getelementptr { ptr, ptr, ptr }, ptr %0, i64 0, i32 2
  %loadgep_4 = load ptr, ptr %gep_3, align 8
  %p.lastiter = alloca i32, align 4
  %p.lowerbound = alloca i32, align 4
  %p.upperbound = alloca i32, align 4
  %p.stride = alloca i32, align 4
  %1 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %omp_loop.tripcount = tail call i32 @llvm.smax.i32(i32 %1, i32 0)
  store i32 0, ptr %p.lowerbound, align 4
  %2 = add nsw i32 %omp_loop.tripcount, -1
  store i32 %2, ptr %p.upperbound, align 4
  store i32 1, ptr %p.stride, align 4
  %omp_global_thread_num4 = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  call void @__kmpc_for_static_init_4u(ptr nonnull @1, i32 %omp_global_thread_num4, i32 34, ptr nonnull %p.lastiter, ptr nonnull %p.lowerbound, ptr nonnull %p.upperbound, ptr nonnull %p.stride, i32 1, i32 0)
  %3 = load i32, ptr %p.lowerbound, align 4
  %4 = load i32, ptr %p.upperbound, align 4
  %.neg = sub i32 0, %3
  %5 = add i32 %.neg, 1
  %6 = add i32 %5, %4
  br label %omp_loop.header

omp_loop.header:                                  ; preds = %omp_loop.body, %omp.par.entry
  %omp_loop.iv = phi i32 [ 0, %omp.par.entry ], [ %omp_loop.next, %omp_loop.body ]
  %omp_loop.cmp = icmp ult i32 %omp_loop.iv, %6
  br i1 %omp_loop.cmp, label %omp_loop.body, label %omp_loop.exit

omp_loop.exit:                                    ; preds = %omp_loop.header
  call void @__kmpc_for_static_fini(ptr nonnull @1, i32 %omp_global_thread_num4)
  call void @__kmpc_barrier(ptr nonnull @2, i32 %omp_global_thread_num4)
  ret void

omp_loop.body:                                    ; preds = %omp_loop.header
  %7 = add i32 %omp_loop.iv, 1
  %8 = add i32 %7, %3
  %9 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %10 = sitofp i32 %9 to float
  %11 = fdiv contract float 1.000000e+00, %10
  %12 = fpext float %11 to double
  %.unpack = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  %.unpack6 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  %.unpack7 = load i32, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  %.unpack8 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  %.unpack9 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  %.unpack10 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  %.unpack11 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  %.unpack12.unpack.unpack = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  %.unpack12.unpack.unpack14 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  %.unpack12.unpack.unpack15 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  store ptr %.unpack, ptr %loadgep_2, align 8, !tbaa !8
  %loadgep_2.repack17 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  store i64 %.unpack6, ptr %loadgep_2.repack17, align 8, !tbaa !8
  %loadgep_2.repack19 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  store i32 %.unpack7, ptr %loadgep_2.repack19, align 8, !tbaa !8
  %loadgep_2.repack21 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  store i8 %.unpack8, ptr %loadgep_2.repack21, align 4, !tbaa !8
  %loadgep_2.repack23 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  store i8 %.unpack9, ptr %loadgep_2.repack23, align 1, !tbaa !8
  %loadgep_2.repack25 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  store i8 %.unpack10, ptr %loadgep_2.repack25, align 2, !tbaa !8
  %loadgep_2.repack27 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  store i8 %.unpack11, ptr %loadgep_2.repack27, align 1, !tbaa !8
  %loadgep_2.repack29 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  store i64 %.unpack12.unpack.unpack, ptr %loadgep_2.repack29, align 8, !tbaa !8
  %loadgep_2.repack29.repack31 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack12.unpack.unpack14, ptr %loadgep_2.repack29.repack31, align 8, !tbaa !8
  %loadgep_2.repack29.repack33 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  store i64 %.unpack12.unpack.unpack15, ptr %loadgep_2.repack29.repack33, align 8, !tbaa !8
  %13 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 0
  %14 = load i64, ptr %13, align 8, !tbaa !8
  %15 = sext i32 %8 to i64
  %16 = sub i64 %15, %14
  %17 = getelementptr double, ptr %.unpack, i64 %16
  store double %12, ptr %17, align 8, !tbaa !4
  store ptr %.unpack, ptr %loadgep_4, align 8, !tbaa !8
  %loadgep_4.repack47 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 1
  store i64 %.unpack6, ptr %loadgep_4.repack47, align 8, !tbaa !8
  %loadgep_4.repack49 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 2
  store i32 %.unpack7, ptr %loadgep_4.repack49, align 8, !tbaa !8
  %loadgep_4.repack51 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 3
  store i8 %.unpack8, ptr %loadgep_4.repack51, align 4, !tbaa !8
  %loadgep_4.repack53 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 4
  store i8 %.unpack9, ptr %loadgep_4.repack53, align 1, !tbaa !8
  %loadgep_4.repack55 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 5
  store i8 %.unpack10, ptr %loadgep_4.repack55, align 2, !tbaa !8
  %loadgep_4.repack57 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 6
  store i8 %.unpack11, ptr %loadgep_4.repack57, align 1, !tbaa !8
  %loadgep_4.repack59 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7
  store i64 %.unpack12.unpack.unpack, ptr %loadgep_4.repack59, align 8, !tbaa !8
  %loadgep_4.repack59.repack61 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack12.unpack.unpack14, ptr %loadgep_4.repack59.repack61, align 8, !tbaa !8
  %loadgep_4.repack59.repack63 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 2
  store i64 %.unpack12.unpack.unpack15, ptr %loadgep_4.repack59.repack63, align 8, !tbaa !8
  %omp_loop.next = add nuw i32 %omp_loop.iv, 1
  br label %omp_loop.header
}
*** IR Dump After LoopSimplifyPass on _QQmain..omp_par ***
; Function Attrs: norecurse nounwind
define internal void @_QQmain..omp_par(ptr noalias %tid.addr, ptr noalias %zero.addr, ptr %0) #2 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %gep_3 = getelementptr { ptr, ptr, ptr }, ptr %0, i64 0, i32 2
  %loadgep_4 = load ptr, ptr %gep_3, align 8
  %p.lastiter = alloca i32, align 4
  %p.lowerbound = alloca i32, align 4
  %p.upperbound = alloca i32, align 4
  %p.stride = alloca i32, align 4
  %1 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %omp_loop.tripcount = tail call i32 @llvm.smax.i32(i32 %1, i32 0)
  store i32 0, ptr %p.lowerbound, align 4
  %2 = add nsw i32 %omp_loop.tripcount, -1
  store i32 %2, ptr %p.upperbound, align 4
  store i32 1, ptr %p.stride, align 4
  %omp_global_thread_num4 = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  call void @__kmpc_for_static_init_4u(ptr nonnull @1, i32 %omp_global_thread_num4, i32 34, ptr nonnull %p.lastiter, ptr nonnull %p.lowerbound, ptr nonnull %p.upperbound, ptr nonnull %p.stride, i32 1, i32 0)
  %3 = load i32, ptr %p.lowerbound, align 4
  %4 = load i32, ptr %p.upperbound, align 4
  %.neg = sub i32 0, %3
  %5 = add i32 %.neg, 1
  %6 = add i32 %5, %4
  br label %omp_loop.header

omp_loop.header:                                  ; preds = %omp_loop.body, %omp.par.entry
  %omp_loop.iv = phi i32 [ 0, %omp.par.entry ], [ %omp_loop.next, %omp_loop.body ]
  %omp_loop.cmp = icmp ult i32 %omp_loop.iv, %6
  br i1 %omp_loop.cmp, label %omp_loop.body, label %omp_loop.exit

omp_loop.exit:                                    ; preds = %omp_loop.header
  call void @__kmpc_for_static_fini(ptr nonnull @1, i32 %omp_global_thread_num4)
  call void @__kmpc_barrier(ptr nonnull @2, i32 %omp_global_thread_num4)
  ret void

omp_loop.body:                                    ; preds = %omp_loop.header
  %7 = add i32 %omp_loop.iv, 1
  %8 = add i32 %7, %3
  %9 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %10 = sitofp i32 %9 to float
  %11 = fdiv contract float 1.000000e+00, %10
  %12 = fpext float %11 to double
  %.unpack = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  %.unpack6 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  %.unpack7 = load i32, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  %.unpack8 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  %.unpack9 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  %.unpack10 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  %.unpack11 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  %.unpack12.unpack.unpack = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  %.unpack12.unpack.unpack14 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  %.unpack12.unpack.unpack15 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  store ptr %.unpack, ptr %loadgep_2, align 8, !tbaa !8
  %loadgep_2.repack17 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  store i64 %.unpack6, ptr %loadgep_2.repack17, align 8, !tbaa !8
  %loadgep_2.repack19 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  store i32 %.unpack7, ptr %loadgep_2.repack19, align 8, !tbaa !8
  %loadgep_2.repack21 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  store i8 %.unpack8, ptr %loadgep_2.repack21, align 4, !tbaa !8
  %loadgep_2.repack23 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  store i8 %.unpack9, ptr %loadgep_2.repack23, align 1, !tbaa !8
  %loadgep_2.repack25 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  store i8 %.unpack10, ptr %loadgep_2.repack25, align 2, !tbaa !8
  %loadgep_2.repack27 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  store i8 %.unpack11, ptr %loadgep_2.repack27, align 1, !tbaa !8
  %loadgep_2.repack29 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  store i64 %.unpack12.unpack.unpack, ptr %loadgep_2.repack29, align 8, !tbaa !8
  %loadgep_2.repack29.repack31 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack12.unpack.unpack14, ptr %loadgep_2.repack29.repack31, align 8, !tbaa !8
  %loadgep_2.repack29.repack33 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  store i64 %.unpack12.unpack.unpack15, ptr %loadgep_2.repack29.repack33, align 8, !tbaa !8
  %13 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 0
  %14 = load i64, ptr %13, align 8, !tbaa !8
  %15 = sext i32 %8 to i64
  %16 = sub i64 %15, %14
  %17 = getelementptr double, ptr %.unpack, i64 %16
  store double %12, ptr %17, align 8, !tbaa !4
  store ptr %.unpack, ptr %loadgep_4, align 8, !tbaa !8
  %loadgep_4.repack47 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 1
  store i64 %.unpack6, ptr %loadgep_4.repack47, align 8, !tbaa !8
  %loadgep_4.repack49 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 2
  store i32 %.unpack7, ptr %loadgep_4.repack49, align 8, !tbaa !8
  %loadgep_4.repack51 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 3
  store i8 %.unpack8, ptr %loadgep_4.repack51, align 4, !tbaa !8
  %loadgep_4.repack53 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 4
  store i8 %.unpack9, ptr %loadgep_4.repack53, align 1, !tbaa !8
  %loadgep_4.repack55 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 5
  store i8 %.unpack10, ptr %loadgep_4.repack55, align 2, !tbaa !8
  %loadgep_4.repack57 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 6
  store i8 %.unpack11, ptr %loadgep_4.repack57, align 1, !tbaa !8
  %loadgep_4.repack59 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7
  store i64 %.unpack12.unpack.unpack, ptr %loadgep_4.repack59, align 8, !tbaa !8
  %loadgep_4.repack59.repack61 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack12.unpack.unpack14, ptr %loadgep_4.repack59.repack61, align 8, !tbaa !8
  %loadgep_4.repack59.repack63 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 2
  store i64 %.unpack12.unpack.unpack15, ptr %loadgep_4.repack59.repack63, align 8, !tbaa !8
  %omp_loop.next = add nuw i32 %omp_loop.iv, 1
  br label %omp_loop.header
}
*** IR Dump After LCSSAPass on _QQmain..omp_par ***
; Function Attrs: norecurse nounwind
define internal void @_QQmain..omp_par(ptr noalias %tid.addr, ptr noalias %zero.addr, ptr %0) #2 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %gep_3 = getelementptr { ptr, ptr, ptr }, ptr %0, i64 0, i32 2
  %loadgep_4 = load ptr, ptr %gep_3, align 8
  %p.lastiter = alloca i32, align 4
  %p.lowerbound = alloca i32, align 4
  %p.upperbound = alloca i32, align 4
  %p.stride = alloca i32, align 4
  %1 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %omp_loop.tripcount = tail call i32 @llvm.smax.i32(i32 %1, i32 0)
  store i32 0, ptr %p.lowerbound, align 4
  %2 = add nsw i32 %omp_loop.tripcount, -1
  store i32 %2, ptr %p.upperbound, align 4
  store i32 1, ptr %p.stride, align 4
  %omp_global_thread_num4 = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  call void @__kmpc_for_static_init_4u(ptr nonnull @1, i32 %omp_global_thread_num4, i32 34, ptr nonnull %p.lastiter, ptr nonnull %p.lowerbound, ptr nonnull %p.upperbound, ptr nonnull %p.stride, i32 1, i32 0)
  %3 = load i32, ptr %p.lowerbound, align 4
  %4 = load i32, ptr %p.upperbound, align 4
  %.neg = sub i32 0, %3
  %5 = add i32 %.neg, 1
  %6 = add i32 %5, %4
  br label %omp_loop.header

omp_loop.header:                                  ; preds = %omp_loop.body, %omp.par.entry
  %omp_loop.iv = phi i32 [ 0, %omp.par.entry ], [ %omp_loop.next, %omp_loop.body ]
  %omp_loop.cmp = icmp ult i32 %omp_loop.iv, %6
  br i1 %omp_loop.cmp, label %omp_loop.body, label %omp_loop.exit

omp_loop.exit:                                    ; preds = %omp_loop.header
  call void @__kmpc_for_static_fini(ptr nonnull @1, i32 %omp_global_thread_num4)
  call void @__kmpc_barrier(ptr nonnull @2, i32 %omp_global_thread_num4)
  ret void

omp_loop.body:                                    ; preds = %omp_loop.header
  %7 = add i32 %omp_loop.iv, 1
  %8 = add i32 %7, %3
  %9 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %10 = sitofp i32 %9 to float
  %11 = fdiv contract float 1.000000e+00, %10
  %12 = fpext float %11 to double
  %.unpack = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  %.unpack6 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  %.unpack7 = load i32, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  %.unpack8 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  %.unpack9 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  %.unpack10 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  %.unpack11 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  %.unpack12.unpack.unpack = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  %.unpack12.unpack.unpack14 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  %.unpack12.unpack.unpack15 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  store ptr %.unpack, ptr %loadgep_2, align 8, !tbaa !8
  %loadgep_2.repack17 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  store i64 %.unpack6, ptr %loadgep_2.repack17, align 8, !tbaa !8
  %loadgep_2.repack19 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  store i32 %.unpack7, ptr %loadgep_2.repack19, align 8, !tbaa !8
  %loadgep_2.repack21 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  store i8 %.unpack8, ptr %loadgep_2.repack21, align 4, !tbaa !8
  %loadgep_2.repack23 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  store i8 %.unpack9, ptr %loadgep_2.repack23, align 1, !tbaa !8
  %loadgep_2.repack25 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  store i8 %.unpack10, ptr %loadgep_2.repack25, align 2, !tbaa !8
  %loadgep_2.repack27 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  store i8 %.unpack11, ptr %loadgep_2.repack27, align 1, !tbaa !8
  %loadgep_2.repack29 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  store i64 %.unpack12.unpack.unpack, ptr %loadgep_2.repack29, align 8, !tbaa !8
  %loadgep_2.repack29.repack31 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack12.unpack.unpack14, ptr %loadgep_2.repack29.repack31, align 8, !tbaa !8
  %loadgep_2.repack29.repack33 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  store i64 %.unpack12.unpack.unpack15, ptr %loadgep_2.repack29.repack33, align 8, !tbaa !8
  %13 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 0
  %14 = load i64, ptr %13, align 8, !tbaa !8
  %15 = sext i32 %8 to i64
  %16 = sub i64 %15, %14
  %17 = getelementptr double, ptr %.unpack, i64 %16
  store double %12, ptr %17, align 8, !tbaa !4
  store ptr %.unpack, ptr %loadgep_4, align 8, !tbaa !8
  %loadgep_4.repack47 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 1
  store i64 %.unpack6, ptr %loadgep_4.repack47, align 8, !tbaa !8
  %loadgep_4.repack49 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 2
  store i32 %.unpack7, ptr %loadgep_4.repack49, align 8, !tbaa !8
  %loadgep_4.repack51 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 3
  store i8 %.unpack8, ptr %loadgep_4.repack51, align 4, !tbaa !8
  %loadgep_4.repack53 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 4
  store i8 %.unpack9, ptr %loadgep_4.repack53, align 1, !tbaa !8
  %loadgep_4.repack55 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 5
  store i8 %.unpack10, ptr %loadgep_4.repack55, align 2, !tbaa !8
  %loadgep_4.repack57 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 6
  store i8 %.unpack11, ptr %loadgep_4.repack57, align 1, !tbaa !8
  %loadgep_4.repack59 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7
  store i64 %.unpack12.unpack.unpack, ptr %loadgep_4.repack59, align 8, !tbaa !8
  %loadgep_4.repack59.repack61 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack12.unpack.unpack14, ptr %loadgep_4.repack59.repack61, align 8, !tbaa !8
  %loadgep_4.repack59.repack63 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 2
  store i64 %.unpack12.unpack.unpack15, ptr %loadgep_4.repack59.repack63, align 8, !tbaa !8
  %omp_loop.next = add nuw i32 %omp_loop.iv, 1
  br label %omp_loop.header
}
*** IR Dump After LoopInstSimplifyPass on omp_loop.header ***

; Preheader:
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %gep_3 = getelementptr { ptr, ptr, ptr }, ptr %0, i64 0, i32 2
  %loadgep_4 = load ptr, ptr %gep_3, align 8
  %p.lastiter = alloca i32, align 4
  %p.lowerbound = alloca i32, align 4
  %p.upperbound = alloca i32, align 4
  %p.stride = alloca i32, align 4
  %1 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %omp_loop.tripcount = tail call i32 @llvm.smax.i32(i32 %1, i32 0)
  store i32 0, ptr %p.lowerbound, align 4
  %2 = add nsw i32 %omp_loop.tripcount, -1
  store i32 %2, ptr %p.upperbound, align 4
  store i32 1, ptr %p.stride, align 4
  %omp_global_thread_num4 = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  call void @__kmpc_for_static_init_4u(ptr nonnull @1, i32 %omp_global_thread_num4, i32 34, ptr nonnull %p.lastiter, ptr nonnull %p.lowerbound, ptr nonnull %p.upperbound, ptr nonnull %p.stride, i32 1, i32 0)
  %3 = load i32, ptr %p.lowerbound, align 4
  %4 = load i32, ptr %p.upperbound, align 4
  %.neg = sub i32 0, %3
  %5 = add i32 %.neg, 1
  %6 = add i32 %5, %4
  br label %omp_loop.header

; Loop:
omp_loop.header:                                  ; preds = %omp_loop.body, %omp.par.entry
  %omp_loop.iv = phi i32 [ 0, %omp.par.entry ], [ %omp_loop.next, %omp_loop.body ]
  %omp_loop.cmp = icmp ult i32 %omp_loop.iv, %6
  br i1 %omp_loop.cmp, label %omp_loop.body, label %omp_loop.exit

omp_loop.body:                                    ; preds = %omp_loop.header
  %7 = add i32 %omp_loop.iv, 1
  %8 = add i32 %7, %3
  %9 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %10 = sitofp i32 %9 to float
  %11 = fdiv contract float 1.000000e+00, %10
  %12 = fpext float %11 to double
  %.unpack = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  %.unpack6 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  %.unpack7 = load i32, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  %.unpack8 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  %.unpack9 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  %.unpack10 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  %.unpack11 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  %.unpack12.unpack.unpack = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  %.unpack12.unpack.unpack14 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  %.unpack12.unpack.unpack15 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  store ptr %.unpack, ptr %loadgep_2, align 8, !tbaa !8
  %loadgep_2.repack17 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  store i64 %.unpack6, ptr %loadgep_2.repack17, align 8, !tbaa !8
  %loadgep_2.repack19 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  store i32 %.unpack7, ptr %loadgep_2.repack19, align 8, !tbaa !8
  %loadgep_2.repack21 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  store i8 %.unpack8, ptr %loadgep_2.repack21, align 4, !tbaa !8
  %loadgep_2.repack23 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  store i8 %.unpack9, ptr %loadgep_2.repack23, align 1, !tbaa !8
  %loadgep_2.repack25 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  store i8 %.unpack10, ptr %loadgep_2.repack25, align 2, !tbaa !8
  %loadgep_2.repack27 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  store i8 %.unpack11, ptr %loadgep_2.repack27, align 1, !tbaa !8
  %loadgep_2.repack29 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  store i64 %.unpack12.unpack.unpack, ptr %loadgep_2.repack29, align 8, !tbaa !8
  %loadgep_2.repack29.repack31 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack12.unpack.unpack14, ptr %loadgep_2.repack29.repack31, align 8, !tbaa !8
  %loadgep_2.repack29.repack33 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  store i64 %.unpack12.unpack.unpack15, ptr %loadgep_2.repack29.repack33, align 8, !tbaa !8
  %13 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 0
  %14 = load i64, ptr %13, align 8, !tbaa !8
  %15 = sext i32 %8 to i64
  %16 = sub i64 %15, %14
  %17 = getelementptr double, ptr %.unpack, i64 %16
  store double %12, ptr %17, align 8, !tbaa !4
  store ptr %.unpack, ptr %loadgep_4, align 8, !tbaa !8
  %loadgep_4.repack47 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 1
  store i64 %.unpack6, ptr %loadgep_4.repack47, align 8, !tbaa !8
  %loadgep_4.repack49 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 2
  store i32 %.unpack7, ptr %loadgep_4.repack49, align 8, !tbaa !8
  %loadgep_4.repack51 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 3
  store i8 %.unpack8, ptr %loadgep_4.repack51, align 4, !tbaa !8
  %loadgep_4.repack53 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 4
  store i8 %.unpack9, ptr %loadgep_4.repack53, align 1, !tbaa !8
  %loadgep_4.repack55 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 5
  store i8 %.unpack10, ptr %loadgep_4.repack55, align 2, !tbaa !8
  %loadgep_4.repack57 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 6
  store i8 %.unpack11, ptr %loadgep_4.repack57, align 1, !tbaa !8
  %loadgep_4.repack59 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7
  store i64 %.unpack12.unpack.unpack, ptr %loadgep_4.repack59, align 8, !tbaa !8
  %loadgep_4.repack59.repack61 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack12.unpack.unpack14, ptr %loadgep_4.repack59.repack61, align 8, !tbaa !8
  %loadgep_4.repack59.repack63 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 2
  store i64 %.unpack12.unpack.unpack15, ptr %loadgep_4.repack59.repack63, align 8, !tbaa !8
  %omp_loop.next = add nuw i32 %omp_loop.iv, 1
  br label %omp_loop.header

; Exit blocks
omp_loop.exit:                                    ; preds = %omp_loop.header
  call void @__kmpc_for_static_fini(ptr nonnull @1, i32 %omp_global_thread_num4)
  call void @__kmpc_barrier(ptr nonnull @2, i32 %omp_global_thread_num4)
  ret void
*** IR Dump After LoopSimplifyCFGPass on omp_loop.header ***

; Preheader:
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %gep_3 = getelementptr { ptr, ptr, ptr }, ptr %0, i64 0, i32 2
  %loadgep_4 = load ptr, ptr %gep_3, align 8
  %p.lastiter = alloca i32, align 4
  %p.lowerbound = alloca i32, align 4
  %p.upperbound = alloca i32, align 4
  %p.stride = alloca i32, align 4
  %1 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %omp_loop.tripcount = tail call i32 @llvm.smax.i32(i32 %1, i32 0)
  store i32 0, ptr %p.lowerbound, align 4
  %2 = add nsw i32 %omp_loop.tripcount, -1
  store i32 %2, ptr %p.upperbound, align 4
  store i32 1, ptr %p.stride, align 4
  %omp_global_thread_num4 = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  call void @__kmpc_for_static_init_4u(ptr nonnull @1, i32 %omp_global_thread_num4, i32 34, ptr nonnull %p.lastiter, ptr nonnull %p.lowerbound, ptr nonnull %p.upperbound, ptr nonnull %p.stride, i32 1, i32 0)
  %3 = load i32, ptr %p.lowerbound, align 4
  %4 = load i32, ptr %p.upperbound, align 4
  %.neg = sub i32 0, %3
  %5 = add i32 %.neg, 1
  %6 = add i32 %5, %4
  br label %omp_loop.header

; Loop:
omp_loop.header:                                  ; preds = %omp_loop.body, %omp.par.entry
  %omp_loop.iv = phi i32 [ 0, %omp.par.entry ], [ %omp_loop.next, %omp_loop.body ]
  %omp_loop.cmp = icmp ult i32 %omp_loop.iv, %6
  br i1 %omp_loop.cmp, label %omp_loop.body, label %omp_loop.exit

omp_loop.body:                                    ; preds = %omp_loop.header
  %7 = add i32 %omp_loop.iv, 1
  %8 = add i32 %7, %3
  %9 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %10 = sitofp i32 %9 to float
  %11 = fdiv contract float 1.000000e+00, %10
  %12 = fpext float %11 to double
  %.unpack = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  %.unpack6 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  %.unpack7 = load i32, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  %.unpack8 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  %.unpack9 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  %.unpack10 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  %.unpack11 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  %.unpack12.unpack.unpack = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  %.unpack12.unpack.unpack14 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  %.unpack12.unpack.unpack15 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  store ptr %.unpack, ptr %loadgep_2, align 8, !tbaa !8
  %loadgep_2.repack17 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  store i64 %.unpack6, ptr %loadgep_2.repack17, align 8, !tbaa !8
  %loadgep_2.repack19 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  store i32 %.unpack7, ptr %loadgep_2.repack19, align 8, !tbaa !8
  %loadgep_2.repack21 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  store i8 %.unpack8, ptr %loadgep_2.repack21, align 4, !tbaa !8
  %loadgep_2.repack23 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  store i8 %.unpack9, ptr %loadgep_2.repack23, align 1, !tbaa !8
  %loadgep_2.repack25 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  store i8 %.unpack10, ptr %loadgep_2.repack25, align 2, !tbaa !8
  %loadgep_2.repack27 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  store i8 %.unpack11, ptr %loadgep_2.repack27, align 1, !tbaa !8
  %loadgep_2.repack29 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  store i64 %.unpack12.unpack.unpack, ptr %loadgep_2.repack29, align 8, !tbaa !8
  %loadgep_2.repack29.repack31 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack12.unpack.unpack14, ptr %loadgep_2.repack29.repack31, align 8, !tbaa !8
  %loadgep_2.repack29.repack33 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  store i64 %.unpack12.unpack.unpack15, ptr %loadgep_2.repack29.repack33, align 8, !tbaa !8
  %13 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 0
  %14 = load i64, ptr %13, align 8, !tbaa !8
  %15 = sext i32 %8 to i64
  %16 = sub i64 %15, %14
  %17 = getelementptr double, ptr %.unpack, i64 %16
  store double %12, ptr %17, align 8, !tbaa !4
  store ptr %.unpack, ptr %loadgep_4, align 8, !tbaa !8
  %loadgep_4.repack47 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 1
  store i64 %.unpack6, ptr %loadgep_4.repack47, align 8, !tbaa !8
  %loadgep_4.repack49 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 2
  store i32 %.unpack7, ptr %loadgep_4.repack49, align 8, !tbaa !8
  %loadgep_4.repack51 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 3
  store i8 %.unpack8, ptr %loadgep_4.repack51, align 4, !tbaa !8
  %loadgep_4.repack53 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 4
  store i8 %.unpack9, ptr %loadgep_4.repack53, align 1, !tbaa !8
  %loadgep_4.repack55 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 5
  store i8 %.unpack10, ptr %loadgep_4.repack55, align 2, !tbaa !8
  %loadgep_4.repack57 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 6
  store i8 %.unpack11, ptr %loadgep_4.repack57, align 1, !tbaa !8
  %loadgep_4.repack59 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7
  store i64 %.unpack12.unpack.unpack, ptr %loadgep_4.repack59, align 8, !tbaa !8
  %loadgep_4.repack59.repack61 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack12.unpack.unpack14, ptr %loadgep_4.repack59.repack61, align 8, !tbaa !8
  %loadgep_4.repack59.repack63 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 2
  store i64 %.unpack12.unpack.unpack15, ptr %loadgep_4.repack59.repack63, align 8, !tbaa !8
  %omp_loop.next = add nuw i32 %omp_loop.iv, 1
  br label %omp_loop.header

; Exit blocks
omp_loop.exit:                                    ; preds = %omp_loop.header
  call void @__kmpc_for_static_fini(ptr nonnull @1, i32 %omp_global_thread_num4)
  call void @__kmpc_barrier(ptr nonnull @2, i32 %omp_global_thread_num4)
  ret void
*** IR Dump After LICMPass on omp_loop.header ***

; Preheader:
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %gep_3 = getelementptr { ptr, ptr, ptr }, ptr %0, i64 0, i32 2
  %loadgep_4 = load ptr, ptr %gep_3, align 8
  %p.lastiter = alloca i32, align 4
  %p.lowerbound = alloca i32, align 4
  %p.upperbound = alloca i32, align 4
  %p.stride = alloca i32, align 4
  %1 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %omp_loop.tripcount = tail call i32 @llvm.smax.i32(i32 %1, i32 0)
  store i32 0, ptr %p.lowerbound, align 4
  %2 = add nsw i32 %omp_loop.tripcount, -1
  store i32 %2, ptr %p.upperbound, align 4
  store i32 1, ptr %p.stride, align 4
  %omp_global_thread_num4 = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  call void @__kmpc_for_static_init_4u(ptr nonnull @1, i32 %omp_global_thread_num4, i32 34, ptr nonnull %p.lastiter, ptr nonnull %p.lowerbound, ptr nonnull %p.upperbound, ptr nonnull %p.stride, i32 1, i32 0)
  %3 = load i32, ptr %p.lowerbound, align 4
  %4 = load i32, ptr %p.upperbound, align 4
  %.neg = sub i32 0, %3
  %5 = add i32 %.neg, 1
  %6 = add i32 %5, %4
  br label %omp_loop.header

; Loop:
omp_loop.header:                                  ; preds = %omp_loop.body, %omp.par.entry
  %omp_loop.iv = phi i32 [ 0, %omp.par.entry ], [ %omp_loop.next, %omp_loop.body ]
  %omp_loop.cmp = icmp ult i32 %omp_loop.iv, %6
  br i1 %omp_loop.cmp, label %omp_loop.body, label %omp_loop.exit

omp_loop.body:                                    ; preds = %omp_loop.header
  %7 = add i32 %omp_loop.iv, 1
  %8 = add i32 %7, %3
  %9 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %10 = sitofp i32 %9 to float
  %11 = fdiv contract float 1.000000e+00, %10
  %12 = fpext float %11 to double
  %.unpack = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  %.unpack6 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  %.unpack7 = load i32, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  %.unpack8 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  %.unpack9 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  %.unpack10 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  %.unpack11 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  %.unpack12.unpack.unpack = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  %.unpack12.unpack.unpack14 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  %.unpack12.unpack.unpack15 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  store ptr %.unpack, ptr %loadgep_2, align 8, !tbaa !8
  %loadgep_2.repack17 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  store i64 %.unpack6, ptr %loadgep_2.repack17, align 8, !tbaa !8
  %loadgep_2.repack19 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  store i32 %.unpack7, ptr %loadgep_2.repack19, align 8, !tbaa !8
  %loadgep_2.repack21 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  store i8 %.unpack8, ptr %loadgep_2.repack21, align 4, !tbaa !8
  %loadgep_2.repack23 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  store i8 %.unpack9, ptr %loadgep_2.repack23, align 1, !tbaa !8
  %loadgep_2.repack25 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  store i8 %.unpack10, ptr %loadgep_2.repack25, align 2, !tbaa !8
  %loadgep_2.repack27 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  store i8 %.unpack11, ptr %loadgep_2.repack27, align 1, !tbaa !8
  %loadgep_2.repack29 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  store i64 %.unpack12.unpack.unpack, ptr %loadgep_2.repack29, align 8, !tbaa !8
  %loadgep_2.repack29.repack31 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack12.unpack.unpack14, ptr %loadgep_2.repack29.repack31, align 8, !tbaa !8
  %loadgep_2.repack29.repack33 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  store i64 %.unpack12.unpack.unpack15, ptr %loadgep_2.repack29.repack33, align 8, !tbaa !8
  %13 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 0
  %14 = load i64, ptr %13, align 8, !tbaa !8
  %15 = sext i32 %8 to i64
  %16 = sub i64 %15, %14
  %17 = getelementptr double, ptr %.unpack, i64 %16
  store double %12, ptr %17, align 8, !tbaa !4
  store ptr %.unpack, ptr %loadgep_4, align 8, !tbaa !8
  %loadgep_4.repack47 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 1
  store i64 %.unpack6, ptr %loadgep_4.repack47, align 8, !tbaa !8
  %loadgep_4.repack49 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 2
  store i32 %.unpack7, ptr %loadgep_4.repack49, align 8, !tbaa !8
  %loadgep_4.repack51 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 3
  store i8 %.unpack8, ptr %loadgep_4.repack51, align 4, !tbaa !8
  %loadgep_4.repack53 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 4
  store i8 %.unpack9, ptr %loadgep_4.repack53, align 1, !tbaa !8
  %loadgep_4.repack55 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 5
  store i8 %.unpack10, ptr %loadgep_4.repack55, align 2, !tbaa !8
  %loadgep_4.repack57 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 6
  store i8 %.unpack11, ptr %loadgep_4.repack57, align 1, !tbaa !8
  %loadgep_4.repack59 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7
  store i64 %.unpack12.unpack.unpack, ptr %loadgep_4.repack59, align 8, !tbaa !8
  %loadgep_4.repack59.repack61 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack12.unpack.unpack14, ptr %loadgep_4.repack59.repack61, align 8, !tbaa !8
  %loadgep_4.repack59.repack63 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 2
  store i64 %.unpack12.unpack.unpack15, ptr %loadgep_4.repack59.repack63, align 8, !tbaa !8
  %omp_loop.next = add nuw i32 %omp_loop.iv, 1
  br label %omp_loop.header

; Exit blocks
omp_loop.exit:                                    ; preds = %omp_loop.header
  call void @__kmpc_for_static_fini(ptr nonnull @1, i32 %omp_global_thread_num4)
  call void @__kmpc_barrier(ptr nonnull @2, i32 %omp_global_thread_num4)
  ret void
*** IR Dump After LoopRotatePass on omp_loop.header ***

; Preheader:
omp_loop.body.lr.ph:                              ; preds = %omp.par.entry
  br label %omp_loop.body

; Loop:
omp_loop.body:                                    ; preds = %omp_loop.body.lr.ph, %omp_loop.body
  %omp_loop.iv66 = phi i32 [ 0, %omp_loop.body.lr.ph ], [ %omp_loop.next, %omp_loop.body ]
  %7 = add i32 %omp_loop.iv66, 1
  %8 = add i32 %7, %3
  %9 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %10 = sitofp i32 %9 to float
  %11 = fdiv contract float 1.000000e+00, %10
  %12 = fpext float %11 to double
  %.unpack = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  %.unpack6 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  %.unpack7 = load i32, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  %.unpack8 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  %.unpack9 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  %.unpack10 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  %.unpack11 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  %.unpack12.unpack.unpack = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  %.unpack12.unpack.unpack14 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  %.unpack12.unpack.unpack15 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  store ptr %.unpack, ptr %loadgep_2, align 8, !tbaa !8
  %loadgep_2.repack17 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  store i64 %.unpack6, ptr %loadgep_2.repack17, align 8, !tbaa !8
  %loadgep_2.repack19 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  store i32 %.unpack7, ptr %loadgep_2.repack19, align 8, !tbaa !8
  %loadgep_2.repack21 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  store i8 %.unpack8, ptr %loadgep_2.repack21, align 4, !tbaa !8
  %loadgep_2.repack23 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  store i8 %.unpack9, ptr %loadgep_2.repack23, align 1, !tbaa !8
  %loadgep_2.repack25 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  store i8 %.unpack10, ptr %loadgep_2.repack25, align 2, !tbaa !8
  %loadgep_2.repack27 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  store i8 %.unpack11, ptr %loadgep_2.repack27, align 1, !tbaa !8
  %loadgep_2.repack29 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  store i64 %.unpack12.unpack.unpack, ptr %loadgep_2.repack29, align 8, !tbaa !8
  %loadgep_2.repack29.repack31 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack12.unpack.unpack14, ptr %loadgep_2.repack29.repack31, align 8, !tbaa !8
  %loadgep_2.repack29.repack33 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  store i64 %.unpack12.unpack.unpack15, ptr %loadgep_2.repack29.repack33, align 8, !tbaa !8
  %13 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 0
  %14 = load i64, ptr %13, align 8, !tbaa !8
  %15 = sext i32 %8 to i64
  %16 = sub i64 %15, %14
  %17 = getelementptr double, ptr %.unpack, i64 %16
  store double %12, ptr %17, align 8, !tbaa !4
  store ptr %.unpack, ptr %loadgep_4, align 8, !tbaa !8
  %loadgep_4.repack47 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 1
  store i64 %.unpack6, ptr %loadgep_4.repack47, align 8, !tbaa !8
  %loadgep_4.repack49 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 2
  store i32 %.unpack7, ptr %loadgep_4.repack49, align 8, !tbaa !8
  %loadgep_4.repack51 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 3
  store i8 %.unpack8, ptr %loadgep_4.repack51, align 4, !tbaa !8
  %loadgep_4.repack53 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 4
  store i8 %.unpack9, ptr %loadgep_4.repack53, align 1, !tbaa !8
  %loadgep_4.repack55 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 5
  store i8 %.unpack10, ptr %loadgep_4.repack55, align 2, !tbaa !8
  %loadgep_4.repack57 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 6
  store i8 %.unpack11, ptr %loadgep_4.repack57, align 1, !tbaa !8
  %loadgep_4.repack59 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7
  store i64 %.unpack12.unpack.unpack, ptr %loadgep_4.repack59, align 8, !tbaa !8
  %loadgep_4.repack59.repack61 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack12.unpack.unpack14, ptr %loadgep_4.repack59.repack61, align 8, !tbaa !8
  %loadgep_4.repack59.repack63 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 2
  store i64 %.unpack12.unpack.unpack15, ptr %loadgep_4.repack59.repack63, align 8, !tbaa !8
  %omp_loop.next = add nuw i32 %omp_loop.iv66, 1
  %omp_loop.cmp = icmp ult i32 %omp_loop.next, %6
  br i1 %omp_loop.cmp, label %omp_loop.body, label %omp_loop.header.omp_loop.exit_crit_edge

; Exit blocks
omp_loop.header.omp_loop.exit_crit_edge:          ; preds = %omp_loop.body
  br label %omp_loop.exit
*** IR Dump After LICMPass on omp_loop.body ***

; Preheader:
omp_loop.body.lr.ph:                              ; preds = %omp.par.entry
  %.unpack = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  %.unpack6 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  %.unpack7 = load i32, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  %.unpack8 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  %.unpack9 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  %.unpack10 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  %.unpack11 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  %.unpack12.unpack.unpack = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  %.unpack12.unpack.unpack14 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  %.unpack12.unpack.unpack15 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  %loadgep_2.repack17 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  %loadgep_2.repack19 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  %loadgep_2.repack21 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  %loadgep_2.repack23 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  %loadgep_2.repack25 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  %loadgep_2.repack27 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  %loadgep_2.repack29 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  %loadgep_2.repack29.repack31 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  %loadgep_2.repack29.repack33 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  %7 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 0
  %loadgep_4.repack47 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 1
  %loadgep_4.repack49 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 2
  %loadgep_4.repack51 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 3
  %loadgep_4.repack53 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 4
  %loadgep_4.repack55 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 5
  %loadgep_4.repack57 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 6
  %loadgep_4.repack59 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7
  %loadgep_4.repack59.repack61 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 1
  %loadgep_4.repack59.repack63 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 2
  br label %omp_loop.body

; Loop:
omp_loop.body:                                    ; preds = %omp_loop.body.lr.ph, %omp_loop.body
  %omp_loop.iv66 = phi i32 [ 0, %omp_loop.body.lr.ph ], [ %omp_loop.next, %omp_loop.body ]
  %8 = add i32 %omp_loop.iv66, 1
  %9 = add i32 %8, %3
  %10 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %11 = sitofp i32 %10 to float
  %12 = fdiv contract float 1.000000e+00, %11
  %13 = fpext float %12 to double
  store ptr %.unpack, ptr %loadgep_2, align 8, !tbaa !8
  store i64 %.unpack6, ptr %loadgep_2.repack17, align 8, !tbaa !8
  store i32 %.unpack7, ptr %loadgep_2.repack19, align 8, !tbaa !8
  store i8 %.unpack8, ptr %loadgep_2.repack21, align 4, !tbaa !8
  store i8 %.unpack9, ptr %loadgep_2.repack23, align 1, !tbaa !8
  store i8 %.unpack10, ptr %loadgep_2.repack25, align 2, !tbaa !8
  store i8 %.unpack11, ptr %loadgep_2.repack27, align 1, !tbaa !8
  store i64 %.unpack12.unpack.unpack, ptr %loadgep_2.repack29, align 8, !tbaa !8
  store i64 %.unpack12.unpack.unpack14, ptr %loadgep_2.repack29.repack31, align 8, !tbaa !8
  store i64 %.unpack12.unpack.unpack15, ptr %loadgep_2.repack29.repack33, align 8, !tbaa !8
  %14 = load i64, ptr %7, align 8, !tbaa !8
  %15 = sext i32 %9 to i64
  %16 = sub i64 %15, %14
  %17 = getelementptr double, ptr %.unpack, i64 %16
  store double %13, ptr %17, align 8, !tbaa !4
  store ptr %.unpack, ptr %loadgep_4, align 8, !tbaa !8
  store i64 %.unpack6, ptr %loadgep_4.repack47, align 8, !tbaa !8
  store i32 %.unpack7, ptr %loadgep_4.repack49, align 8, !tbaa !8
  store i8 %.unpack8, ptr %loadgep_4.repack51, align 4, !tbaa !8
  store i8 %.unpack9, ptr %loadgep_4.repack53, align 1, !tbaa !8
  store i8 %.unpack10, ptr %loadgep_4.repack55, align 2, !tbaa !8
  store i8 %.unpack11, ptr %loadgep_4.repack57, align 1, !tbaa !8
  store i64 %.unpack12.unpack.unpack, ptr %loadgep_4.repack59, align 8, !tbaa !8
  store i64 %.unpack12.unpack.unpack14, ptr %loadgep_4.repack59.repack61, align 8, !tbaa !8
  store i64 %.unpack12.unpack.unpack15, ptr %loadgep_4.repack59.repack63, align 8, !tbaa !8
  %omp_loop.next = add nuw i32 %omp_loop.iv66, 1
  %omp_loop.cmp = icmp ult i32 %omp_loop.next, %6
  br i1 %omp_loop.cmp, label %omp_loop.body, label %omp_loop.header.omp_loop.exit_crit_edge

; Exit blocks
omp_loop.header.omp_loop.exit_crit_edge:          ; preds = %omp_loop.body
  br label %omp_loop.exit
*** IR Dump After SimpleLoopUnswitchPass on omp_loop.body ***

; Preheader:
omp_loop.body.lr.ph:                              ; preds = %omp.par.entry
  %.unpack = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  %.unpack6 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  %.unpack7 = load i32, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  %.unpack8 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  %.unpack9 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  %.unpack10 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  %.unpack11 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  %.unpack12.unpack.unpack = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  %.unpack12.unpack.unpack14 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  %.unpack12.unpack.unpack15 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  %loadgep_2.repack17 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  %loadgep_2.repack19 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  %loadgep_2.repack21 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  %loadgep_2.repack23 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  %loadgep_2.repack25 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  %loadgep_2.repack27 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  %loadgep_2.repack29 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  %loadgep_2.repack29.repack31 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  %loadgep_2.repack29.repack33 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  %7 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 0
  %loadgep_4.repack47 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 1
  %loadgep_4.repack49 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 2
  %loadgep_4.repack51 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 3
  %loadgep_4.repack53 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 4
  %loadgep_4.repack55 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 5
  %loadgep_4.repack57 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 6
  %loadgep_4.repack59 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7
  %loadgep_4.repack59.repack61 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 1
  %loadgep_4.repack59.repack63 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 2
  br label %omp_loop.body

; Loop:
omp_loop.body:                                    ; preds = %omp_loop.body.lr.ph, %omp_loop.body
  %omp_loop.iv66 = phi i32 [ 0, %omp_loop.body.lr.ph ], [ %omp_loop.next, %omp_loop.body ]
  %8 = add i32 %omp_loop.iv66, 1
  %9 = add i32 %8, %3
  %10 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %11 = sitofp i32 %10 to float
  %12 = fdiv contract float 1.000000e+00, %11
  %13 = fpext float %12 to double
  store ptr %.unpack, ptr %loadgep_2, align 8, !tbaa !8
  store i64 %.unpack6, ptr %loadgep_2.repack17, align 8, !tbaa !8
  store i32 %.unpack7, ptr %loadgep_2.repack19, align 8, !tbaa !8
  store i8 %.unpack8, ptr %loadgep_2.repack21, align 4, !tbaa !8
  store i8 %.unpack9, ptr %loadgep_2.repack23, align 1, !tbaa !8
  store i8 %.unpack10, ptr %loadgep_2.repack25, align 2, !tbaa !8
  store i8 %.unpack11, ptr %loadgep_2.repack27, align 1, !tbaa !8
  store i64 %.unpack12.unpack.unpack, ptr %loadgep_2.repack29, align 8, !tbaa !8
  store i64 %.unpack12.unpack.unpack14, ptr %loadgep_2.repack29.repack31, align 8, !tbaa !8
  store i64 %.unpack12.unpack.unpack15, ptr %loadgep_2.repack29.repack33, align 8, !tbaa !8
  %14 = load i64, ptr %7, align 8, !tbaa !8
  %15 = sext i32 %9 to i64
  %16 = sub i64 %15, %14
  %17 = getelementptr double, ptr %.unpack, i64 %16
  store double %13, ptr %17, align 8, !tbaa !4
  store ptr %.unpack, ptr %loadgep_4, align 8, !tbaa !8
  store i64 %.unpack6, ptr %loadgep_4.repack47, align 8, !tbaa !8
  store i32 %.unpack7, ptr %loadgep_4.repack49, align 8, !tbaa !8
  store i8 %.unpack8, ptr %loadgep_4.repack51, align 4, !tbaa !8
  store i8 %.unpack9, ptr %loadgep_4.repack53, align 1, !tbaa !8
  store i8 %.unpack10, ptr %loadgep_4.repack55, align 2, !tbaa !8
  store i8 %.unpack11, ptr %loadgep_4.repack57, align 1, !tbaa !8
  store i64 %.unpack12.unpack.unpack, ptr %loadgep_4.repack59, align 8, !tbaa !8
  store i64 %.unpack12.unpack.unpack14, ptr %loadgep_4.repack59.repack61, align 8, !tbaa !8
  store i64 %.unpack12.unpack.unpack15, ptr %loadgep_4.repack59.repack63, align 8, !tbaa !8
  %omp_loop.next = add nuw i32 %omp_loop.iv66, 1
  %omp_loop.cmp = icmp ult i32 %omp_loop.next, %6
  br i1 %omp_loop.cmp, label %omp_loop.body, label %omp_loop.header.omp_loop.exit_crit_edge

; Exit blocks
omp_loop.header.omp_loop.exit_crit_edge:          ; preds = %omp_loop.body
  br label %omp_loop.exit
*** IR Dump After SimplifyCFGPass on _QQmain..omp_par ***
; Function Attrs: norecurse nounwind
define internal void @_QQmain..omp_par(ptr noalias %tid.addr, ptr noalias %zero.addr, ptr %0) #2 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %gep_3 = getelementptr { ptr, ptr, ptr }, ptr %0, i64 0, i32 2
  %loadgep_4 = load ptr, ptr %gep_3, align 8
  %p.lastiter = alloca i32, align 4
  %p.lowerbound = alloca i32, align 4
  %p.upperbound = alloca i32, align 4
  %p.stride = alloca i32, align 4
  %1 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %omp_loop.tripcount = tail call i32 @llvm.smax.i32(i32 %1, i32 0)
  store i32 0, ptr %p.lowerbound, align 4
  %2 = add nsw i32 %omp_loop.tripcount, -1
  store i32 %2, ptr %p.upperbound, align 4
  store i32 1, ptr %p.stride, align 4
  %omp_global_thread_num4 = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  call void @__kmpc_for_static_init_4u(ptr nonnull @1, i32 %omp_global_thread_num4, i32 34, ptr nonnull %p.lastiter, ptr nonnull %p.lowerbound, ptr nonnull %p.upperbound, ptr nonnull %p.stride, i32 1, i32 0)
  %3 = load i32, ptr %p.lowerbound, align 4
  %4 = load i32, ptr %p.upperbound, align 4
  %.neg = sub i32 0, %3
  %5 = add i32 %.neg, 1
  %6 = add i32 %5, %4
  %omp_loop.cmp65 = icmp ult i32 0, %6
  br i1 %omp_loop.cmp65, label %omp_loop.body.lr.ph, label %omp_loop.exit

omp_loop.body.lr.ph:                              ; preds = %omp.par.entry
  %.unpack = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  %.unpack6 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  %.unpack7 = load i32, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  %.unpack8 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  %.unpack9 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  %.unpack10 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  %.unpack11 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  %.unpack12.unpack.unpack = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  %.unpack12.unpack.unpack14 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  %.unpack12.unpack.unpack15 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  %loadgep_2.repack17 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  %loadgep_2.repack19 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  %loadgep_2.repack21 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  %loadgep_2.repack23 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  %loadgep_2.repack25 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  %loadgep_2.repack27 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  %loadgep_2.repack29 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  %loadgep_2.repack29.repack31 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  %loadgep_2.repack29.repack33 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  %7 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 0
  %loadgep_4.repack47 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 1
  %loadgep_4.repack49 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 2
  %loadgep_4.repack51 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 3
  %loadgep_4.repack53 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 4
  %loadgep_4.repack55 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 5
  %loadgep_4.repack57 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 6
  %loadgep_4.repack59 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7
  %loadgep_4.repack59.repack61 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 1
  %loadgep_4.repack59.repack63 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 2
  br label %omp_loop.body

omp_loop.exit:                                    ; preds = %omp_loop.body, %omp.par.entry
  call void @__kmpc_for_static_fini(ptr nonnull @1, i32 %omp_global_thread_num4)
  call void @__kmpc_barrier(ptr nonnull @2, i32 %omp_global_thread_num4)
  ret void

omp_loop.body:                                    ; preds = %omp_loop.body.lr.ph, %omp_loop.body
  %omp_loop.iv66 = phi i32 [ 0, %omp_loop.body.lr.ph ], [ %omp_loop.next, %omp_loop.body ]
  %8 = add i32 %omp_loop.iv66, 1
  %9 = add i32 %8, %3
  %10 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %11 = sitofp i32 %10 to float
  %12 = fdiv contract float 1.000000e+00, %11
  %13 = fpext float %12 to double
  store ptr %.unpack, ptr %loadgep_2, align 8, !tbaa !8
  store i64 %.unpack6, ptr %loadgep_2.repack17, align 8, !tbaa !8
  store i32 %.unpack7, ptr %loadgep_2.repack19, align 8, !tbaa !8
  store i8 %.unpack8, ptr %loadgep_2.repack21, align 4, !tbaa !8
  store i8 %.unpack9, ptr %loadgep_2.repack23, align 1, !tbaa !8
  store i8 %.unpack10, ptr %loadgep_2.repack25, align 2, !tbaa !8
  store i8 %.unpack11, ptr %loadgep_2.repack27, align 1, !tbaa !8
  store i64 %.unpack12.unpack.unpack, ptr %loadgep_2.repack29, align 8, !tbaa !8
  store i64 %.unpack12.unpack.unpack14, ptr %loadgep_2.repack29.repack31, align 8, !tbaa !8
  store i64 %.unpack12.unpack.unpack15, ptr %loadgep_2.repack29.repack33, align 8, !tbaa !8
  %14 = load i64, ptr %7, align 8, !tbaa !8
  %15 = sext i32 %9 to i64
  %16 = sub i64 %15, %14
  %17 = getelementptr double, ptr %.unpack, i64 %16
  store double %13, ptr %17, align 8, !tbaa !4
  store ptr %.unpack, ptr %loadgep_4, align 8, !tbaa !8
  store i64 %.unpack6, ptr %loadgep_4.repack47, align 8, !tbaa !8
  store i32 %.unpack7, ptr %loadgep_4.repack49, align 8, !tbaa !8
  store i8 %.unpack8, ptr %loadgep_4.repack51, align 4, !tbaa !8
  store i8 %.unpack9, ptr %loadgep_4.repack53, align 1, !tbaa !8
  store i8 %.unpack10, ptr %loadgep_4.repack55, align 2, !tbaa !8
  store i8 %.unpack11, ptr %loadgep_4.repack57, align 1, !tbaa !8
  store i64 %.unpack12.unpack.unpack, ptr %loadgep_4.repack59, align 8, !tbaa !8
  store i64 %.unpack12.unpack.unpack14, ptr %loadgep_4.repack59.repack61, align 8, !tbaa !8
  store i64 %.unpack12.unpack.unpack15, ptr %loadgep_4.repack59.repack63, align 8, !tbaa !8
  %omp_loop.next = add nuw i32 %omp_loop.iv66, 1
  %omp_loop.cmp = icmp ult i32 %omp_loop.next, %6
  br i1 %omp_loop.cmp, label %omp_loop.body, label %omp_loop.exit
}
*** IR Dump After InstCombinePass on _QQmain..omp_par ***
; Function Attrs: norecurse nounwind
define internal void @_QQmain..omp_par(ptr noalias %tid.addr, ptr noalias %zero.addr, ptr %0) #2 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %gep_3 = getelementptr { ptr, ptr, ptr }, ptr %0, i64 0, i32 2
  %loadgep_4 = load ptr, ptr %gep_3, align 8
  %p.lastiter = alloca i32, align 4
  %p.lowerbound = alloca i32, align 4
  %p.upperbound = alloca i32, align 4
  %p.stride = alloca i32, align 4
  %1 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %omp_loop.tripcount = tail call i32 @llvm.smax.i32(i32 %1, i32 0)
  store i32 0, ptr %p.lowerbound, align 4
  %2 = add nsw i32 %omp_loop.tripcount, -1
  store i32 %2, ptr %p.upperbound, align 4
  store i32 1, ptr %p.stride, align 4
  %omp_global_thread_num4 = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  call void @__kmpc_for_static_init_4u(ptr nonnull @1, i32 %omp_global_thread_num4, i32 34, ptr nonnull %p.lastiter, ptr nonnull %p.lowerbound, ptr nonnull %p.upperbound, ptr nonnull %p.stride, i32 1, i32 0)
  %3 = load i32, ptr %p.lowerbound, align 4
  %4 = load i32, ptr %p.upperbound, align 4
  %reass.sub = sub i32 %4, %3
  %5 = add i32 %reass.sub, 1
  %omp_loop.cmp65.not = icmp eq i32 %5, 0
  br i1 %omp_loop.cmp65.not, label %omp_loop.exit, label %omp_loop.body.lr.ph

omp_loop.body.lr.ph:                              ; preds = %omp.par.entry
  %.unpack = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  %.unpack6 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  %.unpack7 = load i32, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  %.unpack8 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  %.unpack9 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  %.unpack10 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  %.unpack11 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  %.unpack12.unpack.unpack = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  %.unpack12.unpack.unpack14 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  %.unpack12.unpack.unpack15 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  %loadgep_2.repack17 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  %loadgep_2.repack19 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  %loadgep_2.repack21 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  %loadgep_2.repack23 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  %loadgep_2.repack25 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  %loadgep_2.repack27 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  %loadgep_2.repack29 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  %loadgep_2.repack29.repack31 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  %loadgep_2.repack29.repack33 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  %6 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 0
  %loadgep_4.repack47 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 1
  %loadgep_4.repack49 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 2
  %loadgep_4.repack51 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 3
  %loadgep_4.repack53 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 4
  %loadgep_4.repack55 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 5
  %loadgep_4.repack57 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 6
  %loadgep_4.repack59 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7
  %loadgep_4.repack59.repack61 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 1
  %loadgep_4.repack59.repack63 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 2
  br label %omp_loop.body

omp_loop.exit:                                    ; preds = %omp_loop.body, %omp.par.entry
  call void @__kmpc_for_static_fini(ptr nonnull @1, i32 %omp_global_thread_num4)
  call void @__kmpc_barrier(ptr nonnull @2, i32 %omp_global_thread_num4)
  ret void

omp_loop.body:                                    ; preds = %omp_loop.body.lr.ph, %omp_loop.body
  %omp_loop.iv66 = phi i32 [ 0, %omp_loop.body.lr.ph ], [ %omp_loop.next, %omp_loop.body ]
  %7 = add i32 %omp_loop.iv66, 1
  %8 = add i32 %7, %3
  %9 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %10 = sitofp i32 %9 to float
  %11 = fdiv contract float 1.000000e+00, %10
  %12 = fpext float %11 to double
  store ptr %.unpack, ptr %loadgep_2, align 8, !tbaa !8
  store i64 %.unpack6, ptr %loadgep_2.repack17, align 8, !tbaa !8
  store i32 %.unpack7, ptr %loadgep_2.repack19, align 8, !tbaa !8
  store i8 %.unpack8, ptr %loadgep_2.repack21, align 4, !tbaa !8
  store i8 %.unpack9, ptr %loadgep_2.repack23, align 1, !tbaa !8
  store i8 %.unpack10, ptr %loadgep_2.repack25, align 2, !tbaa !8
  store i8 %.unpack11, ptr %loadgep_2.repack27, align 1, !tbaa !8
  store i64 %.unpack12.unpack.unpack, ptr %loadgep_2.repack29, align 8, !tbaa !8
  store i64 %.unpack12.unpack.unpack14, ptr %loadgep_2.repack29.repack31, align 8, !tbaa !8
  store i64 %.unpack12.unpack.unpack15, ptr %loadgep_2.repack29.repack33, align 8, !tbaa !8
  %13 = load i64, ptr %6, align 8, !tbaa !8
  %14 = sext i32 %8 to i64
  %15 = sub i64 %14, %13
  %16 = getelementptr double, ptr %.unpack, i64 %15
  store double %12, ptr %16, align 8, !tbaa !4
  store ptr %.unpack, ptr %loadgep_4, align 8, !tbaa !8
  store i64 %.unpack6, ptr %loadgep_4.repack47, align 8, !tbaa !8
  store i32 %.unpack7, ptr %loadgep_4.repack49, align 8, !tbaa !8
  store i8 %.unpack8, ptr %loadgep_4.repack51, align 4, !tbaa !8
  store i8 %.unpack9, ptr %loadgep_4.repack53, align 1, !tbaa !8
  store i8 %.unpack10, ptr %loadgep_4.repack55, align 2, !tbaa !8
  store i8 %.unpack11, ptr %loadgep_4.repack57, align 1, !tbaa !8
  store i64 %.unpack12.unpack.unpack, ptr %loadgep_4.repack59, align 8, !tbaa !8
  store i64 %.unpack12.unpack.unpack14, ptr %loadgep_4.repack59.repack61, align 8, !tbaa !8
  store i64 %.unpack12.unpack.unpack15, ptr %loadgep_4.repack59.repack63, align 8, !tbaa !8
  %omp_loop.next = add nuw i32 %omp_loop.iv66, 1
  %omp_loop.cmp = icmp ult i32 %omp_loop.next, %5
  br i1 %omp_loop.cmp, label %omp_loop.body, label %omp_loop.exit
}
*** IR Dump After LoopSimplifyPass on _QQmain..omp_par ***
; Function Attrs: norecurse nounwind
define internal void @_QQmain..omp_par(ptr noalias %tid.addr, ptr noalias %zero.addr, ptr %0) #2 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %gep_3 = getelementptr { ptr, ptr, ptr }, ptr %0, i64 0, i32 2
  %loadgep_4 = load ptr, ptr %gep_3, align 8
  %p.lastiter = alloca i32, align 4
  %p.lowerbound = alloca i32, align 4
  %p.upperbound = alloca i32, align 4
  %p.stride = alloca i32, align 4
  %1 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %omp_loop.tripcount = tail call i32 @llvm.smax.i32(i32 %1, i32 0)
  store i32 0, ptr %p.lowerbound, align 4
  %2 = add nsw i32 %omp_loop.tripcount, -1
  store i32 %2, ptr %p.upperbound, align 4
  store i32 1, ptr %p.stride, align 4
  %omp_global_thread_num4 = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  call void @__kmpc_for_static_init_4u(ptr nonnull @1, i32 %omp_global_thread_num4, i32 34, ptr nonnull %p.lastiter, ptr nonnull %p.lowerbound, ptr nonnull %p.upperbound, ptr nonnull %p.stride, i32 1, i32 0)
  %3 = load i32, ptr %p.lowerbound, align 4
  %4 = load i32, ptr %p.upperbound, align 4
  %reass.sub = sub i32 %4, %3
  %5 = add i32 %reass.sub, 1
  %omp_loop.cmp65.not = icmp eq i32 %5, 0
  br i1 %omp_loop.cmp65.not, label %omp_loop.exit, label %omp_loop.body.lr.ph

omp_loop.body.lr.ph:                              ; preds = %omp.par.entry
  %.unpack = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  %.unpack6 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  %.unpack7 = load i32, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  %.unpack8 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  %.unpack9 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  %.unpack10 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  %.unpack11 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  %.unpack12.unpack.unpack = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  %.unpack12.unpack.unpack14 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  %.unpack12.unpack.unpack15 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  %loadgep_2.repack17 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  %loadgep_2.repack19 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  %loadgep_2.repack21 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  %loadgep_2.repack23 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  %loadgep_2.repack25 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  %loadgep_2.repack27 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  %loadgep_2.repack29 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  %loadgep_2.repack29.repack31 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  %loadgep_2.repack29.repack33 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  %6 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 0
  %loadgep_4.repack47 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 1
  %loadgep_4.repack49 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 2
  %loadgep_4.repack51 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 3
  %loadgep_4.repack53 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 4
  %loadgep_4.repack55 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 5
  %loadgep_4.repack57 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 6
  %loadgep_4.repack59 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7
  %loadgep_4.repack59.repack61 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 1
  %loadgep_4.repack59.repack63 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 2
  br label %omp_loop.body

omp_loop.exit.loopexit:                           ; preds = %omp_loop.body
  br label %omp_loop.exit

omp_loop.exit:                                    ; preds = %omp_loop.exit.loopexit, %omp.par.entry
  call void @__kmpc_for_static_fini(ptr nonnull @1, i32 %omp_global_thread_num4)
  call void @__kmpc_barrier(ptr nonnull @2, i32 %omp_global_thread_num4)
  ret void

omp_loop.body:                                    ; preds = %omp_loop.body.lr.ph, %omp_loop.body
  %omp_loop.iv66 = phi i32 [ 0, %omp_loop.body.lr.ph ], [ %omp_loop.next, %omp_loop.body ]
  %7 = add i32 %omp_loop.iv66, 1
  %8 = add i32 %7, %3
  %9 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %10 = sitofp i32 %9 to float
  %11 = fdiv contract float 1.000000e+00, %10
  %12 = fpext float %11 to double
  store ptr %.unpack, ptr %loadgep_2, align 8, !tbaa !8
  store i64 %.unpack6, ptr %loadgep_2.repack17, align 8, !tbaa !8
  store i32 %.unpack7, ptr %loadgep_2.repack19, align 8, !tbaa !8
  store i8 %.unpack8, ptr %loadgep_2.repack21, align 4, !tbaa !8
  store i8 %.unpack9, ptr %loadgep_2.repack23, align 1, !tbaa !8
  store i8 %.unpack10, ptr %loadgep_2.repack25, align 2, !tbaa !8
  store i8 %.unpack11, ptr %loadgep_2.repack27, align 1, !tbaa !8
  store i64 %.unpack12.unpack.unpack, ptr %loadgep_2.repack29, align 8, !tbaa !8
  store i64 %.unpack12.unpack.unpack14, ptr %loadgep_2.repack29.repack31, align 8, !tbaa !8
  store i64 %.unpack12.unpack.unpack15, ptr %loadgep_2.repack29.repack33, align 8, !tbaa !8
  %13 = load i64, ptr %6, align 8, !tbaa !8
  %14 = sext i32 %8 to i64
  %15 = sub i64 %14, %13
  %16 = getelementptr double, ptr %.unpack, i64 %15
  store double %12, ptr %16, align 8, !tbaa !4
  store ptr %.unpack, ptr %loadgep_4, align 8, !tbaa !8
  store i64 %.unpack6, ptr %loadgep_4.repack47, align 8, !tbaa !8
  store i32 %.unpack7, ptr %loadgep_4.repack49, align 8, !tbaa !8
  store i8 %.unpack8, ptr %loadgep_4.repack51, align 4, !tbaa !8
  store i8 %.unpack9, ptr %loadgep_4.repack53, align 1, !tbaa !8
  store i8 %.unpack10, ptr %loadgep_4.repack55, align 2, !tbaa !8
  store i8 %.unpack11, ptr %loadgep_4.repack57, align 1, !tbaa !8
  store i64 %.unpack12.unpack.unpack, ptr %loadgep_4.repack59, align 8, !tbaa !8
  store i64 %.unpack12.unpack.unpack14, ptr %loadgep_4.repack59.repack61, align 8, !tbaa !8
  store i64 %.unpack12.unpack.unpack15, ptr %loadgep_4.repack59.repack63, align 8, !tbaa !8
  %omp_loop.next = add nuw i32 %omp_loop.iv66, 1
  %omp_loop.cmp = icmp ult i32 %omp_loop.next, %5
  br i1 %omp_loop.cmp, label %omp_loop.body, label %omp_loop.exit.loopexit
}
*** IR Dump After LCSSAPass on _QQmain..omp_par ***
; Function Attrs: norecurse nounwind
define internal void @_QQmain..omp_par(ptr noalias %tid.addr, ptr noalias %zero.addr, ptr %0) #2 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %gep_3 = getelementptr { ptr, ptr, ptr }, ptr %0, i64 0, i32 2
  %loadgep_4 = load ptr, ptr %gep_3, align 8
  %p.lastiter = alloca i32, align 4
  %p.lowerbound = alloca i32, align 4
  %p.upperbound = alloca i32, align 4
  %p.stride = alloca i32, align 4
  %1 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %omp_loop.tripcount = tail call i32 @llvm.smax.i32(i32 %1, i32 0)
  store i32 0, ptr %p.lowerbound, align 4
  %2 = add nsw i32 %omp_loop.tripcount, -1
  store i32 %2, ptr %p.upperbound, align 4
  store i32 1, ptr %p.stride, align 4
  %omp_global_thread_num4 = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  call void @__kmpc_for_static_init_4u(ptr nonnull @1, i32 %omp_global_thread_num4, i32 34, ptr nonnull %p.lastiter, ptr nonnull %p.lowerbound, ptr nonnull %p.upperbound, ptr nonnull %p.stride, i32 1, i32 0)
  %3 = load i32, ptr %p.lowerbound, align 4
  %4 = load i32, ptr %p.upperbound, align 4
  %reass.sub = sub i32 %4, %3
  %5 = add i32 %reass.sub, 1
  %omp_loop.cmp65.not = icmp eq i32 %5, 0
  br i1 %omp_loop.cmp65.not, label %omp_loop.exit, label %omp_loop.body.lr.ph

omp_loop.body.lr.ph:                              ; preds = %omp.par.entry
  %.unpack = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  %.unpack6 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  %.unpack7 = load i32, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  %.unpack8 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  %.unpack9 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  %.unpack10 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  %.unpack11 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  %.unpack12.unpack.unpack = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  %.unpack12.unpack.unpack14 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  %.unpack12.unpack.unpack15 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  %loadgep_2.repack17 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  %loadgep_2.repack19 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  %loadgep_2.repack21 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  %loadgep_2.repack23 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  %loadgep_2.repack25 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  %loadgep_2.repack27 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  %loadgep_2.repack29 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  %loadgep_2.repack29.repack31 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  %loadgep_2.repack29.repack33 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  %6 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 0
  %loadgep_4.repack47 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 1
  %loadgep_4.repack49 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 2
  %loadgep_4.repack51 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 3
  %loadgep_4.repack53 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 4
  %loadgep_4.repack55 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 5
  %loadgep_4.repack57 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 6
  %loadgep_4.repack59 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7
  %loadgep_4.repack59.repack61 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 1
  %loadgep_4.repack59.repack63 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 2
  br label %omp_loop.body

omp_loop.exit.loopexit:                           ; preds = %omp_loop.body
  br label %omp_loop.exit

omp_loop.exit:                                    ; preds = %omp_loop.exit.loopexit, %omp.par.entry
  call void @__kmpc_for_static_fini(ptr nonnull @1, i32 %omp_global_thread_num4)
  call void @__kmpc_barrier(ptr nonnull @2, i32 %omp_global_thread_num4)
  ret void

omp_loop.body:                                    ; preds = %omp_loop.body.lr.ph, %omp_loop.body
  %omp_loop.iv66 = phi i32 [ 0, %omp_loop.body.lr.ph ], [ %omp_loop.next, %omp_loop.body ]
  %7 = add i32 %omp_loop.iv66, 1
  %8 = add i32 %7, %3
  %9 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %10 = sitofp i32 %9 to float
  %11 = fdiv contract float 1.000000e+00, %10
  %12 = fpext float %11 to double
  store ptr %.unpack, ptr %loadgep_2, align 8, !tbaa !8
  store i64 %.unpack6, ptr %loadgep_2.repack17, align 8, !tbaa !8
  store i32 %.unpack7, ptr %loadgep_2.repack19, align 8, !tbaa !8
  store i8 %.unpack8, ptr %loadgep_2.repack21, align 4, !tbaa !8
  store i8 %.unpack9, ptr %loadgep_2.repack23, align 1, !tbaa !8
  store i8 %.unpack10, ptr %loadgep_2.repack25, align 2, !tbaa !8
  store i8 %.unpack11, ptr %loadgep_2.repack27, align 1, !tbaa !8
  store i64 %.unpack12.unpack.unpack, ptr %loadgep_2.repack29, align 8, !tbaa !8
  store i64 %.unpack12.unpack.unpack14, ptr %loadgep_2.repack29.repack31, align 8, !tbaa !8
  store i64 %.unpack12.unpack.unpack15, ptr %loadgep_2.repack29.repack33, align 8, !tbaa !8
  %13 = load i64, ptr %6, align 8, !tbaa !8
  %14 = sext i32 %8 to i64
  %15 = sub i64 %14, %13
  %16 = getelementptr double, ptr %.unpack, i64 %15
  store double %12, ptr %16, align 8, !tbaa !4
  store ptr %.unpack, ptr %loadgep_4, align 8, !tbaa !8
  store i64 %.unpack6, ptr %loadgep_4.repack47, align 8, !tbaa !8
  store i32 %.unpack7, ptr %loadgep_4.repack49, align 8, !tbaa !8
  store i8 %.unpack8, ptr %loadgep_4.repack51, align 4, !tbaa !8
  store i8 %.unpack9, ptr %loadgep_4.repack53, align 1, !tbaa !8
  store i8 %.unpack10, ptr %loadgep_4.repack55, align 2, !tbaa !8
  store i8 %.unpack11, ptr %loadgep_4.repack57, align 1, !tbaa !8
  store i64 %.unpack12.unpack.unpack, ptr %loadgep_4.repack59, align 8, !tbaa !8
  store i64 %.unpack12.unpack.unpack14, ptr %loadgep_4.repack59.repack61, align 8, !tbaa !8
  store i64 %.unpack12.unpack.unpack15, ptr %loadgep_4.repack59.repack63, align 8, !tbaa !8
  %omp_loop.next = add nuw i32 %omp_loop.iv66, 1
  %omp_loop.cmp = icmp ult i32 %omp_loop.next, %5
  br i1 %omp_loop.cmp, label %omp_loop.body, label %omp_loop.exit.loopexit
}
*** IR Dump After LoopIdiomRecognizePass on omp_loop.body ***

; Preheader:
omp_loop.body.lr.ph:                              ; preds = %omp.par.entry
  %.unpack = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  %.unpack6 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  %.unpack7 = load i32, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  %.unpack8 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  %.unpack9 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  %.unpack10 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  %.unpack11 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  %.unpack12.unpack.unpack = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  %.unpack12.unpack.unpack14 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  %.unpack12.unpack.unpack15 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  %loadgep_2.repack17 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  %loadgep_2.repack19 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  %loadgep_2.repack21 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  %loadgep_2.repack23 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  %loadgep_2.repack25 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  %loadgep_2.repack27 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  %loadgep_2.repack29 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  %loadgep_2.repack29.repack31 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  %loadgep_2.repack29.repack33 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  %6 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 0
  %loadgep_4.repack47 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 1
  %loadgep_4.repack49 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 2
  %loadgep_4.repack51 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 3
  %loadgep_4.repack53 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 4
  %loadgep_4.repack55 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 5
  %loadgep_4.repack57 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 6
  %loadgep_4.repack59 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7
  %loadgep_4.repack59.repack61 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 1
  %loadgep_4.repack59.repack63 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 2
  br label %omp_loop.body

; Loop:
omp_loop.body:                                    ; preds = %omp_loop.body.lr.ph, %omp_loop.body
  %omp_loop.iv66 = phi i32 [ 0, %omp_loop.body.lr.ph ], [ %omp_loop.next, %omp_loop.body ]
  %7 = add i32 %omp_loop.iv66, 1
  %8 = add i32 %7, %3
  %9 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %10 = sitofp i32 %9 to float
  %11 = fdiv contract float 1.000000e+00, %10
  %12 = fpext float %11 to double
  store ptr %.unpack, ptr %loadgep_2, align 8, !tbaa !8
  store i64 %.unpack6, ptr %loadgep_2.repack17, align 8, !tbaa !8
  store i32 %.unpack7, ptr %loadgep_2.repack19, align 8, !tbaa !8
  store i8 %.unpack8, ptr %loadgep_2.repack21, align 4, !tbaa !8
  store i8 %.unpack9, ptr %loadgep_2.repack23, align 1, !tbaa !8
  store i8 %.unpack10, ptr %loadgep_2.repack25, align 2, !tbaa !8
  store i8 %.unpack11, ptr %loadgep_2.repack27, align 1, !tbaa !8
  store i64 %.unpack12.unpack.unpack, ptr %loadgep_2.repack29, align 8, !tbaa !8
  store i64 %.unpack12.unpack.unpack14, ptr %loadgep_2.repack29.repack31, align 8, !tbaa !8
  store i64 %.unpack12.unpack.unpack15, ptr %loadgep_2.repack29.repack33, align 8, !tbaa !8
  %13 = load i64, ptr %6, align 8, !tbaa !8
  %14 = sext i32 %8 to i64
  %15 = sub i64 %14, %13
  %16 = getelementptr double, ptr %.unpack, i64 %15
  store double %12, ptr %16, align 8, !tbaa !4
  store ptr %.unpack, ptr %loadgep_4, align 8, !tbaa !8
  store i64 %.unpack6, ptr %loadgep_4.repack47, align 8, !tbaa !8
  store i32 %.unpack7, ptr %loadgep_4.repack49, align 8, !tbaa !8
  store i8 %.unpack8, ptr %loadgep_4.repack51, align 4, !tbaa !8
  store i8 %.unpack9, ptr %loadgep_4.repack53, align 1, !tbaa !8
  store i8 %.unpack10, ptr %loadgep_4.repack55, align 2, !tbaa !8
  store i8 %.unpack11, ptr %loadgep_4.repack57, align 1, !tbaa !8
  store i64 %.unpack12.unpack.unpack, ptr %loadgep_4.repack59, align 8, !tbaa !8
  store i64 %.unpack12.unpack.unpack14, ptr %loadgep_4.repack59.repack61, align 8, !tbaa !8
  store i64 %.unpack12.unpack.unpack15, ptr %loadgep_4.repack59.repack63, align 8, !tbaa !8
  %omp_loop.next = add nuw i32 %omp_loop.iv66, 1
  %omp_loop.cmp = icmp ult i32 %omp_loop.next, %5
  br i1 %omp_loop.cmp, label %omp_loop.body, label %omp_loop.exit.loopexit

; Exit blocks
omp_loop.exit.loopexit:                           ; preds = %omp_loop.body
  br label %omp_loop.exit
*** IR Dump After IndVarSimplifyPass on omp_loop.body ***

; Preheader:
omp_loop.body.lr.ph:                              ; preds = %omp.par.entry
  %.unpack = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  %.unpack6 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  %.unpack7 = load i32, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  %.unpack8 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  %.unpack9 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  %.unpack10 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  %.unpack11 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  %.unpack12.unpack.unpack = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  %.unpack12.unpack.unpack14 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  %.unpack12.unpack.unpack15 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  %loadgep_2.repack17 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  %loadgep_2.repack19 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  %loadgep_2.repack21 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  %loadgep_2.repack23 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  %loadgep_2.repack25 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  %loadgep_2.repack27 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  %loadgep_2.repack29 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  %loadgep_2.repack29.repack31 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  %loadgep_2.repack29.repack33 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  %6 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 0
  %loadgep_4.repack47 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 1
  %loadgep_4.repack49 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 2
  %loadgep_4.repack51 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 3
  %loadgep_4.repack53 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 4
  %loadgep_4.repack55 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 5
  %loadgep_4.repack57 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 6
  %loadgep_4.repack59 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7
  %loadgep_4.repack59.repack61 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 1
  %loadgep_4.repack59.repack63 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 2
  br label %omp_loop.body

; Loop:
omp_loop.body:                                    ; preds = %omp_loop.body.lr.ph, %omp_loop.body
  %omp_loop.iv66 = phi i32 [ 0, %omp_loop.body.lr.ph ], [ %omp_loop.next, %omp_loop.body ]
  %7 = add nuw i32 %omp_loop.iv66, 1
  %8 = add i32 %7, %3
  %9 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %10 = sitofp i32 %9 to float
  %11 = fdiv contract float 1.000000e+00, %10
  %12 = fpext float %11 to double
  store ptr %.unpack, ptr %loadgep_2, align 8, !tbaa !8
  store i64 %.unpack6, ptr %loadgep_2.repack17, align 8, !tbaa !8
  store i32 %.unpack7, ptr %loadgep_2.repack19, align 8, !tbaa !8
  store i8 %.unpack8, ptr %loadgep_2.repack21, align 4, !tbaa !8
  store i8 %.unpack9, ptr %loadgep_2.repack23, align 1, !tbaa !8
  store i8 %.unpack10, ptr %loadgep_2.repack25, align 2, !tbaa !8
  store i8 %.unpack11, ptr %loadgep_2.repack27, align 1, !tbaa !8
  store i64 %.unpack12.unpack.unpack, ptr %loadgep_2.repack29, align 8, !tbaa !8
  store i64 %.unpack12.unpack.unpack14, ptr %loadgep_2.repack29.repack31, align 8, !tbaa !8
  store i64 %.unpack12.unpack.unpack15, ptr %loadgep_2.repack29.repack33, align 8, !tbaa !8
  %13 = load i64, ptr %6, align 8, !tbaa !8
  %14 = sext i32 %8 to i64
  %15 = sub i64 %14, %13
  %16 = getelementptr double, ptr %.unpack, i64 %15
  store double %12, ptr %16, align 8, !tbaa !4
  store ptr %.unpack, ptr %loadgep_4, align 8, !tbaa !8
  store i64 %.unpack6, ptr %loadgep_4.repack47, align 8, !tbaa !8
  store i32 %.unpack7, ptr %loadgep_4.repack49, align 8, !tbaa !8
  store i8 %.unpack8, ptr %loadgep_4.repack51, align 4, !tbaa !8
  store i8 %.unpack9, ptr %loadgep_4.repack53, align 1, !tbaa !8
  store i8 %.unpack10, ptr %loadgep_4.repack55, align 2, !tbaa !8
  store i8 %.unpack11, ptr %loadgep_4.repack57, align 1, !tbaa !8
  store i64 %.unpack12.unpack.unpack, ptr %loadgep_4.repack59, align 8, !tbaa !8
  store i64 %.unpack12.unpack.unpack14, ptr %loadgep_4.repack59.repack61, align 8, !tbaa !8
  store i64 %.unpack12.unpack.unpack15, ptr %loadgep_4.repack59.repack63, align 8, !tbaa !8
  %omp_loop.next = add nuw i32 %omp_loop.iv66, 1
  %exitcond = icmp ne i32 %omp_loop.next, %5
  br i1 %exitcond, label %omp_loop.body, label %omp_loop.exit.loopexit

; Exit blocks
omp_loop.exit.loopexit:                           ; preds = %omp_loop.body
  br label %omp_loop.exit
*** IR Dump After LoopDeletionPass on omp_loop.body ***

; Preheader:
omp_loop.body.lr.ph:                              ; preds = %omp.par.entry
  %.unpack = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  %.unpack6 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  %.unpack7 = load i32, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  %.unpack8 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  %.unpack9 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  %.unpack10 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  %.unpack11 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  %.unpack12.unpack.unpack = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  %.unpack12.unpack.unpack14 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  %.unpack12.unpack.unpack15 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  %loadgep_2.repack17 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  %loadgep_2.repack19 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  %loadgep_2.repack21 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  %loadgep_2.repack23 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  %loadgep_2.repack25 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  %loadgep_2.repack27 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  %loadgep_2.repack29 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  %loadgep_2.repack29.repack31 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  %loadgep_2.repack29.repack33 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  %6 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 0
  %loadgep_4.repack47 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 1
  %loadgep_4.repack49 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 2
  %loadgep_4.repack51 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 3
  %loadgep_4.repack53 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 4
  %loadgep_4.repack55 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 5
  %loadgep_4.repack57 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 6
  %loadgep_4.repack59 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7
  %loadgep_4.repack59.repack61 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 1
  %loadgep_4.repack59.repack63 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 2
  br label %omp_loop.body

; Loop:
omp_loop.body:                                    ; preds = %omp_loop.body.lr.ph, %omp_loop.body
  %omp_loop.iv66 = phi i32 [ 0, %omp_loop.body.lr.ph ], [ %omp_loop.next, %omp_loop.body ]
  %7 = add nuw i32 %omp_loop.iv66, 1
  %8 = add i32 %7, %3
  %9 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %10 = sitofp i32 %9 to float
  %11 = fdiv contract float 1.000000e+00, %10
  %12 = fpext float %11 to double
  store ptr %.unpack, ptr %loadgep_2, align 8, !tbaa !8
  store i64 %.unpack6, ptr %loadgep_2.repack17, align 8, !tbaa !8
  store i32 %.unpack7, ptr %loadgep_2.repack19, align 8, !tbaa !8
  store i8 %.unpack8, ptr %loadgep_2.repack21, align 4, !tbaa !8
  store i8 %.unpack9, ptr %loadgep_2.repack23, align 1, !tbaa !8
  store i8 %.unpack10, ptr %loadgep_2.repack25, align 2, !tbaa !8
  store i8 %.unpack11, ptr %loadgep_2.repack27, align 1, !tbaa !8
  store i64 %.unpack12.unpack.unpack, ptr %loadgep_2.repack29, align 8, !tbaa !8
  store i64 %.unpack12.unpack.unpack14, ptr %loadgep_2.repack29.repack31, align 8, !tbaa !8
  store i64 %.unpack12.unpack.unpack15, ptr %loadgep_2.repack29.repack33, align 8, !tbaa !8
  %13 = load i64, ptr %6, align 8, !tbaa !8
  %14 = sext i32 %8 to i64
  %15 = sub i64 %14, %13
  %16 = getelementptr double, ptr %.unpack, i64 %15
  store double %12, ptr %16, align 8, !tbaa !4
  store ptr %.unpack, ptr %loadgep_4, align 8, !tbaa !8
  store i64 %.unpack6, ptr %loadgep_4.repack47, align 8, !tbaa !8
  store i32 %.unpack7, ptr %loadgep_4.repack49, align 8, !tbaa !8
  store i8 %.unpack8, ptr %loadgep_4.repack51, align 4, !tbaa !8
  store i8 %.unpack9, ptr %loadgep_4.repack53, align 1, !tbaa !8
  store i8 %.unpack10, ptr %loadgep_4.repack55, align 2, !tbaa !8
  store i8 %.unpack11, ptr %loadgep_4.repack57, align 1, !tbaa !8
  store i64 %.unpack12.unpack.unpack, ptr %loadgep_4.repack59, align 8, !tbaa !8
  store i64 %.unpack12.unpack.unpack14, ptr %loadgep_4.repack59.repack61, align 8, !tbaa !8
  store i64 %.unpack12.unpack.unpack15, ptr %loadgep_4.repack59.repack63, align 8, !tbaa !8
  %omp_loop.next = add nuw i32 %omp_loop.iv66, 1
  %exitcond = icmp ne i32 %omp_loop.next, %5
  br i1 %exitcond, label %omp_loop.body, label %omp_loop.exit.loopexit

; Exit blocks
omp_loop.exit.loopexit:                           ; preds = %omp_loop.body
  br label %omp_loop.exit
*** IR Dump After LoopFullUnrollPass on omp_loop.body ***

; Preheader:
omp_loop.body.lr.ph:                              ; preds = %omp.par.entry
  %.unpack = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  %.unpack6 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  %.unpack7 = load i32, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  %.unpack8 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  %.unpack9 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  %.unpack10 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  %.unpack11 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  %.unpack12.unpack.unpack = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  %.unpack12.unpack.unpack14 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  %.unpack12.unpack.unpack15 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  %loadgep_2.repack17 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  %loadgep_2.repack19 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  %loadgep_2.repack21 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  %loadgep_2.repack23 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  %loadgep_2.repack25 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  %loadgep_2.repack27 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  %loadgep_2.repack29 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  %loadgep_2.repack29.repack31 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  %loadgep_2.repack29.repack33 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  %6 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 0
  %loadgep_4.repack47 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 1
  %loadgep_4.repack49 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 2
  %loadgep_4.repack51 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 3
  %loadgep_4.repack53 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 4
  %loadgep_4.repack55 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 5
  %loadgep_4.repack57 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 6
  %loadgep_4.repack59 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7
  %loadgep_4.repack59.repack61 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 1
  %loadgep_4.repack59.repack63 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 2
  br label %omp_loop.body

; Loop:
omp_loop.body:                                    ; preds = %omp_loop.body.lr.ph, %omp_loop.body
  %omp_loop.iv66 = phi i32 [ 0, %omp_loop.body.lr.ph ], [ %omp_loop.next, %omp_loop.body ]
  %7 = add nuw i32 %omp_loop.iv66, 1
  %8 = add i32 %7, %3
  %9 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %10 = sitofp i32 %9 to float
  %11 = fdiv contract float 1.000000e+00, %10
  %12 = fpext float %11 to double
  store ptr %.unpack, ptr %loadgep_2, align 8, !tbaa !8
  store i64 %.unpack6, ptr %loadgep_2.repack17, align 8, !tbaa !8
  store i32 %.unpack7, ptr %loadgep_2.repack19, align 8, !tbaa !8
  store i8 %.unpack8, ptr %loadgep_2.repack21, align 4, !tbaa !8
  store i8 %.unpack9, ptr %loadgep_2.repack23, align 1, !tbaa !8
  store i8 %.unpack10, ptr %loadgep_2.repack25, align 2, !tbaa !8
  store i8 %.unpack11, ptr %loadgep_2.repack27, align 1, !tbaa !8
  store i64 %.unpack12.unpack.unpack, ptr %loadgep_2.repack29, align 8, !tbaa !8
  store i64 %.unpack12.unpack.unpack14, ptr %loadgep_2.repack29.repack31, align 8, !tbaa !8
  store i64 %.unpack12.unpack.unpack15, ptr %loadgep_2.repack29.repack33, align 8, !tbaa !8
  %13 = load i64, ptr %6, align 8, !tbaa !8
  %14 = sext i32 %8 to i64
  %15 = sub i64 %14, %13
  %16 = getelementptr double, ptr %.unpack, i64 %15
  store double %12, ptr %16, align 8, !tbaa !4
  store ptr %.unpack, ptr %loadgep_4, align 8, !tbaa !8
  store i64 %.unpack6, ptr %loadgep_4.repack47, align 8, !tbaa !8
  store i32 %.unpack7, ptr %loadgep_4.repack49, align 8, !tbaa !8
  store i8 %.unpack8, ptr %loadgep_4.repack51, align 4, !tbaa !8
  store i8 %.unpack9, ptr %loadgep_4.repack53, align 1, !tbaa !8
  store i8 %.unpack10, ptr %loadgep_4.repack55, align 2, !tbaa !8
  store i8 %.unpack11, ptr %loadgep_4.repack57, align 1, !tbaa !8
  store i64 %.unpack12.unpack.unpack, ptr %loadgep_4.repack59, align 8, !tbaa !8
  store i64 %.unpack12.unpack.unpack14, ptr %loadgep_4.repack59.repack61, align 8, !tbaa !8
  store i64 %.unpack12.unpack.unpack15, ptr %loadgep_4.repack59.repack63, align 8, !tbaa !8
  %omp_loop.next = add nuw i32 %omp_loop.iv66, 1
  %exitcond = icmp ne i32 %omp_loop.next, %5
  br i1 %exitcond, label %omp_loop.body, label %omp_loop.exit.loopexit

; Exit blocks
omp_loop.exit.loopexit:                           ; preds = %omp_loop.body
  br label %omp_loop.exit
*** IR Dump After SROAPass on _QQmain..omp_par ***
; Function Attrs: norecurse nounwind
define internal void @_QQmain..omp_par(ptr noalias %tid.addr, ptr noalias %zero.addr, ptr %0) #2 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %gep_3 = getelementptr { ptr, ptr, ptr }, ptr %0, i64 0, i32 2
  %loadgep_4 = load ptr, ptr %gep_3, align 8
  %p.lastiter = alloca i32, align 4
  %p.lowerbound = alloca i32, align 4
  %p.upperbound = alloca i32, align 4
  %p.stride = alloca i32, align 4
  %1 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %omp_loop.tripcount = tail call i32 @llvm.smax.i32(i32 %1, i32 0)
  store i32 0, ptr %p.lowerbound, align 4
  %2 = add nsw i32 %omp_loop.tripcount, -1
  store i32 %2, ptr %p.upperbound, align 4
  store i32 1, ptr %p.stride, align 4
  %omp_global_thread_num4 = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  call void @__kmpc_for_static_init_4u(ptr nonnull @1, i32 %omp_global_thread_num4, i32 34, ptr nonnull %p.lastiter, ptr nonnull %p.lowerbound, ptr nonnull %p.upperbound, ptr nonnull %p.stride, i32 1, i32 0)
  %3 = load i32, ptr %p.lowerbound, align 4
  %4 = load i32, ptr %p.upperbound, align 4
  %reass.sub = sub i32 %4, %3
  %5 = add i32 %reass.sub, 1
  %omp_loop.cmp65.not = icmp eq i32 %5, 0
  br i1 %omp_loop.cmp65.not, label %omp_loop.exit, label %omp_loop.body.lr.ph

omp_loop.body.lr.ph:                              ; preds = %omp.par.entry
  %.unpack = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  %.unpack6 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  %.unpack7 = load i32, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  %.unpack8 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  %.unpack9 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  %.unpack10 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  %.unpack11 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  %.unpack12.unpack.unpack = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  %.unpack12.unpack.unpack14 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  %.unpack12.unpack.unpack15 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  %loadgep_2.repack17 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  %loadgep_2.repack19 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  %loadgep_2.repack21 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  %loadgep_2.repack23 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  %loadgep_2.repack25 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  %loadgep_2.repack27 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  %loadgep_2.repack29 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  %loadgep_2.repack29.repack31 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  %loadgep_2.repack29.repack33 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  %6 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 0
  %loadgep_4.repack47 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 1
  %loadgep_4.repack49 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 2
  %loadgep_4.repack51 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 3
  %loadgep_4.repack53 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 4
  %loadgep_4.repack55 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 5
  %loadgep_4.repack57 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 6
  %loadgep_4.repack59 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7
  %loadgep_4.repack59.repack61 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 1
  %loadgep_4.repack59.repack63 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 2
  br label %omp_loop.body

omp_loop.exit.loopexit:                           ; preds = %omp_loop.body
  br label %omp_loop.exit

omp_loop.exit:                                    ; preds = %omp_loop.exit.loopexit, %omp.par.entry
  call void @__kmpc_for_static_fini(ptr nonnull @1, i32 %omp_global_thread_num4)
  call void @__kmpc_barrier(ptr nonnull @2, i32 %omp_global_thread_num4)
  ret void

omp_loop.body:                                    ; preds = %omp_loop.body.lr.ph, %omp_loop.body
  %omp_loop.iv66 = phi i32 [ 0, %omp_loop.body.lr.ph ], [ %omp_loop.next, %omp_loop.body ]
  %7 = add nuw i32 %omp_loop.iv66, 1
  %8 = add i32 %7, %3
  %9 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %10 = sitofp i32 %9 to float
  %11 = fdiv contract float 1.000000e+00, %10
  %12 = fpext float %11 to double
  store ptr %.unpack, ptr %loadgep_2, align 8, !tbaa !8
  store i64 %.unpack6, ptr %loadgep_2.repack17, align 8, !tbaa !8
  store i32 %.unpack7, ptr %loadgep_2.repack19, align 8, !tbaa !8
  store i8 %.unpack8, ptr %loadgep_2.repack21, align 4, !tbaa !8
  store i8 %.unpack9, ptr %loadgep_2.repack23, align 1, !tbaa !8
  store i8 %.unpack10, ptr %loadgep_2.repack25, align 2, !tbaa !8
  store i8 %.unpack11, ptr %loadgep_2.repack27, align 1, !tbaa !8
  store i64 %.unpack12.unpack.unpack, ptr %loadgep_2.repack29, align 8, !tbaa !8
  store i64 %.unpack12.unpack.unpack14, ptr %loadgep_2.repack29.repack31, align 8, !tbaa !8
  store i64 %.unpack12.unpack.unpack15, ptr %loadgep_2.repack29.repack33, align 8, !tbaa !8
  %13 = load i64, ptr %6, align 8, !tbaa !8
  %14 = sext i32 %8 to i64
  %15 = sub i64 %14, %13
  %16 = getelementptr double, ptr %.unpack, i64 %15
  store double %12, ptr %16, align 8, !tbaa !4
  store ptr %.unpack, ptr %loadgep_4, align 8, !tbaa !8
  store i64 %.unpack6, ptr %loadgep_4.repack47, align 8, !tbaa !8
  store i32 %.unpack7, ptr %loadgep_4.repack49, align 8, !tbaa !8
  store i8 %.unpack8, ptr %loadgep_4.repack51, align 4, !tbaa !8
  store i8 %.unpack9, ptr %loadgep_4.repack53, align 1, !tbaa !8
  store i8 %.unpack10, ptr %loadgep_4.repack55, align 2, !tbaa !8
  store i8 %.unpack11, ptr %loadgep_4.repack57, align 1, !tbaa !8
  store i64 %.unpack12.unpack.unpack, ptr %loadgep_4.repack59, align 8, !tbaa !8
  store i64 %.unpack12.unpack.unpack14, ptr %loadgep_4.repack59.repack61, align 8, !tbaa !8
  store i64 %.unpack12.unpack.unpack15, ptr %loadgep_4.repack59.repack63, align 8, !tbaa !8
  %omp_loop.next = add nuw i32 %omp_loop.iv66, 1
  %exitcond = icmp ne i32 %omp_loop.next, %5
  br i1 %exitcond, label %omp_loop.body, label %omp_loop.exit.loopexit
}
*** IR Dump After VectorCombinePass on _QQmain..omp_par ***
; Function Attrs: norecurse nounwind
define internal void @_QQmain..omp_par(ptr noalias %tid.addr, ptr noalias %zero.addr, ptr %0) #2 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %gep_3 = getelementptr { ptr, ptr, ptr }, ptr %0, i64 0, i32 2
  %loadgep_4 = load ptr, ptr %gep_3, align 8
  %p.lastiter = alloca i32, align 4
  %p.lowerbound = alloca i32, align 4
  %p.upperbound = alloca i32, align 4
  %p.stride = alloca i32, align 4
  %1 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %omp_loop.tripcount = tail call i32 @llvm.smax.i32(i32 %1, i32 0)
  store i32 0, ptr %p.lowerbound, align 4
  %2 = add nsw i32 %omp_loop.tripcount, -1
  store i32 %2, ptr %p.upperbound, align 4
  store i32 1, ptr %p.stride, align 4
  %omp_global_thread_num4 = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  call void @__kmpc_for_static_init_4u(ptr nonnull @1, i32 %omp_global_thread_num4, i32 34, ptr nonnull %p.lastiter, ptr nonnull %p.lowerbound, ptr nonnull %p.upperbound, ptr nonnull %p.stride, i32 1, i32 0)
  %3 = load i32, ptr %p.lowerbound, align 4
  %4 = load i32, ptr %p.upperbound, align 4
  %reass.sub = sub i32 %4, %3
  %5 = add i32 %reass.sub, 1
  %omp_loop.cmp65.not = icmp eq i32 %5, 0
  br i1 %omp_loop.cmp65.not, label %omp_loop.exit, label %omp_loop.body.lr.ph

omp_loop.body.lr.ph:                              ; preds = %omp.par.entry
  %.unpack = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  %.unpack6 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  %.unpack7 = load i32, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  %.unpack8 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  %.unpack9 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  %.unpack10 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  %.unpack11 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  %.unpack12.unpack.unpack = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  %.unpack12.unpack.unpack14 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  %.unpack12.unpack.unpack15 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  %loadgep_2.repack17 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  %loadgep_2.repack19 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  %loadgep_2.repack21 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  %loadgep_2.repack23 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  %loadgep_2.repack25 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  %loadgep_2.repack27 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  %loadgep_2.repack29 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  %loadgep_2.repack29.repack31 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  %loadgep_2.repack29.repack33 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  %6 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 0
  %loadgep_4.repack47 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 1
  %loadgep_4.repack49 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 2
  %loadgep_4.repack51 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 3
  %loadgep_4.repack53 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 4
  %loadgep_4.repack55 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 5
  %loadgep_4.repack57 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 6
  %loadgep_4.repack59 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7
  %loadgep_4.repack59.repack61 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 1
  %loadgep_4.repack59.repack63 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 2
  br label %omp_loop.body

omp_loop.exit.loopexit:                           ; preds = %omp_loop.body
  br label %omp_loop.exit

omp_loop.exit:                                    ; preds = %omp_loop.exit.loopexit, %omp.par.entry
  call void @__kmpc_for_static_fini(ptr nonnull @1, i32 %omp_global_thread_num4)
  call void @__kmpc_barrier(ptr nonnull @2, i32 %omp_global_thread_num4)
  ret void

omp_loop.body:                                    ; preds = %omp_loop.body.lr.ph, %omp_loop.body
  %omp_loop.iv66 = phi i32 [ 0, %omp_loop.body.lr.ph ], [ %omp_loop.next, %omp_loop.body ]
  %7 = add nuw i32 %omp_loop.iv66, 1
  %8 = add i32 %7, %3
  %9 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %10 = sitofp i32 %9 to float
  %11 = fdiv contract float 1.000000e+00, %10
  %12 = fpext float %11 to double
  store ptr %.unpack, ptr %loadgep_2, align 8, !tbaa !8
  store i64 %.unpack6, ptr %loadgep_2.repack17, align 8, !tbaa !8
  store i32 %.unpack7, ptr %loadgep_2.repack19, align 8, !tbaa !8
  store i8 %.unpack8, ptr %loadgep_2.repack21, align 4, !tbaa !8
  store i8 %.unpack9, ptr %loadgep_2.repack23, align 1, !tbaa !8
  store i8 %.unpack10, ptr %loadgep_2.repack25, align 2, !tbaa !8
  store i8 %.unpack11, ptr %loadgep_2.repack27, align 1, !tbaa !8
  store i64 %.unpack12.unpack.unpack, ptr %loadgep_2.repack29, align 8, !tbaa !8
  store i64 %.unpack12.unpack.unpack14, ptr %loadgep_2.repack29.repack31, align 8, !tbaa !8
  store i64 %.unpack12.unpack.unpack15, ptr %loadgep_2.repack29.repack33, align 8, !tbaa !8
  %13 = load i64, ptr %6, align 8, !tbaa !8
  %14 = sext i32 %8 to i64
  %15 = sub i64 %14, %13
  %16 = getelementptr double, ptr %.unpack, i64 %15
  store double %12, ptr %16, align 8, !tbaa !4
  store ptr %.unpack, ptr %loadgep_4, align 8, !tbaa !8
  store i64 %.unpack6, ptr %loadgep_4.repack47, align 8, !tbaa !8
  store i32 %.unpack7, ptr %loadgep_4.repack49, align 8, !tbaa !8
  store i8 %.unpack8, ptr %loadgep_4.repack51, align 4, !tbaa !8
  store i8 %.unpack9, ptr %loadgep_4.repack53, align 1, !tbaa !8
  store i8 %.unpack10, ptr %loadgep_4.repack55, align 2, !tbaa !8
  store i8 %.unpack11, ptr %loadgep_4.repack57, align 1, !tbaa !8
  store i64 %.unpack12.unpack.unpack, ptr %loadgep_4.repack59, align 8, !tbaa !8
  store i64 %.unpack12.unpack.unpack14, ptr %loadgep_4.repack59.repack61, align 8, !tbaa !8
  store i64 %.unpack12.unpack.unpack15, ptr %loadgep_4.repack59.repack63, align 8, !tbaa !8
  %omp_loop.next = add nuw i32 %omp_loop.iv66, 1
  %exitcond = icmp ne i32 %omp_loop.next, %5
  br i1 %exitcond, label %omp_loop.body, label %omp_loop.exit.loopexit
}
*** IR Dump After MergedLoadStoreMotionPass on _QQmain..omp_par ***
; Function Attrs: norecurse nounwind
define internal void @_QQmain..omp_par(ptr noalias %tid.addr, ptr noalias %zero.addr, ptr %0) #2 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %gep_3 = getelementptr { ptr, ptr, ptr }, ptr %0, i64 0, i32 2
  %loadgep_4 = load ptr, ptr %gep_3, align 8
  %p.lastiter = alloca i32, align 4
  %p.lowerbound = alloca i32, align 4
  %p.upperbound = alloca i32, align 4
  %p.stride = alloca i32, align 4
  %1 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %omp_loop.tripcount = tail call i32 @llvm.smax.i32(i32 %1, i32 0)
  store i32 0, ptr %p.lowerbound, align 4
  %2 = add nsw i32 %omp_loop.tripcount, -1
  store i32 %2, ptr %p.upperbound, align 4
  store i32 1, ptr %p.stride, align 4
  %omp_global_thread_num4 = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  call void @__kmpc_for_static_init_4u(ptr nonnull @1, i32 %omp_global_thread_num4, i32 34, ptr nonnull %p.lastiter, ptr nonnull %p.lowerbound, ptr nonnull %p.upperbound, ptr nonnull %p.stride, i32 1, i32 0)
  %3 = load i32, ptr %p.lowerbound, align 4
  %4 = load i32, ptr %p.upperbound, align 4
  %reass.sub = sub i32 %4, %3
  %5 = add i32 %reass.sub, 1
  %omp_loop.cmp65.not = icmp eq i32 %5, 0
  br i1 %omp_loop.cmp65.not, label %omp_loop.exit, label %omp_loop.body.lr.ph

omp_loop.body.lr.ph:                              ; preds = %omp.par.entry
  %.unpack = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  %.unpack6 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  %.unpack7 = load i32, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  %.unpack8 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  %.unpack9 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  %.unpack10 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  %.unpack11 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  %.unpack12.unpack.unpack = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  %.unpack12.unpack.unpack14 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  %.unpack12.unpack.unpack15 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  %loadgep_2.repack17 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  %loadgep_2.repack19 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  %loadgep_2.repack21 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  %loadgep_2.repack23 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  %loadgep_2.repack25 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  %loadgep_2.repack27 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  %loadgep_2.repack29 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  %loadgep_2.repack29.repack31 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  %loadgep_2.repack29.repack33 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  %6 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 0
  %loadgep_4.repack47 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 1
  %loadgep_4.repack49 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 2
  %loadgep_4.repack51 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 3
  %loadgep_4.repack53 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 4
  %loadgep_4.repack55 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 5
  %loadgep_4.repack57 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 6
  %loadgep_4.repack59 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7
  %loadgep_4.repack59.repack61 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 1
  %loadgep_4.repack59.repack63 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 2
  br label %omp_loop.body

omp_loop.exit.loopexit:                           ; preds = %omp_loop.body
  br label %omp_loop.exit

omp_loop.exit:                                    ; preds = %omp_loop.exit.loopexit, %omp.par.entry
  call void @__kmpc_for_static_fini(ptr nonnull @1, i32 %omp_global_thread_num4)
  call void @__kmpc_barrier(ptr nonnull @2, i32 %omp_global_thread_num4)
  ret void

omp_loop.body:                                    ; preds = %omp_loop.body.lr.ph, %omp_loop.body
  %omp_loop.iv66 = phi i32 [ 0, %omp_loop.body.lr.ph ], [ %omp_loop.next, %omp_loop.body ]
  %7 = add nuw i32 %omp_loop.iv66, 1
  %8 = add i32 %7, %3
  %9 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %10 = sitofp i32 %9 to float
  %11 = fdiv contract float 1.000000e+00, %10
  %12 = fpext float %11 to double
  store ptr %.unpack, ptr %loadgep_2, align 8, !tbaa !8
  store i64 %.unpack6, ptr %loadgep_2.repack17, align 8, !tbaa !8
  store i32 %.unpack7, ptr %loadgep_2.repack19, align 8, !tbaa !8
  store i8 %.unpack8, ptr %loadgep_2.repack21, align 4, !tbaa !8
  store i8 %.unpack9, ptr %loadgep_2.repack23, align 1, !tbaa !8
  store i8 %.unpack10, ptr %loadgep_2.repack25, align 2, !tbaa !8
  store i8 %.unpack11, ptr %loadgep_2.repack27, align 1, !tbaa !8
  store i64 %.unpack12.unpack.unpack, ptr %loadgep_2.repack29, align 8, !tbaa !8
  store i64 %.unpack12.unpack.unpack14, ptr %loadgep_2.repack29.repack31, align 8, !tbaa !8
  store i64 %.unpack12.unpack.unpack15, ptr %loadgep_2.repack29.repack33, align 8, !tbaa !8
  %13 = load i64, ptr %6, align 8, !tbaa !8
  %14 = sext i32 %8 to i64
  %15 = sub i64 %14, %13
  %16 = getelementptr double, ptr %.unpack, i64 %15
  store double %12, ptr %16, align 8, !tbaa !4
  store ptr %.unpack, ptr %loadgep_4, align 8, !tbaa !8
  store i64 %.unpack6, ptr %loadgep_4.repack47, align 8, !tbaa !8
  store i32 %.unpack7, ptr %loadgep_4.repack49, align 8, !tbaa !8
  store i8 %.unpack8, ptr %loadgep_4.repack51, align 4, !tbaa !8
  store i8 %.unpack9, ptr %loadgep_4.repack53, align 1, !tbaa !8
  store i8 %.unpack10, ptr %loadgep_4.repack55, align 2, !tbaa !8
  store i8 %.unpack11, ptr %loadgep_4.repack57, align 1, !tbaa !8
  store i64 %.unpack12.unpack.unpack, ptr %loadgep_4.repack59, align 8, !tbaa !8
  store i64 %.unpack12.unpack.unpack14, ptr %loadgep_4.repack59.repack61, align 8, !tbaa !8
  store i64 %.unpack12.unpack.unpack15, ptr %loadgep_4.repack59.repack63, align 8, !tbaa !8
  %omp_loop.next = add nuw i32 %omp_loop.iv66, 1
  %exitcond = icmp ne i32 %omp_loop.next, %5
  br i1 %exitcond, label %omp_loop.body, label %omp_loop.exit.loopexit
}
*** IR Dump After GVNPass on _QQmain..omp_par ***
; Function Attrs: norecurse nounwind
define internal void @_QQmain..omp_par(ptr noalias %tid.addr, ptr noalias %zero.addr, ptr %0) #2 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %gep_3 = getelementptr { ptr, ptr, ptr }, ptr %0, i64 0, i32 2
  %loadgep_4 = load ptr, ptr %gep_3, align 8
  %p.lastiter = alloca i32, align 4
  %p.lowerbound = alloca i32, align 4
  %p.upperbound = alloca i32, align 4
  %p.stride = alloca i32, align 4
  %1 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %omp_loop.tripcount = tail call i32 @llvm.smax.i32(i32 %1, i32 0)
  store i32 0, ptr %p.lowerbound, align 4
  %2 = add nsw i32 %omp_loop.tripcount, -1
  store i32 %2, ptr %p.upperbound, align 4
  store i32 1, ptr %p.stride, align 4
  %omp_global_thread_num4 = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  call void @__kmpc_for_static_init_4u(ptr nonnull @1, i32 %omp_global_thread_num4, i32 34, ptr nonnull %p.lastiter, ptr nonnull %p.lowerbound, ptr nonnull %p.upperbound, ptr nonnull %p.stride, i32 1, i32 0)
  %3 = load i32, ptr %p.lowerbound, align 4
  %4 = load i32, ptr %p.upperbound, align 4
  %reass.sub = sub i32 %4, %3
  %5 = add i32 %reass.sub, 1
  %omp_loop.cmp65.not = icmp eq i32 %5, 0
  br i1 %omp_loop.cmp65.not, label %omp_loop.exit, label %omp_loop.body.lr.ph

omp_loop.body.lr.ph:                              ; preds = %omp.par.entry
  %.unpack = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  %.unpack6 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  %.unpack7 = load i32, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  %.unpack8 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  %.unpack9 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  %.unpack10 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  %.unpack11 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  %.unpack12.unpack.unpack = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  %.unpack12.unpack.unpack14 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  %.unpack12.unpack.unpack15 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  %loadgep_2.repack17 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  %loadgep_2.repack19 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  %loadgep_2.repack21 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  %loadgep_2.repack23 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  %loadgep_2.repack25 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  %loadgep_2.repack27 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  %loadgep_2.repack29 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  %loadgep_2.repack29.repack31 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  %loadgep_2.repack29.repack33 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  %loadgep_4.repack47 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 1
  %loadgep_4.repack49 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 2
  %loadgep_4.repack51 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 3
  %loadgep_4.repack53 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 4
  %loadgep_4.repack55 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 5
  %loadgep_4.repack57 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 6
  %loadgep_4.repack59 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7
  %loadgep_4.repack59.repack61 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 1
  %loadgep_4.repack59.repack63 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 2
  br label %omp_loop.body

omp_loop.exit.loopexit:                           ; preds = %omp_loop.body
  br label %omp_loop.exit

omp_loop.exit:                                    ; preds = %omp_loop.exit.loopexit, %omp.par.entry
  call void @__kmpc_for_static_fini(ptr nonnull @1, i32 %omp_global_thread_num4)
  call void @__kmpc_barrier(ptr nonnull @2, i32 %omp_global_thread_num4)
  ret void

omp_loop.body:                                    ; preds = %omp_loop.body.lr.ph, %omp_loop.body
  %omp_loop.iv66 = phi i32 [ 0, %omp_loop.body.lr.ph ], [ %6, %omp_loop.body ]
  %6 = add nuw i32 %omp_loop.iv66, 1
  %7 = add i32 %6, %3
  %8 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %9 = sitofp i32 %8 to float
  %10 = fdiv contract float 1.000000e+00, %9
  %11 = fpext float %10 to double
  store ptr %.unpack, ptr %loadgep_2, align 8, !tbaa !8
  store i64 %.unpack6, ptr %loadgep_2.repack17, align 8, !tbaa !8
  store i32 %.unpack7, ptr %loadgep_2.repack19, align 8, !tbaa !8
  store i8 %.unpack8, ptr %loadgep_2.repack21, align 4, !tbaa !8
  store i8 %.unpack9, ptr %loadgep_2.repack23, align 1, !tbaa !8
  store i8 %.unpack10, ptr %loadgep_2.repack25, align 2, !tbaa !8
  store i8 %.unpack11, ptr %loadgep_2.repack27, align 1, !tbaa !8
  store i64 %.unpack12.unpack.unpack, ptr %loadgep_2.repack29, align 8, !tbaa !8
  store i64 %.unpack12.unpack.unpack14, ptr %loadgep_2.repack29.repack31, align 8, !tbaa !8
  store i64 %.unpack12.unpack.unpack15, ptr %loadgep_2.repack29.repack33, align 8, !tbaa !8
  %12 = sext i32 %7 to i64
  %13 = sub i64 %12, %.unpack12.unpack.unpack
  %14 = getelementptr double, ptr %.unpack, i64 %13
  store double %11, ptr %14, align 8, !tbaa !4
  store ptr %.unpack, ptr %loadgep_4, align 8, !tbaa !8
  store i64 %.unpack6, ptr %loadgep_4.repack47, align 8, !tbaa !8
  store i32 %.unpack7, ptr %loadgep_4.repack49, align 8, !tbaa !8
  store i8 %.unpack8, ptr %loadgep_4.repack51, align 4, !tbaa !8
  store i8 %.unpack9, ptr %loadgep_4.repack53, align 1, !tbaa !8
  store i8 %.unpack10, ptr %loadgep_4.repack55, align 2, !tbaa !8
  store i8 %.unpack11, ptr %loadgep_4.repack57, align 1, !tbaa !8
  store i64 %.unpack12.unpack.unpack, ptr %loadgep_4.repack59, align 8, !tbaa !8
  store i64 %.unpack12.unpack.unpack14, ptr %loadgep_4.repack59.repack61, align 8, !tbaa !8
  store i64 %.unpack12.unpack.unpack15, ptr %loadgep_4.repack59.repack63, align 8, !tbaa !8
  %exitcond = icmp ne i32 %6, %5
  br i1 %exitcond, label %omp_loop.body, label %omp_loop.exit.loopexit
}
*** IR Dump After SCCPPass on _QQmain..omp_par ***
; Function Attrs: norecurse nounwind
define internal void @_QQmain..omp_par(ptr noalias %tid.addr, ptr noalias %zero.addr, ptr %0) #2 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %gep_3 = getelementptr { ptr, ptr, ptr }, ptr %0, i64 0, i32 2
  %loadgep_4 = load ptr, ptr %gep_3, align 8
  %p.lastiter = alloca i32, align 4
  %p.lowerbound = alloca i32, align 4
  %p.upperbound = alloca i32, align 4
  %p.stride = alloca i32, align 4
  %1 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %omp_loop.tripcount = tail call i32 @llvm.smax.i32(i32 %1, i32 0)
  store i32 0, ptr %p.lowerbound, align 4
  %2 = add nsw i32 %omp_loop.tripcount, -1
  store i32 %2, ptr %p.upperbound, align 4
  store i32 1, ptr %p.stride, align 4
  %omp_global_thread_num4 = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  call void @__kmpc_for_static_init_4u(ptr nonnull @1, i32 %omp_global_thread_num4, i32 34, ptr nonnull %p.lastiter, ptr nonnull %p.lowerbound, ptr nonnull %p.upperbound, ptr nonnull %p.stride, i32 1, i32 0)
  %3 = load i32, ptr %p.lowerbound, align 4
  %4 = load i32, ptr %p.upperbound, align 4
  %reass.sub = sub i32 %4, %3
  %5 = add i32 %reass.sub, 1
  %omp_loop.cmp65.not = icmp eq i32 %5, 0
  br i1 %omp_loop.cmp65.not, label %omp_loop.exit, label %omp_loop.body.lr.ph

omp_loop.body.lr.ph:                              ; preds = %omp.par.entry
  %.unpack = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  %.unpack6 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  %.unpack7 = load i32, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  %.unpack8 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  %.unpack9 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  %.unpack10 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  %.unpack11 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  %.unpack12.unpack.unpack = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  %.unpack12.unpack.unpack14 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  %.unpack12.unpack.unpack15 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  %loadgep_2.repack17 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  %loadgep_2.repack19 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  %loadgep_2.repack21 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  %loadgep_2.repack23 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  %loadgep_2.repack25 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  %loadgep_2.repack27 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  %loadgep_2.repack29 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  %loadgep_2.repack29.repack31 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  %loadgep_2.repack29.repack33 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  %loadgep_4.repack47 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 1
  %loadgep_4.repack49 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 2
  %loadgep_4.repack51 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 3
  %loadgep_4.repack53 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 4
  %loadgep_4.repack55 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 5
  %loadgep_4.repack57 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 6
  %loadgep_4.repack59 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7
  %loadgep_4.repack59.repack61 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 1
  %loadgep_4.repack59.repack63 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 2
  br label %omp_loop.body

omp_loop.exit.loopexit:                           ; preds = %omp_loop.body
  br label %omp_loop.exit

omp_loop.exit:                                    ; preds = %omp_loop.exit.loopexit, %omp.par.entry
  call void @__kmpc_for_static_fini(ptr nonnull @1, i32 %omp_global_thread_num4)
  call void @__kmpc_barrier(ptr nonnull @2, i32 %omp_global_thread_num4)
  ret void

omp_loop.body:                                    ; preds = %omp_loop.body.lr.ph, %omp_loop.body
  %omp_loop.iv66 = phi i32 [ 0, %omp_loop.body.lr.ph ], [ %6, %omp_loop.body ]
  %6 = add nuw i32 %omp_loop.iv66, 1
  %7 = add i32 %6, %3
  %8 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %9 = sitofp i32 %8 to float
  %10 = fdiv contract float 1.000000e+00, %9
  %11 = fpext float %10 to double
  store ptr %.unpack, ptr %loadgep_2, align 8, !tbaa !8
  store i64 %.unpack6, ptr %loadgep_2.repack17, align 8, !tbaa !8
  store i32 %.unpack7, ptr %loadgep_2.repack19, align 8, !tbaa !8
  store i8 %.unpack8, ptr %loadgep_2.repack21, align 4, !tbaa !8
  store i8 %.unpack9, ptr %loadgep_2.repack23, align 1, !tbaa !8
  store i8 %.unpack10, ptr %loadgep_2.repack25, align 2, !tbaa !8
  store i8 %.unpack11, ptr %loadgep_2.repack27, align 1, !tbaa !8
  store i64 %.unpack12.unpack.unpack, ptr %loadgep_2.repack29, align 8, !tbaa !8
  store i64 %.unpack12.unpack.unpack14, ptr %loadgep_2.repack29.repack31, align 8, !tbaa !8
  store i64 %.unpack12.unpack.unpack15, ptr %loadgep_2.repack29.repack33, align 8, !tbaa !8
  %12 = sext i32 %7 to i64
  %13 = sub i64 %12, %.unpack12.unpack.unpack
  %14 = getelementptr double, ptr %.unpack, i64 %13
  store double %11, ptr %14, align 8, !tbaa !4
  store ptr %.unpack, ptr %loadgep_4, align 8, !tbaa !8
  store i64 %.unpack6, ptr %loadgep_4.repack47, align 8, !tbaa !8
  store i32 %.unpack7, ptr %loadgep_4.repack49, align 8, !tbaa !8
  store i8 %.unpack8, ptr %loadgep_4.repack51, align 4, !tbaa !8
  store i8 %.unpack9, ptr %loadgep_4.repack53, align 1, !tbaa !8
  store i8 %.unpack10, ptr %loadgep_4.repack55, align 2, !tbaa !8
  store i8 %.unpack11, ptr %loadgep_4.repack57, align 1, !tbaa !8
  store i64 %.unpack12.unpack.unpack, ptr %loadgep_4.repack59, align 8, !tbaa !8
  store i64 %.unpack12.unpack.unpack14, ptr %loadgep_4.repack59.repack61, align 8, !tbaa !8
  store i64 %.unpack12.unpack.unpack15, ptr %loadgep_4.repack59.repack63, align 8, !tbaa !8
  %exitcond = icmp ne i32 %6, %5
  br i1 %exitcond, label %omp_loop.body, label %omp_loop.exit.loopexit
}
*** IR Dump After BDCEPass on _QQmain..omp_par ***
; Function Attrs: norecurse nounwind
define internal void @_QQmain..omp_par(ptr noalias %tid.addr, ptr noalias %zero.addr, ptr %0) #2 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %gep_3 = getelementptr { ptr, ptr, ptr }, ptr %0, i64 0, i32 2
  %loadgep_4 = load ptr, ptr %gep_3, align 8
  %p.lastiter = alloca i32, align 4
  %p.lowerbound = alloca i32, align 4
  %p.upperbound = alloca i32, align 4
  %p.stride = alloca i32, align 4
  %1 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %omp_loop.tripcount = tail call i32 @llvm.smax.i32(i32 %1, i32 0)
  store i32 0, ptr %p.lowerbound, align 4
  %2 = add nsw i32 %omp_loop.tripcount, -1
  store i32 %2, ptr %p.upperbound, align 4
  store i32 1, ptr %p.stride, align 4
  %omp_global_thread_num4 = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  call void @__kmpc_for_static_init_4u(ptr nonnull @1, i32 %omp_global_thread_num4, i32 34, ptr nonnull %p.lastiter, ptr nonnull %p.lowerbound, ptr nonnull %p.upperbound, ptr nonnull %p.stride, i32 1, i32 0)
  %3 = load i32, ptr %p.lowerbound, align 4
  %4 = load i32, ptr %p.upperbound, align 4
  %reass.sub = sub i32 %4, %3
  %5 = add i32 %reass.sub, 1
  %omp_loop.cmp65.not = icmp eq i32 %5, 0
  br i1 %omp_loop.cmp65.not, label %omp_loop.exit, label %omp_loop.body.lr.ph

omp_loop.body.lr.ph:                              ; preds = %omp.par.entry
  %.unpack = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  %.unpack6 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  %.unpack7 = load i32, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  %.unpack8 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  %.unpack9 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  %.unpack10 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  %.unpack11 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  %.unpack12.unpack.unpack = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  %.unpack12.unpack.unpack14 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  %.unpack12.unpack.unpack15 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  %loadgep_2.repack17 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  %loadgep_2.repack19 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  %loadgep_2.repack21 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  %loadgep_2.repack23 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  %loadgep_2.repack25 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  %loadgep_2.repack27 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  %loadgep_2.repack29 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  %loadgep_2.repack29.repack31 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  %loadgep_2.repack29.repack33 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  %loadgep_4.repack47 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 1
  %loadgep_4.repack49 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 2
  %loadgep_4.repack51 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 3
  %loadgep_4.repack53 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 4
  %loadgep_4.repack55 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 5
  %loadgep_4.repack57 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 6
  %loadgep_4.repack59 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7
  %loadgep_4.repack59.repack61 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 1
  %loadgep_4.repack59.repack63 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 2
  br label %omp_loop.body

omp_loop.exit.loopexit:                           ; preds = %omp_loop.body
  br label %omp_loop.exit

omp_loop.exit:                                    ; preds = %omp_loop.exit.loopexit, %omp.par.entry
  call void @__kmpc_for_static_fini(ptr nonnull @1, i32 %omp_global_thread_num4)
  call void @__kmpc_barrier(ptr nonnull @2, i32 %omp_global_thread_num4)
  ret void

omp_loop.body:                                    ; preds = %omp_loop.body.lr.ph, %omp_loop.body
  %omp_loop.iv66 = phi i32 [ 0, %omp_loop.body.lr.ph ], [ %6, %omp_loop.body ]
  %6 = add nuw i32 %omp_loop.iv66, 1
  %7 = add i32 %6, %3
  %8 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %9 = sitofp i32 %8 to float
  %10 = fdiv contract float 1.000000e+00, %9
  %11 = fpext float %10 to double
  store ptr %.unpack, ptr %loadgep_2, align 8, !tbaa !8
  store i64 %.unpack6, ptr %loadgep_2.repack17, align 8, !tbaa !8
  store i32 %.unpack7, ptr %loadgep_2.repack19, align 8, !tbaa !8
  store i8 %.unpack8, ptr %loadgep_2.repack21, align 4, !tbaa !8
  store i8 %.unpack9, ptr %loadgep_2.repack23, align 1, !tbaa !8
  store i8 %.unpack10, ptr %loadgep_2.repack25, align 2, !tbaa !8
  store i8 %.unpack11, ptr %loadgep_2.repack27, align 1, !tbaa !8
  store i64 %.unpack12.unpack.unpack, ptr %loadgep_2.repack29, align 8, !tbaa !8
  store i64 %.unpack12.unpack.unpack14, ptr %loadgep_2.repack29.repack31, align 8, !tbaa !8
  store i64 %.unpack12.unpack.unpack15, ptr %loadgep_2.repack29.repack33, align 8, !tbaa !8
  %12 = sext i32 %7 to i64
  %13 = sub i64 %12, %.unpack12.unpack.unpack
  %14 = getelementptr double, ptr %.unpack, i64 %13
  store double %11, ptr %14, align 8, !tbaa !4
  store ptr %.unpack, ptr %loadgep_4, align 8, !tbaa !8
  store i64 %.unpack6, ptr %loadgep_4.repack47, align 8, !tbaa !8
  store i32 %.unpack7, ptr %loadgep_4.repack49, align 8, !tbaa !8
  store i8 %.unpack8, ptr %loadgep_4.repack51, align 4, !tbaa !8
  store i8 %.unpack9, ptr %loadgep_4.repack53, align 1, !tbaa !8
  store i8 %.unpack10, ptr %loadgep_4.repack55, align 2, !tbaa !8
  store i8 %.unpack11, ptr %loadgep_4.repack57, align 1, !tbaa !8
  store i64 %.unpack12.unpack.unpack, ptr %loadgep_4.repack59, align 8, !tbaa !8
  store i64 %.unpack12.unpack.unpack14, ptr %loadgep_4.repack59.repack61, align 8, !tbaa !8
  store i64 %.unpack12.unpack.unpack15, ptr %loadgep_4.repack59.repack63, align 8, !tbaa !8
  %exitcond = icmp ne i32 %6, %5
  br i1 %exitcond, label %omp_loop.body, label %omp_loop.exit.loopexit
}
*** IR Dump After InstCombinePass on _QQmain..omp_par ***
; Function Attrs: norecurse nounwind
define internal void @_QQmain..omp_par(ptr noalias %tid.addr, ptr noalias %zero.addr, ptr %0) #2 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %gep_3 = getelementptr { ptr, ptr, ptr }, ptr %0, i64 0, i32 2
  %loadgep_4 = load ptr, ptr %gep_3, align 8
  %p.lastiter = alloca i32, align 4
  %p.lowerbound = alloca i32, align 4
  %p.upperbound = alloca i32, align 4
  %p.stride = alloca i32, align 4
  %1 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %omp_loop.tripcount = tail call i32 @llvm.smax.i32(i32 %1, i32 0)
  store i32 0, ptr %p.lowerbound, align 4
  %2 = add nsw i32 %omp_loop.tripcount, -1
  store i32 %2, ptr %p.upperbound, align 4
  store i32 1, ptr %p.stride, align 4
  %omp_global_thread_num4 = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  call void @__kmpc_for_static_init_4u(ptr nonnull @1, i32 %omp_global_thread_num4, i32 34, ptr nonnull %p.lastiter, ptr nonnull %p.lowerbound, ptr nonnull %p.upperbound, ptr nonnull %p.stride, i32 1, i32 0)
  %3 = load i32, ptr %p.lowerbound, align 4
  %4 = load i32, ptr %p.upperbound, align 4
  %reass.sub = sub i32 %4, %3
  %omp_loop.cmp65.not = icmp eq i32 %reass.sub, -1
  br i1 %omp_loop.cmp65.not, label %omp_loop.exit, label %omp_loop.body.lr.ph

omp_loop.body.lr.ph:                              ; preds = %omp.par.entry
  %.unpack = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  %.unpack6 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  %.unpack7 = load i32, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  %.unpack8 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  %.unpack9 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  %.unpack10 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  %.unpack11 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  %.unpack12.unpack.unpack = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  %.unpack12.unpack.unpack14 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  %.unpack12.unpack.unpack15 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  %loadgep_2.repack17 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  %loadgep_2.repack19 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  %loadgep_2.repack21 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  %loadgep_2.repack23 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  %loadgep_2.repack25 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  %loadgep_2.repack27 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  %loadgep_2.repack29 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  %loadgep_2.repack29.repack31 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  %loadgep_2.repack29.repack33 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  %loadgep_4.repack47 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 1
  %loadgep_4.repack49 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 2
  %loadgep_4.repack51 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 3
  %loadgep_4.repack53 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 4
  %loadgep_4.repack55 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 5
  %loadgep_4.repack57 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 6
  %loadgep_4.repack59 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7
  %loadgep_4.repack59.repack61 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 1
  %loadgep_4.repack59.repack63 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 2
  br label %omp_loop.body

omp_loop.exit.loopexit:                           ; preds = %omp_loop.body
  br label %omp_loop.exit

omp_loop.exit:                                    ; preds = %omp_loop.exit.loopexit, %omp.par.entry
  call void @__kmpc_for_static_fini(ptr nonnull @1, i32 %omp_global_thread_num4)
  call void @__kmpc_barrier(ptr nonnull @2, i32 %omp_global_thread_num4)
  ret void

omp_loop.body:                                    ; preds = %omp_loop.body.lr.ph, %omp_loop.body
  %omp_loop.iv66 = phi i32 [ 0, %omp_loop.body.lr.ph ], [ %5, %omp_loop.body ]
  %5 = add nuw i32 %omp_loop.iv66, 1
  %6 = add i32 %5, %3
  %7 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %8 = sitofp i32 %7 to float
  %9 = fdiv contract float 1.000000e+00, %8
  %10 = fpext float %9 to double
  store ptr %.unpack, ptr %loadgep_2, align 8, !tbaa !8
  store i64 %.unpack6, ptr %loadgep_2.repack17, align 8, !tbaa !8
  store i32 %.unpack7, ptr %loadgep_2.repack19, align 8, !tbaa !8
  store i8 %.unpack8, ptr %loadgep_2.repack21, align 4, !tbaa !8
  store i8 %.unpack9, ptr %loadgep_2.repack23, align 1, !tbaa !8
  store i8 %.unpack10, ptr %loadgep_2.repack25, align 2, !tbaa !8
  store i8 %.unpack11, ptr %loadgep_2.repack27, align 1, !tbaa !8
  store i64 %.unpack12.unpack.unpack, ptr %loadgep_2.repack29, align 8, !tbaa !8
  store i64 %.unpack12.unpack.unpack14, ptr %loadgep_2.repack29.repack31, align 8, !tbaa !8
  store i64 %.unpack12.unpack.unpack15, ptr %loadgep_2.repack29.repack33, align 8, !tbaa !8
  %11 = sext i32 %6 to i64
  %12 = sub i64 %11, %.unpack12.unpack.unpack
  %13 = getelementptr double, ptr %.unpack, i64 %12
  store double %10, ptr %13, align 8, !tbaa !4
  store ptr %.unpack, ptr %loadgep_4, align 8, !tbaa !8
  store i64 %.unpack6, ptr %loadgep_4.repack47, align 8, !tbaa !8
  store i32 %.unpack7, ptr %loadgep_4.repack49, align 8, !tbaa !8
  store i8 %.unpack8, ptr %loadgep_4.repack51, align 4, !tbaa !8
  store i8 %.unpack9, ptr %loadgep_4.repack53, align 1, !tbaa !8
  store i8 %.unpack10, ptr %loadgep_4.repack55, align 2, !tbaa !8
  store i8 %.unpack11, ptr %loadgep_4.repack57, align 1, !tbaa !8
  store i64 %.unpack12.unpack.unpack, ptr %loadgep_4.repack59, align 8, !tbaa !8
  store i64 %.unpack12.unpack.unpack14, ptr %loadgep_4.repack59.repack61, align 8, !tbaa !8
  store i64 %.unpack12.unpack.unpack15, ptr %loadgep_4.repack59.repack63, align 8, !tbaa !8
  %exitcond.not = icmp eq i32 %omp_loop.iv66, %reass.sub
  br i1 %exitcond.not, label %omp_loop.exit.loopexit, label %omp_loop.body
}
*** IR Dump After JumpThreadingPass on _QQmain..omp_par ***
; Function Attrs: norecurse nounwind
define internal void @_QQmain..omp_par(ptr noalias %tid.addr, ptr noalias %zero.addr, ptr %0) #2 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %gep_3 = getelementptr { ptr, ptr, ptr }, ptr %0, i64 0, i32 2
  %loadgep_4 = load ptr, ptr %gep_3, align 8
  %p.lastiter = alloca i32, align 4
  %p.lowerbound = alloca i32, align 4
  %p.upperbound = alloca i32, align 4
  %p.stride = alloca i32, align 4
  %1 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %omp_loop.tripcount = tail call i32 @llvm.smax.i32(i32 %1, i32 0)
  store i32 0, ptr %p.lowerbound, align 4
  %2 = add nsw i32 %omp_loop.tripcount, -1
  store i32 %2, ptr %p.upperbound, align 4
  store i32 1, ptr %p.stride, align 4
  %omp_global_thread_num4 = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  call void @__kmpc_for_static_init_4u(ptr nonnull @1, i32 %omp_global_thread_num4, i32 34, ptr nonnull %p.lastiter, ptr nonnull %p.lowerbound, ptr nonnull %p.upperbound, ptr nonnull %p.stride, i32 1, i32 0)
  %3 = load i32, ptr %p.lowerbound, align 4
  %4 = load i32, ptr %p.upperbound, align 4
  %reass.sub = sub i32 %4, %3
  %omp_loop.cmp65.not = icmp eq i32 %reass.sub, -1
  br i1 %omp_loop.cmp65.not, label %omp_loop.exit, label %omp_loop.body.lr.ph

omp_loop.body.lr.ph:                              ; preds = %omp.par.entry
  %.unpack = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  %.unpack6 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  %.unpack7 = load i32, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  %.unpack8 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  %.unpack9 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  %.unpack10 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  %.unpack11 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  %.unpack12.unpack.unpack = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  %.unpack12.unpack.unpack14 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  %.unpack12.unpack.unpack15 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  %loadgep_2.repack17 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  %loadgep_2.repack19 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  %loadgep_2.repack21 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  %loadgep_2.repack23 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  %loadgep_2.repack25 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  %loadgep_2.repack27 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  %loadgep_2.repack29 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  %loadgep_2.repack29.repack31 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  %loadgep_2.repack29.repack33 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  %loadgep_4.repack47 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 1
  %loadgep_4.repack49 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 2
  %loadgep_4.repack51 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 3
  %loadgep_4.repack53 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 4
  %loadgep_4.repack55 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 5
  %loadgep_4.repack57 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 6
  %loadgep_4.repack59 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7
  %loadgep_4.repack59.repack61 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 1
  %loadgep_4.repack59.repack63 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 2
  br label %omp_loop.body

omp_loop.exit:                                    ; preds = %omp_loop.body, %omp.par.entry
  call void @__kmpc_for_static_fini(ptr nonnull @1, i32 %omp_global_thread_num4)
  call void @__kmpc_barrier(ptr nonnull @2, i32 %omp_global_thread_num4)
  ret void

omp_loop.body:                                    ; preds = %omp_loop.body.lr.ph, %omp_loop.body
  %omp_loop.iv66 = phi i32 [ 0, %omp_loop.body.lr.ph ], [ %5, %omp_loop.body ]
  %5 = add nuw i32 %omp_loop.iv66, 1
  %6 = add i32 %5, %3
  %7 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %8 = sitofp i32 %7 to float
  %9 = fdiv contract float 1.000000e+00, %8
  %10 = fpext float %9 to double
  store ptr %.unpack, ptr %loadgep_2, align 8, !tbaa !8
  store i64 %.unpack6, ptr %loadgep_2.repack17, align 8, !tbaa !8
  store i32 %.unpack7, ptr %loadgep_2.repack19, align 8, !tbaa !8
  store i8 %.unpack8, ptr %loadgep_2.repack21, align 4, !tbaa !8
  store i8 %.unpack9, ptr %loadgep_2.repack23, align 1, !tbaa !8
  store i8 %.unpack10, ptr %loadgep_2.repack25, align 2, !tbaa !8
  store i8 %.unpack11, ptr %loadgep_2.repack27, align 1, !tbaa !8
  store i64 %.unpack12.unpack.unpack, ptr %loadgep_2.repack29, align 8, !tbaa !8
  store i64 %.unpack12.unpack.unpack14, ptr %loadgep_2.repack29.repack31, align 8, !tbaa !8
  store i64 %.unpack12.unpack.unpack15, ptr %loadgep_2.repack29.repack33, align 8, !tbaa !8
  %11 = sext i32 %6 to i64
  %12 = sub i64 %11, %.unpack12.unpack.unpack
  %13 = getelementptr double, ptr %.unpack, i64 %12
  store double %10, ptr %13, align 8, !tbaa !4
  store ptr %.unpack, ptr %loadgep_4, align 8, !tbaa !8
  store i64 %.unpack6, ptr %loadgep_4.repack47, align 8, !tbaa !8
  store i32 %.unpack7, ptr %loadgep_4.repack49, align 8, !tbaa !8
  store i8 %.unpack8, ptr %loadgep_4.repack51, align 4, !tbaa !8
  store i8 %.unpack9, ptr %loadgep_4.repack53, align 1, !tbaa !8
  store i8 %.unpack10, ptr %loadgep_4.repack55, align 2, !tbaa !8
  store i8 %.unpack11, ptr %loadgep_4.repack57, align 1, !tbaa !8
  store i64 %.unpack12.unpack.unpack, ptr %loadgep_4.repack59, align 8, !tbaa !8
  store i64 %.unpack12.unpack.unpack14, ptr %loadgep_4.repack59.repack61, align 8, !tbaa !8
  store i64 %.unpack12.unpack.unpack15, ptr %loadgep_4.repack59.repack63, align 8, !tbaa !8
  %exitcond.not = icmp eq i32 %omp_loop.iv66, %reass.sub
  br i1 %exitcond.not, label %omp_loop.exit, label %omp_loop.body
}
*** IR Dump After CorrelatedValuePropagationPass on _QQmain..omp_par ***
; Function Attrs: norecurse nounwind
define internal void @_QQmain..omp_par(ptr noalias %tid.addr, ptr noalias %zero.addr, ptr %0) #2 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %gep_3 = getelementptr { ptr, ptr, ptr }, ptr %0, i64 0, i32 2
  %loadgep_4 = load ptr, ptr %gep_3, align 8
  %p.lastiter = alloca i32, align 4
  %p.lowerbound = alloca i32, align 4
  %p.upperbound = alloca i32, align 4
  %p.stride = alloca i32, align 4
  %1 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %omp_loop.tripcount = tail call i32 @llvm.smax.i32(i32 %1, i32 0)
  store i32 0, ptr %p.lowerbound, align 4
  %2 = add nsw i32 %omp_loop.tripcount, -1
  store i32 %2, ptr %p.upperbound, align 4
  store i32 1, ptr %p.stride, align 4
  %omp_global_thread_num4 = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  call void @__kmpc_for_static_init_4u(ptr nonnull @1, i32 %omp_global_thread_num4, i32 34, ptr nonnull %p.lastiter, ptr nonnull %p.lowerbound, ptr nonnull %p.upperbound, ptr nonnull %p.stride, i32 1, i32 0)
  %3 = load i32, ptr %p.lowerbound, align 4
  %4 = load i32, ptr %p.upperbound, align 4
  %reass.sub = sub i32 %4, %3
  %omp_loop.cmp65.not = icmp eq i32 %reass.sub, -1
  br i1 %omp_loop.cmp65.not, label %omp_loop.exit, label %omp_loop.body.lr.ph

omp_loop.body.lr.ph:                              ; preds = %omp.par.entry
  %.unpack = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  %.unpack6 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  %.unpack7 = load i32, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  %.unpack8 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  %.unpack9 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  %.unpack10 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  %.unpack11 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  %.unpack12.unpack.unpack = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  %.unpack12.unpack.unpack14 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  %.unpack12.unpack.unpack15 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  %loadgep_2.repack17 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  %loadgep_2.repack19 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  %loadgep_2.repack21 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  %loadgep_2.repack23 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  %loadgep_2.repack25 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  %loadgep_2.repack27 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  %loadgep_2.repack29 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  %loadgep_2.repack29.repack31 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  %loadgep_2.repack29.repack33 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  %loadgep_4.repack47 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 1
  %loadgep_4.repack49 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 2
  %loadgep_4.repack51 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 3
  %loadgep_4.repack53 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 4
  %loadgep_4.repack55 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 5
  %loadgep_4.repack57 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 6
  %loadgep_4.repack59 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7
  %loadgep_4.repack59.repack61 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 1
  %loadgep_4.repack59.repack63 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 2
  br label %omp_loop.body

omp_loop.exit:                                    ; preds = %omp_loop.body, %omp.par.entry
  call void @__kmpc_for_static_fini(ptr nonnull @1, i32 %omp_global_thread_num4)
  call void @__kmpc_barrier(ptr nonnull @2, i32 %omp_global_thread_num4)
  ret void

omp_loop.body:                                    ; preds = %omp_loop.body.lr.ph, %omp_loop.body
  %omp_loop.iv66 = phi i32 [ 0, %omp_loop.body.lr.ph ], [ %5, %omp_loop.body ]
  %5 = add nuw i32 %omp_loop.iv66, 1
  %6 = add i32 %5, %3
  %7 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %8 = sitofp i32 %7 to float
  %9 = fdiv contract float 1.000000e+00, %8
  %10 = fpext float %9 to double
  store ptr %.unpack, ptr %loadgep_2, align 8, !tbaa !8
  store i64 %.unpack6, ptr %loadgep_2.repack17, align 8, !tbaa !8
  store i32 %.unpack7, ptr %loadgep_2.repack19, align 8, !tbaa !8
  store i8 %.unpack8, ptr %loadgep_2.repack21, align 4, !tbaa !8
  store i8 %.unpack9, ptr %loadgep_2.repack23, align 1, !tbaa !8
  store i8 %.unpack10, ptr %loadgep_2.repack25, align 2, !tbaa !8
  store i8 %.unpack11, ptr %loadgep_2.repack27, align 1, !tbaa !8
  store i64 %.unpack12.unpack.unpack, ptr %loadgep_2.repack29, align 8, !tbaa !8
  store i64 %.unpack12.unpack.unpack14, ptr %loadgep_2.repack29.repack31, align 8, !tbaa !8
  store i64 %.unpack12.unpack.unpack15, ptr %loadgep_2.repack29.repack33, align 8, !tbaa !8
  %11 = sext i32 %6 to i64
  %12 = sub i64 %11, %.unpack12.unpack.unpack
  %13 = getelementptr double, ptr %.unpack, i64 %12
  store double %10, ptr %13, align 8, !tbaa !4
  store ptr %.unpack, ptr %loadgep_4, align 8, !tbaa !8
  store i64 %.unpack6, ptr %loadgep_4.repack47, align 8, !tbaa !8
  store i32 %.unpack7, ptr %loadgep_4.repack49, align 8, !tbaa !8
  store i8 %.unpack8, ptr %loadgep_4.repack51, align 4, !tbaa !8
  store i8 %.unpack9, ptr %loadgep_4.repack53, align 1, !tbaa !8
  store i8 %.unpack10, ptr %loadgep_4.repack55, align 2, !tbaa !8
  store i8 %.unpack11, ptr %loadgep_4.repack57, align 1, !tbaa !8
  store i64 %.unpack12.unpack.unpack, ptr %loadgep_4.repack59, align 8, !tbaa !8
  store i64 %.unpack12.unpack.unpack14, ptr %loadgep_4.repack59.repack61, align 8, !tbaa !8
  store i64 %.unpack12.unpack.unpack15, ptr %loadgep_4.repack59.repack63, align 8, !tbaa !8
  %exitcond.not = icmp eq i32 %omp_loop.iv66, %reass.sub
  br i1 %exitcond.not, label %omp_loop.exit, label %omp_loop.body
}
*** IR Dump After ADCEPass on _QQmain..omp_par ***
; Function Attrs: norecurse nounwind
define internal void @_QQmain..omp_par(ptr noalias %tid.addr, ptr noalias %zero.addr, ptr %0) #2 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %gep_3 = getelementptr { ptr, ptr, ptr }, ptr %0, i64 0, i32 2
  %loadgep_4 = load ptr, ptr %gep_3, align 8
  %p.lastiter = alloca i32, align 4
  %p.lowerbound = alloca i32, align 4
  %p.upperbound = alloca i32, align 4
  %p.stride = alloca i32, align 4
  %1 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %omp_loop.tripcount = tail call i32 @llvm.smax.i32(i32 %1, i32 0)
  store i32 0, ptr %p.lowerbound, align 4
  %2 = add nsw i32 %omp_loop.tripcount, -1
  store i32 %2, ptr %p.upperbound, align 4
  store i32 1, ptr %p.stride, align 4
  %omp_global_thread_num4 = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  call void @__kmpc_for_static_init_4u(ptr nonnull @1, i32 %omp_global_thread_num4, i32 34, ptr nonnull %p.lastiter, ptr nonnull %p.lowerbound, ptr nonnull %p.upperbound, ptr nonnull %p.stride, i32 1, i32 0)
  %3 = load i32, ptr %p.lowerbound, align 4
  %4 = load i32, ptr %p.upperbound, align 4
  %reass.sub = sub i32 %4, %3
  %omp_loop.cmp65.not = icmp eq i32 %reass.sub, -1
  br i1 %omp_loop.cmp65.not, label %omp_loop.exit, label %omp_loop.body.lr.ph

omp_loop.body.lr.ph:                              ; preds = %omp.par.entry
  %.unpack = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  %.unpack6 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  %.unpack7 = load i32, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  %.unpack8 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  %.unpack9 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  %.unpack10 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  %.unpack11 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  %.unpack12.unpack.unpack = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  %.unpack12.unpack.unpack14 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  %.unpack12.unpack.unpack15 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  %loadgep_2.repack17 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  %loadgep_2.repack19 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  %loadgep_2.repack21 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  %loadgep_2.repack23 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  %loadgep_2.repack25 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  %loadgep_2.repack27 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  %loadgep_2.repack29 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  %loadgep_2.repack29.repack31 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  %loadgep_2.repack29.repack33 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  %loadgep_4.repack47 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 1
  %loadgep_4.repack49 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 2
  %loadgep_4.repack51 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 3
  %loadgep_4.repack53 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 4
  %loadgep_4.repack55 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 5
  %loadgep_4.repack57 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 6
  %loadgep_4.repack59 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7
  %loadgep_4.repack59.repack61 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 1
  %loadgep_4.repack59.repack63 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 2
  br label %omp_loop.body

omp_loop.exit:                                    ; preds = %omp_loop.body, %omp.par.entry
  call void @__kmpc_for_static_fini(ptr nonnull @1, i32 %omp_global_thread_num4)
  call void @__kmpc_barrier(ptr nonnull @2, i32 %omp_global_thread_num4)
  ret void

omp_loop.body:                                    ; preds = %omp_loop.body.lr.ph, %omp_loop.body
  %omp_loop.iv66 = phi i32 [ 0, %omp_loop.body.lr.ph ], [ %5, %omp_loop.body ]
  %5 = add nuw i32 %omp_loop.iv66, 1
  %6 = add i32 %5, %3
  %7 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %8 = sitofp i32 %7 to float
  %9 = fdiv contract float 1.000000e+00, %8
  %10 = fpext float %9 to double
  store ptr %.unpack, ptr %loadgep_2, align 8, !tbaa !8
  store i64 %.unpack6, ptr %loadgep_2.repack17, align 8, !tbaa !8
  store i32 %.unpack7, ptr %loadgep_2.repack19, align 8, !tbaa !8
  store i8 %.unpack8, ptr %loadgep_2.repack21, align 4, !tbaa !8
  store i8 %.unpack9, ptr %loadgep_2.repack23, align 1, !tbaa !8
  store i8 %.unpack10, ptr %loadgep_2.repack25, align 2, !tbaa !8
  store i8 %.unpack11, ptr %loadgep_2.repack27, align 1, !tbaa !8
  store i64 %.unpack12.unpack.unpack, ptr %loadgep_2.repack29, align 8, !tbaa !8
  store i64 %.unpack12.unpack.unpack14, ptr %loadgep_2.repack29.repack31, align 8, !tbaa !8
  store i64 %.unpack12.unpack.unpack15, ptr %loadgep_2.repack29.repack33, align 8, !tbaa !8
  %11 = sext i32 %6 to i64
  %12 = sub i64 %11, %.unpack12.unpack.unpack
  %13 = getelementptr double, ptr %.unpack, i64 %12
  store double %10, ptr %13, align 8, !tbaa !4
  store ptr %.unpack, ptr %loadgep_4, align 8, !tbaa !8
  store i64 %.unpack6, ptr %loadgep_4.repack47, align 8, !tbaa !8
  store i32 %.unpack7, ptr %loadgep_4.repack49, align 8, !tbaa !8
  store i8 %.unpack8, ptr %loadgep_4.repack51, align 4, !tbaa !8
  store i8 %.unpack9, ptr %loadgep_4.repack53, align 1, !tbaa !8
  store i8 %.unpack10, ptr %loadgep_4.repack55, align 2, !tbaa !8
  store i8 %.unpack11, ptr %loadgep_4.repack57, align 1, !tbaa !8
  store i64 %.unpack12.unpack.unpack, ptr %loadgep_4.repack59, align 8, !tbaa !8
  store i64 %.unpack12.unpack.unpack14, ptr %loadgep_4.repack59.repack61, align 8, !tbaa !8
  store i64 %.unpack12.unpack.unpack15, ptr %loadgep_4.repack59.repack63, align 8, !tbaa !8
  %exitcond.not = icmp eq i32 %omp_loop.iv66, %reass.sub
  br i1 %exitcond.not, label %omp_loop.exit, label %omp_loop.body
}
*** IR Dump After MemCpyOptPass on _QQmain..omp_par ***
; Function Attrs: norecurse nounwind
define internal void @_QQmain..omp_par(ptr noalias %tid.addr, ptr noalias %zero.addr, ptr %0) #2 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %gep_3 = getelementptr { ptr, ptr, ptr }, ptr %0, i64 0, i32 2
  %loadgep_4 = load ptr, ptr %gep_3, align 8
  %p.lastiter = alloca i32, align 4
  %p.lowerbound = alloca i32, align 4
  %p.upperbound = alloca i32, align 4
  %p.stride = alloca i32, align 4
  %1 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %omp_loop.tripcount = tail call i32 @llvm.smax.i32(i32 %1, i32 0)
  store i32 0, ptr %p.lowerbound, align 4
  %2 = add nsw i32 %omp_loop.tripcount, -1
  store i32 %2, ptr %p.upperbound, align 4
  store i32 1, ptr %p.stride, align 4
  %omp_global_thread_num4 = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  call void @__kmpc_for_static_init_4u(ptr nonnull @1, i32 %omp_global_thread_num4, i32 34, ptr nonnull %p.lastiter, ptr nonnull %p.lowerbound, ptr nonnull %p.upperbound, ptr nonnull %p.stride, i32 1, i32 0)
  %3 = load i32, ptr %p.lowerbound, align 4
  %4 = load i32, ptr %p.upperbound, align 4
  %reass.sub = sub i32 %4, %3
  %omp_loop.cmp65.not = icmp eq i32 %reass.sub, -1
  br i1 %omp_loop.cmp65.not, label %omp_loop.exit, label %omp_loop.body.lr.ph

omp_loop.body.lr.ph:                              ; preds = %omp.par.entry
  %.unpack = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  %.unpack6 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  %.unpack7 = load i32, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  %.unpack8 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  %.unpack9 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  %.unpack10 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  %.unpack11 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  %.unpack12.unpack.unpack = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  %.unpack12.unpack.unpack14 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  %.unpack12.unpack.unpack15 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  %loadgep_2.repack17 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  %loadgep_2.repack19 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  %loadgep_2.repack21 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  %loadgep_2.repack23 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  %loadgep_2.repack25 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  %loadgep_2.repack27 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  %loadgep_2.repack29 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  %loadgep_2.repack29.repack31 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  %loadgep_2.repack29.repack33 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  %loadgep_4.repack47 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 1
  %loadgep_4.repack49 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 2
  %loadgep_4.repack51 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 3
  %loadgep_4.repack53 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 4
  %loadgep_4.repack55 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 5
  %loadgep_4.repack57 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 6
  %loadgep_4.repack59 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7
  %loadgep_4.repack59.repack61 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 1
  %loadgep_4.repack59.repack63 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 2
  br label %omp_loop.body

omp_loop.exit:                                    ; preds = %omp_loop.body, %omp.par.entry
  call void @__kmpc_for_static_fini(ptr nonnull @1, i32 %omp_global_thread_num4)
  call void @__kmpc_barrier(ptr nonnull @2, i32 %omp_global_thread_num4)
  ret void

omp_loop.body:                                    ; preds = %omp_loop.body.lr.ph, %omp_loop.body
  %omp_loop.iv66 = phi i32 [ 0, %omp_loop.body.lr.ph ], [ %5, %omp_loop.body ]
  %5 = add nuw i32 %omp_loop.iv66, 1
  %6 = add i32 %5, %3
  %7 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %8 = sitofp i32 %7 to float
  %9 = fdiv contract float 1.000000e+00, %8
  %10 = fpext float %9 to double
  store ptr %.unpack, ptr %loadgep_2, align 8, !tbaa !8
  store i64 %.unpack6, ptr %loadgep_2.repack17, align 8, !tbaa !8
  store i32 %.unpack7, ptr %loadgep_2.repack19, align 8, !tbaa !8
  store i8 %.unpack8, ptr %loadgep_2.repack21, align 4, !tbaa !8
  store i8 %.unpack9, ptr %loadgep_2.repack23, align 1, !tbaa !8
  store i8 %.unpack10, ptr %loadgep_2.repack25, align 2, !tbaa !8
  store i8 %.unpack11, ptr %loadgep_2.repack27, align 1, !tbaa !8
  store i64 %.unpack12.unpack.unpack, ptr %loadgep_2.repack29, align 8, !tbaa !8
  store i64 %.unpack12.unpack.unpack14, ptr %loadgep_2.repack29.repack31, align 8, !tbaa !8
  store i64 %.unpack12.unpack.unpack15, ptr %loadgep_2.repack29.repack33, align 8, !tbaa !8
  %11 = sext i32 %6 to i64
  %12 = sub i64 %11, %.unpack12.unpack.unpack
  %13 = getelementptr double, ptr %.unpack, i64 %12
  store double %10, ptr %13, align 8, !tbaa !4
  store ptr %.unpack, ptr %loadgep_4, align 8, !tbaa !8
  store i64 %.unpack6, ptr %loadgep_4.repack47, align 8, !tbaa !8
  store i32 %.unpack7, ptr %loadgep_4.repack49, align 8, !tbaa !8
  store i8 %.unpack8, ptr %loadgep_4.repack51, align 4, !tbaa !8
  store i8 %.unpack9, ptr %loadgep_4.repack53, align 1, !tbaa !8
  store i8 %.unpack10, ptr %loadgep_4.repack55, align 2, !tbaa !8
  store i8 %.unpack11, ptr %loadgep_4.repack57, align 1, !tbaa !8
  store i64 %.unpack12.unpack.unpack, ptr %loadgep_4.repack59, align 8, !tbaa !8
  store i64 %.unpack12.unpack.unpack14, ptr %loadgep_4.repack59.repack61, align 8, !tbaa !8
  store i64 %.unpack12.unpack.unpack15, ptr %loadgep_4.repack59.repack63, align 8, !tbaa !8
  %exitcond.not = icmp eq i32 %omp_loop.iv66, %reass.sub
  br i1 %exitcond.not, label %omp_loop.exit, label %omp_loop.body
}
*** IR Dump After DSEPass on _QQmain..omp_par ***
; Function Attrs: norecurse nounwind
define internal void @_QQmain..omp_par(ptr noalias %tid.addr, ptr noalias %zero.addr, ptr %0) #2 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %gep_3 = getelementptr { ptr, ptr, ptr }, ptr %0, i64 0, i32 2
  %loadgep_4 = load ptr, ptr %gep_3, align 8
  %p.lastiter = alloca i32, align 4
  %p.lowerbound = alloca i32, align 4
  %p.upperbound = alloca i32, align 4
  %p.stride = alloca i32, align 4
  %1 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %omp_loop.tripcount = tail call i32 @llvm.smax.i32(i32 %1, i32 0)
  store i32 0, ptr %p.lowerbound, align 4
  %2 = add nsw i32 %omp_loop.tripcount, -1
  store i32 %2, ptr %p.upperbound, align 4
  store i32 1, ptr %p.stride, align 4
  %omp_global_thread_num4 = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  call void @__kmpc_for_static_init_4u(ptr nonnull @1, i32 %omp_global_thread_num4, i32 34, ptr nonnull %p.lastiter, ptr nonnull %p.lowerbound, ptr nonnull %p.upperbound, ptr nonnull %p.stride, i32 1, i32 0)
  %3 = load i32, ptr %p.lowerbound, align 4
  %4 = load i32, ptr %p.upperbound, align 4
  %reass.sub = sub i32 %4, %3
  %omp_loop.cmp65.not = icmp eq i32 %reass.sub, -1
  br i1 %omp_loop.cmp65.not, label %omp_loop.exit, label %omp_loop.body.lr.ph

omp_loop.body.lr.ph:                              ; preds = %omp.par.entry
  %.unpack = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  %.unpack6 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  %.unpack7 = load i32, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  %.unpack8 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  %.unpack9 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  %.unpack10 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  %.unpack11 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  %.unpack12.unpack.unpack = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  %.unpack12.unpack.unpack14 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  %.unpack12.unpack.unpack15 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  %loadgep_2.repack17 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  %loadgep_2.repack19 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  %loadgep_2.repack21 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  %loadgep_2.repack23 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  %loadgep_2.repack25 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  %loadgep_2.repack27 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  %loadgep_2.repack29 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  %loadgep_2.repack29.repack31 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  %loadgep_2.repack29.repack33 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  %loadgep_4.repack47 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 1
  %loadgep_4.repack49 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 2
  %loadgep_4.repack51 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 3
  %loadgep_4.repack53 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 4
  %loadgep_4.repack55 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 5
  %loadgep_4.repack57 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 6
  %loadgep_4.repack59 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7
  %loadgep_4.repack59.repack61 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 1
  %loadgep_4.repack59.repack63 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 2
  br label %omp_loop.body

omp_loop.exit:                                    ; preds = %omp_loop.body, %omp.par.entry
  call void @__kmpc_for_static_fini(ptr nonnull @1, i32 %omp_global_thread_num4)
  call void @__kmpc_barrier(ptr nonnull @2, i32 %omp_global_thread_num4)
  ret void

omp_loop.body:                                    ; preds = %omp_loop.body.lr.ph, %omp_loop.body
  %omp_loop.iv66 = phi i32 [ 0, %omp_loop.body.lr.ph ], [ %5, %omp_loop.body ]
  %5 = add nuw i32 %omp_loop.iv66, 1
  %6 = add i32 %5, %3
  %7 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %8 = sitofp i32 %7 to float
  %9 = fdiv contract float 1.000000e+00, %8
  %10 = fpext float %9 to double
  store ptr %.unpack, ptr %loadgep_2, align 8, !tbaa !8
  store i64 %.unpack6, ptr %loadgep_2.repack17, align 8, !tbaa !8
  store i32 %.unpack7, ptr %loadgep_2.repack19, align 8, !tbaa !8
  store i8 %.unpack8, ptr %loadgep_2.repack21, align 4, !tbaa !8
  store i8 %.unpack9, ptr %loadgep_2.repack23, align 1, !tbaa !8
  store i8 %.unpack10, ptr %loadgep_2.repack25, align 2, !tbaa !8
  store i8 %.unpack11, ptr %loadgep_2.repack27, align 1, !tbaa !8
  store i64 %.unpack12.unpack.unpack, ptr %loadgep_2.repack29, align 8, !tbaa !8
  store i64 %.unpack12.unpack.unpack14, ptr %loadgep_2.repack29.repack31, align 8, !tbaa !8
  store i64 %.unpack12.unpack.unpack15, ptr %loadgep_2.repack29.repack33, align 8, !tbaa !8
  %11 = sext i32 %6 to i64
  %12 = sub i64 %11, %.unpack12.unpack.unpack
  %13 = getelementptr double, ptr %.unpack, i64 %12
  store double %10, ptr %13, align 8, !tbaa !4
  store ptr %.unpack, ptr %loadgep_4, align 8, !tbaa !8
  store i64 %.unpack6, ptr %loadgep_4.repack47, align 8, !tbaa !8
  store i32 %.unpack7, ptr %loadgep_4.repack49, align 8, !tbaa !8
  store i8 %.unpack8, ptr %loadgep_4.repack51, align 4, !tbaa !8
  store i8 %.unpack9, ptr %loadgep_4.repack53, align 1, !tbaa !8
  store i8 %.unpack10, ptr %loadgep_4.repack55, align 2, !tbaa !8
  store i8 %.unpack11, ptr %loadgep_4.repack57, align 1, !tbaa !8
  store i64 %.unpack12.unpack.unpack, ptr %loadgep_4.repack59, align 8, !tbaa !8
  store i64 %.unpack12.unpack.unpack14, ptr %loadgep_4.repack59.repack61, align 8, !tbaa !8
  store i64 %.unpack12.unpack.unpack15, ptr %loadgep_4.repack59.repack63, align 8, !tbaa !8
  %exitcond.not = icmp eq i32 %omp_loop.iv66, %reass.sub
  br i1 %exitcond.not, label %omp_loop.exit, label %omp_loop.body
}
*** IR Dump After MoveAutoInitPass on _QQmain..omp_par ***
; Function Attrs: norecurse nounwind
define internal void @_QQmain..omp_par(ptr noalias %tid.addr, ptr noalias %zero.addr, ptr %0) #2 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %gep_3 = getelementptr { ptr, ptr, ptr }, ptr %0, i64 0, i32 2
  %loadgep_4 = load ptr, ptr %gep_3, align 8
  %p.lastiter = alloca i32, align 4
  %p.lowerbound = alloca i32, align 4
  %p.upperbound = alloca i32, align 4
  %p.stride = alloca i32, align 4
  %1 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %omp_loop.tripcount = tail call i32 @llvm.smax.i32(i32 %1, i32 0)
  store i32 0, ptr %p.lowerbound, align 4
  %2 = add nsw i32 %omp_loop.tripcount, -1
  store i32 %2, ptr %p.upperbound, align 4
  store i32 1, ptr %p.stride, align 4
  %omp_global_thread_num4 = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  call void @__kmpc_for_static_init_4u(ptr nonnull @1, i32 %omp_global_thread_num4, i32 34, ptr nonnull %p.lastiter, ptr nonnull %p.lowerbound, ptr nonnull %p.upperbound, ptr nonnull %p.stride, i32 1, i32 0)
  %3 = load i32, ptr %p.lowerbound, align 4
  %4 = load i32, ptr %p.upperbound, align 4
  %reass.sub = sub i32 %4, %3
  %omp_loop.cmp65.not = icmp eq i32 %reass.sub, -1
  br i1 %omp_loop.cmp65.not, label %omp_loop.exit, label %omp_loop.body.lr.ph

omp_loop.body.lr.ph:                              ; preds = %omp.par.entry
  %.unpack = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  %.unpack6 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  %.unpack7 = load i32, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  %.unpack8 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  %.unpack9 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  %.unpack10 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  %.unpack11 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  %.unpack12.unpack.unpack = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  %.unpack12.unpack.unpack14 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  %.unpack12.unpack.unpack15 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  %loadgep_2.repack17 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  %loadgep_2.repack19 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  %loadgep_2.repack21 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  %loadgep_2.repack23 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  %loadgep_2.repack25 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  %loadgep_2.repack27 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  %loadgep_2.repack29 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  %loadgep_2.repack29.repack31 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  %loadgep_2.repack29.repack33 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  %loadgep_4.repack47 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 1
  %loadgep_4.repack49 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 2
  %loadgep_4.repack51 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 3
  %loadgep_4.repack53 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 4
  %loadgep_4.repack55 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 5
  %loadgep_4.repack57 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 6
  %loadgep_4.repack59 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7
  %loadgep_4.repack59.repack61 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 1
  %loadgep_4.repack59.repack63 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 2
  br label %omp_loop.body

omp_loop.exit:                                    ; preds = %omp_loop.body, %omp.par.entry
  call void @__kmpc_for_static_fini(ptr nonnull @1, i32 %omp_global_thread_num4)
  call void @__kmpc_barrier(ptr nonnull @2, i32 %omp_global_thread_num4)
  ret void

omp_loop.body:                                    ; preds = %omp_loop.body.lr.ph, %omp_loop.body
  %omp_loop.iv66 = phi i32 [ 0, %omp_loop.body.lr.ph ], [ %5, %omp_loop.body ]
  %5 = add nuw i32 %omp_loop.iv66, 1
  %6 = add i32 %5, %3
  %7 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %8 = sitofp i32 %7 to float
  %9 = fdiv contract float 1.000000e+00, %8
  %10 = fpext float %9 to double
  store ptr %.unpack, ptr %loadgep_2, align 8, !tbaa !8
  store i64 %.unpack6, ptr %loadgep_2.repack17, align 8, !tbaa !8
  store i32 %.unpack7, ptr %loadgep_2.repack19, align 8, !tbaa !8
  store i8 %.unpack8, ptr %loadgep_2.repack21, align 4, !tbaa !8
  store i8 %.unpack9, ptr %loadgep_2.repack23, align 1, !tbaa !8
  store i8 %.unpack10, ptr %loadgep_2.repack25, align 2, !tbaa !8
  store i8 %.unpack11, ptr %loadgep_2.repack27, align 1, !tbaa !8
  store i64 %.unpack12.unpack.unpack, ptr %loadgep_2.repack29, align 8, !tbaa !8
  store i64 %.unpack12.unpack.unpack14, ptr %loadgep_2.repack29.repack31, align 8, !tbaa !8
  store i64 %.unpack12.unpack.unpack15, ptr %loadgep_2.repack29.repack33, align 8, !tbaa !8
  %11 = sext i32 %6 to i64
  %12 = sub i64 %11, %.unpack12.unpack.unpack
  %13 = getelementptr double, ptr %.unpack, i64 %12
  store double %10, ptr %13, align 8, !tbaa !4
  store ptr %.unpack, ptr %loadgep_4, align 8, !tbaa !8
  store i64 %.unpack6, ptr %loadgep_4.repack47, align 8, !tbaa !8
  store i32 %.unpack7, ptr %loadgep_4.repack49, align 8, !tbaa !8
  store i8 %.unpack8, ptr %loadgep_4.repack51, align 4, !tbaa !8
  store i8 %.unpack9, ptr %loadgep_4.repack53, align 1, !tbaa !8
  store i8 %.unpack10, ptr %loadgep_4.repack55, align 2, !tbaa !8
  store i8 %.unpack11, ptr %loadgep_4.repack57, align 1, !tbaa !8
  store i64 %.unpack12.unpack.unpack, ptr %loadgep_4.repack59, align 8, !tbaa !8
  store i64 %.unpack12.unpack.unpack14, ptr %loadgep_4.repack59.repack61, align 8, !tbaa !8
  store i64 %.unpack12.unpack.unpack15, ptr %loadgep_4.repack59.repack63, align 8, !tbaa !8
  %exitcond.not = icmp eq i32 %omp_loop.iv66, %reass.sub
  br i1 %exitcond.not, label %omp_loop.exit, label %omp_loop.body
}
*** IR Dump After LoopSimplifyPass on _QQmain..omp_par ***
; Function Attrs: norecurse nounwind
define internal void @_QQmain..omp_par(ptr noalias %tid.addr, ptr noalias %zero.addr, ptr %0) #2 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %gep_3 = getelementptr { ptr, ptr, ptr }, ptr %0, i64 0, i32 2
  %loadgep_4 = load ptr, ptr %gep_3, align 8
  %p.lastiter = alloca i32, align 4
  %p.lowerbound = alloca i32, align 4
  %p.upperbound = alloca i32, align 4
  %p.stride = alloca i32, align 4
  %1 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %omp_loop.tripcount = tail call i32 @llvm.smax.i32(i32 %1, i32 0)
  store i32 0, ptr %p.lowerbound, align 4
  %2 = add nsw i32 %omp_loop.tripcount, -1
  store i32 %2, ptr %p.upperbound, align 4
  store i32 1, ptr %p.stride, align 4
  %omp_global_thread_num4 = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  call void @__kmpc_for_static_init_4u(ptr nonnull @1, i32 %omp_global_thread_num4, i32 34, ptr nonnull %p.lastiter, ptr nonnull %p.lowerbound, ptr nonnull %p.upperbound, ptr nonnull %p.stride, i32 1, i32 0)
  %3 = load i32, ptr %p.lowerbound, align 4
  %4 = load i32, ptr %p.upperbound, align 4
  %reass.sub = sub i32 %4, %3
  %omp_loop.cmp65.not = icmp eq i32 %reass.sub, -1
  br i1 %omp_loop.cmp65.not, label %omp_loop.exit, label %omp_loop.body.lr.ph

omp_loop.body.lr.ph:                              ; preds = %omp.par.entry
  %.unpack = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  %.unpack6 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  %.unpack7 = load i32, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  %.unpack8 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  %.unpack9 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  %.unpack10 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  %.unpack11 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  %.unpack12.unpack.unpack = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  %.unpack12.unpack.unpack14 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  %.unpack12.unpack.unpack15 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  %loadgep_2.repack17 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  %loadgep_2.repack19 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  %loadgep_2.repack21 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  %loadgep_2.repack23 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  %loadgep_2.repack25 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  %loadgep_2.repack27 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  %loadgep_2.repack29 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  %loadgep_2.repack29.repack31 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  %loadgep_2.repack29.repack33 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  %loadgep_4.repack47 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 1
  %loadgep_4.repack49 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 2
  %loadgep_4.repack51 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 3
  %loadgep_4.repack53 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 4
  %loadgep_4.repack55 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 5
  %loadgep_4.repack57 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 6
  %loadgep_4.repack59 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7
  %loadgep_4.repack59.repack61 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 1
  %loadgep_4.repack59.repack63 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 2
  br label %omp_loop.body

omp_loop.exit.loopexit:                           ; preds = %omp_loop.body
  br label %omp_loop.exit

omp_loop.exit:                                    ; preds = %omp_loop.exit.loopexit, %omp.par.entry
  call void @__kmpc_for_static_fini(ptr nonnull @1, i32 %omp_global_thread_num4)
  call void @__kmpc_barrier(ptr nonnull @2, i32 %omp_global_thread_num4)
  ret void

omp_loop.body:                                    ; preds = %omp_loop.body.lr.ph, %omp_loop.body
  %omp_loop.iv66 = phi i32 [ 0, %omp_loop.body.lr.ph ], [ %5, %omp_loop.body ]
  %5 = add nuw i32 %omp_loop.iv66, 1
  %6 = add i32 %5, %3
  %7 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %8 = sitofp i32 %7 to float
  %9 = fdiv contract float 1.000000e+00, %8
  %10 = fpext float %9 to double
  store ptr %.unpack, ptr %loadgep_2, align 8, !tbaa !8
  store i64 %.unpack6, ptr %loadgep_2.repack17, align 8, !tbaa !8
  store i32 %.unpack7, ptr %loadgep_2.repack19, align 8, !tbaa !8
  store i8 %.unpack8, ptr %loadgep_2.repack21, align 4, !tbaa !8
  store i8 %.unpack9, ptr %loadgep_2.repack23, align 1, !tbaa !8
  store i8 %.unpack10, ptr %loadgep_2.repack25, align 2, !tbaa !8
  store i8 %.unpack11, ptr %loadgep_2.repack27, align 1, !tbaa !8
  store i64 %.unpack12.unpack.unpack, ptr %loadgep_2.repack29, align 8, !tbaa !8
  store i64 %.unpack12.unpack.unpack14, ptr %loadgep_2.repack29.repack31, align 8, !tbaa !8
  store i64 %.unpack12.unpack.unpack15, ptr %loadgep_2.repack29.repack33, align 8, !tbaa !8
  %11 = sext i32 %6 to i64
  %12 = sub i64 %11, %.unpack12.unpack.unpack
  %13 = getelementptr double, ptr %.unpack, i64 %12
  store double %10, ptr %13, align 8, !tbaa !4
  store ptr %.unpack, ptr %loadgep_4, align 8, !tbaa !8
  store i64 %.unpack6, ptr %loadgep_4.repack47, align 8, !tbaa !8
  store i32 %.unpack7, ptr %loadgep_4.repack49, align 8, !tbaa !8
  store i8 %.unpack8, ptr %loadgep_4.repack51, align 4, !tbaa !8
  store i8 %.unpack9, ptr %loadgep_4.repack53, align 1, !tbaa !8
  store i8 %.unpack10, ptr %loadgep_4.repack55, align 2, !tbaa !8
  store i8 %.unpack11, ptr %loadgep_4.repack57, align 1, !tbaa !8
  store i64 %.unpack12.unpack.unpack, ptr %loadgep_4.repack59, align 8, !tbaa !8
  store i64 %.unpack12.unpack.unpack14, ptr %loadgep_4.repack59.repack61, align 8, !tbaa !8
  store i64 %.unpack12.unpack.unpack15, ptr %loadgep_4.repack59.repack63, align 8, !tbaa !8
  %exitcond.not = icmp eq i32 %omp_loop.iv66, %reass.sub
  br i1 %exitcond.not, label %omp_loop.exit.loopexit, label %omp_loop.body
}
*** IR Dump After LCSSAPass on _QQmain..omp_par ***
; Function Attrs: norecurse nounwind
define internal void @_QQmain..omp_par(ptr noalias %tid.addr, ptr noalias %zero.addr, ptr %0) #2 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %gep_3 = getelementptr { ptr, ptr, ptr }, ptr %0, i64 0, i32 2
  %loadgep_4 = load ptr, ptr %gep_3, align 8
  %p.lastiter = alloca i32, align 4
  %p.lowerbound = alloca i32, align 4
  %p.upperbound = alloca i32, align 4
  %p.stride = alloca i32, align 4
  %1 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %omp_loop.tripcount = tail call i32 @llvm.smax.i32(i32 %1, i32 0)
  store i32 0, ptr %p.lowerbound, align 4
  %2 = add nsw i32 %omp_loop.tripcount, -1
  store i32 %2, ptr %p.upperbound, align 4
  store i32 1, ptr %p.stride, align 4
  %omp_global_thread_num4 = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  call void @__kmpc_for_static_init_4u(ptr nonnull @1, i32 %omp_global_thread_num4, i32 34, ptr nonnull %p.lastiter, ptr nonnull %p.lowerbound, ptr nonnull %p.upperbound, ptr nonnull %p.stride, i32 1, i32 0)
  %3 = load i32, ptr %p.lowerbound, align 4
  %4 = load i32, ptr %p.upperbound, align 4
  %reass.sub = sub i32 %4, %3
  %omp_loop.cmp65.not = icmp eq i32 %reass.sub, -1
  br i1 %omp_loop.cmp65.not, label %omp_loop.exit, label %omp_loop.body.lr.ph

omp_loop.body.lr.ph:                              ; preds = %omp.par.entry
  %.unpack = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  %.unpack6 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  %.unpack7 = load i32, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  %.unpack8 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  %.unpack9 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  %.unpack10 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  %.unpack11 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  %.unpack12.unpack.unpack = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  %.unpack12.unpack.unpack14 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  %.unpack12.unpack.unpack15 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  %loadgep_2.repack17 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  %loadgep_2.repack19 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  %loadgep_2.repack21 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  %loadgep_2.repack23 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  %loadgep_2.repack25 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  %loadgep_2.repack27 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  %loadgep_2.repack29 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  %loadgep_2.repack29.repack31 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  %loadgep_2.repack29.repack33 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  %loadgep_4.repack47 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 1
  %loadgep_4.repack49 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 2
  %loadgep_4.repack51 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 3
  %loadgep_4.repack53 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 4
  %loadgep_4.repack55 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 5
  %loadgep_4.repack57 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 6
  %loadgep_4.repack59 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7
  %loadgep_4.repack59.repack61 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 1
  %loadgep_4.repack59.repack63 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 2
  br label %omp_loop.body

omp_loop.exit.loopexit:                           ; preds = %omp_loop.body
  br label %omp_loop.exit

omp_loop.exit:                                    ; preds = %omp_loop.exit.loopexit, %omp.par.entry
  call void @__kmpc_for_static_fini(ptr nonnull @1, i32 %omp_global_thread_num4)
  call void @__kmpc_barrier(ptr nonnull @2, i32 %omp_global_thread_num4)
  ret void

omp_loop.body:                                    ; preds = %omp_loop.body.lr.ph, %omp_loop.body
  %omp_loop.iv66 = phi i32 [ 0, %omp_loop.body.lr.ph ], [ %5, %omp_loop.body ]
  %5 = add nuw i32 %omp_loop.iv66, 1
  %6 = add i32 %5, %3
  %7 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %8 = sitofp i32 %7 to float
  %9 = fdiv contract float 1.000000e+00, %8
  %10 = fpext float %9 to double
  store ptr %.unpack, ptr %loadgep_2, align 8, !tbaa !8
  store i64 %.unpack6, ptr %loadgep_2.repack17, align 8, !tbaa !8
  store i32 %.unpack7, ptr %loadgep_2.repack19, align 8, !tbaa !8
  store i8 %.unpack8, ptr %loadgep_2.repack21, align 4, !tbaa !8
  store i8 %.unpack9, ptr %loadgep_2.repack23, align 1, !tbaa !8
  store i8 %.unpack10, ptr %loadgep_2.repack25, align 2, !tbaa !8
  store i8 %.unpack11, ptr %loadgep_2.repack27, align 1, !tbaa !8
  store i64 %.unpack12.unpack.unpack, ptr %loadgep_2.repack29, align 8, !tbaa !8
  store i64 %.unpack12.unpack.unpack14, ptr %loadgep_2.repack29.repack31, align 8, !tbaa !8
  store i64 %.unpack12.unpack.unpack15, ptr %loadgep_2.repack29.repack33, align 8, !tbaa !8
  %11 = sext i32 %6 to i64
  %12 = sub i64 %11, %.unpack12.unpack.unpack
  %13 = getelementptr double, ptr %.unpack, i64 %12
  store double %10, ptr %13, align 8, !tbaa !4
  store ptr %.unpack, ptr %loadgep_4, align 8, !tbaa !8
  store i64 %.unpack6, ptr %loadgep_4.repack47, align 8, !tbaa !8
  store i32 %.unpack7, ptr %loadgep_4.repack49, align 8, !tbaa !8
  store i8 %.unpack8, ptr %loadgep_4.repack51, align 4, !tbaa !8
  store i8 %.unpack9, ptr %loadgep_4.repack53, align 1, !tbaa !8
  store i8 %.unpack10, ptr %loadgep_4.repack55, align 2, !tbaa !8
  store i8 %.unpack11, ptr %loadgep_4.repack57, align 1, !tbaa !8
  store i64 %.unpack12.unpack.unpack, ptr %loadgep_4.repack59, align 8, !tbaa !8
  store i64 %.unpack12.unpack.unpack14, ptr %loadgep_4.repack59.repack61, align 8, !tbaa !8
  store i64 %.unpack12.unpack.unpack15, ptr %loadgep_4.repack59.repack63, align 8, !tbaa !8
  %exitcond.not = icmp eq i32 %omp_loop.iv66, %reass.sub
  br i1 %exitcond.not, label %omp_loop.exit.loopexit, label %omp_loop.body
}
*** IR Dump After LICMPass on omp_loop.body ***

; Preheader:
omp_loop.body.lr.ph:                              ; preds = %omp.par.entry
  %.unpack = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  %.unpack6 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  %.unpack7 = load i32, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  %.unpack8 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  %.unpack9 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  %.unpack10 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  %.unpack11 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  %.unpack12.unpack.unpack = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  %.unpack12.unpack.unpack14 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  %.unpack12.unpack.unpack15 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  %loadgep_2.repack17 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  %loadgep_2.repack19 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  %loadgep_2.repack21 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  %loadgep_2.repack23 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  %loadgep_2.repack25 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  %loadgep_2.repack27 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  %loadgep_2.repack29 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  %loadgep_2.repack29.repack31 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  %loadgep_2.repack29.repack33 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  %loadgep_4.repack47 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 1
  %loadgep_4.repack49 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 2
  %loadgep_4.repack51 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 3
  %loadgep_4.repack53 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 4
  %loadgep_4.repack55 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 5
  %loadgep_4.repack57 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 6
  %loadgep_4.repack59 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7
  %loadgep_4.repack59.repack61 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 1
  %loadgep_4.repack59.repack63 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 2
  br label %omp_loop.body

; Loop:
omp_loop.body:                                    ; preds = %omp_loop.body.lr.ph, %omp_loop.body
  %omp_loop.iv66 = phi i32 [ 0, %omp_loop.body.lr.ph ], [ %5, %omp_loop.body ]
  %5 = add nuw i32 %omp_loop.iv66, 1
  %6 = add i32 %5, %3
  %7 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %8 = sitofp i32 %7 to float
  %9 = fdiv contract float 1.000000e+00, %8
  %10 = fpext float %9 to double
  store ptr %.unpack, ptr %loadgep_2, align 8, !tbaa !8
  store i64 %.unpack6, ptr %loadgep_2.repack17, align 8, !tbaa !8
  store i32 %.unpack7, ptr %loadgep_2.repack19, align 8, !tbaa !8
  store i8 %.unpack8, ptr %loadgep_2.repack21, align 4, !tbaa !8
  store i8 %.unpack9, ptr %loadgep_2.repack23, align 1, !tbaa !8
  store i8 %.unpack10, ptr %loadgep_2.repack25, align 2, !tbaa !8
  store i8 %.unpack11, ptr %loadgep_2.repack27, align 1, !tbaa !8
  store i64 %.unpack12.unpack.unpack, ptr %loadgep_2.repack29, align 8, !tbaa !8
  store i64 %.unpack12.unpack.unpack14, ptr %loadgep_2.repack29.repack31, align 8, !tbaa !8
  store i64 %.unpack12.unpack.unpack15, ptr %loadgep_2.repack29.repack33, align 8, !tbaa !8
  %11 = sext i32 %6 to i64
  %12 = sub i64 %11, %.unpack12.unpack.unpack
  %13 = getelementptr double, ptr %.unpack, i64 %12
  store double %10, ptr %13, align 8, !tbaa !4
  store ptr %.unpack, ptr %loadgep_4, align 8, !tbaa !8
  store i64 %.unpack6, ptr %loadgep_4.repack47, align 8, !tbaa !8
  store i32 %.unpack7, ptr %loadgep_4.repack49, align 8, !tbaa !8
  store i8 %.unpack8, ptr %loadgep_4.repack51, align 4, !tbaa !8
  store i8 %.unpack9, ptr %loadgep_4.repack53, align 1, !tbaa !8
  store i8 %.unpack10, ptr %loadgep_4.repack55, align 2, !tbaa !8
  store i8 %.unpack11, ptr %loadgep_4.repack57, align 1, !tbaa !8
  store i64 %.unpack12.unpack.unpack, ptr %loadgep_4.repack59, align 8, !tbaa !8
  store i64 %.unpack12.unpack.unpack14, ptr %loadgep_4.repack59.repack61, align 8, !tbaa !8
  store i64 %.unpack12.unpack.unpack15, ptr %loadgep_4.repack59.repack63, align 8, !tbaa !8
  %exitcond.not = icmp eq i32 %omp_loop.iv66, %reass.sub
  br i1 %exitcond.not, label %omp_loop.exit.loopexit, label %omp_loop.body

; Exit blocks
omp_loop.exit.loopexit:                           ; preds = %omp_loop.body
  br label %omp_loop.exit
*** IR Dump After CoroElidePass on _QQmain..omp_par ***
; Function Attrs: norecurse nounwind
define internal void @_QQmain..omp_par(ptr noalias %tid.addr, ptr noalias %zero.addr, ptr %0) #2 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %gep_3 = getelementptr { ptr, ptr, ptr }, ptr %0, i64 0, i32 2
  %loadgep_4 = load ptr, ptr %gep_3, align 8
  %p.lastiter = alloca i32, align 4
  %p.lowerbound = alloca i32, align 4
  %p.upperbound = alloca i32, align 4
  %p.stride = alloca i32, align 4
  %1 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %omp_loop.tripcount = tail call i32 @llvm.smax.i32(i32 %1, i32 0)
  store i32 0, ptr %p.lowerbound, align 4
  %2 = add nsw i32 %omp_loop.tripcount, -1
  store i32 %2, ptr %p.upperbound, align 4
  store i32 1, ptr %p.stride, align 4
  %omp_global_thread_num4 = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  call void @__kmpc_for_static_init_4u(ptr nonnull @1, i32 %omp_global_thread_num4, i32 34, ptr nonnull %p.lastiter, ptr nonnull %p.lowerbound, ptr nonnull %p.upperbound, ptr nonnull %p.stride, i32 1, i32 0)
  %3 = load i32, ptr %p.lowerbound, align 4
  %4 = load i32, ptr %p.upperbound, align 4
  %reass.sub = sub i32 %4, %3
  %omp_loop.cmp65.not = icmp eq i32 %reass.sub, -1
  br i1 %omp_loop.cmp65.not, label %omp_loop.exit, label %omp_loop.body.lr.ph

omp_loop.body.lr.ph:                              ; preds = %omp.par.entry
  %.unpack = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  %.unpack6 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  %.unpack7 = load i32, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  %.unpack8 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  %.unpack9 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  %.unpack10 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  %.unpack11 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  %.unpack12.unpack.unpack = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  %.unpack12.unpack.unpack14 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  %.unpack12.unpack.unpack15 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  %loadgep_2.repack17 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  %loadgep_2.repack19 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  %loadgep_2.repack21 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  %loadgep_2.repack23 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  %loadgep_2.repack25 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  %loadgep_2.repack27 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  %loadgep_2.repack29 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  %loadgep_2.repack29.repack31 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  %loadgep_2.repack29.repack33 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  %loadgep_4.repack47 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 1
  %loadgep_4.repack49 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 2
  %loadgep_4.repack51 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 3
  %loadgep_4.repack53 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 4
  %loadgep_4.repack55 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 5
  %loadgep_4.repack57 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 6
  %loadgep_4.repack59 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7
  %loadgep_4.repack59.repack61 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 1
  %loadgep_4.repack59.repack63 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 2
  br label %omp_loop.body

omp_loop.exit.loopexit:                           ; preds = %omp_loop.body
  br label %omp_loop.exit

omp_loop.exit:                                    ; preds = %omp_loop.exit.loopexit, %omp.par.entry
  call void @__kmpc_for_static_fini(ptr nonnull @1, i32 %omp_global_thread_num4)
  call void @__kmpc_barrier(ptr nonnull @2, i32 %omp_global_thread_num4)
  ret void

omp_loop.body:                                    ; preds = %omp_loop.body.lr.ph, %omp_loop.body
  %omp_loop.iv66 = phi i32 [ 0, %omp_loop.body.lr.ph ], [ %5, %omp_loop.body ]
  %5 = add nuw i32 %omp_loop.iv66, 1
  %6 = add i32 %5, %3
  %7 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %8 = sitofp i32 %7 to float
  %9 = fdiv contract float 1.000000e+00, %8
  %10 = fpext float %9 to double
  store ptr %.unpack, ptr %loadgep_2, align 8, !tbaa !8
  store i64 %.unpack6, ptr %loadgep_2.repack17, align 8, !tbaa !8
  store i32 %.unpack7, ptr %loadgep_2.repack19, align 8, !tbaa !8
  store i8 %.unpack8, ptr %loadgep_2.repack21, align 4, !tbaa !8
  store i8 %.unpack9, ptr %loadgep_2.repack23, align 1, !tbaa !8
  store i8 %.unpack10, ptr %loadgep_2.repack25, align 2, !tbaa !8
  store i8 %.unpack11, ptr %loadgep_2.repack27, align 1, !tbaa !8
  store i64 %.unpack12.unpack.unpack, ptr %loadgep_2.repack29, align 8, !tbaa !8
  store i64 %.unpack12.unpack.unpack14, ptr %loadgep_2.repack29.repack31, align 8, !tbaa !8
  store i64 %.unpack12.unpack.unpack15, ptr %loadgep_2.repack29.repack33, align 8, !tbaa !8
  %11 = sext i32 %6 to i64
  %12 = sub i64 %11, %.unpack12.unpack.unpack
  %13 = getelementptr double, ptr %.unpack, i64 %12
  store double %10, ptr %13, align 8, !tbaa !4
  store ptr %.unpack, ptr %loadgep_4, align 8, !tbaa !8
  store i64 %.unpack6, ptr %loadgep_4.repack47, align 8, !tbaa !8
  store i32 %.unpack7, ptr %loadgep_4.repack49, align 8, !tbaa !8
  store i8 %.unpack8, ptr %loadgep_4.repack51, align 4, !tbaa !8
  store i8 %.unpack9, ptr %loadgep_4.repack53, align 1, !tbaa !8
  store i8 %.unpack10, ptr %loadgep_4.repack55, align 2, !tbaa !8
  store i8 %.unpack11, ptr %loadgep_4.repack57, align 1, !tbaa !8
  store i64 %.unpack12.unpack.unpack, ptr %loadgep_4.repack59, align 8, !tbaa !8
  store i64 %.unpack12.unpack.unpack14, ptr %loadgep_4.repack59.repack61, align 8, !tbaa !8
  store i64 %.unpack12.unpack.unpack15, ptr %loadgep_4.repack59.repack63, align 8, !tbaa !8
  %exitcond.not = icmp eq i32 %omp_loop.iv66, %reass.sub
  br i1 %exitcond.not, label %omp_loop.exit.loopexit, label %omp_loop.body
}
*** IR Dump After SimplifyCFGPass on _QQmain..omp_par ***
; Function Attrs: norecurse nounwind
define internal void @_QQmain..omp_par(ptr noalias %tid.addr, ptr noalias %zero.addr, ptr %0) #2 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %gep_3 = getelementptr { ptr, ptr, ptr }, ptr %0, i64 0, i32 2
  %loadgep_4 = load ptr, ptr %gep_3, align 8
  %p.lastiter = alloca i32, align 4
  %p.lowerbound = alloca i32, align 4
  %p.upperbound = alloca i32, align 4
  %p.stride = alloca i32, align 4
  %1 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %omp_loop.tripcount = tail call i32 @llvm.smax.i32(i32 %1, i32 0)
  store i32 0, ptr %p.lowerbound, align 4
  %2 = add nsw i32 %omp_loop.tripcount, -1
  store i32 %2, ptr %p.upperbound, align 4
  store i32 1, ptr %p.stride, align 4
  %omp_global_thread_num4 = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  call void @__kmpc_for_static_init_4u(ptr nonnull @1, i32 %omp_global_thread_num4, i32 34, ptr nonnull %p.lastiter, ptr nonnull %p.lowerbound, ptr nonnull %p.upperbound, ptr nonnull %p.stride, i32 1, i32 0)
  %3 = load i32, ptr %p.lowerbound, align 4
  %4 = load i32, ptr %p.upperbound, align 4
  %reass.sub = sub i32 %4, %3
  %omp_loop.cmp65.not = icmp eq i32 %reass.sub, -1
  br i1 %omp_loop.cmp65.not, label %omp_loop.exit, label %omp_loop.body.lr.ph

omp_loop.body.lr.ph:                              ; preds = %omp.par.entry
  %.unpack = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  %.unpack6 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  %.unpack7 = load i32, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  %.unpack8 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  %.unpack9 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  %.unpack10 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  %.unpack11 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  %.unpack12.unpack.unpack = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  %.unpack12.unpack.unpack14 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  %.unpack12.unpack.unpack15 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  %loadgep_2.repack17 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  %loadgep_2.repack19 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  %loadgep_2.repack21 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  %loadgep_2.repack23 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  %loadgep_2.repack25 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  %loadgep_2.repack27 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  %loadgep_2.repack29 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  %loadgep_2.repack29.repack31 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  %loadgep_2.repack29.repack33 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  %loadgep_4.repack47 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 1
  %loadgep_4.repack49 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 2
  %loadgep_4.repack51 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 3
  %loadgep_4.repack53 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 4
  %loadgep_4.repack55 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 5
  %loadgep_4.repack57 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 6
  %loadgep_4.repack59 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7
  %loadgep_4.repack59.repack61 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 1
  %loadgep_4.repack59.repack63 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 2
  br label %omp_loop.body

omp_loop.exit:                                    ; preds = %omp_loop.body, %omp.par.entry
  call void @__kmpc_for_static_fini(ptr nonnull @1, i32 %omp_global_thread_num4)
  call void @__kmpc_barrier(ptr nonnull @2, i32 %omp_global_thread_num4)
  ret void

omp_loop.body:                                    ; preds = %omp_loop.body.lr.ph, %omp_loop.body
  %omp_loop.iv66 = phi i32 [ 0, %omp_loop.body.lr.ph ], [ %5, %omp_loop.body ]
  %5 = add nuw i32 %omp_loop.iv66, 1
  %6 = add i32 %5, %3
  %7 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %8 = sitofp i32 %7 to float
  %9 = fdiv contract float 1.000000e+00, %8
  %10 = fpext float %9 to double
  store ptr %.unpack, ptr %loadgep_2, align 8, !tbaa !8
  store i64 %.unpack6, ptr %loadgep_2.repack17, align 8, !tbaa !8
  store i32 %.unpack7, ptr %loadgep_2.repack19, align 8, !tbaa !8
  store i8 %.unpack8, ptr %loadgep_2.repack21, align 4, !tbaa !8
  store i8 %.unpack9, ptr %loadgep_2.repack23, align 1, !tbaa !8
  store i8 %.unpack10, ptr %loadgep_2.repack25, align 2, !tbaa !8
  store i8 %.unpack11, ptr %loadgep_2.repack27, align 1, !tbaa !8
  store i64 %.unpack12.unpack.unpack, ptr %loadgep_2.repack29, align 8, !tbaa !8
  store i64 %.unpack12.unpack.unpack14, ptr %loadgep_2.repack29.repack31, align 8, !tbaa !8
  store i64 %.unpack12.unpack.unpack15, ptr %loadgep_2.repack29.repack33, align 8, !tbaa !8
  %11 = sext i32 %6 to i64
  %12 = sub i64 %11, %.unpack12.unpack.unpack
  %13 = getelementptr double, ptr %.unpack, i64 %12
  store double %10, ptr %13, align 8, !tbaa !4
  store ptr %.unpack, ptr %loadgep_4, align 8, !tbaa !8
  store i64 %.unpack6, ptr %loadgep_4.repack47, align 8, !tbaa !8
  store i32 %.unpack7, ptr %loadgep_4.repack49, align 8, !tbaa !8
  store i8 %.unpack8, ptr %loadgep_4.repack51, align 4, !tbaa !8
  store i8 %.unpack9, ptr %loadgep_4.repack53, align 1, !tbaa !8
  store i8 %.unpack10, ptr %loadgep_4.repack55, align 2, !tbaa !8
  store i8 %.unpack11, ptr %loadgep_4.repack57, align 1, !tbaa !8
  store i64 %.unpack12.unpack.unpack, ptr %loadgep_4.repack59, align 8, !tbaa !8
  store i64 %.unpack12.unpack.unpack14, ptr %loadgep_4.repack59.repack61, align 8, !tbaa !8
  store i64 %.unpack12.unpack.unpack15, ptr %loadgep_4.repack59.repack63, align 8, !tbaa !8
  %exitcond.not = icmp eq i32 %omp_loop.iv66, %reass.sub
  br i1 %exitcond.not, label %omp_loop.exit, label %omp_loop.body
}
*** IR Dump After InstCombinePass on _QQmain..omp_par ***
; Function Attrs: norecurse nounwind
define internal void @_QQmain..omp_par(ptr noalias %tid.addr, ptr noalias %zero.addr, ptr %0) #2 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %gep_3 = getelementptr { ptr, ptr, ptr }, ptr %0, i64 0, i32 2
  %loadgep_4 = load ptr, ptr %gep_3, align 8
  %p.lastiter = alloca i32, align 4
  %p.lowerbound = alloca i32, align 4
  %p.upperbound = alloca i32, align 4
  %p.stride = alloca i32, align 4
  %1 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %omp_loop.tripcount = tail call i32 @llvm.smax.i32(i32 %1, i32 0)
  store i32 0, ptr %p.lowerbound, align 4
  %2 = add nsw i32 %omp_loop.tripcount, -1
  store i32 %2, ptr %p.upperbound, align 4
  store i32 1, ptr %p.stride, align 4
  %omp_global_thread_num4 = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  call void @__kmpc_for_static_init_4u(ptr nonnull @1, i32 %omp_global_thread_num4, i32 34, ptr nonnull %p.lastiter, ptr nonnull %p.lowerbound, ptr nonnull %p.upperbound, ptr nonnull %p.stride, i32 1, i32 0)
  %3 = load i32, ptr %p.lowerbound, align 4
  %4 = load i32, ptr %p.upperbound, align 4
  %reass.sub = sub i32 %4, %3
  %omp_loop.cmp65.not = icmp eq i32 %reass.sub, -1
  br i1 %omp_loop.cmp65.not, label %omp_loop.exit, label %omp_loop.body.lr.ph

omp_loop.body.lr.ph:                              ; preds = %omp.par.entry
  %.unpack = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  %.unpack6 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  %.unpack7 = load i32, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  %.unpack8 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  %.unpack9 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  %.unpack10 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  %.unpack11 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  %.unpack12.unpack.unpack = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  %.unpack12.unpack.unpack14 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  %.unpack12.unpack.unpack15 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  %loadgep_2.repack17 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  %loadgep_2.repack19 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  %loadgep_2.repack21 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  %loadgep_2.repack23 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  %loadgep_2.repack25 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  %loadgep_2.repack27 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  %loadgep_2.repack29 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  %loadgep_2.repack29.repack31 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  %loadgep_2.repack29.repack33 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  %loadgep_4.repack47 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 1
  %loadgep_4.repack49 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 2
  %loadgep_4.repack51 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 3
  %loadgep_4.repack53 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 4
  %loadgep_4.repack55 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 5
  %loadgep_4.repack57 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 6
  %loadgep_4.repack59 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7
  %loadgep_4.repack59.repack61 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 1
  %loadgep_4.repack59.repack63 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 2
  br label %omp_loop.body

omp_loop.exit:                                    ; preds = %omp_loop.body, %omp.par.entry
  call void @__kmpc_for_static_fini(ptr nonnull @1, i32 %omp_global_thread_num4)
  call void @__kmpc_barrier(ptr nonnull @2, i32 %omp_global_thread_num4)
  ret void

omp_loop.body:                                    ; preds = %omp_loop.body.lr.ph, %omp_loop.body
  %omp_loop.iv66 = phi i32 [ 0, %omp_loop.body.lr.ph ], [ %5, %omp_loop.body ]
  %5 = add nuw i32 %omp_loop.iv66, 1
  %6 = add i32 %5, %3
  %7 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %8 = sitofp i32 %7 to float
  %9 = fdiv contract float 1.000000e+00, %8
  %10 = fpext float %9 to double
  store ptr %.unpack, ptr %loadgep_2, align 8, !tbaa !8
  store i64 %.unpack6, ptr %loadgep_2.repack17, align 8, !tbaa !8
  store i32 %.unpack7, ptr %loadgep_2.repack19, align 8, !tbaa !8
  store i8 %.unpack8, ptr %loadgep_2.repack21, align 4, !tbaa !8
  store i8 %.unpack9, ptr %loadgep_2.repack23, align 1, !tbaa !8
  store i8 %.unpack10, ptr %loadgep_2.repack25, align 2, !tbaa !8
  store i8 %.unpack11, ptr %loadgep_2.repack27, align 1, !tbaa !8
  store i64 %.unpack12.unpack.unpack, ptr %loadgep_2.repack29, align 8, !tbaa !8
  store i64 %.unpack12.unpack.unpack14, ptr %loadgep_2.repack29.repack31, align 8, !tbaa !8
  store i64 %.unpack12.unpack.unpack15, ptr %loadgep_2.repack29.repack33, align 8, !tbaa !8
  %11 = sext i32 %6 to i64
  %12 = sub i64 %11, %.unpack12.unpack.unpack
  %13 = getelementptr double, ptr %.unpack, i64 %12
  store double %10, ptr %13, align 8, !tbaa !4
  store ptr %.unpack, ptr %loadgep_4, align 8, !tbaa !8
  store i64 %.unpack6, ptr %loadgep_4.repack47, align 8, !tbaa !8
  store i32 %.unpack7, ptr %loadgep_4.repack49, align 8, !tbaa !8
  store i8 %.unpack8, ptr %loadgep_4.repack51, align 4, !tbaa !8
  store i8 %.unpack9, ptr %loadgep_4.repack53, align 1, !tbaa !8
  store i8 %.unpack10, ptr %loadgep_4.repack55, align 2, !tbaa !8
  store i8 %.unpack11, ptr %loadgep_4.repack57, align 1, !tbaa !8
  store i64 %.unpack12.unpack.unpack, ptr %loadgep_4.repack59, align 8, !tbaa !8
  store i64 %.unpack12.unpack.unpack14, ptr %loadgep_4.repack59.repack61, align 8, !tbaa !8
  store i64 %.unpack12.unpack.unpack15, ptr %loadgep_4.repack59.repack63, align 8, !tbaa !8
  %exitcond.not = icmp eq i32 %omp_loop.iv66, %reass.sub
  br i1 %exitcond.not, label %omp_loop.exit, label %omp_loop.body
}
*** IR Dump After PostOrderFunctionAttrsPass on (_QQmain..omp_par) ***
; Function Attrs: norecurse nounwind
define internal void @_QQmain..omp_par(ptr noalias nocapture readnone %tid.addr, ptr noalias nocapture readnone %zero.addr, ptr nocapture readonly %0) #2 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %gep_3 = getelementptr { ptr, ptr, ptr }, ptr %0, i64 0, i32 2
  %loadgep_4 = load ptr, ptr %gep_3, align 8
  %p.lastiter = alloca i32, align 4
  %p.lowerbound = alloca i32, align 4
  %p.upperbound = alloca i32, align 4
  %p.stride = alloca i32, align 4
  %1 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %omp_loop.tripcount = tail call i32 @llvm.smax.i32(i32 %1, i32 0)
  store i32 0, ptr %p.lowerbound, align 4
  %2 = add nsw i32 %omp_loop.tripcount, -1
  store i32 %2, ptr %p.upperbound, align 4
  store i32 1, ptr %p.stride, align 4
  %omp_global_thread_num4 = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  call void @__kmpc_for_static_init_4u(ptr nonnull @1, i32 %omp_global_thread_num4, i32 34, ptr nonnull %p.lastiter, ptr nonnull %p.lowerbound, ptr nonnull %p.upperbound, ptr nonnull %p.stride, i32 1, i32 0)
  %3 = load i32, ptr %p.lowerbound, align 4
  %4 = load i32, ptr %p.upperbound, align 4
  %reass.sub = sub i32 %4, %3
  %omp_loop.cmp65.not = icmp eq i32 %reass.sub, -1
  br i1 %omp_loop.cmp65.not, label %omp_loop.exit, label %omp_loop.body.lr.ph

omp_loop.body.lr.ph:                              ; preds = %omp.par.entry
  %.unpack = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  %.unpack6 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  %.unpack7 = load i32, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  %.unpack8 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  %.unpack9 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  %.unpack10 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  %.unpack11 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  %.unpack12.unpack.unpack = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  %.unpack12.unpack.unpack14 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  %.unpack12.unpack.unpack15 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  %loadgep_2.repack17 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  %loadgep_2.repack19 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  %loadgep_2.repack21 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  %loadgep_2.repack23 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  %loadgep_2.repack25 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  %loadgep_2.repack27 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  %loadgep_2.repack29 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  %loadgep_2.repack29.repack31 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  %loadgep_2.repack29.repack33 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  %loadgep_4.repack47 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 1
  %loadgep_4.repack49 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 2
  %loadgep_4.repack51 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 3
  %loadgep_4.repack53 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 4
  %loadgep_4.repack55 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 5
  %loadgep_4.repack57 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 6
  %loadgep_4.repack59 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7
  %loadgep_4.repack59.repack61 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 1
  %loadgep_4.repack59.repack63 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 2
  br label %omp_loop.body

omp_loop.exit:                                    ; preds = %omp_loop.body, %omp.par.entry
  call void @__kmpc_for_static_fini(ptr nonnull @1, i32 %omp_global_thread_num4)
  call void @__kmpc_barrier(ptr nonnull @2, i32 %omp_global_thread_num4)
  ret void

omp_loop.body:                                    ; preds = %omp_loop.body.lr.ph, %omp_loop.body
  %omp_loop.iv66 = phi i32 [ 0, %omp_loop.body.lr.ph ], [ %5, %omp_loop.body ]
  %5 = add nuw i32 %omp_loop.iv66, 1
  %6 = add i32 %5, %3
  %7 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %8 = sitofp i32 %7 to float
  %9 = fdiv contract float 1.000000e+00, %8
  %10 = fpext float %9 to double
  store ptr %.unpack, ptr %loadgep_2, align 8, !tbaa !8
  store i64 %.unpack6, ptr %loadgep_2.repack17, align 8, !tbaa !8
  store i32 %.unpack7, ptr %loadgep_2.repack19, align 8, !tbaa !8
  store i8 %.unpack8, ptr %loadgep_2.repack21, align 4, !tbaa !8
  store i8 %.unpack9, ptr %loadgep_2.repack23, align 1, !tbaa !8
  store i8 %.unpack10, ptr %loadgep_2.repack25, align 2, !tbaa !8
  store i8 %.unpack11, ptr %loadgep_2.repack27, align 1, !tbaa !8
  store i64 %.unpack12.unpack.unpack, ptr %loadgep_2.repack29, align 8, !tbaa !8
  store i64 %.unpack12.unpack.unpack14, ptr %loadgep_2.repack29.repack31, align 8, !tbaa !8
  store i64 %.unpack12.unpack.unpack15, ptr %loadgep_2.repack29.repack33, align 8, !tbaa !8
  %11 = sext i32 %6 to i64
  %12 = sub i64 %11, %.unpack12.unpack.unpack
  %13 = getelementptr double, ptr %.unpack, i64 %12
  store double %10, ptr %13, align 8, !tbaa !4
  store ptr %.unpack, ptr %loadgep_4, align 8, !tbaa !8
  store i64 %.unpack6, ptr %loadgep_4.repack47, align 8, !tbaa !8
  store i32 %.unpack7, ptr %loadgep_4.repack49, align 8, !tbaa !8
  store i8 %.unpack8, ptr %loadgep_4.repack51, align 4, !tbaa !8
  store i8 %.unpack9, ptr %loadgep_4.repack53, align 1, !tbaa !8
  store i8 %.unpack10, ptr %loadgep_4.repack55, align 2, !tbaa !8
  store i8 %.unpack11, ptr %loadgep_4.repack57, align 1, !tbaa !8
  store i64 %.unpack12.unpack.unpack, ptr %loadgep_4.repack59, align 8, !tbaa !8
  store i64 %.unpack12.unpack.unpack14, ptr %loadgep_4.repack59.repack61, align 8, !tbaa !8
  store i64 %.unpack12.unpack.unpack15, ptr %loadgep_4.repack59.repack63, align 8, !tbaa !8
  %exitcond.not = icmp eq i32 %omp_loop.iv66, %reass.sub
  br i1 %exitcond.not, label %omp_loop.exit, label %omp_loop.body
}
*** IR Dump After RequireAnalysisPass<llvm::ShouldNotRunFunctionPassesAnalysis, llvm::Function> on _QQmain..omp_par ***
; Function Attrs: norecurse nounwind
define internal void @_QQmain..omp_par(ptr noalias nocapture readnone %tid.addr, ptr noalias nocapture readnone %zero.addr, ptr nocapture readonly %0) #2 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %gep_3 = getelementptr { ptr, ptr, ptr }, ptr %0, i64 0, i32 2
  %loadgep_4 = load ptr, ptr %gep_3, align 8
  %p.lastiter = alloca i32, align 4
  %p.lowerbound = alloca i32, align 4
  %p.upperbound = alloca i32, align 4
  %p.stride = alloca i32, align 4
  %1 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %omp_loop.tripcount = tail call i32 @llvm.smax.i32(i32 %1, i32 0)
  store i32 0, ptr %p.lowerbound, align 4
  %2 = add nsw i32 %omp_loop.tripcount, -1
  store i32 %2, ptr %p.upperbound, align 4
  store i32 1, ptr %p.stride, align 4
  %omp_global_thread_num4 = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  call void @__kmpc_for_static_init_4u(ptr nonnull @1, i32 %omp_global_thread_num4, i32 34, ptr nonnull %p.lastiter, ptr nonnull %p.lowerbound, ptr nonnull %p.upperbound, ptr nonnull %p.stride, i32 1, i32 0)
  %3 = load i32, ptr %p.lowerbound, align 4
  %4 = load i32, ptr %p.upperbound, align 4
  %reass.sub = sub i32 %4, %3
  %omp_loop.cmp65.not = icmp eq i32 %reass.sub, -1
  br i1 %omp_loop.cmp65.not, label %omp_loop.exit, label %omp_loop.body.lr.ph

omp_loop.body.lr.ph:                              ; preds = %omp.par.entry
  %.unpack = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  %.unpack6 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  %.unpack7 = load i32, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  %.unpack8 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  %.unpack9 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  %.unpack10 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  %.unpack11 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  %.unpack12.unpack.unpack = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  %.unpack12.unpack.unpack14 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  %.unpack12.unpack.unpack15 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  %loadgep_2.repack17 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  %loadgep_2.repack19 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  %loadgep_2.repack21 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  %loadgep_2.repack23 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  %loadgep_2.repack25 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  %loadgep_2.repack27 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  %loadgep_2.repack29 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  %loadgep_2.repack29.repack31 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  %loadgep_2.repack29.repack33 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  %loadgep_4.repack47 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 1
  %loadgep_4.repack49 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 2
  %loadgep_4.repack51 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 3
  %loadgep_4.repack53 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 4
  %loadgep_4.repack55 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 5
  %loadgep_4.repack57 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 6
  %loadgep_4.repack59 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7
  %loadgep_4.repack59.repack61 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 1
  %loadgep_4.repack59.repack63 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 2
  br label %omp_loop.body

omp_loop.exit:                                    ; preds = %omp_loop.body, %omp.par.entry
  call void @__kmpc_for_static_fini(ptr nonnull @1, i32 %omp_global_thread_num4)
  call void @__kmpc_barrier(ptr nonnull @2, i32 %omp_global_thread_num4)
  ret void

omp_loop.body:                                    ; preds = %omp_loop.body.lr.ph, %omp_loop.body
  %omp_loop.iv66 = phi i32 [ 0, %omp_loop.body.lr.ph ], [ %5, %omp_loop.body ]
  %5 = add nuw i32 %omp_loop.iv66, 1
  %6 = add i32 %5, %3
  %7 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %8 = sitofp i32 %7 to float
  %9 = fdiv contract float 1.000000e+00, %8
  %10 = fpext float %9 to double
  store ptr %.unpack, ptr %loadgep_2, align 8, !tbaa !8
  store i64 %.unpack6, ptr %loadgep_2.repack17, align 8, !tbaa !8
  store i32 %.unpack7, ptr %loadgep_2.repack19, align 8, !tbaa !8
  store i8 %.unpack8, ptr %loadgep_2.repack21, align 4, !tbaa !8
  store i8 %.unpack9, ptr %loadgep_2.repack23, align 1, !tbaa !8
  store i8 %.unpack10, ptr %loadgep_2.repack25, align 2, !tbaa !8
  store i8 %.unpack11, ptr %loadgep_2.repack27, align 1, !tbaa !8
  store i64 %.unpack12.unpack.unpack, ptr %loadgep_2.repack29, align 8, !tbaa !8
  store i64 %.unpack12.unpack.unpack14, ptr %loadgep_2.repack29.repack31, align 8, !tbaa !8
  store i64 %.unpack12.unpack.unpack15, ptr %loadgep_2.repack29.repack33, align 8, !tbaa !8
  %11 = sext i32 %6 to i64
  %12 = sub i64 %11, %.unpack12.unpack.unpack
  %13 = getelementptr double, ptr %.unpack, i64 %12
  store double %10, ptr %13, align 8, !tbaa !4
  store ptr %.unpack, ptr %loadgep_4, align 8, !tbaa !8
  store i64 %.unpack6, ptr %loadgep_4.repack47, align 8, !tbaa !8
  store i32 %.unpack7, ptr %loadgep_4.repack49, align 8, !tbaa !8
  store i8 %.unpack8, ptr %loadgep_4.repack51, align 4, !tbaa !8
  store i8 %.unpack9, ptr %loadgep_4.repack53, align 1, !tbaa !8
  store i8 %.unpack10, ptr %loadgep_4.repack55, align 2, !tbaa !8
  store i8 %.unpack11, ptr %loadgep_4.repack57, align 1, !tbaa !8
  store i64 %.unpack12.unpack.unpack, ptr %loadgep_4.repack59, align 8, !tbaa !8
  store i64 %.unpack12.unpack.unpack14, ptr %loadgep_4.repack59.repack61, align 8, !tbaa !8
  store i64 %.unpack12.unpack.unpack15, ptr %loadgep_4.repack59.repack63, align 8, !tbaa !8
  %exitcond.not = icmp eq i32 %omp_loop.iv66, %reass.sub
  br i1 %exitcond.not, label %omp_loop.exit, label %omp_loop.body
}
*** IR Dump After CoroSplitPass on (_QQmain..omp_par) ***
; Function Attrs: norecurse nounwind
define internal void @_QQmain..omp_par(ptr noalias nocapture readnone %tid.addr, ptr noalias nocapture readnone %zero.addr, ptr nocapture readonly %0) #2 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %gep_3 = getelementptr { ptr, ptr, ptr }, ptr %0, i64 0, i32 2
  %loadgep_4 = load ptr, ptr %gep_3, align 8
  %p.lastiter = alloca i32, align 4
  %p.lowerbound = alloca i32, align 4
  %p.upperbound = alloca i32, align 4
  %p.stride = alloca i32, align 4
  %1 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %omp_loop.tripcount = tail call i32 @llvm.smax.i32(i32 %1, i32 0)
  store i32 0, ptr %p.lowerbound, align 4
  %2 = add nsw i32 %omp_loop.tripcount, -1
  store i32 %2, ptr %p.upperbound, align 4
  store i32 1, ptr %p.stride, align 4
  %omp_global_thread_num4 = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  call void @__kmpc_for_static_init_4u(ptr nonnull @1, i32 %omp_global_thread_num4, i32 34, ptr nonnull %p.lastiter, ptr nonnull %p.lowerbound, ptr nonnull %p.upperbound, ptr nonnull %p.stride, i32 1, i32 0)
  %3 = load i32, ptr %p.lowerbound, align 4
  %4 = load i32, ptr %p.upperbound, align 4
  %reass.sub = sub i32 %4, %3
  %omp_loop.cmp65.not = icmp eq i32 %reass.sub, -1
  br i1 %omp_loop.cmp65.not, label %omp_loop.exit, label %omp_loop.body.lr.ph

omp_loop.body.lr.ph:                              ; preds = %omp.par.entry
  %.unpack = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  %.unpack6 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  %.unpack7 = load i32, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  %.unpack8 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  %.unpack9 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  %.unpack10 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  %.unpack11 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  %.unpack12.unpack.unpack = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  %.unpack12.unpack.unpack14 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  %.unpack12.unpack.unpack15 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  %loadgep_2.repack17 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  %loadgep_2.repack19 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  %loadgep_2.repack21 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  %loadgep_2.repack23 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  %loadgep_2.repack25 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  %loadgep_2.repack27 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  %loadgep_2.repack29 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  %loadgep_2.repack29.repack31 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  %loadgep_2.repack29.repack33 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  %loadgep_4.repack47 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 1
  %loadgep_4.repack49 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 2
  %loadgep_4.repack51 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 3
  %loadgep_4.repack53 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 4
  %loadgep_4.repack55 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 5
  %loadgep_4.repack57 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 6
  %loadgep_4.repack59 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7
  %loadgep_4.repack59.repack61 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 1
  %loadgep_4.repack59.repack63 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 2
  br label %omp_loop.body

omp_loop.exit:                                    ; preds = %omp_loop.body, %omp.par.entry
  call void @__kmpc_for_static_fini(ptr nonnull @1, i32 %omp_global_thread_num4)
  call void @__kmpc_barrier(ptr nonnull @2, i32 %omp_global_thread_num4)
  ret void

omp_loop.body:                                    ; preds = %omp_loop.body.lr.ph, %omp_loop.body
  %omp_loop.iv66 = phi i32 [ 0, %omp_loop.body.lr.ph ], [ %5, %omp_loop.body ]
  %5 = add nuw i32 %omp_loop.iv66, 1
  %6 = add i32 %5, %3
  %7 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %8 = sitofp i32 %7 to float
  %9 = fdiv contract float 1.000000e+00, %8
  %10 = fpext float %9 to double
  store ptr %.unpack, ptr %loadgep_2, align 8, !tbaa !8
  store i64 %.unpack6, ptr %loadgep_2.repack17, align 8, !tbaa !8
  store i32 %.unpack7, ptr %loadgep_2.repack19, align 8, !tbaa !8
  store i8 %.unpack8, ptr %loadgep_2.repack21, align 4, !tbaa !8
  store i8 %.unpack9, ptr %loadgep_2.repack23, align 1, !tbaa !8
  store i8 %.unpack10, ptr %loadgep_2.repack25, align 2, !tbaa !8
  store i8 %.unpack11, ptr %loadgep_2.repack27, align 1, !tbaa !8
  store i64 %.unpack12.unpack.unpack, ptr %loadgep_2.repack29, align 8, !tbaa !8
  store i64 %.unpack12.unpack.unpack14, ptr %loadgep_2.repack29.repack31, align 8, !tbaa !8
  store i64 %.unpack12.unpack.unpack15, ptr %loadgep_2.repack29.repack33, align 8, !tbaa !8
  %11 = sext i32 %6 to i64
  %12 = sub i64 %11, %.unpack12.unpack.unpack
  %13 = getelementptr double, ptr %.unpack, i64 %12
  store double %10, ptr %13, align 8, !tbaa !4
  store ptr %.unpack, ptr %loadgep_4, align 8, !tbaa !8
  store i64 %.unpack6, ptr %loadgep_4.repack47, align 8, !tbaa !8
  store i32 %.unpack7, ptr %loadgep_4.repack49, align 8, !tbaa !8
  store i8 %.unpack8, ptr %loadgep_4.repack51, align 4, !tbaa !8
  store i8 %.unpack9, ptr %loadgep_4.repack53, align 1, !tbaa !8
  store i8 %.unpack10, ptr %loadgep_4.repack55, align 2, !tbaa !8
  store i8 %.unpack11, ptr %loadgep_4.repack57, align 1, !tbaa !8
  store i64 %.unpack12.unpack.unpack, ptr %loadgep_4.repack59, align 8, !tbaa !8
  store i64 %.unpack12.unpack.unpack14, ptr %loadgep_4.repack59.repack61, align 8, !tbaa !8
  store i64 %.unpack12.unpack.unpack15, ptr %loadgep_4.repack59.repack63, align 8, !tbaa !8
  %exitcond.not = icmp eq i32 %omp_loop.iv66, %reass.sub
  br i1 %exitcond.not, label %omp_loop.exit, label %omp_loop.body
}
*** IR Dump After InlinerPass on (_QQmain) ***
define void @_QQmain() local_unnamed_addr {
entry:
  %structArg = alloca { ptr, ptr, ptr }, align 8
  %0 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %1 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %2 = alloca i32, align 4
  store i32 1048576, ptr %2, align 4, !tbaa !4
  %3 = call dereferenceable_or_null(8388608) ptr @malloc(i64 8388608)
  store ptr %3, ptr @_QFEarr, align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  store i32 20180515, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  store i8 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  store i8 28, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  store i8 2, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  store i8 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  store i64 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  store i64 1048576, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  %omp_global_thread_num = call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %2, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %1, ptr %gep_5, align 8
  %gep_6 = getelementptr inbounds { ptr, ptr, ptr }, ptr %structArg, i64 0, i32 2
  store ptr %0, ptr %gep_6, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QQmain..omp_par, ptr nonnull %structArg)
  %4 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.60ea5a38555821a77357f87d16df9a0f, i32 21)
  %5 = call i1 @_FortranAioOutputAscii(ptr %4, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %6 = load i32, ptr %2, align 4, !tbaa !4
  %7 = call i1 @_FortranAioOutputInteger32(ptr %4, i32 %6)
  %8 = call i1 @_FortranAioOutputAscii(ptr %4, ptr nonnull @_QQcl.2920697320, i64 5)
  %.unpack = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  %.unpack96.unpack.unpack = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  %9 = sub i64 1, %.unpack96.unpack.unpack
  %10 = getelementptr double, ptr %.unpack, i64 %9
  %11 = load double, ptr %10, align 8, !tbaa !4
  %12 = load i32, ptr %2, align 4, !tbaa !4
  %13 = sext i32 %12 to i64
  %14 = sub i64 %13, %.unpack96.unpack.unpack
  %15 = getelementptr double, ptr %.unpack, i64 %14
  %16 = load double, ptr %15, align 8, !tbaa !4
  %17 = fadd contract double %11, %16
  %18 = call i1 @_FortranAioOutputReal64(ptr %4, double %17)
  %19 = call i32 @_FortranAioEndIoStatement(ptr %4)
  %.unpack101 = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  call void @free(ptr %.unpack101)
  store ptr null, ptr @_QFEarr, align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  store i32 20180515, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  store i8 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  store i8 28, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  store i8 2, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  store i8 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  store i64 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  store i64 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  ret void
}
*** IR Dump After InlinerPass on (_QQmain) ***
define void @_QQmain() local_unnamed_addr {
entry:
  %structArg = alloca { ptr, ptr, ptr }, align 8
  %0 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %1 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %2 = alloca i32, align 4
  store i32 1048576, ptr %2, align 4, !tbaa !4
  %3 = call dereferenceable_or_null(8388608) ptr @malloc(i64 8388608)
  store ptr %3, ptr @_QFEarr, align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  store i32 20180515, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  store i8 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  store i8 28, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  store i8 2, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  store i8 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  store i64 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  store i64 1048576, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  %omp_global_thread_num = call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %2, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %1, ptr %gep_5, align 8
  %gep_6 = getelementptr inbounds { ptr, ptr, ptr }, ptr %structArg, i64 0, i32 2
  store ptr %0, ptr %gep_6, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QQmain..omp_par, ptr nonnull %structArg)
  %4 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.60ea5a38555821a77357f87d16df9a0f, i32 21)
  %5 = call i1 @_FortranAioOutputAscii(ptr %4, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %6 = load i32, ptr %2, align 4, !tbaa !4
  %7 = call i1 @_FortranAioOutputInteger32(ptr %4, i32 %6)
  %8 = call i1 @_FortranAioOutputAscii(ptr %4, ptr nonnull @_QQcl.2920697320, i64 5)
  %.unpack = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  %.unpack96.unpack.unpack = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  %9 = sub i64 1, %.unpack96.unpack.unpack
  %10 = getelementptr double, ptr %.unpack, i64 %9
  %11 = load double, ptr %10, align 8, !tbaa !4
  %12 = load i32, ptr %2, align 4, !tbaa !4
  %13 = sext i32 %12 to i64
  %14 = sub i64 %13, %.unpack96.unpack.unpack
  %15 = getelementptr double, ptr %.unpack, i64 %14
  %16 = load double, ptr %15, align 8, !tbaa !4
  %17 = fadd contract double %11, %16
  %18 = call i1 @_FortranAioOutputReal64(ptr %4, double %17)
  %19 = call i32 @_FortranAioEndIoStatement(ptr %4)
  %.unpack101 = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  call void @free(ptr %.unpack101)
  store ptr null, ptr @_QFEarr, align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  store i32 20180515, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  store i8 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  store i8 28, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  store i8 2, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  store i8 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  store i64 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  store i64 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  ret void
}
*** IR Dump After PostOrderFunctionAttrsPass on (_QQmain) ***
define void @_QQmain() local_unnamed_addr {
entry:
  %structArg = alloca { ptr, ptr, ptr }, align 8
  %0 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %1 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %2 = alloca i32, align 4
  store i32 1048576, ptr %2, align 4, !tbaa !4
  %3 = call dereferenceable_or_null(8388608) ptr @malloc(i64 8388608)
  store ptr %3, ptr @_QFEarr, align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  store i32 20180515, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  store i8 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  store i8 28, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  store i8 2, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  store i8 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  store i64 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  store i64 1048576, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  %omp_global_thread_num = call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %2, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %1, ptr %gep_5, align 8
  %gep_6 = getelementptr inbounds { ptr, ptr, ptr }, ptr %structArg, i64 0, i32 2
  store ptr %0, ptr %gep_6, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QQmain..omp_par, ptr nonnull %structArg)
  %4 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.60ea5a38555821a77357f87d16df9a0f, i32 21)
  %5 = call i1 @_FortranAioOutputAscii(ptr %4, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %6 = load i32, ptr %2, align 4, !tbaa !4
  %7 = call i1 @_FortranAioOutputInteger32(ptr %4, i32 %6)
  %8 = call i1 @_FortranAioOutputAscii(ptr %4, ptr nonnull @_QQcl.2920697320, i64 5)
  %.unpack = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  %.unpack96.unpack.unpack = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  %9 = sub i64 1, %.unpack96.unpack.unpack
  %10 = getelementptr double, ptr %.unpack, i64 %9
  %11 = load double, ptr %10, align 8, !tbaa !4
  %12 = load i32, ptr %2, align 4, !tbaa !4
  %13 = sext i32 %12 to i64
  %14 = sub i64 %13, %.unpack96.unpack.unpack
  %15 = getelementptr double, ptr %.unpack, i64 %14
  %16 = load double, ptr %15, align 8, !tbaa !4
  %17 = fadd contract double %11, %16
  %18 = call i1 @_FortranAioOutputReal64(ptr %4, double %17)
  %19 = call i32 @_FortranAioEndIoStatement(ptr %4)
  %.unpack101 = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  call void @free(ptr %.unpack101)
  store ptr null, ptr @_QFEarr, align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  store i32 20180515, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  store i8 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  store i8 28, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  store i8 2, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  store i8 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  store i64 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  store i64 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  ret void
}
*** IR Dump After ArgumentPromotionPass on (_QQmain) ***
define void @_QQmain() local_unnamed_addr {
entry:
  %structArg = alloca { ptr, ptr, ptr }, align 8
  %0 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %1 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %2 = alloca i32, align 4
  store i32 1048576, ptr %2, align 4, !tbaa !4
  %3 = call dereferenceable_or_null(8388608) ptr @malloc(i64 8388608)
  store ptr %3, ptr @_QFEarr, align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  store i32 20180515, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  store i8 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  store i8 28, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  store i8 2, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  store i8 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  store i64 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  store i64 1048576, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  %omp_global_thread_num = call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %2, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %1, ptr %gep_5, align 8
  %gep_6 = getelementptr inbounds { ptr, ptr, ptr }, ptr %structArg, i64 0, i32 2
  store ptr %0, ptr %gep_6, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QQmain..omp_par, ptr nonnull %structArg)
  %4 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.60ea5a38555821a77357f87d16df9a0f, i32 21)
  %5 = call i1 @_FortranAioOutputAscii(ptr %4, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %6 = load i32, ptr %2, align 4, !tbaa !4
  %7 = call i1 @_FortranAioOutputInteger32(ptr %4, i32 %6)
  %8 = call i1 @_FortranAioOutputAscii(ptr %4, ptr nonnull @_QQcl.2920697320, i64 5)
  %.unpack = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  %.unpack96.unpack.unpack = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  %9 = sub i64 1, %.unpack96.unpack.unpack
  %10 = getelementptr double, ptr %.unpack, i64 %9
  %11 = load double, ptr %10, align 8, !tbaa !4
  %12 = load i32, ptr %2, align 4, !tbaa !4
  %13 = sext i32 %12 to i64
  %14 = sub i64 %13, %.unpack96.unpack.unpack
  %15 = getelementptr double, ptr %.unpack, i64 %14
  %16 = load double, ptr %15, align 8, !tbaa !4
  %17 = fadd contract double %11, %16
  %18 = call i1 @_FortranAioOutputReal64(ptr %4, double %17)
  %19 = call i32 @_FortranAioEndIoStatement(ptr %4)
  %.unpack101 = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  call void @free(ptr %.unpack101)
  store ptr null, ptr @_QFEarr, align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  store i32 20180515, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  store i8 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  store i8 28, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  store i8 2, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  store i8 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  store i64 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  store i64 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  ret void
}
*** IR Dump After OpenMPOptCGSCCPass on (_QQmain) ***
define void @_QQmain() local_unnamed_addr {
entry:
  %structArg = alloca { ptr, ptr, ptr }, align 8
  %0 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %1 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %2 = alloca i32, align 4
  store i32 1048576, ptr %2, align 4, !tbaa !4
  %3 = call dereferenceable_or_null(8388608) ptr @malloc(i64 8388608)
  store ptr %3, ptr @_QFEarr, align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  store i32 20180515, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  store i8 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  store i8 28, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  store i8 2, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  store i8 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  store i64 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  store i64 1048576, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  %omp_global_thread_num = call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %2, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %1, ptr %gep_5, align 8
  %gep_6 = getelementptr inbounds { ptr, ptr, ptr }, ptr %structArg, i64 0, i32 2
  store ptr %0, ptr %gep_6, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QQmain..omp_par, ptr nonnull %structArg)
  %4 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.60ea5a38555821a77357f87d16df9a0f, i32 21)
  %5 = call i1 @_FortranAioOutputAscii(ptr %4, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %6 = load i32, ptr %2, align 4, !tbaa !4
  %7 = call i1 @_FortranAioOutputInteger32(ptr %4, i32 %6)
  %8 = call i1 @_FortranAioOutputAscii(ptr %4, ptr nonnull @_QQcl.2920697320, i64 5)
  %.unpack = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  %.unpack96.unpack.unpack = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  %9 = sub i64 1, %.unpack96.unpack.unpack
  %10 = getelementptr double, ptr %.unpack, i64 %9
  %11 = load double, ptr %10, align 8, !tbaa !4
  %12 = load i32, ptr %2, align 4, !tbaa !4
  %13 = sext i32 %12 to i64
  %14 = sub i64 %13, %.unpack96.unpack.unpack
  %15 = getelementptr double, ptr %.unpack, i64 %14
  %16 = load double, ptr %15, align 8, !tbaa !4
  %17 = fadd contract double %11, %16
  %18 = call i1 @_FortranAioOutputReal64(ptr %4, double %17)
  %19 = call i32 @_FortranAioEndIoStatement(ptr %4)
  %.unpack101 = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  call void @free(ptr %.unpack101)
  store ptr null, ptr @_QFEarr, align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  store i32 20180515, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  store i8 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  store i8 28, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  store i8 2, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  store i8 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  store i64 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  store i64 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  ret void
}
*** IR Dump After SROAPass on _QQmain ***
define void @_QQmain() local_unnamed_addr {
entry:
  %structArg = alloca { ptr, ptr, ptr }, align 8
  %0 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %1 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %2 = alloca i32, align 4
  store i32 1048576, ptr %2, align 4, !tbaa !4
  %3 = call dereferenceable_or_null(8388608) ptr @malloc(i64 8388608)
  store ptr %3, ptr @_QFEarr, align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  store i32 20180515, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  store i8 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  store i8 28, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  store i8 2, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  store i8 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  store i64 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  store i64 1048576, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  %omp_global_thread_num = call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %2, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %1, ptr %gep_5, align 8
  %gep_6 = getelementptr inbounds { ptr, ptr, ptr }, ptr %structArg, i64 0, i32 2
  store ptr %0, ptr %gep_6, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QQmain..omp_par, ptr nonnull %structArg)
  %4 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.60ea5a38555821a77357f87d16df9a0f, i32 21)
  %5 = call i1 @_FortranAioOutputAscii(ptr %4, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %6 = load i32, ptr %2, align 4, !tbaa !4
  %7 = call i1 @_FortranAioOutputInteger32(ptr %4, i32 %6)
  %8 = call i1 @_FortranAioOutputAscii(ptr %4, ptr nonnull @_QQcl.2920697320, i64 5)
  %.unpack = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  %.unpack96.unpack.unpack = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  %9 = sub i64 1, %.unpack96.unpack.unpack
  %10 = getelementptr double, ptr %.unpack, i64 %9
  %11 = load double, ptr %10, align 8, !tbaa !4
  %12 = load i32, ptr %2, align 4, !tbaa !4
  %13 = sext i32 %12 to i64
  %14 = sub i64 %13, %.unpack96.unpack.unpack
  %15 = getelementptr double, ptr %.unpack, i64 %14
  %16 = load double, ptr %15, align 8, !tbaa !4
  %17 = fadd contract double %11, %16
  %18 = call i1 @_FortranAioOutputReal64(ptr %4, double %17)
  %19 = call i32 @_FortranAioEndIoStatement(ptr %4)
  %.unpack101 = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  call void @free(ptr %.unpack101)
  store ptr null, ptr @_QFEarr, align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  store i32 20180515, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  store i8 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  store i8 28, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  store i8 2, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  store i8 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  store i64 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  store i64 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  ret void
}
*** IR Dump After EarlyCSEPass on _QQmain ***
define void @_QQmain() local_unnamed_addr {
entry:
  %structArg = alloca { ptr, ptr, ptr }, align 8
  %0 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %1 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %2 = alloca i32, align 4
  store i32 1048576, ptr %2, align 4, !tbaa !4
  %3 = call dereferenceable_or_null(8388608) ptr @malloc(i64 8388608)
  store ptr %3, ptr @_QFEarr, align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  store i32 20180515, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  store i8 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  store i8 28, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  store i8 2, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  store i8 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  store i64 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  store i64 1048576, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  %omp_global_thread_num = call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %2, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %1, ptr %gep_5, align 8
  %gep_6 = getelementptr inbounds { ptr, ptr, ptr }, ptr %structArg, i64 0, i32 2
  store ptr %0, ptr %gep_6, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QQmain..omp_par, ptr nonnull %structArg)
  %4 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.60ea5a38555821a77357f87d16df9a0f, i32 21)
  %5 = call i1 @_FortranAioOutputAscii(ptr %4, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %6 = load i32, ptr %2, align 4, !tbaa !4
  %7 = call i1 @_FortranAioOutputInteger32(ptr %4, i32 %6)
  %8 = call i1 @_FortranAioOutputAscii(ptr %4, ptr nonnull @_QQcl.2920697320, i64 5)
  %.unpack = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  %.unpack96.unpack.unpack = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  %9 = sub i64 1, %.unpack96.unpack.unpack
  %10 = getelementptr double, ptr %.unpack, i64 %9
  %11 = load double, ptr %10, align 8, !tbaa !4
  %12 = load i32, ptr %2, align 4, !tbaa !4
  %13 = sext i32 %12 to i64
  %14 = sub i64 %13, %.unpack96.unpack.unpack
  %15 = getelementptr double, ptr %.unpack, i64 %14
  %16 = load double, ptr %15, align 8, !tbaa !4
  %17 = fadd contract double %11, %16
  %18 = call i1 @_FortranAioOutputReal64(ptr %4, double %17)
  %19 = call i32 @_FortranAioEndIoStatement(ptr %4)
  %.unpack101 = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  call void @free(ptr %.unpack101)
  store ptr null, ptr @_QFEarr, align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  store i32 20180515, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  store i8 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  store i8 28, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  store i8 2, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  store i8 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  store i64 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  store i64 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  ret void
}
*** IR Dump After SpeculativeExecutionPass on _QQmain ***
define void @_QQmain() local_unnamed_addr {
entry:
  %structArg = alloca { ptr, ptr, ptr }, align 8
  %0 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %1 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %2 = alloca i32, align 4
  store i32 1048576, ptr %2, align 4, !tbaa !4
  %3 = call dereferenceable_or_null(8388608) ptr @malloc(i64 8388608)
  store ptr %3, ptr @_QFEarr, align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  store i32 20180515, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  store i8 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  store i8 28, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  store i8 2, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  store i8 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  store i64 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  store i64 1048576, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  %omp_global_thread_num = call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %2, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %1, ptr %gep_5, align 8
  %gep_6 = getelementptr inbounds { ptr, ptr, ptr }, ptr %structArg, i64 0, i32 2
  store ptr %0, ptr %gep_6, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QQmain..omp_par, ptr nonnull %structArg)
  %4 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.60ea5a38555821a77357f87d16df9a0f, i32 21)
  %5 = call i1 @_FortranAioOutputAscii(ptr %4, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %6 = load i32, ptr %2, align 4, !tbaa !4
  %7 = call i1 @_FortranAioOutputInteger32(ptr %4, i32 %6)
  %8 = call i1 @_FortranAioOutputAscii(ptr %4, ptr nonnull @_QQcl.2920697320, i64 5)
  %.unpack = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  %.unpack96.unpack.unpack = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  %9 = sub i64 1, %.unpack96.unpack.unpack
  %10 = getelementptr double, ptr %.unpack, i64 %9
  %11 = load double, ptr %10, align 8, !tbaa !4
  %12 = load i32, ptr %2, align 4, !tbaa !4
  %13 = sext i32 %12 to i64
  %14 = sub i64 %13, %.unpack96.unpack.unpack
  %15 = getelementptr double, ptr %.unpack, i64 %14
  %16 = load double, ptr %15, align 8, !tbaa !4
  %17 = fadd contract double %11, %16
  %18 = call i1 @_FortranAioOutputReal64(ptr %4, double %17)
  %19 = call i32 @_FortranAioEndIoStatement(ptr %4)
  %.unpack101 = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  call void @free(ptr %.unpack101)
  store ptr null, ptr @_QFEarr, align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  store i32 20180515, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  store i8 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  store i8 28, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  store i8 2, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  store i8 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  store i64 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  store i64 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  ret void
}
*** IR Dump After JumpThreadingPass on _QQmain ***
define void @_QQmain() local_unnamed_addr {
entry:
  %structArg = alloca { ptr, ptr, ptr }, align 8
  %0 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %1 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %2 = alloca i32, align 4
  store i32 1048576, ptr %2, align 4, !tbaa !4
  %3 = call dereferenceable_or_null(8388608) ptr @malloc(i64 8388608)
  store ptr %3, ptr @_QFEarr, align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  store i32 20180515, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  store i8 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  store i8 28, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  store i8 2, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  store i8 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  store i64 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  store i64 1048576, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  %omp_global_thread_num = call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %2, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %1, ptr %gep_5, align 8
  %gep_6 = getelementptr inbounds { ptr, ptr, ptr }, ptr %structArg, i64 0, i32 2
  store ptr %0, ptr %gep_6, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QQmain..omp_par, ptr nonnull %structArg)
  %4 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.60ea5a38555821a77357f87d16df9a0f, i32 21)
  %5 = call i1 @_FortranAioOutputAscii(ptr %4, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %6 = load i32, ptr %2, align 4, !tbaa !4
  %7 = call i1 @_FortranAioOutputInteger32(ptr %4, i32 %6)
  %8 = call i1 @_FortranAioOutputAscii(ptr %4, ptr nonnull @_QQcl.2920697320, i64 5)
  %.unpack = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  %.unpack96.unpack.unpack = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  %9 = sub i64 1, %.unpack96.unpack.unpack
  %10 = getelementptr double, ptr %.unpack, i64 %9
  %11 = load double, ptr %10, align 8, !tbaa !4
  %12 = load i32, ptr %2, align 4, !tbaa !4
  %13 = sext i32 %12 to i64
  %14 = sub i64 %13, %.unpack96.unpack.unpack
  %15 = getelementptr double, ptr %.unpack, i64 %14
  %16 = load double, ptr %15, align 8, !tbaa !4
  %17 = fadd contract double %11, %16
  %18 = call i1 @_FortranAioOutputReal64(ptr %4, double %17)
  %19 = call i32 @_FortranAioEndIoStatement(ptr %4)
  %.unpack101 = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  call void @free(ptr %.unpack101)
  store ptr null, ptr @_QFEarr, align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  store i32 20180515, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  store i8 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  store i8 28, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  store i8 2, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  store i8 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  store i64 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  store i64 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  ret void
}
*** IR Dump After CorrelatedValuePropagationPass on _QQmain ***
define void @_QQmain() local_unnamed_addr {
entry:
  %structArg = alloca { ptr, ptr, ptr }, align 8
  %0 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %1 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %2 = alloca i32, align 4
  store i32 1048576, ptr %2, align 4, !tbaa !4
  %3 = call dereferenceable_or_null(8388608) ptr @malloc(i64 8388608)
  store ptr %3, ptr @_QFEarr, align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  store i32 20180515, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  store i8 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  store i8 28, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  store i8 2, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  store i8 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  store i64 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  store i64 1048576, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  %omp_global_thread_num = call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %2, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %1, ptr %gep_5, align 8
  %gep_6 = getelementptr inbounds { ptr, ptr, ptr }, ptr %structArg, i64 0, i32 2
  store ptr %0, ptr %gep_6, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QQmain..omp_par, ptr nonnull %structArg)
  %4 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.60ea5a38555821a77357f87d16df9a0f, i32 21)
  %5 = call i1 @_FortranAioOutputAscii(ptr %4, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %6 = load i32, ptr %2, align 4, !tbaa !4
  %7 = call i1 @_FortranAioOutputInteger32(ptr %4, i32 %6)
  %8 = call i1 @_FortranAioOutputAscii(ptr %4, ptr nonnull @_QQcl.2920697320, i64 5)
  %.unpack = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  %.unpack96.unpack.unpack = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  %9 = sub i64 1, %.unpack96.unpack.unpack
  %10 = getelementptr double, ptr %.unpack, i64 %9
  %11 = load double, ptr %10, align 8, !tbaa !4
  %12 = load i32, ptr %2, align 4, !tbaa !4
  %13 = sext i32 %12 to i64
  %14 = sub i64 %13, %.unpack96.unpack.unpack
  %15 = getelementptr double, ptr %.unpack, i64 %14
  %16 = load double, ptr %15, align 8, !tbaa !4
  %17 = fadd contract double %11, %16
  %18 = call i1 @_FortranAioOutputReal64(ptr %4, double %17)
  %19 = call i32 @_FortranAioEndIoStatement(ptr %4)
  %.unpack101 = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  call void @free(ptr %.unpack101)
  store ptr null, ptr @_QFEarr, align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  store i32 20180515, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  store i8 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  store i8 28, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  store i8 2, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  store i8 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  store i64 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  store i64 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  ret void
}
*** IR Dump After SimplifyCFGPass on _QQmain ***
define void @_QQmain() local_unnamed_addr {
entry:
  %structArg = alloca { ptr, ptr, ptr }, align 8
  %0 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %1 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %2 = alloca i32, align 4
  store i32 1048576, ptr %2, align 4, !tbaa !4
  %3 = call dereferenceable_or_null(8388608) ptr @malloc(i64 8388608)
  store ptr %3, ptr @_QFEarr, align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  store i32 20180515, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  store i8 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  store i8 28, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  store i8 2, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  store i8 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  store i64 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  store i64 1048576, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  %omp_global_thread_num = call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %2, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %1, ptr %gep_5, align 8
  %gep_6 = getelementptr inbounds { ptr, ptr, ptr }, ptr %structArg, i64 0, i32 2
  store ptr %0, ptr %gep_6, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QQmain..omp_par, ptr nonnull %structArg)
  %4 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.60ea5a38555821a77357f87d16df9a0f, i32 21)
  %5 = call i1 @_FortranAioOutputAscii(ptr %4, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %6 = load i32, ptr %2, align 4, !tbaa !4
  %7 = call i1 @_FortranAioOutputInteger32(ptr %4, i32 %6)
  %8 = call i1 @_FortranAioOutputAscii(ptr %4, ptr nonnull @_QQcl.2920697320, i64 5)
  %.unpack = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  %.unpack96.unpack.unpack = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  %9 = sub i64 1, %.unpack96.unpack.unpack
  %10 = getelementptr double, ptr %.unpack, i64 %9
  %11 = load double, ptr %10, align 8, !tbaa !4
  %12 = load i32, ptr %2, align 4, !tbaa !4
  %13 = sext i32 %12 to i64
  %14 = sub i64 %13, %.unpack96.unpack.unpack
  %15 = getelementptr double, ptr %.unpack, i64 %14
  %16 = load double, ptr %15, align 8, !tbaa !4
  %17 = fadd contract double %11, %16
  %18 = call i1 @_FortranAioOutputReal64(ptr %4, double %17)
  %19 = call i32 @_FortranAioEndIoStatement(ptr %4)
  %.unpack101 = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  call void @free(ptr %.unpack101)
  store ptr null, ptr @_QFEarr, align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  store i32 20180515, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  store i8 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  store i8 28, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  store i8 2, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  store i8 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  store i64 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  store i64 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  ret void
}
*** IR Dump After InstCombinePass on _QQmain ***
define void @_QQmain() local_unnamed_addr {
entry:
  %structArg = alloca { ptr, ptr, ptr }, align 8
  %0 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %1 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %2 = alloca i32, align 4
  store i32 1048576, ptr %2, align 4, !tbaa !4
  %3 = call dereferenceable_or_null(8388608) ptr @malloc(i64 8388608)
  store ptr %3, ptr @_QFEarr, align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  store i32 20180515, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  store i8 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  store i8 28, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  store i8 2, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  store i8 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  store i64 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  store i64 1048576, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  %omp_global_thread_num = call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %2, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %1, ptr %gep_5, align 8
  %gep_6 = getelementptr inbounds { ptr, ptr, ptr }, ptr %structArg, i64 0, i32 2
  store ptr %0, ptr %gep_6, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QQmain..omp_par, ptr nonnull %structArg)
  %4 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.60ea5a38555821a77357f87d16df9a0f, i32 21)
  %5 = call i1 @_FortranAioOutputAscii(ptr %4, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %6 = load i32, ptr %2, align 4, !tbaa !4
  %7 = call i1 @_FortranAioOutputInteger32(ptr %4, i32 %6)
  %8 = call i1 @_FortranAioOutputAscii(ptr %4, ptr nonnull @_QQcl.2920697320, i64 5)
  %.unpack = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  %.unpack96.unpack.unpack = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  %9 = sub i64 1, %.unpack96.unpack.unpack
  %10 = getelementptr double, ptr %.unpack, i64 %9
  %11 = load double, ptr %10, align 8, !tbaa !4
  %12 = load i32, ptr %2, align 4, !tbaa !4
  %13 = sext i32 %12 to i64
  %14 = sub i64 %13, %.unpack96.unpack.unpack
  %15 = getelementptr double, ptr %.unpack, i64 %14
  %16 = load double, ptr %15, align 8, !tbaa !4
  %17 = fadd contract double %11, %16
  %18 = call i1 @_FortranAioOutputReal64(ptr %4, double %17)
  %19 = call i32 @_FortranAioEndIoStatement(ptr %4)
  %.unpack101 = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  call void @free(ptr %.unpack101)
  store ptr null, ptr @_QFEarr, align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  store i32 20180515, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  store i8 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  store i8 28, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  store i8 2, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  store i8 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  store i64 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  store i64 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  ret void
}
*** IR Dump After AggressiveInstCombinePass on _QQmain ***
define void @_QQmain() local_unnamed_addr {
entry:
  %structArg = alloca { ptr, ptr, ptr }, align 8
  %0 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %1 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %2 = alloca i32, align 4
  store i32 1048576, ptr %2, align 4, !tbaa !4
  %3 = call dereferenceable_or_null(8388608) ptr @malloc(i64 8388608)
  store ptr %3, ptr @_QFEarr, align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  store i32 20180515, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  store i8 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  store i8 28, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  store i8 2, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  store i8 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  store i64 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  store i64 1048576, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  %omp_global_thread_num = call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %2, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %1, ptr %gep_5, align 8
  %gep_6 = getelementptr inbounds { ptr, ptr, ptr }, ptr %structArg, i64 0, i32 2
  store ptr %0, ptr %gep_6, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QQmain..omp_par, ptr nonnull %structArg)
  %4 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.60ea5a38555821a77357f87d16df9a0f, i32 21)
  %5 = call i1 @_FortranAioOutputAscii(ptr %4, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %6 = load i32, ptr %2, align 4, !tbaa !4
  %7 = call i1 @_FortranAioOutputInteger32(ptr %4, i32 %6)
  %8 = call i1 @_FortranAioOutputAscii(ptr %4, ptr nonnull @_QQcl.2920697320, i64 5)
  %.unpack = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  %.unpack96.unpack.unpack = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  %9 = sub i64 1, %.unpack96.unpack.unpack
  %10 = getelementptr double, ptr %.unpack, i64 %9
  %11 = load double, ptr %10, align 8, !tbaa !4
  %12 = load i32, ptr %2, align 4, !tbaa !4
  %13 = sext i32 %12 to i64
  %14 = sub i64 %13, %.unpack96.unpack.unpack
  %15 = getelementptr double, ptr %.unpack, i64 %14
  %16 = load double, ptr %15, align 8, !tbaa !4
  %17 = fadd contract double %11, %16
  %18 = call i1 @_FortranAioOutputReal64(ptr %4, double %17)
  %19 = call i32 @_FortranAioEndIoStatement(ptr %4)
  %.unpack101 = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  call void @free(ptr %.unpack101)
  store ptr null, ptr @_QFEarr, align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  store i32 20180515, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  store i8 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  store i8 28, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  store i8 2, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  store i8 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  store i64 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  store i64 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  ret void
}
*** IR Dump After ConstraintEliminationPass on _QQmain ***
define void @_QQmain() local_unnamed_addr {
entry:
  %structArg = alloca { ptr, ptr, ptr }, align 8
  %0 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %1 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %2 = alloca i32, align 4
  store i32 1048576, ptr %2, align 4, !tbaa !4
  %3 = call dereferenceable_or_null(8388608) ptr @malloc(i64 8388608)
  store ptr %3, ptr @_QFEarr, align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  store i32 20180515, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  store i8 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  store i8 28, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  store i8 2, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  store i8 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  store i64 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  store i64 1048576, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  %omp_global_thread_num = call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %2, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %1, ptr %gep_5, align 8
  %gep_6 = getelementptr inbounds { ptr, ptr, ptr }, ptr %structArg, i64 0, i32 2
  store ptr %0, ptr %gep_6, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QQmain..omp_par, ptr nonnull %structArg)
  %4 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.60ea5a38555821a77357f87d16df9a0f, i32 21)
  %5 = call i1 @_FortranAioOutputAscii(ptr %4, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %6 = load i32, ptr %2, align 4, !tbaa !4
  %7 = call i1 @_FortranAioOutputInteger32(ptr %4, i32 %6)
  %8 = call i1 @_FortranAioOutputAscii(ptr %4, ptr nonnull @_QQcl.2920697320, i64 5)
  %.unpack = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  %.unpack96.unpack.unpack = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  %9 = sub i64 1, %.unpack96.unpack.unpack
  %10 = getelementptr double, ptr %.unpack, i64 %9
  %11 = load double, ptr %10, align 8, !tbaa !4
  %12 = load i32, ptr %2, align 4, !tbaa !4
  %13 = sext i32 %12 to i64
  %14 = sub i64 %13, %.unpack96.unpack.unpack
  %15 = getelementptr double, ptr %.unpack, i64 %14
  %16 = load double, ptr %15, align 8, !tbaa !4
  %17 = fadd contract double %11, %16
  %18 = call i1 @_FortranAioOutputReal64(ptr %4, double %17)
  %19 = call i32 @_FortranAioEndIoStatement(ptr %4)
  %.unpack101 = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  call void @free(ptr %.unpack101)
  store ptr null, ptr @_QFEarr, align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  store i32 20180515, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  store i8 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  store i8 28, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  store i8 2, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  store i8 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  store i64 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  store i64 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  ret void
}
*** IR Dump After LibCallsShrinkWrapPass on _QQmain ***
define void @_QQmain() local_unnamed_addr {
entry:
  %structArg = alloca { ptr, ptr, ptr }, align 8
  %0 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %1 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %2 = alloca i32, align 4
  store i32 1048576, ptr %2, align 4, !tbaa !4
  %3 = call dereferenceable_or_null(8388608) ptr @malloc(i64 8388608)
  store ptr %3, ptr @_QFEarr, align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  store i32 20180515, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  store i8 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  store i8 28, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  store i8 2, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  store i8 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  store i64 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  store i64 1048576, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  %omp_global_thread_num = call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %2, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %1, ptr %gep_5, align 8
  %gep_6 = getelementptr inbounds { ptr, ptr, ptr }, ptr %structArg, i64 0, i32 2
  store ptr %0, ptr %gep_6, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QQmain..omp_par, ptr nonnull %structArg)
  %4 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.60ea5a38555821a77357f87d16df9a0f, i32 21)
  %5 = call i1 @_FortranAioOutputAscii(ptr %4, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %6 = load i32, ptr %2, align 4, !tbaa !4
  %7 = call i1 @_FortranAioOutputInteger32(ptr %4, i32 %6)
  %8 = call i1 @_FortranAioOutputAscii(ptr %4, ptr nonnull @_QQcl.2920697320, i64 5)
  %.unpack = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  %.unpack96.unpack.unpack = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  %9 = sub i64 1, %.unpack96.unpack.unpack
  %10 = getelementptr double, ptr %.unpack, i64 %9
  %11 = load double, ptr %10, align 8, !tbaa !4
  %12 = load i32, ptr %2, align 4, !tbaa !4
  %13 = sext i32 %12 to i64
  %14 = sub i64 %13, %.unpack96.unpack.unpack
  %15 = getelementptr double, ptr %.unpack, i64 %14
  %16 = load double, ptr %15, align 8, !tbaa !4
  %17 = fadd contract double %11, %16
  %18 = call i1 @_FortranAioOutputReal64(ptr %4, double %17)
  %19 = call i32 @_FortranAioEndIoStatement(ptr %4)
  %.unpack101 = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  call void @free(ptr %.unpack101)
  store ptr null, ptr @_QFEarr, align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  store i32 20180515, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  store i8 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  store i8 28, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  store i8 2, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  store i8 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  store i64 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  store i64 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  ret void
}
*** IR Dump After TailCallElimPass on _QQmain ***
define void @_QQmain() local_unnamed_addr {
entry:
  %structArg = alloca { ptr, ptr, ptr }, align 8
  %0 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %1 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %2 = alloca i32, align 4
  store i32 1048576, ptr %2, align 4, !tbaa !4
  %3 = tail call dereferenceable_or_null(8388608) ptr @malloc(i64 8388608)
  store ptr %3, ptr @_QFEarr, align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  store i32 20180515, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  store i8 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  store i8 28, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  store i8 2, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  store i8 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  store i64 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  store i64 1048576, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  %omp_global_thread_num = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %2, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %1, ptr %gep_5, align 8
  %gep_6 = getelementptr inbounds { ptr, ptr, ptr }, ptr %structArg, i64 0, i32 2
  store ptr %0, ptr %gep_6, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QQmain..omp_par, ptr nonnull %structArg)
  %4 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.60ea5a38555821a77357f87d16df9a0f, i32 21)
  %5 = call i1 @_FortranAioOutputAscii(ptr %4, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %6 = load i32, ptr %2, align 4, !tbaa !4
  %7 = call i1 @_FortranAioOutputInteger32(ptr %4, i32 %6)
  %8 = call i1 @_FortranAioOutputAscii(ptr %4, ptr nonnull @_QQcl.2920697320, i64 5)
  %.unpack = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  %.unpack96.unpack.unpack = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  %9 = sub i64 1, %.unpack96.unpack.unpack
  %10 = getelementptr double, ptr %.unpack, i64 %9
  %11 = load double, ptr %10, align 8, !tbaa !4
  %12 = load i32, ptr %2, align 4, !tbaa !4
  %13 = sext i32 %12 to i64
  %14 = sub i64 %13, %.unpack96.unpack.unpack
  %15 = getelementptr double, ptr %.unpack, i64 %14
  %16 = load double, ptr %15, align 8, !tbaa !4
  %17 = fadd contract double %11, %16
  %18 = call i1 @_FortranAioOutputReal64(ptr %4, double %17)
  %19 = call i32 @_FortranAioEndIoStatement(ptr %4)
  %.unpack101 = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  call void @free(ptr %.unpack101)
  store ptr null, ptr @_QFEarr, align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  store i32 20180515, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  store i8 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  store i8 28, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  store i8 2, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  store i8 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  store i64 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  store i64 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  ret void
}
*** IR Dump After SimplifyCFGPass on _QQmain ***
define void @_QQmain() local_unnamed_addr {
entry:
  %structArg = alloca { ptr, ptr, ptr }, align 8
  %0 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %1 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %2 = alloca i32, align 4
  store i32 1048576, ptr %2, align 4, !tbaa !4
  %3 = tail call dereferenceable_or_null(8388608) ptr @malloc(i64 8388608)
  store ptr %3, ptr @_QFEarr, align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  store i32 20180515, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  store i8 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  store i8 28, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  store i8 2, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  store i8 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  store i64 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  store i64 1048576, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  %omp_global_thread_num = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %2, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %1, ptr %gep_5, align 8
  %gep_6 = getelementptr inbounds { ptr, ptr, ptr }, ptr %structArg, i64 0, i32 2
  store ptr %0, ptr %gep_6, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QQmain..omp_par, ptr nonnull %structArg)
  %4 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.60ea5a38555821a77357f87d16df9a0f, i32 21)
  %5 = call i1 @_FortranAioOutputAscii(ptr %4, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %6 = load i32, ptr %2, align 4, !tbaa !4
  %7 = call i1 @_FortranAioOutputInteger32(ptr %4, i32 %6)
  %8 = call i1 @_FortranAioOutputAscii(ptr %4, ptr nonnull @_QQcl.2920697320, i64 5)
  %.unpack = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  %.unpack96.unpack.unpack = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  %9 = sub i64 1, %.unpack96.unpack.unpack
  %10 = getelementptr double, ptr %.unpack, i64 %9
  %11 = load double, ptr %10, align 8, !tbaa !4
  %12 = load i32, ptr %2, align 4, !tbaa !4
  %13 = sext i32 %12 to i64
  %14 = sub i64 %13, %.unpack96.unpack.unpack
  %15 = getelementptr double, ptr %.unpack, i64 %14
  %16 = load double, ptr %15, align 8, !tbaa !4
  %17 = fadd contract double %11, %16
  %18 = call i1 @_FortranAioOutputReal64(ptr %4, double %17)
  %19 = call i32 @_FortranAioEndIoStatement(ptr %4)
  %.unpack101 = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  call void @free(ptr %.unpack101)
  store ptr null, ptr @_QFEarr, align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  store i32 20180515, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  store i8 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  store i8 28, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  store i8 2, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  store i8 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  store i64 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  store i64 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  ret void
}
*** IR Dump After ReassociatePass on _QQmain ***
define void @_QQmain() local_unnamed_addr {
entry:
  %structArg = alloca { ptr, ptr, ptr }, align 8
  %0 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %1 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %2 = alloca i32, align 4
  store i32 1048576, ptr %2, align 4, !tbaa !4
  %3 = tail call dereferenceable_or_null(8388608) ptr @malloc(i64 8388608)
  store ptr %3, ptr @_QFEarr, align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  store i32 20180515, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  store i8 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  store i8 28, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  store i8 2, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  store i8 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  store i64 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  store i64 1048576, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  %omp_global_thread_num = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %2, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %1, ptr %gep_5, align 8
  %gep_6 = getelementptr inbounds { ptr, ptr, ptr }, ptr %structArg, i64 0, i32 2
  store ptr %0, ptr %gep_6, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QQmain..omp_par, ptr nonnull %structArg)
  %4 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.60ea5a38555821a77357f87d16df9a0f, i32 21)
  %5 = call i1 @_FortranAioOutputAscii(ptr %4, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %6 = load i32, ptr %2, align 4, !tbaa !4
  %7 = call i1 @_FortranAioOutputInteger32(ptr %4, i32 %6)
  %8 = call i1 @_FortranAioOutputAscii(ptr %4, ptr nonnull @_QQcl.2920697320, i64 5)
  %.unpack = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  %.unpack96.unpack.unpack = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  %9 = sub i64 1, %.unpack96.unpack.unpack
  %10 = getelementptr double, ptr %.unpack, i64 %9
  %11 = load double, ptr %10, align 8, !tbaa !4
  %12 = load i32, ptr %2, align 4, !tbaa !4
  %13 = sext i32 %12 to i64
  %14 = sub i64 %13, %.unpack96.unpack.unpack
  %15 = getelementptr double, ptr %.unpack, i64 %14
  %16 = load double, ptr %15, align 8, !tbaa !4
  %17 = fadd contract double %11, %16
  %18 = call i1 @_FortranAioOutputReal64(ptr %4, double %17)
  %19 = call i32 @_FortranAioEndIoStatement(ptr %4)
  %.unpack101 = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  call void @free(ptr %.unpack101)
  store ptr null, ptr @_QFEarr, align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  store i32 20180515, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  store i8 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  store i8 28, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  store i8 2, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  store i8 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  store i64 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  store i64 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  ret void
}
*** IR Dump After LoopSimplifyPass on _QQmain ***
define void @_QQmain() local_unnamed_addr {
entry:
  %structArg = alloca { ptr, ptr, ptr }, align 8
  %0 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %1 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %2 = alloca i32, align 4
  store i32 1048576, ptr %2, align 4, !tbaa !4
  %3 = tail call dereferenceable_or_null(8388608) ptr @malloc(i64 8388608)
  store ptr %3, ptr @_QFEarr, align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  store i32 20180515, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  store i8 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  store i8 28, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  store i8 2, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  store i8 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  store i64 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  store i64 1048576, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  %omp_global_thread_num = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %2, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %1, ptr %gep_5, align 8
  %gep_6 = getelementptr inbounds { ptr, ptr, ptr }, ptr %structArg, i64 0, i32 2
  store ptr %0, ptr %gep_6, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QQmain..omp_par, ptr nonnull %structArg)
  %4 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.60ea5a38555821a77357f87d16df9a0f, i32 21)
  %5 = call i1 @_FortranAioOutputAscii(ptr %4, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %6 = load i32, ptr %2, align 4, !tbaa !4
  %7 = call i1 @_FortranAioOutputInteger32(ptr %4, i32 %6)
  %8 = call i1 @_FortranAioOutputAscii(ptr %4, ptr nonnull @_QQcl.2920697320, i64 5)
  %.unpack = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  %.unpack96.unpack.unpack = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  %9 = sub i64 1, %.unpack96.unpack.unpack
  %10 = getelementptr double, ptr %.unpack, i64 %9
  %11 = load double, ptr %10, align 8, !tbaa !4
  %12 = load i32, ptr %2, align 4, !tbaa !4
  %13 = sext i32 %12 to i64
  %14 = sub i64 %13, %.unpack96.unpack.unpack
  %15 = getelementptr double, ptr %.unpack, i64 %14
  %16 = load double, ptr %15, align 8, !tbaa !4
  %17 = fadd contract double %11, %16
  %18 = call i1 @_FortranAioOutputReal64(ptr %4, double %17)
  %19 = call i32 @_FortranAioEndIoStatement(ptr %4)
  %.unpack101 = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  call void @free(ptr %.unpack101)
  store ptr null, ptr @_QFEarr, align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  store i32 20180515, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  store i8 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  store i8 28, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  store i8 2, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  store i8 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  store i64 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  store i64 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  ret void
}
*** IR Dump After LCSSAPass on _QQmain ***
define void @_QQmain() local_unnamed_addr {
entry:
  %structArg = alloca { ptr, ptr, ptr }, align 8
  %0 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %1 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %2 = alloca i32, align 4
  store i32 1048576, ptr %2, align 4, !tbaa !4
  %3 = tail call dereferenceable_or_null(8388608) ptr @malloc(i64 8388608)
  store ptr %3, ptr @_QFEarr, align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  store i32 20180515, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  store i8 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  store i8 28, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  store i8 2, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  store i8 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  store i64 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  store i64 1048576, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  %omp_global_thread_num = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %2, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %1, ptr %gep_5, align 8
  %gep_6 = getelementptr inbounds { ptr, ptr, ptr }, ptr %structArg, i64 0, i32 2
  store ptr %0, ptr %gep_6, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QQmain..omp_par, ptr nonnull %structArg)
  %4 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.60ea5a38555821a77357f87d16df9a0f, i32 21)
  %5 = call i1 @_FortranAioOutputAscii(ptr %4, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %6 = load i32, ptr %2, align 4, !tbaa !4
  %7 = call i1 @_FortranAioOutputInteger32(ptr %4, i32 %6)
  %8 = call i1 @_FortranAioOutputAscii(ptr %4, ptr nonnull @_QQcl.2920697320, i64 5)
  %.unpack = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  %.unpack96.unpack.unpack = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  %9 = sub i64 1, %.unpack96.unpack.unpack
  %10 = getelementptr double, ptr %.unpack, i64 %9
  %11 = load double, ptr %10, align 8, !tbaa !4
  %12 = load i32, ptr %2, align 4, !tbaa !4
  %13 = sext i32 %12 to i64
  %14 = sub i64 %13, %.unpack96.unpack.unpack
  %15 = getelementptr double, ptr %.unpack, i64 %14
  %16 = load double, ptr %15, align 8, !tbaa !4
  %17 = fadd contract double %11, %16
  %18 = call i1 @_FortranAioOutputReal64(ptr %4, double %17)
  %19 = call i32 @_FortranAioEndIoStatement(ptr %4)
  %.unpack101 = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  call void @free(ptr %.unpack101)
  store ptr null, ptr @_QFEarr, align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  store i32 20180515, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  store i8 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  store i8 28, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  store i8 2, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  store i8 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  store i64 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  store i64 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  ret void
}
*** IR Dump After SimplifyCFGPass on _QQmain ***
define void @_QQmain() local_unnamed_addr {
entry:
  %structArg = alloca { ptr, ptr, ptr }, align 8
  %0 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %1 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %2 = alloca i32, align 4
  store i32 1048576, ptr %2, align 4, !tbaa !4
  %3 = tail call dereferenceable_or_null(8388608) ptr @malloc(i64 8388608)
  store ptr %3, ptr @_QFEarr, align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  store i32 20180515, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  store i8 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  store i8 28, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  store i8 2, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  store i8 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  store i64 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  store i64 1048576, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  %omp_global_thread_num = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %2, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %1, ptr %gep_5, align 8
  %gep_6 = getelementptr inbounds { ptr, ptr, ptr }, ptr %structArg, i64 0, i32 2
  store ptr %0, ptr %gep_6, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QQmain..omp_par, ptr nonnull %structArg)
  %4 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.60ea5a38555821a77357f87d16df9a0f, i32 21)
  %5 = call i1 @_FortranAioOutputAscii(ptr %4, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %6 = load i32, ptr %2, align 4, !tbaa !4
  %7 = call i1 @_FortranAioOutputInteger32(ptr %4, i32 %6)
  %8 = call i1 @_FortranAioOutputAscii(ptr %4, ptr nonnull @_QQcl.2920697320, i64 5)
  %.unpack = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  %.unpack96.unpack.unpack = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  %9 = sub i64 1, %.unpack96.unpack.unpack
  %10 = getelementptr double, ptr %.unpack, i64 %9
  %11 = load double, ptr %10, align 8, !tbaa !4
  %12 = load i32, ptr %2, align 4, !tbaa !4
  %13 = sext i32 %12 to i64
  %14 = sub i64 %13, %.unpack96.unpack.unpack
  %15 = getelementptr double, ptr %.unpack, i64 %14
  %16 = load double, ptr %15, align 8, !tbaa !4
  %17 = fadd contract double %11, %16
  %18 = call i1 @_FortranAioOutputReal64(ptr %4, double %17)
  %19 = call i32 @_FortranAioEndIoStatement(ptr %4)
  %.unpack101 = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  call void @free(ptr %.unpack101)
  store ptr null, ptr @_QFEarr, align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  store i32 20180515, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  store i8 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  store i8 28, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  store i8 2, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  store i8 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  store i64 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  store i64 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  ret void
}
*** IR Dump After InstCombinePass on _QQmain ***
define void @_QQmain() local_unnamed_addr {
entry:
  %structArg = alloca { ptr, ptr, ptr }, align 8
  %0 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %1 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %2 = alloca i32, align 4
  store i32 1048576, ptr %2, align 4, !tbaa !4
  %3 = tail call dereferenceable_or_null(8388608) ptr @malloc(i64 8388608)
  store ptr %3, ptr @_QFEarr, align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  store i32 20180515, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  store i8 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  store i8 28, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  store i8 2, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  store i8 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  store i64 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  store i64 1048576, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  %omp_global_thread_num = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %2, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %1, ptr %gep_5, align 8
  %gep_6 = getelementptr inbounds { ptr, ptr, ptr }, ptr %structArg, i64 0, i32 2
  store ptr %0, ptr %gep_6, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QQmain..omp_par, ptr nonnull %structArg)
  %4 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.60ea5a38555821a77357f87d16df9a0f, i32 21)
  %5 = call i1 @_FortranAioOutputAscii(ptr %4, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %6 = load i32, ptr %2, align 4, !tbaa !4
  %7 = call i1 @_FortranAioOutputInteger32(ptr %4, i32 %6)
  %8 = call i1 @_FortranAioOutputAscii(ptr %4, ptr nonnull @_QQcl.2920697320, i64 5)
  %.unpack = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  %.unpack96.unpack.unpack = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  %9 = sub i64 1, %.unpack96.unpack.unpack
  %10 = getelementptr double, ptr %.unpack, i64 %9
  %11 = load double, ptr %10, align 8, !tbaa !4
  %12 = load i32, ptr %2, align 4, !tbaa !4
  %13 = sext i32 %12 to i64
  %14 = sub i64 %13, %.unpack96.unpack.unpack
  %15 = getelementptr double, ptr %.unpack, i64 %14
  %16 = load double, ptr %15, align 8, !tbaa !4
  %17 = fadd contract double %11, %16
  %18 = call i1 @_FortranAioOutputReal64(ptr %4, double %17)
  %19 = call i32 @_FortranAioEndIoStatement(ptr %4)
  %.unpack101 = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  call void @free(ptr %.unpack101)
  store ptr null, ptr @_QFEarr, align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  store i32 20180515, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  store i8 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  store i8 28, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  store i8 2, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  store i8 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  store i64 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  store i64 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  ret void
}
*** IR Dump After LoopSimplifyPass on _QQmain ***
define void @_QQmain() local_unnamed_addr {
entry:
  %structArg = alloca { ptr, ptr, ptr }, align 8
  %0 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %1 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %2 = alloca i32, align 4
  store i32 1048576, ptr %2, align 4, !tbaa !4
  %3 = tail call dereferenceable_or_null(8388608) ptr @malloc(i64 8388608)
  store ptr %3, ptr @_QFEarr, align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  store i32 20180515, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  store i8 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  store i8 28, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  store i8 2, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  store i8 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  store i64 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  store i64 1048576, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  %omp_global_thread_num = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %2, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %1, ptr %gep_5, align 8
  %gep_6 = getelementptr inbounds { ptr, ptr, ptr }, ptr %structArg, i64 0, i32 2
  store ptr %0, ptr %gep_6, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QQmain..omp_par, ptr nonnull %structArg)
  %4 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.60ea5a38555821a77357f87d16df9a0f, i32 21)
  %5 = call i1 @_FortranAioOutputAscii(ptr %4, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %6 = load i32, ptr %2, align 4, !tbaa !4
  %7 = call i1 @_FortranAioOutputInteger32(ptr %4, i32 %6)
  %8 = call i1 @_FortranAioOutputAscii(ptr %4, ptr nonnull @_QQcl.2920697320, i64 5)
  %.unpack = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  %.unpack96.unpack.unpack = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  %9 = sub i64 1, %.unpack96.unpack.unpack
  %10 = getelementptr double, ptr %.unpack, i64 %9
  %11 = load double, ptr %10, align 8, !tbaa !4
  %12 = load i32, ptr %2, align 4, !tbaa !4
  %13 = sext i32 %12 to i64
  %14 = sub i64 %13, %.unpack96.unpack.unpack
  %15 = getelementptr double, ptr %.unpack, i64 %14
  %16 = load double, ptr %15, align 8, !tbaa !4
  %17 = fadd contract double %11, %16
  %18 = call i1 @_FortranAioOutputReal64(ptr %4, double %17)
  %19 = call i32 @_FortranAioEndIoStatement(ptr %4)
  %.unpack101 = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  call void @free(ptr %.unpack101)
  store ptr null, ptr @_QFEarr, align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  store i32 20180515, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  store i8 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  store i8 28, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  store i8 2, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  store i8 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  store i64 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  store i64 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  ret void
}
*** IR Dump After LCSSAPass on _QQmain ***
define void @_QQmain() local_unnamed_addr {
entry:
  %structArg = alloca { ptr, ptr, ptr }, align 8
  %0 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %1 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %2 = alloca i32, align 4
  store i32 1048576, ptr %2, align 4, !tbaa !4
  %3 = tail call dereferenceable_or_null(8388608) ptr @malloc(i64 8388608)
  store ptr %3, ptr @_QFEarr, align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  store i32 20180515, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  store i8 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  store i8 28, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  store i8 2, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  store i8 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  store i64 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  store i64 1048576, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  %omp_global_thread_num = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %2, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %1, ptr %gep_5, align 8
  %gep_6 = getelementptr inbounds { ptr, ptr, ptr }, ptr %structArg, i64 0, i32 2
  store ptr %0, ptr %gep_6, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QQmain..omp_par, ptr nonnull %structArg)
  %4 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.60ea5a38555821a77357f87d16df9a0f, i32 21)
  %5 = call i1 @_FortranAioOutputAscii(ptr %4, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %6 = load i32, ptr %2, align 4, !tbaa !4
  %7 = call i1 @_FortranAioOutputInteger32(ptr %4, i32 %6)
  %8 = call i1 @_FortranAioOutputAscii(ptr %4, ptr nonnull @_QQcl.2920697320, i64 5)
  %.unpack = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  %.unpack96.unpack.unpack = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  %9 = sub i64 1, %.unpack96.unpack.unpack
  %10 = getelementptr double, ptr %.unpack, i64 %9
  %11 = load double, ptr %10, align 8, !tbaa !4
  %12 = load i32, ptr %2, align 4, !tbaa !4
  %13 = sext i32 %12 to i64
  %14 = sub i64 %13, %.unpack96.unpack.unpack
  %15 = getelementptr double, ptr %.unpack, i64 %14
  %16 = load double, ptr %15, align 8, !tbaa !4
  %17 = fadd contract double %11, %16
  %18 = call i1 @_FortranAioOutputReal64(ptr %4, double %17)
  %19 = call i32 @_FortranAioEndIoStatement(ptr %4)
  %.unpack101 = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  call void @free(ptr %.unpack101)
  store ptr null, ptr @_QFEarr, align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  store i32 20180515, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  store i8 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  store i8 28, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  store i8 2, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  store i8 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  store i64 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  store i64 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  ret void
}
*** IR Dump After SROAPass on _QQmain ***
define void @_QQmain() local_unnamed_addr {
entry:
  %structArg = alloca { ptr, ptr, ptr }, align 8
  %0 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %1 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %2 = alloca i32, align 4
  store i32 1048576, ptr %2, align 4, !tbaa !4
  %3 = tail call dereferenceable_or_null(8388608) ptr @malloc(i64 8388608)
  store ptr %3, ptr @_QFEarr, align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  store i32 20180515, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  store i8 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  store i8 28, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  store i8 2, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  store i8 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  store i64 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  store i64 1048576, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  %omp_global_thread_num = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %2, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %1, ptr %gep_5, align 8
  %gep_6 = getelementptr inbounds { ptr, ptr, ptr }, ptr %structArg, i64 0, i32 2
  store ptr %0, ptr %gep_6, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QQmain..omp_par, ptr nonnull %structArg)
  %4 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.60ea5a38555821a77357f87d16df9a0f, i32 21)
  %5 = call i1 @_FortranAioOutputAscii(ptr %4, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %6 = load i32, ptr %2, align 4, !tbaa !4
  %7 = call i1 @_FortranAioOutputInteger32(ptr %4, i32 %6)
  %8 = call i1 @_FortranAioOutputAscii(ptr %4, ptr nonnull @_QQcl.2920697320, i64 5)
  %.unpack = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  %.unpack96.unpack.unpack = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  %9 = sub i64 1, %.unpack96.unpack.unpack
  %10 = getelementptr double, ptr %.unpack, i64 %9
  %11 = load double, ptr %10, align 8, !tbaa !4
  %12 = load i32, ptr %2, align 4, !tbaa !4
  %13 = sext i32 %12 to i64
  %14 = sub i64 %13, %.unpack96.unpack.unpack
  %15 = getelementptr double, ptr %.unpack, i64 %14
  %16 = load double, ptr %15, align 8, !tbaa !4
  %17 = fadd contract double %11, %16
  %18 = call i1 @_FortranAioOutputReal64(ptr %4, double %17)
  %19 = call i32 @_FortranAioEndIoStatement(ptr %4)
  %.unpack101 = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  call void @free(ptr %.unpack101)
  store ptr null, ptr @_QFEarr, align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  store i32 20180515, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  store i8 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  store i8 28, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  store i8 2, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  store i8 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  store i64 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  store i64 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  ret void
}
*** IR Dump After VectorCombinePass on _QQmain ***
define void @_QQmain() local_unnamed_addr {
entry:
  %structArg = alloca { ptr, ptr, ptr }, align 8
  %0 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %1 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %2 = alloca i32, align 4
  store i32 1048576, ptr %2, align 4, !tbaa !4
  %3 = tail call dereferenceable_or_null(8388608) ptr @malloc(i64 8388608)
  store ptr %3, ptr @_QFEarr, align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  store i32 20180515, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  store i8 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  store i8 28, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  store i8 2, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  store i8 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  store i64 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  store i64 1048576, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  %omp_global_thread_num = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %2, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %1, ptr %gep_5, align 8
  %gep_6 = getelementptr inbounds { ptr, ptr, ptr }, ptr %structArg, i64 0, i32 2
  store ptr %0, ptr %gep_6, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QQmain..omp_par, ptr nonnull %structArg)
  %4 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.60ea5a38555821a77357f87d16df9a0f, i32 21)
  %5 = call i1 @_FortranAioOutputAscii(ptr %4, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %6 = load i32, ptr %2, align 4, !tbaa !4
  %7 = call i1 @_FortranAioOutputInteger32(ptr %4, i32 %6)
  %8 = call i1 @_FortranAioOutputAscii(ptr %4, ptr nonnull @_QQcl.2920697320, i64 5)
  %.unpack = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  %.unpack96.unpack.unpack = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  %9 = sub i64 1, %.unpack96.unpack.unpack
  %10 = getelementptr double, ptr %.unpack, i64 %9
  %11 = load double, ptr %10, align 8, !tbaa !4
  %12 = load i32, ptr %2, align 4, !tbaa !4
  %13 = sext i32 %12 to i64
  %14 = sub i64 %13, %.unpack96.unpack.unpack
  %15 = getelementptr double, ptr %.unpack, i64 %14
  %16 = load double, ptr %15, align 8, !tbaa !4
  %17 = fadd contract double %11, %16
  %18 = call i1 @_FortranAioOutputReal64(ptr %4, double %17)
  %19 = call i32 @_FortranAioEndIoStatement(ptr %4)
  %.unpack101 = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  call void @free(ptr %.unpack101)
  store ptr null, ptr @_QFEarr, align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  store i32 20180515, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  store i8 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  store i8 28, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  store i8 2, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  store i8 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  store i64 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  store i64 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  ret void
}
*** IR Dump After MergedLoadStoreMotionPass on _QQmain ***
define void @_QQmain() local_unnamed_addr {
entry:
  %structArg = alloca { ptr, ptr, ptr }, align 8
  %0 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %1 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %2 = alloca i32, align 4
  store i32 1048576, ptr %2, align 4, !tbaa !4
  %3 = tail call dereferenceable_or_null(8388608) ptr @malloc(i64 8388608)
  store ptr %3, ptr @_QFEarr, align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  store i32 20180515, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  store i8 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  store i8 28, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  store i8 2, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  store i8 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  store i64 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  store i64 1048576, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  %omp_global_thread_num = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %2, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %1, ptr %gep_5, align 8
  %gep_6 = getelementptr inbounds { ptr, ptr, ptr }, ptr %structArg, i64 0, i32 2
  store ptr %0, ptr %gep_6, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QQmain..omp_par, ptr nonnull %structArg)
  %4 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.60ea5a38555821a77357f87d16df9a0f, i32 21)
  %5 = call i1 @_FortranAioOutputAscii(ptr %4, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %6 = load i32, ptr %2, align 4, !tbaa !4
  %7 = call i1 @_FortranAioOutputInteger32(ptr %4, i32 %6)
  %8 = call i1 @_FortranAioOutputAscii(ptr %4, ptr nonnull @_QQcl.2920697320, i64 5)
  %.unpack = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  %.unpack96.unpack.unpack = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  %9 = sub i64 1, %.unpack96.unpack.unpack
  %10 = getelementptr double, ptr %.unpack, i64 %9
  %11 = load double, ptr %10, align 8, !tbaa !4
  %12 = load i32, ptr %2, align 4, !tbaa !4
  %13 = sext i32 %12 to i64
  %14 = sub i64 %13, %.unpack96.unpack.unpack
  %15 = getelementptr double, ptr %.unpack, i64 %14
  %16 = load double, ptr %15, align 8, !tbaa !4
  %17 = fadd contract double %11, %16
  %18 = call i1 @_FortranAioOutputReal64(ptr %4, double %17)
  %19 = call i32 @_FortranAioEndIoStatement(ptr %4)
  %.unpack101 = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  call void @free(ptr %.unpack101)
  store ptr null, ptr @_QFEarr, align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  store i32 20180515, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  store i8 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  store i8 28, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  store i8 2, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  store i8 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  store i64 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  store i64 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  ret void
}
*** IR Dump After GVNPass on _QQmain ***
define void @_QQmain() local_unnamed_addr {
entry:
  %structArg = alloca { ptr, ptr, ptr }, align 8
  %0 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %1 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %2 = alloca i32, align 4
  store i32 1048576, ptr %2, align 4, !tbaa !4
  %3 = tail call dereferenceable_or_null(8388608) ptr @malloc(i64 8388608)
  store ptr %3, ptr @_QFEarr, align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  store i32 20180515, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  store i8 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  store i8 28, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  store i8 2, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  store i8 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  store i64 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  store i64 1048576, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  %omp_global_thread_num = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %2, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %1, ptr %gep_5, align 8
  %gep_6 = getelementptr inbounds { ptr, ptr, ptr }, ptr %structArg, i64 0, i32 2
  store ptr %0, ptr %gep_6, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QQmain..omp_par, ptr nonnull %structArg)
  %4 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.60ea5a38555821a77357f87d16df9a0f, i32 21)
  %5 = call i1 @_FortranAioOutputAscii(ptr %4, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %6 = load i32, ptr %2, align 4, !tbaa !4
  %7 = call i1 @_FortranAioOutputInteger32(ptr %4, i32 %6)
  %8 = call i1 @_FortranAioOutputAscii(ptr %4, ptr nonnull @_QQcl.2920697320, i64 5)
  %.unpack = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  %.unpack96.unpack.unpack = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  %9 = sub i64 1, %.unpack96.unpack.unpack
  %10 = getelementptr double, ptr %.unpack, i64 %9
  %11 = load double, ptr %10, align 8, !tbaa !4
  %12 = load i32, ptr %2, align 4, !tbaa !4
  %13 = sext i32 %12 to i64
  %14 = sub i64 %13, %.unpack96.unpack.unpack
  %15 = getelementptr double, ptr %.unpack, i64 %14
  %16 = load double, ptr %15, align 8, !tbaa !4
  %17 = fadd contract double %11, %16
  %18 = call i1 @_FortranAioOutputReal64(ptr %4, double %17)
  %19 = call i32 @_FortranAioEndIoStatement(ptr %4)
  %.unpack101 = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  call void @free(ptr %.unpack101)
  store ptr null, ptr @_QFEarr, align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  store i32 20180515, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  store i8 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  store i8 28, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  store i8 2, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  store i8 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  store i64 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  store i64 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  ret void
}
*** IR Dump After SCCPPass on _QQmain ***
define void @_QQmain() local_unnamed_addr {
entry:
  %structArg = alloca { ptr, ptr, ptr }, align 8
  %0 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %1 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %2 = alloca i32, align 4
  store i32 1048576, ptr %2, align 4, !tbaa !4
  %3 = tail call dereferenceable_or_null(8388608) ptr @malloc(i64 8388608)
  store ptr %3, ptr @_QFEarr, align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  store i32 20180515, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  store i8 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  store i8 28, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  store i8 2, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  store i8 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  store i64 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  store i64 1048576, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  %omp_global_thread_num = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %2, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %1, ptr %gep_5, align 8
  %gep_6 = getelementptr inbounds { ptr, ptr, ptr }, ptr %structArg, i64 0, i32 2
  store ptr %0, ptr %gep_6, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QQmain..omp_par, ptr nonnull %structArg)
  %4 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.60ea5a38555821a77357f87d16df9a0f, i32 21)
  %5 = call i1 @_FortranAioOutputAscii(ptr %4, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %6 = load i32, ptr %2, align 4, !tbaa !4
  %7 = call i1 @_FortranAioOutputInteger32(ptr %4, i32 %6)
  %8 = call i1 @_FortranAioOutputAscii(ptr %4, ptr nonnull @_QQcl.2920697320, i64 5)
  %.unpack = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  %.unpack96.unpack.unpack = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  %9 = sub i64 1, %.unpack96.unpack.unpack
  %10 = getelementptr double, ptr %.unpack, i64 %9
  %11 = load double, ptr %10, align 8, !tbaa !4
  %12 = load i32, ptr %2, align 4, !tbaa !4
  %13 = sext i32 %12 to i64
  %14 = sub i64 %13, %.unpack96.unpack.unpack
  %15 = getelementptr double, ptr %.unpack, i64 %14
  %16 = load double, ptr %15, align 8, !tbaa !4
  %17 = fadd contract double %11, %16
  %18 = call i1 @_FortranAioOutputReal64(ptr %4, double %17)
  %19 = call i32 @_FortranAioEndIoStatement(ptr %4)
  %.unpack101 = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  call void @free(ptr %.unpack101)
  store ptr null, ptr @_QFEarr, align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  store i32 20180515, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  store i8 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  store i8 28, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  store i8 2, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  store i8 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  store i64 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  store i64 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  ret void
}
*** IR Dump After BDCEPass on _QQmain ***
define void @_QQmain() local_unnamed_addr {
entry:
  %structArg = alloca { ptr, ptr, ptr }, align 8
  %0 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %1 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %2 = alloca i32, align 4
  store i32 1048576, ptr %2, align 4, !tbaa !4
  %3 = tail call dereferenceable_or_null(8388608) ptr @malloc(i64 8388608)
  store ptr %3, ptr @_QFEarr, align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  store i32 20180515, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  store i8 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  store i8 28, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  store i8 2, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  store i8 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  store i64 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  store i64 1048576, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  %omp_global_thread_num = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %2, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %1, ptr %gep_5, align 8
  %gep_6 = getelementptr inbounds { ptr, ptr, ptr }, ptr %structArg, i64 0, i32 2
  store ptr %0, ptr %gep_6, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QQmain..omp_par, ptr nonnull %structArg)
  %4 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.60ea5a38555821a77357f87d16df9a0f, i32 21)
  %5 = call i1 @_FortranAioOutputAscii(ptr %4, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %6 = load i32, ptr %2, align 4, !tbaa !4
  %7 = call i1 @_FortranAioOutputInteger32(ptr %4, i32 %6)
  %8 = call i1 @_FortranAioOutputAscii(ptr %4, ptr nonnull @_QQcl.2920697320, i64 5)
  %.unpack = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  %.unpack96.unpack.unpack = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  %9 = sub i64 1, %.unpack96.unpack.unpack
  %10 = getelementptr double, ptr %.unpack, i64 %9
  %11 = load double, ptr %10, align 8, !tbaa !4
  %12 = load i32, ptr %2, align 4, !tbaa !4
  %13 = sext i32 %12 to i64
  %14 = sub i64 %13, %.unpack96.unpack.unpack
  %15 = getelementptr double, ptr %.unpack, i64 %14
  %16 = load double, ptr %15, align 8, !tbaa !4
  %17 = fadd contract double %11, %16
  %18 = call i1 @_FortranAioOutputReal64(ptr %4, double %17)
  %19 = call i32 @_FortranAioEndIoStatement(ptr %4)
  %.unpack101 = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  call void @free(ptr %.unpack101)
  store ptr null, ptr @_QFEarr, align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  store i32 20180515, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  store i8 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  store i8 28, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  store i8 2, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  store i8 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  store i64 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  store i64 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  ret void
}
*** IR Dump After InstCombinePass on _QQmain ***
define void @_QQmain() local_unnamed_addr {
entry:
  %structArg = alloca { ptr, ptr, ptr }, align 8
  %0 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %1 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %2 = alloca i32, align 4
  store i32 1048576, ptr %2, align 4, !tbaa !4
  %3 = tail call dereferenceable_or_null(8388608) ptr @malloc(i64 8388608)
  store ptr %3, ptr @_QFEarr, align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  store i32 20180515, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  store i8 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  store i8 28, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  store i8 2, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  store i8 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  store i64 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  store i64 1048576, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  %omp_global_thread_num = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %2, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %1, ptr %gep_5, align 8
  %gep_6 = getelementptr inbounds { ptr, ptr, ptr }, ptr %structArg, i64 0, i32 2
  store ptr %0, ptr %gep_6, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QQmain..omp_par, ptr nonnull %structArg)
  %4 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.60ea5a38555821a77357f87d16df9a0f, i32 21)
  %5 = call i1 @_FortranAioOutputAscii(ptr %4, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %6 = load i32, ptr %2, align 4, !tbaa !4
  %7 = call i1 @_FortranAioOutputInteger32(ptr %4, i32 %6)
  %8 = call i1 @_FortranAioOutputAscii(ptr %4, ptr nonnull @_QQcl.2920697320, i64 5)
  %.unpack = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  %.unpack96.unpack.unpack = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  %9 = sub i64 1, %.unpack96.unpack.unpack
  %10 = getelementptr double, ptr %.unpack, i64 %9
  %11 = load double, ptr %10, align 8, !tbaa !4
  %12 = load i32, ptr %2, align 4, !tbaa !4
  %13 = sext i32 %12 to i64
  %14 = sub i64 %13, %.unpack96.unpack.unpack
  %15 = getelementptr double, ptr %.unpack, i64 %14
  %16 = load double, ptr %15, align 8, !tbaa !4
  %17 = fadd contract double %11, %16
  %18 = call i1 @_FortranAioOutputReal64(ptr %4, double %17)
  %19 = call i32 @_FortranAioEndIoStatement(ptr %4)
  %.unpack101 = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  call void @free(ptr %.unpack101)
  store ptr null, ptr @_QFEarr, align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  store i32 20180515, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  store i8 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  store i8 28, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  store i8 2, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  store i8 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  store i64 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  store i64 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  ret void
}
*** IR Dump After JumpThreadingPass on _QQmain ***
define void @_QQmain() local_unnamed_addr {
entry:
  %structArg = alloca { ptr, ptr, ptr }, align 8
  %0 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %1 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %2 = alloca i32, align 4
  store i32 1048576, ptr %2, align 4, !tbaa !4
  %3 = tail call dereferenceable_or_null(8388608) ptr @malloc(i64 8388608)
  store ptr %3, ptr @_QFEarr, align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  store i32 20180515, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  store i8 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  store i8 28, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  store i8 2, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  store i8 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  store i64 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  store i64 1048576, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  %omp_global_thread_num = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %2, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %1, ptr %gep_5, align 8
  %gep_6 = getelementptr inbounds { ptr, ptr, ptr }, ptr %structArg, i64 0, i32 2
  store ptr %0, ptr %gep_6, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QQmain..omp_par, ptr nonnull %structArg)
  %4 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.60ea5a38555821a77357f87d16df9a0f, i32 21)
  %5 = call i1 @_FortranAioOutputAscii(ptr %4, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %6 = load i32, ptr %2, align 4, !tbaa !4
  %7 = call i1 @_FortranAioOutputInteger32(ptr %4, i32 %6)
  %8 = call i1 @_FortranAioOutputAscii(ptr %4, ptr nonnull @_QQcl.2920697320, i64 5)
  %.unpack = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  %.unpack96.unpack.unpack = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  %9 = sub i64 1, %.unpack96.unpack.unpack
  %10 = getelementptr double, ptr %.unpack, i64 %9
  %11 = load double, ptr %10, align 8, !tbaa !4
  %12 = load i32, ptr %2, align 4, !tbaa !4
  %13 = sext i32 %12 to i64
  %14 = sub i64 %13, %.unpack96.unpack.unpack
  %15 = getelementptr double, ptr %.unpack, i64 %14
  %16 = load double, ptr %15, align 8, !tbaa !4
  %17 = fadd contract double %11, %16
  %18 = call i1 @_FortranAioOutputReal64(ptr %4, double %17)
  %19 = call i32 @_FortranAioEndIoStatement(ptr %4)
  %.unpack101 = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  call void @free(ptr %.unpack101)
  store ptr null, ptr @_QFEarr, align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  store i32 20180515, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  store i8 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  store i8 28, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  store i8 2, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  store i8 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  store i64 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  store i64 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  ret void
}
*** IR Dump After CorrelatedValuePropagationPass on _QQmain ***
define void @_QQmain() local_unnamed_addr {
entry:
  %structArg = alloca { ptr, ptr, ptr }, align 8
  %0 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %1 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %2 = alloca i32, align 4
  store i32 1048576, ptr %2, align 4, !tbaa !4
  %3 = tail call dereferenceable_or_null(8388608) ptr @malloc(i64 8388608)
  store ptr %3, ptr @_QFEarr, align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  store i32 20180515, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  store i8 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  store i8 28, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  store i8 2, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  store i8 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  store i64 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  store i64 1048576, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  %omp_global_thread_num = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %2, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %1, ptr %gep_5, align 8
  %gep_6 = getelementptr inbounds { ptr, ptr, ptr }, ptr %structArg, i64 0, i32 2
  store ptr %0, ptr %gep_6, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QQmain..omp_par, ptr nonnull %structArg)
  %4 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.60ea5a38555821a77357f87d16df9a0f, i32 21)
  %5 = call i1 @_FortranAioOutputAscii(ptr %4, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %6 = load i32, ptr %2, align 4, !tbaa !4
  %7 = call i1 @_FortranAioOutputInteger32(ptr %4, i32 %6)
  %8 = call i1 @_FortranAioOutputAscii(ptr %4, ptr nonnull @_QQcl.2920697320, i64 5)
  %.unpack = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  %.unpack96.unpack.unpack = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  %9 = sub i64 1, %.unpack96.unpack.unpack
  %10 = getelementptr double, ptr %.unpack, i64 %9
  %11 = load double, ptr %10, align 8, !tbaa !4
  %12 = load i32, ptr %2, align 4, !tbaa !4
  %13 = sext i32 %12 to i64
  %14 = sub i64 %13, %.unpack96.unpack.unpack
  %15 = getelementptr double, ptr %.unpack, i64 %14
  %16 = load double, ptr %15, align 8, !tbaa !4
  %17 = fadd contract double %11, %16
  %18 = call i1 @_FortranAioOutputReal64(ptr %4, double %17)
  %19 = call i32 @_FortranAioEndIoStatement(ptr %4)
  %.unpack101 = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  call void @free(ptr %.unpack101)
  store ptr null, ptr @_QFEarr, align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  store i32 20180515, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  store i8 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  store i8 28, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  store i8 2, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  store i8 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  store i64 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  store i64 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  ret void
}
*** IR Dump After ADCEPass on _QQmain ***
define void @_QQmain() local_unnamed_addr {
entry:
  %structArg = alloca { ptr, ptr, ptr }, align 8
  %0 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %1 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %2 = alloca i32, align 4
  store i32 1048576, ptr %2, align 4, !tbaa !4
  %3 = tail call dereferenceable_or_null(8388608) ptr @malloc(i64 8388608)
  store ptr %3, ptr @_QFEarr, align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  store i32 20180515, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  store i8 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  store i8 28, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  store i8 2, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  store i8 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  store i64 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  store i64 1048576, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  %omp_global_thread_num = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %2, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %1, ptr %gep_5, align 8
  %gep_6 = getelementptr inbounds { ptr, ptr, ptr }, ptr %structArg, i64 0, i32 2
  store ptr %0, ptr %gep_6, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QQmain..omp_par, ptr nonnull %structArg)
  %4 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.60ea5a38555821a77357f87d16df9a0f, i32 21)
  %5 = call i1 @_FortranAioOutputAscii(ptr %4, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %6 = load i32, ptr %2, align 4, !tbaa !4
  %7 = call i1 @_FortranAioOutputInteger32(ptr %4, i32 %6)
  %8 = call i1 @_FortranAioOutputAscii(ptr %4, ptr nonnull @_QQcl.2920697320, i64 5)
  %.unpack = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  %.unpack96.unpack.unpack = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  %9 = sub i64 1, %.unpack96.unpack.unpack
  %10 = getelementptr double, ptr %.unpack, i64 %9
  %11 = load double, ptr %10, align 8, !tbaa !4
  %12 = load i32, ptr %2, align 4, !tbaa !4
  %13 = sext i32 %12 to i64
  %14 = sub i64 %13, %.unpack96.unpack.unpack
  %15 = getelementptr double, ptr %.unpack, i64 %14
  %16 = load double, ptr %15, align 8, !tbaa !4
  %17 = fadd contract double %11, %16
  %18 = call i1 @_FortranAioOutputReal64(ptr %4, double %17)
  %19 = call i32 @_FortranAioEndIoStatement(ptr %4)
  %.unpack101 = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  call void @free(ptr %.unpack101)
  store ptr null, ptr @_QFEarr, align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  store i32 20180515, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  store i8 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  store i8 28, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  store i8 2, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  store i8 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  store i64 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  store i64 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  ret void
}
*** IR Dump After MemCpyOptPass on _QQmain ***
define void @_QQmain() local_unnamed_addr {
entry:
  %structArg = alloca { ptr, ptr, ptr }, align 8
  %0 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %1 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %2 = alloca i32, align 4
  store i32 1048576, ptr %2, align 4, !tbaa !4
  %3 = tail call dereferenceable_or_null(8388608) ptr @malloc(i64 8388608)
  store ptr %3, ptr @_QFEarr, align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  store i32 20180515, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  store i8 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  store i8 28, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  store i8 2, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  store i8 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  store i64 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  store i64 1048576, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  %omp_global_thread_num = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %2, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %1, ptr %gep_5, align 8
  %gep_6 = getelementptr inbounds { ptr, ptr, ptr }, ptr %structArg, i64 0, i32 2
  store ptr %0, ptr %gep_6, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QQmain..omp_par, ptr nonnull %structArg)
  %4 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.60ea5a38555821a77357f87d16df9a0f, i32 21)
  %5 = call i1 @_FortranAioOutputAscii(ptr %4, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %6 = load i32, ptr %2, align 4, !tbaa !4
  %7 = call i1 @_FortranAioOutputInteger32(ptr %4, i32 %6)
  %8 = call i1 @_FortranAioOutputAscii(ptr %4, ptr nonnull @_QQcl.2920697320, i64 5)
  %.unpack = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  %.unpack96.unpack.unpack = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  %9 = sub i64 1, %.unpack96.unpack.unpack
  %10 = getelementptr double, ptr %.unpack, i64 %9
  %11 = load double, ptr %10, align 8, !tbaa !4
  %12 = load i32, ptr %2, align 4, !tbaa !4
  %13 = sext i32 %12 to i64
  %14 = sub i64 %13, %.unpack96.unpack.unpack
  %15 = getelementptr double, ptr %.unpack, i64 %14
  %16 = load double, ptr %15, align 8, !tbaa !4
  %17 = fadd contract double %11, %16
  %18 = call i1 @_FortranAioOutputReal64(ptr %4, double %17)
  %19 = call i32 @_FortranAioEndIoStatement(ptr %4)
  %.unpack101 = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  call void @free(ptr %.unpack101)
  store ptr null, ptr @_QFEarr, align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  store i32 20180515, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  store i8 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  store i8 28, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  store i8 2, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  store i8 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  store i64 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  store i64 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  ret void
}
*** IR Dump After DSEPass on _QQmain ***
define void @_QQmain() local_unnamed_addr {
entry:
  %structArg = alloca { ptr, ptr, ptr }, align 8
  %0 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %1 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %2 = alloca i32, align 4
  store i32 1048576, ptr %2, align 4, !tbaa !4
  %3 = tail call dereferenceable_or_null(8388608) ptr @malloc(i64 8388608)
  store ptr %3, ptr @_QFEarr, align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  store i32 20180515, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  store i8 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  store i8 28, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  store i8 2, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  store i8 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  store i64 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  store i64 1048576, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  %omp_global_thread_num = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %2, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %1, ptr %gep_5, align 8
  %gep_6 = getelementptr inbounds { ptr, ptr, ptr }, ptr %structArg, i64 0, i32 2
  store ptr %0, ptr %gep_6, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QQmain..omp_par, ptr nonnull %structArg)
  %4 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.60ea5a38555821a77357f87d16df9a0f, i32 21)
  %5 = call i1 @_FortranAioOutputAscii(ptr %4, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %6 = load i32, ptr %2, align 4, !tbaa !4
  %7 = call i1 @_FortranAioOutputInteger32(ptr %4, i32 %6)
  %8 = call i1 @_FortranAioOutputAscii(ptr %4, ptr nonnull @_QQcl.2920697320, i64 5)
  %.unpack = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  %.unpack96.unpack.unpack = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  %9 = sub i64 1, %.unpack96.unpack.unpack
  %10 = getelementptr double, ptr %.unpack, i64 %9
  %11 = load double, ptr %10, align 8, !tbaa !4
  %12 = load i32, ptr %2, align 4, !tbaa !4
  %13 = sext i32 %12 to i64
  %14 = sub i64 %13, %.unpack96.unpack.unpack
  %15 = getelementptr double, ptr %.unpack, i64 %14
  %16 = load double, ptr %15, align 8, !tbaa !4
  %17 = fadd contract double %11, %16
  %18 = call i1 @_FortranAioOutputReal64(ptr %4, double %17)
  %19 = call i32 @_FortranAioEndIoStatement(ptr %4)
  %.unpack101 = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  call void @free(ptr %.unpack101)
  store ptr null, ptr @_QFEarr, align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  store i32 20180515, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  store i8 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  store i8 28, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  store i8 2, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  store i8 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  store i64 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  store i64 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  ret void
}
*** IR Dump After MoveAutoInitPass on _QQmain ***
define void @_QQmain() local_unnamed_addr {
entry:
  %structArg = alloca { ptr, ptr, ptr }, align 8
  %0 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %1 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %2 = alloca i32, align 4
  store i32 1048576, ptr %2, align 4, !tbaa !4
  %3 = tail call dereferenceable_or_null(8388608) ptr @malloc(i64 8388608)
  store ptr %3, ptr @_QFEarr, align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  store i32 20180515, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  store i8 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  store i8 28, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  store i8 2, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  store i8 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  store i64 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  store i64 1048576, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  %omp_global_thread_num = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %2, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %1, ptr %gep_5, align 8
  %gep_6 = getelementptr inbounds { ptr, ptr, ptr }, ptr %structArg, i64 0, i32 2
  store ptr %0, ptr %gep_6, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QQmain..omp_par, ptr nonnull %structArg)
  %4 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.60ea5a38555821a77357f87d16df9a0f, i32 21)
  %5 = call i1 @_FortranAioOutputAscii(ptr %4, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %6 = load i32, ptr %2, align 4, !tbaa !4
  %7 = call i1 @_FortranAioOutputInteger32(ptr %4, i32 %6)
  %8 = call i1 @_FortranAioOutputAscii(ptr %4, ptr nonnull @_QQcl.2920697320, i64 5)
  %.unpack = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  %.unpack96.unpack.unpack = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  %9 = sub i64 1, %.unpack96.unpack.unpack
  %10 = getelementptr double, ptr %.unpack, i64 %9
  %11 = load double, ptr %10, align 8, !tbaa !4
  %12 = load i32, ptr %2, align 4, !tbaa !4
  %13 = sext i32 %12 to i64
  %14 = sub i64 %13, %.unpack96.unpack.unpack
  %15 = getelementptr double, ptr %.unpack, i64 %14
  %16 = load double, ptr %15, align 8, !tbaa !4
  %17 = fadd contract double %11, %16
  %18 = call i1 @_FortranAioOutputReal64(ptr %4, double %17)
  %19 = call i32 @_FortranAioEndIoStatement(ptr %4)
  %.unpack101 = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  call void @free(ptr %.unpack101)
  store ptr null, ptr @_QFEarr, align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  store i32 20180515, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  store i8 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  store i8 28, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  store i8 2, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  store i8 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  store i64 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  store i64 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  ret void
}
*** IR Dump After LoopSimplifyPass on _QQmain ***
define void @_QQmain() local_unnamed_addr {
entry:
  %structArg = alloca { ptr, ptr, ptr }, align 8
  %0 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %1 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %2 = alloca i32, align 4
  store i32 1048576, ptr %2, align 4, !tbaa !4
  %3 = tail call dereferenceable_or_null(8388608) ptr @malloc(i64 8388608)
  store ptr %3, ptr @_QFEarr, align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  store i32 20180515, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  store i8 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  store i8 28, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  store i8 2, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  store i8 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  store i64 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  store i64 1048576, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  %omp_global_thread_num = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %2, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %1, ptr %gep_5, align 8
  %gep_6 = getelementptr inbounds { ptr, ptr, ptr }, ptr %structArg, i64 0, i32 2
  store ptr %0, ptr %gep_6, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QQmain..omp_par, ptr nonnull %structArg)
  %4 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.60ea5a38555821a77357f87d16df9a0f, i32 21)
  %5 = call i1 @_FortranAioOutputAscii(ptr %4, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %6 = load i32, ptr %2, align 4, !tbaa !4
  %7 = call i1 @_FortranAioOutputInteger32(ptr %4, i32 %6)
  %8 = call i1 @_FortranAioOutputAscii(ptr %4, ptr nonnull @_QQcl.2920697320, i64 5)
  %.unpack = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  %.unpack96.unpack.unpack = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  %9 = sub i64 1, %.unpack96.unpack.unpack
  %10 = getelementptr double, ptr %.unpack, i64 %9
  %11 = load double, ptr %10, align 8, !tbaa !4
  %12 = load i32, ptr %2, align 4, !tbaa !4
  %13 = sext i32 %12 to i64
  %14 = sub i64 %13, %.unpack96.unpack.unpack
  %15 = getelementptr double, ptr %.unpack, i64 %14
  %16 = load double, ptr %15, align 8, !tbaa !4
  %17 = fadd contract double %11, %16
  %18 = call i1 @_FortranAioOutputReal64(ptr %4, double %17)
  %19 = call i32 @_FortranAioEndIoStatement(ptr %4)
  %.unpack101 = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  call void @free(ptr %.unpack101)
  store ptr null, ptr @_QFEarr, align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  store i32 20180515, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  store i8 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  store i8 28, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  store i8 2, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  store i8 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  store i64 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  store i64 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  ret void
}
*** IR Dump After LCSSAPass on _QQmain ***
define void @_QQmain() local_unnamed_addr {
entry:
  %structArg = alloca { ptr, ptr, ptr }, align 8
  %0 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %1 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %2 = alloca i32, align 4
  store i32 1048576, ptr %2, align 4, !tbaa !4
  %3 = tail call dereferenceable_or_null(8388608) ptr @malloc(i64 8388608)
  store ptr %3, ptr @_QFEarr, align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  store i32 20180515, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  store i8 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  store i8 28, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  store i8 2, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  store i8 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  store i64 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  store i64 1048576, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  %omp_global_thread_num = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %2, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %1, ptr %gep_5, align 8
  %gep_6 = getelementptr inbounds { ptr, ptr, ptr }, ptr %structArg, i64 0, i32 2
  store ptr %0, ptr %gep_6, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QQmain..omp_par, ptr nonnull %structArg)
  %4 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.60ea5a38555821a77357f87d16df9a0f, i32 21)
  %5 = call i1 @_FortranAioOutputAscii(ptr %4, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %6 = load i32, ptr %2, align 4, !tbaa !4
  %7 = call i1 @_FortranAioOutputInteger32(ptr %4, i32 %6)
  %8 = call i1 @_FortranAioOutputAscii(ptr %4, ptr nonnull @_QQcl.2920697320, i64 5)
  %.unpack = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  %.unpack96.unpack.unpack = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  %9 = sub i64 1, %.unpack96.unpack.unpack
  %10 = getelementptr double, ptr %.unpack, i64 %9
  %11 = load double, ptr %10, align 8, !tbaa !4
  %12 = load i32, ptr %2, align 4, !tbaa !4
  %13 = sext i32 %12 to i64
  %14 = sub i64 %13, %.unpack96.unpack.unpack
  %15 = getelementptr double, ptr %.unpack, i64 %14
  %16 = load double, ptr %15, align 8, !tbaa !4
  %17 = fadd contract double %11, %16
  %18 = call i1 @_FortranAioOutputReal64(ptr %4, double %17)
  %19 = call i32 @_FortranAioEndIoStatement(ptr %4)
  %.unpack101 = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  call void @free(ptr %.unpack101)
  store ptr null, ptr @_QFEarr, align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  store i32 20180515, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  store i8 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  store i8 28, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  store i8 2, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  store i8 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  store i64 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  store i64 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  ret void
}
*** IR Dump After CoroElidePass on _QQmain ***
define void @_QQmain() local_unnamed_addr {
entry:
  %structArg = alloca { ptr, ptr, ptr }, align 8
  %0 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %1 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %2 = alloca i32, align 4
  store i32 1048576, ptr %2, align 4, !tbaa !4
  %3 = tail call dereferenceable_or_null(8388608) ptr @malloc(i64 8388608)
  store ptr %3, ptr @_QFEarr, align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  store i32 20180515, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  store i8 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  store i8 28, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  store i8 2, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  store i8 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  store i64 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  store i64 1048576, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  %omp_global_thread_num = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %2, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %1, ptr %gep_5, align 8
  %gep_6 = getelementptr inbounds { ptr, ptr, ptr }, ptr %structArg, i64 0, i32 2
  store ptr %0, ptr %gep_6, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QQmain..omp_par, ptr nonnull %structArg)
  %4 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.60ea5a38555821a77357f87d16df9a0f, i32 21)
  %5 = call i1 @_FortranAioOutputAscii(ptr %4, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %6 = load i32, ptr %2, align 4, !tbaa !4
  %7 = call i1 @_FortranAioOutputInteger32(ptr %4, i32 %6)
  %8 = call i1 @_FortranAioOutputAscii(ptr %4, ptr nonnull @_QQcl.2920697320, i64 5)
  %.unpack = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  %.unpack96.unpack.unpack = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  %9 = sub i64 1, %.unpack96.unpack.unpack
  %10 = getelementptr double, ptr %.unpack, i64 %9
  %11 = load double, ptr %10, align 8, !tbaa !4
  %12 = load i32, ptr %2, align 4, !tbaa !4
  %13 = sext i32 %12 to i64
  %14 = sub i64 %13, %.unpack96.unpack.unpack
  %15 = getelementptr double, ptr %.unpack, i64 %14
  %16 = load double, ptr %15, align 8, !tbaa !4
  %17 = fadd contract double %11, %16
  %18 = call i1 @_FortranAioOutputReal64(ptr %4, double %17)
  %19 = call i32 @_FortranAioEndIoStatement(ptr %4)
  %.unpack101 = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  call void @free(ptr %.unpack101)
  store ptr null, ptr @_QFEarr, align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  store i32 20180515, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  store i8 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  store i8 28, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  store i8 2, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  store i8 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  store i64 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  store i64 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  ret void
}
*** IR Dump After SimplifyCFGPass on _QQmain ***
define void @_QQmain() local_unnamed_addr {
entry:
  %structArg = alloca { ptr, ptr, ptr }, align 8
  %0 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %1 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %2 = alloca i32, align 4
  store i32 1048576, ptr %2, align 4, !tbaa !4
  %3 = tail call dereferenceable_or_null(8388608) ptr @malloc(i64 8388608)
  store ptr %3, ptr @_QFEarr, align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  store i32 20180515, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  store i8 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  store i8 28, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  store i8 2, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  store i8 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  store i64 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  store i64 1048576, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  %omp_global_thread_num = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %2, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %1, ptr %gep_5, align 8
  %gep_6 = getelementptr inbounds { ptr, ptr, ptr }, ptr %structArg, i64 0, i32 2
  store ptr %0, ptr %gep_6, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QQmain..omp_par, ptr nonnull %structArg)
  %4 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.60ea5a38555821a77357f87d16df9a0f, i32 21)
  %5 = call i1 @_FortranAioOutputAscii(ptr %4, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %6 = load i32, ptr %2, align 4, !tbaa !4
  %7 = call i1 @_FortranAioOutputInteger32(ptr %4, i32 %6)
  %8 = call i1 @_FortranAioOutputAscii(ptr %4, ptr nonnull @_QQcl.2920697320, i64 5)
  %.unpack = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  %.unpack96.unpack.unpack = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  %9 = sub i64 1, %.unpack96.unpack.unpack
  %10 = getelementptr double, ptr %.unpack, i64 %9
  %11 = load double, ptr %10, align 8, !tbaa !4
  %12 = load i32, ptr %2, align 4, !tbaa !4
  %13 = sext i32 %12 to i64
  %14 = sub i64 %13, %.unpack96.unpack.unpack
  %15 = getelementptr double, ptr %.unpack, i64 %14
  %16 = load double, ptr %15, align 8, !tbaa !4
  %17 = fadd contract double %11, %16
  %18 = call i1 @_FortranAioOutputReal64(ptr %4, double %17)
  %19 = call i32 @_FortranAioEndIoStatement(ptr %4)
  %.unpack101 = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  call void @free(ptr %.unpack101)
  store ptr null, ptr @_QFEarr, align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  store i32 20180515, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  store i8 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  store i8 28, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  store i8 2, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  store i8 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  store i64 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  store i64 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  ret void
}
*** IR Dump After InstCombinePass on _QQmain ***
define void @_QQmain() local_unnamed_addr {
entry:
  %structArg = alloca { ptr, ptr, ptr }, align 8
  %0 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %1 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %2 = alloca i32, align 4
  store i32 1048576, ptr %2, align 4, !tbaa !4
  %3 = tail call dereferenceable_or_null(8388608) ptr @malloc(i64 8388608)
  store ptr %3, ptr @_QFEarr, align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  store i32 20180515, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  store i8 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  store i8 28, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  store i8 2, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  store i8 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  store i64 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  store i64 1048576, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  %omp_global_thread_num = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %2, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %1, ptr %gep_5, align 8
  %gep_6 = getelementptr inbounds { ptr, ptr, ptr }, ptr %structArg, i64 0, i32 2
  store ptr %0, ptr %gep_6, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QQmain..omp_par, ptr nonnull %structArg)
  %4 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.60ea5a38555821a77357f87d16df9a0f, i32 21)
  %5 = call i1 @_FortranAioOutputAscii(ptr %4, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %6 = load i32, ptr %2, align 4, !tbaa !4
  %7 = call i1 @_FortranAioOutputInteger32(ptr %4, i32 %6)
  %8 = call i1 @_FortranAioOutputAscii(ptr %4, ptr nonnull @_QQcl.2920697320, i64 5)
  %.unpack = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  %.unpack96.unpack.unpack = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  %9 = sub i64 1, %.unpack96.unpack.unpack
  %10 = getelementptr double, ptr %.unpack, i64 %9
  %11 = load double, ptr %10, align 8, !tbaa !4
  %12 = load i32, ptr %2, align 4, !tbaa !4
  %13 = sext i32 %12 to i64
  %14 = sub i64 %13, %.unpack96.unpack.unpack
  %15 = getelementptr double, ptr %.unpack, i64 %14
  %16 = load double, ptr %15, align 8, !tbaa !4
  %17 = fadd contract double %11, %16
  %18 = call i1 @_FortranAioOutputReal64(ptr %4, double %17)
  %19 = call i32 @_FortranAioEndIoStatement(ptr %4)
  %.unpack101 = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  call void @free(ptr %.unpack101)
  store ptr null, ptr @_QFEarr, align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  store i32 20180515, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  store i8 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  store i8 28, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  store i8 2, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  store i8 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  store i64 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  store i64 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  ret void
}
*** IR Dump After PostOrderFunctionAttrsPass on (_QQmain) ***
define void @_QQmain() local_unnamed_addr {
entry:
  %structArg = alloca { ptr, ptr, ptr }, align 8
  %0 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %1 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %2 = alloca i32, align 4
  store i32 1048576, ptr %2, align 4, !tbaa !4
  %3 = tail call dereferenceable_or_null(8388608) ptr @malloc(i64 8388608)
  store ptr %3, ptr @_QFEarr, align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  store i32 20180515, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  store i8 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  store i8 28, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  store i8 2, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  store i8 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  store i64 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  store i64 1048576, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  %omp_global_thread_num = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %2, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %1, ptr %gep_5, align 8
  %gep_6 = getelementptr inbounds { ptr, ptr, ptr }, ptr %structArg, i64 0, i32 2
  store ptr %0, ptr %gep_6, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QQmain..omp_par, ptr nonnull %structArg)
  %4 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.60ea5a38555821a77357f87d16df9a0f, i32 21)
  %5 = call i1 @_FortranAioOutputAscii(ptr %4, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %6 = load i32, ptr %2, align 4, !tbaa !4
  %7 = call i1 @_FortranAioOutputInteger32(ptr %4, i32 %6)
  %8 = call i1 @_FortranAioOutputAscii(ptr %4, ptr nonnull @_QQcl.2920697320, i64 5)
  %.unpack = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  %.unpack96.unpack.unpack = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  %9 = sub i64 1, %.unpack96.unpack.unpack
  %10 = getelementptr double, ptr %.unpack, i64 %9
  %11 = load double, ptr %10, align 8, !tbaa !4
  %12 = load i32, ptr %2, align 4, !tbaa !4
  %13 = sext i32 %12 to i64
  %14 = sub i64 %13, %.unpack96.unpack.unpack
  %15 = getelementptr double, ptr %.unpack, i64 %14
  %16 = load double, ptr %15, align 8, !tbaa !4
  %17 = fadd contract double %11, %16
  %18 = call i1 @_FortranAioOutputReal64(ptr %4, double %17)
  %19 = call i32 @_FortranAioEndIoStatement(ptr %4)
  %.unpack101 = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  call void @free(ptr %.unpack101)
  store ptr null, ptr @_QFEarr, align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  store i32 20180515, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  store i8 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  store i8 28, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  store i8 2, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  store i8 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  store i64 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  store i64 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  ret void
}
*** IR Dump After RequireAnalysisPass<llvm::ShouldNotRunFunctionPassesAnalysis, llvm::Function> on _QQmain ***
define void @_QQmain() local_unnamed_addr {
entry:
  %structArg = alloca { ptr, ptr, ptr }, align 8
  %0 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %1 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %2 = alloca i32, align 4
  store i32 1048576, ptr %2, align 4, !tbaa !4
  %3 = tail call dereferenceable_or_null(8388608) ptr @malloc(i64 8388608)
  store ptr %3, ptr @_QFEarr, align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  store i32 20180515, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  store i8 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  store i8 28, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  store i8 2, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  store i8 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  store i64 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  store i64 1048576, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  %omp_global_thread_num = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %2, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %1, ptr %gep_5, align 8
  %gep_6 = getelementptr inbounds { ptr, ptr, ptr }, ptr %structArg, i64 0, i32 2
  store ptr %0, ptr %gep_6, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QQmain..omp_par, ptr nonnull %structArg)
  %4 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.60ea5a38555821a77357f87d16df9a0f, i32 21)
  %5 = call i1 @_FortranAioOutputAscii(ptr %4, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %6 = load i32, ptr %2, align 4, !tbaa !4
  %7 = call i1 @_FortranAioOutputInteger32(ptr %4, i32 %6)
  %8 = call i1 @_FortranAioOutputAscii(ptr %4, ptr nonnull @_QQcl.2920697320, i64 5)
  %.unpack = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  %.unpack96.unpack.unpack = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  %9 = sub i64 1, %.unpack96.unpack.unpack
  %10 = getelementptr double, ptr %.unpack, i64 %9
  %11 = load double, ptr %10, align 8, !tbaa !4
  %12 = load i32, ptr %2, align 4, !tbaa !4
  %13 = sext i32 %12 to i64
  %14 = sub i64 %13, %.unpack96.unpack.unpack
  %15 = getelementptr double, ptr %.unpack, i64 %14
  %16 = load double, ptr %15, align 8, !tbaa !4
  %17 = fadd contract double %11, %16
  %18 = call i1 @_FortranAioOutputReal64(ptr %4, double %17)
  %19 = call i32 @_FortranAioEndIoStatement(ptr %4)
  %.unpack101 = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  call void @free(ptr %.unpack101)
  store ptr null, ptr @_QFEarr, align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  store i32 20180515, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  store i8 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  store i8 28, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  store i8 2, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  store i8 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  store i64 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  store i64 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  ret void
}
*** IR Dump After CoroSplitPass on (_QQmain) ***
define void @_QQmain() local_unnamed_addr {
entry:
  %structArg = alloca { ptr, ptr, ptr }, align 8
  %0 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %1 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %2 = alloca i32, align 4
  store i32 1048576, ptr %2, align 4, !tbaa !4
  %3 = tail call dereferenceable_or_null(8388608) ptr @malloc(i64 8388608)
  store ptr %3, ptr @_QFEarr, align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  store i32 20180515, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  store i8 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  store i8 28, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  store i8 2, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  store i8 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  store i64 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  store i64 1048576, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  %omp_global_thread_num = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %2, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %1, ptr %gep_5, align 8
  %gep_6 = getelementptr inbounds { ptr, ptr, ptr }, ptr %structArg, i64 0, i32 2
  store ptr %0, ptr %gep_6, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QQmain..omp_par, ptr nonnull %structArg)
  %4 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.60ea5a38555821a77357f87d16df9a0f, i32 21)
  %5 = call i1 @_FortranAioOutputAscii(ptr %4, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %6 = load i32, ptr %2, align 4, !tbaa !4
  %7 = call i1 @_FortranAioOutputInteger32(ptr %4, i32 %6)
  %8 = call i1 @_FortranAioOutputAscii(ptr %4, ptr nonnull @_QQcl.2920697320, i64 5)
  %.unpack = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  %.unpack96.unpack.unpack = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  %9 = sub i64 1, %.unpack96.unpack.unpack
  %10 = getelementptr double, ptr %.unpack, i64 %9
  %11 = load double, ptr %10, align 8, !tbaa !4
  %12 = load i32, ptr %2, align 4, !tbaa !4
  %13 = sext i32 %12 to i64
  %14 = sub i64 %13, %.unpack96.unpack.unpack
  %15 = getelementptr double, ptr %.unpack, i64 %14
  %16 = load double, ptr %15, align 8, !tbaa !4
  %17 = fadd contract double %11, %16
  %18 = call i1 @_FortranAioOutputReal64(ptr %4, double %17)
  %19 = call i32 @_FortranAioEndIoStatement(ptr %4)
  %.unpack101 = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  call void @free(ptr %.unpack101)
  store ptr null, ptr @_QFEarr, align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  store i32 20180515, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  store i8 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  store i8 28, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  store i8 2, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  store i8 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  store i64 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  store i64 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  ret void
}
*** IR Dump After InvalidateAnalysisPass<llvm::ShouldNotRunFunctionPassesAnalysis> on _QQmain ***
define void @_QQmain() local_unnamed_addr {
entry:
  %structArg = alloca { ptr, ptr, ptr }, align 8
  %0 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %1 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %2 = alloca i32, align 4
  store i32 1048576, ptr %2, align 4, !tbaa !4
  %3 = tail call dereferenceable_or_null(8388608) ptr @malloc(i64 8388608)
  store ptr %3, ptr @_QFEarr, align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  store i32 20180515, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  store i8 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  store i8 28, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  store i8 2, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  store i8 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  store i64 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  store i64 1048576, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  %omp_global_thread_num = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %2, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %1, ptr %gep_5, align 8
  %gep_6 = getelementptr inbounds { ptr, ptr, ptr }, ptr %structArg, i64 0, i32 2
  store ptr %0, ptr %gep_6, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QQmain..omp_par, ptr nonnull %structArg)
  %4 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.60ea5a38555821a77357f87d16df9a0f, i32 21)
  %5 = call i1 @_FortranAioOutputAscii(ptr %4, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %6 = load i32, ptr %2, align 4, !tbaa !4
  %7 = call i1 @_FortranAioOutputInteger32(ptr %4, i32 %6)
  %8 = call i1 @_FortranAioOutputAscii(ptr %4, ptr nonnull @_QQcl.2920697320, i64 5)
  %.unpack = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  %.unpack96.unpack.unpack = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  %9 = sub i64 1, %.unpack96.unpack.unpack
  %10 = getelementptr double, ptr %.unpack, i64 %9
  %11 = load double, ptr %10, align 8, !tbaa !4
  %12 = load i32, ptr %2, align 4, !tbaa !4
  %13 = sext i32 %12 to i64
  %14 = sub i64 %13, %.unpack96.unpack.unpack
  %15 = getelementptr double, ptr %.unpack, i64 %14
  %16 = load double, ptr %15, align 8, !tbaa !4
  %17 = fadd contract double %11, %16
  %18 = call i1 @_FortranAioOutputReal64(ptr %4, double %17)
  %19 = call i32 @_FortranAioEndIoStatement(ptr %4)
  %.unpack101 = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  call void @free(ptr %.unpack101)
  store ptr null, ptr @_QFEarr, align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  store i32 20180515, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  store i8 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  store i8 28, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  store i8 2, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  store i8 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  store i64 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  store i64 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  ret void
}
*** IR Dump After InvalidateAnalysisPass<llvm::ShouldNotRunFunctionPassesAnalysis> on _QQmain..omp_par ***
; Function Attrs: norecurse nounwind
define internal void @_QQmain..omp_par(ptr noalias nocapture readnone %tid.addr, ptr noalias nocapture readnone %zero.addr, ptr nocapture readonly %0) #2 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %gep_3 = getelementptr { ptr, ptr, ptr }, ptr %0, i64 0, i32 2
  %loadgep_4 = load ptr, ptr %gep_3, align 8
  %p.lastiter = alloca i32, align 4
  %p.lowerbound = alloca i32, align 4
  %p.upperbound = alloca i32, align 4
  %p.stride = alloca i32, align 4
  %1 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %omp_loop.tripcount = tail call i32 @llvm.smax.i32(i32 %1, i32 0)
  store i32 0, ptr %p.lowerbound, align 4
  %2 = add nsw i32 %omp_loop.tripcount, -1
  store i32 %2, ptr %p.upperbound, align 4
  store i32 1, ptr %p.stride, align 4
  %omp_global_thread_num4 = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  call void @__kmpc_for_static_init_4u(ptr nonnull @1, i32 %omp_global_thread_num4, i32 34, ptr nonnull %p.lastiter, ptr nonnull %p.lowerbound, ptr nonnull %p.upperbound, ptr nonnull %p.stride, i32 1, i32 0)
  %3 = load i32, ptr %p.lowerbound, align 4
  %4 = load i32, ptr %p.upperbound, align 4
  %reass.sub = sub i32 %4, %3
  %omp_loop.cmp65.not = icmp eq i32 %reass.sub, -1
  br i1 %omp_loop.cmp65.not, label %omp_loop.exit, label %omp_loop.body.lr.ph

omp_loop.body.lr.ph:                              ; preds = %omp.par.entry
  %.unpack = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  %.unpack6 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  %.unpack7 = load i32, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  %.unpack8 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  %.unpack9 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  %.unpack10 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  %.unpack11 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  %.unpack12.unpack.unpack = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  %.unpack12.unpack.unpack14 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  %.unpack12.unpack.unpack15 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  %loadgep_2.repack17 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  %loadgep_2.repack19 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  %loadgep_2.repack21 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  %loadgep_2.repack23 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  %loadgep_2.repack25 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  %loadgep_2.repack27 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  %loadgep_2.repack29 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  %loadgep_2.repack29.repack31 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  %loadgep_2.repack29.repack33 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  %loadgep_4.repack47 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 1
  %loadgep_4.repack49 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 2
  %loadgep_4.repack51 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 3
  %loadgep_4.repack53 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 4
  %loadgep_4.repack55 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 5
  %loadgep_4.repack57 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 6
  %loadgep_4.repack59 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7
  %loadgep_4.repack59.repack61 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 1
  %loadgep_4.repack59.repack63 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 2
  br label %omp_loop.body

omp_loop.exit:                                    ; preds = %omp_loop.body, %omp.par.entry
  call void @__kmpc_for_static_fini(ptr nonnull @1, i32 %omp_global_thread_num4)
  call void @__kmpc_barrier(ptr nonnull @2, i32 %omp_global_thread_num4)
  ret void

omp_loop.body:                                    ; preds = %omp_loop.body.lr.ph, %omp_loop.body
  %omp_loop.iv66 = phi i32 [ 0, %omp_loop.body.lr.ph ], [ %5, %omp_loop.body ]
  %5 = add nuw i32 %omp_loop.iv66, 1
  %6 = add i32 %5, %3
  %7 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %8 = sitofp i32 %7 to float
  %9 = fdiv contract float 1.000000e+00, %8
  %10 = fpext float %9 to double
  store ptr %.unpack, ptr %loadgep_2, align 8, !tbaa !8
  store i64 %.unpack6, ptr %loadgep_2.repack17, align 8, !tbaa !8
  store i32 %.unpack7, ptr %loadgep_2.repack19, align 8, !tbaa !8
  store i8 %.unpack8, ptr %loadgep_2.repack21, align 4, !tbaa !8
  store i8 %.unpack9, ptr %loadgep_2.repack23, align 1, !tbaa !8
  store i8 %.unpack10, ptr %loadgep_2.repack25, align 2, !tbaa !8
  store i8 %.unpack11, ptr %loadgep_2.repack27, align 1, !tbaa !8
  store i64 %.unpack12.unpack.unpack, ptr %loadgep_2.repack29, align 8, !tbaa !8
  store i64 %.unpack12.unpack.unpack14, ptr %loadgep_2.repack29.repack31, align 8, !tbaa !8
  store i64 %.unpack12.unpack.unpack15, ptr %loadgep_2.repack29.repack33, align 8, !tbaa !8
  %11 = sext i32 %6 to i64
  %12 = sub i64 %11, %.unpack12.unpack.unpack
  %13 = getelementptr double, ptr %.unpack, i64 %12
  store double %10, ptr %13, align 8, !tbaa !4
  store ptr %.unpack, ptr %loadgep_4, align 8, !tbaa !8
  store i64 %.unpack6, ptr %loadgep_4.repack47, align 8, !tbaa !8
  store i32 %.unpack7, ptr %loadgep_4.repack49, align 8, !tbaa !8
  store i8 %.unpack8, ptr %loadgep_4.repack51, align 4, !tbaa !8
  store i8 %.unpack9, ptr %loadgep_4.repack53, align 1, !tbaa !8
  store i8 %.unpack10, ptr %loadgep_4.repack55, align 2, !tbaa !8
  store i8 %.unpack11, ptr %loadgep_4.repack57, align 1, !tbaa !8
  store i64 %.unpack12.unpack.unpack, ptr %loadgep_4.repack59, align 8, !tbaa !8
  store i64 %.unpack12.unpack.unpack14, ptr %loadgep_4.repack59.repack61, align 8, !tbaa !8
  store i64 %.unpack12.unpack.unpack15, ptr %loadgep_4.repack59.repack63, align 8, !tbaa !8
  %exitcond.not = icmp eq i32 %omp_loop.iv66, %reass.sub
  br i1 %exitcond.not, label %omp_loop.exit, label %omp_loop.body
}
*** IR Dump After DeadArgumentEliminationPass on [module] ***
; ModuleID = 'FIRModule'
source_filename = "FIRModule"
target datalayout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128"
target triple = "x86_64-unknown-linux-gnu"

%struct.ident_t = type { i32, i32, i32, i32, ptr }

@_QFEarr = internal unnamed_addr global { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } { ptr null, i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), i32 20180515, i8 1, i8 28, i8 2, i8 0, [1 x [3 x i64]] [[3 x i64] [i64 1, i64 0, i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64)]] }
@_QQcl.60ea5a38555821a77357f87d16df9a0f = internal constant [62 x i8] c"/g/g92/rydahl1/flangtests/src/duplicate_array_descriptors.f90\00"
@_QQcl.28612C69372C612C6531332E36653229 = internal constant [16 x i8] c"(a,i7,a,e13.6e2)"
@_QQcl.54686520726573756C74206F6620286172722831292B61727228 = internal constant [26 x i8] c"The result of (arr(1)+arr("
@_QQcl.2920697320 = internal constant [5 x i8] c") is "
@_QQEnvironmentDefaults = local_unnamed_addr constant ptr null
@0 = private unnamed_addr constant [23 x i8] c";unknown;unknown;0;0;;\00", align 1
@1 = private unnamed_addr constant %struct.ident_t { i32 0, i32 2, i32 0, i32 22, ptr @0 }, align 8
@2 = private unnamed_addr constant %struct.ident_t { i32 0, i32 66, i32 0, i32 22, ptr @0 }, align 8

; Function Attrs: mustprogress nofree nounwind willreturn allockind("alloc,uninitialized") allocsize(0) memory(inaccessiblemem: readwrite)
declare noalias noundef ptr @malloc(i64 noundef) local_unnamed_addr #0

; Function Attrs: mustprogress nounwind willreturn allockind("free") memory(argmem: readwrite, inaccessiblemem: readwrite)
declare void @free(ptr allocptr nocapture noundef) local_unnamed_addr #1

define void @_QQmain() local_unnamed_addr {
entry:
  %structArg = alloca { ptr, ptr, ptr }, align 8
  %0 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %1 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %2 = alloca i32, align 4
  store i32 1048576, ptr %2, align 4, !tbaa !4
  %3 = tail call dereferenceable_or_null(8388608) ptr @malloc(i64 8388608)
  store ptr %3, ptr @_QFEarr, align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  store i32 20180515, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  store i8 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  store i8 28, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  store i8 2, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  store i8 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  store i64 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  store i64 1048576, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  %omp_global_thread_num = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %2, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %1, ptr %gep_5, align 8
  %gep_6 = getelementptr inbounds { ptr, ptr, ptr }, ptr %structArg, i64 0, i32 2
  store ptr %0, ptr %gep_6, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QQmain..omp_par, ptr nonnull %structArg)
  %4 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.60ea5a38555821a77357f87d16df9a0f, i32 21)
  %5 = call i1 @_FortranAioOutputAscii(ptr %4, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %6 = load i32, ptr %2, align 4, !tbaa !4
  %7 = call i1 @_FortranAioOutputInteger32(ptr %4, i32 %6)
  %8 = call i1 @_FortranAioOutputAscii(ptr %4, ptr nonnull @_QQcl.2920697320, i64 5)
  %.unpack = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  %.unpack96.unpack.unpack = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  %9 = sub i64 1, %.unpack96.unpack.unpack
  %10 = getelementptr double, ptr %.unpack, i64 %9
  %11 = load double, ptr %10, align 8, !tbaa !4
  %12 = load i32, ptr %2, align 4, !tbaa !4
  %13 = sext i32 %12 to i64
  %14 = sub i64 %13, %.unpack96.unpack.unpack
  %15 = getelementptr double, ptr %.unpack, i64 %14
  %16 = load double, ptr %15, align 8, !tbaa !4
  %17 = fadd contract double %11, %16
  %18 = call i1 @_FortranAioOutputReal64(ptr %4, double %17)
  %19 = call i32 @_FortranAioEndIoStatement(ptr %4)
  %.unpack101 = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  call void @free(ptr %.unpack101)
  store ptr null, ptr @_QFEarr, align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  store i32 20180515, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  store i8 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  store i8 28, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  store i8 2, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  store i8 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  store i64 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  store i64 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  ret void
}

; Function Attrs: norecurse nounwind
define internal void @_QQmain..omp_par(ptr noalias nocapture readnone %tid.addr, ptr noalias nocapture readnone %zero.addr, ptr nocapture readonly %0) #2 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %gep_3 = getelementptr { ptr, ptr, ptr }, ptr %0, i64 0, i32 2
  %loadgep_4 = load ptr, ptr %gep_3, align 8
  %p.lastiter = alloca i32, align 4
  %p.lowerbound = alloca i32, align 4
  %p.upperbound = alloca i32, align 4
  %p.stride = alloca i32, align 4
  %1 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %omp_loop.tripcount = tail call i32 @llvm.smax.i32(i32 %1, i32 0)
  store i32 0, ptr %p.lowerbound, align 4
  %2 = add nsw i32 %omp_loop.tripcount, -1
  store i32 %2, ptr %p.upperbound, align 4
  store i32 1, ptr %p.stride, align 4
  %omp_global_thread_num4 = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  call void @__kmpc_for_static_init_4u(ptr nonnull @1, i32 %omp_global_thread_num4, i32 34, ptr nonnull %p.lastiter, ptr nonnull %p.lowerbound, ptr nonnull %p.upperbound, ptr nonnull %p.stride, i32 1, i32 0)
  %3 = load i32, ptr %p.lowerbound, align 4
  %4 = load i32, ptr %p.upperbound, align 4
  %reass.sub = sub i32 %4, %3
  %omp_loop.cmp65.not = icmp eq i32 %reass.sub, -1
  br i1 %omp_loop.cmp65.not, label %omp_loop.exit, label %omp_loop.body.lr.ph

omp_loop.body.lr.ph:                              ; preds = %omp.par.entry
  %.unpack = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  %.unpack6 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  %.unpack7 = load i32, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  %.unpack8 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  %.unpack9 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  %.unpack10 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  %.unpack11 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  %.unpack12.unpack.unpack = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  %.unpack12.unpack.unpack14 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  %.unpack12.unpack.unpack15 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  %loadgep_2.repack17 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  %loadgep_2.repack19 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  %loadgep_2.repack21 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  %loadgep_2.repack23 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  %loadgep_2.repack25 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  %loadgep_2.repack27 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  %loadgep_2.repack29 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  %loadgep_2.repack29.repack31 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  %loadgep_2.repack29.repack33 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  %loadgep_4.repack47 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 1
  %loadgep_4.repack49 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 2
  %loadgep_4.repack51 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 3
  %loadgep_4.repack53 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 4
  %loadgep_4.repack55 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 5
  %loadgep_4.repack57 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 6
  %loadgep_4.repack59 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7
  %loadgep_4.repack59.repack61 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 1
  %loadgep_4.repack59.repack63 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 2
  br label %omp_loop.body

omp_loop.exit:                                    ; preds = %omp_loop.body, %omp.par.entry
  call void @__kmpc_for_static_fini(ptr nonnull @1, i32 %omp_global_thread_num4)
  call void @__kmpc_barrier(ptr nonnull @2, i32 %omp_global_thread_num4)
  ret void

omp_loop.body:                                    ; preds = %omp_loop.body.lr.ph, %omp_loop.body
  %omp_loop.iv66 = phi i32 [ 0, %omp_loop.body.lr.ph ], [ %5, %omp_loop.body ]
  %5 = add nuw i32 %omp_loop.iv66, 1
  %6 = add i32 %5, %3
  %7 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %8 = sitofp i32 %7 to float
  %9 = fdiv contract float 1.000000e+00, %8
  %10 = fpext float %9 to double
  store ptr %.unpack, ptr %loadgep_2, align 8, !tbaa !8
  store i64 %.unpack6, ptr %loadgep_2.repack17, align 8, !tbaa !8
  store i32 %.unpack7, ptr %loadgep_2.repack19, align 8, !tbaa !8
  store i8 %.unpack8, ptr %loadgep_2.repack21, align 4, !tbaa !8
  store i8 %.unpack9, ptr %loadgep_2.repack23, align 1, !tbaa !8
  store i8 %.unpack10, ptr %loadgep_2.repack25, align 2, !tbaa !8
  store i8 %.unpack11, ptr %loadgep_2.repack27, align 1, !tbaa !8
  store i64 %.unpack12.unpack.unpack, ptr %loadgep_2.repack29, align 8, !tbaa !8
  store i64 %.unpack12.unpack.unpack14, ptr %loadgep_2.repack29.repack31, align 8, !tbaa !8
  store i64 %.unpack12.unpack.unpack15, ptr %loadgep_2.repack29.repack33, align 8, !tbaa !8
  %11 = sext i32 %6 to i64
  %12 = sub i64 %11, %.unpack12.unpack.unpack
  %13 = getelementptr double, ptr %.unpack, i64 %12
  store double %10, ptr %13, align 8, !tbaa !4
  store ptr %.unpack, ptr %loadgep_4, align 8, !tbaa !8
  store i64 %.unpack6, ptr %loadgep_4.repack47, align 8, !tbaa !8
  store i32 %.unpack7, ptr %loadgep_4.repack49, align 8, !tbaa !8
  store i8 %.unpack8, ptr %loadgep_4.repack51, align 4, !tbaa !8
  store i8 %.unpack9, ptr %loadgep_4.repack53, align 1, !tbaa !8
  store i8 %.unpack10, ptr %loadgep_4.repack55, align 2, !tbaa !8
  store i8 %.unpack11, ptr %loadgep_4.repack57, align 1, !tbaa !8
  store i64 %.unpack12.unpack.unpack, ptr %loadgep_4.repack59, align 8, !tbaa !8
  store i64 %.unpack12.unpack.unpack14, ptr %loadgep_4.repack59.repack61, align 8, !tbaa !8
  store i64 %.unpack12.unpack.unpack15, ptr %loadgep_4.repack59.repack63, align 8, !tbaa !8
  %exitcond.not = icmp eq i32 %omp_loop.iv66, %reass.sub
  br i1 %exitcond.not, label %omp_loop.exit, label %omp_loop.body
}

declare ptr @_FortranAioBeginExternalFormattedOutput(ptr, i64, ptr, i32, ptr, i32) local_unnamed_addr

declare zeroext i1 @_FortranAioOutputAscii(ptr, ptr, i64) local_unnamed_addr

declare zeroext i1 @_FortranAioOutputInteger32(ptr, i32) local_unnamed_addr

declare zeroext i1 @_FortranAioOutputReal64(ptr, double) local_unnamed_addr

declare i32 @_FortranAioEndIoStatement(ptr) local_unnamed_addr

; Function Attrs: nounwind
declare i32 @__kmpc_global_thread_num(ptr) local_unnamed_addr #3

; Function Attrs: nounwind
declare void @__kmpc_for_static_init_4u(ptr, i32, i32, ptr, ptr, ptr, ptr, i32, i32) local_unnamed_addr #3

; Function Attrs: nounwind
declare void @__kmpc_for_static_fini(ptr, i32) local_unnamed_addr #3

; Function Attrs: convergent nounwind
declare void @__kmpc_barrier(ptr, i32) local_unnamed_addr #4

; Function Attrs: nounwind
declare !callback !10 void @__kmpc_fork_call(ptr, i32, ptr, ...) local_unnamed_addr #3

; Function Attrs: nocallback nofree nosync nounwind speculatable willreturn memory(none)
declare i32 @llvm.smax.i32(i32, i32) #5

attributes #0 = { mustprogress nofree nounwind willreturn allockind("alloc,uninitialized") allocsize(0) memory(inaccessiblemem: readwrite) "alloc-family"="malloc" }
attributes #1 = { mustprogress nounwind willreturn allockind("free") memory(argmem: readwrite, inaccessiblemem: readwrite) "alloc-family"="malloc" }
attributes #2 = { norecurse nounwind }
attributes #3 = { nounwind }
attributes #4 = { convergent nounwind }
attributes #5 = { nocallback nofree nosync nounwind speculatable willreturn memory(none) }

!llvm.module.flags = !{!0, !1, !2, !3}

!0 = !{i32 2, !"Debug Info Version", i32 3}
!1 = !{i32 7, !"openmp", i32 11}
!2 = !{i32 8, !"PIC Level", i32 2}
!3 = !{i32 7, !"PIE Level", i32 2}
!4 = !{!5, !5, i64 0}
!5 = !{!"any data access", !6, i64 0}
!6 = !{!"any access", !7, i64 0}
!7 = !{!"Flang Type TBAA Root"}
!8 = !{!9, !9, i64 0}
!9 = !{!"descriptor member", !6, i64 0}
!10 = !{!11}
!11 = !{i64 2, i64 -1, i64 -1, i1 true}
*** IR Dump After CoroCleanupPass on [module] ***
; ModuleID = 'FIRModule'
source_filename = "FIRModule"
target datalayout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128"
target triple = "x86_64-unknown-linux-gnu"

%struct.ident_t = type { i32, i32, i32, i32, ptr }

@_QFEarr = internal unnamed_addr global { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } { ptr null, i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), i32 20180515, i8 1, i8 28, i8 2, i8 0, [1 x [3 x i64]] [[3 x i64] [i64 1, i64 0, i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64)]] }
@_QQcl.60ea5a38555821a77357f87d16df9a0f = internal constant [62 x i8] c"/g/g92/rydahl1/flangtests/src/duplicate_array_descriptors.f90\00"
@_QQcl.28612C69372C612C6531332E36653229 = internal constant [16 x i8] c"(a,i7,a,e13.6e2)"
@_QQcl.54686520726573756C74206F6620286172722831292B61727228 = internal constant [26 x i8] c"The result of (arr(1)+arr("
@_QQcl.2920697320 = internal constant [5 x i8] c") is "
@_QQEnvironmentDefaults = local_unnamed_addr constant ptr null
@0 = private unnamed_addr constant [23 x i8] c";unknown;unknown;0;0;;\00", align 1
@1 = private unnamed_addr constant %struct.ident_t { i32 0, i32 2, i32 0, i32 22, ptr @0 }, align 8
@2 = private unnamed_addr constant %struct.ident_t { i32 0, i32 66, i32 0, i32 22, ptr @0 }, align 8

; Function Attrs: mustprogress nofree nounwind willreturn allockind("alloc,uninitialized") allocsize(0) memory(inaccessiblemem: readwrite)
declare noalias noundef ptr @malloc(i64 noundef) local_unnamed_addr #0

; Function Attrs: mustprogress nounwind willreturn allockind("free") memory(argmem: readwrite, inaccessiblemem: readwrite)
declare void @free(ptr allocptr nocapture noundef) local_unnamed_addr #1

define void @_QQmain() local_unnamed_addr {
entry:
  %structArg = alloca { ptr, ptr, ptr }, align 8
  %0 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %1 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %2 = alloca i32, align 4
  store i32 1048576, ptr %2, align 4, !tbaa !4
  %3 = tail call dereferenceable_or_null(8388608) ptr @malloc(i64 8388608)
  store ptr %3, ptr @_QFEarr, align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  store i32 20180515, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  store i8 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  store i8 28, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  store i8 2, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  store i8 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  store i64 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  store i64 1048576, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  %omp_global_thread_num = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %2, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %1, ptr %gep_5, align 8
  %gep_6 = getelementptr inbounds { ptr, ptr, ptr }, ptr %structArg, i64 0, i32 2
  store ptr %0, ptr %gep_6, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QQmain..omp_par, ptr nonnull %structArg)
  %4 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.60ea5a38555821a77357f87d16df9a0f, i32 21)
  %5 = call i1 @_FortranAioOutputAscii(ptr %4, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %6 = load i32, ptr %2, align 4, !tbaa !4
  %7 = call i1 @_FortranAioOutputInteger32(ptr %4, i32 %6)
  %8 = call i1 @_FortranAioOutputAscii(ptr %4, ptr nonnull @_QQcl.2920697320, i64 5)
  %.unpack = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  %.unpack96.unpack.unpack = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  %9 = sub i64 1, %.unpack96.unpack.unpack
  %10 = getelementptr double, ptr %.unpack, i64 %9
  %11 = load double, ptr %10, align 8, !tbaa !4
  %12 = load i32, ptr %2, align 4, !tbaa !4
  %13 = sext i32 %12 to i64
  %14 = sub i64 %13, %.unpack96.unpack.unpack
  %15 = getelementptr double, ptr %.unpack, i64 %14
  %16 = load double, ptr %15, align 8, !tbaa !4
  %17 = fadd contract double %11, %16
  %18 = call i1 @_FortranAioOutputReal64(ptr %4, double %17)
  %19 = call i32 @_FortranAioEndIoStatement(ptr %4)
  %.unpack101 = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  call void @free(ptr %.unpack101)
  store ptr null, ptr @_QFEarr, align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  store i32 20180515, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  store i8 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  store i8 28, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  store i8 2, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  store i8 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  store i64 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  store i64 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  ret void
}

; Function Attrs: norecurse nounwind
define internal void @_QQmain..omp_par(ptr noalias nocapture readnone %tid.addr, ptr noalias nocapture readnone %zero.addr, ptr nocapture readonly %0) #2 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %gep_3 = getelementptr { ptr, ptr, ptr }, ptr %0, i64 0, i32 2
  %loadgep_4 = load ptr, ptr %gep_3, align 8
  %p.lastiter = alloca i32, align 4
  %p.lowerbound = alloca i32, align 4
  %p.upperbound = alloca i32, align 4
  %p.stride = alloca i32, align 4
  %1 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %omp_loop.tripcount = tail call i32 @llvm.smax.i32(i32 %1, i32 0)
  store i32 0, ptr %p.lowerbound, align 4
  %2 = add nsw i32 %omp_loop.tripcount, -1
  store i32 %2, ptr %p.upperbound, align 4
  store i32 1, ptr %p.stride, align 4
  %omp_global_thread_num4 = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  call void @__kmpc_for_static_init_4u(ptr nonnull @1, i32 %omp_global_thread_num4, i32 34, ptr nonnull %p.lastiter, ptr nonnull %p.lowerbound, ptr nonnull %p.upperbound, ptr nonnull %p.stride, i32 1, i32 0)
  %3 = load i32, ptr %p.lowerbound, align 4
  %4 = load i32, ptr %p.upperbound, align 4
  %reass.sub = sub i32 %4, %3
  %omp_loop.cmp65.not = icmp eq i32 %reass.sub, -1
  br i1 %omp_loop.cmp65.not, label %omp_loop.exit, label %omp_loop.body.lr.ph

omp_loop.body.lr.ph:                              ; preds = %omp.par.entry
  %.unpack = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  %.unpack6 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  %.unpack7 = load i32, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  %.unpack8 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  %.unpack9 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  %.unpack10 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  %.unpack11 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  %.unpack12.unpack.unpack = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  %.unpack12.unpack.unpack14 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  %.unpack12.unpack.unpack15 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  %loadgep_2.repack17 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  %loadgep_2.repack19 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  %loadgep_2.repack21 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  %loadgep_2.repack23 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  %loadgep_2.repack25 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  %loadgep_2.repack27 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  %loadgep_2.repack29 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  %loadgep_2.repack29.repack31 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  %loadgep_2.repack29.repack33 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  %loadgep_4.repack47 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 1
  %loadgep_4.repack49 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 2
  %loadgep_4.repack51 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 3
  %loadgep_4.repack53 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 4
  %loadgep_4.repack55 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 5
  %loadgep_4.repack57 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 6
  %loadgep_4.repack59 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7
  %loadgep_4.repack59.repack61 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 1
  %loadgep_4.repack59.repack63 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 2
  br label %omp_loop.body

omp_loop.exit:                                    ; preds = %omp_loop.body, %omp.par.entry
  call void @__kmpc_for_static_fini(ptr nonnull @1, i32 %omp_global_thread_num4)
  call void @__kmpc_barrier(ptr nonnull @2, i32 %omp_global_thread_num4)
  ret void

omp_loop.body:                                    ; preds = %omp_loop.body.lr.ph, %omp_loop.body
  %omp_loop.iv66 = phi i32 [ 0, %omp_loop.body.lr.ph ], [ %5, %omp_loop.body ]
  %5 = add nuw i32 %omp_loop.iv66, 1
  %6 = add i32 %5, %3
  %7 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %8 = sitofp i32 %7 to float
  %9 = fdiv contract float 1.000000e+00, %8
  %10 = fpext float %9 to double
  store ptr %.unpack, ptr %loadgep_2, align 8, !tbaa !8
  store i64 %.unpack6, ptr %loadgep_2.repack17, align 8, !tbaa !8
  store i32 %.unpack7, ptr %loadgep_2.repack19, align 8, !tbaa !8
  store i8 %.unpack8, ptr %loadgep_2.repack21, align 4, !tbaa !8
  store i8 %.unpack9, ptr %loadgep_2.repack23, align 1, !tbaa !8
  store i8 %.unpack10, ptr %loadgep_2.repack25, align 2, !tbaa !8
  store i8 %.unpack11, ptr %loadgep_2.repack27, align 1, !tbaa !8
  store i64 %.unpack12.unpack.unpack, ptr %loadgep_2.repack29, align 8, !tbaa !8
  store i64 %.unpack12.unpack.unpack14, ptr %loadgep_2.repack29.repack31, align 8, !tbaa !8
  store i64 %.unpack12.unpack.unpack15, ptr %loadgep_2.repack29.repack33, align 8, !tbaa !8
  %11 = sext i32 %6 to i64
  %12 = sub i64 %11, %.unpack12.unpack.unpack
  %13 = getelementptr double, ptr %.unpack, i64 %12
  store double %10, ptr %13, align 8, !tbaa !4
  store ptr %.unpack, ptr %loadgep_4, align 8, !tbaa !8
  store i64 %.unpack6, ptr %loadgep_4.repack47, align 8, !tbaa !8
  store i32 %.unpack7, ptr %loadgep_4.repack49, align 8, !tbaa !8
  store i8 %.unpack8, ptr %loadgep_4.repack51, align 4, !tbaa !8
  store i8 %.unpack9, ptr %loadgep_4.repack53, align 1, !tbaa !8
  store i8 %.unpack10, ptr %loadgep_4.repack55, align 2, !tbaa !8
  store i8 %.unpack11, ptr %loadgep_4.repack57, align 1, !tbaa !8
  store i64 %.unpack12.unpack.unpack, ptr %loadgep_4.repack59, align 8, !tbaa !8
  store i64 %.unpack12.unpack.unpack14, ptr %loadgep_4.repack59.repack61, align 8, !tbaa !8
  store i64 %.unpack12.unpack.unpack15, ptr %loadgep_4.repack59.repack63, align 8, !tbaa !8
  %exitcond.not = icmp eq i32 %omp_loop.iv66, %reass.sub
  br i1 %exitcond.not, label %omp_loop.exit, label %omp_loop.body
}

declare ptr @_FortranAioBeginExternalFormattedOutput(ptr, i64, ptr, i32, ptr, i32) local_unnamed_addr

declare zeroext i1 @_FortranAioOutputAscii(ptr, ptr, i64) local_unnamed_addr

declare zeroext i1 @_FortranAioOutputInteger32(ptr, i32) local_unnamed_addr

declare zeroext i1 @_FortranAioOutputReal64(ptr, double) local_unnamed_addr

declare i32 @_FortranAioEndIoStatement(ptr) local_unnamed_addr

; Function Attrs: nounwind
declare i32 @__kmpc_global_thread_num(ptr) local_unnamed_addr #3

; Function Attrs: nounwind
declare void @__kmpc_for_static_init_4u(ptr, i32, i32, ptr, ptr, ptr, ptr, i32, i32) local_unnamed_addr #3

; Function Attrs: nounwind
declare void @__kmpc_for_static_fini(ptr, i32) local_unnamed_addr #3

; Function Attrs: convergent nounwind
declare void @__kmpc_barrier(ptr, i32) local_unnamed_addr #4

; Function Attrs: nounwind
declare !callback !10 void @__kmpc_fork_call(ptr, i32, ptr, ...) local_unnamed_addr #3

; Function Attrs: nocallback nofree nosync nounwind speculatable willreturn memory(none)
declare i32 @llvm.smax.i32(i32, i32) #5

attributes #0 = { mustprogress nofree nounwind willreturn allockind("alloc,uninitialized") allocsize(0) memory(inaccessiblemem: readwrite) "alloc-family"="malloc" }
attributes #1 = { mustprogress nounwind willreturn allockind("free") memory(argmem: readwrite, inaccessiblemem: readwrite) "alloc-family"="malloc" }
attributes #2 = { norecurse nounwind }
attributes #3 = { nounwind }
attributes #4 = { convergent nounwind }
attributes #5 = { nocallback nofree nosync nounwind speculatable willreturn memory(none) }

!llvm.module.flags = !{!0, !1, !2, !3}

!0 = !{i32 2, !"Debug Info Version", i32 3}
!1 = !{i32 7, !"openmp", i32 11}
!2 = !{i32 8, !"PIC Level", i32 2}
!3 = !{i32 7, !"PIE Level", i32 2}
!4 = !{!5, !5, i64 0}
!5 = !{!"any data access", !6, i64 0}
!6 = !{!"any access", !7, i64 0}
!7 = !{!"Flang Type TBAA Root"}
!8 = !{!9, !9, i64 0}
!9 = !{!"descriptor member", !6, i64 0}
!10 = !{!11}
!11 = !{i64 2, i64 -1, i64 -1, i1 true}
*** IR Dump After GlobalOptPass on [module] ***
; ModuleID = 'FIRModule'
source_filename = "FIRModule"
target datalayout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128"
target triple = "x86_64-unknown-linux-gnu"

%struct.ident_t = type { i32, i32, i32, i32, ptr }

@_QFEarr.0 = internal unnamed_addr global ptr null
@_QFEarr.8 = internal unnamed_addr global i1 false
@_QQcl.60ea5a38555821a77357f87d16df9a0f = internal constant [62 x i8] c"/g/g92/rydahl1/flangtests/src/duplicate_array_descriptors.f90\00"
@_QQcl.28612C69372C612C6531332E36653229 = internal constant [16 x i8] c"(a,i7,a,e13.6e2)"
@_QQcl.54686520726573756C74206F6620286172722831292B61727228 = internal constant [26 x i8] c"The result of (arr(1)+arr("
@_QQcl.2920697320 = internal constant [5 x i8] c") is "
@_QQEnvironmentDefaults = local_unnamed_addr constant ptr null
@0 = private unnamed_addr constant [23 x i8] c";unknown;unknown;0;0;;\00", align 1
@1 = private unnamed_addr constant %struct.ident_t { i32 0, i32 2, i32 0, i32 22, ptr @0 }, align 8
@2 = private unnamed_addr constant %struct.ident_t { i32 0, i32 66, i32 0, i32 22, ptr @0 }, align 8

; Function Attrs: mustprogress nofree nounwind willreturn allockind("alloc,uninitialized") allocsize(0) memory(inaccessiblemem: readwrite)
declare noalias noundef ptr @malloc(i64 noundef) local_unnamed_addr #0

; Function Attrs: mustprogress nounwind willreturn allockind("free") memory(argmem: readwrite, inaccessiblemem: readwrite)
declare void @free(ptr allocptr nocapture noundef) local_unnamed_addr #1

define void @_QQmain() local_unnamed_addr {
entry:
  %structArg = alloca { ptr, ptr, ptr }, align 8
  %0 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %1 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %2 = alloca i32, align 4
  store i32 1048576, ptr %2, align 4, !tbaa !4
  %3 = tail call dereferenceable_or_null(8388608) ptr @malloc(i64 8388608)
  store ptr %3, ptr @_QFEarr.0, align 8, !tbaa !8
  store i1 true, ptr @_QFEarr.8, align 1
  %omp_global_thread_num = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %2, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %1, ptr %gep_5, align 8
  %gep_6 = getelementptr inbounds { ptr, ptr, ptr }, ptr %structArg, i64 0, i32 2
  store ptr %0, ptr %gep_6, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QQmain..omp_par, ptr nonnull %structArg)
  %4 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.60ea5a38555821a77357f87d16df9a0f, i32 21)
  %5 = call i1 @_FortranAioOutputAscii(ptr %4, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %6 = load i32, ptr %2, align 4, !tbaa !4
  %7 = call i1 @_FortranAioOutputInteger32(ptr %4, i32 %6)
  %8 = call i1 @_FortranAioOutputAscii(ptr %4, ptr nonnull @_QQcl.2920697320, i64 5)
  %.unpack = load ptr, ptr @_QFEarr.0, align 8, !tbaa !8
  %9 = sub i64 1, 1
  %10 = getelementptr double, ptr %.unpack, i64 %9
  %11 = load double, ptr %10, align 8, !tbaa !4
  %12 = load i32, ptr %2, align 4, !tbaa !4
  %13 = sext i32 %12 to i64
  %14 = sub i64 %13, 1
  %15 = getelementptr double, ptr %.unpack, i64 %14
  %16 = load double, ptr %15, align 8, !tbaa !4
  %17 = fadd contract double %11, %16
  %18 = call i1 @_FortranAioOutputReal64(ptr %4, double %17)
  %19 = call i32 @_FortranAioEndIoStatement(ptr %4)
  %.unpack101 = load ptr, ptr @_QFEarr.0, align 8, !tbaa !8
  call void @free(ptr %.unpack101)
  store ptr null, ptr @_QFEarr.0, align 8, !tbaa !8
  store i1 false, ptr @_QFEarr.8, align 1
  ret void
}

; Function Attrs: norecurse nounwind
define internal void @_QQmain..omp_par(ptr noalias nocapture readnone %tid.addr, ptr noalias nocapture readnone %zero.addr, ptr nocapture readonly %0) #2 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %gep_3 = getelementptr { ptr, ptr, ptr }, ptr %0, i64 0, i32 2
  %loadgep_4 = load ptr, ptr %gep_3, align 8
  %p.lastiter = alloca i32, align 4
  %p.lowerbound = alloca i32, align 4
  %p.upperbound = alloca i32, align 4
  %p.stride = alloca i32, align 4
  %1 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %omp_loop.tripcount = tail call i32 @llvm.smax.i32(i32 %1, i32 0)
  store i32 0, ptr %p.lowerbound, align 4
  %2 = add nsw i32 %omp_loop.tripcount, -1
  store i32 %2, ptr %p.upperbound, align 4
  store i32 1, ptr %p.stride, align 4
  %omp_global_thread_num4 = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  call void @__kmpc_for_static_init_4u(ptr nonnull @1, i32 %omp_global_thread_num4, i32 34, ptr nonnull %p.lastiter, ptr nonnull %p.lowerbound, ptr nonnull %p.upperbound, ptr nonnull %p.stride, i32 1, i32 0)
  %3 = load i32, ptr %p.lowerbound, align 4
  %4 = load i32, ptr %p.upperbound, align 4
  %reass.sub = sub i32 %4, %3
  %omp_loop.cmp65.not = icmp eq i32 %reass.sub, -1
  br i1 %omp_loop.cmp65.not, label %omp_loop.exit, label %omp_loop.body.lr.ph

omp_loop.body.lr.ph:                              ; preds = %omp.par.entry
  %.unpack = load ptr, ptr @_QFEarr.0, align 8, !tbaa !8
  %.unpack12.unpack.unpack14.b = load i1, ptr @_QFEarr.8, align 1
  %.unpack12.unpack.unpack14 = select i1 %.unpack12.unpack.unpack14.b, i64 1048576, i64 0
  %loadgep_2.repack17 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  %loadgep_2.repack19 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  %loadgep_2.repack21 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  %loadgep_2.repack23 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  %loadgep_2.repack25 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  %loadgep_2.repack27 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  %loadgep_2.repack29 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  %loadgep_2.repack29.repack31 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  %loadgep_2.repack29.repack33 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  %loadgep_4.repack47 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 1
  %loadgep_4.repack49 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 2
  %loadgep_4.repack51 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 3
  %loadgep_4.repack53 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 4
  %loadgep_4.repack55 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 5
  %loadgep_4.repack57 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 6
  %loadgep_4.repack59 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7
  %loadgep_4.repack59.repack61 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 1
  %loadgep_4.repack59.repack63 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 2
  br label %omp_loop.body

omp_loop.exit:                                    ; preds = %omp_loop.body, %omp.par.entry
  call void @__kmpc_for_static_fini(ptr nonnull @1, i32 %omp_global_thread_num4)
  call void @__kmpc_barrier(ptr nonnull @2, i32 %omp_global_thread_num4)
  ret void

omp_loop.body:                                    ; preds = %omp_loop.body.lr.ph, %omp_loop.body
  %omp_loop.iv66 = phi i32 [ 0, %omp_loop.body.lr.ph ], [ %5, %omp_loop.body ]
  %5 = add nuw i32 %omp_loop.iv66, 1
  %6 = add i32 %5, %3
  %7 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %8 = sitofp i32 %7 to float
  %9 = fdiv contract float 1.000000e+00, %8
  %10 = fpext float %9 to double
  store ptr %.unpack, ptr %loadgep_2, align 8, !tbaa !8
  store i64 8, ptr %loadgep_2.repack17, align 8, !tbaa !8
  store i32 20180515, ptr %loadgep_2.repack19, align 8, !tbaa !8
  store i8 1, ptr %loadgep_2.repack21, align 4, !tbaa !8
  store i8 28, ptr %loadgep_2.repack23, align 1, !tbaa !8
  store i8 2, ptr %loadgep_2.repack25, align 2, !tbaa !8
  store i8 0, ptr %loadgep_2.repack27, align 1, !tbaa !8
  store i64 1, ptr %loadgep_2.repack29, align 8, !tbaa !8
  store i64 %.unpack12.unpack.unpack14, ptr %loadgep_2.repack29.repack31, align 8, !tbaa !8
  store i64 8, ptr %loadgep_2.repack29.repack33, align 8, !tbaa !8
  %11 = sext i32 %6 to i64
  %12 = sub i64 %11, 1
  %13 = getelementptr double, ptr %.unpack, i64 %12
  store double %10, ptr %13, align 8, !tbaa !4
  store ptr %.unpack, ptr %loadgep_4, align 8, !tbaa !8
  store i64 8, ptr %loadgep_4.repack47, align 8, !tbaa !8
  store i32 20180515, ptr %loadgep_4.repack49, align 8, !tbaa !8
  store i8 1, ptr %loadgep_4.repack51, align 4, !tbaa !8
  store i8 28, ptr %loadgep_4.repack53, align 1, !tbaa !8
  store i8 2, ptr %loadgep_4.repack55, align 2, !tbaa !8
  store i8 0, ptr %loadgep_4.repack57, align 1, !tbaa !8
  store i64 1, ptr %loadgep_4.repack59, align 8, !tbaa !8
  store i64 %.unpack12.unpack.unpack14, ptr %loadgep_4.repack59.repack61, align 8, !tbaa !8
  store i64 8, ptr %loadgep_4.repack59.repack63, align 8, !tbaa !8
  %exitcond.not = icmp eq i32 %omp_loop.iv66, %reass.sub
  br i1 %exitcond.not, label %omp_loop.exit, label %omp_loop.body
}

declare ptr @_FortranAioBeginExternalFormattedOutput(ptr, i64, ptr, i32, ptr, i32) local_unnamed_addr

declare zeroext i1 @_FortranAioOutputAscii(ptr, ptr, i64) local_unnamed_addr

declare zeroext i1 @_FortranAioOutputInteger32(ptr, i32) local_unnamed_addr

declare zeroext i1 @_FortranAioOutputReal64(ptr, double) local_unnamed_addr

declare i32 @_FortranAioEndIoStatement(ptr) local_unnamed_addr

; Function Attrs: nounwind
declare i32 @__kmpc_global_thread_num(ptr) local_unnamed_addr #3

; Function Attrs: nounwind
declare void @__kmpc_for_static_init_4u(ptr, i32, i32, ptr, ptr, ptr, ptr, i32, i32) local_unnamed_addr #3

; Function Attrs: nounwind
declare void @__kmpc_for_static_fini(ptr, i32) local_unnamed_addr #3

; Function Attrs: convergent nounwind
declare void @__kmpc_barrier(ptr, i32) local_unnamed_addr #4

; Function Attrs: nounwind
declare !callback !10 void @__kmpc_fork_call(ptr, i32, ptr, ...) local_unnamed_addr #3

; Function Attrs: nocallback nofree nosync nounwind speculatable willreturn memory(none)
declare i32 @llvm.smax.i32(i32, i32) #5

attributes #0 = { mustprogress nofree nounwind willreturn allockind("alloc,uninitialized") allocsize(0) memory(inaccessiblemem: readwrite) "alloc-family"="malloc" }
attributes #1 = { mustprogress nounwind willreturn allockind("free") memory(argmem: readwrite, inaccessiblemem: readwrite) "alloc-family"="malloc" }
attributes #2 = { norecurse nounwind }
attributes #3 = { nounwind }
attributes #4 = { convergent nounwind }
attributes #5 = { nocallback nofree nosync nounwind speculatable willreturn memory(none) }

!llvm.module.flags = !{!0, !1, !2, !3}

!0 = !{i32 2, !"Debug Info Version", i32 3}
!1 = !{i32 7, !"openmp", i32 11}
!2 = !{i32 8, !"PIC Level", i32 2}
!3 = !{i32 7, !"PIE Level", i32 2}
!4 = !{!5, !5, i64 0}
!5 = !{!"any data access", !6, i64 0}
!6 = !{!"any access", !7, i64 0}
!7 = !{!"Flang Type TBAA Root"}
!8 = !{!9, !9, i64 0}
!9 = !{!"descriptor member", !6, i64 0}
!10 = !{!11}
!11 = !{i64 2, i64 -1, i64 -1, i1 true}
*** IR Dump After GlobalDCEPass on [module] ***
; ModuleID = 'FIRModule'
source_filename = "FIRModule"
target datalayout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128"
target triple = "x86_64-unknown-linux-gnu"

%struct.ident_t = type { i32, i32, i32, i32, ptr }

@_QFEarr.0 = internal unnamed_addr global ptr null
@_QFEarr.8 = internal unnamed_addr global i1 false
@_QQcl.60ea5a38555821a77357f87d16df9a0f = internal constant [62 x i8] c"/g/g92/rydahl1/flangtests/src/duplicate_array_descriptors.f90\00"
@_QQcl.28612C69372C612C6531332E36653229 = internal constant [16 x i8] c"(a,i7,a,e13.6e2)"
@_QQcl.54686520726573756C74206F6620286172722831292B61727228 = internal constant [26 x i8] c"The result of (arr(1)+arr("
@_QQcl.2920697320 = internal constant [5 x i8] c") is "
@_QQEnvironmentDefaults = local_unnamed_addr constant ptr null
@0 = private unnamed_addr constant [23 x i8] c";unknown;unknown;0;0;;\00", align 1
@1 = private unnamed_addr constant %struct.ident_t { i32 0, i32 2, i32 0, i32 22, ptr @0 }, align 8
@2 = private unnamed_addr constant %struct.ident_t { i32 0, i32 66, i32 0, i32 22, ptr @0 }, align 8

; Function Attrs: mustprogress nofree nounwind willreturn allockind("alloc,uninitialized") allocsize(0) memory(inaccessiblemem: readwrite)
declare noalias noundef ptr @malloc(i64 noundef) local_unnamed_addr #0

; Function Attrs: mustprogress nounwind willreturn allockind("free") memory(argmem: readwrite, inaccessiblemem: readwrite)
declare void @free(ptr allocptr nocapture noundef) local_unnamed_addr #1

define void @_QQmain() local_unnamed_addr {
entry:
  %structArg = alloca { ptr, ptr, ptr }, align 8
  %0 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %1 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %2 = alloca i32, align 4
  store i32 1048576, ptr %2, align 4, !tbaa !4
  %3 = tail call dereferenceable_or_null(8388608) ptr @malloc(i64 8388608)
  store ptr %3, ptr @_QFEarr.0, align 8, !tbaa !8
  store i1 true, ptr @_QFEarr.8, align 1
  %omp_global_thread_num = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %2, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %1, ptr %gep_5, align 8
  %gep_6 = getelementptr inbounds { ptr, ptr, ptr }, ptr %structArg, i64 0, i32 2
  store ptr %0, ptr %gep_6, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QQmain..omp_par, ptr nonnull %structArg)
  %4 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.60ea5a38555821a77357f87d16df9a0f, i32 21)
  %5 = call i1 @_FortranAioOutputAscii(ptr %4, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %6 = load i32, ptr %2, align 4, !tbaa !4
  %7 = call i1 @_FortranAioOutputInteger32(ptr %4, i32 %6)
  %8 = call i1 @_FortranAioOutputAscii(ptr %4, ptr nonnull @_QQcl.2920697320, i64 5)
  %.unpack = load ptr, ptr @_QFEarr.0, align 8, !tbaa !8
  %9 = sub i64 1, 1
  %10 = getelementptr double, ptr %.unpack, i64 %9
  %11 = load double, ptr %10, align 8, !tbaa !4
  %12 = load i32, ptr %2, align 4, !tbaa !4
  %13 = sext i32 %12 to i64
  %14 = sub i64 %13, 1
  %15 = getelementptr double, ptr %.unpack, i64 %14
  %16 = load double, ptr %15, align 8, !tbaa !4
  %17 = fadd contract double %11, %16
  %18 = call i1 @_FortranAioOutputReal64(ptr %4, double %17)
  %19 = call i32 @_FortranAioEndIoStatement(ptr %4)
  %.unpack101 = load ptr, ptr @_QFEarr.0, align 8, !tbaa !8
  call void @free(ptr %.unpack101)
  store ptr null, ptr @_QFEarr.0, align 8, !tbaa !8
  store i1 false, ptr @_QFEarr.8, align 1
  ret void
}

; Function Attrs: norecurse nounwind
define internal void @_QQmain..omp_par(ptr noalias nocapture readnone %tid.addr, ptr noalias nocapture readnone %zero.addr, ptr nocapture readonly %0) #2 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %gep_3 = getelementptr { ptr, ptr, ptr }, ptr %0, i64 0, i32 2
  %loadgep_4 = load ptr, ptr %gep_3, align 8
  %p.lastiter = alloca i32, align 4
  %p.lowerbound = alloca i32, align 4
  %p.upperbound = alloca i32, align 4
  %p.stride = alloca i32, align 4
  %1 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %omp_loop.tripcount = tail call i32 @llvm.smax.i32(i32 %1, i32 0)
  store i32 0, ptr %p.lowerbound, align 4
  %2 = add nsw i32 %omp_loop.tripcount, -1
  store i32 %2, ptr %p.upperbound, align 4
  store i32 1, ptr %p.stride, align 4
  %omp_global_thread_num4 = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  call void @__kmpc_for_static_init_4u(ptr nonnull @1, i32 %omp_global_thread_num4, i32 34, ptr nonnull %p.lastiter, ptr nonnull %p.lowerbound, ptr nonnull %p.upperbound, ptr nonnull %p.stride, i32 1, i32 0)
  %3 = load i32, ptr %p.lowerbound, align 4
  %4 = load i32, ptr %p.upperbound, align 4
  %reass.sub = sub i32 %4, %3
  %omp_loop.cmp65.not = icmp eq i32 %reass.sub, -1
  br i1 %omp_loop.cmp65.not, label %omp_loop.exit, label %omp_loop.body.lr.ph

omp_loop.body.lr.ph:                              ; preds = %omp.par.entry
  %.unpack = load ptr, ptr @_QFEarr.0, align 8, !tbaa !8
  %.unpack12.unpack.unpack14.b = load i1, ptr @_QFEarr.8, align 1
  %.unpack12.unpack.unpack14 = select i1 %.unpack12.unpack.unpack14.b, i64 1048576, i64 0
  %loadgep_2.repack17 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  %loadgep_2.repack19 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  %loadgep_2.repack21 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  %loadgep_2.repack23 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  %loadgep_2.repack25 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  %loadgep_2.repack27 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  %loadgep_2.repack29 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  %loadgep_2.repack29.repack31 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  %loadgep_2.repack29.repack33 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  %loadgep_4.repack47 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 1
  %loadgep_4.repack49 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 2
  %loadgep_4.repack51 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 3
  %loadgep_4.repack53 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 4
  %loadgep_4.repack55 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 5
  %loadgep_4.repack57 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 6
  %loadgep_4.repack59 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7
  %loadgep_4.repack59.repack61 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 1
  %loadgep_4.repack59.repack63 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 2
  br label %omp_loop.body

omp_loop.exit:                                    ; preds = %omp_loop.body, %omp.par.entry
  call void @__kmpc_for_static_fini(ptr nonnull @1, i32 %omp_global_thread_num4)
  call void @__kmpc_barrier(ptr nonnull @2, i32 %omp_global_thread_num4)
  ret void

omp_loop.body:                                    ; preds = %omp_loop.body.lr.ph, %omp_loop.body
  %omp_loop.iv66 = phi i32 [ 0, %omp_loop.body.lr.ph ], [ %5, %omp_loop.body ]
  %5 = add nuw i32 %omp_loop.iv66, 1
  %6 = add i32 %5, %3
  %7 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %8 = sitofp i32 %7 to float
  %9 = fdiv contract float 1.000000e+00, %8
  %10 = fpext float %9 to double
  store ptr %.unpack, ptr %loadgep_2, align 8, !tbaa !8
  store i64 8, ptr %loadgep_2.repack17, align 8, !tbaa !8
  store i32 20180515, ptr %loadgep_2.repack19, align 8, !tbaa !8
  store i8 1, ptr %loadgep_2.repack21, align 4, !tbaa !8
  store i8 28, ptr %loadgep_2.repack23, align 1, !tbaa !8
  store i8 2, ptr %loadgep_2.repack25, align 2, !tbaa !8
  store i8 0, ptr %loadgep_2.repack27, align 1, !tbaa !8
  store i64 1, ptr %loadgep_2.repack29, align 8, !tbaa !8
  store i64 %.unpack12.unpack.unpack14, ptr %loadgep_2.repack29.repack31, align 8, !tbaa !8
  store i64 8, ptr %loadgep_2.repack29.repack33, align 8, !tbaa !8
  %11 = sext i32 %6 to i64
  %12 = sub i64 %11, 1
  %13 = getelementptr double, ptr %.unpack, i64 %12
  store double %10, ptr %13, align 8, !tbaa !4
  store ptr %.unpack, ptr %loadgep_4, align 8, !tbaa !8
  store i64 8, ptr %loadgep_4.repack47, align 8, !tbaa !8
  store i32 20180515, ptr %loadgep_4.repack49, align 8, !tbaa !8
  store i8 1, ptr %loadgep_4.repack51, align 4, !tbaa !8
  store i8 28, ptr %loadgep_4.repack53, align 1, !tbaa !8
  store i8 2, ptr %loadgep_4.repack55, align 2, !tbaa !8
  store i8 0, ptr %loadgep_4.repack57, align 1, !tbaa !8
  store i64 1, ptr %loadgep_4.repack59, align 8, !tbaa !8
  store i64 %.unpack12.unpack.unpack14, ptr %loadgep_4.repack59.repack61, align 8, !tbaa !8
  store i64 8, ptr %loadgep_4.repack59.repack63, align 8, !tbaa !8
  %exitcond.not = icmp eq i32 %omp_loop.iv66, %reass.sub
  br i1 %exitcond.not, label %omp_loop.exit, label %omp_loop.body
}

declare ptr @_FortranAioBeginExternalFormattedOutput(ptr, i64, ptr, i32, ptr, i32) local_unnamed_addr

declare zeroext i1 @_FortranAioOutputAscii(ptr, ptr, i64) local_unnamed_addr

declare zeroext i1 @_FortranAioOutputInteger32(ptr, i32) local_unnamed_addr

declare zeroext i1 @_FortranAioOutputReal64(ptr, double) local_unnamed_addr

declare i32 @_FortranAioEndIoStatement(ptr) local_unnamed_addr

; Function Attrs: nounwind
declare i32 @__kmpc_global_thread_num(ptr) local_unnamed_addr #3

; Function Attrs: nounwind
declare void @__kmpc_for_static_init_4u(ptr, i32, i32, ptr, ptr, ptr, ptr, i32, i32) local_unnamed_addr #3

; Function Attrs: nounwind
declare void @__kmpc_for_static_fini(ptr, i32) local_unnamed_addr #3

; Function Attrs: convergent nounwind
declare void @__kmpc_barrier(ptr, i32) local_unnamed_addr #4

; Function Attrs: nounwind
declare !callback !10 void @__kmpc_fork_call(ptr, i32, ptr, ...) local_unnamed_addr #3

; Function Attrs: nocallback nofree nosync nounwind speculatable willreturn memory(none)
declare i32 @llvm.smax.i32(i32, i32) #5

attributes #0 = { mustprogress nofree nounwind willreturn allockind("alloc,uninitialized") allocsize(0) memory(inaccessiblemem: readwrite) "alloc-family"="malloc" }
attributes #1 = { mustprogress nounwind willreturn allockind("free") memory(argmem: readwrite, inaccessiblemem: readwrite) "alloc-family"="malloc" }
attributes #2 = { norecurse nounwind }
attributes #3 = { nounwind }
attributes #4 = { convergent nounwind }
attributes #5 = { nocallback nofree nosync nounwind speculatable willreturn memory(none) }

!llvm.module.flags = !{!0, !1, !2, !3}

!0 = !{i32 2, !"Debug Info Version", i32 3}
!1 = !{i32 7, !"openmp", i32 11}
!2 = !{i32 8, !"PIC Level", i32 2}
!3 = !{i32 7, !"PIE Level", i32 2}
!4 = !{!5, !5, i64 0}
!5 = !{!"any data access", !6, i64 0}
!6 = !{!"any access", !7, i64 0}
!7 = !{!"Flang Type TBAA Root"}
!8 = !{!9, !9, i64 0}
!9 = !{!"descriptor member", !6, i64 0}
!10 = !{!11}
!11 = !{i64 2, i64 -1, i64 -1, i1 true}
*** IR Dump After EliminateAvailableExternallyPass on [module] ***
; ModuleID = 'FIRModule'
source_filename = "FIRModule"
target datalayout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128"
target triple = "x86_64-unknown-linux-gnu"

%struct.ident_t = type { i32, i32, i32, i32, ptr }

@_QFEarr.0 = internal unnamed_addr global ptr null
@_QFEarr.8 = internal unnamed_addr global i1 false
@_QQcl.60ea5a38555821a77357f87d16df9a0f = internal constant [62 x i8] c"/g/g92/rydahl1/flangtests/src/duplicate_array_descriptors.f90\00"
@_QQcl.28612C69372C612C6531332E36653229 = internal constant [16 x i8] c"(a,i7,a,e13.6e2)"
@_QQcl.54686520726573756C74206F6620286172722831292B61727228 = internal constant [26 x i8] c"The result of (arr(1)+arr("
@_QQcl.2920697320 = internal constant [5 x i8] c") is "
@_QQEnvironmentDefaults = local_unnamed_addr constant ptr null
@0 = private unnamed_addr constant [23 x i8] c";unknown;unknown;0;0;;\00", align 1
@1 = private unnamed_addr constant %struct.ident_t { i32 0, i32 2, i32 0, i32 22, ptr @0 }, align 8
@2 = private unnamed_addr constant %struct.ident_t { i32 0, i32 66, i32 0, i32 22, ptr @0 }, align 8

; Function Attrs: mustprogress nofree nounwind willreturn allockind("alloc,uninitialized") allocsize(0) memory(inaccessiblemem: readwrite)
declare noalias noundef ptr @malloc(i64 noundef) local_unnamed_addr #0

; Function Attrs: mustprogress nounwind willreturn allockind("free") memory(argmem: readwrite, inaccessiblemem: readwrite)
declare void @free(ptr allocptr nocapture noundef) local_unnamed_addr #1

define void @_QQmain() local_unnamed_addr {
entry:
  %structArg = alloca { ptr, ptr, ptr }, align 8
  %0 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %1 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %2 = alloca i32, align 4
  store i32 1048576, ptr %2, align 4, !tbaa !4
  %3 = tail call dereferenceable_or_null(8388608) ptr @malloc(i64 8388608)
  store ptr %3, ptr @_QFEarr.0, align 8, !tbaa !8
  store i1 true, ptr @_QFEarr.8, align 1
  %omp_global_thread_num = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %2, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %1, ptr %gep_5, align 8
  %gep_6 = getelementptr inbounds { ptr, ptr, ptr }, ptr %structArg, i64 0, i32 2
  store ptr %0, ptr %gep_6, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QQmain..omp_par, ptr nonnull %structArg)
  %4 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.60ea5a38555821a77357f87d16df9a0f, i32 21)
  %5 = call i1 @_FortranAioOutputAscii(ptr %4, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %6 = load i32, ptr %2, align 4, !tbaa !4
  %7 = call i1 @_FortranAioOutputInteger32(ptr %4, i32 %6)
  %8 = call i1 @_FortranAioOutputAscii(ptr %4, ptr nonnull @_QQcl.2920697320, i64 5)
  %.unpack = load ptr, ptr @_QFEarr.0, align 8, !tbaa !8
  %9 = sub i64 1, 1
  %10 = getelementptr double, ptr %.unpack, i64 %9
  %11 = load double, ptr %10, align 8, !tbaa !4
  %12 = load i32, ptr %2, align 4, !tbaa !4
  %13 = sext i32 %12 to i64
  %14 = sub i64 %13, 1
  %15 = getelementptr double, ptr %.unpack, i64 %14
  %16 = load double, ptr %15, align 8, !tbaa !4
  %17 = fadd contract double %11, %16
  %18 = call i1 @_FortranAioOutputReal64(ptr %4, double %17)
  %19 = call i32 @_FortranAioEndIoStatement(ptr %4)
  %.unpack101 = load ptr, ptr @_QFEarr.0, align 8, !tbaa !8
  call void @free(ptr %.unpack101)
  store ptr null, ptr @_QFEarr.0, align 8, !tbaa !8
  store i1 false, ptr @_QFEarr.8, align 1
  ret void
}

; Function Attrs: norecurse nounwind
define internal void @_QQmain..omp_par(ptr noalias nocapture readnone %tid.addr, ptr noalias nocapture readnone %zero.addr, ptr nocapture readonly %0) #2 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %gep_3 = getelementptr { ptr, ptr, ptr }, ptr %0, i64 0, i32 2
  %loadgep_4 = load ptr, ptr %gep_3, align 8
  %p.lastiter = alloca i32, align 4
  %p.lowerbound = alloca i32, align 4
  %p.upperbound = alloca i32, align 4
  %p.stride = alloca i32, align 4
  %1 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %omp_loop.tripcount = tail call i32 @llvm.smax.i32(i32 %1, i32 0)
  store i32 0, ptr %p.lowerbound, align 4
  %2 = add nsw i32 %omp_loop.tripcount, -1
  store i32 %2, ptr %p.upperbound, align 4
  store i32 1, ptr %p.stride, align 4
  %omp_global_thread_num4 = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  call void @__kmpc_for_static_init_4u(ptr nonnull @1, i32 %omp_global_thread_num4, i32 34, ptr nonnull %p.lastiter, ptr nonnull %p.lowerbound, ptr nonnull %p.upperbound, ptr nonnull %p.stride, i32 1, i32 0)
  %3 = load i32, ptr %p.lowerbound, align 4
  %4 = load i32, ptr %p.upperbound, align 4
  %reass.sub = sub i32 %4, %3
  %omp_loop.cmp65.not = icmp eq i32 %reass.sub, -1
  br i1 %omp_loop.cmp65.not, label %omp_loop.exit, label %omp_loop.body.lr.ph

omp_loop.body.lr.ph:                              ; preds = %omp.par.entry
  %.unpack = load ptr, ptr @_QFEarr.0, align 8, !tbaa !8
  %.unpack12.unpack.unpack14.b = load i1, ptr @_QFEarr.8, align 1
  %.unpack12.unpack.unpack14 = select i1 %.unpack12.unpack.unpack14.b, i64 1048576, i64 0
  %loadgep_2.repack17 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  %loadgep_2.repack19 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  %loadgep_2.repack21 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  %loadgep_2.repack23 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  %loadgep_2.repack25 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  %loadgep_2.repack27 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  %loadgep_2.repack29 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  %loadgep_2.repack29.repack31 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  %loadgep_2.repack29.repack33 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  %loadgep_4.repack47 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 1
  %loadgep_4.repack49 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 2
  %loadgep_4.repack51 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 3
  %loadgep_4.repack53 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 4
  %loadgep_4.repack55 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 5
  %loadgep_4.repack57 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 6
  %loadgep_4.repack59 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7
  %loadgep_4.repack59.repack61 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 1
  %loadgep_4.repack59.repack63 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 2
  br label %omp_loop.body

omp_loop.exit:                                    ; preds = %omp_loop.body, %omp.par.entry
  call void @__kmpc_for_static_fini(ptr nonnull @1, i32 %omp_global_thread_num4)
  call void @__kmpc_barrier(ptr nonnull @2, i32 %omp_global_thread_num4)
  ret void

omp_loop.body:                                    ; preds = %omp_loop.body.lr.ph, %omp_loop.body
  %omp_loop.iv66 = phi i32 [ 0, %omp_loop.body.lr.ph ], [ %5, %omp_loop.body ]
  %5 = add nuw i32 %omp_loop.iv66, 1
  %6 = add i32 %5, %3
  %7 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %8 = sitofp i32 %7 to float
  %9 = fdiv contract float 1.000000e+00, %8
  %10 = fpext float %9 to double
  store ptr %.unpack, ptr %loadgep_2, align 8, !tbaa !8
  store i64 8, ptr %loadgep_2.repack17, align 8, !tbaa !8
  store i32 20180515, ptr %loadgep_2.repack19, align 8, !tbaa !8
  store i8 1, ptr %loadgep_2.repack21, align 4, !tbaa !8
  store i8 28, ptr %loadgep_2.repack23, align 1, !tbaa !8
  store i8 2, ptr %loadgep_2.repack25, align 2, !tbaa !8
  store i8 0, ptr %loadgep_2.repack27, align 1, !tbaa !8
  store i64 1, ptr %loadgep_2.repack29, align 8, !tbaa !8
  store i64 %.unpack12.unpack.unpack14, ptr %loadgep_2.repack29.repack31, align 8, !tbaa !8
  store i64 8, ptr %loadgep_2.repack29.repack33, align 8, !tbaa !8
  %11 = sext i32 %6 to i64
  %12 = sub i64 %11, 1
  %13 = getelementptr double, ptr %.unpack, i64 %12
  store double %10, ptr %13, align 8, !tbaa !4
  store ptr %.unpack, ptr %loadgep_4, align 8, !tbaa !8
  store i64 8, ptr %loadgep_4.repack47, align 8, !tbaa !8
  store i32 20180515, ptr %loadgep_4.repack49, align 8, !tbaa !8
  store i8 1, ptr %loadgep_4.repack51, align 4, !tbaa !8
  store i8 28, ptr %loadgep_4.repack53, align 1, !tbaa !8
  store i8 2, ptr %loadgep_4.repack55, align 2, !tbaa !8
  store i8 0, ptr %loadgep_4.repack57, align 1, !tbaa !8
  store i64 1, ptr %loadgep_4.repack59, align 8, !tbaa !8
  store i64 %.unpack12.unpack.unpack14, ptr %loadgep_4.repack59.repack61, align 8, !tbaa !8
  store i64 8, ptr %loadgep_4.repack59.repack63, align 8, !tbaa !8
  %exitcond.not = icmp eq i32 %omp_loop.iv66, %reass.sub
  br i1 %exitcond.not, label %omp_loop.exit, label %omp_loop.body
}

declare ptr @_FortranAioBeginExternalFormattedOutput(ptr, i64, ptr, i32, ptr, i32) local_unnamed_addr

declare zeroext i1 @_FortranAioOutputAscii(ptr, ptr, i64) local_unnamed_addr

declare zeroext i1 @_FortranAioOutputInteger32(ptr, i32) local_unnamed_addr

declare zeroext i1 @_FortranAioOutputReal64(ptr, double) local_unnamed_addr

declare i32 @_FortranAioEndIoStatement(ptr) local_unnamed_addr

; Function Attrs: nounwind
declare i32 @__kmpc_global_thread_num(ptr) local_unnamed_addr #3

; Function Attrs: nounwind
declare void @__kmpc_for_static_init_4u(ptr, i32, i32, ptr, ptr, ptr, ptr, i32, i32) local_unnamed_addr #3

; Function Attrs: nounwind
declare void @__kmpc_for_static_fini(ptr, i32) local_unnamed_addr #3

; Function Attrs: convergent nounwind
declare void @__kmpc_barrier(ptr, i32) local_unnamed_addr #4

; Function Attrs: nounwind
declare !callback !10 void @__kmpc_fork_call(ptr, i32, ptr, ...) local_unnamed_addr #3

; Function Attrs: nocallback nofree nosync nounwind speculatable willreturn memory(none)
declare i32 @llvm.smax.i32(i32, i32) #5

attributes #0 = { mustprogress nofree nounwind willreturn allockind("alloc,uninitialized") allocsize(0) memory(inaccessiblemem: readwrite) "alloc-family"="malloc" }
attributes #1 = { mustprogress nounwind willreturn allockind("free") memory(argmem: readwrite, inaccessiblemem: readwrite) "alloc-family"="malloc" }
attributes #2 = { norecurse nounwind }
attributes #3 = { nounwind }
attributes #4 = { convergent nounwind }
attributes #5 = { nocallback nofree nosync nounwind speculatable willreturn memory(none) }

!llvm.module.flags = !{!0, !1, !2, !3}

!0 = !{i32 2, !"Debug Info Version", i32 3}
!1 = !{i32 7, !"openmp", i32 11}
!2 = !{i32 8, !"PIC Level", i32 2}
!3 = !{i32 7, !"PIE Level", i32 2}
!4 = !{!5, !5, i64 0}
!5 = !{!"any data access", !6, i64 0}
!6 = !{!"any access", !7, i64 0}
!7 = !{!"Flang Type TBAA Root"}
!8 = !{!9, !9, i64 0}
!9 = !{!"descriptor member", !6, i64 0}
!10 = !{!11}
!11 = !{i64 2, i64 -1, i64 -1, i1 true}
*** IR Dump After ReversePostOrderFunctionAttrsPass on [module] ***
; ModuleID = 'FIRModule'
source_filename = "FIRModule"
target datalayout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128"
target triple = "x86_64-unknown-linux-gnu"

%struct.ident_t = type { i32, i32, i32, i32, ptr }

@_QFEarr.0 = internal unnamed_addr global ptr null
@_QFEarr.8 = internal unnamed_addr global i1 false
@_QQcl.60ea5a38555821a77357f87d16df9a0f = internal constant [62 x i8] c"/g/g92/rydahl1/flangtests/src/duplicate_array_descriptors.f90\00"
@_QQcl.28612C69372C612C6531332E36653229 = internal constant [16 x i8] c"(a,i7,a,e13.6e2)"
@_QQcl.54686520726573756C74206F6620286172722831292B61727228 = internal constant [26 x i8] c"The result of (arr(1)+arr("
@_QQcl.2920697320 = internal constant [5 x i8] c") is "
@_QQEnvironmentDefaults = local_unnamed_addr constant ptr null
@0 = private unnamed_addr constant [23 x i8] c";unknown;unknown;0;0;;\00", align 1
@1 = private unnamed_addr constant %struct.ident_t { i32 0, i32 2, i32 0, i32 22, ptr @0 }, align 8
@2 = private unnamed_addr constant %struct.ident_t { i32 0, i32 66, i32 0, i32 22, ptr @0 }, align 8

; Function Attrs: mustprogress nofree nounwind willreturn allockind("alloc,uninitialized") allocsize(0) memory(inaccessiblemem: readwrite)
declare noalias noundef ptr @malloc(i64 noundef) local_unnamed_addr #0

; Function Attrs: mustprogress nounwind willreturn allockind("free") memory(argmem: readwrite, inaccessiblemem: readwrite)
declare void @free(ptr allocptr nocapture noundef) local_unnamed_addr #1

define void @_QQmain() local_unnamed_addr {
entry:
  %structArg = alloca { ptr, ptr, ptr }, align 8
  %0 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %1 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %2 = alloca i32, align 4
  store i32 1048576, ptr %2, align 4, !tbaa !4
  %3 = tail call dereferenceable_or_null(8388608) ptr @malloc(i64 8388608)
  store ptr %3, ptr @_QFEarr.0, align 8, !tbaa !8
  store i1 true, ptr @_QFEarr.8, align 1
  %omp_global_thread_num = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %2, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %1, ptr %gep_5, align 8
  %gep_6 = getelementptr inbounds { ptr, ptr, ptr }, ptr %structArg, i64 0, i32 2
  store ptr %0, ptr %gep_6, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QQmain..omp_par, ptr nonnull %structArg)
  %4 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.60ea5a38555821a77357f87d16df9a0f, i32 21)
  %5 = call i1 @_FortranAioOutputAscii(ptr %4, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %6 = load i32, ptr %2, align 4, !tbaa !4
  %7 = call i1 @_FortranAioOutputInteger32(ptr %4, i32 %6)
  %8 = call i1 @_FortranAioOutputAscii(ptr %4, ptr nonnull @_QQcl.2920697320, i64 5)
  %.unpack = load ptr, ptr @_QFEarr.0, align 8, !tbaa !8
  %9 = sub i64 1, 1
  %10 = getelementptr double, ptr %.unpack, i64 %9
  %11 = load double, ptr %10, align 8, !tbaa !4
  %12 = load i32, ptr %2, align 4, !tbaa !4
  %13 = sext i32 %12 to i64
  %14 = sub i64 %13, 1
  %15 = getelementptr double, ptr %.unpack, i64 %14
  %16 = load double, ptr %15, align 8, !tbaa !4
  %17 = fadd contract double %11, %16
  %18 = call i1 @_FortranAioOutputReal64(ptr %4, double %17)
  %19 = call i32 @_FortranAioEndIoStatement(ptr %4)
  %.unpack101 = load ptr, ptr @_QFEarr.0, align 8, !tbaa !8
  call void @free(ptr %.unpack101)
  store ptr null, ptr @_QFEarr.0, align 8, !tbaa !8
  store i1 false, ptr @_QFEarr.8, align 1
  ret void
}

; Function Attrs: norecurse nounwind
define internal void @_QQmain..omp_par(ptr noalias nocapture readnone %tid.addr, ptr noalias nocapture readnone %zero.addr, ptr nocapture readonly %0) #2 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %gep_3 = getelementptr { ptr, ptr, ptr }, ptr %0, i64 0, i32 2
  %loadgep_4 = load ptr, ptr %gep_3, align 8
  %p.lastiter = alloca i32, align 4
  %p.lowerbound = alloca i32, align 4
  %p.upperbound = alloca i32, align 4
  %p.stride = alloca i32, align 4
  %1 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %omp_loop.tripcount = tail call i32 @llvm.smax.i32(i32 %1, i32 0)
  store i32 0, ptr %p.lowerbound, align 4
  %2 = add nsw i32 %omp_loop.tripcount, -1
  store i32 %2, ptr %p.upperbound, align 4
  store i32 1, ptr %p.stride, align 4
  %omp_global_thread_num4 = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  call void @__kmpc_for_static_init_4u(ptr nonnull @1, i32 %omp_global_thread_num4, i32 34, ptr nonnull %p.lastiter, ptr nonnull %p.lowerbound, ptr nonnull %p.upperbound, ptr nonnull %p.stride, i32 1, i32 0)
  %3 = load i32, ptr %p.lowerbound, align 4
  %4 = load i32, ptr %p.upperbound, align 4
  %reass.sub = sub i32 %4, %3
  %omp_loop.cmp65.not = icmp eq i32 %reass.sub, -1
  br i1 %omp_loop.cmp65.not, label %omp_loop.exit, label %omp_loop.body.lr.ph

omp_loop.body.lr.ph:                              ; preds = %omp.par.entry
  %.unpack = load ptr, ptr @_QFEarr.0, align 8, !tbaa !8
  %.unpack12.unpack.unpack14.b = load i1, ptr @_QFEarr.8, align 1
  %.unpack12.unpack.unpack14 = select i1 %.unpack12.unpack.unpack14.b, i64 1048576, i64 0
  %loadgep_2.repack17 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  %loadgep_2.repack19 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  %loadgep_2.repack21 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  %loadgep_2.repack23 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  %loadgep_2.repack25 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  %loadgep_2.repack27 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  %loadgep_2.repack29 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  %loadgep_2.repack29.repack31 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  %loadgep_2.repack29.repack33 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  %loadgep_4.repack47 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 1
  %loadgep_4.repack49 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 2
  %loadgep_4.repack51 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 3
  %loadgep_4.repack53 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 4
  %loadgep_4.repack55 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 5
  %loadgep_4.repack57 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 6
  %loadgep_4.repack59 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7
  %loadgep_4.repack59.repack61 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 1
  %loadgep_4.repack59.repack63 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 2
  br label %omp_loop.body

omp_loop.exit:                                    ; preds = %omp_loop.body, %omp.par.entry
  call void @__kmpc_for_static_fini(ptr nonnull @1, i32 %omp_global_thread_num4)
  call void @__kmpc_barrier(ptr nonnull @2, i32 %omp_global_thread_num4)
  ret void

omp_loop.body:                                    ; preds = %omp_loop.body.lr.ph, %omp_loop.body
  %omp_loop.iv66 = phi i32 [ 0, %omp_loop.body.lr.ph ], [ %5, %omp_loop.body ]
  %5 = add nuw i32 %omp_loop.iv66, 1
  %6 = add i32 %5, %3
  %7 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %8 = sitofp i32 %7 to float
  %9 = fdiv contract float 1.000000e+00, %8
  %10 = fpext float %9 to double
  store ptr %.unpack, ptr %loadgep_2, align 8, !tbaa !8
  store i64 8, ptr %loadgep_2.repack17, align 8, !tbaa !8
  store i32 20180515, ptr %loadgep_2.repack19, align 8, !tbaa !8
  store i8 1, ptr %loadgep_2.repack21, align 4, !tbaa !8
  store i8 28, ptr %loadgep_2.repack23, align 1, !tbaa !8
  store i8 2, ptr %loadgep_2.repack25, align 2, !tbaa !8
  store i8 0, ptr %loadgep_2.repack27, align 1, !tbaa !8
  store i64 1, ptr %loadgep_2.repack29, align 8, !tbaa !8
  store i64 %.unpack12.unpack.unpack14, ptr %loadgep_2.repack29.repack31, align 8, !tbaa !8
  store i64 8, ptr %loadgep_2.repack29.repack33, align 8, !tbaa !8
  %11 = sext i32 %6 to i64
  %12 = sub i64 %11, 1
  %13 = getelementptr double, ptr %.unpack, i64 %12
  store double %10, ptr %13, align 8, !tbaa !4
  store ptr %.unpack, ptr %loadgep_4, align 8, !tbaa !8
  store i64 8, ptr %loadgep_4.repack47, align 8, !tbaa !8
  store i32 20180515, ptr %loadgep_4.repack49, align 8, !tbaa !8
  store i8 1, ptr %loadgep_4.repack51, align 4, !tbaa !8
  store i8 28, ptr %loadgep_4.repack53, align 1, !tbaa !8
  store i8 2, ptr %loadgep_4.repack55, align 2, !tbaa !8
  store i8 0, ptr %loadgep_4.repack57, align 1, !tbaa !8
  store i64 1, ptr %loadgep_4.repack59, align 8, !tbaa !8
  store i64 %.unpack12.unpack.unpack14, ptr %loadgep_4.repack59.repack61, align 8, !tbaa !8
  store i64 8, ptr %loadgep_4.repack59.repack63, align 8, !tbaa !8
  %exitcond.not = icmp eq i32 %omp_loop.iv66, %reass.sub
  br i1 %exitcond.not, label %omp_loop.exit, label %omp_loop.body
}

declare ptr @_FortranAioBeginExternalFormattedOutput(ptr, i64, ptr, i32, ptr, i32) local_unnamed_addr

declare zeroext i1 @_FortranAioOutputAscii(ptr, ptr, i64) local_unnamed_addr

declare zeroext i1 @_FortranAioOutputInteger32(ptr, i32) local_unnamed_addr

declare zeroext i1 @_FortranAioOutputReal64(ptr, double) local_unnamed_addr

declare i32 @_FortranAioEndIoStatement(ptr) local_unnamed_addr

; Function Attrs: nounwind
declare i32 @__kmpc_global_thread_num(ptr) local_unnamed_addr #3

; Function Attrs: nounwind
declare void @__kmpc_for_static_init_4u(ptr, i32, i32, ptr, ptr, ptr, ptr, i32, i32) local_unnamed_addr #3

; Function Attrs: nounwind
declare void @__kmpc_for_static_fini(ptr, i32) local_unnamed_addr #3

; Function Attrs: convergent nounwind
declare void @__kmpc_barrier(ptr, i32) local_unnamed_addr #4

; Function Attrs: nounwind
declare !callback !10 void @__kmpc_fork_call(ptr, i32, ptr, ...) local_unnamed_addr #3

; Function Attrs: nocallback nofree nosync nounwind speculatable willreturn memory(none)
declare i32 @llvm.smax.i32(i32, i32) #5

attributes #0 = { mustprogress nofree nounwind willreturn allockind("alloc,uninitialized") allocsize(0) memory(inaccessiblemem: readwrite) "alloc-family"="malloc" }
attributes #1 = { mustprogress nounwind willreturn allockind("free") memory(argmem: readwrite, inaccessiblemem: readwrite) "alloc-family"="malloc" }
attributes #2 = { norecurse nounwind }
attributes #3 = { nounwind }
attributes #4 = { convergent nounwind }
attributes #5 = { nocallback nofree nosync nounwind speculatable willreturn memory(none) }

!llvm.module.flags = !{!0, !1, !2, !3}

!0 = !{i32 2, !"Debug Info Version", i32 3}
!1 = !{i32 7, !"openmp", i32 11}
!2 = !{i32 8, !"PIC Level", i32 2}
!3 = !{i32 7, !"PIE Level", i32 2}
!4 = !{!5, !5, i64 0}
!5 = !{!"any data access", !6, i64 0}
!6 = !{!"any access", !7, i64 0}
!7 = !{!"Flang Type TBAA Root"}
!8 = !{!9, !9, i64 0}
!9 = !{!"descriptor member", !6, i64 0}
!10 = !{!11}
!11 = !{i64 2, i64 -1, i64 -1, i1 true}
*** IR Dump After RecomputeGlobalsAAPass on [module] ***
; ModuleID = 'FIRModule'
source_filename = "FIRModule"
target datalayout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128"
target triple = "x86_64-unknown-linux-gnu"

%struct.ident_t = type { i32, i32, i32, i32, ptr }

@_QFEarr.0 = internal unnamed_addr global ptr null
@_QFEarr.8 = internal unnamed_addr global i1 false
@_QQcl.60ea5a38555821a77357f87d16df9a0f = internal constant [62 x i8] c"/g/g92/rydahl1/flangtests/src/duplicate_array_descriptors.f90\00"
@_QQcl.28612C69372C612C6531332E36653229 = internal constant [16 x i8] c"(a,i7,a,e13.6e2)"
@_QQcl.54686520726573756C74206F6620286172722831292B61727228 = internal constant [26 x i8] c"The result of (arr(1)+arr("
@_QQcl.2920697320 = internal constant [5 x i8] c") is "
@_QQEnvironmentDefaults = local_unnamed_addr constant ptr null
@0 = private unnamed_addr constant [23 x i8] c";unknown;unknown;0;0;;\00", align 1
@1 = private unnamed_addr constant %struct.ident_t { i32 0, i32 2, i32 0, i32 22, ptr @0 }, align 8
@2 = private unnamed_addr constant %struct.ident_t { i32 0, i32 66, i32 0, i32 22, ptr @0 }, align 8

; Function Attrs: mustprogress nofree nounwind willreturn allockind("alloc,uninitialized") allocsize(0) memory(inaccessiblemem: readwrite)
declare noalias noundef ptr @malloc(i64 noundef) local_unnamed_addr #0

; Function Attrs: mustprogress nounwind willreturn allockind("free") memory(argmem: readwrite, inaccessiblemem: readwrite)
declare void @free(ptr allocptr nocapture noundef) local_unnamed_addr #1

define void @_QQmain() local_unnamed_addr {
entry:
  %structArg = alloca { ptr, ptr, ptr }, align 8
  %0 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %1 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %2 = alloca i32, align 4
  store i32 1048576, ptr %2, align 4, !tbaa !4
  %3 = tail call dereferenceable_or_null(8388608) ptr @malloc(i64 8388608)
  store ptr %3, ptr @_QFEarr.0, align 8, !tbaa !8
  store i1 true, ptr @_QFEarr.8, align 1
  %omp_global_thread_num = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %2, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %1, ptr %gep_5, align 8
  %gep_6 = getelementptr inbounds { ptr, ptr, ptr }, ptr %structArg, i64 0, i32 2
  store ptr %0, ptr %gep_6, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QQmain..omp_par, ptr nonnull %structArg)
  %4 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.60ea5a38555821a77357f87d16df9a0f, i32 21)
  %5 = call i1 @_FortranAioOutputAscii(ptr %4, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %6 = load i32, ptr %2, align 4, !tbaa !4
  %7 = call i1 @_FortranAioOutputInteger32(ptr %4, i32 %6)
  %8 = call i1 @_FortranAioOutputAscii(ptr %4, ptr nonnull @_QQcl.2920697320, i64 5)
  %.unpack = load ptr, ptr @_QFEarr.0, align 8, !tbaa !8
  %9 = sub i64 1, 1
  %10 = getelementptr double, ptr %.unpack, i64 %9
  %11 = load double, ptr %10, align 8, !tbaa !4
  %12 = load i32, ptr %2, align 4, !tbaa !4
  %13 = sext i32 %12 to i64
  %14 = sub i64 %13, 1
  %15 = getelementptr double, ptr %.unpack, i64 %14
  %16 = load double, ptr %15, align 8, !tbaa !4
  %17 = fadd contract double %11, %16
  %18 = call i1 @_FortranAioOutputReal64(ptr %4, double %17)
  %19 = call i32 @_FortranAioEndIoStatement(ptr %4)
  %.unpack101 = load ptr, ptr @_QFEarr.0, align 8, !tbaa !8
  call void @free(ptr %.unpack101)
  store ptr null, ptr @_QFEarr.0, align 8, !tbaa !8
  store i1 false, ptr @_QFEarr.8, align 1
  ret void
}

; Function Attrs: norecurse nounwind
define internal void @_QQmain..omp_par(ptr noalias nocapture readnone %tid.addr, ptr noalias nocapture readnone %zero.addr, ptr nocapture readonly %0) #2 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %gep_3 = getelementptr { ptr, ptr, ptr }, ptr %0, i64 0, i32 2
  %loadgep_4 = load ptr, ptr %gep_3, align 8
  %p.lastiter = alloca i32, align 4
  %p.lowerbound = alloca i32, align 4
  %p.upperbound = alloca i32, align 4
  %p.stride = alloca i32, align 4
  %1 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %omp_loop.tripcount = tail call i32 @llvm.smax.i32(i32 %1, i32 0)
  store i32 0, ptr %p.lowerbound, align 4
  %2 = add nsw i32 %omp_loop.tripcount, -1
  store i32 %2, ptr %p.upperbound, align 4
  store i32 1, ptr %p.stride, align 4
  %omp_global_thread_num4 = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  call void @__kmpc_for_static_init_4u(ptr nonnull @1, i32 %omp_global_thread_num4, i32 34, ptr nonnull %p.lastiter, ptr nonnull %p.lowerbound, ptr nonnull %p.upperbound, ptr nonnull %p.stride, i32 1, i32 0)
  %3 = load i32, ptr %p.lowerbound, align 4
  %4 = load i32, ptr %p.upperbound, align 4
  %reass.sub = sub i32 %4, %3
  %omp_loop.cmp65.not = icmp eq i32 %reass.sub, -1
  br i1 %omp_loop.cmp65.not, label %omp_loop.exit, label %omp_loop.body.lr.ph

omp_loop.body.lr.ph:                              ; preds = %omp.par.entry
  %.unpack = load ptr, ptr @_QFEarr.0, align 8, !tbaa !8
  %.unpack12.unpack.unpack14.b = load i1, ptr @_QFEarr.8, align 1
  %.unpack12.unpack.unpack14 = select i1 %.unpack12.unpack.unpack14.b, i64 1048576, i64 0
  %loadgep_2.repack17 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  %loadgep_2.repack19 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  %loadgep_2.repack21 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  %loadgep_2.repack23 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  %loadgep_2.repack25 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  %loadgep_2.repack27 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  %loadgep_2.repack29 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  %loadgep_2.repack29.repack31 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  %loadgep_2.repack29.repack33 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  %loadgep_4.repack47 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 1
  %loadgep_4.repack49 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 2
  %loadgep_4.repack51 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 3
  %loadgep_4.repack53 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 4
  %loadgep_4.repack55 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 5
  %loadgep_4.repack57 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 6
  %loadgep_4.repack59 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7
  %loadgep_4.repack59.repack61 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 1
  %loadgep_4.repack59.repack63 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 2
  br label %omp_loop.body

omp_loop.exit:                                    ; preds = %omp_loop.body, %omp.par.entry
  call void @__kmpc_for_static_fini(ptr nonnull @1, i32 %omp_global_thread_num4)
  call void @__kmpc_barrier(ptr nonnull @2, i32 %omp_global_thread_num4)
  ret void

omp_loop.body:                                    ; preds = %omp_loop.body.lr.ph, %omp_loop.body
  %omp_loop.iv66 = phi i32 [ 0, %omp_loop.body.lr.ph ], [ %5, %omp_loop.body ]
  %5 = add nuw i32 %omp_loop.iv66, 1
  %6 = add i32 %5, %3
  %7 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %8 = sitofp i32 %7 to float
  %9 = fdiv contract float 1.000000e+00, %8
  %10 = fpext float %9 to double
  store ptr %.unpack, ptr %loadgep_2, align 8, !tbaa !8
  store i64 8, ptr %loadgep_2.repack17, align 8, !tbaa !8
  store i32 20180515, ptr %loadgep_2.repack19, align 8, !tbaa !8
  store i8 1, ptr %loadgep_2.repack21, align 4, !tbaa !8
  store i8 28, ptr %loadgep_2.repack23, align 1, !tbaa !8
  store i8 2, ptr %loadgep_2.repack25, align 2, !tbaa !8
  store i8 0, ptr %loadgep_2.repack27, align 1, !tbaa !8
  store i64 1, ptr %loadgep_2.repack29, align 8, !tbaa !8
  store i64 %.unpack12.unpack.unpack14, ptr %loadgep_2.repack29.repack31, align 8, !tbaa !8
  store i64 8, ptr %loadgep_2.repack29.repack33, align 8, !tbaa !8
  %11 = sext i32 %6 to i64
  %12 = sub i64 %11, 1
  %13 = getelementptr double, ptr %.unpack, i64 %12
  store double %10, ptr %13, align 8, !tbaa !4
  store ptr %.unpack, ptr %loadgep_4, align 8, !tbaa !8
  store i64 8, ptr %loadgep_4.repack47, align 8, !tbaa !8
  store i32 20180515, ptr %loadgep_4.repack49, align 8, !tbaa !8
  store i8 1, ptr %loadgep_4.repack51, align 4, !tbaa !8
  store i8 28, ptr %loadgep_4.repack53, align 1, !tbaa !8
  store i8 2, ptr %loadgep_4.repack55, align 2, !tbaa !8
  store i8 0, ptr %loadgep_4.repack57, align 1, !tbaa !8
  store i64 1, ptr %loadgep_4.repack59, align 8, !tbaa !8
  store i64 %.unpack12.unpack.unpack14, ptr %loadgep_4.repack59.repack61, align 8, !tbaa !8
  store i64 8, ptr %loadgep_4.repack59.repack63, align 8, !tbaa !8
  %exitcond.not = icmp eq i32 %omp_loop.iv66, %reass.sub
  br i1 %exitcond.not, label %omp_loop.exit, label %omp_loop.body
}

declare ptr @_FortranAioBeginExternalFormattedOutput(ptr, i64, ptr, i32, ptr, i32) local_unnamed_addr

declare zeroext i1 @_FortranAioOutputAscii(ptr, ptr, i64) local_unnamed_addr

declare zeroext i1 @_FortranAioOutputInteger32(ptr, i32) local_unnamed_addr

declare zeroext i1 @_FortranAioOutputReal64(ptr, double) local_unnamed_addr

declare i32 @_FortranAioEndIoStatement(ptr) local_unnamed_addr

; Function Attrs: nounwind
declare i32 @__kmpc_global_thread_num(ptr) local_unnamed_addr #3

; Function Attrs: nounwind
declare void @__kmpc_for_static_init_4u(ptr, i32, i32, ptr, ptr, ptr, ptr, i32, i32) local_unnamed_addr #3

; Function Attrs: nounwind
declare void @__kmpc_for_static_fini(ptr, i32) local_unnamed_addr #3

; Function Attrs: convergent nounwind
declare void @__kmpc_barrier(ptr, i32) local_unnamed_addr #4

; Function Attrs: nounwind
declare !callback !10 void @__kmpc_fork_call(ptr, i32, ptr, ...) local_unnamed_addr #3

; Function Attrs: nocallback nofree nosync nounwind speculatable willreturn memory(none)
declare i32 @llvm.smax.i32(i32, i32) #5

attributes #0 = { mustprogress nofree nounwind willreturn allockind("alloc,uninitialized") allocsize(0) memory(inaccessiblemem: readwrite) "alloc-family"="malloc" }
attributes #1 = { mustprogress nounwind willreturn allockind("free") memory(argmem: readwrite, inaccessiblemem: readwrite) "alloc-family"="malloc" }
attributes #2 = { norecurse nounwind }
attributes #3 = { nounwind }
attributes #4 = { convergent nounwind }
attributes #5 = { nocallback nofree nosync nounwind speculatable willreturn memory(none) }

!llvm.module.flags = !{!0, !1, !2, !3}

!0 = !{i32 2, !"Debug Info Version", i32 3}
!1 = !{i32 7, !"openmp", i32 11}
!2 = !{i32 8, !"PIC Level", i32 2}
!3 = !{i32 7, !"PIE Level", i32 2}
!4 = !{!5, !5, i64 0}
!5 = !{!"any data access", !6, i64 0}
!6 = !{!"any access", !7, i64 0}
!7 = !{!"Flang Type TBAA Root"}
!8 = !{!9, !9, i64 0}
!9 = !{!"descriptor member", !6, i64 0}
!10 = !{!11}
!11 = !{i64 2, i64 -1, i64 -1, i1 true}
*** IR Dump After Float2IntPass on _QQmain ***
define void @_QQmain() local_unnamed_addr {
entry:
  %structArg = alloca { ptr, ptr, ptr }, align 8
  %0 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %1 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %2 = alloca i32, align 4
  store i32 1048576, ptr %2, align 4, !tbaa !4
  %3 = tail call dereferenceable_or_null(8388608) ptr @malloc(i64 8388608)
  store ptr %3, ptr @_QFEarr.0, align 8, !tbaa !8
  store i1 true, ptr @_QFEarr.8, align 1
  %omp_global_thread_num = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %2, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %1, ptr %gep_5, align 8
  %gep_6 = getelementptr inbounds { ptr, ptr, ptr }, ptr %structArg, i64 0, i32 2
  store ptr %0, ptr %gep_6, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QQmain..omp_par, ptr nonnull %structArg)
  %4 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.60ea5a38555821a77357f87d16df9a0f, i32 21)
  %5 = call i1 @_FortranAioOutputAscii(ptr %4, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %6 = load i32, ptr %2, align 4, !tbaa !4
  %7 = call i1 @_FortranAioOutputInteger32(ptr %4, i32 %6)
  %8 = call i1 @_FortranAioOutputAscii(ptr %4, ptr nonnull @_QQcl.2920697320, i64 5)
  %.unpack = load ptr, ptr @_QFEarr.0, align 8, !tbaa !8
  %9 = sub i64 1, 1
  %10 = getelementptr double, ptr %.unpack, i64 %9
  %11 = load double, ptr %10, align 8, !tbaa !4
  %12 = load i32, ptr %2, align 4, !tbaa !4
  %13 = sext i32 %12 to i64
  %14 = sub i64 %13, 1
  %15 = getelementptr double, ptr %.unpack, i64 %14
  %16 = load double, ptr %15, align 8, !tbaa !4
  %17 = fadd contract double %11, %16
  %18 = call i1 @_FortranAioOutputReal64(ptr %4, double %17)
  %19 = call i32 @_FortranAioEndIoStatement(ptr %4)
  %.unpack101 = load ptr, ptr @_QFEarr.0, align 8, !tbaa !8
  call void @free(ptr %.unpack101)
  store ptr null, ptr @_QFEarr.0, align 8, !tbaa !8
  store i1 false, ptr @_QFEarr.8, align 1
  ret void
}
*** IR Dump After LowerConstantIntrinsicsPass on _QQmain ***
define void @_QQmain() local_unnamed_addr {
entry:
  %structArg = alloca { ptr, ptr, ptr }, align 8
  %0 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %1 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %2 = alloca i32, align 4
  store i32 1048576, ptr %2, align 4, !tbaa !4
  %3 = tail call dereferenceable_or_null(8388608) ptr @malloc(i64 8388608)
  store ptr %3, ptr @_QFEarr.0, align 8, !tbaa !8
  store i1 true, ptr @_QFEarr.8, align 1
  %omp_global_thread_num = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %2, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %1, ptr %gep_5, align 8
  %gep_6 = getelementptr inbounds { ptr, ptr, ptr }, ptr %structArg, i64 0, i32 2
  store ptr %0, ptr %gep_6, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QQmain..omp_par, ptr nonnull %structArg)
  %4 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.60ea5a38555821a77357f87d16df9a0f, i32 21)
  %5 = call i1 @_FortranAioOutputAscii(ptr %4, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %6 = load i32, ptr %2, align 4, !tbaa !4
  %7 = call i1 @_FortranAioOutputInteger32(ptr %4, i32 %6)
  %8 = call i1 @_FortranAioOutputAscii(ptr %4, ptr nonnull @_QQcl.2920697320, i64 5)
  %.unpack = load ptr, ptr @_QFEarr.0, align 8, !tbaa !8
  %9 = sub i64 1, 1
  %10 = getelementptr double, ptr %.unpack, i64 %9
  %11 = load double, ptr %10, align 8, !tbaa !4
  %12 = load i32, ptr %2, align 4, !tbaa !4
  %13 = sext i32 %12 to i64
  %14 = sub i64 %13, 1
  %15 = getelementptr double, ptr %.unpack, i64 %14
  %16 = load double, ptr %15, align 8, !tbaa !4
  %17 = fadd contract double %11, %16
  %18 = call i1 @_FortranAioOutputReal64(ptr %4, double %17)
  %19 = call i32 @_FortranAioEndIoStatement(ptr %4)
  %.unpack101 = load ptr, ptr @_QFEarr.0, align 8, !tbaa !8
  call void @free(ptr %.unpack101)
  store ptr null, ptr @_QFEarr.0, align 8, !tbaa !8
  store i1 false, ptr @_QFEarr.8, align 1
  ret void
}
*** IR Dump After ControlHeightReductionPass on _QQmain ***
define void @_QQmain() local_unnamed_addr {
entry:
  %structArg = alloca { ptr, ptr, ptr }, align 8
  %0 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %1 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %2 = alloca i32, align 4
  store i32 1048576, ptr %2, align 4, !tbaa !4
  %3 = tail call dereferenceable_or_null(8388608) ptr @malloc(i64 8388608)
  store ptr %3, ptr @_QFEarr.0, align 8, !tbaa !8
  store i1 true, ptr @_QFEarr.8, align 1
  %omp_global_thread_num = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %2, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %1, ptr %gep_5, align 8
  %gep_6 = getelementptr inbounds { ptr, ptr, ptr }, ptr %structArg, i64 0, i32 2
  store ptr %0, ptr %gep_6, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QQmain..omp_par, ptr nonnull %structArg)
  %4 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.60ea5a38555821a77357f87d16df9a0f, i32 21)
  %5 = call i1 @_FortranAioOutputAscii(ptr %4, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %6 = load i32, ptr %2, align 4, !tbaa !4
  %7 = call i1 @_FortranAioOutputInteger32(ptr %4, i32 %6)
  %8 = call i1 @_FortranAioOutputAscii(ptr %4, ptr nonnull @_QQcl.2920697320, i64 5)
  %.unpack = load ptr, ptr @_QFEarr.0, align 8, !tbaa !8
  %9 = sub i64 1, 1
  %10 = getelementptr double, ptr %.unpack, i64 %9
  %11 = load double, ptr %10, align 8, !tbaa !4
  %12 = load i32, ptr %2, align 4, !tbaa !4
  %13 = sext i32 %12 to i64
  %14 = sub i64 %13, 1
  %15 = getelementptr double, ptr %.unpack, i64 %14
  %16 = load double, ptr %15, align 8, !tbaa !4
  %17 = fadd contract double %11, %16
  %18 = call i1 @_FortranAioOutputReal64(ptr %4, double %17)
  %19 = call i32 @_FortranAioEndIoStatement(ptr %4)
  %.unpack101 = load ptr, ptr @_QFEarr.0, align 8, !tbaa !8
  call void @free(ptr %.unpack101)
  store ptr null, ptr @_QFEarr.0, align 8, !tbaa !8
  store i1 false, ptr @_QFEarr.8, align 1
  ret void
}
*** IR Dump After LoopSimplifyPass on _QQmain ***
define void @_QQmain() local_unnamed_addr {
entry:
  %structArg = alloca { ptr, ptr, ptr }, align 8
  %0 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %1 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %2 = alloca i32, align 4
  store i32 1048576, ptr %2, align 4, !tbaa !4
  %3 = tail call dereferenceable_or_null(8388608) ptr @malloc(i64 8388608)
  store ptr %3, ptr @_QFEarr.0, align 8, !tbaa !8
  store i1 true, ptr @_QFEarr.8, align 1
  %omp_global_thread_num = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %2, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %1, ptr %gep_5, align 8
  %gep_6 = getelementptr inbounds { ptr, ptr, ptr }, ptr %structArg, i64 0, i32 2
  store ptr %0, ptr %gep_6, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QQmain..omp_par, ptr nonnull %structArg)
  %4 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.60ea5a38555821a77357f87d16df9a0f, i32 21)
  %5 = call i1 @_FortranAioOutputAscii(ptr %4, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %6 = load i32, ptr %2, align 4, !tbaa !4
  %7 = call i1 @_FortranAioOutputInteger32(ptr %4, i32 %6)
  %8 = call i1 @_FortranAioOutputAscii(ptr %4, ptr nonnull @_QQcl.2920697320, i64 5)
  %.unpack = load ptr, ptr @_QFEarr.0, align 8, !tbaa !8
  %9 = sub i64 1, 1
  %10 = getelementptr double, ptr %.unpack, i64 %9
  %11 = load double, ptr %10, align 8, !tbaa !4
  %12 = load i32, ptr %2, align 4, !tbaa !4
  %13 = sext i32 %12 to i64
  %14 = sub i64 %13, 1
  %15 = getelementptr double, ptr %.unpack, i64 %14
  %16 = load double, ptr %15, align 8, !tbaa !4
  %17 = fadd contract double %11, %16
  %18 = call i1 @_FortranAioOutputReal64(ptr %4, double %17)
  %19 = call i32 @_FortranAioEndIoStatement(ptr %4)
  %.unpack101 = load ptr, ptr @_QFEarr.0, align 8, !tbaa !8
  call void @free(ptr %.unpack101)
  store ptr null, ptr @_QFEarr.0, align 8, !tbaa !8
  store i1 false, ptr @_QFEarr.8, align 1
  ret void
}
*** IR Dump After LCSSAPass on _QQmain ***
define void @_QQmain() local_unnamed_addr {
entry:
  %structArg = alloca { ptr, ptr, ptr }, align 8
  %0 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %1 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %2 = alloca i32, align 4
  store i32 1048576, ptr %2, align 4, !tbaa !4
  %3 = tail call dereferenceable_or_null(8388608) ptr @malloc(i64 8388608)
  store ptr %3, ptr @_QFEarr.0, align 8, !tbaa !8
  store i1 true, ptr @_QFEarr.8, align 1
  %omp_global_thread_num = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %2, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %1, ptr %gep_5, align 8
  %gep_6 = getelementptr inbounds { ptr, ptr, ptr }, ptr %structArg, i64 0, i32 2
  store ptr %0, ptr %gep_6, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QQmain..omp_par, ptr nonnull %structArg)
  %4 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.60ea5a38555821a77357f87d16df9a0f, i32 21)
  %5 = call i1 @_FortranAioOutputAscii(ptr %4, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %6 = load i32, ptr %2, align 4, !tbaa !4
  %7 = call i1 @_FortranAioOutputInteger32(ptr %4, i32 %6)
  %8 = call i1 @_FortranAioOutputAscii(ptr %4, ptr nonnull @_QQcl.2920697320, i64 5)
  %.unpack = load ptr, ptr @_QFEarr.0, align 8, !tbaa !8
  %9 = sub i64 1, 1
  %10 = getelementptr double, ptr %.unpack, i64 %9
  %11 = load double, ptr %10, align 8, !tbaa !4
  %12 = load i32, ptr %2, align 4, !tbaa !4
  %13 = sext i32 %12 to i64
  %14 = sub i64 %13, 1
  %15 = getelementptr double, ptr %.unpack, i64 %14
  %16 = load double, ptr %15, align 8, !tbaa !4
  %17 = fadd contract double %11, %16
  %18 = call i1 @_FortranAioOutputReal64(ptr %4, double %17)
  %19 = call i32 @_FortranAioEndIoStatement(ptr %4)
  %.unpack101 = load ptr, ptr @_QFEarr.0, align 8, !tbaa !8
  call void @free(ptr %.unpack101)
  store ptr null, ptr @_QFEarr.0, align 8, !tbaa !8
  store i1 false, ptr @_QFEarr.8, align 1
  ret void
}
*** IR Dump After LoopDistributePass on _QQmain ***
define void @_QQmain() local_unnamed_addr {
entry:
  %structArg = alloca { ptr, ptr, ptr }, align 8
  %0 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %1 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %2 = alloca i32, align 4
  store i32 1048576, ptr %2, align 4, !tbaa !4
  %3 = tail call dereferenceable_or_null(8388608) ptr @malloc(i64 8388608)
  store ptr %3, ptr @_QFEarr.0, align 8, !tbaa !8
  store i1 true, ptr @_QFEarr.8, align 1
  %omp_global_thread_num = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %2, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %1, ptr %gep_5, align 8
  %gep_6 = getelementptr inbounds { ptr, ptr, ptr }, ptr %structArg, i64 0, i32 2
  store ptr %0, ptr %gep_6, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QQmain..omp_par, ptr nonnull %structArg)
  %4 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.60ea5a38555821a77357f87d16df9a0f, i32 21)
  %5 = call i1 @_FortranAioOutputAscii(ptr %4, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %6 = load i32, ptr %2, align 4, !tbaa !4
  %7 = call i1 @_FortranAioOutputInteger32(ptr %4, i32 %6)
  %8 = call i1 @_FortranAioOutputAscii(ptr %4, ptr nonnull @_QQcl.2920697320, i64 5)
  %.unpack = load ptr, ptr @_QFEarr.0, align 8, !tbaa !8
  %9 = sub i64 1, 1
  %10 = getelementptr double, ptr %.unpack, i64 %9
  %11 = load double, ptr %10, align 8, !tbaa !4
  %12 = load i32, ptr %2, align 4, !tbaa !4
  %13 = sext i32 %12 to i64
  %14 = sub i64 %13, 1
  %15 = getelementptr double, ptr %.unpack, i64 %14
  %16 = load double, ptr %15, align 8, !tbaa !4
  %17 = fadd contract double %11, %16
  %18 = call i1 @_FortranAioOutputReal64(ptr %4, double %17)
  %19 = call i32 @_FortranAioEndIoStatement(ptr %4)
  %.unpack101 = load ptr, ptr @_QFEarr.0, align 8, !tbaa !8
  call void @free(ptr %.unpack101)
  store ptr null, ptr @_QFEarr.0, align 8, !tbaa !8
  store i1 false, ptr @_QFEarr.8, align 1
  ret void
}
*** IR Dump After InjectTLIMappings on _QQmain ***
define void @_QQmain() local_unnamed_addr {
entry:
  %structArg = alloca { ptr, ptr, ptr }, align 8
  %0 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %1 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %2 = alloca i32, align 4
  store i32 1048576, ptr %2, align 4, !tbaa !4
  %3 = tail call dereferenceable_or_null(8388608) ptr @malloc(i64 8388608)
  store ptr %3, ptr @_QFEarr.0, align 8, !tbaa !8
  store i1 true, ptr @_QFEarr.8, align 1
  %omp_global_thread_num = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %2, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %1, ptr %gep_5, align 8
  %gep_6 = getelementptr inbounds { ptr, ptr, ptr }, ptr %structArg, i64 0, i32 2
  store ptr %0, ptr %gep_6, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QQmain..omp_par, ptr nonnull %structArg)
  %4 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.60ea5a38555821a77357f87d16df9a0f, i32 21)
  %5 = call i1 @_FortranAioOutputAscii(ptr %4, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %6 = load i32, ptr %2, align 4, !tbaa !4
  %7 = call i1 @_FortranAioOutputInteger32(ptr %4, i32 %6)
  %8 = call i1 @_FortranAioOutputAscii(ptr %4, ptr nonnull @_QQcl.2920697320, i64 5)
  %.unpack = load ptr, ptr @_QFEarr.0, align 8, !tbaa !8
  %9 = sub i64 1, 1
  %10 = getelementptr double, ptr %.unpack, i64 %9
  %11 = load double, ptr %10, align 8, !tbaa !4
  %12 = load i32, ptr %2, align 4, !tbaa !4
  %13 = sext i32 %12 to i64
  %14 = sub i64 %13, 1
  %15 = getelementptr double, ptr %.unpack, i64 %14
  %16 = load double, ptr %15, align 8, !tbaa !4
  %17 = fadd contract double %11, %16
  %18 = call i1 @_FortranAioOutputReal64(ptr %4, double %17)
  %19 = call i32 @_FortranAioEndIoStatement(ptr %4)
  %.unpack101 = load ptr, ptr @_QFEarr.0, align 8, !tbaa !8
  call void @free(ptr %.unpack101)
  store ptr null, ptr @_QFEarr.0, align 8, !tbaa !8
  store i1 false, ptr @_QFEarr.8, align 1
  ret void
}
*** IR Dump After LoopVectorizePass on _QQmain ***
define void @_QQmain() local_unnamed_addr {
entry:
  %structArg = alloca { ptr, ptr, ptr }, align 8
  %0 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %1 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %2 = alloca i32, align 4
  store i32 1048576, ptr %2, align 4, !tbaa !4
  %3 = tail call dereferenceable_or_null(8388608) ptr @malloc(i64 8388608)
  store ptr %3, ptr @_QFEarr.0, align 8, !tbaa !8
  store i1 true, ptr @_QFEarr.8, align 1
  %omp_global_thread_num = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %2, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %1, ptr %gep_5, align 8
  %gep_6 = getelementptr inbounds { ptr, ptr, ptr }, ptr %structArg, i64 0, i32 2
  store ptr %0, ptr %gep_6, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QQmain..omp_par, ptr nonnull %structArg)
  %4 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.60ea5a38555821a77357f87d16df9a0f, i32 21)
  %5 = call i1 @_FortranAioOutputAscii(ptr %4, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %6 = load i32, ptr %2, align 4, !tbaa !4
  %7 = call i1 @_FortranAioOutputInteger32(ptr %4, i32 %6)
  %8 = call i1 @_FortranAioOutputAscii(ptr %4, ptr nonnull @_QQcl.2920697320, i64 5)
  %.unpack = load ptr, ptr @_QFEarr.0, align 8, !tbaa !8
  %9 = sub i64 1, 1
  %10 = getelementptr double, ptr %.unpack, i64 %9
  %11 = load double, ptr %10, align 8, !tbaa !4
  %12 = load i32, ptr %2, align 4, !tbaa !4
  %13 = sext i32 %12 to i64
  %14 = sub i64 %13, 1
  %15 = getelementptr double, ptr %.unpack, i64 %14
  %16 = load double, ptr %15, align 8, !tbaa !4
  %17 = fadd contract double %11, %16
  %18 = call i1 @_FortranAioOutputReal64(ptr %4, double %17)
  %19 = call i32 @_FortranAioEndIoStatement(ptr %4)
  %.unpack101 = load ptr, ptr @_QFEarr.0, align 8, !tbaa !8
  call void @free(ptr %.unpack101)
  store ptr null, ptr @_QFEarr.0, align 8, !tbaa !8
  store i1 false, ptr @_QFEarr.8, align 1
  ret void
}
*** IR Dump After LoopLoadEliminationPass on _QQmain ***
define void @_QQmain() local_unnamed_addr {
entry:
  %structArg = alloca { ptr, ptr, ptr }, align 8
  %0 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %1 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %2 = alloca i32, align 4
  store i32 1048576, ptr %2, align 4, !tbaa !4
  %3 = tail call dereferenceable_or_null(8388608) ptr @malloc(i64 8388608)
  store ptr %3, ptr @_QFEarr.0, align 8, !tbaa !8
  store i1 true, ptr @_QFEarr.8, align 1
  %omp_global_thread_num = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %2, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %1, ptr %gep_5, align 8
  %gep_6 = getelementptr inbounds { ptr, ptr, ptr }, ptr %structArg, i64 0, i32 2
  store ptr %0, ptr %gep_6, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QQmain..omp_par, ptr nonnull %structArg)
  %4 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.60ea5a38555821a77357f87d16df9a0f, i32 21)
  %5 = call i1 @_FortranAioOutputAscii(ptr %4, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %6 = load i32, ptr %2, align 4, !tbaa !4
  %7 = call i1 @_FortranAioOutputInteger32(ptr %4, i32 %6)
  %8 = call i1 @_FortranAioOutputAscii(ptr %4, ptr nonnull @_QQcl.2920697320, i64 5)
  %.unpack = load ptr, ptr @_QFEarr.0, align 8, !tbaa !8
  %9 = sub i64 1, 1
  %10 = getelementptr double, ptr %.unpack, i64 %9
  %11 = load double, ptr %10, align 8, !tbaa !4
  %12 = load i32, ptr %2, align 4, !tbaa !4
  %13 = sext i32 %12 to i64
  %14 = sub i64 %13, 1
  %15 = getelementptr double, ptr %.unpack, i64 %14
  %16 = load double, ptr %15, align 8, !tbaa !4
  %17 = fadd contract double %11, %16
  %18 = call i1 @_FortranAioOutputReal64(ptr %4, double %17)
  %19 = call i32 @_FortranAioEndIoStatement(ptr %4)
  %.unpack101 = load ptr, ptr @_QFEarr.0, align 8, !tbaa !8
  call void @free(ptr %.unpack101)
  store ptr null, ptr @_QFEarr.0, align 8, !tbaa !8
  store i1 false, ptr @_QFEarr.8, align 1
  ret void
}
*** IR Dump After InstCombinePass on _QQmain ***
define void @_QQmain() local_unnamed_addr {
entry:
  %structArg = alloca { ptr, ptr, ptr }, align 8
  %0 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %1 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %2 = alloca i32, align 4
  store i32 1048576, ptr %2, align 4, !tbaa !4
  %3 = tail call dereferenceable_or_null(8388608) ptr @malloc(i64 8388608)
  store ptr %3, ptr @_QFEarr.0, align 8, !tbaa !8
  store i1 true, ptr @_QFEarr.8, align 1
  %omp_global_thread_num = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %2, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %1, ptr %gep_5, align 8
  %gep_6 = getelementptr inbounds { ptr, ptr, ptr }, ptr %structArg, i64 0, i32 2
  store ptr %0, ptr %gep_6, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QQmain..omp_par, ptr nonnull %structArg)
  %4 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.60ea5a38555821a77357f87d16df9a0f, i32 21)
  %5 = call i1 @_FortranAioOutputAscii(ptr %4, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %6 = load i32, ptr %2, align 4, !tbaa !4
  %7 = call i1 @_FortranAioOutputInteger32(ptr %4, i32 %6)
  %8 = call i1 @_FortranAioOutputAscii(ptr %4, ptr nonnull @_QQcl.2920697320, i64 5)
  %.unpack = load ptr, ptr @_QFEarr.0, align 8, !tbaa !8
  %9 = load double, ptr %.unpack, align 8, !tbaa !4
  %10 = load i32, ptr %2, align 4, !tbaa !4
  %11 = sext i32 %10 to i64
  %12 = add nsw i64 %11, -1
  %13 = getelementptr double, ptr %.unpack, i64 %12
  %14 = load double, ptr %13, align 8, !tbaa !4
  %15 = fadd contract double %9, %14
  %16 = call i1 @_FortranAioOutputReal64(ptr %4, double %15)
  %17 = call i32 @_FortranAioEndIoStatement(ptr %4)
  %.unpack101 = load ptr, ptr @_QFEarr.0, align 8, !tbaa !8
  call void @free(ptr %.unpack101)
  store ptr null, ptr @_QFEarr.0, align 8, !tbaa !8
  store i1 false, ptr @_QFEarr.8, align 1
  ret void
}
*** IR Dump After SimplifyCFGPass on _QQmain ***
define void @_QQmain() local_unnamed_addr {
entry:
  %structArg = alloca { ptr, ptr, ptr }, align 8
  %0 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %1 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %2 = alloca i32, align 4
  store i32 1048576, ptr %2, align 4, !tbaa !4
  %3 = tail call dereferenceable_or_null(8388608) ptr @malloc(i64 8388608)
  store ptr %3, ptr @_QFEarr.0, align 8, !tbaa !8
  store i1 true, ptr @_QFEarr.8, align 1
  %omp_global_thread_num = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %2, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %1, ptr %gep_5, align 8
  %gep_6 = getelementptr inbounds { ptr, ptr, ptr }, ptr %structArg, i64 0, i32 2
  store ptr %0, ptr %gep_6, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QQmain..omp_par, ptr nonnull %structArg)
  %4 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.60ea5a38555821a77357f87d16df9a0f, i32 21)
  %5 = call i1 @_FortranAioOutputAscii(ptr %4, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %6 = load i32, ptr %2, align 4, !tbaa !4
  %7 = call i1 @_FortranAioOutputInteger32(ptr %4, i32 %6)
  %8 = call i1 @_FortranAioOutputAscii(ptr %4, ptr nonnull @_QQcl.2920697320, i64 5)
  %.unpack = load ptr, ptr @_QFEarr.0, align 8, !tbaa !8
  %9 = load double, ptr %.unpack, align 8, !tbaa !4
  %10 = load i32, ptr %2, align 4, !tbaa !4
  %11 = sext i32 %10 to i64
  %12 = add nsw i64 %11, -1
  %13 = getelementptr double, ptr %.unpack, i64 %12
  %14 = load double, ptr %13, align 8, !tbaa !4
  %15 = fadd contract double %9, %14
  %16 = call i1 @_FortranAioOutputReal64(ptr %4, double %15)
  %17 = call i32 @_FortranAioEndIoStatement(ptr %4)
  %.unpack101 = load ptr, ptr @_QFEarr.0, align 8, !tbaa !8
  call void @free(ptr %.unpack101)
  store ptr null, ptr @_QFEarr.0, align 8, !tbaa !8
  store i1 false, ptr @_QFEarr.8, align 1
  ret void
}
*** IR Dump After VectorCombinePass on _QQmain ***
define void @_QQmain() local_unnamed_addr {
entry:
  %structArg = alloca { ptr, ptr, ptr }, align 8
  %0 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %1 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %2 = alloca i32, align 4
  store i32 1048576, ptr %2, align 4, !tbaa !4
  %3 = tail call dereferenceable_or_null(8388608) ptr @malloc(i64 8388608)
  store ptr %3, ptr @_QFEarr.0, align 8, !tbaa !8
  store i1 true, ptr @_QFEarr.8, align 1
  %omp_global_thread_num = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %2, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %1, ptr %gep_5, align 8
  %gep_6 = getelementptr inbounds { ptr, ptr, ptr }, ptr %structArg, i64 0, i32 2
  store ptr %0, ptr %gep_6, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QQmain..omp_par, ptr nonnull %structArg)
  %4 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.60ea5a38555821a77357f87d16df9a0f, i32 21)
  %5 = call i1 @_FortranAioOutputAscii(ptr %4, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %6 = load i32, ptr %2, align 4, !tbaa !4
  %7 = call i1 @_FortranAioOutputInteger32(ptr %4, i32 %6)
  %8 = call i1 @_FortranAioOutputAscii(ptr %4, ptr nonnull @_QQcl.2920697320, i64 5)
  %.unpack = load ptr, ptr @_QFEarr.0, align 8, !tbaa !8
  %9 = load double, ptr %.unpack, align 8, !tbaa !4
  %10 = load i32, ptr %2, align 4, !tbaa !4
  %11 = sext i32 %10 to i64
  %12 = add nsw i64 %11, -1
  %13 = getelementptr double, ptr %.unpack, i64 %12
  %14 = load double, ptr %13, align 8, !tbaa !4
  %15 = fadd contract double %9, %14
  %16 = call i1 @_FortranAioOutputReal64(ptr %4, double %15)
  %17 = call i32 @_FortranAioEndIoStatement(ptr %4)
  %.unpack101 = load ptr, ptr @_QFEarr.0, align 8, !tbaa !8
  call void @free(ptr %.unpack101)
  store ptr null, ptr @_QFEarr.0, align 8, !tbaa !8
  store i1 false, ptr @_QFEarr.8, align 1
  ret void
}
*** IR Dump After InstCombinePass on _QQmain ***
define void @_QQmain() local_unnamed_addr {
entry:
  %structArg = alloca { ptr, ptr, ptr }, align 8
  %0 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %1 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %2 = alloca i32, align 4
  store i32 1048576, ptr %2, align 4, !tbaa !4
  %3 = tail call dereferenceable_or_null(8388608) ptr @malloc(i64 8388608)
  store ptr %3, ptr @_QFEarr.0, align 8, !tbaa !8
  store i1 true, ptr @_QFEarr.8, align 1
  %omp_global_thread_num = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %2, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %1, ptr %gep_5, align 8
  %gep_6 = getelementptr inbounds { ptr, ptr, ptr }, ptr %structArg, i64 0, i32 2
  store ptr %0, ptr %gep_6, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QQmain..omp_par, ptr nonnull %structArg)
  %4 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.60ea5a38555821a77357f87d16df9a0f, i32 21)
  %5 = call i1 @_FortranAioOutputAscii(ptr %4, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %6 = load i32, ptr %2, align 4, !tbaa !4
  %7 = call i1 @_FortranAioOutputInteger32(ptr %4, i32 %6)
  %8 = call i1 @_FortranAioOutputAscii(ptr %4, ptr nonnull @_QQcl.2920697320, i64 5)
  %.unpack = load ptr, ptr @_QFEarr.0, align 8, !tbaa !8
  %9 = load double, ptr %.unpack, align 8, !tbaa !4
  %10 = load i32, ptr %2, align 4, !tbaa !4
  %11 = sext i32 %10 to i64
  %12 = add nsw i64 %11, -1
  %13 = getelementptr double, ptr %.unpack, i64 %12
  %14 = load double, ptr %13, align 8, !tbaa !4
  %15 = fadd contract double %9, %14
  %16 = call i1 @_FortranAioOutputReal64(ptr %4, double %15)
  %17 = call i32 @_FortranAioEndIoStatement(ptr %4)
  %.unpack101 = load ptr, ptr @_QFEarr.0, align 8, !tbaa !8
  call void @free(ptr %.unpack101)
  store ptr null, ptr @_QFEarr.0, align 8, !tbaa !8
  store i1 false, ptr @_QFEarr.8, align 1
  ret void
}
*** IR Dump After LoopUnrollPass on _QQmain ***
define void @_QQmain() local_unnamed_addr {
entry:
  %structArg = alloca { ptr, ptr, ptr }, align 8
  %0 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %1 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %2 = alloca i32, align 4
  store i32 1048576, ptr %2, align 4, !tbaa !4
  %3 = tail call dereferenceable_or_null(8388608) ptr @malloc(i64 8388608)
  store ptr %3, ptr @_QFEarr.0, align 8, !tbaa !8
  store i1 true, ptr @_QFEarr.8, align 1
  %omp_global_thread_num = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %2, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %1, ptr %gep_5, align 8
  %gep_6 = getelementptr inbounds { ptr, ptr, ptr }, ptr %structArg, i64 0, i32 2
  store ptr %0, ptr %gep_6, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QQmain..omp_par, ptr nonnull %structArg)
  %4 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.60ea5a38555821a77357f87d16df9a0f, i32 21)
  %5 = call i1 @_FortranAioOutputAscii(ptr %4, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %6 = load i32, ptr %2, align 4, !tbaa !4
  %7 = call i1 @_FortranAioOutputInteger32(ptr %4, i32 %6)
  %8 = call i1 @_FortranAioOutputAscii(ptr %4, ptr nonnull @_QQcl.2920697320, i64 5)
  %.unpack = load ptr, ptr @_QFEarr.0, align 8, !tbaa !8
  %9 = load double, ptr %.unpack, align 8, !tbaa !4
  %10 = load i32, ptr %2, align 4, !tbaa !4
  %11 = sext i32 %10 to i64
  %12 = add nsw i64 %11, -1
  %13 = getelementptr double, ptr %.unpack, i64 %12
  %14 = load double, ptr %13, align 8, !tbaa !4
  %15 = fadd contract double %9, %14
  %16 = call i1 @_FortranAioOutputReal64(ptr %4, double %15)
  %17 = call i32 @_FortranAioEndIoStatement(ptr %4)
  %.unpack101 = load ptr, ptr @_QFEarr.0, align 8, !tbaa !8
  call void @free(ptr %.unpack101)
  store ptr null, ptr @_QFEarr.0, align 8, !tbaa !8
  store i1 false, ptr @_QFEarr.8, align 1
  ret void
}
*** IR Dump After WarnMissedTransformationsPass on _QQmain ***
define void @_QQmain() local_unnamed_addr {
entry:
  %structArg = alloca { ptr, ptr, ptr }, align 8
  %0 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %1 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %2 = alloca i32, align 4
  store i32 1048576, ptr %2, align 4, !tbaa !4
  %3 = tail call dereferenceable_or_null(8388608) ptr @malloc(i64 8388608)
  store ptr %3, ptr @_QFEarr.0, align 8, !tbaa !8
  store i1 true, ptr @_QFEarr.8, align 1
  %omp_global_thread_num = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %2, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %1, ptr %gep_5, align 8
  %gep_6 = getelementptr inbounds { ptr, ptr, ptr }, ptr %structArg, i64 0, i32 2
  store ptr %0, ptr %gep_6, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QQmain..omp_par, ptr nonnull %structArg)
  %4 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.60ea5a38555821a77357f87d16df9a0f, i32 21)
  %5 = call i1 @_FortranAioOutputAscii(ptr %4, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %6 = load i32, ptr %2, align 4, !tbaa !4
  %7 = call i1 @_FortranAioOutputInteger32(ptr %4, i32 %6)
  %8 = call i1 @_FortranAioOutputAscii(ptr %4, ptr nonnull @_QQcl.2920697320, i64 5)
  %.unpack = load ptr, ptr @_QFEarr.0, align 8, !tbaa !8
  %9 = load double, ptr %.unpack, align 8, !tbaa !4
  %10 = load i32, ptr %2, align 4, !tbaa !4
  %11 = sext i32 %10 to i64
  %12 = add nsw i64 %11, -1
  %13 = getelementptr double, ptr %.unpack, i64 %12
  %14 = load double, ptr %13, align 8, !tbaa !4
  %15 = fadd contract double %9, %14
  %16 = call i1 @_FortranAioOutputReal64(ptr %4, double %15)
  %17 = call i32 @_FortranAioEndIoStatement(ptr %4)
  %.unpack101 = load ptr, ptr @_QFEarr.0, align 8, !tbaa !8
  call void @free(ptr %.unpack101)
  store ptr null, ptr @_QFEarr.0, align 8, !tbaa !8
  store i1 false, ptr @_QFEarr.8, align 1
  ret void
}
*** IR Dump After SROAPass on _QQmain ***
define void @_QQmain() local_unnamed_addr {
entry:
  %structArg = alloca { ptr, ptr, ptr }, align 8
  %0 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %1 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %2 = alloca i32, align 4
  store i32 1048576, ptr %2, align 4, !tbaa !4
  %3 = tail call dereferenceable_or_null(8388608) ptr @malloc(i64 8388608)
  store ptr %3, ptr @_QFEarr.0, align 8, !tbaa !8
  store i1 true, ptr @_QFEarr.8, align 1
  %omp_global_thread_num = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %2, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %1, ptr %gep_5, align 8
  %gep_6 = getelementptr inbounds { ptr, ptr, ptr }, ptr %structArg, i64 0, i32 2
  store ptr %0, ptr %gep_6, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QQmain..omp_par, ptr nonnull %structArg)
  %4 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.60ea5a38555821a77357f87d16df9a0f, i32 21)
  %5 = call i1 @_FortranAioOutputAscii(ptr %4, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %6 = load i32, ptr %2, align 4, !tbaa !4
  %7 = call i1 @_FortranAioOutputInteger32(ptr %4, i32 %6)
  %8 = call i1 @_FortranAioOutputAscii(ptr %4, ptr nonnull @_QQcl.2920697320, i64 5)
  %.unpack = load ptr, ptr @_QFEarr.0, align 8, !tbaa !8
  %9 = load double, ptr %.unpack, align 8, !tbaa !4
  %10 = load i32, ptr %2, align 4, !tbaa !4
  %11 = sext i32 %10 to i64
  %12 = add nsw i64 %11, -1
  %13 = getelementptr double, ptr %.unpack, i64 %12
  %14 = load double, ptr %13, align 8, !tbaa !4
  %15 = fadd contract double %9, %14
  %16 = call i1 @_FortranAioOutputReal64(ptr %4, double %15)
  %17 = call i32 @_FortranAioEndIoStatement(ptr %4)
  %.unpack101 = load ptr, ptr @_QFEarr.0, align 8, !tbaa !8
  call void @free(ptr %.unpack101)
  store ptr null, ptr @_QFEarr.0, align 8, !tbaa !8
  store i1 false, ptr @_QFEarr.8, align 1
  ret void
}
*** IR Dump After InstCombinePass on _QQmain ***
define void @_QQmain() local_unnamed_addr {
entry:
  %structArg = alloca { ptr, ptr, ptr }, align 8
  %0 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %1 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %2 = alloca i32, align 4
  store i32 1048576, ptr %2, align 4, !tbaa !4
  %3 = tail call dereferenceable_or_null(8388608) ptr @malloc(i64 8388608)
  store ptr %3, ptr @_QFEarr.0, align 8, !tbaa !8
  store i1 true, ptr @_QFEarr.8, align 1
  %omp_global_thread_num = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %2, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %1, ptr %gep_5, align 8
  %gep_6 = getelementptr inbounds { ptr, ptr, ptr }, ptr %structArg, i64 0, i32 2
  store ptr %0, ptr %gep_6, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QQmain..omp_par, ptr nonnull %structArg)
  %4 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.60ea5a38555821a77357f87d16df9a0f, i32 21)
  %5 = call i1 @_FortranAioOutputAscii(ptr %4, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %6 = load i32, ptr %2, align 4, !tbaa !4
  %7 = call i1 @_FortranAioOutputInteger32(ptr %4, i32 %6)
  %8 = call i1 @_FortranAioOutputAscii(ptr %4, ptr nonnull @_QQcl.2920697320, i64 5)
  %.unpack = load ptr, ptr @_QFEarr.0, align 8, !tbaa !8
  %9 = load double, ptr %.unpack, align 8, !tbaa !4
  %10 = load i32, ptr %2, align 4, !tbaa !4
  %11 = sext i32 %10 to i64
  %12 = add nsw i64 %11, -1
  %13 = getelementptr double, ptr %.unpack, i64 %12
  %14 = load double, ptr %13, align 8, !tbaa !4
  %15 = fadd contract double %9, %14
  %16 = call i1 @_FortranAioOutputReal64(ptr %4, double %15)
  %17 = call i32 @_FortranAioEndIoStatement(ptr %4)
  %.unpack101 = load ptr, ptr @_QFEarr.0, align 8, !tbaa !8
  call void @free(ptr %.unpack101)
  store ptr null, ptr @_QFEarr.0, align 8, !tbaa !8
  store i1 false, ptr @_QFEarr.8, align 1
  ret void
}
*** IR Dump After LoopSimplifyPass on _QQmain ***
define void @_QQmain() local_unnamed_addr {
entry:
  %structArg = alloca { ptr, ptr, ptr }, align 8
  %0 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %1 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %2 = alloca i32, align 4
  store i32 1048576, ptr %2, align 4, !tbaa !4
  %3 = tail call dereferenceable_or_null(8388608) ptr @malloc(i64 8388608)
  store ptr %3, ptr @_QFEarr.0, align 8, !tbaa !8
  store i1 true, ptr @_QFEarr.8, align 1
  %omp_global_thread_num = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %2, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %1, ptr %gep_5, align 8
  %gep_6 = getelementptr inbounds { ptr, ptr, ptr }, ptr %structArg, i64 0, i32 2
  store ptr %0, ptr %gep_6, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QQmain..omp_par, ptr nonnull %structArg)
  %4 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.60ea5a38555821a77357f87d16df9a0f, i32 21)
  %5 = call i1 @_FortranAioOutputAscii(ptr %4, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %6 = load i32, ptr %2, align 4, !tbaa !4
  %7 = call i1 @_FortranAioOutputInteger32(ptr %4, i32 %6)
  %8 = call i1 @_FortranAioOutputAscii(ptr %4, ptr nonnull @_QQcl.2920697320, i64 5)
  %.unpack = load ptr, ptr @_QFEarr.0, align 8, !tbaa !8
  %9 = load double, ptr %.unpack, align 8, !tbaa !4
  %10 = load i32, ptr %2, align 4, !tbaa !4
  %11 = sext i32 %10 to i64
  %12 = add nsw i64 %11, -1
  %13 = getelementptr double, ptr %.unpack, i64 %12
  %14 = load double, ptr %13, align 8, !tbaa !4
  %15 = fadd contract double %9, %14
  %16 = call i1 @_FortranAioOutputReal64(ptr %4, double %15)
  %17 = call i32 @_FortranAioEndIoStatement(ptr %4)
  %.unpack101 = load ptr, ptr @_QFEarr.0, align 8, !tbaa !8
  call void @free(ptr %.unpack101)
  store ptr null, ptr @_QFEarr.0, align 8, !tbaa !8
  store i1 false, ptr @_QFEarr.8, align 1
  ret void
}
*** IR Dump After LCSSAPass on _QQmain ***
define void @_QQmain() local_unnamed_addr {
entry:
  %structArg = alloca { ptr, ptr, ptr }, align 8
  %0 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %1 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %2 = alloca i32, align 4
  store i32 1048576, ptr %2, align 4, !tbaa !4
  %3 = tail call dereferenceable_or_null(8388608) ptr @malloc(i64 8388608)
  store ptr %3, ptr @_QFEarr.0, align 8, !tbaa !8
  store i1 true, ptr @_QFEarr.8, align 1
  %omp_global_thread_num = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %2, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %1, ptr %gep_5, align 8
  %gep_6 = getelementptr inbounds { ptr, ptr, ptr }, ptr %structArg, i64 0, i32 2
  store ptr %0, ptr %gep_6, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QQmain..omp_par, ptr nonnull %structArg)
  %4 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.60ea5a38555821a77357f87d16df9a0f, i32 21)
  %5 = call i1 @_FortranAioOutputAscii(ptr %4, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %6 = load i32, ptr %2, align 4, !tbaa !4
  %7 = call i1 @_FortranAioOutputInteger32(ptr %4, i32 %6)
  %8 = call i1 @_FortranAioOutputAscii(ptr %4, ptr nonnull @_QQcl.2920697320, i64 5)
  %.unpack = load ptr, ptr @_QFEarr.0, align 8, !tbaa !8
  %9 = load double, ptr %.unpack, align 8, !tbaa !4
  %10 = load i32, ptr %2, align 4, !tbaa !4
  %11 = sext i32 %10 to i64
  %12 = add nsw i64 %11, -1
  %13 = getelementptr double, ptr %.unpack, i64 %12
  %14 = load double, ptr %13, align 8, !tbaa !4
  %15 = fadd contract double %9, %14
  %16 = call i1 @_FortranAioOutputReal64(ptr %4, double %15)
  %17 = call i32 @_FortranAioEndIoStatement(ptr %4)
  %.unpack101 = load ptr, ptr @_QFEarr.0, align 8, !tbaa !8
  call void @free(ptr %.unpack101)
  store ptr null, ptr @_QFEarr.0, align 8, !tbaa !8
  store i1 false, ptr @_QFEarr.8, align 1
  ret void
}
*** IR Dump After AlignmentFromAssumptionsPass on _QQmain ***
define void @_QQmain() local_unnamed_addr {
entry:
  %structArg = alloca { ptr, ptr, ptr }, align 8
  %0 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %1 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %2 = alloca i32, align 4
  store i32 1048576, ptr %2, align 4, !tbaa !4
  %3 = tail call dereferenceable_or_null(8388608) ptr @malloc(i64 8388608)
  store ptr %3, ptr @_QFEarr.0, align 8, !tbaa !8
  store i1 true, ptr @_QFEarr.8, align 1
  %omp_global_thread_num = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %2, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %1, ptr %gep_5, align 8
  %gep_6 = getelementptr inbounds { ptr, ptr, ptr }, ptr %structArg, i64 0, i32 2
  store ptr %0, ptr %gep_6, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QQmain..omp_par, ptr nonnull %structArg)
  %4 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.60ea5a38555821a77357f87d16df9a0f, i32 21)
  %5 = call i1 @_FortranAioOutputAscii(ptr %4, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %6 = load i32, ptr %2, align 4, !tbaa !4
  %7 = call i1 @_FortranAioOutputInteger32(ptr %4, i32 %6)
  %8 = call i1 @_FortranAioOutputAscii(ptr %4, ptr nonnull @_QQcl.2920697320, i64 5)
  %.unpack = load ptr, ptr @_QFEarr.0, align 8, !tbaa !8
  %9 = load double, ptr %.unpack, align 8, !tbaa !4
  %10 = load i32, ptr %2, align 4, !tbaa !4
  %11 = sext i32 %10 to i64
  %12 = add nsw i64 %11, -1
  %13 = getelementptr double, ptr %.unpack, i64 %12
  %14 = load double, ptr %13, align 8, !tbaa !4
  %15 = fadd contract double %9, %14
  %16 = call i1 @_FortranAioOutputReal64(ptr %4, double %15)
  %17 = call i32 @_FortranAioEndIoStatement(ptr %4)
  %.unpack101 = load ptr, ptr @_QFEarr.0, align 8, !tbaa !8
  call void @free(ptr %.unpack101)
  store ptr null, ptr @_QFEarr.0, align 8, !tbaa !8
  store i1 false, ptr @_QFEarr.8, align 1
  ret void
}
*** IR Dump After LoopSinkPass on _QQmain ***
define void @_QQmain() local_unnamed_addr {
entry:
  %structArg = alloca { ptr, ptr, ptr }, align 8
  %0 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %1 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %2 = alloca i32, align 4
  store i32 1048576, ptr %2, align 4, !tbaa !4
  %3 = tail call dereferenceable_or_null(8388608) ptr @malloc(i64 8388608)
  store ptr %3, ptr @_QFEarr.0, align 8, !tbaa !8
  store i1 true, ptr @_QFEarr.8, align 1
  %omp_global_thread_num = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %2, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %1, ptr %gep_5, align 8
  %gep_6 = getelementptr inbounds { ptr, ptr, ptr }, ptr %structArg, i64 0, i32 2
  store ptr %0, ptr %gep_6, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QQmain..omp_par, ptr nonnull %structArg)
  %4 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.60ea5a38555821a77357f87d16df9a0f, i32 21)
  %5 = call i1 @_FortranAioOutputAscii(ptr %4, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %6 = load i32, ptr %2, align 4, !tbaa !4
  %7 = call i1 @_FortranAioOutputInteger32(ptr %4, i32 %6)
  %8 = call i1 @_FortranAioOutputAscii(ptr %4, ptr nonnull @_QQcl.2920697320, i64 5)
  %.unpack = load ptr, ptr @_QFEarr.0, align 8, !tbaa !8
  %9 = load double, ptr %.unpack, align 8, !tbaa !4
  %10 = load i32, ptr %2, align 4, !tbaa !4
  %11 = sext i32 %10 to i64
  %12 = add nsw i64 %11, -1
  %13 = getelementptr double, ptr %.unpack, i64 %12
  %14 = load double, ptr %13, align 8, !tbaa !4
  %15 = fadd contract double %9, %14
  %16 = call i1 @_FortranAioOutputReal64(ptr %4, double %15)
  %17 = call i32 @_FortranAioEndIoStatement(ptr %4)
  %.unpack101 = load ptr, ptr @_QFEarr.0, align 8, !tbaa !8
  call void @free(ptr %.unpack101)
  store ptr null, ptr @_QFEarr.0, align 8, !tbaa !8
  store i1 false, ptr @_QFEarr.8, align 1
  ret void
}
*** IR Dump After InstSimplifyPass on _QQmain ***
define void @_QQmain() local_unnamed_addr {
entry:
  %structArg = alloca { ptr, ptr, ptr }, align 8
  %0 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %1 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %2 = alloca i32, align 4
  store i32 1048576, ptr %2, align 4, !tbaa !4
  %3 = tail call dereferenceable_or_null(8388608) ptr @malloc(i64 8388608)
  store ptr %3, ptr @_QFEarr.0, align 8, !tbaa !8
  store i1 true, ptr @_QFEarr.8, align 1
  %omp_global_thread_num = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %2, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %1, ptr %gep_5, align 8
  %gep_6 = getelementptr inbounds { ptr, ptr, ptr }, ptr %structArg, i64 0, i32 2
  store ptr %0, ptr %gep_6, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QQmain..omp_par, ptr nonnull %structArg)
  %4 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.60ea5a38555821a77357f87d16df9a0f, i32 21)
  %5 = call i1 @_FortranAioOutputAscii(ptr %4, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %6 = load i32, ptr %2, align 4, !tbaa !4
  %7 = call i1 @_FortranAioOutputInteger32(ptr %4, i32 %6)
  %8 = call i1 @_FortranAioOutputAscii(ptr %4, ptr nonnull @_QQcl.2920697320, i64 5)
  %.unpack = load ptr, ptr @_QFEarr.0, align 8, !tbaa !8
  %9 = load double, ptr %.unpack, align 8, !tbaa !4
  %10 = load i32, ptr %2, align 4, !tbaa !4
  %11 = sext i32 %10 to i64
  %12 = add nsw i64 %11, -1
  %13 = getelementptr double, ptr %.unpack, i64 %12
  %14 = load double, ptr %13, align 8, !tbaa !4
  %15 = fadd contract double %9, %14
  %16 = call i1 @_FortranAioOutputReal64(ptr %4, double %15)
  %17 = call i32 @_FortranAioEndIoStatement(ptr %4)
  %.unpack101 = load ptr, ptr @_QFEarr.0, align 8, !tbaa !8
  call void @free(ptr %.unpack101)
  store ptr null, ptr @_QFEarr.0, align 8, !tbaa !8
  store i1 false, ptr @_QFEarr.8, align 1
  ret void
}
*** IR Dump After DivRemPairsPass on _QQmain ***
define void @_QQmain() local_unnamed_addr {
entry:
  %structArg = alloca { ptr, ptr, ptr }, align 8
  %0 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %1 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %2 = alloca i32, align 4
  store i32 1048576, ptr %2, align 4, !tbaa !4
  %3 = tail call dereferenceable_or_null(8388608) ptr @malloc(i64 8388608)
  store ptr %3, ptr @_QFEarr.0, align 8, !tbaa !8
  store i1 true, ptr @_QFEarr.8, align 1
  %omp_global_thread_num = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %2, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %1, ptr %gep_5, align 8
  %gep_6 = getelementptr inbounds { ptr, ptr, ptr }, ptr %structArg, i64 0, i32 2
  store ptr %0, ptr %gep_6, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QQmain..omp_par, ptr nonnull %structArg)
  %4 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.60ea5a38555821a77357f87d16df9a0f, i32 21)
  %5 = call i1 @_FortranAioOutputAscii(ptr %4, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %6 = load i32, ptr %2, align 4, !tbaa !4
  %7 = call i1 @_FortranAioOutputInteger32(ptr %4, i32 %6)
  %8 = call i1 @_FortranAioOutputAscii(ptr %4, ptr nonnull @_QQcl.2920697320, i64 5)
  %.unpack = load ptr, ptr @_QFEarr.0, align 8, !tbaa !8
  %9 = load double, ptr %.unpack, align 8, !tbaa !4
  %10 = load i32, ptr %2, align 4, !tbaa !4
  %11 = sext i32 %10 to i64
  %12 = add nsw i64 %11, -1
  %13 = getelementptr double, ptr %.unpack, i64 %12
  %14 = load double, ptr %13, align 8, !tbaa !4
  %15 = fadd contract double %9, %14
  %16 = call i1 @_FortranAioOutputReal64(ptr %4, double %15)
  %17 = call i32 @_FortranAioEndIoStatement(ptr %4)
  %.unpack101 = load ptr, ptr @_QFEarr.0, align 8, !tbaa !8
  call void @free(ptr %.unpack101)
  store ptr null, ptr @_QFEarr.0, align 8, !tbaa !8
  store i1 false, ptr @_QFEarr.8, align 1
  ret void
}
*** IR Dump After TailCallElimPass on _QQmain ***
define void @_QQmain() local_unnamed_addr {
entry:
  %structArg = alloca { ptr, ptr, ptr }, align 8
  %0 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %1 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %2 = alloca i32, align 4
  store i32 1048576, ptr %2, align 4, !tbaa !4
  %3 = tail call dereferenceable_or_null(8388608) ptr @malloc(i64 8388608)
  store ptr %3, ptr @_QFEarr.0, align 8, !tbaa !8
  store i1 true, ptr @_QFEarr.8, align 1
  %omp_global_thread_num = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %2, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %1, ptr %gep_5, align 8
  %gep_6 = getelementptr inbounds { ptr, ptr, ptr }, ptr %structArg, i64 0, i32 2
  store ptr %0, ptr %gep_6, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QQmain..omp_par, ptr nonnull %structArg)
  %4 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.60ea5a38555821a77357f87d16df9a0f, i32 21)
  %5 = call i1 @_FortranAioOutputAscii(ptr %4, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %6 = load i32, ptr %2, align 4, !tbaa !4
  %7 = call i1 @_FortranAioOutputInteger32(ptr %4, i32 %6)
  %8 = call i1 @_FortranAioOutputAscii(ptr %4, ptr nonnull @_QQcl.2920697320, i64 5)
  %.unpack = load ptr, ptr @_QFEarr.0, align 8, !tbaa !8
  %9 = load double, ptr %.unpack, align 8, !tbaa !4
  %10 = load i32, ptr %2, align 4, !tbaa !4
  %11 = sext i32 %10 to i64
  %12 = add nsw i64 %11, -1
  %13 = getelementptr double, ptr %.unpack, i64 %12
  %14 = load double, ptr %13, align 8, !tbaa !4
  %15 = fadd contract double %9, %14
  %16 = call i1 @_FortranAioOutputReal64(ptr %4, double %15)
  %17 = call i32 @_FortranAioEndIoStatement(ptr %4)
  %.unpack101 = load ptr, ptr @_QFEarr.0, align 8, !tbaa !8
  call void @free(ptr %.unpack101)
  store ptr null, ptr @_QFEarr.0, align 8, !tbaa !8
  store i1 false, ptr @_QFEarr.8, align 1
  ret void
}
*** IR Dump After SimplifyCFGPass on _QQmain ***
define void @_QQmain() local_unnamed_addr {
entry:
  %structArg = alloca { ptr, ptr, ptr }, align 8
  %0 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %1 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %2 = alloca i32, align 4
  store i32 1048576, ptr %2, align 4, !tbaa !4
  %3 = tail call dereferenceable_or_null(8388608) ptr @malloc(i64 8388608)
  store ptr %3, ptr @_QFEarr.0, align 8, !tbaa !8
  store i1 true, ptr @_QFEarr.8, align 1
  %omp_global_thread_num = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %2, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %1, ptr %gep_5, align 8
  %gep_6 = getelementptr inbounds { ptr, ptr, ptr }, ptr %structArg, i64 0, i32 2
  store ptr %0, ptr %gep_6, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QQmain..omp_par, ptr nonnull %structArg)
  %4 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.60ea5a38555821a77357f87d16df9a0f, i32 21)
  %5 = call i1 @_FortranAioOutputAscii(ptr %4, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %6 = load i32, ptr %2, align 4, !tbaa !4
  %7 = call i1 @_FortranAioOutputInteger32(ptr %4, i32 %6)
  %8 = call i1 @_FortranAioOutputAscii(ptr %4, ptr nonnull @_QQcl.2920697320, i64 5)
  %.unpack = load ptr, ptr @_QFEarr.0, align 8, !tbaa !8
  %9 = load double, ptr %.unpack, align 8, !tbaa !4
  %10 = load i32, ptr %2, align 4, !tbaa !4
  %11 = sext i32 %10 to i64
  %12 = add nsw i64 %11, -1
  %13 = getelementptr double, ptr %.unpack, i64 %12
  %14 = load double, ptr %13, align 8, !tbaa !4
  %15 = fadd contract double %9, %14
  %16 = call i1 @_FortranAioOutputReal64(ptr %4, double %15)
  %17 = call i32 @_FortranAioEndIoStatement(ptr %4)
  %.unpack101 = load ptr, ptr @_QFEarr.0, align 8, !tbaa !8
  call void @free(ptr %.unpack101)
  store ptr null, ptr @_QFEarr.0, align 8, !tbaa !8
  store i1 false, ptr @_QFEarr.8, align 1
  ret void
}
*** IR Dump After Float2IntPass on _QQmain..omp_par ***
; Function Attrs: norecurse nounwind
define internal void @_QQmain..omp_par(ptr noalias nocapture readnone %tid.addr, ptr noalias nocapture readnone %zero.addr, ptr nocapture readonly %0) #2 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %gep_3 = getelementptr { ptr, ptr, ptr }, ptr %0, i64 0, i32 2
  %loadgep_4 = load ptr, ptr %gep_3, align 8
  %p.lastiter = alloca i32, align 4
  %p.lowerbound = alloca i32, align 4
  %p.upperbound = alloca i32, align 4
  %p.stride = alloca i32, align 4
  %1 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %omp_loop.tripcount = tail call i32 @llvm.smax.i32(i32 %1, i32 0)
  store i32 0, ptr %p.lowerbound, align 4
  %2 = add nsw i32 %omp_loop.tripcount, -1
  store i32 %2, ptr %p.upperbound, align 4
  store i32 1, ptr %p.stride, align 4
  %omp_global_thread_num4 = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  call void @__kmpc_for_static_init_4u(ptr nonnull @1, i32 %omp_global_thread_num4, i32 34, ptr nonnull %p.lastiter, ptr nonnull %p.lowerbound, ptr nonnull %p.upperbound, ptr nonnull %p.stride, i32 1, i32 0)
  %3 = load i32, ptr %p.lowerbound, align 4
  %4 = load i32, ptr %p.upperbound, align 4
  %reass.sub = sub i32 %4, %3
  %omp_loop.cmp65.not = icmp eq i32 %reass.sub, -1
  br i1 %omp_loop.cmp65.not, label %omp_loop.exit, label %omp_loop.body.lr.ph

omp_loop.body.lr.ph:                              ; preds = %omp.par.entry
  %.unpack = load ptr, ptr @_QFEarr.0, align 8, !tbaa !8
  %.unpack12.unpack.unpack14.b = load i1, ptr @_QFEarr.8, align 1
  %.unpack12.unpack.unpack14 = select i1 %.unpack12.unpack.unpack14.b, i64 1048576, i64 0
  %loadgep_2.repack17 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  %loadgep_2.repack19 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  %loadgep_2.repack21 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  %loadgep_2.repack23 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  %loadgep_2.repack25 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  %loadgep_2.repack27 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  %loadgep_2.repack29 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  %loadgep_2.repack29.repack31 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  %loadgep_2.repack29.repack33 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  %loadgep_4.repack47 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 1
  %loadgep_4.repack49 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 2
  %loadgep_4.repack51 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 3
  %loadgep_4.repack53 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 4
  %loadgep_4.repack55 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 5
  %loadgep_4.repack57 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 6
  %loadgep_4.repack59 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7
  %loadgep_4.repack59.repack61 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 1
  %loadgep_4.repack59.repack63 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 2
  br label %omp_loop.body

omp_loop.exit:                                    ; preds = %omp_loop.body, %omp.par.entry
  call void @__kmpc_for_static_fini(ptr nonnull @1, i32 %omp_global_thread_num4)
  call void @__kmpc_barrier(ptr nonnull @2, i32 %omp_global_thread_num4)
  ret void

omp_loop.body:                                    ; preds = %omp_loop.body.lr.ph, %omp_loop.body
  %omp_loop.iv66 = phi i32 [ 0, %omp_loop.body.lr.ph ], [ %5, %omp_loop.body ]
  %5 = add nuw i32 %omp_loop.iv66, 1
  %6 = add i32 %5, %3
  %7 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %8 = sitofp i32 %7 to float
  %9 = fdiv contract float 1.000000e+00, %8
  %10 = fpext float %9 to double
  store ptr %.unpack, ptr %loadgep_2, align 8, !tbaa !8
  store i64 8, ptr %loadgep_2.repack17, align 8, !tbaa !8
  store i32 20180515, ptr %loadgep_2.repack19, align 8, !tbaa !8
  store i8 1, ptr %loadgep_2.repack21, align 4, !tbaa !8
  store i8 28, ptr %loadgep_2.repack23, align 1, !tbaa !8
  store i8 2, ptr %loadgep_2.repack25, align 2, !tbaa !8
  store i8 0, ptr %loadgep_2.repack27, align 1, !tbaa !8
  store i64 1, ptr %loadgep_2.repack29, align 8, !tbaa !8
  store i64 %.unpack12.unpack.unpack14, ptr %loadgep_2.repack29.repack31, align 8, !tbaa !8
  store i64 8, ptr %loadgep_2.repack29.repack33, align 8, !tbaa !8
  %11 = sext i32 %6 to i64
  %12 = sub i64 %11, 1
  %13 = getelementptr double, ptr %.unpack, i64 %12
  store double %10, ptr %13, align 8, !tbaa !4
  store ptr %.unpack, ptr %loadgep_4, align 8, !tbaa !8
  store i64 8, ptr %loadgep_4.repack47, align 8, !tbaa !8
  store i32 20180515, ptr %loadgep_4.repack49, align 8, !tbaa !8
  store i8 1, ptr %loadgep_4.repack51, align 4, !tbaa !8
  store i8 28, ptr %loadgep_4.repack53, align 1, !tbaa !8
  store i8 2, ptr %loadgep_4.repack55, align 2, !tbaa !8
  store i8 0, ptr %loadgep_4.repack57, align 1, !tbaa !8
  store i64 1, ptr %loadgep_4.repack59, align 8, !tbaa !8
  store i64 %.unpack12.unpack.unpack14, ptr %loadgep_4.repack59.repack61, align 8, !tbaa !8
  store i64 8, ptr %loadgep_4.repack59.repack63, align 8, !tbaa !8
  %exitcond.not = icmp eq i32 %omp_loop.iv66, %reass.sub
  br i1 %exitcond.not, label %omp_loop.exit, label %omp_loop.body
}
*** IR Dump After LowerConstantIntrinsicsPass on _QQmain..omp_par ***
; Function Attrs: norecurse nounwind
define internal void @_QQmain..omp_par(ptr noalias nocapture readnone %tid.addr, ptr noalias nocapture readnone %zero.addr, ptr nocapture readonly %0) #2 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %gep_3 = getelementptr { ptr, ptr, ptr }, ptr %0, i64 0, i32 2
  %loadgep_4 = load ptr, ptr %gep_3, align 8
  %p.lastiter = alloca i32, align 4
  %p.lowerbound = alloca i32, align 4
  %p.upperbound = alloca i32, align 4
  %p.stride = alloca i32, align 4
  %1 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %omp_loop.tripcount = tail call i32 @llvm.smax.i32(i32 %1, i32 0)
  store i32 0, ptr %p.lowerbound, align 4
  %2 = add nsw i32 %omp_loop.tripcount, -1
  store i32 %2, ptr %p.upperbound, align 4
  store i32 1, ptr %p.stride, align 4
  %omp_global_thread_num4 = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  call void @__kmpc_for_static_init_4u(ptr nonnull @1, i32 %omp_global_thread_num4, i32 34, ptr nonnull %p.lastiter, ptr nonnull %p.lowerbound, ptr nonnull %p.upperbound, ptr nonnull %p.stride, i32 1, i32 0)
  %3 = load i32, ptr %p.lowerbound, align 4
  %4 = load i32, ptr %p.upperbound, align 4
  %reass.sub = sub i32 %4, %3
  %omp_loop.cmp65.not = icmp eq i32 %reass.sub, -1
  br i1 %omp_loop.cmp65.not, label %omp_loop.exit, label %omp_loop.body.lr.ph

omp_loop.body.lr.ph:                              ; preds = %omp.par.entry
  %.unpack = load ptr, ptr @_QFEarr.0, align 8, !tbaa !8
  %.unpack12.unpack.unpack14.b = load i1, ptr @_QFEarr.8, align 1
  %.unpack12.unpack.unpack14 = select i1 %.unpack12.unpack.unpack14.b, i64 1048576, i64 0
  %loadgep_2.repack17 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  %loadgep_2.repack19 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  %loadgep_2.repack21 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  %loadgep_2.repack23 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  %loadgep_2.repack25 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  %loadgep_2.repack27 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  %loadgep_2.repack29 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  %loadgep_2.repack29.repack31 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  %loadgep_2.repack29.repack33 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  %loadgep_4.repack47 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 1
  %loadgep_4.repack49 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 2
  %loadgep_4.repack51 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 3
  %loadgep_4.repack53 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 4
  %loadgep_4.repack55 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 5
  %loadgep_4.repack57 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 6
  %loadgep_4.repack59 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7
  %loadgep_4.repack59.repack61 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 1
  %loadgep_4.repack59.repack63 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 2
  br label %omp_loop.body

omp_loop.exit:                                    ; preds = %omp_loop.body, %omp.par.entry
  call void @__kmpc_for_static_fini(ptr nonnull @1, i32 %omp_global_thread_num4)
  call void @__kmpc_barrier(ptr nonnull @2, i32 %omp_global_thread_num4)
  ret void

omp_loop.body:                                    ; preds = %omp_loop.body.lr.ph, %omp_loop.body
  %omp_loop.iv66 = phi i32 [ 0, %omp_loop.body.lr.ph ], [ %5, %omp_loop.body ]
  %5 = add nuw i32 %omp_loop.iv66, 1
  %6 = add i32 %5, %3
  %7 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %8 = sitofp i32 %7 to float
  %9 = fdiv contract float 1.000000e+00, %8
  %10 = fpext float %9 to double
  store ptr %.unpack, ptr %loadgep_2, align 8, !tbaa !8
  store i64 8, ptr %loadgep_2.repack17, align 8, !tbaa !8
  store i32 20180515, ptr %loadgep_2.repack19, align 8, !tbaa !8
  store i8 1, ptr %loadgep_2.repack21, align 4, !tbaa !8
  store i8 28, ptr %loadgep_2.repack23, align 1, !tbaa !8
  store i8 2, ptr %loadgep_2.repack25, align 2, !tbaa !8
  store i8 0, ptr %loadgep_2.repack27, align 1, !tbaa !8
  store i64 1, ptr %loadgep_2.repack29, align 8, !tbaa !8
  store i64 %.unpack12.unpack.unpack14, ptr %loadgep_2.repack29.repack31, align 8, !tbaa !8
  store i64 8, ptr %loadgep_2.repack29.repack33, align 8, !tbaa !8
  %11 = sext i32 %6 to i64
  %12 = sub i64 %11, 1
  %13 = getelementptr double, ptr %.unpack, i64 %12
  store double %10, ptr %13, align 8, !tbaa !4
  store ptr %.unpack, ptr %loadgep_4, align 8, !tbaa !8
  store i64 8, ptr %loadgep_4.repack47, align 8, !tbaa !8
  store i32 20180515, ptr %loadgep_4.repack49, align 8, !tbaa !8
  store i8 1, ptr %loadgep_4.repack51, align 4, !tbaa !8
  store i8 28, ptr %loadgep_4.repack53, align 1, !tbaa !8
  store i8 2, ptr %loadgep_4.repack55, align 2, !tbaa !8
  store i8 0, ptr %loadgep_4.repack57, align 1, !tbaa !8
  store i64 1, ptr %loadgep_4.repack59, align 8, !tbaa !8
  store i64 %.unpack12.unpack.unpack14, ptr %loadgep_4.repack59.repack61, align 8, !tbaa !8
  store i64 8, ptr %loadgep_4.repack59.repack63, align 8, !tbaa !8
  %exitcond.not = icmp eq i32 %omp_loop.iv66, %reass.sub
  br i1 %exitcond.not, label %omp_loop.exit, label %omp_loop.body
}
*** IR Dump After ControlHeightReductionPass on _QQmain..omp_par ***
; Function Attrs: norecurse nounwind
define internal void @_QQmain..omp_par(ptr noalias nocapture readnone %tid.addr, ptr noalias nocapture readnone %zero.addr, ptr nocapture readonly %0) #2 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %gep_3 = getelementptr { ptr, ptr, ptr }, ptr %0, i64 0, i32 2
  %loadgep_4 = load ptr, ptr %gep_3, align 8
  %p.lastiter = alloca i32, align 4
  %p.lowerbound = alloca i32, align 4
  %p.upperbound = alloca i32, align 4
  %p.stride = alloca i32, align 4
  %1 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %omp_loop.tripcount = tail call i32 @llvm.smax.i32(i32 %1, i32 0)
  store i32 0, ptr %p.lowerbound, align 4
  %2 = add nsw i32 %omp_loop.tripcount, -1
  store i32 %2, ptr %p.upperbound, align 4
  store i32 1, ptr %p.stride, align 4
  %omp_global_thread_num4 = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  call void @__kmpc_for_static_init_4u(ptr nonnull @1, i32 %omp_global_thread_num4, i32 34, ptr nonnull %p.lastiter, ptr nonnull %p.lowerbound, ptr nonnull %p.upperbound, ptr nonnull %p.stride, i32 1, i32 0)
  %3 = load i32, ptr %p.lowerbound, align 4
  %4 = load i32, ptr %p.upperbound, align 4
  %reass.sub = sub i32 %4, %3
  %omp_loop.cmp65.not = icmp eq i32 %reass.sub, -1
  br i1 %omp_loop.cmp65.not, label %omp_loop.exit, label %omp_loop.body.lr.ph

omp_loop.body.lr.ph:                              ; preds = %omp.par.entry
  %.unpack = load ptr, ptr @_QFEarr.0, align 8, !tbaa !8
  %.unpack12.unpack.unpack14.b = load i1, ptr @_QFEarr.8, align 1
  %.unpack12.unpack.unpack14 = select i1 %.unpack12.unpack.unpack14.b, i64 1048576, i64 0
  %loadgep_2.repack17 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  %loadgep_2.repack19 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  %loadgep_2.repack21 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  %loadgep_2.repack23 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  %loadgep_2.repack25 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  %loadgep_2.repack27 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  %loadgep_2.repack29 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  %loadgep_2.repack29.repack31 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  %loadgep_2.repack29.repack33 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  %loadgep_4.repack47 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 1
  %loadgep_4.repack49 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 2
  %loadgep_4.repack51 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 3
  %loadgep_4.repack53 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 4
  %loadgep_4.repack55 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 5
  %loadgep_4.repack57 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 6
  %loadgep_4.repack59 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7
  %loadgep_4.repack59.repack61 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 1
  %loadgep_4.repack59.repack63 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 2
  br label %omp_loop.body

omp_loop.exit:                                    ; preds = %omp_loop.body, %omp.par.entry
  call void @__kmpc_for_static_fini(ptr nonnull @1, i32 %omp_global_thread_num4)
  call void @__kmpc_barrier(ptr nonnull @2, i32 %omp_global_thread_num4)
  ret void

omp_loop.body:                                    ; preds = %omp_loop.body.lr.ph, %omp_loop.body
  %omp_loop.iv66 = phi i32 [ 0, %omp_loop.body.lr.ph ], [ %5, %omp_loop.body ]
  %5 = add nuw i32 %omp_loop.iv66, 1
  %6 = add i32 %5, %3
  %7 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %8 = sitofp i32 %7 to float
  %9 = fdiv contract float 1.000000e+00, %8
  %10 = fpext float %9 to double
  store ptr %.unpack, ptr %loadgep_2, align 8, !tbaa !8
  store i64 8, ptr %loadgep_2.repack17, align 8, !tbaa !8
  store i32 20180515, ptr %loadgep_2.repack19, align 8, !tbaa !8
  store i8 1, ptr %loadgep_2.repack21, align 4, !tbaa !8
  store i8 28, ptr %loadgep_2.repack23, align 1, !tbaa !8
  store i8 2, ptr %loadgep_2.repack25, align 2, !tbaa !8
  store i8 0, ptr %loadgep_2.repack27, align 1, !tbaa !8
  store i64 1, ptr %loadgep_2.repack29, align 8, !tbaa !8
  store i64 %.unpack12.unpack.unpack14, ptr %loadgep_2.repack29.repack31, align 8, !tbaa !8
  store i64 8, ptr %loadgep_2.repack29.repack33, align 8, !tbaa !8
  %11 = sext i32 %6 to i64
  %12 = sub i64 %11, 1
  %13 = getelementptr double, ptr %.unpack, i64 %12
  store double %10, ptr %13, align 8, !tbaa !4
  store ptr %.unpack, ptr %loadgep_4, align 8, !tbaa !8
  store i64 8, ptr %loadgep_4.repack47, align 8, !tbaa !8
  store i32 20180515, ptr %loadgep_4.repack49, align 8, !tbaa !8
  store i8 1, ptr %loadgep_4.repack51, align 4, !tbaa !8
  store i8 28, ptr %loadgep_4.repack53, align 1, !tbaa !8
  store i8 2, ptr %loadgep_4.repack55, align 2, !tbaa !8
  store i8 0, ptr %loadgep_4.repack57, align 1, !tbaa !8
  store i64 1, ptr %loadgep_4.repack59, align 8, !tbaa !8
  store i64 %.unpack12.unpack.unpack14, ptr %loadgep_4.repack59.repack61, align 8, !tbaa !8
  store i64 8, ptr %loadgep_4.repack59.repack63, align 8, !tbaa !8
  %exitcond.not = icmp eq i32 %omp_loop.iv66, %reass.sub
  br i1 %exitcond.not, label %omp_loop.exit, label %omp_loop.body
}
*** IR Dump After LoopSimplifyPass on _QQmain..omp_par ***
; Function Attrs: norecurse nounwind
define internal void @_QQmain..omp_par(ptr noalias nocapture readnone %tid.addr, ptr noalias nocapture readnone %zero.addr, ptr nocapture readonly %0) #2 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %gep_3 = getelementptr { ptr, ptr, ptr }, ptr %0, i64 0, i32 2
  %loadgep_4 = load ptr, ptr %gep_3, align 8
  %p.lastiter = alloca i32, align 4
  %p.lowerbound = alloca i32, align 4
  %p.upperbound = alloca i32, align 4
  %p.stride = alloca i32, align 4
  %1 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %omp_loop.tripcount = tail call i32 @llvm.smax.i32(i32 %1, i32 0)
  store i32 0, ptr %p.lowerbound, align 4
  %2 = add nsw i32 %omp_loop.tripcount, -1
  store i32 %2, ptr %p.upperbound, align 4
  store i32 1, ptr %p.stride, align 4
  %omp_global_thread_num4 = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  call void @__kmpc_for_static_init_4u(ptr nonnull @1, i32 %omp_global_thread_num4, i32 34, ptr nonnull %p.lastiter, ptr nonnull %p.lowerbound, ptr nonnull %p.upperbound, ptr nonnull %p.stride, i32 1, i32 0)
  %3 = load i32, ptr %p.lowerbound, align 4
  %4 = load i32, ptr %p.upperbound, align 4
  %reass.sub = sub i32 %4, %3
  %omp_loop.cmp65.not = icmp eq i32 %reass.sub, -1
  br i1 %omp_loop.cmp65.not, label %omp_loop.exit, label %omp_loop.body.lr.ph

omp_loop.body.lr.ph:                              ; preds = %omp.par.entry
  %.unpack = load ptr, ptr @_QFEarr.0, align 8, !tbaa !8
  %.unpack12.unpack.unpack14.b = load i1, ptr @_QFEarr.8, align 1
  %.unpack12.unpack.unpack14 = select i1 %.unpack12.unpack.unpack14.b, i64 1048576, i64 0
  %loadgep_2.repack17 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  %loadgep_2.repack19 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  %loadgep_2.repack21 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  %loadgep_2.repack23 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  %loadgep_2.repack25 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  %loadgep_2.repack27 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  %loadgep_2.repack29 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  %loadgep_2.repack29.repack31 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  %loadgep_2.repack29.repack33 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  %loadgep_4.repack47 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 1
  %loadgep_4.repack49 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 2
  %loadgep_4.repack51 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 3
  %loadgep_4.repack53 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 4
  %loadgep_4.repack55 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 5
  %loadgep_4.repack57 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 6
  %loadgep_4.repack59 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7
  %loadgep_4.repack59.repack61 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 1
  %loadgep_4.repack59.repack63 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 2
  br label %omp_loop.body

omp_loop.exit.loopexit:                           ; preds = %omp_loop.body
  br label %omp_loop.exit

omp_loop.exit:                                    ; preds = %omp_loop.exit.loopexit, %omp.par.entry
  call void @__kmpc_for_static_fini(ptr nonnull @1, i32 %omp_global_thread_num4)
  call void @__kmpc_barrier(ptr nonnull @2, i32 %omp_global_thread_num4)
  ret void

omp_loop.body:                                    ; preds = %omp_loop.body.lr.ph, %omp_loop.body
  %omp_loop.iv66 = phi i32 [ 0, %omp_loop.body.lr.ph ], [ %5, %omp_loop.body ]
  %5 = add nuw i32 %omp_loop.iv66, 1
  %6 = add i32 %5, %3
  %7 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %8 = sitofp i32 %7 to float
  %9 = fdiv contract float 1.000000e+00, %8
  %10 = fpext float %9 to double
  store ptr %.unpack, ptr %loadgep_2, align 8, !tbaa !8
  store i64 8, ptr %loadgep_2.repack17, align 8, !tbaa !8
  store i32 20180515, ptr %loadgep_2.repack19, align 8, !tbaa !8
  store i8 1, ptr %loadgep_2.repack21, align 4, !tbaa !8
  store i8 28, ptr %loadgep_2.repack23, align 1, !tbaa !8
  store i8 2, ptr %loadgep_2.repack25, align 2, !tbaa !8
  store i8 0, ptr %loadgep_2.repack27, align 1, !tbaa !8
  store i64 1, ptr %loadgep_2.repack29, align 8, !tbaa !8
  store i64 %.unpack12.unpack.unpack14, ptr %loadgep_2.repack29.repack31, align 8, !tbaa !8
  store i64 8, ptr %loadgep_2.repack29.repack33, align 8, !tbaa !8
  %11 = sext i32 %6 to i64
  %12 = sub i64 %11, 1
  %13 = getelementptr double, ptr %.unpack, i64 %12
  store double %10, ptr %13, align 8, !tbaa !4
  store ptr %.unpack, ptr %loadgep_4, align 8, !tbaa !8
  store i64 8, ptr %loadgep_4.repack47, align 8, !tbaa !8
  store i32 20180515, ptr %loadgep_4.repack49, align 8, !tbaa !8
  store i8 1, ptr %loadgep_4.repack51, align 4, !tbaa !8
  store i8 28, ptr %loadgep_4.repack53, align 1, !tbaa !8
  store i8 2, ptr %loadgep_4.repack55, align 2, !tbaa !8
  store i8 0, ptr %loadgep_4.repack57, align 1, !tbaa !8
  store i64 1, ptr %loadgep_4.repack59, align 8, !tbaa !8
  store i64 %.unpack12.unpack.unpack14, ptr %loadgep_4.repack59.repack61, align 8, !tbaa !8
  store i64 8, ptr %loadgep_4.repack59.repack63, align 8, !tbaa !8
  %exitcond.not = icmp eq i32 %omp_loop.iv66, %reass.sub
  br i1 %exitcond.not, label %omp_loop.exit.loopexit, label %omp_loop.body
}
*** IR Dump After LCSSAPass on _QQmain..omp_par ***
; Function Attrs: norecurse nounwind
define internal void @_QQmain..omp_par(ptr noalias nocapture readnone %tid.addr, ptr noalias nocapture readnone %zero.addr, ptr nocapture readonly %0) #2 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %gep_3 = getelementptr { ptr, ptr, ptr }, ptr %0, i64 0, i32 2
  %loadgep_4 = load ptr, ptr %gep_3, align 8
  %p.lastiter = alloca i32, align 4
  %p.lowerbound = alloca i32, align 4
  %p.upperbound = alloca i32, align 4
  %p.stride = alloca i32, align 4
  %1 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %omp_loop.tripcount = tail call i32 @llvm.smax.i32(i32 %1, i32 0)
  store i32 0, ptr %p.lowerbound, align 4
  %2 = add nsw i32 %omp_loop.tripcount, -1
  store i32 %2, ptr %p.upperbound, align 4
  store i32 1, ptr %p.stride, align 4
  %omp_global_thread_num4 = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  call void @__kmpc_for_static_init_4u(ptr nonnull @1, i32 %omp_global_thread_num4, i32 34, ptr nonnull %p.lastiter, ptr nonnull %p.lowerbound, ptr nonnull %p.upperbound, ptr nonnull %p.stride, i32 1, i32 0)
  %3 = load i32, ptr %p.lowerbound, align 4
  %4 = load i32, ptr %p.upperbound, align 4
  %reass.sub = sub i32 %4, %3
  %omp_loop.cmp65.not = icmp eq i32 %reass.sub, -1
  br i1 %omp_loop.cmp65.not, label %omp_loop.exit, label %omp_loop.body.lr.ph

omp_loop.body.lr.ph:                              ; preds = %omp.par.entry
  %.unpack = load ptr, ptr @_QFEarr.0, align 8, !tbaa !8
  %.unpack12.unpack.unpack14.b = load i1, ptr @_QFEarr.8, align 1
  %.unpack12.unpack.unpack14 = select i1 %.unpack12.unpack.unpack14.b, i64 1048576, i64 0
  %loadgep_2.repack17 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  %loadgep_2.repack19 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  %loadgep_2.repack21 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  %loadgep_2.repack23 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  %loadgep_2.repack25 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  %loadgep_2.repack27 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  %loadgep_2.repack29 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  %loadgep_2.repack29.repack31 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  %loadgep_2.repack29.repack33 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  %loadgep_4.repack47 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 1
  %loadgep_4.repack49 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 2
  %loadgep_4.repack51 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 3
  %loadgep_4.repack53 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 4
  %loadgep_4.repack55 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 5
  %loadgep_4.repack57 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 6
  %loadgep_4.repack59 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7
  %loadgep_4.repack59.repack61 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 1
  %loadgep_4.repack59.repack63 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 2
  br label %omp_loop.body

omp_loop.exit.loopexit:                           ; preds = %omp_loop.body
  br label %omp_loop.exit

omp_loop.exit:                                    ; preds = %omp_loop.exit.loopexit, %omp.par.entry
  call void @__kmpc_for_static_fini(ptr nonnull @1, i32 %omp_global_thread_num4)
  call void @__kmpc_barrier(ptr nonnull @2, i32 %omp_global_thread_num4)
  ret void

omp_loop.body:                                    ; preds = %omp_loop.body.lr.ph, %omp_loop.body
  %omp_loop.iv66 = phi i32 [ 0, %omp_loop.body.lr.ph ], [ %5, %omp_loop.body ]
  %5 = add nuw i32 %omp_loop.iv66, 1
  %6 = add i32 %5, %3
  %7 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %8 = sitofp i32 %7 to float
  %9 = fdiv contract float 1.000000e+00, %8
  %10 = fpext float %9 to double
  store ptr %.unpack, ptr %loadgep_2, align 8, !tbaa !8
  store i64 8, ptr %loadgep_2.repack17, align 8, !tbaa !8
  store i32 20180515, ptr %loadgep_2.repack19, align 8, !tbaa !8
  store i8 1, ptr %loadgep_2.repack21, align 4, !tbaa !8
  store i8 28, ptr %loadgep_2.repack23, align 1, !tbaa !8
  store i8 2, ptr %loadgep_2.repack25, align 2, !tbaa !8
  store i8 0, ptr %loadgep_2.repack27, align 1, !tbaa !8
  store i64 1, ptr %loadgep_2.repack29, align 8, !tbaa !8
  store i64 %.unpack12.unpack.unpack14, ptr %loadgep_2.repack29.repack31, align 8, !tbaa !8
  store i64 8, ptr %loadgep_2.repack29.repack33, align 8, !tbaa !8
  %11 = sext i32 %6 to i64
  %12 = sub i64 %11, 1
  %13 = getelementptr double, ptr %.unpack, i64 %12
  store double %10, ptr %13, align 8, !tbaa !4
  store ptr %.unpack, ptr %loadgep_4, align 8, !tbaa !8
  store i64 8, ptr %loadgep_4.repack47, align 8, !tbaa !8
  store i32 20180515, ptr %loadgep_4.repack49, align 8, !tbaa !8
  store i8 1, ptr %loadgep_4.repack51, align 4, !tbaa !8
  store i8 28, ptr %loadgep_4.repack53, align 1, !tbaa !8
  store i8 2, ptr %loadgep_4.repack55, align 2, !tbaa !8
  store i8 0, ptr %loadgep_4.repack57, align 1, !tbaa !8
  store i64 1, ptr %loadgep_4.repack59, align 8, !tbaa !8
  store i64 %.unpack12.unpack.unpack14, ptr %loadgep_4.repack59.repack61, align 8, !tbaa !8
  store i64 8, ptr %loadgep_4.repack59.repack63, align 8, !tbaa !8
  %exitcond.not = icmp eq i32 %omp_loop.iv66, %reass.sub
  br i1 %exitcond.not, label %omp_loop.exit.loopexit, label %omp_loop.body
}
*** IR Dump After LoopRotatePass on omp_loop.body ***

; Preheader:
omp_loop.body.lr.ph:                              ; preds = %omp.par.entry
  %.unpack = load ptr, ptr @_QFEarr.0, align 8, !tbaa !8
  %.unpack12.unpack.unpack14.b = load i1, ptr @_QFEarr.8, align 1
  %.unpack12.unpack.unpack14 = select i1 %.unpack12.unpack.unpack14.b, i64 1048576, i64 0
  %loadgep_2.repack17 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  %loadgep_2.repack19 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  %loadgep_2.repack21 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  %loadgep_2.repack23 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  %loadgep_2.repack25 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  %loadgep_2.repack27 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  %loadgep_2.repack29 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  %loadgep_2.repack29.repack31 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  %loadgep_2.repack29.repack33 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  %loadgep_4.repack47 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 1
  %loadgep_4.repack49 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 2
  %loadgep_4.repack51 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 3
  %loadgep_4.repack53 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 4
  %loadgep_4.repack55 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 5
  %loadgep_4.repack57 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 6
  %loadgep_4.repack59 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7
  %loadgep_4.repack59.repack61 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 1
  %loadgep_4.repack59.repack63 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 2
  br label %omp_loop.body

; Loop:
omp_loop.body:                                    ; preds = %omp_loop.body.lr.ph, %omp_loop.body
  %omp_loop.iv66 = phi i32 [ 0, %omp_loop.body.lr.ph ], [ %5, %omp_loop.body ]
  %5 = add nuw i32 %omp_loop.iv66, 1
  %6 = add i32 %5, %3
  %7 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %8 = sitofp i32 %7 to float
  %9 = fdiv contract float 1.000000e+00, %8
  %10 = fpext float %9 to double
  store ptr %.unpack, ptr %loadgep_2, align 8, !tbaa !8
  store i64 8, ptr %loadgep_2.repack17, align 8, !tbaa !8
  store i32 20180515, ptr %loadgep_2.repack19, align 8, !tbaa !8
  store i8 1, ptr %loadgep_2.repack21, align 4, !tbaa !8
  store i8 28, ptr %loadgep_2.repack23, align 1, !tbaa !8
  store i8 2, ptr %loadgep_2.repack25, align 2, !tbaa !8
  store i8 0, ptr %loadgep_2.repack27, align 1, !tbaa !8
  store i64 1, ptr %loadgep_2.repack29, align 8, !tbaa !8
  store i64 %.unpack12.unpack.unpack14, ptr %loadgep_2.repack29.repack31, align 8, !tbaa !8
  store i64 8, ptr %loadgep_2.repack29.repack33, align 8, !tbaa !8
  %11 = sext i32 %6 to i64
  %12 = sub i64 %11, 1
  %13 = getelementptr double, ptr %.unpack, i64 %12
  store double %10, ptr %13, align 8, !tbaa !4
  store ptr %.unpack, ptr %loadgep_4, align 8, !tbaa !8
  store i64 8, ptr %loadgep_4.repack47, align 8, !tbaa !8
  store i32 20180515, ptr %loadgep_4.repack49, align 8, !tbaa !8
  store i8 1, ptr %loadgep_4.repack51, align 4, !tbaa !8
  store i8 28, ptr %loadgep_4.repack53, align 1, !tbaa !8
  store i8 2, ptr %loadgep_4.repack55, align 2, !tbaa !8
  store i8 0, ptr %loadgep_4.repack57, align 1, !tbaa !8
  store i64 1, ptr %loadgep_4.repack59, align 8, !tbaa !8
  store i64 %.unpack12.unpack.unpack14, ptr %loadgep_4.repack59.repack61, align 8, !tbaa !8
  store i64 8, ptr %loadgep_4.repack59.repack63, align 8, !tbaa !8
  %exitcond.not = icmp eq i32 %omp_loop.iv66, %reass.sub
  br i1 %exitcond.not, label %omp_loop.exit.loopexit, label %omp_loop.body

; Exit blocks
omp_loop.exit.loopexit:                           ; preds = %omp_loop.body
  br label %omp_loop.exit
*** IR Dump After LoopDeletionPass on omp_loop.body ***

; Preheader:
omp_loop.body.lr.ph:                              ; preds = %omp.par.entry
  %.unpack = load ptr, ptr @_QFEarr.0, align 8, !tbaa !8
  %.unpack12.unpack.unpack14.b = load i1, ptr @_QFEarr.8, align 1
  %.unpack12.unpack.unpack14 = select i1 %.unpack12.unpack.unpack14.b, i64 1048576, i64 0
  %loadgep_2.repack17 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  %loadgep_2.repack19 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  %loadgep_2.repack21 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  %loadgep_2.repack23 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  %loadgep_2.repack25 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  %loadgep_2.repack27 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  %loadgep_2.repack29 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  %loadgep_2.repack29.repack31 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  %loadgep_2.repack29.repack33 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  %loadgep_4.repack47 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 1
  %loadgep_4.repack49 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 2
  %loadgep_4.repack51 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 3
  %loadgep_4.repack53 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 4
  %loadgep_4.repack55 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 5
  %loadgep_4.repack57 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 6
  %loadgep_4.repack59 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7
  %loadgep_4.repack59.repack61 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 1
  %loadgep_4.repack59.repack63 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 2
  br label %omp_loop.body

; Loop:
omp_loop.body:                                    ; preds = %omp_loop.body.lr.ph, %omp_loop.body
  %omp_loop.iv66 = phi i32 [ 0, %omp_loop.body.lr.ph ], [ %5, %omp_loop.body ]
  %5 = add nuw i32 %omp_loop.iv66, 1
  %6 = add i32 %5, %3
  %7 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %8 = sitofp i32 %7 to float
  %9 = fdiv contract float 1.000000e+00, %8
  %10 = fpext float %9 to double
  store ptr %.unpack, ptr %loadgep_2, align 8, !tbaa !8
  store i64 8, ptr %loadgep_2.repack17, align 8, !tbaa !8
  store i32 20180515, ptr %loadgep_2.repack19, align 8, !tbaa !8
  store i8 1, ptr %loadgep_2.repack21, align 4, !tbaa !8
  store i8 28, ptr %loadgep_2.repack23, align 1, !tbaa !8
  store i8 2, ptr %loadgep_2.repack25, align 2, !tbaa !8
  store i8 0, ptr %loadgep_2.repack27, align 1, !tbaa !8
  store i64 1, ptr %loadgep_2.repack29, align 8, !tbaa !8
  store i64 %.unpack12.unpack.unpack14, ptr %loadgep_2.repack29.repack31, align 8, !tbaa !8
  store i64 8, ptr %loadgep_2.repack29.repack33, align 8, !tbaa !8
  %11 = sext i32 %6 to i64
  %12 = sub i64 %11, 1
  %13 = getelementptr double, ptr %.unpack, i64 %12
  store double %10, ptr %13, align 8, !tbaa !4
  store ptr %.unpack, ptr %loadgep_4, align 8, !tbaa !8
  store i64 8, ptr %loadgep_4.repack47, align 8, !tbaa !8
  store i32 20180515, ptr %loadgep_4.repack49, align 8, !tbaa !8
  store i8 1, ptr %loadgep_4.repack51, align 4, !tbaa !8
  store i8 28, ptr %loadgep_4.repack53, align 1, !tbaa !8
  store i8 2, ptr %loadgep_4.repack55, align 2, !tbaa !8
  store i8 0, ptr %loadgep_4.repack57, align 1, !tbaa !8
  store i64 1, ptr %loadgep_4.repack59, align 8, !tbaa !8
  store i64 %.unpack12.unpack.unpack14, ptr %loadgep_4.repack59.repack61, align 8, !tbaa !8
  store i64 8, ptr %loadgep_4.repack59.repack63, align 8, !tbaa !8
  %exitcond.not = icmp eq i32 %omp_loop.iv66, %reass.sub
  br i1 %exitcond.not, label %omp_loop.exit.loopexit, label %omp_loop.body

; Exit blocks
omp_loop.exit.loopexit:                           ; preds = %omp_loop.body
  br label %omp_loop.exit
*** IR Dump After LoopDistributePass on _QQmain..omp_par ***
; Function Attrs: norecurse nounwind
define internal void @_QQmain..omp_par(ptr noalias nocapture readnone %tid.addr, ptr noalias nocapture readnone %zero.addr, ptr nocapture readonly %0) #2 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %gep_3 = getelementptr { ptr, ptr, ptr }, ptr %0, i64 0, i32 2
  %loadgep_4 = load ptr, ptr %gep_3, align 8
  %p.lastiter = alloca i32, align 4
  %p.lowerbound = alloca i32, align 4
  %p.upperbound = alloca i32, align 4
  %p.stride = alloca i32, align 4
  %1 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %omp_loop.tripcount = tail call i32 @llvm.smax.i32(i32 %1, i32 0)
  store i32 0, ptr %p.lowerbound, align 4
  %2 = add nsw i32 %omp_loop.tripcount, -1
  store i32 %2, ptr %p.upperbound, align 4
  store i32 1, ptr %p.stride, align 4
  %omp_global_thread_num4 = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  call void @__kmpc_for_static_init_4u(ptr nonnull @1, i32 %omp_global_thread_num4, i32 34, ptr nonnull %p.lastiter, ptr nonnull %p.lowerbound, ptr nonnull %p.upperbound, ptr nonnull %p.stride, i32 1, i32 0)
  %3 = load i32, ptr %p.lowerbound, align 4
  %4 = load i32, ptr %p.upperbound, align 4
  %reass.sub = sub i32 %4, %3
  %omp_loop.cmp65.not = icmp eq i32 %reass.sub, -1
  br i1 %omp_loop.cmp65.not, label %omp_loop.exit, label %omp_loop.body.lr.ph

omp_loop.body.lr.ph:                              ; preds = %omp.par.entry
  %.unpack = load ptr, ptr @_QFEarr.0, align 8, !tbaa !8
  %.unpack12.unpack.unpack14.b = load i1, ptr @_QFEarr.8, align 1
  %.unpack12.unpack.unpack14 = select i1 %.unpack12.unpack.unpack14.b, i64 1048576, i64 0
  %loadgep_2.repack17 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  %loadgep_2.repack19 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  %loadgep_2.repack21 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  %loadgep_2.repack23 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  %loadgep_2.repack25 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  %loadgep_2.repack27 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  %loadgep_2.repack29 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  %loadgep_2.repack29.repack31 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  %loadgep_2.repack29.repack33 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  %loadgep_4.repack47 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 1
  %loadgep_4.repack49 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 2
  %loadgep_4.repack51 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 3
  %loadgep_4.repack53 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 4
  %loadgep_4.repack55 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 5
  %loadgep_4.repack57 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 6
  %loadgep_4.repack59 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7
  %loadgep_4.repack59.repack61 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 1
  %loadgep_4.repack59.repack63 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 2
  br label %omp_loop.body

omp_loop.exit.loopexit:                           ; preds = %omp_loop.body
  br label %omp_loop.exit

omp_loop.exit:                                    ; preds = %omp_loop.exit.loopexit, %omp.par.entry
  call void @__kmpc_for_static_fini(ptr nonnull @1, i32 %omp_global_thread_num4)
  call void @__kmpc_barrier(ptr nonnull @2, i32 %omp_global_thread_num4)
  ret void

omp_loop.body:                                    ; preds = %omp_loop.body.lr.ph, %omp_loop.body
  %omp_loop.iv66 = phi i32 [ 0, %omp_loop.body.lr.ph ], [ %5, %omp_loop.body ]
  %5 = add nuw i32 %omp_loop.iv66, 1
  %6 = add i32 %5, %3
  %7 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %8 = sitofp i32 %7 to float
  %9 = fdiv contract float 1.000000e+00, %8
  %10 = fpext float %9 to double
  store ptr %.unpack, ptr %loadgep_2, align 8, !tbaa !8
  store i64 8, ptr %loadgep_2.repack17, align 8, !tbaa !8
  store i32 20180515, ptr %loadgep_2.repack19, align 8, !tbaa !8
  store i8 1, ptr %loadgep_2.repack21, align 4, !tbaa !8
  store i8 28, ptr %loadgep_2.repack23, align 1, !tbaa !8
  store i8 2, ptr %loadgep_2.repack25, align 2, !tbaa !8
  store i8 0, ptr %loadgep_2.repack27, align 1, !tbaa !8
  store i64 1, ptr %loadgep_2.repack29, align 8, !tbaa !8
  store i64 %.unpack12.unpack.unpack14, ptr %loadgep_2.repack29.repack31, align 8, !tbaa !8
  store i64 8, ptr %loadgep_2.repack29.repack33, align 8, !tbaa !8
  %11 = sext i32 %6 to i64
  %12 = sub i64 %11, 1
  %13 = getelementptr double, ptr %.unpack, i64 %12
  store double %10, ptr %13, align 8, !tbaa !4
  store ptr %.unpack, ptr %loadgep_4, align 8, !tbaa !8
  store i64 8, ptr %loadgep_4.repack47, align 8, !tbaa !8
  store i32 20180515, ptr %loadgep_4.repack49, align 8, !tbaa !8
  store i8 1, ptr %loadgep_4.repack51, align 4, !tbaa !8
  store i8 28, ptr %loadgep_4.repack53, align 1, !tbaa !8
  store i8 2, ptr %loadgep_4.repack55, align 2, !tbaa !8
  store i8 0, ptr %loadgep_4.repack57, align 1, !tbaa !8
  store i64 1, ptr %loadgep_4.repack59, align 8, !tbaa !8
  store i64 %.unpack12.unpack.unpack14, ptr %loadgep_4.repack59.repack61, align 8, !tbaa !8
  store i64 8, ptr %loadgep_4.repack59.repack63, align 8, !tbaa !8
  %exitcond.not = icmp eq i32 %omp_loop.iv66, %reass.sub
  br i1 %exitcond.not, label %omp_loop.exit.loopexit, label %omp_loop.body
}
*** IR Dump After InjectTLIMappings on _QQmain..omp_par ***
; Function Attrs: norecurse nounwind
define internal void @_QQmain..omp_par(ptr noalias nocapture readnone %tid.addr, ptr noalias nocapture readnone %zero.addr, ptr nocapture readonly %0) #2 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %gep_3 = getelementptr { ptr, ptr, ptr }, ptr %0, i64 0, i32 2
  %loadgep_4 = load ptr, ptr %gep_3, align 8
  %p.lastiter = alloca i32, align 4
  %p.lowerbound = alloca i32, align 4
  %p.upperbound = alloca i32, align 4
  %p.stride = alloca i32, align 4
  %1 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %omp_loop.tripcount = tail call i32 @llvm.smax.i32(i32 %1, i32 0)
  store i32 0, ptr %p.lowerbound, align 4
  %2 = add nsw i32 %omp_loop.tripcount, -1
  store i32 %2, ptr %p.upperbound, align 4
  store i32 1, ptr %p.stride, align 4
  %omp_global_thread_num4 = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  call void @__kmpc_for_static_init_4u(ptr nonnull @1, i32 %omp_global_thread_num4, i32 34, ptr nonnull %p.lastiter, ptr nonnull %p.lowerbound, ptr nonnull %p.upperbound, ptr nonnull %p.stride, i32 1, i32 0)
  %3 = load i32, ptr %p.lowerbound, align 4
  %4 = load i32, ptr %p.upperbound, align 4
  %reass.sub = sub i32 %4, %3
  %omp_loop.cmp65.not = icmp eq i32 %reass.sub, -1
  br i1 %omp_loop.cmp65.not, label %omp_loop.exit, label %omp_loop.body.lr.ph

omp_loop.body.lr.ph:                              ; preds = %omp.par.entry
  %.unpack = load ptr, ptr @_QFEarr.0, align 8, !tbaa !8
  %.unpack12.unpack.unpack14.b = load i1, ptr @_QFEarr.8, align 1
  %.unpack12.unpack.unpack14 = select i1 %.unpack12.unpack.unpack14.b, i64 1048576, i64 0
  %loadgep_2.repack17 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  %loadgep_2.repack19 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  %loadgep_2.repack21 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  %loadgep_2.repack23 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  %loadgep_2.repack25 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  %loadgep_2.repack27 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  %loadgep_2.repack29 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  %loadgep_2.repack29.repack31 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  %loadgep_2.repack29.repack33 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  %loadgep_4.repack47 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 1
  %loadgep_4.repack49 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 2
  %loadgep_4.repack51 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 3
  %loadgep_4.repack53 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 4
  %loadgep_4.repack55 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 5
  %loadgep_4.repack57 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 6
  %loadgep_4.repack59 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7
  %loadgep_4.repack59.repack61 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 1
  %loadgep_4.repack59.repack63 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 2
  br label %omp_loop.body

omp_loop.exit.loopexit:                           ; preds = %omp_loop.body
  br label %omp_loop.exit

omp_loop.exit:                                    ; preds = %omp_loop.exit.loopexit, %omp.par.entry
  call void @__kmpc_for_static_fini(ptr nonnull @1, i32 %omp_global_thread_num4)
  call void @__kmpc_barrier(ptr nonnull @2, i32 %omp_global_thread_num4)
  ret void

omp_loop.body:                                    ; preds = %omp_loop.body.lr.ph, %omp_loop.body
  %omp_loop.iv66 = phi i32 [ 0, %omp_loop.body.lr.ph ], [ %5, %omp_loop.body ]
  %5 = add nuw i32 %omp_loop.iv66, 1
  %6 = add i32 %5, %3
  %7 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %8 = sitofp i32 %7 to float
  %9 = fdiv contract float 1.000000e+00, %8
  %10 = fpext float %9 to double
  store ptr %.unpack, ptr %loadgep_2, align 8, !tbaa !8
  store i64 8, ptr %loadgep_2.repack17, align 8, !tbaa !8
  store i32 20180515, ptr %loadgep_2.repack19, align 8, !tbaa !8
  store i8 1, ptr %loadgep_2.repack21, align 4, !tbaa !8
  store i8 28, ptr %loadgep_2.repack23, align 1, !tbaa !8
  store i8 2, ptr %loadgep_2.repack25, align 2, !tbaa !8
  store i8 0, ptr %loadgep_2.repack27, align 1, !tbaa !8
  store i64 1, ptr %loadgep_2.repack29, align 8, !tbaa !8
  store i64 %.unpack12.unpack.unpack14, ptr %loadgep_2.repack29.repack31, align 8, !tbaa !8
  store i64 8, ptr %loadgep_2.repack29.repack33, align 8, !tbaa !8
  %11 = sext i32 %6 to i64
  %12 = sub i64 %11, 1
  %13 = getelementptr double, ptr %.unpack, i64 %12
  store double %10, ptr %13, align 8, !tbaa !4
  store ptr %.unpack, ptr %loadgep_4, align 8, !tbaa !8
  store i64 8, ptr %loadgep_4.repack47, align 8, !tbaa !8
  store i32 20180515, ptr %loadgep_4.repack49, align 8, !tbaa !8
  store i8 1, ptr %loadgep_4.repack51, align 4, !tbaa !8
  store i8 28, ptr %loadgep_4.repack53, align 1, !tbaa !8
  store i8 2, ptr %loadgep_4.repack55, align 2, !tbaa !8
  store i8 0, ptr %loadgep_4.repack57, align 1, !tbaa !8
  store i64 1, ptr %loadgep_4.repack59, align 8, !tbaa !8
  store i64 %.unpack12.unpack.unpack14, ptr %loadgep_4.repack59.repack61, align 8, !tbaa !8
  store i64 8, ptr %loadgep_4.repack59.repack63, align 8, !tbaa !8
  %exitcond.not = icmp eq i32 %omp_loop.iv66, %reass.sub
  br i1 %exitcond.not, label %omp_loop.exit.loopexit, label %omp_loop.body
}
*** IR Dump After LoopVectorizePass on _QQmain..omp_par ***
; Function Attrs: norecurse nounwind
define internal void @_QQmain..omp_par(ptr noalias nocapture readnone %tid.addr, ptr noalias nocapture readnone %zero.addr, ptr nocapture readonly %0) #2 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %gep_3 = getelementptr { ptr, ptr, ptr }, ptr %0, i64 0, i32 2
  %loadgep_4 = load ptr, ptr %gep_3, align 8
  %p.lastiter = alloca i32, align 4
  %p.lowerbound = alloca i32, align 4
  %p.upperbound = alloca i32, align 4
  %p.stride = alloca i32, align 4
  %1 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %omp_loop.tripcount = tail call i32 @llvm.smax.i32(i32 %1, i32 0)
  store i32 0, ptr %p.lowerbound, align 4
  %2 = add nsw i32 %omp_loop.tripcount, -1
  store i32 %2, ptr %p.upperbound, align 4
  store i32 1, ptr %p.stride, align 4
  %omp_global_thread_num4 = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  call void @__kmpc_for_static_init_4u(ptr nonnull @1, i32 %omp_global_thread_num4, i32 34, ptr nonnull %p.lastiter, ptr nonnull %p.lowerbound, ptr nonnull %p.upperbound, ptr nonnull %p.stride, i32 1, i32 0)
  %3 = load i32, ptr %p.lowerbound, align 4
  %4 = load i32, ptr %p.upperbound, align 4
  %reass.sub = sub i32 %4, %3
  %omp_loop.cmp65.not = icmp eq i32 %reass.sub, -1
  br i1 %omp_loop.cmp65.not, label %omp_loop.exit, label %omp_loop.body.lr.ph

omp_loop.body.lr.ph:                              ; preds = %omp.par.entry
  %.unpack = load ptr, ptr @_QFEarr.0, align 8, !tbaa !8
  %.unpack12.unpack.unpack14.b = load i1, ptr @_QFEarr.8, align 1
  %.unpack12.unpack.unpack14 = select i1 %.unpack12.unpack.unpack14.b, i64 1048576, i64 0
  %loadgep_2.repack17 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  %loadgep_2.repack19 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  %loadgep_2.repack21 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  %loadgep_2.repack23 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  %loadgep_2.repack25 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  %loadgep_2.repack27 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  %loadgep_2.repack29 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  %loadgep_2.repack29.repack31 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  %loadgep_2.repack29.repack33 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  %loadgep_4.repack47 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 1
  %loadgep_4.repack49 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 2
  %loadgep_4.repack51 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 3
  %loadgep_4.repack53 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 4
  %loadgep_4.repack55 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 5
  %loadgep_4.repack57 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 6
  %loadgep_4.repack59 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7
  %loadgep_4.repack59.repack61 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 1
  %loadgep_4.repack59.repack63 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 2
  br label %omp_loop.body

omp_loop.exit.loopexit:                           ; preds = %omp_loop.body
  br label %omp_loop.exit

omp_loop.exit:                                    ; preds = %omp_loop.exit.loopexit, %omp.par.entry
  call void @__kmpc_for_static_fini(ptr nonnull @1, i32 %omp_global_thread_num4)
  call void @__kmpc_barrier(ptr nonnull @2, i32 %omp_global_thread_num4)
  ret void

omp_loop.body:                                    ; preds = %omp_loop.body.lr.ph, %omp_loop.body
  %omp_loop.iv66 = phi i32 [ 0, %omp_loop.body.lr.ph ], [ %5, %omp_loop.body ]
  %5 = add nuw i32 %omp_loop.iv66, 1
  %6 = add i32 %5, %3
  %7 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %8 = sitofp i32 %7 to float
  %9 = fdiv contract float 1.000000e+00, %8
  %10 = fpext float %9 to double
  store ptr %.unpack, ptr %loadgep_2, align 8, !tbaa !8
  store i64 8, ptr %loadgep_2.repack17, align 8, !tbaa !8
  store i32 20180515, ptr %loadgep_2.repack19, align 8, !tbaa !8
  store i8 1, ptr %loadgep_2.repack21, align 4, !tbaa !8
  store i8 28, ptr %loadgep_2.repack23, align 1, !tbaa !8
  store i8 2, ptr %loadgep_2.repack25, align 2, !tbaa !8
  store i8 0, ptr %loadgep_2.repack27, align 1, !tbaa !8
  store i64 1, ptr %loadgep_2.repack29, align 8, !tbaa !8
  store i64 %.unpack12.unpack.unpack14, ptr %loadgep_2.repack29.repack31, align 8, !tbaa !8
  store i64 8, ptr %loadgep_2.repack29.repack33, align 8, !tbaa !8
  %11 = sext i32 %6 to i64
  %12 = sub i64 %11, 1
  %13 = getelementptr double, ptr %.unpack, i64 %12
  store double %10, ptr %13, align 8, !tbaa !4
  store ptr %.unpack, ptr %loadgep_4, align 8, !tbaa !8
  store i64 8, ptr %loadgep_4.repack47, align 8, !tbaa !8
  store i32 20180515, ptr %loadgep_4.repack49, align 8, !tbaa !8
  store i8 1, ptr %loadgep_4.repack51, align 4, !tbaa !8
  store i8 28, ptr %loadgep_4.repack53, align 1, !tbaa !8
  store i8 2, ptr %loadgep_4.repack55, align 2, !tbaa !8
  store i8 0, ptr %loadgep_4.repack57, align 1, !tbaa !8
  store i64 1, ptr %loadgep_4.repack59, align 8, !tbaa !8
  store i64 %.unpack12.unpack.unpack14, ptr %loadgep_4.repack59.repack61, align 8, !tbaa !8
  store i64 8, ptr %loadgep_4.repack59.repack63, align 8, !tbaa !8
  %exitcond.not = icmp eq i32 %omp_loop.iv66, %reass.sub
  br i1 %exitcond.not, label %omp_loop.exit.loopexit, label %omp_loop.body
}
*** IR Dump After LoopLoadEliminationPass on _QQmain..omp_par ***
; Function Attrs: norecurse nounwind
define internal void @_QQmain..omp_par(ptr noalias nocapture readnone %tid.addr, ptr noalias nocapture readnone %zero.addr, ptr nocapture readonly %0) #2 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %gep_3 = getelementptr { ptr, ptr, ptr }, ptr %0, i64 0, i32 2
  %loadgep_4 = load ptr, ptr %gep_3, align 8
  %p.lastiter = alloca i32, align 4
  %p.lowerbound = alloca i32, align 4
  %p.upperbound = alloca i32, align 4
  %p.stride = alloca i32, align 4
  %1 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %omp_loop.tripcount = tail call i32 @llvm.smax.i32(i32 %1, i32 0)
  store i32 0, ptr %p.lowerbound, align 4
  %2 = add nsw i32 %omp_loop.tripcount, -1
  store i32 %2, ptr %p.upperbound, align 4
  store i32 1, ptr %p.stride, align 4
  %omp_global_thread_num4 = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  call void @__kmpc_for_static_init_4u(ptr nonnull @1, i32 %omp_global_thread_num4, i32 34, ptr nonnull %p.lastiter, ptr nonnull %p.lowerbound, ptr nonnull %p.upperbound, ptr nonnull %p.stride, i32 1, i32 0)
  %3 = load i32, ptr %p.lowerbound, align 4
  %4 = load i32, ptr %p.upperbound, align 4
  %reass.sub = sub i32 %4, %3
  %omp_loop.cmp65.not = icmp eq i32 %reass.sub, -1
  br i1 %omp_loop.cmp65.not, label %omp_loop.exit, label %omp_loop.body.lr.ph

omp_loop.body.lr.ph:                              ; preds = %omp.par.entry
  %.unpack = load ptr, ptr @_QFEarr.0, align 8, !tbaa !8
  %.unpack12.unpack.unpack14.b = load i1, ptr @_QFEarr.8, align 1
  %.unpack12.unpack.unpack14 = select i1 %.unpack12.unpack.unpack14.b, i64 1048576, i64 0
  %loadgep_2.repack17 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  %loadgep_2.repack19 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  %loadgep_2.repack21 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  %loadgep_2.repack23 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  %loadgep_2.repack25 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  %loadgep_2.repack27 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  %loadgep_2.repack29 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  %loadgep_2.repack29.repack31 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  %loadgep_2.repack29.repack33 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  %loadgep_4.repack47 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 1
  %loadgep_4.repack49 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 2
  %loadgep_4.repack51 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 3
  %loadgep_4.repack53 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 4
  %loadgep_4.repack55 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 5
  %loadgep_4.repack57 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 6
  %loadgep_4.repack59 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7
  %loadgep_4.repack59.repack61 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 1
  %loadgep_4.repack59.repack63 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 2
  br label %omp_loop.body

omp_loop.exit.loopexit:                           ; preds = %omp_loop.body
  br label %omp_loop.exit

omp_loop.exit:                                    ; preds = %omp_loop.exit.loopexit, %omp.par.entry
  call void @__kmpc_for_static_fini(ptr nonnull @1, i32 %omp_global_thread_num4)
  call void @__kmpc_barrier(ptr nonnull @2, i32 %omp_global_thread_num4)
  ret void

omp_loop.body:                                    ; preds = %omp_loop.body.lr.ph, %omp_loop.body
  %omp_loop.iv66 = phi i32 [ 0, %omp_loop.body.lr.ph ], [ %5, %omp_loop.body ]
  %5 = add nuw i32 %omp_loop.iv66, 1
  %6 = add i32 %5, %3
  %7 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %8 = sitofp i32 %7 to float
  %9 = fdiv contract float 1.000000e+00, %8
  %10 = fpext float %9 to double
  store ptr %.unpack, ptr %loadgep_2, align 8, !tbaa !8
  store i64 8, ptr %loadgep_2.repack17, align 8, !tbaa !8
  store i32 20180515, ptr %loadgep_2.repack19, align 8, !tbaa !8
  store i8 1, ptr %loadgep_2.repack21, align 4, !tbaa !8
  store i8 28, ptr %loadgep_2.repack23, align 1, !tbaa !8
  store i8 2, ptr %loadgep_2.repack25, align 2, !tbaa !8
  store i8 0, ptr %loadgep_2.repack27, align 1, !tbaa !8
  store i64 1, ptr %loadgep_2.repack29, align 8, !tbaa !8
  store i64 %.unpack12.unpack.unpack14, ptr %loadgep_2.repack29.repack31, align 8, !tbaa !8
  store i64 8, ptr %loadgep_2.repack29.repack33, align 8, !tbaa !8
  %11 = sext i32 %6 to i64
  %12 = sub i64 %11, 1
  %13 = getelementptr double, ptr %.unpack, i64 %12
  store double %10, ptr %13, align 8, !tbaa !4
  store ptr %.unpack, ptr %loadgep_4, align 8, !tbaa !8
  store i64 8, ptr %loadgep_4.repack47, align 8, !tbaa !8
  store i32 20180515, ptr %loadgep_4.repack49, align 8, !tbaa !8
  store i8 1, ptr %loadgep_4.repack51, align 4, !tbaa !8
  store i8 28, ptr %loadgep_4.repack53, align 1, !tbaa !8
  store i8 2, ptr %loadgep_4.repack55, align 2, !tbaa !8
  store i8 0, ptr %loadgep_4.repack57, align 1, !tbaa !8
  store i64 1, ptr %loadgep_4.repack59, align 8, !tbaa !8
  store i64 %.unpack12.unpack.unpack14, ptr %loadgep_4.repack59.repack61, align 8, !tbaa !8
  store i64 8, ptr %loadgep_4.repack59.repack63, align 8, !tbaa !8
  %exitcond.not = icmp eq i32 %omp_loop.iv66, %reass.sub
  br i1 %exitcond.not, label %omp_loop.exit.loopexit, label %omp_loop.body
}
*** IR Dump After InstCombinePass on _QQmain..omp_par ***
; Function Attrs: norecurse nounwind
define internal void @_QQmain..omp_par(ptr noalias nocapture readnone %tid.addr, ptr noalias nocapture readnone %zero.addr, ptr nocapture readonly %0) #2 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %gep_3 = getelementptr { ptr, ptr, ptr }, ptr %0, i64 0, i32 2
  %loadgep_4 = load ptr, ptr %gep_3, align 8
  %p.lastiter = alloca i32, align 4
  %p.lowerbound = alloca i32, align 4
  %p.upperbound = alloca i32, align 4
  %p.stride = alloca i32, align 4
  %1 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %omp_loop.tripcount = tail call i32 @llvm.smax.i32(i32 %1, i32 0)
  store i32 0, ptr %p.lowerbound, align 4
  %2 = add nsw i32 %omp_loop.tripcount, -1
  store i32 %2, ptr %p.upperbound, align 4
  store i32 1, ptr %p.stride, align 4
  %omp_global_thread_num4 = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  call void @__kmpc_for_static_init_4u(ptr nonnull @1, i32 %omp_global_thread_num4, i32 34, ptr nonnull %p.lastiter, ptr nonnull %p.lowerbound, ptr nonnull %p.upperbound, ptr nonnull %p.stride, i32 1, i32 0)
  %3 = load i32, ptr %p.lowerbound, align 4
  %4 = load i32, ptr %p.upperbound, align 4
  %reass.sub = sub i32 %4, %3
  %omp_loop.cmp65.not = icmp eq i32 %reass.sub, -1
  br i1 %omp_loop.cmp65.not, label %omp_loop.exit, label %omp_loop.body.lr.ph

omp_loop.body.lr.ph:                              ; preds = %omp.par.entry
  %.unpack = load ptr, ptr @_QFEarr.0, align 8, !tbaa !8
  %.unpack12.unpack.unpack14.b = load i1, ptr @_QFEarr.8, align 1
  %.unpack12.unpack.unpack14 = select i1 %.unpack12.unpack.unpack14.b, i64 1048576, i64 0
  %loadgep_2.repack17 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  %loadgep_2.repack19 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  %loadgep_2.repack21 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  %loadgep_2.repack23 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  %loadgep_2.repack25 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  %loadgep_2.repack27 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  %loadgep_2.repack29 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  %loadgep_2.repack29.repack31 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  %loadgep_2.repack29.repack33 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  %loadgep_4.repack47 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 1
  %loadgep_4.repack49 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 2
  %loadgep_4.repack51 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 3
  %loadgep_4.repack53 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 4
  %loadgep_4.repack55 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 5
  %loadgep_4.repack57 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 6
  %loadgep_4.repack59 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7
  %loadgep_4.repack59.repack61 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 1
  %loadgep_4.repack59.repack63 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 2
  br label %omp_loop.body

omp_loop.exit.loopexit:                           ; preds = %omp_loop.body
  br label %omp_loop.exit

omp_loop.exit:                                    ; preds = %omp_loop.exit.loopexit, %omp.par.entry
  call void @__kmpc_for_static_fini(ptr nonnull @1, i32 %omp_global_thread_num4)
  call void @__kmpc_barrier(ptr nonnull @2, i32 %omp_global_thread_num4)
  ret void

omp_loop.body:                                    ; preds = %omp_loop.body.lr.ph, %omp_loop.body
  %omp_loop.iv66 = phi i32 [ 0, %omp_loop.body.lr.ph ], [ %5, %omp_loop.body ]
  %5 = add nuw i32 %omp_loop.iv66, 1
  %6 = add i32 %5, %3
  %7 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %8 = sitofp i32 %7 to float
  %9 = fdiv contract float 1.000000e+00, %8
  %10 = fpext float %9 to double
  store ptr %.unpack, ptr %loadgep_2, align 8, !tbaa !8
  store i64 8, ptr %loadgep_2.repack17, align 8, !tbaa !8
  store i32 20180515, ptr %loadgep_2.repack19, align 8, !tbaa !8
  store i8 1, ptr %loadgep_2.repack21, align 4, !tbaa !8
  store i8 28, ptr %loadgep_2.repack23, align 1, !tbaa !8
  store i8 2, ptr %loadgep_2.repack25, align 2, !tbaa !8
  store i8 0, ptr %loadgep_2.repack27, align 1, !tbaa !8
  store i64 1, ptr %loadgep_2.repack29, align 8, !tbaa !8
  store i64 %.unpack12.unpack.unpack14, ptr %loadgep_2.repack29.repack31, align 8, !tbaa !8
  store i64 8, ptr %loadgep_2.repack29.repack33, align 8, !tbaa !8
  %11 = sext i32 %6 to i64
  %12 = add nsw i64 %11, -1
  %13 = getelementptr double, ptr %.unpack, i64 %12
  store double %10, ptr %13, align 8, !tbaa !4
  store ptr %.unpack, ptr %loadgep_4, align 8, !tbaa !8
  store i64 8, ptr %loadgep_4.repack47, align 8, !tbaa !8
  store i32 20180515, ptr %loadgep_4.repack49, align 8, !tbaa !8
  store i8 1, ptr %loadgep_4.repack51, align 4, !tbaa !8
  store i8 28, ptr %loadgep_4.repack53, align 1, !tbaa !8
  store i8 2, ptr %loadgep_4.repack55, align 2, !tbaa !8
  store i8 0, ptr %loadgep_4.repack57, align 1, !tbaa !8
  store i64 1, ptr %loadgep_4.repack59, align 8, !tbaa !8
  store i64 %.unpack12.unpack.unpack14, ptr %loadgep_4.repack59.repack61, align 8, !tbaa !8
  store i64 8, ptr %loadgep_4.repack59.repack63, align 8, !tbaa !8
  %exitcond.not = icmp eq i32 %omp_loop.iv66, %reass.sub
  br i1 %exitcond.not, label %omp_loop.exit.loopexit, label %omp_loop.body
}
*** IR Dump After SimplifyCFGPass on _QQmain..omp_par ***
; Function Attrs: norecurse nounwind
define internal void @_QQmain..omp_par(ptr noalias nocapture readnone %tid.addr, ptr noalias nocapture readnone %zero.addr, ptr nocapture readonly %0) #2 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %gep_3 = getelementptr { ptr, ptr, ptr }, ptr %0, i64 0, i32 2
  %loadgep_4 = load ptr, ptr %gep_3, align 8
  %p.lastiter = alloca i32, align 4
  %p.lowerbound = alloca i32, align 4
  %p.upperbound = alloca i32, align 4
  %p.stride = alloca i32, align 4
  %1 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %omp_loop.tripcount = tail call i32 @llvm.smax.i32(i32 %1, i32 0)
  store i32 0, ptr %p.lowerbound, align 4
  %2 = add nsw i32 %omp_loop.tripcount, -1
  store i32 %2, ptr %p.upperbound, align 4
  store i32 1, ptr %p.stride, align 4
  %omp_global_thread_num4 = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  call void @__kmpc_for_static_init_4u(ptr nonnull @1, i32 %omp_global_thread_num4, i32 34, ptr nonnull %p.lastiter, ptr nonnull %p.lowerbound, ptr nonnull %p.upperbound, ptr nonnull %p.stride, i32 1, i32 0)
  %3 = load i32, ptr %p.lowerbound, align 4
  %4 = load i32, ptr %p.upperbound, align 4
  %reass.sub = sub i32 %4, %3
  %omp_loop.cmp65.not = icmp eq i32 %reass.sub, -1
  br i1 %omp_loop.cmp65.not, label %omp_loop.exit, label %omp_loop.body.lr.ph

omp_loop.body.lr.ph:                              ; preds = %omp.par.entry
  %.unpack = load ptr, ptr @_QFEarr.0, align 8, !tbaa !8
  %.unpack12.unpack.unpack14.b = load i1, ptr @_QFEarr.8, align 1
  %.unpack12.unpack.unpack14 = select i1 %.unpack12.unpack.unpack14.b, i64 1048576, i64 0
  %loadgep_2.repack17 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  %loadgep_2.repack19 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  %loadgep_2.repack21 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  %loadgep_2.repack23 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  %loadgep_2.repack25 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  %loadgep_2.repack27 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  %loadgep_2.repack29 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  %loadgep_2.repack29.repack31 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  %loadgep_2.repack29.repack33 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  %loadgep_4.repack47 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 1
  %loadgep_4.repack49 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 2
  %loadgep_4.repack51 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 3
  %loadgep_4.repack53 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 4
  %loadgep_4.repack55 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 5
  %loadgep_4.repack57 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 6
  %loadgep_4.repack59 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7
  %loadgep_4.repack59.repack61 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 1
  %loadgep_4.repack59.repack63 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 2
  br label %omp_loop.body

omp_loop.exit:                                    ; preds = %omp_loop.body, %omp.par.entry
  call void @__kmpc_for_static_fini(ptr nonnull @1, i32 %omp_global_thread_num4)
  call void @__kmpc_barrier(ptr nonnull @2, i32 %omp_global_thread_num4)
  ret void

omp_loop.body:                                    ; preds = %omp_loop.body.lr.ph, %omp_loop.body
  %omp_loop.iv66 = phi i32 [ 0, %omp_loop.body.lr.ph ], [ %5, %omp_loop.body ]
  %5 = add nuw i32 %omp_loop.iv66, 1
  %6 = add i32 %5, %3
  %7 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %8 = sitofp i32 %7 to float
  %9 = fdiv contract float 1.000000e+00, %8
  %10 = fpext float %9 to double
  store ptr %.unpack, ptr %loadgep_2, align 8, !tbaa !8
  store i64 8, ptr %loadgep_2.repack17, align 8, !tbaa !8
  store i32 20180515, ptr %loadgep_2.repack19, align 8, !tbaa !8
  store i8 1, ptr %loadgep_2.repack21, align 4, !tbaa !8
  store i8 28, ptr %loadgep_2.repack23, align 1, !tbaa !8
  store i8 2, ptr %loadgep_2.repack25, align 2, !tbaa !8
  store i8 0, ptr %loadgep_2.repack27, align 1, !tbaa !8
  store i64 1, ptr %loadgep_2.repack29, align 8, !tbaa !8
  store i64 %.unpack12.unpack.unpack14, ptr %loadgep_2.repack29.repack31, align 8, !tbaa !8
  store i64 8, ptr %loadgep_2.repack29.repack33, align 8, !tbaa !8
  %11 = sext i32 %6 to i64
  %12 = add nsw i64 %11, -1
  %13 = getelementptr double, ptr %.unpack, i64 %12
  store double %10, ptr %13, align 8, !tbaa !4
  store ptr %.unpack, ptr %loadgep_4, align 8, !tbaa !8
  store i64 8, ptr %loadgep_4.repack47, align 8, !tbaa !8
  store i32 20180515, ptr %loadgep_4.repack49, align 8, !tbaa !8
  store i8 1, ptr %loadgep_4.repack51, align 4, !tbaa !8
  store i8 28, ptr %loadgep_4.repack53, align 1, !tbaa !8
  store i8 2, ptr %loadgep_4.repack55, align 2, !tbaa !8
  store i8 0, ptr %loadgep_4.repack57, align 1, !tbaa !8
  store i64 1, ptr %loadgep_4.repack59, align 8, !tbaa !8
  store i64 %.unpack12.unpack.unpack14, ptr %loadgep_4.repack59.repack61, align 8, !tbaa !8
  store i64 8, ptr %loadgep_4.repack59.repack63, align 8, !tbaa !8
  %exitcond.not = icmp eq i32 %omp_loop.iv66, %reass.sub
  br i1 %exitcond.not, label %omp_loop.exit, label %omp_loop.body
}
*** IR Dump After VectorCombinePass on _QQmain..omp_par ***
; Function Attrs: norecurse nounwind
define internal void @_QQmain..omp_par(ptr noalias nocapture readnone %tid.addr, ptr noalias nocapture readnone %zero.addr, ptr nocapture readonly %0) #2 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %gep_3 = getelementptr { ptr, ptr, ptr }, ptr %0, i64 0, i32 2
  %loadgep_4 = load ptr, ptr %gep_3, align 8
  %p.lastiter = alloca i32, align 4
  %p.lowerbound = alloca i32, align 4
  %p.upperbound = alloca i32, align 4
  %p.stride = alloca i32, align 4
  %1 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %omp_loop.tripcount = tail call i32 @llvm.smax.i32(i32 %1, i32 0)
  store i32 0, ptr %p.lowerbound, align 4
  %2 = add nsw i32 %omp_loop.tripcount, -1
  store i32 %2, ptr %p.upperbound, align 4
  store i32 1, ptr %p.stride, align 4
  %omp_global_thread_num4 = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  call void @__kmpc_for_static_init_4u(ptr nonnull @1, i32 %omp_global_thread_num4, i32 34, ptr nonnull %p.lastiter, ptr nonnull %p.lowerbound, ptr nonnull %p.upperbound, ptr nonnull %p.stride, i32 1, i32 0)
  %3 = load i32, ptr %p.lowerbound, align 4
  %4 = load i32, ptr %p.upperbound, align 4
  %reass.sub = sub i32 %4, %3
  %omp_loop.cmp65.not = icmp eq i32 %reass.sub, -1
  br i1 %omp_loop.cmp65.not, label %omp_loop.exit, label %omp_loop.body.lr.ph

omp_loop.body.lr.ph:                              ; preds = %omp.par.entry
  %.unpack = load ptr, ptr @_QFEarr.0, align 8, !tbaa !8
  %.unpack12.unpack.unpack14.b = load i1, ptr @_QFEarr.8, align 1
  %.unpack12.unpack.unpack14 = select i1 %.unpack12.unpack.unpack14.b, i64 1048576, i64 0
  %loadgep_2.repack17 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  %loadgep_2.repack19 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  %loadgep_2.repack21 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  %loadgep_2.repack23 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  %loadgep_2.repack25 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  %loadgep_2.repack27 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  %loadgep_2.repack29 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  %loadgep_2.repack29.repack31 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  %loadgep_2.repack29.repack33 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  %loadgep_4.repack47 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 1
  %loadgep_4.repack49 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 2
  %loadgep_4.repack51 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 3
  %loadgep_4.repack53 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 4
  %loadgep_4.repack55 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 5
  %loadgep_4.repack57 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 6
  %loadgep_4.repack59 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7
  %loadgep_4.repack59.repack61 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 1
  %loadgep_4.repack59.repack63 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 2
  br label %omp_loop.body

omp_loop.exit:                                    ; preds = %omp_loop.body, %omp.par.entry
  call void @__kmpc_for_static_fini(ptr nonnull @1, i32 %omp_global_thread_num4)
  call void @__kmpc_barrier(ptr nonnull @2, i32 %omp_global_thread_num4)
  ret void

omp_loop.body:                                    ; preds = %omp_loop.body.lr.ph, %omp_loop.body
  %omp_loop.iv66 = phi i32 [ 0, %omp_loop.body.lr.ph ], [ %5, %omp_loop.body ]
  %5 = add nuw i32 %omp_loop.iv66, 1
  %6 = add i32 %5, %3
  %7 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %8 = sitofp i32 %7 to float
  %9 = fdiv contract float 1.000000e+00, %8
  %10 = fpext float %9 to double
  store ptr %.unpack, ptr %loadgep_2, align 8, !tbaa !8
  store i64 8, ptr %loadgep_2.repack17, align 8, !tbaa !8
  store i32 20180515, ptr %loadgep_2.repack19, align 8, !tbaa !8
  store i8 1, ptr %loadgep_2.repack21, align 4, !tbaa !8
  store i8 28, ptr %loadgep_2.repack23, align 1, !tbaa !8
  store i8 2, ptr %loadgep_2.repack25, align 2, !tbaa !8
  store i8 0, ptr %loadgep_2.repack27, align 1, !tbaa !8
  store i64 1, ptr %loadgep_2.repack29, align 8, !tbaa !8
  store i64 %.unpack12.unpack.unpack14, ptr %loadgep_2.repack29.repack31, align 8, !tbaa !8
  store i64 8, ptr %loadgep_2.repack29.repack33, align 8, !tbaa !8
  %11 = sext i32 %6 to i64
  %12 = add nsw i64 %11, -1
  %13 = getelementptr double, ptr %.unpack, i64 %12
  store double %10, ptr %13, align 8, !tbaa !4
  store ptr %.unpack, ptr %loadgep_4, align 8, !tbaa !8
  store i64 8, ptr %loadgep_4.repack47, align 8, !tbaa !8
  store i32 20180515, ptr %loadgep_4.repack49, align 8, !tbaa !8
  store i8 1, ptr %loadgep_4.repack51, align 4, !tbaa !8
  store i8 28, ptr %loadgep_4.repack53, align 1, !tbaa !8
  store i8 2, ptr %loadgep_4.repack55, align 2, !tbaa !8
  store i8 0, ptr %loadgep_4.repack57, align 1, !tbaa !8
  store i64 1, ptr %loadgep_4.repack59, align 8, !tbaa !8
  store i64 %.unpack12.unpack.unpack14, ptr %loadgep_4.repack59.repack61, align 8, !tbaa !8
  store i64 8, ptr %loadgep_4.repack59.repack63, align 8, !tbaa !8
  %exitcond.not = icmp eq i32 %omp_loop.iv66, %reass.sub
  br i1 %exitcond.not, label %omp_loop.exit, label %omp_loop.body
}
*** IR Dump After InstCombinePass on _QQmain..omp_par ***
; Function Attrs: norecurse nounwind
define internal void @_QQmain..omp_par(ptr noalias nocapture readnone %tid.addr, ptr noalias nocapture readnone %zero.addr, ptr nocapture readonly %0) #2 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %gep_3 = getelementptr { ptr, ptr, ptr }, ptr %0, i64 0, i32 2
  %loadgep_4 = load ptr, ptr %gep_3, align 8
  %p.lastiter = alloca i32, align 4
  %p.lowerbound = alloca i32, align 4
  %p.upperbound = alloca i32, align 4
  %p.stride = alloca i32, align 4
  %1 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %omp_loop.tripcount = tail call i32 @llvm.smax.i32(i32 %1, i32 0)
  store i32 0, ptr %p.lowerbound, align 4
  %2 = add nsw i32 %omp_loop.tripcount, -1
  store i32 %2, ptr %p.upperbound, align 4
  store i32 1, ptr %p.stride, align 4
  %omp_global_thread_num4 = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  call void @__kmpc_for_static_init_4u(ptr nonnull @1, i32 %omp_global_thread_num4, i32 34, ptr nonnull %p.lastiter, ptr nonnull %p.lowerbound, ptr nonnull %p.upperbound, ptr nonnull %p.stride, i32 1, i32 0)
  %3 = load i32, ptr %p.lowerbound, align 4
  %4 = load i32, ptr %p.upperbound, align 4
  %reass.sub = sub i32 %4, %3
  %omp_loop.cmp65.not = icmp eq i32 %reass.sub, -1
  br i1 %omp_loop.cmp65.not, label %omp_loop.exit, label %omp_loop.body.lr.ph

omp_loop.body.lr.ph:                              ; preds = %omp.par.entry
  %.unpack = load ptr, ptr @_QFEarr.0, align 8, !tbaa !8
  %.unpack12.unpack.unpack14.b = load i1, ptr @_QFEarr.8, align 1
  %.unpack12.unpack.unpack14 = select i1 %.unpack12.unpack.unpack14.b, i64 1048576, i64 0
  %loadgep_2.repack17 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  %loadgep_2.repack19 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  %loadgep_2.repack21 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  %loadgep_2.repack23 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  %loadgep_2.repack25 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  %loadgep_2.repack27 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  %loadgep_2.repack29 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  %loadgep_2.repack29.repack31 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  %loadgep_2.repack29.repack33 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  %loadgep_4.repack47 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 1
  %loadgep_4.repack49 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 2
  %loadgep_4.repack51 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 3
  %loadgep_4.repack53 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 4
  %loadgep_4.repack55 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 5
  %loadgep_4.repack57 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 6
  %loadgep_4.repack59 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7
  %loadgep_4.repack59.repack61 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 1
  %loadgep_4.repack59.repack63 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 2
  br label %omp_loop.body

omp_loop.exit:                                    ; preds = %omp_loop.body, %omp.par.entry
  call void @__kmpc_for_static_fini(ptr nonnull @1, i32 %omp_global_thread_num4)
  call void @__kmpc_barrier(ptr nonnull @2, i32 %omp_global_thread_num4)
  ret void

omp_loop.body:                                    ; preds = %omp_loop.body.lr.ph, %omp_loop.body
  %omp_loop.iv66 = phi i32 [ 0, %omp_loop.body.lr.ph ], [ %5, %omp_loop.body ]
  %5 = add nuw i32 %omp_loop.iv66, 1
  %6 = add i32 %5, %3
  %7 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %8 = sitofp i32 %7 to float
  %9 = fdiv contract float 1.000000e+00, %8
  %10 = fpext float %9 to double
  store ptr %.unpack, ptr %loadgep_2, align 8, !tbaa !8
  store i64 8, ptr %loadgep_2.repack17, align 8, !tbaa !8
  store i32 20180515, ptr %loadgep_2.repack19, align 8, !tbaa !8
  store i8 1, ptr %loadgep_2.repack21, align 4, !tbaa !8
  store i8 28, ptr %loadgep_2.repack23, align 1, !tbaa !8
  store i8 2, ptr %loadgep_2.repack25, align 2, !tbaa !8
  store i8 0, ptr %loadgep_2.repack27, align 1, !tbaa !8
  store i64 1, ptr %loadgep_2.repack29, align 8, !tbaa !8
  store i64 %.unpack12.unpack.unpack14, ptr %loadgep_2.repack29.repack31, align 8, !tbaa !8
  store i64 8, ptr %loadgep_2.repack29.repack33, align 8, !tbaa !8
  %11 = sext i32 %6 to i64
  %12 = add nsw i64 %11, -1
  %13 = getelementptr double, ptr %.unpack, i64 %12
  store double %10, ptr %13, align 8, !tbaa !4
  store ptr %.unpack, ptr %loadgep_4, align 8, !tbaa !8
  store i64 8, ptr %loadgep_4.repack47, align 8, !tbaa !8
  store i32 20180515, ptr %loadgep_4.repack49, align 8, !tbaa !8
  store i8 1, ptr %loadgep_4.repack51, align 4, !tbaa !8
  store i8 28, ptr %loadgep_4.repack53, align 1, !tbaa !8
  store i8 2, ptr %loadgep_4.repack55, align 2, !tbaa !8
  store i8 0, ptr %loadgep_4.repack57, align 1, !tbaa !8
  store i64 1, ptr %loadgep_4.repack59, align 8, !tbaa !8
  store i64 %.unpack12.unpack.unpack14, ptr %loadgep_4.repack59.repack61, align 8, !tbaa !8
  store i64 8, ptr %loadgep_4.repack59.repack63, align 8, !tbaa !8
  %exitcond.not = icmp eq i32 %omp_loop.iv66, %reass.sub
  br i1 %exitcond.not, label %omp_loop.exit, label %omp_loop.body
}
*** IR Dump After LoopUnrollPass on _QQmain..omp_par ***
; Function Attrs: norecurse nounwind
define internal void @_QQmain..omp_par(ptr noalias nocapture readnone %tid.addr, ptr noalias nocapture readnone %zero.addr, ptr nocapture readonly %0) #2 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %gep_3 = getelementptr { ptr, ptr, ptr }, ptr %0, i64 0, i32 2
  %loadgep_4 = load ptr, ptr %gep_3, align 8
  %p.lastiter = alloca i32, align 4
  %p.lowerbound = alloca i32, align 4
  %p.upperbound = alloca i32, align 4
  %p.stride = alloca i32, align 4
  %1 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %omp_loop.tripcount = tail call i32 @llvm.smax.i32(i32 %1, i32 0)
  store i32 0, ptr %p.lowerbound, align 4
  %2 = add nsw i32 %omp_loop.tripcount, -1
  store i32 %2, ptr %p.upperbound, align 4
  store i32 1, ptr %p.stride, align 4
  %omp_global_thread_num4 = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  call void @__kmpc_for_static_init_4u(ptr nonnull @1, i32 %omp_global_thread_num4, i32 34, ptr nonnull %p.lastiter, ptr nonnull %p.lowerbound, ptr nonnull %p.upperbound, ptr nonnull %p.stride, i32 1, i32 0)
  %3 = load i32, ptr %p.lowerbound, align 4
  %4 = load i32, ptr %p.upperbound, align 4
  %reass.sub = sub i32 %4, %3
  %omp_loop.cmp65.not = icmp eq i32 %reass.sub, -1
  br i1 %omp_loop.cmp65.not, label %omp_loop.exit, label %omp_loop.body.lr.ph

omp_loop.body.lr.ph:                              ; preds = %omp.par.entry
  %.unpack = load ptr, ptr @_QFEarr.0, align 8, !tbaa !8
  %.unpack12.unpack.unpack14.b = load i1, ptr @_QFEarr.8, align 1
  %.unpack12.unpack.unpack14 = select i1 %.unpack12.unpack.unpack14.b, i64 1048576, i64 0
  %loadgep_2.repack17 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  %loadgep_2.repack19 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  %loadgep_2.repack21 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  %loadgep_2.repack23 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  %loadgep_2.repack25 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  %loadgep_2.repack27 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  %loadgep_2.repack29 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  %loadgep_2.repack29.repack31 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  %loadgep_2.repack29.repack33 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  %loadgep_4.repack47 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 1
  %loadgep_4.repack49 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 2
  %loadgep_4.repack51 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 3
  %loadgep_4.repack53 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 4
  %loadgep_4.repack55 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 5
  %loadgep_4.repack57 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 6
  %loadgep_4.repack59 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7
  %loadgep_4.repack59.repack61 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 1
  %loadgep_4.repack59.repack63 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 2
  br label %omp_loop.body

omp_loop.exit.loopexit:                           ; preds = %omp_loop.body
  br label %omp_loop.exit

omp_loop.exit:                                    ; preds = %omp_loop.exit.loopexit, %omp.par.entry
  call void @__kmpc_for_static_fini(ptr nonnull @1, i32 %omp_global_thread_num4)
  call void @__kmpc_barrier(ptr nonnull @2, i32 %omp_global_thread_num4)
  ret void

omp_loop.body:                                    ; preds = %omp_loop.body.lr.ph, %omp_loop.body
  %omp_loop.iv66 = phi i32 [ 0, %omp_loop.body.lr.ph ], [ %5, %omp_loop.body ]
  %5 = add nuw i32 %omp_loop.iv66, 1
  %6 = add i32 %5, %3
  %7 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %8 = sitofp i32 %7 to float
  %9 = fdiv contract float 1.000000e+00, %8
  %10 = fpext float %9 to double
  store ptr %.unpack, ptr %loadgep_2, align 8, !tbaa !8
  store i64 8, ptr %loadgep_2.repack17, align 8, !tbaa !8
  store i32 20180515, ptr %loadgep_2.repack19, align 8, !tbaa !8
  store i8 1, ptr %loadgep_2.repack21, align 4, !tbaa !8
  store i8 28, ptr %loadgep_2.repack23, align 1, !tbaa !8
  store i8 2, ptr %loadgep_2.repack25, align 2, !tbaa !8
  store i8 0, ptr %loadgep_2.repack27, align 1, !tbaa !8
  store i64 1, ptr %loadgep_2.repack29, align 8, !tbaa !8
  store i64 %.unpack12.unpack.unpack14, ptr %loadgep_2.repack29.repack31, align 8, !tbaa !8
  store i64 8, ptr %loadgep_2.repack29.repack33, align 8, !tbaa !8
  %11 = sext i32 %6 to i64
  %12 = add nsw i64 %11, -1
  %13 = getelementptr double, ptr %.unpack, i64 %12
  store double %10, ptr %13, align 8, !tbaa !4
  store ptr %.unpack, ptr %loadgep_4, align 8, !tbaa !8
  store i64 8, ptr %loadgep_4.repack47, align 8, !tbaa !8
  store i32 20180515, ptr %loadgep_4.repack49, align 8, !tbaa !8
  store i8 1, ptr %loadgep_4.repack51, align 4, !tbaa !8
  store i8 28, ptr %loadgep_4.repack53, align 1, !tbaa !8
  store i8 2, ptr %loadgep_4.repack55, align 2, !tbaa !8
  store i8 0, ptr %loadgep_4.repack57, align 1, !tbaa !8
  store i64 1, ptr %loadgep_4.repack59, align 8, !tbaa !8
  store i64 %.unpack12.unpack.unpack14, ptr %loadgep_4.repack59.repack61, align 8, !tbaa !8
  store i64 8, ptr %loadgep_4.repack59.repack63, align 8, !tbaa !8
  %exitcond.not = icmp eq i32 %omp_loop.iv66, %reass.sub
  br i1 %exitcond.not, label %omp_loop.exit.loopexit, label %omp_loop.body
}
*** IR Dump After WarnMissedTransformationsPass on _QQmain..omp_par ***
; Function Attrs: norecurse nounwind
define internal void @_QQmain..omp_par(ptr noalias nocapture readnone %tid.addr, ptr noalias nocapture readnone %zero.addr, ptr nocapture readonly %0) #2 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %gep_3 = getelementptr { ptr, ptr, ptr }, ptr %0, i64 0, i32 2
  %loadgep_4 = load ptr, ptr %gep_3, align 8
  %p.lastiter = alloca i32, align 4
  %p.lowerbound = alloca i32, align 4
  %p.upperbound = alloca i32, align 4
  %p.stride = alloca i32, align 4
  %1 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %omp_loop.tripcount = tail call i32 @llvm.smax.i32(i32 %1, i32 0)
  store i32 0, ptr %p.lowerbound, align 4
  %2 = add nsw i32 %omp_loop.tripcount, -1
  store i32 %2, ptr %p.upperbound, align 4
  store i32 1, ptr %p.stride, align 4
  %omp_global_thread_num4 = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  call void @__kmpc_for_static_init_4u(ptr nonnull @1, i32 %omp_global_thread_num4, i32 34, ptr nonnull %p.lastiter, ptr nonnull %p.lowerbound, ptr nonnull %p.upperbound, ptr nonnull %p.stride, i32 1, i32 0)
  %3 = load i32, ptr %p.lowerbound, align 4
  %4 = load i32, ptr %p.upperbound, align 4
  %reass.sub = sub i32 %4, %3
  %omp_loop.cmp65.not = icmp eq i32 %reass.sub, -1
  br i1 %omp_loop.cmp65.not, label %omp_loop.exit, label %omp_loop.body.lr.ph

omp_loop.body.lr.ph:                              ; preds = %omp.par.entry
  %.unpack = load ptr, ptr @_QFEarr.0, align 8, !tbaa !8
  %.unpack12.unpack.unpack14.b = load i1, ptr @_QFEarr.8, align 1
  %.unpack12.unpack.unpack14 = select i1 %.unpack12.unpack.unpack14.b, i64 1048576, i64 0
  %loadgep_2.repack17 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  %loadgep_2.repack19 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  %loadgep_2.repack21 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  %loadgep_2.repack23 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  %loadgep_2.repack25 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  %loadgep_2.repack27 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  %loadgep_2.repack29 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  %loadgep_2.repack29.repack31 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  %loadgep_2.repack29.repack33 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  %loadgep_4.repack47 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 1
  %loadgep_4.repack49 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 2
  %loadgep_4.repack51 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 3
  %loadgep_4.repack53 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 4
  %loadgep_4.repack55 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 5
  %loadgep_4.repack57 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 6
  %loadgep_4.repack59 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7
  %loadgep_4.repack59.repack61 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 1
  %loadgep_4.repack59.repack63 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 2
  br label %omp_loop.body

omp_loop.exit.loopexit:                           ; preds = %omp_loop.body
  br label %omp_loop.exit

omp_loop.exit:                                    ; preds = %omp_loop.exit.loopexit, %omp.par.entry
  call void @__kmpc_for_static_fini(ptr nonnull @1, i32 %omp_global_thread_num4)
  call void @__kmpc_barrier(ptr nonnull @2, i32 %omp_global_thread_num4)
  ret void

omp_loop.body:                                    ; preds = %omp_loop.body.lr.ph, %omp_loop.body
  %omp_loop.iv66 = phi i32 [ 0, %omp_loop.body.lr.ph ], [ %5, %omp_loop.body ]
  %5 = add nuw i32 %omp_loop.iv66, 1
  %6 = add i32 %5, %3
  %7 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %8 = sitofp i32 %7 to float
  %9 = fdiv contract float 1.000000e+00, %8
  %10 = fpext float %9 to double
  store ptr %.unpack, ptr %loadgep_2, align 8, !tbaa !8
  store i64 8, ptr %loadgep_2.repack17, align 8, !tbaa !8
  store i32 20180515, ptr %loadgep_2.repack19, align 8, !tbaa !8
  store i8 1, ptr %loadgep_2.repack21, align 4, !tbaa !8
  store i8 28, ptr %loadgep_2.repack23, align 1, !tbaa !8
  store i8 2, ptr %loadgep_2.repack25, align 2, !tbaa !8
  store i8 0, ptr %loadgep_2.repack27, align 1, !tbaa !8
  store i64 1, ptr %loadgep_2.repack29, align 8, !tbaa !8
  store i64 %.unpack12.unpack.unpack14, ptr %loadgep_2.repack29.repack31, align 8, !tbaa !8
  store i64 8, ptr %loadgep_2.repack29.repack33, align 8, !tbaa !8
  %11 = sext i32 %6 to i64
  %12 = add nsw i64 %11, -1
  %13 = getelementptr double, ptr %.unpack, i64 %12
  store double %10, ptr %13, align 8, !tbaa !4
  store ptr %.unpack, ptr %loadgep_4, align 8, !tbaa !8
  store i64 8, ptr %loadgep_4.repack47, align 8, !tbaa !8
  store i32 20180515, ptr %loadgep_4.repack49, align 8, !tbaa !8
  store i8 1, ptr %loadgep_4.repack51, align 4, !tbaa !8
  store i8 28, ptr %loadgep_4.repack53, align 1, !tbaa !8
  store i8 2, ptr %loadgep_4.repack55, align 2, !tbaa !8
  store i8 0, ptr %loadgep_4.repack57, align 1, !tbaa !8
  store i64 1, ptr %loadgep_4.repack59, align 8, !tbaa !8
  store i64 %.unpack12.unpack.unpack14, ptr %loadgep_4.repack59.repack61, align 8, !tbaa !8
  store i64 8, ptr %loadgep_4.repack59.repack63, align 8, !tbaa !8
  %exitcond.not = icmp eq i32 %omp_loop.iv66, %reass.sub
  br i1 %exitcond.not, label %omp_loop.exit.loopexit, label %omp_loop.body
}
*** IR Dump After SROAPass on _QQmain..omp_par ***
; Function Attrs: norecurse nounwind
define internal void @_QQmain..omp_par(ptr noalias nocapture readnone %tid.addr, ptr noalias nocapture readnone %zero.addr, ptr nocapture readonly %0) #2 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %gep_3 = getelementptr { ptr, ptr, ptr }, ptr %0, i64 0, i32 2
  %loadgep_4 = load ptr, ptr %gep_3, align 8
  %p.lastiter = alloca i32, align 4
  %p.lowerbound = alloca i32, align 4
  %p.upperbound = alloca i32, align 4
  %p.stride = alloca i32, align 4
  %1 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %omp_loop.tripcount = tail call i32 @llvm.smax.i32(i32 %1, i32 0)
  store i32 0, ptr %p.lowerbound, align 4
  %2 = add nsw i32 %omp_loop.tripcount, -1
  store i32 %2, ptr %p.upperbound, align 4
  store i32 1, ptr %p.stride, align 4
  %omp_global_thread_num4 = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  call void @__kmpc_for_static_init_4u(ptr nonnull @1, i32 %omp_global_thread_num4, i32 34, ptr nonnull %p.lastiter, ptr nonnull %p.lowerbound, ptr nonnull %p.upperbound, ptr nonnull %p.stride, i32 1, i32 0)
  %3 = load i32, ptr %p.lowerbound, align 4
  %4 = load i32, ptr %p.upperbound, align 4
  %reass.sub = sub i32 %4, %3
  %omp_loop.cmp65.not = icmp eq i32 %reass.sub, -1
  br i1 %omp_loop.cmp65.not, label %omp_loop.exit, label %omp_loop.body.lr.ph

omp_loop.body.lr.ph:                              ; preds = %omp.par.entry
  %.unpack = load ptr, ptr @_QFEarr.0, align 8, !tbaa !8
  %.unpack12.unpack.unpack14.b = load i1, ptr @_QFEarr.8, align 1
  %.unpack12.unpack.unpack14 = select i1 %.unpack12.unpack.unpack14.b, i64 1048576, i64 0
  %loadgep_2.repack17 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  %loadgep_2.repack19 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  %loadgep_2.repack21 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  %loadgep_2.repack23 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  %loadgep_2.repack25 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  %loadgep_2.repack27 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  %loadgep_2.repack29 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  %loadgep_2.repack29.repack31 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  %loadgep_2.repack29.repack33 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  %loadgep_4.repack47 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 1
  %loadgep_4.repack49 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 2
  %loadgep_4.repack51 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 3
  %loadgep_4.repack53 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 4
  %loadgep_4.repack55 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 5
  %loadgep_4.repack57 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 6
  %loadgep_4.repack59 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7
  %loadgep_4.repack59.repack61 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 1
  %loadgep_4.repack59.repack63 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 2
  br label %omp_loop.body

omp_loop.exit.loopexit:                           ; preds = %omp_loop.body
  br label %omp_loop.exit

omp_loop.exit:                                    ; preds = %omp_loop.exit.loopexit, %omp.par.entry
  call void @__kmpc_for_static_fini(ptr nonnull @1, i32 %omp_global_thread_num4)
  call void @__kmpc_barrier(ptr nonnull @2, i32 %omp_global_thread_num4)
  ret void

omp_loop.body:                                    ; preds = %omp_loop.body.lr.ph, %omp_loop.body
  %omp_loop.iv66 = phi i32 [ 0, %omp_loop.body.lr.ph ], [ %5, %omp_loop.body ]
  %5 = add nuw i32 %omp_loop.iv66, 1
  %6 = add i32 %5, %3
  %7 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %8 = sitofp i32 %7 to float
  %9 = fdiv contract float 1.000000e+00, %8
  %10 = fpext float %9 to double
  store ptr %.unpack, ptr %loadgep_2, align 8, !tbaa !8
  store i64 8, ptr %loadgep_2.repack17, align 8, !tbaa !8
  store i32 20180515, ptr %loadgep_2.repack19, align 8, !tbaa !8
  store i8 1, ptr %loadgep_2.repack21, align 4, !tbaa !8
  store i8 28, ptr %loadgep_2.repack23, align 1, !tbaa !8
  store i8 2, ptr %loadgep_2.repack25, align 2, !tbaa !8
  store i8 0, ptr %loadgep_2.repack27, align 1, !tbaa !8
  store i64 1, ptr %loadgep_2.repack29, align 8, !tbaa !8
  store i64 %.unpack12.unpack.unpack14, ptr %loadgep_2.repack29.repack31, align 8, !tbaa !8
  store i64 8, ptr %loadgep_2.repack29.repack33, align 8, !tbaa !8
  %11 = sext i32 %6 to i64
  %12 = add nsw i64 %11, -1
  %13 = getelementptr double, ptr %.unpack, i64 %12
  store double %10, ptr %13, align 8, !tbaa !4
  store ptr %.unpack, ptr %loadgep_4, align 8, !tbaa !8
  store i64 8, ptr %loadgep_4.repack47, align 8, !tbaa !8
  store i32 20180515, ptr %loadgep_4.repack49, align 8, !tbaa !8
  store i8 1, ptr %loadgep_4.repack51, align 4, !tbaa !8
  store i8 28, ptr %loadgep_4.repack53, align 1, !tbaa !8
  store i8 2, ptr %loadgep_4.repack55, align 2, !tbaa !8
  store i8 0, ptr %loadgep_4.repack57, align 1, !tbaa !8
  store i64 1, ptr %loadgep_4.repack59, align 8, !tbaa !8
  store i64 %.unpack12.unpack.unpack14, ptr %loadgep_4.repack59.repack61, align 8, !tbaa !8
  store i64 8, ptr %loadgep_4.repack59.repack63, align 8, !tbaa !8
  %exitcond.not = icmp eq i32 %omp_loop.iv66, %reass.sub
  br i1 %exitcond.not, label %omp_loop.exit.loopexit, label %omp_loop.body
}
*** IR Dump After InstCombinePass on _QQmain..omp_par ***
; Function Attrs: norecurse nounwind
define internal void @_QQmain..omp_par(ptr noalias nocapture readnone %tid.addr, ptr noalias nocapture readnone %zero.addr, ptr nocapture readonly %0) #2 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %gep_3 = getelementptr { ptr, ptr, ptr }, ptr %0, i64 0, i32 2
  %loadgep_4 = load ptr, ptr %gep_3, align 8
  %p.lastiter = alloca i32, align 4
  %p.lowerbound = alloca i32, align 4
  %p.upperbound = alloca i32, align 4
  %p.stride = alloca i32, align 4
  %1 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %omp_loop.tripcount = tail call i32 @llvm.smax.i32(i32 %1, i32 0)
  store i32 0, ptr %p.lowerbound, align 4
  %2 = add nsw i32 %omp_loop.tripcount, -1
  store i32 %2, ptr %p.upperbound, align 4
  store i32 1, ptr %p.stride, align 4
  %omp_global_thread_num4 = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  call void @__kmpc_for_static_init_4u(ptr nonnull @1, i32 %omp_global_thread_num4, i32 34, ptr nonnull %p.lastiter, ptr nonnull %p.lowerbound, ptr nonnull %p.upperbound, ptr nonnull %p.stride, i32 1, i32 0)
  %3 = load i32, ptr %p.lowerbound, align 4
  %4 = load i32, ptr %p.upperbound, align 4
  %reass.sub = sub i32 %4, %3
  %omp_loop.cmp65.not = icmp eq i32 %reass.sub, -1
  br i1 %omp_loop.cmp65.not, label %omp_loop.exit, label %omp_loop.body.lr.ph

omp_loop.body.lr.ph:                              ; preds = %omp.par.entry
  %.unpack = load ptr, ptr @_QFEarr.0, align 8, !tbaa !8
  %.unpack12.unpack.unpack14.b = load i1, ptr @_QFEarr.8, align 1
  %.unpack12.unpack.unpack14 = select i1 %.unpack12.unpack.unpack14.b, i64 1048576, i64 0
  %loadgep_2.repack17 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  %loadgep_2.repack19 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  %loadgep_2.repack21 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  %loadgep_2.repack23 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  %loadgep_2.repack25 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  %loadgep_2.repack27 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  %loadgep_2.repack29 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  %loadgep_2.repack29.repack31 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  %loadgep_2.repack29.repack33 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  %loadgep_4.repack47 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 1
  %loadgep_4.repack49 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 2
  %loadgep_4.repack51 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 3
  %loadgep_4.repack53 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 4
  %loadgep_4.repack55 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 5
  %loadgep_4.repack57 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 6
  %loadgep_4.repack59 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7
  %loadgep_4.repack59.repack61 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 1
  %loadgep_4.repack59.repack63 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 2
  br label %omp_loop.body

omp_loop.exit.loopexit:                           ; preds = %omp_loop.body
  br label %omp_loop.exit

omp_loop.exit:                                    ; preds = %omp_loop.exit.loopexit, %omp.par.entry
  call void @__kmpc_for_static_fini(ptr nonnull @1, i32 %omp_global_thread_num4)
  call void @__kmpc_barrier(ptr nonnull @2, i32 %omp_global_thread_num4)
  ret void

omp_loop.body:                                    ; preds = %omp_loop.body.lr.ph, %omp_loop.body
  %omp_loop.iv66 = phi i32 [ 0, %omp_loop.body.lr.ph ], [ %5, %omp_loop.body ]
  %5 = add nuw i32 %omp_loop.iv66, 1
  %6 = add i32 %5, %3
  %7 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %8 = sitofp i32 %7 to float
  %9 = fdiv contract float 1.000000e+00, %8
  %10 = fpext float %9 to double
  store ptr %.unpack, ptr %loadgep_2, align 8, !tbaa !8
  store i64 8, ptr %loadgep_2.repack17, align 8, !tbaa !8
  store i32 20180515, ptr %loadgep_2.repack19, align 8, !tbaa !8
  store i8 1, ptr %loadgep_2.repack21, align 4, !tbaa !8
  store i8 28, ptr %loadgep_2.repack23, align 1, !tbaa !8
  store i8 2, ptr %loadgep_2.repack25, align 2, !tbaa !8
  store i8 0, ptr %loadgep_2.repack27, align 1, !tbaa !8
  store i64 1, ptr %loadgep_2.repack29, align 8, !tbaa !8
  store i64 %.unpack12.unpack.unpack14, ptr %loadgep_2.repack29.repack31, align 8, !tbaa !8
  store i64 8, ptr %loadgep_2.repack29.repack33, align 8, !tbaa !8
  %11 = sext i32 %6 to i64
  %12 = add nsw i64 %11, -1
  %13 = getelementptr double, ptr %.unpack, i64 %12
  store double %10, ptr %13, align 8, !tbaa !4
  store ptr %.unpack, ptr %loadgep_4, align 8, !tbaa !8
  store i64 8, ptr %loadgep_4.repack47, align 8, !tbaa !8
  store i32 20180515, ptr %loadgep_4.repack49, align 8, !tbaa !8
  store i8 1, ptr %loadgep_4.repack51, align 4, !tbaa !8
  store i8 28, ptr %loadgep_4.repack53, align 1, !tbaa !8
  store i8 2, ptr %loadgep_4.repack55, align 2, !tbaa !8
  store i8 0, ptr %loadgep_4.repack57, align 1, !tbaa !8
  store i64 1, ptr %loadgep_4.repack59, align 8, !tbaa !8
  store i64 %.unpack12.unpack.unpack14, ptr %loadgep_4.repack59.repack61, align 8, !tbaa !8
  store i64 8, ptr %loadgep_4.repack59.repack63, align 8, !tbaa !8
  %exitcond.not = icmp eq i32 %omp_loop.iv66, %reass.sub
  br i1 %exitcond.not, label %omp_loop.exit.loopexit, label %omp_loop.body
}
*** IR Dump After LoopSimplifyPass on _QQmain..omp_par ***
; Function Attrs: norecurse nounwind
define internal void @_QQmain..omp_par(ptr noalias nocapture readnone %tid.addr, ptr noalias nocapture readnone %zero.addr, ptr nocapture readonly %0) #2 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %gep_3 = getelementptr { ptr, ptr, ptr }, ptr %0, i64 0, i32 2
  %loadgep_4 = load ptr, ptr %gep_3, align 8
  %p.lastiter = alloca i32, align 4
  %p.lowerbound = alloca i32, align 4
  %p.upperbound = alloca i32, align 4
  %p.stride = alloca i32, align 4
  %1 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %omp_loop.tripcount = tail call i32 @llvm.smax.i32(i32 %1, i32 0)
  store i32 0, ptr %p.lowerbound, align 4
  %2 = add nsw i32 %omp_loop.tripcount, -1
  store i32 %2, ptr %p.upperbound, align 4
  store i32 1, ptr %p.stride, align 4
  %omp_global_thread_num4 = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  call void @__kmpc_for_static_init_4u(ptr nonnull @1, i32 %omp_global_thread_num4, i32 34, ptr nonnull %p.lastiter, ptr nonnull %p.lowerbound, ptr nonnull %p.upperbound, ptr nonnull %p.stride, i32 1, i32 0)
  %3 = load i32, ptr %p.lowerbound, align 4
  %4 = load i32, ptr %p.upperbound, align 4
  %reass.sub = sub i32 %4, %3
  %omp_loop.cmp65.not = icmp eq i32 %reass.sub, -1
  br i1 %omp_loop.cmp65.not, label %omp_loop.exit, label %omp_loop.body.lr.ph

omp_loop.body.lr.ph:                              ; preds = %omp.par.entry
  %.unpack = load ptr, ptr @_QFEarr.0, align 8, !tbaa !8
  %.unpack12.unpack.unpack14.b = load i1, ptr @_QFEarr.8, align 1
  %.unpack12.unpack.unpack14 = select i1 %.unpack12.unpack.unpack14.b, i64 1048576, i64 0
  %loadgep_2.repack17 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  %loadgep_2.repack19 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  %loadgep_2.repack21 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  %loadgep_2.repack23 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  %loadgep_2.repack25 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  %loadgep_2.repack27 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  %loadgep_2.repack29 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  %loadgep_2.repack29.repack31 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  %loadgep_2.repack29.repack33 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  %loadgep_4.repack47 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 1
  %loadgep_4.repack49 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 2
  %loadgep_4.repack51 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 3
  %loadgep_4.repack53 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 4
  %loadgep_4.repack55 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 5
  %loadgep_4.repack57 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 6
  %loadgep_4.repack59 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7
  %loadgep_4.repack59.repack61 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 1
  %loadgep_4.repack59.repack63 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 2
  br label %omp_loop.body

omp_loop.exit.loopexit:                           ; preds = %omp_loop.body
  br label %omp_loop.exit

omp_loop.exit:                                    ; preds = %omp_loop.exit.loopexit, %omp.par.entry
  call void @__kmpc_for_static_fini(ptr nonnull @1, i32 %omp_global_thread_num4)
  call void @__kmpc_barrier(ptr nonnull @2, i32 %omp_global_thread_num4)
  ret void

omp_loop.body:                                    ; preds = %omp_loop.body.lr.ph, %omp_loop.body
  %omp_loop.iv66 = phi i32 [ 0, %omp_loop.body.lr.ph ], [ %5, %omp_loop.body ]
  %5 = add nuw i32 %omp_loop.iv66, 1
  %6 = add i32 %5, %3
  %7 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %8 = sitofp i32 %7 to float
  %9 = fdiv contract float 1.000000e+00, %8
  %10 = fpext float %9 to double
  store ptr %.unpack, ptr %loadgep_2, align 8, !tbaa !8
  store i64 8, ptr %loadgep_2.repack17, align 8, !tbaa !8
  store i32 20180515, ptr %loadgep_2.repack19, align 8, !tbaa !8
  store i8 1, ptr %loadgep_2.repack21, align 4, !tbaa !8
  store i8 28, ptr %loadgep_2.repack23, align 1, !tbaa !8
  store i8 2, ptr %loadgep_2.repack25, align 2, !tbaa !8
  store i8 0, ptr %loadgep_2.repack27, align 1, !tbaa !8
  store i64 1, ptr %loadgep_2.repack29, align 8, !tbaa !8
  store i64 %.unpack12.unpack.unpack14, ptr %loadgep_2.repack29.repack31, align 8, !tbaa !8
  store i64 8, ptr %loadgep_2.repack29.repack33, align 8, !tbaa !8
  %11 = sext i32 %6 to i64
  %12 = add nsw i64 %11, -1
  %13 = getelementptr double, ptr %.unpack, i64 %12
  store double %10, ptr %13, align 8, !tbaa !4
  store ptr %.unpack, ptr %loadgep_4, align 8, !tbaa !8
  store i64 8, ptr %loadgep_4.repack47, align 8, !tbaa !8
  store i32 20180515, ptr %loadgep_4.repack49, align 8, !tbaa !8
  store i8 1, ptr %loadgep_4.repack51, align 4, !tbaa !8
  store i8 28, ptr %loadgep_4.repack53, align 1, !tbaa !8
  store i8 2, ptr %loadgep_4.repack55, align 2, !tbaa !8
  store i8 0, ptr %loadgep_4.repack57, align 1, !tbaa !8
  store i64 1, ptr %loadgep_4.repack59, align 8, !tbaa !8
  store i64 %.unpack12.unpack.unpack14, ptr %loadgep_4.repack59.repack61, align 8, !tbaa !8
  store i64 8, ptr %loadgep_4.repack59.repack63, align 8, !tbaa !8
  %exitcond.not = icmp eq i32 %omp_loop.iv66, %reass.sub
  br i1 %exitcond.not, label %omp_loop.exit.loopexit, label %omp_loop.body
}
*** IR Dump After LCSSAPass on _QQmain..omp_par ***
; Function Attrs: norecurse nounwind
define internal void @_QQmain..omp_par(ptr noalias nocapture readnone %tid.addr, ptr noalias nocapture readnone %zero.addr, ptr nocapture readonly %0) #2 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %gep_3 = getelementptr { ptr, ptr, ptr }, ptr %0, i64 0, i32 2
  %loadgep_4 = load ptr, ptr %gep_3, align 8
  %p.lastiter = alloca i32, align 4
  %p.lowerbound = alloca i32, align 4
  %p.upperbound = alloca i32, align 4
  %p.stride = alloca i32, align 4
  %1 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %omp_loop.tripcount = tail call i32 @llvm.smax.i32(i32 %1, i32 0)
  store i32 0, ptr %p.lowerbound, align 4
  %2 = add nsw i32 %omp_loop.tripcount, -1
  store i32 %2, ptr %p.upperbound, align 4
  store i32 1, ptr %p.stride, align 4
  %omp_global_thread_num4 = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  call void @__kmpc_for_static_init_4u(ptr nonnull @1, i32 %omp_global_thread_num4, i32 34, ptr nonnull %p.lastiter, ptr nonnull %p.lowerbound, ptr nonnull %p.upperbound, ptr nonnull %p.stride, i32 1, i32 0)
  %3 = load i32, ptr %p.lowerbound, align 4
  %4 = load i32, ptr %p.upperbound, align 4
  %reass.sub = sub i32 %4, %3
  %omp_loop.cmp65.not = icmp eq i32 %reass.sub, -1
  br i1 %omp_loop.cmp65.not, label %omp_loop.exit, label %omp_loop.body.lr.ph

omp_loop.body.lr.ph:                              ; preds = %omp.par.entry
  %.unpack = load ptr, ptr @_QFEarr.0, align 8, !tbaa !8
  %.unpack12.unpack.unpack14.b = load i1, ptr @_QFEarr.8, align 1
  %.unpack12.unpack.unpack14 = select i1 %.unpack12.unpack.unpack14.b, i64 1048576, i64 0
  %loadgep_2.repack17 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  %loadgep_2.repack19 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  %loadgep_2.repack21 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  %loadgep_2.repack23 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  %loadgep_2.repack25 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  %loadgep_2.repack27 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  %loadgep_2.repack29 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  %loadgep_2.repack29.repack31 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  %loadgep_2.repack29.repack33 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  %loadgep_4.repack47 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 1
  %loadgep_4.repack49 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 2
  %loadgep_4.repack51 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 3
  %loadgep_4.repack53 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 4
  %loadgep_4.repack55 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 5
  %loadgep_4.repack57 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 6
  %loadgep_4.repack59 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7
  %loadgep_4.repack59.repack61 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 1
  %loadgep_4.repack59.repack63 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 2
  br label %omp_loop.body

omp_loop.exit.loopexit:                           ; preds = %omp_loop.body
  br label %omp_loop.exit

omp_loop.exit:                                    ; preds = %omp_loop.exit.loopexit, %omp.par.entry
  call void @__kmpc_for_static_fini(ptr nonnull @1, i32 %omp_global_thread_num4)
  call void @__kmpc_barrier(ptr nonnull @2, i32 %omp_global_thread_num4)
  ret void

omp_loop.body:                                    ; preds = %omp_loop.body.lr.ph, %omp_loop.body
  %omp_loop.iv66 = phi i32 [ 0, %omp_loop.body.lr.ph ], [ %5, %omp_loop.body ]
  %5 = add nuw i32 %omp_loop.iv66, 1
  %6 = add i32 %5, %3
  %7 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %8 = sitofp i32 %7 to float
  %9 = fdiv contract float 1.000000e+00, %8
  %10 = fpext float %9 to double
  store ptr %.unpack, ptr %loadgep_2, align 8, !tbaa !8
  store i64 8, ptr %loadgep_2.repack17, align 8, !tbaa !8
  store i32 20180515, ptr %loadgep_2.repack19, align 8, !tbaa !8
  store i8 1, ptr %loadgep_2.repack21, align 4, !tbaa !8
  store i8 28, ptr %loadgep_2.repack23, align 1, !tbaa !8
  store i8 2, ptr %loadgep_2.repack25, align 2, !tbaa !8
  store i8 0, ptr %loadgep_2.repack27, align 1, !tbaa !8
  store i64 1, ptr %loadgep_2.repack29, align 8, !tbaa !8
  store i64 %.unpack12.unpack.unpack14, ptr %loadgep_2.repack29.repack31, align 8, !tbaa !8
  store i64 8, ptr %loadgep_2.repack29.repack33, align 8, !tbaa !8
  %11 = sext i32 %6 to i64
  %12 = add nsw i64 %11, -1
  %13 = getelementptr double, ptr %.unpack, i64 %12
  store double %10, ptr %13, align 8, !tbaa !4
  store ptr %.unpack, ptr %loadgep_4, align 8, !tbaa !8
  store i64 8, ptr %loadgep_4.repack47, align 8, !tbaa !8
  store i32 20180515, ptr %loadgep_4.repack49, align 8, !tbaa !8
  store i8 1, ptr %loadgep_4.repack51, align 4, !tbaa !8
  store i8 28, ptr %loadgep_4.repack53, align 1, !tbaa !8
  store i8 2, ptr %loadgep_4.repack55, align 2, !tbaa !8
  store i8 0, ptr %loadgep_4.repack57, align 1, !tbaa !8
  store i64 1, ptr %loadgep_4.repack59, align 8, !tbaa !8
  store i64 %.unpack12.unpack.unpack14, ptr %loadgep_4.repack59.repack61, align 8, !tbaa !8
  store i64 8, ptr %loadgep_4.repack59.repack63, align 8, !tbaa !8
  %exitcond.not = icmp eq i32 %omp_loop.iv66, %reass.sub
  br i1 %exitcond.not, label %omp_loop.exit.loopexit, label %omp_loop.body
}
*** IR Dump After LICMPass on omp_loop.body ***

; Preheader:
omp_loop.body.lr.ph:                              ; preds = %omp.par.entry
  %.unpack = load ptr, ptr @_QFEarr.0, align 8, !tbaa !8
  %.unpack12.unpack.unpack14.b = load i1, ptr @_QFEarr.8, align 1
  %.unpack12.unpack.unpack14 = select i1 %.unpack12.unpack.unpack14.b, i64 1048576, i64 0
  %loadgep_2.repack17 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  %loadgep_2.repack19 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  %loadgep_2.repack21 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  %loadgep_2.repack23 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  %loadgep_2.repack25 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  %loadgep_2.repack27 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  %loadgep_2.repack29 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  %loadgep_2.repack29.repack31 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  %loadgep_2.repack29.repack33 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  %loadgep_4.repack47 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 1
  %loadgep_4.repack49 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 2
  %loadgep_4.repack51 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 3
  %loadgep_4.repack53 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 4
  %loadgep_4.repack55 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 5
  %loadgep_4.repack57 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 6
  %loadgep_4.repack59 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7
  %loadgep_4.repack59.repack61 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 1
  %loadgep_4.repack59.repack63 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 2
  br label %omp_loop.body

; Loop:
omp_loop.body:                                    ; preds = %omp_loop.body.lr.ph, %omp_loop.body
  %omp_loop.iv66 = phi i32 [ 0, %omp_loop.body.lr.ph ], [ %5, %omp_loop.body ]
  %5 = add nuw i32 %omp_loop.iv66, 1
  %6 = add i32 %5, %3
  %7 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %8 = sitofp i32 %7 to float
  %9 = fdiv contract float 1.000000e+00, %8
  %10 = fpext float %9 to double
  store ptr %.unpack, ptr %loadgep_2, align 8, !tbaa !8
  store i64 8, ptr %loadgep_2.repack17, align 8, !tbaa !8
  store i32 20180515, ptr %loadgep_2.repack19, align 8, !tbaa !8
  store i8 1, ptr %loadgep_2.repack21, align 4, !tbaa !8
  store i8 28, ptr %loadgep_2.repack23, align 1, !tbaa !8
  store i8 2, ptr %loadgep_2.repack25, align 2, !tbaa !8
  store i8 0, ptr %loadgep_2.repack27, align 1, !tbaa !8
  store i64 1, ptr %loadgep_2.repack29, align 8, !tbaa !8
  store i64 %.unpack12.unpack.unpack14, ptr %loadgep_2.repack29.repack31, align 8, !tbaa !8
  store i64 8, ptr %loadgep_2.repack29.repack33, align 8, !tbaa !8
  %11 = sext i32 %6 to i64
  %12 = add nsw i64 %11, -1
  %13 = getelementptr double, ptr %.unpack, i64 %12
  store double %10, ptr %13, align 8, !tbaa !4
  store ptr %.unpack, ptr %loadgep_4, align 8, !tbaa !8
  store i64 8, ptr %loadgep_4.repack47, align 8, !tbaa !8
  store i32 20180515, ptr %loadgep_4.repack49, align 8, !tbaa !8
  store i8 1, ptr %loadgep_4.repack51, align 4, !tbaa !8
  store i8 28, ptr %loadgep_4.repack53, align 1, !tbaa !8
  store i8 2, ptr %loadgep_4.repack55, align 2, !tbaa !8
  store i8 0, ptr %loadgep_4.repack57, align 1, !tbaa !8
  store i64 1, ptr %loadgep_4.repack59, align 8, !tbaa !8
  store i64 %.unpack12.unpack.unpack14, ptr %loadgep_4.repack59.repack61, align 8, !tbaa !8
  store i64 8, ptr %loadgep_4.repack59.repack63, align 8, !tbaa !8
  %exitcond.not = icmp eq i32 %omp_loop.iv66, %reass.sub
  br i1 %exitcond.not, label %omp_loop.exit.loopexit, label %omp_loop.body

; Exit blocks
omp_loop.exit.loopexit:                           ; preds = %omp_loop.body
  br label %omp_loop.exit
*** IR Dump After AlignmentFromAssumptionsPass on _QQmain..omp_par ***
; Function Attrs: norecurse nounwind
define internal void @_QQmain..omp_par(ptr noalias nocapture readnone %tid.addr, ptr noalias nocapture readnone %zero.addr, ptr nocapture readonly %0) #2 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %gep_3 = getelementptr { ptr, ptr, ptr }, ptr %0, i64 0, i32 2
  %loadgep_4 = load ptr, ptr %gep_3, align 8
  %p.lastiter = alloca i32, align 4
  %p.lowerbound = alloca i32, align 4
  %p.upperbound = alloca i32, align 4
  %p.stride = alloca i32, align 4
  %1 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %omp_loop.tripcount = tail call i32 @llvm.smax.i32(i32 %1, i32 0)
  store i32 0, ptr %p.lowerbound, align 4
  %2 = add nsw i32 %omp_loop.tripcount, -1
  store i32 %2, ptr %p.upperbound, align 4
  store i32 1, ptr %p.stride, align 4
  %omp_global_thread_num4 = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  call void @__kmpc_for_static_init_4u(ptr nonnull @1, i32 %omp_global_thread_num4, i32 34, ptr nonnull %p.lastiter, ptr nonnull %p.lowerbound, ptr nonnull %p.upperbound, ptr nonnull %p.stride, i32 1, i32 0)
  %3 = load i32, ptr %p.lowerbound, align 4
  %4 = load i32, ptr %p.upperbound, align 4
  %reass.sub = sub i32 %4, %3
  %omp_loop.cmp65.not = icmp eq i32 %reass.sub, -1
  br i1 %omp_loop.cmp65.not, label %omp_loop.exit, label %omp_loop.body.lr.ph

omp_loop.body.lr.ph:                              ; preds = %omp.par.entry
  %.unpack = load ptr, ptr @_QFEarr.0, align 8, !tbaa !8
  %.unpack12.unpack.unpack14.b = load i1, ptr @_QFEarr.8, align 1
  %.unpack12.unpack.unpack14 = select i1 %.unpack12.unpack.unpack14.b, i64 1048576, i64 0
  %loadgep_2.repack17 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  %loadgep_2.repack19 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  %loadgep_2.repack21 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  %loadgep_2.repack23 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  %loadgep_2.repack25 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  %loadgep_2.repack27 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  %loadgep_2.repack29 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  %loadgep_2.repack29.repack31 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  %loadgep_2.repack29.repack33 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  %loadgep_4.repack47 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 1
  %loadgep_4.repack49 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 2
  %loadgep_4.repack51 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 3
  %loadgep_4.repack53 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 4
  %loadgep_4.repack55 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 5
  %loadgep_4.repack57 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 6
  %loadgep_4.repack59 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7
  %loadgep_4.repack59.repack61 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 1
  %loadgep_4.repack59.repack63 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 2
  br label %omp_loop.body

omp_loop.exit.loopexit:                           ; preds = %omp_loop.body
  br label %omp_loop.exit

omp_loop.exit:                                    ; preds = %omp_loop.exit.loopexit, %omp.par.entry
  call void @__kmpc_for_static_fini(ptr nonnull @1, i32 %omp_global_thread_num4)
  call void @__kmpc_barrier(ptr nonnull @2, i32 %omp_global_thread_num4)
  ret void

omp_loop.body:                                    ; preds = %omp_loop.body.lr.ph, %omp_loop.body
  %omp_loop.iv66 = phi i32 [ 0, %omp_loop.body.lr.ph ], [ %5, %omp_loop.body ]
  %5 = add nuw i32 %omp_loop.iv66, 1
  %6 = add i32 %5, %3
  %7 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %8 = sitofp i32 %7 to float
  %9 = fdiv contract float 1.000000e+00, %8
  %10 = fpext float %9 to double
  store ptr %.unpack, ptr %loadgep_2, align 8, !tbaa !8
  store i64 8, ptr %loadgep_2.repack17, align 8, !tbaa !8
  store i32 20180515, ptr %loadgep_2.repack19, align 8, !tbaa !8
  store i8 1, ptr %loadgep_2.repack21, align 4, !tbaa !8
  store i8 28, ptr %loadgep_2.repack23, align 1, !tbaa !8
  store i8 2, ptr %loadgep_2.repack25, align 2, !tbaa !8
  store i8 0, ptr %loadgep_2.repack27, align 1, !tbaa !8
  store i64 1, ptr %loadgep_2.repack29, align 8, !tbaa !8
  store i64 %.unpack12.unpack.unpack14, ptr %loadgep_2.repack29.repack31, align 8, !tbaa !8
  store i64 8, ptr %loadgep_2.repack29.repack33, align 8, !tbaa !8
  %11 = sext i32 %6 to i64
  %12 = add nsw i64 %11, -1
  %13 = getelementptr double, ptr %.unpack, i64 %12
  store double %10, ptr %13, align 8, !tbaa !4
  store ptr %.unpack, ptr %loadgep_4, align 8, !tbaa !8
  store i64 8, ptr %loadgep_4.repack47, align 8, !tbaa !8
  store i32 20180515, ptr %loadgep_4.repack49, align 8, !tbaa !8
  store i8 1, ptr %loadgep_4.repack51, align 4, !tbaa !8
  store i8 28, ptr %loadgep_4.repack53, align 1, !tbaa !8
  store i8 2, ptr %loadgep_4.repack55, align 2, !tbaa !8
  store i8 0, ptr %loadgep_4.repack57, align 1, !tbaa !8
  store i64 1, ptr %loadgep_4.repack59, align 8, !tbaa !8
  store i64 %.unpack12.unpack.unpack14, ptr %loadgep_4.repack59.repack61, align 8, !tbaa !8
  store i64 8, ptr %loadgep_4.repack59.repack63, align 8, !tbaa !8
  %exitcond.not = icmp eq i32 %omp_loop.iv66, %reass.sub
  br i1 %exitcond.not, label %omp_loop.exit.loopexit, label %omp_loop.body
}
*** IR Dump After LoopSinkPass on _QQmain..omp_par ***
; Function Attrs: norecurse nounwind
define internal void @_QQmain..omp_par(ptr noalias nocapture readnone %tid.addr, ptr noalias nocapture readnone %zero.addr, ptr nocapture readonly %0) #2 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %gep_3 = getelementptr { ptr, ptr, ptr }, ptr %0, i64 0, i32 2
  %loadgep_4 = load ptr, ptr %gep_3, align 8
  %p.lastiter = alloca i32, align 4
  %p.lowerbound = alloca i32, align 4
  %p.upperbound = alloca i32, align 4
  %p.stride = alloca i32, align 4
  %1 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %omp_loop.tripcount = tail call i32 @llvm.smax.i32(i32 %1, i32 0)
  store i32 0, ptr %p.lowerbound, align 4
  %2 = add nsw i32 %omp_loop.tripcount, -1
  store i32 %2, ptr %p.upperbound, align 4
  store i32 1, ptr %p.stride, align 4
  %omp_global_thread_num4 = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  call void @__kmpc_for_static_init_4u(ptr nonnull @1, i32 %omp_global_thread_num4, i32 34, ptr nonnull %p.lastiter, ptr nonnull %p.lowerbound, ptr nonnull %p.upperbound, ptr nonnull %p.stride, i32 1, i32 0)
  %3 = load i32, ptr %p.lowerbound, align 4
  %4 = load i32, ptr %p.upperbound, align 4
  %reass.sub = sub i32 %4, %3
  %omp_loop.cmp65.not = icmp eq i32 %reass.sub, -1
  br i1 %omp_loop.cmp65.not, label %omp_loop.exit, label %omp_loop.body.lr.ph

omp_loop.body.lr.ph:                              ; preds = %omp.par.entry
  %.unpack = load ptr, ptr @_QFEarr.0, align 8, !tbaa !8
  %.unpack12.unpack.unpack14.b = load i1, ptr @_QFEarr.8, align 1
  %.unpack12.unpack.unpack14 = select i1 %.unpack12.unpack.unpack14.b, i64 1048576, i64 0
  %loadgep_2.repack17 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  %loadgep_2.repack19 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  %loadgep_2.repack21 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  %loadgep_2.repack23 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  %loadgep_2.repack25 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  %loadgep_2.repack27 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  %loadgep_2.repack29 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  %loadgep_2.repack29.repack31 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  %loadgep_2.repack29.repack33 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  %loadgep_4.repack47 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 1
  %loadgep_4.repack49 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 2
  %loadgep_4.repack51 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 3
  %loadgep_4.repack53 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 4
  %loadgep_4.repack55 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 5
  %loadgep_4.repack57 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 6
  %loadgep_4.repack59 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7
  %loadgep_4.repack59.repack61 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 1
  %loadgep_4.repack59.repack63 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 2
  br label %omp_loop.body

omp_loop.exit.loopexit:                           ; preds = %omp_loop.body
  br label %omp_loop.exit

omp_loop.exit:                                    ; preds = %omp_loop.exit.loopexit, %omp.par.entry
  call void @__kmpc_for_static_fini(ptr nonnull @1, i32 %omp_global_thread_num4)
  call void @__kmpc_barrier(ptr nonnull @2, i32 %omp_global_thread_num4)
  ret void

omp_loop.body:                                    ; preds = %omp_loop.body.lr.ph, %omp_loop.body
  %omp_loop.iv66 = phi i32 [ 0, %omp_loop.body.lr.ph ], [ %5, %omp_loop.body ]
  %5 = add nuw i32 %omp_loop.iv66, 1
  %6 = add i32 %5, %3
  %7 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %8 = sitofp i32 %7 to float
  %9 = fdiv contract float 1.000000e+00, %8
  %10 = fpext float %9 to double
  store ptr %.unpack, ptr %loadgep_2, align 8, !tbaa !8
  store i64 8, ptr %loadgep_2.repack17, align 8, !tbaa !8
  store i32 20180515, ptr %loadgep_2.repack19, align 8, !tbaa !8
  store i8 1, ptr %loadgep_2.repack21, align 4, !tbaa !8
  store i8 28, ptr %loadgep_2.repack23, align 1, !tbaa !8
  store i8 2, ptr %loadgep_2.repack25, align 2, !tbaa !8
  store i8 0, ptr %loadgep_2.repack27, align 1, !tbaa !8
  store i64 1, ptr %loadgep_2.repack29, align 8, !tbaa !8
  store i64 %.unpack12.unpack.unpack14, ptr %loadgep_2.repack29.repack31, align 8, !tbaa !8
  store i64 8, ptr %loadgep_2.repack29.repack33, align 8, !tbaa !8
  %11 = sext i32 %6 to i64
  %12 = add nsw i64 %11, -1
  %13 = getelementptr double, ptr %.unpack, i64 %12
  store double %10, ptr %13, align 8, !tbaa !4
  store ptr %.unpack, ptr %loadgep_4, align 8, !tbaa !8
  store i64 8, ptr %loadgep_4.repack47, align 8, !tbaa !8
  store i32 20180515, ptr %loadgep_4.repack49, align 8, !tbaa !8
  store i8 1, ptr %loadgep_4.repack51, align 4, !tbaa !8
  store i8 28, ptr %loadgep_4.repack53, align 1, !tbaa !8
  store i8 2, ptr %loadgep_4.repack55, align 2, !tbaa !8
  store i8 0, ptr %loadgep_4.repack57, align 1, !tbaa !8
  store i64 1, ptr %loadgep_4.repack59, align 8, !tbaa !8
  store i64 %.unpack12.unpack.unpack14, ptr %loadgep_4.repack59.repack61, align 8, !tbaa !8
  store i64 8, ptr %loadgep_4.repack59.repack63, align 8, !tbaa !8
  %exitcond.not = icmp eq i32 %omp_loop.iv66, %reass.sub
  br i1 %exitcond.not, label %omp_loop.exit.loopexit, label %omp_loop.body
}
*** IR Dump After InstSimplifyPass on _QQmain..omp_par ***
; Function Attrs: norecurse nounwind
define internal void @_QQmain..omp_par(ptr noalias nocapture readnone %tid.addr, ptr noalias nocapture readnone %zero.addr, ptr nocapture readonly %0) #2 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %gep_3 = getelementptr { ptr, ptr, ptr }, ptr %0, i64 0, i32 2
  %loadgep_4 = load ptr, ptr %gep_3, align 8
  %p.lastiter = alloca i32, align 4
  %p.lowerbound = alloca i32, align 4
  %p.upperbound = alloca i32, align 4
  %p.stride = alloca i32, align 4
  %1 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %omp_loop.tripcount = tail call i32 @llvm.smax.i32(i32 %1, i32 0)
  store i32 0, ptr %p.lowerbound, align 4
  %2 = add nsw i32 %omp_loop.tripcount, -1
  store i32 %2, ptr %p.upperbound, align 4
  store i32 1, ptr %p.stride, align 4
  %omp_global_thread_num4 = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  call void @__kmpc_for_static_init_4u(ptr nonnull @1, i32 %omp_global_thread_num4, i32 34, ptr nonnull %p.lastiter, ptr nonnull %p.lowerbound, ptr nonnull %p.upperbound, ptr nonnull %p.stride, i32 1, i32 0)
  %3 = load i32, ptr %p.lowerbound, align 4
  %4 = load i32, ptr %p.upperbound, align 4
  %reass.sub = sub i32 %4, %3
  %omp_loop.cmp65.not = icmp eq i32 %reass.sub, -1
  br i1 %omp_loop.cmp65.not, label %omp_loop.exit, label %omp_loop.body.lr.ph

omp_loop.body.lr.ph:                              ; preds = %omp.par.entry
  %.unpack = load ptr, ptr @_QFEarr.0, align 8, !tbaa !8
  %.unpack12.unpack.unpack14.b = load i1, ptr @_QFEarr.8, align 1
  %.unpack12.unpack.unpack14 = select i1 %.unpack12.unpack.unpack14.b, i64 1048576, i64 0
  %loadgep_2.repack17 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  %loadgep_2.repack19 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  %loadgep_2.repack21 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  %loadgep_2.repack23 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  %loadgep_2.repack25 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  %loadgep_2.repack27 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  %loadgep_2.repack29 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  %loadgep_2.repack29.repack31 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  %loadgep_2.repack29.repack33 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  %loadgep_4.repack47 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 1
  %loadgep_4.repack49 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 2
  %loadgep_4.repack51 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 3
  %loadgep_4.repack53 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 4
  %loadgep_4.repack55 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 5
  %loadgep_4.repack57 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 6
  %loadgep_4.repack59 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7
  %loadgep_4.repack59.repack61 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 1
  %loadgep_4.repack59.repack63 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 2
  br label %omp_loop.body

omp_loop.exit.loopexit:                           ; preds = %omp_loop.body
  br label %omp_loop.exit

omp_loop.exit:                                    ; preds = %omp_loop.exit.loopexit, %omp.par.entry
  call void @__kmpc_for_static_fini(ptr nonnull @1, i32 %omp_global_thread_num4)
  call void @__kmpc_barrier(ptr nonnull @2, i32 %omp_global_thread_num4)
  ret void

omp_loop.body:                                    ; preds = %omp_loop.body.lr.ph, %omp_loop.body
  %omp_loop.iv66 = phi i32 [ 0, %omp_loop.body.lr.ph ], [ %5, %omp_loop.body ]
  %5 = add nuw i32 %omp_loop.iv66, 1
  %6 = add i32 %5, %3
  %7 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %8 = sitofp i32 %7 to float
  %9 = fdiv contract float 1.000000e+00, %8
  %10 = fpext float %9 to double
  store ptr %.unpack, ptr %loadgep_2, align 8, !tbaa !8
  store i64 8, ptr %loadgep_2.repack17, align 8, !tbaa !8
  store i32 20180515, ptr %loadgep_2.repack19, align 8, !tbaa !8
  store i8 1, ptr %loadgep_2.repack21, align 4, !tbaa !8
  store i8 28, ptr %loadgep_2.repack23, align 1, !tbaa !8
  store i8 2, ptr %loadgep_2.repack25, align 2, !tbaa !8
  store i8 0, ptr %loadgep_2.repack27, align 1, !tbaa !8
  store i64 1, ptr %loadgep_2.repack29, align 8, !tbaa !8
  store i64 %.unpack12.unpack.unpack14, ptr %loadgep_2.repack29.repack31, align 8, !tbaa !8
  store i64 8, ptr %loadgep_2.repack29.repack33, align 8, !tbaa !8
  %11 = sext i32 %6 to i64
  %12 = add nsw i64 %11, -1
  %13 = getelementptr double, ptr %.unpack, i64 %12
  store double %10, ptr %13, align 8, !tbaa !4
  store ptr %.unpack, ptr %loadgep_4, align 8, !tbaa !8
  store i64 8, ptr %loadgep_4.repack47, align 8, !tbaa !8
  store i32 20180515, ptr %loadgep_4.repack49, align 8, !tbaa !8
  store i8 1, ptr %loadgep_4.repack51, align 4, !tbaa !8
  store i8 28, ptr %loadgep_4.repack53, align 1, !tbaa !8
  store i8 2, ptr %loadgep_4.repack55, align 2, !tbaa !8
  store i8 0, ptr %loadgep_4.repack57, align 1, !tbaa !8
  store i64 1, ptr %loadgep_4.repack59, align 8, !tbaa !8
  store i64 %.unpack12.unpack.unpack14, ptr %loadgep_4.repack59.repack61, align 8, !tbaa !8
  store i64 8, ptr %loadgep_4.repack59.repack63, align 8, !tbaa !8
  %exitcond.not = icmp eq i32 %omp_loop.iv66, %reass.sub
  br i1 %exitcond.not, label %omp_loop.exit.loopexit, label %omp_loop.body
}
*** IR Dump After DivRemPairsPass on _QQmain..omp_par ***
; Function Attrs: norecurse nounwind
define internal void @_QQmain..omp_par(ptr noalias nocapture readnone %tid.addr, ptr noalias nocapture readnone %zero.addr, ptr nocapture readonly %0) #2 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %gep_3 = getelementptr { ptr, ptr, ptr }, ptr %0, i64 0, i32 2
  %loadgep_4 = load ptr, ptr %gep_3, align 8
  %p.lastiter = alloca i32, align 4
  %p.lowerbound = alloca i32, align 4
  %p.upperbound = alloca i32, align 4
  %p.stride = alloca i32, align 4
  %1 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %omp_loop.tripcount = tail call i32 @llvm.smax.i32(i32 %1, i32 0)
  store i32 0, ptr %p.lowerbound, align 4
  %2 = add nsw i32 %omp_loop.tripcount, -1
  store i32 %2, ptr %p.upperbound, align 4
  store i32 1, ptr %p.stride, align 4
  %omp_global_thread_num4 = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  call void @__kmpc_for_static_init_4u(ptr nonnull @1, i32 %omp_global_thread_num4, i32 34, ptr nonnull %p.lastiter, ptr nonnull %p.lowerbound, ptr nonnull %p.upperbound, ptr nonnull %p.stride, i32 1, i32 0)
  %3 = load i32, ptr %p.lowerbound, align 4
  %4 = load i32, ptr %p.upperbound, align 4
  %reass.sub = sub i32 %4, %3
  %omp_loop.cmp65.not = icmp eq i32 %reass.sub, -1
  br i1 %omp_loop.cmp65.not, label %omp_loop.exit, label %omp_loop.body.lr.ph

omp_loop.body.lr.ph:                              ; preds = %omp.par.entry
  %.unpack = load ptr, ptr @_QFEarr.0, align 8, !tbaa !8
  %.unpack12.unpack.unpack14.b = load i1, ptr @_QFEarr.8, align 1
  %.unpack12.unpack.unpack14 = select i1 %.unpack12.unpack.unpack14.b, i64 1048576, i64 0
  %loadgep_2.repack17 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  %loadgep_2.repack19 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  %loadgep_2.repack21 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  %loadgep_2.repack23 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  %loadgep_2.repack25 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  %loadgep_2.repack27 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  %loadgep_2.repack29 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  %loadgep_2.repack29.repack31 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  %loadgep_2.repack29.repack33 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  %loadgep_4.repack47 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 1
  %loadgep_4.repack49 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 2
  %loadgep_4.repack51 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 3
  %loadgep_4.repack53 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 4
  %loadgep_4.repack55 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 5
  %loadgep_4.repack57 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 6
  %loadgep_4.repack59 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7
  %loadgep_4.repack59.repack61 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 1
  %loadgep_4.repack59.repack63 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 2
  br label %omp_loop.body

omp_loop.exit.loopexit:                           ; preds = %omp_loop.body
  br label %omp_loop.exit

omp_loop.exit:                                    ; preds = %omp_loop.exit.loopexit, %omp.par.entry
  call void @__kmpc_for_static_fini(ptr nonnull @1, i32 %omp_global_thread_num4)
  call void @__kmpc_barrier(ptr nonnull @2, i32 %omp_global_thread_num4)
  ret void

omp_loop.body:                                    ; preds = %omp_loop.body.lr.ph, %omp_loop.body
  %omp_loop.iv66 = phi i32 [ 0, %omp_loop.body.lr.ph ], [ %5, %omp_loop.body ]
  %5 = add nuw i32 %omp_loop.iv66, 1
  %6 = add i32 %5, %3
  %7 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %8 = sitofp i32 %7 to float
  %9 = fdiv contract float 1.000000e+00, %8
  %10 = fpext float %9 to double
  store ptr %.unpack, ptr %loadgep_2, align 8, !tbaa !8
  store i64 8, ptr %loadgep_2.repack17, align 8, !tbaa !8
  store i32 20180515, ptr %loadgep_2.repack19, align 8, !tbaa !8
  store i8 1, ptr %loadgep_2.repack21, align 4, !tbaa !8
  store i8 28, ptr %loadgep_2.repack23, align 1, !tbaa !8
  store i8 2, ptr %loadgep_2.repack25, align 2, !tbaa !8
  store i8 0, ptr %loadgep_2.repack27, align 1, !tbaa !8
  store i64 1, ptr %loadgep_2.repack29, align 8, !tbaa !8
  store i64 %.unpack12.unpack.unpack14, ptr %loadgep_2.repack29.repack31, align 8, !tbaa !8
  store i64 8, ptr %loadgep_2.repack29.repack33, align 8, !tbaa !8
  %11 = sext i32 %6 to i64
  %12 = add nsw i64 %11, -1
  %13 = getelementptr double, ptr %.unpack, i64 %12
  store double %10, ptr %13, align 8, !tbaa !4
  store ptr %.unpack, ptr %loadgep_4, align 8, !tbaa !8
  store i64 8, ptr %loadgep_4.repack47, align 8, !tbaa !8
  store i32 20180515, ptr %loadgep_4.repack49, align 8, !tbaa !8
  store i8 1, ptr %loadgep_4.repack51, align 4, !tbaa !8
  store i8 28, ptr %loadgep_4.repack53, align 1, !tbaa !8
  store i8 2, ptr %loadgep_4.repack55, align 2, !tbaa !8
  store i8 0, ptr %loadgep_4.repack57, align 1, !tbaa !8
  store i64 1, ptr %loadgep_4.repack59, align 8, !tbaa !8
  store i64 %.unpack12.unpack.unpack14, ptr %loadgep_4.repack59.repack61, align 8, !tbaa !8
  store i64 8, ptr %loadgep_4.repack59.repack63, align 8, !tbaa !8
  %exitcond.not = icmp eq i32 %omp_loop.iv66, %reass.sub
  br i1 %exitcond.not, label %omp_loop.exit.loopexit, label %omp_loop.body
}
*** IR Dump After TailCallElimPass on _QQmain..omp_par ***
; Function Attrs: norecurse nounwind
define internal void @_QQmain..omp_par(ptr noalias nocapture readnone %tid.addr, ptr noalias nocapture readnone %zero.addr, ptr nocapture readonly %0) #2 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %gep_3 = getelementptr { ptr, ptr, ptr }, ptr %0, i64 0, i32 2
  %loadgep_4 = load ptr, ptr %gep_3, align 8
  %p.lastiter = alloca i32, align 4
  %p.lowerbound = alloca i32, align 4
  %p.upperbound = alloca i32, align 4
  %p.stride = alloca i32, align 4
  %1 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %omp_loop.tripcount = tail call i32 @llvm.smax.i32(i32 %1, i32 0)
  store i32 0, ptr %p.lowerbound, align 4
  %2 = add nsw i32 %omp_loop.tripcount, -1
  store i32 %2, ptr %p.upperbound, align 4
  store i32 1, ptr %p.stride, align 4
  %omp_global_thread_num4 = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  call void @__kmpc_for_static_init_4u(ptr nonnull @1, i32 %omp_global_thread_num4, i32 34, ptr nonnull %p.lastiter, ptr nonnull %p.lowerbound, ptr nonnull %p.upperbound, ptr nonnull %p.stride, i32 1, i32 0)
  %3 = load i32, ptr %p.lowerbound, align 4
  %4 = load i32, ptr %p.upperbound, align 4
  %reass.sub = sub i32 %4, %3
  %omp_loop.cmp65.not = icmp eq i32 %reass.sub, -1
  br i1 %omp_loop.cmp65.not, label %omp_loop.exit, label %omp_loop.body.lr.ph

omp_loop.body.lr.ph:                              ; preds = %omp.par.entry
  %.unpack = load ptr, ptr @_QFEarr.0, align 8, !tbaa !8
  %.unpack12.unpack.unpack14.b = load i1, ptr @_QFEarr.8, align 1
  %.unpack12.unpack.unpack14 = select i1 %.unpack12.unpack.unpack14.b, i64 1048576, i64 0
  %loadgep_2.repack17 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  %loadgep_2.repack19 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  %loadgep_2.repack21 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  %loadgep_2.repack23 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  %loadgep_2.repack25 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  %loadgep_2.repack27 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  %loadgep_2.repack29 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  %loadgep_2.repack29.repack31 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  %loadgep_2.repack29.repack33 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  %loadgep_4.repack47 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 1
  %loadgep_4.repack49 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 2
  %loadgep_4.repack51 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 3
  %loadgep_4.repack53 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 4
  %loadgep_4.repack55 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 5
  %loadgep_4.repack57 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 6
  %loadgep_4.repack59 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7
  %loadgep_4.repack59.repack61 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 1
  %loadgep_4.repack59.repack63 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 2
  br label %omp_loop.body

omp_loop.exit.loopexit:                           ; preds = %omp_loop.body
  br label %omp_loop.exit

omp_loop.exit:                                    ; preds = %omp_loop.exit.loopexit, %omp.par.entry
  call void @__kmpc_for_static_fini(ptr nonnull @1, i32 %omp_global_thread_num4)
  call void @__kmpc_barrier(ptr nonnull @2, i32 %omp_global_thread_num4)
  ret void

omp_loop.body:                                    ; preds = %omp_loop.body.lr.ph, %omp_loop.body
  %omp_loop.iv66 = phi i32 [ 0, %omp_loop.body.lr.ph ], [ %5, %omp_loop.body ]
  %5 = add nuw i32 %omp_loop.iv66, 1
  %6 = add i32 %5, %3
  %7 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %8 = sitofp i32 %7 to float
  %9 = fdiv contract float 1.000000e+00, %8
  %10 = fpext float %9 to double
  store ptr %.unpack, ptr %loadgep_2, align 8, !tbaa !8
  store i64 8, ptr %loadgep_2.repack17, align 8, !tbaa !8
  store i32 20180515, ptr %loadgep_2.repack19, align 8, !tbaa !8
  store i8 1, ptr %loadgep_2.repack21, align 4, !tbaa !8
  store i8 28, ptr %loadgep_2.repack23, align 1, !tbaa !8
  store i8 2, ptr %loadgep_2.repack25, align 2, !tbaa !8
  store i8 0, ptr %loadgep_2.repack27, align 1, !tbaa !8
  store i64 1, ptr %loadgep_2.repack29, align 8, !tbaa !8
  store i64 %.unpack12.unpack.unpack14, ptr %loadgep_2.repack29.repack31, align 8, !tbaa !8
  store i64 8, ptr %loadgep_2.repack29.repack33, align 8, !tbaa !8
  %11 = sext i32 %6 to i64
  %12 = add nsw i64 %11, -1
  %13 = getelementptr double, ptr %.unpack, i64 %12
  store double %10, ptr %13, align 8, !tbaa !4
  store ptr %.unpack, ptr %loadgep_4, align 8, !tbaa !8
  store i64 8, ptr %loadgep_4.repack47, align 8, !tbaa !8
  store i32 20180515, ptr %loadgep_4.repack49, align 8, !tbaa !8
  store i8 1, ptr %loadgep_4.repack51, align 4, !tbaa !8
  store i8 28, ptr %loadgep_4.repack53, align 1, !tbaa !8
  store i8 2, ptr %loadgep_4.repack55, align 2, !tbaa !8
  store i8 0, ptr %loadgep_4.repack57, align 1, !tbaa !8
  store i64 1, ptr %loadgep_4.repack59, align 8, !tbaa !8
  store i64 %.unpack12.unpack.unpack14, ptr %loadgep_4.repack59.repack61, align 8, !tbaa !8
  store i64 8, ptr %loadgep_4.repack59.repack63, align 8, !tbaa !8
  %exitcond.not = icmp eq i32 %omp_loop.iv66, %reass.sub
  br i1 %exitcond.not, label %omp_loop.exit.loopexit, label %omp_loop.body
}
*** IR Dump After SimplifyCFGPass on _QQmain..omp_par ***
; Function Attrs: norecurse nounwind
define internal void @_QQmain..omp_par(ptr noalias nocapture readnone %tid.addr, ptr noalias nocapture readnone %zero.addr, ptr nocapture readonly %0) #2 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %gep_3 = getelementptr { ptr, ptr, ptr }, ptr %0, i64 0, i32 2
  %loadgep_4 = load ptr, ptr %gep_3, align 8
  %p.lastiter = alloca i32, align 4
  %p.lowerbound = alloca i32, align 4
  %p.upperbound = alloca i32, align 4
  %p.stride = alloca i32, align 4
  %1 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %omp_loop.tripcount = tail call i32 @llvm.smax.i32(i32 %1, i32 0)
  store i32 0, ptr %p.lowerbound, align 4
  %2 = add nsw i32 %omp_loop.tripcount, -1
  store i32 %2, ptr %p.upperbound, align 4
  store i32 1, ptr %p.stride, align 4
  %omp_global_thread_num4 = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  call void @__kmpc_for_static_init_4u(ptr nonnull @1, i32 %omp_global_thread_num4, i32 34, ptr nonnull %p.lastiter, ptr nonnull %p.lowerbound, ptr nonnull %p.upperbound, ptr nonnull %p.stride, i32 1, i32 0)
  %3 = load i32, ptr %p.lowerbound, align 4
  %4 = load i32, ptr %p.upperbound, align 4
  %reass.sub = sub i32 %4, %3
  %omp_loop.cmp65.not = icmp eq i32 %reass.sub, -1
  br i1 %omp_loop.cmp65.not, label %omp_loop.exit, label %omp_loop.body.lr.ph

omp_loop.body.lr.ph:                              ; preds = %omp.par.entry
  %.unpack = load ptr, ptr @_QFEarr.0, align 8, !tbaa !8
  %.unpack12.unpack.unpack14.b = load i1, ptr @_QFEarr.8, align 1
  %.unpack12.unpack.unpack14 = select i1 %.unpack12.unpack.unpack14.b, i64 1048576, i64 0
  %loadgep_2.repack17 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  %loadgep_2.repack19 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  %loadgep_2.repack21 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  %loadgep_2.repack23 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  %loadgep_2.repack25 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  %loadgep_2.repack27 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  %loadgep_2.repack29 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  %loadgep_2.repack29.repack31 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  %loadgep_2.repack29.repack33 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  %loadgep_4.repack47 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 1
  %loadgep_4.repack49 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 2
  %loadgep_4.repack51 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 3
  %loadgep_4.repack53 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 4
  %loadgep_4.repack55 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 5
  %loadgep_4.repack57 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 6
  %loadgep_4.repack59 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7
  %loadgep_4.repack59.repack61 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 1
  %loadgep_4.repack59.repack63 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 2
  br label %omp_loop.body

omp_loop.exit:                                    ; preds = %omp_loop.body, %omp.par.entry
  call void @__kmpc_for_static_fini(ptr nonnull @1, i32 %omp_global_thread_num4)
  call void @__kmpc_barrier(ptr nonnull @2, i32 %omp_global_thread_num4)
  ret void

omp_loop.body:                                    ; preds = %omp_loop.body.lr.ph, %omp_loop.body
  %omp_loop.iv66 = phi i32 [ 0, %omp_loop.body.lr.ph ], [ %5, %omp_loop.body ]
  %5 = add nuw i32 %omp_loop.iv66, 1
  %6 = add i32 %5, %3
  %7 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %8 = sitofp i32 %7 to float
  %9 = fdiv contract float 1.000000e+00, %8
  %10 = fpext float %9 to double
  store ptr %.unpack, ptr %loadgep_2, align 8, !tbaa !8
  store i64 8, ptr %loadgep_2.repack17, align 8, !tbaa !8
  store i32 20180515, ptr %loadgep_2.repack19, align 8, !tbaa !8
  store i8 1, ptr %loadgep_2.repack21, align 4, !tbaa !8
  store i8 28, ptr %loadgep_2.repack23, align 1, !tbaa !8
  store i8 2, ptr %loadgep_2.repack25, align 2, !tbaa !8
  store i8 0, ptr %loadgep_2.repack27, align 1, !tbaa !8
  store i64 1, ptr %loadgep_2.repack29, align 8, !tbaa !8
  store i64 %.unpack12.unpack.unpack14, ptr %loadgep_2.repack29.repack31, align 8, !tbaa !8
  store i64 8, ptr %loadgep_2.repack29.repack33, align 8, !tbaa !8
  %11 = sext i32 %6 to i64
  %12 = add nsw i64 %11, -1
  %13 = getelementptr double, ptr %.unpack, i64 %12
  store double %10, ptr %13, align 8, !tbaa !4
  store ptr %.unpack, ptr %loadgep_4, align 8, !tbaa !8
  store i64 8, ptr %loadgep_4.repack47, align 8, !tbaa !8
  store i32 20180515, ptr %loadgep_4.repack49, align 8, !tbaa !8
  store i8 1, ptr %loadgep_4.repack51, align 4, !tbaa !8
  store i8 28, ptr %loadgep_4.repack53, align 1, !tbaa !8
  store i8 2, ptr %loadgep_4.repack55, align 2, !tbaa !8
  store i8 0, ptr %loadgep_4.repack57, align 1, !tbaa !8
  store i64 1, ptr %loadgep_4.repack59, align 8, !tbaa !8
  store i64 %.unpack12.unpack.unpack14, ptr %loadgep_4.repack59.repack61, align 8, !tbaa !8
  store i64 8, ptr %loadgep_4.repack59.repack63, align 8, !tbaa !8
  %exitcond.not = icmp eq i32 %omp_loop.iv66, %reass.sub
  br i1 %exitcond.not, label %omp_loop.exit, label %omp_loop.body
}
*** IR Dump After GlobalDCEPass on [module] ***
; ModuleID = 'FIRModule'
source_filename = "FIRModule"
target datalayout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128"
target triple = "x86_64-unknown-linux-gnu"

%struct.ident_t = type { i32, i32, i32, i32, ptr }

@_QFEarr.0 = internal unnamed_addr global ptr null
@_QFEarr.8 = internal unnamed_addr global i1 false
@_QQcl.60ea5a38555821a77357f87d16df9a0f = internal constant [62 x i8] c"/g/g92/rydahl1/flangtests/src/duplicate_array_descriptors.f90\00"
@_QQcl.28612C69372C612C6531332E36653229 = internal constant [16 x i8] c"(a,i7,a,e13.6e2)"
@_QQcl.54686520726573756C74206F6620286172722831292B61727228 = internal constant [26 x i8] c"The result of (arr(1)+arr("
@_QQcl.2920697320 = internal constant [5 x i8] c") is "
@_QQEnvironmentDefaults = local_unnamed_addr constant ptr null
@0 = private unnamed_addr constant [23 x i8] c";unknown;unknown;0;0;;\00", align 1
@1 = private unnamed_addr constant %struct.ident_t { i32 0, i32 2, i32 0, i32 22, ptr @0 }, align 8
@2 = private unnamed_addr constant %struct.ident_t { i32 0, i32 66, i32 0, i32 22, ptr @0 }, align 8

; Function Attrs: mustprogress nofree nounwind willreturn allockind("alloc,uninitialized") allocsize(0) memory(inaccessiblemem: readwrite)
declare noalias noundef ptr @malloc(i64 noundef) local_unnamed_addr #0

; Function Attrs: mustprogress nounwind willreturn allockind("free") memory(argmem: readwrite, inaccessiblemem: readwrite)
declare void @free(ptr allocptr nocapture noundef) local_unnamed_addr #1

define void @_QQmain() local_unnamed_addr {
entry:
  %structArg = alloca { ptr, ptr, ptr }, align 8
  %0 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %1 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %2 = alloca i32, align 4
  store i32 1048576, ptr %2, align 4, !tbaa !4
  %3 = tail call dereferenceable_or_null(8388608) ptr @malloc(i64 8388608)
  store ptr %3, ptr @_QFEarr.0, align 8, !tbaa !8
  store i1 true, ptr @_QFEarr.8, align 1
  %omp_global_thread_num = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %2, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %1, ptr %gep_5, align 8
  %gep_6 = getelementptr inbounds { ptr, ptr, ptr }, ptr %structArg, i64 0, i32 2
  store ptr %0, ptr %gep_6, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QQmain..omp_par, ptr nonnull %structArg)
  %4 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.60ea5a38555821a77357f87d16df9a0f, i32 21)
  %5 = call i1 @_FortranAioOutputAscii(ptr %4, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %6 = load i32, ptr %2, align 4, !tbaa !4
  %7 = call i1 @_FortranAioOutputInteger32(ptr %4, i32 %6)
  %8 = call i1 @_FortranAioOutputAscii(ptr %4, ptr nonnull @_QQcl.2920697320, i64 5)
  %.unpack = load ptr, ptr @_QFEarr.0, align 8, !tbaa !8
  %9 = load double, ptr %.unpack, align 8, !tbaa !4
  %10 = load i32, ptr %2, align 4, !tbaa !4
  %11 = sext i32 %10 to i64
  %12 = add nsw i64 %11, -1
  %13 = getelementptr double, ptr %.unpack, i64 %12
  %14 = load double, ptr %13, align 8, !tbaa !4
  %15 = fadd contract double %9, %14
  %16 = call i1 @_FortranAioOutputReal64(ptr %4, double %15)
  %17 = call i32 @_FortranAioEndIoStatement(ptr %4)
  %.unpack101 = load ptr, ptr @_QFEarr.0, align 8, !tbaa !8
  call void @free(ptr %.unpack101)
  store ptr null, ptr @_QFEarr.0, align 8, !tbaa !8
  store i1 false, ptr @_QFEarr.8, align 1
  ret void
}

; Function Attrs: norecurse nounwind
define internal void @_QQmain..omp_par(ptr noalias nocapture readnone %tid.addr, ptr noalias nocapture readnone %zero.addr, ptr nocapture readonly %0) #2 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %gep_3 = getelementptr { ptr, ptr, ptr }, ptr %0, i64 0, i32 2
  %loadgep_4 = load ptr, ptr %gep_3, align 8
  %p.lastiter = alloca i32, align 4
  %p.lowerbound = alloca i32, align 4
  %p.upperbound = alloca i32, align 4
  %p.stride = alloca i32, align 4
  %1 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %omp_loop.tripcount = tail call i32 @llvm.smax.i32(i32 %1, i32 0)
  store i32 0, ptr %p.lowerbound, align 4
  %2 = add nsw i32 %omp_loop.tripcount, -1
  store i32 %2, ptr %p.upperbound, align 4
  store i32 1, ptr %p.stride, align 4
  %omp_global_thread_num4 = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  call void @__kmpc_for_static_init_4u(ptr nonnull @1, i32 %omp_global_thread_num4, i32 34, ptr nonnull %p.lastiter, ptr nonnull %p.lowerbound, ptr nonnull %p.upperbound, ptr nonnull %p.stride, i32 1, i32 0)
  %3 = load i32, ptr %p.lowerbound, align 4
  %4 = load i32, ptr %p.upperbound, align 4
  %reass.sub = sub i32 %4, %3
  %omp_loop.cmp65.not = icmp eq i32 %reass.sub, -1
  br i1 %omp_loop.cmp65.not, label %omp_loop.exit, label %omp_loop.body.lr.ph

omp_loop.body.lr.ph:                              ; preds = %omp.par.entry
  %.unpack = load ptr, ptr @_QFEarr.0, align 8, !tbaa !8
  %.unpack12.unpack.unpack14.b = load i1, ptr @_QFEarr.8, align 1
  %.unpack12.unpack.unpack14 = select i1 %.unpack12.unpack.unpack14.b, i64 1048576, i64 0
  %loadgep_2.repack17 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  %loadgep_2.repack19 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  %loadgep_2.repack21 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  %loadgep_2.repack23 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  %loadgep_2.repack25 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  %loadgep_2.repack27 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  %loadgep_2.repack29 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  %loadgep_2.repack29.repack31 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  %loadgep_2.repack29.repack33 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  %loadgep_4.repack47 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 1
  %loadgep_4.repack49 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 2
  %loadgep_4.repack51 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 3
  %loadgep_4.repack53 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 4
  %loadgep_4.repack55 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 5
  %loadgep_4.repack57 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 6
  %loadgep_4.repack59 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7
  %loadgep_4.repack59.repack61 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 1
  %loadgep_4.repack59.repack63 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 2
  br label %omp_loop.body

omp_loop.exit:                                    ; preds = %omp_loop.body, %omp.par.entry
  call void @__kmpc_for_static_fini(ptr nonnull @1, i32 %omp_global_thread_num4)
  call void @__kmpc_barrier(ptr nonnull @2, i32 %omp_global_thread_num4)
  ret void

omp_loop.body:                                    ; preds = %omp_loop.body.lr.ph, %omp_loop.body
  %omp_loop.iv66 = phi i32 [ 0, %omp_loop.body.lr.ph ], [ %5, %omp_loop.body ]
  %5 = add nuw i32 %omp_loop.iv66, 1
  %6 = add i32 %5, %3
  %7 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %8 = sitofp i32 %7 to float
  %9 = fdiv contract float 1.000000e+00, %8
  %10 = fpext float %9 to double
  store ptr %.unpack, ptr %loadgep_2, align 8, !tbaa !8
  store i64 8, ptr %loadgep_2.repack17, align 8, !tbaa !8
  store i32 20180515, ptr %loadgep_2.repack19, align 8, !tbaa !8
  store i8 1, ptr %loadgep_2.repack21, align 4, !tbaa !8
  store i8 28, ptr %loadgep_2.repack23, align 1, !tbaa !8
  store i8 2, ptr %loadgep_2.repack25, align 2, !tbaa !8
  store i8 0, ptr %loadgep_2.repack27, align 1, !tbaa !8
  store i64 1, ptr %loadgep_2.repack29, align 8, !tbaa !8
  store i64 %.unpack12.unpack.unpack14, ptr %loadgep_2.repack29.repack31, align 8, !tbaa !8
  store i64 8, ptr %loadgep_2.repack29.repack33, align 8, !tbaa !8
  %11 = sext i32 %6 to i64
  %12 = add nsw i64 %11, -1
  %13 = getelementptr double, ptr %.unpack, i64 %12
  store double %10, ptr %13, align 8, !tbaa !4
  store ptr %.unpack, ptr %loadgep_4, align 8, !tbaa !8
  store i64 8, ptr %loadgep_4.repack47, align 8, !tbaa !8
  store i32 20180515, ptr %loadgep_4.repack49, align 8, !tbaa !8
  store i8 1, ptr %loadgep_4.repack51, align 4, !tbaa !8
  store i8 28, ptr %loadgep_4.repack53, align 1, !tbaa !8
  store i8 2, ptr %loadgep_4.repack55, align 2, !tbaa !8
  store i8 0, ptr %loadgep_4.repack57, align 1, !tbaa !8
  store i64 1, ptr %loadgep_4.repack59, align 8, !tbaa !8
  store i64 %.unpack12.unpack.unpack14, ptr %loadgep_4.repack59.repack61, align 8, !tbaa !8
  store i64 8, ptr %loadgep_4.repack59.repack63, align 8, !tbaa !8
  %exitcond.not = icmp eq i32 %omp_loop.iv66, %reass.sub
  br i1 %exitcond.not, label %omp_loop.exit, label %omp_loop.body
}

declare ptr @_FortranAioBeginExternalFormattedOutput(ptr, i64, ptr, i32, ptr, i32) local_unnamed_addr

declare zeroext i1 @_FortranAioOutputAscii(ptr, ptr, i64) local_unnamed_addr

declare zeroext i1 @_FortranAioOutputInteger32(ptr, i32) local_unnamed_addr

declare zeroext i1 @_FortranAioOutputReal64(ptr, double) local_unnamed_addr

declare i32 @_FortranAioEndIoStatement(ptr) local_unnamed_addr

; Function Attrs: nounwind
declare i32 @__kmpc_global_thread_num(ptr) local_unnamed_addr #3

; Function Attrs: nounwind
declare void @__kmpc_for_static_init_4u(ptr, i32, i32, ptr, ptr, ptr, ptr, i32, i32) local_unnamed_addr #3

; Function Attrs: nounwind
declare void @__kmpc_for_static_fini(ptr, i32) local_unnamed_addr #3

; Function Attrs: convergent nounwind
declare void @__kmpc_barrier(ptr, i32) local_unnamed_addr #4

; Function Attrs: nounwind
declare !callback !10 void @__kmpc_fork_call(ptr, i32, ptr, ...) local_unnamed_addr #3

; Function Attrs: nocallback nofree nosync nounwind speculatable willreturn memory(none)
declare i32 @llvm.smax.i32(i32, i32) #5

attributes #0 = { mustprogress nofree nounwind willreturn allockind("alloc,uninitialized") allocsize(0) memory(inaccessiblemem: readwrite) "alloc-family"="malloc" }
attributes #1 = { mustprogress nounwind willreturn allockind("free") memory(argmem: readwrite, inaccessiblemem: readwrite) "alloc-family"="malloc" }
attributes #2 = { norecurse nounwind }
attributes #3 = { nounwind }
attributes #4 = { convergent nounwind }
attributes #5 = { nocallback nofree nosync nounwind speculatable willreturn memory(none) }

!llvm.module.flags = !{!0, !1, !2, !3}

!0 = !{i32 2, !"Debug Info Version", i32 3}
!1 = !{i32 7, !"openmp", i32 11}
!2 = !{i32 8, !"PIC Level", i32 2}
!3 = !{i32 7, !"PIE Level", i32 2}
!4 = !{!5, !5, i64 0}
!5 = !{!"any data access", !6, i64 0}
!6 = !{!"any access", !7, i64 0}
!7 = !{!"Flang Type TBAA Root"}
!8 = !{!9, !9, i64 0}
!9 = !{!"descriptor member", !6, i64 0}
!10 = !{!11}
!11 = !{i64 2, i64 -1, i64 -1, i1 true}
*** IR Dump After ConstantMergePass on [module] ***
; ModuleID = 'FIRModule'
source_filename = "FIRModule"
target datalayout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128"
target triple = "x86_64-unknown-linux-gnu"

%struct.ident_t = type { i32, i32, i32, i32, ptr }

@_QFEarr.0 = internal unnamed_addr global ptr null
@_QFEarr.8 = internal unnamed_addr global i1 false
@_QQcl.60ea5a38555821a77357f87d16df9a0f = internal constant [62 x i8] c"/g/g92/rydahl1/flangtests/src/duplicate_array_descriptors.f90\00"
@_QQcl.28612C69372C612C6531332E36653229 = internal constant [16 x i8] c"(a,i7,a,e13.6e2)"
@_QQcl.54686520726573756C74206F6620286172722831292B61727228 = internal constant [26 x i8] c"The result of (arr(1)+arr("
@_QQcl.2920697320 = internal constant [5 x i8] c") is "
@_QQEnvironmentDefaults = local_unnamed_addr constant ptr null
@0 = private unnamed_addr constant [23 x i8] c";unknown;unknown;0;0;;\00", align 1
@1 = private unnamed_addr constant %struct.ident_t { i32 0, i32 2, i32 0, i32 22, ptr @0 }, align 8
@2 = private unnamed_addr constant %struct.ident_t { i32 0, i32 66, i32 0, i32 22, ptr @0 }, align 8

; Function Attrs: mustprogress nofree nounwind willreturn allockind("alloc,uninitialized") allocsize(0) memory(inaccessiblemem: readwrite)
declare noalias noundef ptr @malloc(i64 noundef) local_unnamed_addr #0

; Function Attrs: mustprogress nounwind willreturn allockind("free") memory(argmem: readwrite, inaccessiblemem: readwrite)
declare void @free(ptr allocptr nocapture noundef) local_unnamed_addr #1

define void @_QQmain() local_unnamed_addr {
entry:
  %structArg = alloca { ptr, ptr, ptr }, align 8
  %0 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %1 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %2 = alloca i32, align 4
  store i32 1048576, ptr %2, align 4, !tbaa !4
  %3 = tail call dereferenceable_or_null(8388608) ptr @malloc(i64 8388608)
  store ptr %3, ptr @_QFEarr.0, align 8, !tbaa !8
  store i1 true, ptr @_QFEarr.8, align 1
  %omp_global_thread_num = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %2, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %1, ptr %gep_5, align 8
  %gep_6 = getelementptr inbounds { ptr, ptr, ptr }, ptr %structArg, i64 0, i32 2
  store ptr %0, ptr %gep_6, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QQmain..omp_par, ptr nonnull %structArg)
  %4 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.60ea5a38555821a77357f87d16df9a0f, i32 21)
  %5 = call i1 @_FortranAioOutputAscii(ptr %4, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %6 = load i32, ptr %2, align 4, !tbaa !4
  %7 = call i1 @_FortranAioOutputInteger32(ptr %4, i32 %6)
  %8 = call i1 @_FortranAioOutputAscii(ptr %4, ptr nonnull @_QQcl.2920697320, i64 5)
  %.unpack = load ptr, ptr @_QFEarr.0, align 8, !tbaa !8
  %9 = load double, ptr %.unpack, align 8, !tbaa !4
  %10 = load i32, ptr %2, align 4, !tbaa !4
  %11 = sext i32 %10 to i64
  %12 = add nsw i64 %11, -1
  %13 = getelementptr double, ptr %.unpack, i64 %12
  %14 = load double, ptr %13, align 8, !tbaa !4
  %15 = fadd contract double %9, %14
  %16 = call i1 @_FortranAioOutputReal64(ptr %4, double %15)
  %17 = call i32 @_FortranAioEndIoStatement(ptr %4)
  %.unpack101 = load ptr, ptr @_QFEarr.0, align 8, !tbaa !8
  call void @free(ptr %.unpack101)
  store ptr null, ptr @_QFEarr.0, align 8, !tbaa !8
  store i1 false, ptr @_QFEarr.8, align 1
  ret void
}

; Function Attrs: norecurse nounwind
define internal void @_QQmain..omp_par(ptr noalias nocapture readnone %tid.addr, ptr noalias nocapture readnone %zero.addr, ptr nocapture readonly %0) #2 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %gep_3 = getelementptr { ptr, ptr, ptr }, ptr %0, i64 0, i32 2
  %loadgep_4 = load ptr, ptr %gep_3, align 8
  %p.lastiter = alloca i32, align 4
  %p.lowerbound = alloca i32, align 4
  %p.upperbound = alloca i32, align 4
  %p.stride = alloca i32, align 4
  %1 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %omp_loop.tripcount = tail call i32 @llvm.smax.i32(i32 %1, i32 0)
  store i32 0, ptr %p.lowerbound, align 4
  %2 = add nsw i32 %omp_loop.tripcount, -1
  store i32 %2, ptr %p.upperbound, align 4
  store i32 1, ptr %p.stride, align 4
  %omp_global_thread_num4 = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  call void @__kmpc_for_static_init_4u(ptr nonnull @1, i32 %omp_global_thread_num4, i32 34, ptr nonnull %p.lastiter, ptr nonnull %p.lowerbound, ptr nonnull %p.upperbound, ptr nonnull %p.stride, i32 1, i32 0)
  %3 = load i32, ptr %p.lowerbound, align 4
  %4 = load i32, ptr %p.upperbound, align 4
  %reass.sub = sub i32 %4, %3
  %omp_loop.cmp65.not = icmp eq i32 %reass.sub, -1
  br i1 %omp_loop.cmp65.not, label %omp_loop.exit, label %omp_loop.body.lr.ph

omp_loop.body.lr.ph:                              ; preds = %omp.par.entry
  %.unpack = load ptr, ptr @_QFEarr.0, align 8, !tbaa !8
  %.unpack12.unpack.unpack14.b = load i1, ptr @_QFEarr.8, align 1
  %.unpack12.unpack.unpack14 = select i1 %.unpack12.unpack.unpack14.b, i64 1048576, i64 0
  %loadgep_2.repack17 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  %loadgep_2.repack19 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  %loadgep_2.repack21 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  %loadgep_2.repack23 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  %loadgep_2.repack25 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  %loadgep_2.repack27 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  %loadgep_2.repack29 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  %loadgep_2.repack29.repack31 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  %loadgep_2.repack29.repack33 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  %loadgep_4.repack47 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 1
  %loadgep_4.repack49 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 2
  %loadgep_4.repack51 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 3
  %loadgep_4.repack53 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 4
  %loadgep_4.repack55 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 5
  %loadgep_4.repack57 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 6
  %loadgep_4.repack59 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7
  %loadgep_4.repack59.repack61 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 1
  %loadgep_4.repack59.repack63 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 2
  br label %omp_loop.body

omp_loop.exit:                                    ; preds = %omp_loop.body, %omp.par.entry
  call void @__kmpc_for_static_fini(ptr nonnull @1, i32 %omp_global_thread_num4)
  call void @__kmpc_barrier(ptr nonnull @2, i32 %omp_global_thread_num4)
  ret void

omp_loop.body:                                    ; preds = %omp_loop.body.lr.ph, %omp_loop.body
  %omp_loop.iv66 = phi i32 [ 0, %omp_loop.body.lr.ph ], [ %5, %omp_loop.body ]
  %5 = add nuw i32 %omp_loop.iv66, 1
  %6 = add i32 %5, %3
  %7 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %8 = sitofp i32 %7 to float
  %9 = fdiv contract float 1.000000e+00, %8
  %10 = fpext float %9 to double
  store ptr %.unpack, ptr %loadgep_2, align 8, !tbaa !8
  store i64 8, ptr %loadgep_2.repack17, align 8, !tbaa !8
  store i32 20180515, ptr %loadgep_2.repack19, align 8, !tbaa !8
  store i8 1, ptr %loadgep_2.repack21, align 4, !tbaa !8
  store i8 28, ptr %loadgep_2.repack23, align 1, !tbaa !8
  store i8 2, ptr %loadgep_2.repack25, align 2, !tbaa !8
  store i8 0, ptr %loadgep_2.repack27, align 1, !tbaa !8
  store i64 1, ptr %loadgep_2.repack29, align 8, !tbaa !8
  store i64 %.unpack12.unpack.unpack14, ptr %loadgep_2.repack29.repack31, align 8, !tbaa !8
  store i64 8, ptr %loadgep_2.repack29.repack33, align 8, !tbaa !8
  %11 = sext i32 %6 to i64
  %12 = add nsw i64 %11, -1
  %13 = getelementptr double, ptr %.unpack, i64 %12
  store double %10, ptr %13, align 8, !tbaa !4
  store ptr %.unpack, ptr %loadgep_4, align 8, !tbaa !8
  store i64 8, ptr %loadgep_4.repack47, align 8, !tbaa !8
  store i32 20180515, ptr %loadgep_4.repack49, align 8, !tbaa !8
  store i8 1, ptr %loadgep_4.repack51, align 4, !tbaa !8
  store i8 28, ptr %loadgep_4.repack53, align 1, !tbaa !8
  store i8 2, ptr %loadgep_4.repack55, align 2, !tbaa !8
  store i8 0, ptr %loadgep_4.repack57, align 1, !tbaa !8
  store i64 1, ptr %loadgep_4.repack59, align 8, !tbaa !8
  store i64 %.unpack12.unpack.unpack14, ptr %loadgep_4.repack59.repack61, align 8, !tbaa !8
  store i64 8, ptr %loadgep_4.repack59.repack63, align 8, !tbaa !8
  %exitcond.not = icmp eq i32 %omp_loop.iv66, %reass.sub
  br i1 %exitcond.not, label %omp_loop.exit, label %omp_loop.body
}

declare ptr @_FortranAioBeginExternalFormattedOutput(ptr, i64, ptr, i32, ptr, i32) local_unnamed_addr

declare zeroext i1 @_FortranAioOutputAscii(ptr, ptr, i64) local_unnamed_addr

declare zeroext i1 @_FortranAioOutputInteger32(ptr, i32) local_unnamed_addr

declare zeroext i1 @_FortranAioOutputReal64(ptr, double) local_unnamed_addr

declare i32 @_FortranAioEndIoStatement(ptr) local_unnamed_addr

; Function Attrs: nounwind
declare i32 @__kmpc_global_thread_num(ptr) local_unnamed_addr #3

; Function Attrs: nounwind
declare void @__kmpc_for_static_init_4u(ptr, i32, i32, ptr, ptr, ptr, ptr, i32, i32) local_unnamed_addr #3

; Function Attrs: nounwind
declare void @__kmpc_for_static_fini(ptr, i32) local_unnamed_addr #3

; Function Attrs: convergent nounwind
declare void @__kmpc_barrier(ptr, i32) local_unnamed_addr #4

; Function Attrs: nounwind
declare !callback !10 void @__kmpc_fork_call(ptr, i32, ptr, ...) local_unnamed_addr #3

; Function Attrs: nocallback nofree nosync nounwind speculatable willreturn memory(none)
declare i32 @llvm.smax.i32(i32, i32) #5

attributes #0 = { mustprogress nofree nounwind willreturn allockind("alloc,uninitialized") allocsize(0) memory(inaccessiblemem: readwrite) "alloc-family"="malloc" }
attributes #1 = { mustprogress nounwind willreturn allockind("free") memory(argmem: readwrite, inaccessiblemem: readwrite) "alloc-family"="malloc" }
attributes #2 = { norecurse nounwind }
attributes #3 = { nounwind }
attributes #4 = { convergent nounwind }
attributes #5 = { nocallback nofree nosync nounwind speculatable willreturn memory(none) }

!llvm.module.flags = !{!0, !1, !2, !3}

!0 = !{i32 2, !"Debug Info Version", i32 3}
!1 = !{i32 7, !"openmp", i32 11}
!2 = !{i32 8, !"PIC Level", i32 2}
!3 = !{i32 7, !"PIE Level", i32 2}
!4 = !{!5, !5, i64 0}
!5 = !{!"any data access", !6, i64 0}
!6 = !{!"any access", !7, i64 0}
!7 = !{!"Flang Type TBAA Root"}
!8 = !{!9, !9, i64 0}
!9 = !{!"descriptor member", !6, i64 0}
!10 = !{!11}
!11 = !{i64 2, i64 -1, i64 -1, i1 true}
*** IR Dump After CGProfilePass on [module] ***
; ModuleID = 'FIRModule'
source_filename = "FIRModule"
target datalayout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128"
target triple = "x86_64-unknown-linux-gnu"

%struct.ident_t = type { i32, i32, i32, i32, ptr }

@_QFEarr.0 = internal unnamed_addr global ptr null
@_QFEarr.8 = internal unnamed_addr global i1 false
@_QQcl.60ea5a38555821a77357f87d16df9a0f = internal constant [62 x i8] c"/g/g92/rydahl1/flangtests/src/duplicate_array_descriptors.f90\00"
@_QQcl.28612C69372C612C6531332E36653229 = internal constant [16 x i8] c"(a,i7,a,e13.6e2)"
@_QQcl.54686520726573756C74206F6620286172722831292B61727228 = internal constant [26 x i8] c"The result of (arr(1)+arr("
@_QQcl.2920697320 = internal constant [5 x i8] c") is "
@_QQEnvironmentDefaults = local_unnamed_addr constant ptr null
@0 = private unnamed_addr constant [23 x i8] c";unknown;unknown;0;0;;\00", align 1
@1 = private unnamed_addr constant %struct.ident_t { i32 0, i32 2, i32 0, i32 22, ptr @0 }, align 8
@2 = private unnamed_addr constant %struct.ident_t { i32 0, i32 66, i32 0, i32 22, ptr @0 }, align 8

; Function Attrs: mustprogress nofree nounwind willreturn allockind("alloc,uninitialized") allocsize(0) memory(inaccessiblemem: readwrite)
declare noalias noundef ptr @malloc(i64 noundef) local_unnamed_addr #0

; Function Attrs: mustprogress nounwind willreturn allockind("free") memory(argmem: readwrite, inaccessiblemem: readwrite)
declare void @free(ptr allocptr nocapture noundef) local_unnamed_addr #1

define void @_QQmain() local_unnamed_addr {
entry:
  %structArg = alloca { ptr, ptr, ptr }, align 8
  %0 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %1 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %2 = alloca i32, align 4
  store i32 1048576, ptr %2, align 4, !tbaa !4
  %3 = tail call dereferenceable_or_null(8388608) ptr @malloc(i64 8388608)
  store ptr %3, ptr @_QFEarr.0, align 8, !tbaa !8
  store i1 true, ptr @_QFEarr.8, align 1
  %omp_global_thread_num = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %2, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %1, ptr %gep_5, align 8
  %gep_6 = getelementptr inbounds { ptr, ptr, ptr }, ptr %structArg, i64 0, i32 2
  store ptr %0, ptr %gep_6, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QQmain..omp_par, ptr nonnull %structArg)
  %4 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.60ea5a38555821a77357f87d16df9a0f, i32 21)
  %5 = call i1 @_FortranAioOutputAscii(ptr %4, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %6 = load i32, ptr %2, align 4, !tbaa !4
  %7 = call i1 @_FortranAioOutputInteger32(ptr %4, i32 %6)
  %8 = call i1 @_FortranAioOutputAscii(ptr %4, ptr nonnull @_QQcl.2920697320, i64 5)
  %.unpack = load ptr, ptr @_QFEarr.0, align 8, !tbaa !8
  %9 = load double, ptr %.unpack, align 8, !tbaa !4
  %10 = load i32, ptr %2, align 4, !tbaa !4
  %11 = sext i32 %10 to i64
  %12 = add nsw i64 %11, -1
  %13 = getelementptr double, ptr %.unpack, i64 %12
  %14 = load double, ptr %13, align 8, !tbaa !4
  %15 = fadd contract double %9, %14
  %16 = call i1 @_FortranAioOutputReal64(ptr %4, double %15)
  %17 = call i32 @_FortranAioEndIoStatement(ptr %4)
  %.unpack101 = load ptr, ptr @_QFEarr.0, align 8, !tbaa !8
  call void @free(ptr %.unpack101)
  store ptr null, ptr @_QFEarr.0, align 8, !tbaa !8
  store i1 false, ptr @_QFEarr.8, align 1
  ret void
}

; Function Attrs: norecurse nounwind
define internal void @_QQmain..omp_par(ptr noalias nocapture readnone %tid.addr, ptr noalias nocapture readnone %zero.addr, ptr nocapture readonly %0) #2 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %gep_3 = getelementptr { ptr, ptr, ptr }, ptr %0, i64 0, i32 2
  %loadgep_4 = load ptr, ptr %gep_3, align 8
  %p.lastiter = alloca i32, align 4
  %p.lowerbound = alloca i32, align 4
  %p.upperbound = alloca i32, align 4
  %p.stride = alloca i32, align 4
  %1 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %omp_loop.tripcount = tail call i32 @llvm.smax.i32(i32 %1, i32 0)
  store i32 0, ptr %p.lowerbound, align 4
  %2 = add nsw i32 %omp_loop.tripcount, -1
  store i32 %2, ptr %p.upperbound, align 4
  store i32 1, ptr %p.stride, align 4
  %omp_global_thread_num4 = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  call void @__kmpc_for_static_init_4u(ptr nonnull @1, i32 %omp_global_thread_num4, i32 34, ptr nonnull %p.lastiter, ptr nonnull %p.lowerbound, ptr nonnull %p.upperbound, ptr nonnull %p.stride, i32 1, i32 0)
  %3 = load i32, ptr %p.lowerbound, align 4
  %4 = load i32, ptr %p.upperbound, align 4
  %reass.sub = sub i32 %4, %3
  %omp_loop.cmp65.not = icmp eq i32 %reass.sub, -1
  br i1 %omp_loop.cmp65.not, label %omp_loop.exit, label %omp_loop.body.lr.ph

omp_loop.body.lr.ph:                              ; preds = %omp.par.entry
  %.unpack = load ptr, ptr @_QFEarr.0, align 8, !tbaa !8
  %.unpack12.unpack.unpack14.b = load i1, ptr @_QFEarr.8, align 1
  %.unpack12.unpack.unpack14 = select i1 %.unpack12.unpack.unpack14.b, i64 1048576, i64 0
  %loadgep_2.repack17 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  %loadgep_2.repack19 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  %loadgep_2.repack21 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  %loadgep_2.repack23 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  %loadgep_2.repack25 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  %loadgep_2.repack27 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  %loadgep_2.repack29 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  %loadgep_2.repack29.repack31 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  %loadgep_2.repack29.repack33 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  %loadgep_4.repack47 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 1
  %loadgep_4.repack49 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 2
  %loadgep_4.repack51 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 3
  %loadgep_4.repack53 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 4
  %loadgep_4.repack55 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 5
  %loadgep_4.repack57 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 6
  %loadgep_4.repack59 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7
  %loadgep_4.repack59.repack61 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 1
  %loadgep_4.repack59.repack63 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 2
  br label %omp_loop.body

omp_loop.exit:                                    ; preds = %omp_loop.body, %omp.par.entry
  call void @__kmpc_for_static_fini(ptr nonnull @1, i32 %omp_global_thread_num4)
  call void @__kmpc_barrier(ptr nonnull @2, i32 %omp_global_thread_num4)
  ret void

omp_loop.body:                                    ; preds = %omp_loop.body.lr.ph, %omp_loop.body
  %omp_loop.iv66 = phi i32 [ 0, %omp_loop.body.lr.ph ], [ %5, %omp_loop.body ]
  %5 = add nuw i32 %omp_loop.iv66, 1
  %6 = add i32 %5, %3
  %7 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %8 = sitofp i32 %7 to float
  %9 = fdiv contract float 1.000000e+00, %8
  %10 = fpext float %9 to double
  store ptr %.unpack, ptr %loadgep_2, align 8, !tbaa !8
  store i64 8, ptr %loadgep_2.repack17, align 8, !tbaa !8
  store i32 20180515, ptr %loadgep_2.repack19, align 8, !tbaa !8
  store i8 1, ptr %loadgep_2.repack21, align 4, !tbaa !8
  store i8 28, ptr %loadgep_2.repack23, align 1, !tbaa !8
  store i8 2, ptr %loadgep_2.repack25, align 2, !tbaa !8
  store i8 0, ptr %loadgep_2.repack27, align 1, !tbaa !8
  store i64 1, ptr %loadgep_2.repack29, align 8, !tbaa !8
  store i64 %.unpack12.unpack.unpack14, ptr %loadgep_2.repack29.repack31, align 8, !tbaa !8
  store i64 8, ptr %loadgep_2.repack29.repack33, align 8, !tbaa !8
  %11 = sext i32 %6 to i64
  %12 = add nsw i64 %11, -1
  %13 = getelementptr double, ptr %.unpack, i64 %12
  store double %10, ptr %13, align 8, !tbaa !4
  store ptr %.unpack, ptr %loadgep_4, align 8, !tbaa !8
  store i64 8, ptr %loadgep_4.repack47, align 8, !tbaa !8
  store i32 20180515, ptr %loadgep_4.repack49, align 8, !tbaa !8
  store i8 1, ptr %loadgep_4.repack51, align 4, !tbaa !8
  store i8 28, ptr %loadgep_4.repack53, align 1, !tbaa !8
  store i8 2, ptr %loadgep_4.repack55, align 2, !tbaa !8
  store i8 0, ptr %loadgep_4.repack57, align 1, !tbaa !8
  store i64 1, ptr %loadgep_4.repack59, align 8, !tbaa !8
  store i64 %.unpack12.unpack.unpack14, ptr %loadgep_4.repack59.repack61, align 8, !tbaa !8
  store i64 8, ptr %loadgep_4.repack59.repack63, align 8, !tbaa !8
  %exitcond.not = icmp eq i32 %omp_loop.iv66, %reass.sub
  br i1 %exitcond.not, label %omp_loop.exit, label %omp_loop.body
}

declare ptr @_FortranAioBeginExternalFormattedOutput(ptr, i64, ptr, i32, ptr, i32) local_unnamed_addr

declare zeroext i1 @_FortranAioOutputAscii(ptr, ptr, i64) local_unnamed_addr

declare zeroext i1 @_FortranAioOutputInteger32(ptr, i32) local_unnamed_addr

declare zeroext i1 @_FortranAioOutputReal64(ptr, double) local_unnamed_addr

declare i32 @_FortranAioEndIoStatement(ptr) local_unnamed_addr

; Function Attrs: nounwind
declare i32 @__kmpc_global_thread_num(ptr) local_unnamed_addr #3

; Function Attrs: nounwind
declare void @__kmpc_for_static_init_4u(ptr, i32, i32, ptr, ptr, ptr, ptr, i32, i32) local_unnamed_addr #3

; Function Attrs: nounwind
declare void @__kmpc_for_static_fini(ptr, i32) local_unnamed_addr #3

; Function Attrs: convergent nounwind
declare void @__kmpc_barrier(ptr, i32) local_unnamed_addr #4

; Function Attrs: nounwind
declare !callback !10 void @__kmpc_fork_call(ptr, i32, ptr, ...) local_unnamed_addr #3

; Function Attrs: nocallback nofree nosync nounwind speculatable willreturn memory(none)
declare i32 @llvm.smax.i32(i32, i32) #5

attributes #0 = { mustprogress nofree nounwind willreturn allockind("alloc,uninitialized") allocsize(0) memory(inaccessiblemem: readwrite) "alloc-family"="malloc" }
attributes #1 = { mustprogress nounwind willreturn allockind("free") memory(argmem: readwrite, inaccessiblemem: readwrite) "alloc-family"="malloc" }
attributes #2 = { norecurse nounwind }
attributes #3 = { nounwind }
attributes #4 = { convergent nounwind }
attributes #5 = { nocallback nofree nosync nounwind speculatable willreturn memory(none) }

!llvm.module.flags = !{!0, !1, !2, !3}

!0 = !{i32 2, !"Debug Info Version", i32 3}
!1 = !{i32 7, !"openmp", i32 11}
!2 = !{i32 8, !"PIC Level", i32 2}
!3 = !{i32 7, !"PIE Level", i32 2}
!4 = !{!5, !5, i64 0}
!5 = !{!"any data access", !6, i64 0}
!6 = !{!"any access", !7, i64 0}
!7 = !{!"Flang Type TBAA Root"}
!8 = !{!9, !9, i64 0}
!9 = !{!"descriptor member", !6, i64 0}
!10 = !{!11}
!11 = !{i64 2, i64 -1, i64 -1, i1 true}
*** IR Dump After RelLookupTableConverterPass on [module] ***
; ModuleID = 'FIRModule'
source_filename = "FIRModule"
target datalayout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128"
target triple = "x86_64-unknown-linux-gnu"

%struct.ident_t = type { i32, i32, i32, i32, ptr }

@_QFEarr.0 = internal unnamed_addr global ptr null
@_QFEarr.8 = internal unnamed_addr global i1 false
@_QQcl.60ea5a38555821a77357f87d16df9a0f = internal constant [62 x i8] c"/g/g92/rydahl1/flangtests/src/duplicate_array_descriptors.f90\00"
@_QQcl.28612C69372C612C6531332E36653229 = internal constant [16 x i8] c"(a,i7,a,e13.6e2)"
@_QQcl.54686520726573756C74206F6620286172722831292B61727228 = internal constant [26 x i8] c"The result of (arr(1)+arr("
@_QQcl.2920697320 = internal constant [5 x i8] c") is "
@_QQEnvironmentDefaults = local_unnamed_addr constant ptr null
@0 = private unnamed_addr constant [23 x i8] c";unknown;unknown;0;0;;\00", align 1
@1 = private unnamed_addr constant %struct.ident_t { i32 0, i32 2, i32 0, i32 22, ptr @0 }, align 8
@2 = private unnamed_addr constant %struct.ident_t { i32 0, i32 66, i32 0, i32 22, ptr @0 }, align 8

; Function Attrs: mustprogress nofree nounwind willreturn allockind("alloc,uninitialized") allocsize(0) memory(inaccessiblemem: readwrite)
declare noalias noundef ptr @malloc(i64 noundef) local_unnamed_addr #0

; Function Attrs: mustprogress nounwind willreturn allockind("free") memory(argmem: readwrite, inaccessiblemem: readwrite)
declare void @free(ptr allocptr nocapture noundef) local_unnamed_addr #1

define void @_QQmain() local_unnamed_addr {
entry:
  %structArg = alloca { ptr, ptr, ptr }, align 8
  %0 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %1 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %2 = alloca i32, align 4
  store i32 1048576, ptr %2, align 4, !tbaa !4
  %3 = tail call dereferenceable_or_null(8388608) ptr @malloc(i64 8388608)
  store ptr %3, ptr @_QFEarr.0, align 8, !tbaa !8
  store i1 true, ptr @_QFEarr.8, align 1
  %omp_global_thread_num = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %2, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %1, ptr %gep_5, align 8
  %gep_6 = getelementptr inbounds { ptr, ptr, ptr }, ptr %structArg, i64 0, i32 2
  store ptr %0, ptr %gep_6, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QQmain..omp_par, ptr nonnull %structArg)
  %4 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.60ea5a38555821a77357f87d16df9a0f, i32 21)
  %5 = call i1 @_FortranAioOutputAscii(ptr %4, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %6 = load i32, ptr %2, align 4, !tbaa !4
  %7 = call i1 @_FortranAioOutputInteger32(ptr %4, i32 %6)
  %8 = call i1 @_FortranAioOutputAscii(ptr %4, ptr nonnull @_QQcl.2920697320, i64 5)
  %.unpack = load ptr, ptr @_QFEarr.0, align 8, !tbaa !8
  %9 = load double, ptr %.unpack, align 8, !tbaa !4
  %10 = load i32, ptr %2, align 4, !tbaa !4
  %11 = sext i32 %10 to i64
  %12 = add nsw i64 %11, -1
  %13 = getelementptr double, ptr %.unpack, i64 %12
  %14 = load double, ptr %13, align 8, !tbaa !4
  %15 = fadd contract double %9, %14
  %16 = call i1 @_FortranAioOutputReal64(ptr %4, double %15)
  %17 = call i32 @_FortranAioEndIoStatement(ptr %4)
  %.unpack101 = load ptr, ptr @_QFEarr.0, align 8, !tbaa !8
  call void @free(ptr %.unpack101)
  store ptr null, ptr @_QFEarr.0, align 8, !tbaa !8
  store i1 false, ptr @_QFEarr.8, align 1
  ret void
}

; Function Attrs: norecurse nounwind
define internal void @_QQmain..omp_par(ptr noalias nocapture readnone %tid.addr, ptr noalias nocapture readnone %zero.addr, ptr nocapture readonly %0) #2 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %gep_3 = getelementptr { ptr, ptr, ptr }, ptr %0, i64 0, i32 2
  %loadgep_4 = load ptr, ptr %gep_3, align 8
  %p.lastiter = alloca i32, align 4
  %p.lowerbound = alloca i32, align 4
  %p.upperbound = alloca i32, align 4
  %p.stride = alloca i32, align 4
  %1 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %omp_loop.tripcount = tail call i32 @llvm.smax.i32(i32 %1, i32 0)
  store i32 0, ptr %p.lowerbound, align 4
  %2 = add nsw i32 %omp_loop.tripcount, -1
  store i32 %2, ptr %p.upperbound, align 4
  store i32 1, ptr %p.stride, align 4
  %omp_global_thread_num4 = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  call void @__kmpc_for_static_init_4u(ptr nonnull @1, i32 %omp_global_thread_num4, i32 34, ptr nonnull %p.lastiter, ptr nonnull %p.lowerbound, ptr nonnull %p.upperbound, ptr nonnull %p.stride, i32 1, i32 0)
  %3 = load i32, ptr %p.lowerbound, align 4
  %4 = load i32, ptr %p.upperbound, align 4
  %reass.sub = sub i32 %4, %3
  %omp_loop.cmp65.not = icmp eq i32 %reass.sub, -1
  br i1 %omp_loop.cmp65.not, label %omp_loop.exit, label %omp_loop.body.lr.ph

omp_loop.body.lr.ph:                              ; preds = %omp.par.entry
  %.unpack = load ptr, ptr @_QFEarr.0, align 8, !tbaa !8
  %.unpack12.unpack.unpack14.b = load i1, ptr @_QFEarr.8, align 1
  %.unpack12.unpack.unpack14 = select i1 %.unpack12.unpack.unpack14.b, i64 1048576, i64 0
  %loadgep_2.repack17 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  %loadgep_2.repack19 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  %loadgep_2.repack21 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  %loadgep_2.repack23 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  %loadgep_2.repack25 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  %loadgep_2.repack27 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  %loadgep_2.repack29 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  %loadgep_2.repack29.repack31 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  %loadgep_2.repack29.repack33 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  %loadgep_4.repack47 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 1
  %loadgep_4.repack49 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 2
  %loadgep_4.repack51 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 3
  %loadgep_4.repack53 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 4
  %loadgep_4.repack55 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 5
  %loadgep_4.repack57 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 6
  %loadgep_4.repack59 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7
  %loadgep_4.repack59.repack61 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 1
  %loadgep_4.repack59.repack63 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 2
  br label %omp_loop.body

omp_loop.exit:                                    ; preds = %omp_loop.body, %omp.par.entry
  call void @__kmpc_for_static_fini(ptr nonnull @1, i32 %omp_global_thread_num4)
  call void @__kmpc_barrier(ptr nonnull @2, i32 %omp_global_thread_num4)
  ret void

omp_loop.body:                                    ; preds = %omp_loop.body.lr.ph, %omp_loop.body
  %omp_loop.iv66 = phi i32 [ 0, %omp_loop.body.lr.ph ], [ %5, %omp_loop.body ]
  %5 = add nuw i32 %omp_loop.iv66, 1
  %6 = add i32 %5, %3
  %7 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %8 = sitofp i32 %7 to float
  %9 = fdiv contract float 1.000000e+00, %8
  %10 = fpext float %9 to double
  store ptr %.unpack, ptr %loadgep_2, align 8, !tbaa !8
  store i64 8, ptr %loadgep_2.repack17, align 8, !tbaa !8
  store i32 20180515, ptr %loadgep_2.repack19, align 8, !tbaa !8
  store i8 1, ptr %loadgep_2.repack21, align 4, !tbaa !8
  store i8 28, ptr %loadgep_2.repack23, align 1, !tbaa !8
  store i8 2, ptr %loadgep_2.repack25, align 2, !tbaa !8
  store i8 0, ptr %loadgep_2.repack27, align 1, !tbaa !8
  store i64 1, ptr %loadgep_2.repack29, align 8, !tbaa !8
  store i64 %.unpack12.unpack.unpack14, ptr %loadgep_2.repack29.repack31, align 8, !tbaa !8
  store i64 8, ptr %loadgep_2.repack29.repack33, align 8, !tbaa !8
  %11 = sext i32 %6 to i64
  %12 = add nsw i64 %11, -1
  %13 = getelementptr double, ptr %.unpack, i64 %12
  store double %10, ptr %13, align 8, !tbaa !4
  store ptr %.unpack, ptr %loadgep_4, align 8, !tbaa !8
  store i64 8, ptr %loadgep_4.repack47, align 8, !tbaa !8
  store i32 20180515, ptr %loadgep_4.repack49, align 8, !tbaa !8
  store i8 1, ptr %loadgep_4.repack51, align 4, !tbaa !8
  store i8 28, ptr %loadgep_4.repack53, align 1, !tbaa !8
  store i8 2, ptr %loadgep_4.repack55, align 2, !tbaa !8
  store i8 0, ptr %loadgep_4.repack57, align 1, !tbaa !8
  store i64 1, ptr %loadgep_4.repack59, align 8, !tbaa !8
  store i64 %.unpack12.unpack.unpack14, ptr %loadgep_4.repack59.repack61, align 8, !tbaa !8
  store i64 8, ptr %loadgep_4.repack59.repack63, align 8, !tbaa !8
  %exitcond.not = icmp eq i32 %omp_loop.iv66, %reass.sub
  br i1 %exitcond.not, label %omp_loop.exit, label %omp_loop.body
}

declare ptr @_FortranAioBeginExternalFormattedOutput(ptr, i64, ptr, i32, ptr, i32) local_unnamed_addr

declare zeroext i1 @_FortranAioOutputAscii(ptr, ptr, i64) local_unnamed_addr

declare zeroext i1 @_FortranAioOutputInteger32(ptr, i32) local_unnamed_addr

declare zeroext i1 @_FortranAioOutputReal64(ptr, double) local_unnamed_addr

declare i32 @_FortranAioEndIoStatement(ptr) local_unnamed_addr

; Function Attrs: nounwind
declare i32 @__kmpc_global_thread_num(ptr) local_unnamed_addr #3

; Function Attrs: nounwind
declare void @__kmpc_for_static_init_4u(ptr, i32, i32, ptr, ptr, ptr, ptr, i32, i32) local_unnamed_addr #3

; Function Attrs: nounwind
declare void @__kmpc_for_static_fini(ptr, i32) local_unnamed_addr #3

; Function Attrs: convergent nounwind
declare void @__kmpc_barrier(ptr, i32) local_unnamed_addr #4

; Function Attrs: nounwind
declare !callback !10 void @__kmpc_fork_call(ptr, i32, ptr, ...) local_unnamed_addr #3

; Function Attrs: nocallback nofree nosync nounwind speculatable willreturn memory(none)
declare i32 @llvm.smax.i32(i32, i32) #5

attributes #0 = { mustprogress nofree nounwind willreturn allockind("alloc,uninitialized") allocsize(0) memory(inaccessiblemem: readwrite) "alloc-family"="malloc" }
attributes #1 = { mustprogress nounwind willreturn allockind("free") memory(argmem: readwrite, inaccessiblemem: readwrite) "alloc-family"="malloc" }
attributes #2 = { norecurse nounwind }
attributes #3 = { nounwind }
attributes #4 = { convergent nounwind }
attributes #5 = { nocallback nofree nosync nounwind speculatable willreturn memory(none) }

!llvm.module.flags = !{!0, !1, !2, !3}

!0 = !{i32 2, !"Debug Info Version", i32 3}
!1 = !{i32 7, !"openmp", i32 11}
!2 = !{i32 8, !"PIC Level", i32 2}
!3 = !{i32 7, !"PIE Level", i32 2}
!4 = !{!5, !5, i64 0}
!5 = !{!"any data access", !6, i64 0}
!6 = !{!"any access", !7, i64 0}
!7 = !{!"Flang Type TBAA Root"}
!8 = !{!9, !9, i64 0}
!9 = !{!"descriptor member", !6, i64 0}
!10 = !{!11}
!11 = !{i64 2, i64 -1, i64 -1, i1 true}
*** IR Dump After AnnotationRemarksPass on _QQmain ***
define void @_QQmain() local_unnamed_addr {
entry:
  %structArg = alloca { ptr, ptr, ptr }, align 8
  %0 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %1 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %2 = alloca i32, align 4
  store i32 1048576, ptr %2, align 4, !tbaa !4
  %3 = tail call dereferenceable_or_null(8388608) ptr @malloc(i64 8388608)
  store ptr %3, ptr @_QFEarr.0, align 8, !tbaa !8
  store i1 true, ptr @_QFEarr.8, align 1
  %omp_global_thread_num = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %2, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %1, ptr %gep_5, align 8
  %gep_6 = getelementptr inbounds { ptr, ptr, ptr }, ptr %structArg, i64 0, i32 2
  store ptr %0, ptr %gep_6, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QQmain..omp_par, ptr nonnull %structArg)
  %4 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.60ea5a38555821a77357f87d16df9a0f, i32 21)
  %5 = call i1 @_FortranAioOutputAscii(ptr %4, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %6 = load i32, ptr %2, align 4, !tbaa !4
  %7 = call i1 @_FortranAioOutputInteger32(ptr %4, i32 %6)
  %8 = call i1 @_FortranAioOutputAscii(ptr %4, ptr nonnull @_QQcl.2920697320, i64 5)
  %.unpack = load ptr, ptr @_QFEarr.0, align 8, !tbaa !8
  %9 = load double, ptr %.unpack, align 8, !tbaa !4
  %10 = load i32, ptr %2, align 4, !tbaa !4
  %11 = sext i32 %10 to i64
  %12 = add nsw i64 %11, -1
  %13 = getelementptr double, ptr %.unpack, i64 %12
  %14 = load double, ptr %13, align 8, !tbaa !4
  %15 = fadd contract double %9, %14
  %16 = call i1 @_FortranAioOutputReal64(ptr %4, double %15)
  %17 = call i32 @_FortranAioEndIoStatement(ptr %4)
  %.unpack101 = load ptr, ptr @_QFEarr.0, align 8, !tbaa !8
  call void @free(ptr %.unpack101)
  store ptr null, ptr @_QFEarr.0, align 8, !tbaa !8
  store i1 false, ptr @_QFEarr.8, align 1
  ret void
}
*** IR Dump After AnnotationRemarksPass on _QQmain..omp_par ***
; Function Attrs: norecurse nounwind
define internal void @_QQmain..omp_par(ptr noalias nocapture readnone %tid.addr, ptr noalias nocapture readnone %zero.addr, ptr nocapture readonly %0) #2 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %gep_3 = getelementptr { ptr, ptr, ptr }, ptr %0, i64 0, i32 2
  %loadgep_4 = load ptr, ptr %gep_3, align 8
  %p.lastiter = alloca i32, align 4
  %p.lowerbound = alloca i32, align 4
  %p.upperbound = alloca i32, align 4
  %p.stride = alloca i32, align 4
  %1 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %omp_loop.tripcount = tail call i32 @llvm.smax.i32(i32 %1, i32 0)
  store i32 0, ptr %p.lowerbound, align 4
  %2 = add nsw i32 %omp_loop.tripcount, -1
  store i32 %2, ptr %p.upperbound, align 4
  store i32 1, ptr %p.stride, align 4
  %omp_global_thread_num4 = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  call void @__kmpc_for_static_init_4u(ptr nonnull @1, i32 %omp_global_thread_num4, i32 34, ptr nonnull %p.lastiter, ptr nonnull %p.lowerbound, ptr nonnull %p.upperbound, ptr nonnull %p.stride, i32 1, i32 0)
  %3 = load i32, ptr %p.lowerbound, align 4
  %4 = load i32, ptr %p.upperbound, align 4
  %reass.sub = sub i32 %4, %3
  %omp_loop.cmp65.not = icmp eq i32 %reass.sub, -1
  br i1 %omp_loop.cmp65.not, label %omp_loop.exit, label %omp_loop.body.lr.ph

omp_loop.body.lr.ph:                              ; preds = %omp.par.entry
  %.unpack = load ptr, ptr @_QFEarr.0, align 8, !tbaa !8
  %.unpack12.unpack.unpack14.b = load i1, ptr @_QFEarr.8, align 1
  %.unpack12.unpack.unpack14 = select i1 %.unpack12.unpack.unpack14.b, i64 1048576, i64 0
  %loadgep_2.repack17 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  %loadgep_2.repack19 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  %loadgep_2.repack21 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  %loadgep_2.repack23 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  %loadgep_2.repack25 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  %loadgep_2.repack27 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  %loadgep_2.repack29 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  %loadgep_2.repack29.repack31 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  %loadgep_2.repack29.repack33 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  %loadgep_4.repack47 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 1
  %loadgep_4.repack49 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 2
  %loadgep_4.repack51 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 3
  %loadgep_4.repack53 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 4
  %loadgep_4.repack55 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 5
  %loadgep_4.repack57 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 6
  %loadgep_4.repack59 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7
  %loadgep_4.repack59.repack61 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 1
  %loadgep_4.repack59.repack63 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 2
  br label %omp_loop.body

omp_loop.exit:                                    ; preds = %omp_loop.body, %omp.par.entry
  call void @__kmpc_for_static_fini(ptr nonnull @1, i32 %omp_global_thread_num4)
  call void @__kmpc_barrier(ptr nonnull @2, i32 %omp_global_thread_num4)
  ret void

omp_loop.body:                                    ; preds = %omp_loop.body.lr.ph, %omp_loop.body
  %omp_loop.iv66 = phi i32 [ 0, %omp_loop.body.lr.ph ], [ %5, %omp_loop.body ]
  %5 = add nuw i32 %omp_loop.iv66, 1
  %6 = add i32 %5, %3
  %7 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %8 = sitofp i32 %7 to float
  %9 = fdiv contract float 1.000000e+00, %8
  %10 = fpext float %9 to double
  store ptr %.unpack, ptr %loadgep_2, align 8, !tbaa !8
  store i64 8, ptr %loadgep_2.repack17, align 8, !tbaa !8
  store i32 20180515, ptr %loadgep_2.repack19, align 8, !tbaa !8
  store i8 1, ptr %loadgep_2.repack21, align 4, !tbaa !8
  store i8 28, ptr %loadgep_2.repack23, align 1, !tbaa !8
  store i8 2, ptr %loadgep_2.repack25, align 2, !tbaa !8
  store i8 0, ptr %loadgep_2.repack27, align 1, !tbaa !8
  store i64 1, ptr %loadgep_2.repack29, align 8, !tbaa !8
  store i64 %.unpack12.unpack.unpack14, ptr %loadgep_2.repack29.repack31, align 8, !tbaa !8
  store i64 8, ptr %loadgep_2.repack29.repack33, align 8, !tbaa !8
  %11 = sext i32 %6 to i64
  %12 = add nsw i64 %11, -1
  %13 = getelementptr double, ptr %.unpack, i64 %12
  store double %10, ptr %13, align 8, !tbaa !4
  store ptr %.unpack, ptr %loadgep_4, align 8, !tbaa !8
  store i64 8, ptr %loadgep_4.repack47, align 8, !tbaa !8
  store i32 20180515, ptr %loadgep_4.repack49, align 8, !tbaa !8
  store i8 1, ptr %loadgep_4.repack51, align 4, !tbaa !8
  store i8 28, ptr %loadgep_4.repack53, align 1, !tbaa !8
  store i8 2, ptr %loadgep_4.repack55, align 2, !tbaa !8
  store i8 0, ptr %loadgep_4.repack57, align 1, !tbaa !8
  store i64 1, ptr %loadgep_4.repack59, align 8, !tbaa !8
  store i64 %.unpack12.unpack.unpack14, ptr %loadgep_4.repack59.repack61, align 8, !tbaa !8
  store i64 8, ptr %loadgep_4.repack59.repack63, align 8, !tbaa !8
  %exitcond.not = icmp eq i32 %omp_loop.iv66, %reass.sub
  br i1 %exitcond.not, label %omp_loop.exit, label %omp_loop.body
}
