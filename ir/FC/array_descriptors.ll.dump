*** IR Dump After Annotation2MetadataPass on [module] ***
; ModuleID = 'FIRModule'
source_filename = "FIRModule"
target datalayout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128"
target triple = "x86_64-unknown-linux-gnu"

%struct.ident_t = type { i32, i32, i32, i32, ptr }

@_QFEarr = internal global { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } { ptr null, i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), i32 20180515, i8 1, i8 28, i8 2, i8 0, [1 x [3 x i64]] [[3 x i64] [i64 1, i64 0, i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64)]] }
@_QQcl.68815510185ede6107d6524e77abf791 = internal constant [52 x i8] c"/g/g92/rydahl1/flangtests/src/array_descriptors.f90\00"
@_QQcl.28612C69372C612C6531332E36653229 = internal constant [16 x i8] c"(a,i7,a,e13.6e2)"
@_QQcl.54686520726573756C74206F6620286172722831292B61727228 = internal constant [26 x i8] c"The result of (arr(1)+arr("
@_QQcl.2920697320 = internal constant [5 x i8] c") is "
@_QQEnvironmentDefaults = constant ptr null
@0 = private unnamed_addr constant [23 x i8] c";unknown;unknown;0;0;;\00", align 1
@1 = private unnamed_addr constant %struct.ident_t { i32 0, i32 2, i32 0, i32 22, ptr @0 }, align 8
@2 = private unnamed_addr constant %struct.ident_t { i32 0, i32 66, i32 0, i32 22, ptr @0 }, align 8

declare ptr @malloc(i64)

declare void @free(ptr)

define void @_QQmain() {
  %structArg = alloca { ptr, ptr }, align 8
  %1 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %2 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %3 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %4 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %5 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %6 = alloca i32, i64 1, align 4
  %7 = alloca i32, i64 1, align 4
  store i32 1048576, ptr %7, align 4, !tbaa !4
  %8 = load i32, ptr %7, align 4, !tbaa !4
  %9 = sext i32 %8 to i64
  %10 = icmp sgt i64 %9, 0
  %11 = select i1 %10, i64 %9, i64 0
  %12 = mul i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), %11
  %13 = call ptr @malloc(i64 %12)
  %14 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } { ptr undef, i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), i32 20180515, i8 1, i8 28, i8 2, i8 0, [1 x [3 x i64]] [[3 x i64] [i64 1, i64 undef, i64 undef]] }, i64 %11, 7, 0, 1
  %15 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %14, i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), 7, 0, 2
  %16 = mul i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), %11
  %17 = mul i64 1, %11
  %18 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %15, ptr %13, 0
  store { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %18, ptr %5, align 8, !tbaa !8
  %19 = load { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, align 8, !tbaa !8
  store { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %19, ptr @_QFEarr, align 8, !tbaa !8
  br label %entry

entry:                                            ; preds = %0
  %omp_global_thread_num = call i32 @__kmpc_global_thread_num(ptr @1)
  br label %omp_parallel

omp_parallel:                                     ; preds = %entry
  %gep_ = getelementptr { ptr, ptr }, ptr %structArg, i32 0, i32 0
  store ptr %7, ptr %gep_, align 8
  %gep_5 = getelementptr { ptr, ptr }, ptr %structArg, i32 0, i32 1
  store ptr %4, ptr %gep_5, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr @1, i32 1, ptr @_QQmain..omp_par, ptr %structArg)
  br label %omp.par.outlined.exit

omp.par.outlined.exit:                            ; preds = %omp_parallel
  br label %omp.par.exit.split

omp.par.exit.split:                               ; preds = %omp.par.outlined.exit
  %20 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr @_QQcl.68815510185ede6107d6524e77abf791, i32 19)
  %21 = call i1 @_FortranAioOutputAscii(ptr %20, ptr @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %22 = load i32, ptr %7, align 4, !tbaa !4
  %23 = call i1 @_FortranAioOutputInteger32(ptr %20, i32 %22)
  %24 = call i1 @_FortranAioOutputAscii(ptr %20, ptr @_QQcl.2920697320, i64 5)
  %25 = load { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, align 8, !tbaa !8
  store { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %25, ptr %3, align 8, !tbaa !8
  %26 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i32 0, i32 7, i64 0, i32 0
  %27 = load i64, ptr %26, align 8, !tbaa !8
  %28 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i32 0, i32 7, i64 0, i32 1
  %29 = load i64, ptr %28, align 8, !tbaa !8
  %30 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i32 0, i32 7, i64 0, i32 2
  %31 = load i64, ptr %30, align 8, !tbaa !8
  %32 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i32 0, i32 0
  %33 = load ptr, ptr %32, align 8, !tbaa !8
  %34 = sub i64 1, %27
  %35 = getelementptr double, ptr %33, i64 %34
  %36 = load double, ptr %35, align 8, !tbaa !4
  %37 = load i32, ptr %7, align 4, !tbaa !4
  %38 = sext i32 %37 to i64
  %39 = sub i64 %38, %27
  %40 = getelementptr double, ptr %33, i64 %39
  %41 = load double, ptr %40, align 8, !tbaa !4
  %42 = fadd contract double %36, %41
  %43 = call i1 @_FortranAioOutputReal64(ptr %20, double %42)
  %44 = call i32 @_FortranAioEndIoStatement(ptr %20)
  %45 = load { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, align 8, !tbaa !8
  store { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %45, ptr %2, align 8, !tbaa !8
  %46 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %2, i32 0, i32 0
  %47 = load ptr, ptr %46, align 8, !tbaa !8
  call void @free(ptr %47)
  store { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } { ptr null, i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), i32 20180515, i8 1, i8 28, i8 2, i8 0, [1 x [3 x i64]] [[3 x i64] [i64 1, i64 0, i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64)]] }, ptr %1, align 8, !tbaa !8
  %48 = load { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %1, align 8, !tbaa !8
  store { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %48, ptr @_QFEarr, align 8, !tbaa !8
  ret void
}

; Function Attrs: norecurse nounwind
define internal void @_QQmain..omp_par(ptr noalias %tid.addr, ptr noalias %zero.addr, ptr %0) #0 {
omp.par.entry:
  %gep_ = getelementptr { ptr, ptr }, ptr %0, i32 0, i32 0
  %loadgep_ = load ptr, ptr %gep_, align 8
  %gep_1 = getelementptr { ptr, ptr }, ptr %0, i32 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %tid.addr.local = alloca i32, align 4
  %1 = load i32, ptr %tid.addr, align 4
  store i32 %1, ptr %tid.addr.local, align 4
  %tid = load i32, ptr %tid.addr.local, align 4
  %p.lastiter = alloca i32, align 4
  %p.lowerbound = alloca i32, align 4
  %p.upperbound = alloca i32, align 4
  %p.stride = alloca i32, align 4
  br label %omp.par.region

omp.par.region:                                   ; preds = %omp.par.entry
  br label %omp.par.region1

omp.par.region1:                                  ; preds = %omp.par.region
  %2 = alloca i32, i64 1, align 4
  %3 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %4 = select i1 false, i32 %3, i32 1
  %5 = select i1 false, i32 1, i32 %3
  %6 = sub nsw i32 %5, %4
  %7 = icmp slt i32 %5, %4
  %8 = udiv i32 %6, 1
  %9 = add i32 %8, 1
  %omp_loop.tripcount = select i1 %7, i32 0, i32 %9
  br label %omp_loop.preheader

omp_loop.preheader:                               ; preds = %omp.par.region1
  store i32 0, ptr %p.lowerbound, align 4
  %10 = sub i32 %omp_loop.tripcount, 1
  store i32 %10, ptr %p.upperbound, align 4
  store i32 1, ptr %p.stride, align 4
  %omp_global_thread_num3 = call i32 @__kmpc_global_thread_num(ptr @1)
  call void @__kmpc_for_static_init_4u(ptr @1, i32 %omp_global_thread_num3, i32 34, ptr %p.lastiter, ptr %p.lowerbound, ptr %p.upperbound, ptr %p.stride, i32 1, i32 0)
  %11 = load i32, ptr %p.lowerbound, align 4
  %12 = load i32, ptr %p.upperbound, align 4
  %13 = sub i32 %12, %11
  %14 = add i32 %13, 1
  br label %omp_loop.header

omp_loop.header:                                  ; preds = %omp_loop.inc, %omp_loop.preheader
  %omp_loop.iv = phi i32 [ 0, %omp_loop.preheader ], [ %omp_loop.next, %omp_loop.inc ]
  br label %omp_loop.cond

omp_loop.cond:                                    ; preds = %omp_loop.header
  %omp_loop.cmp = icmp ult i32 %omp_loop.iv, %14
  br i1 %omp_loop.cmp, label %omp_loop.body, label %omp_loop.exit

omp_loop.exit:                                    ; preds = %omp_loop.cond
  call void @__kmpc_for_static_fini(ptr @1, i32 %omp_global_thread_num3)
  %omp_global_thread_num4 = call i32 @__kmpc_global_thread_num(ptr @1)
  call void @__kmpc_barrier(ptr @2, i32 %omp_global_thread_num4)
  br label %omp_loop.after

omp_loop.after:                                   ; preds = %omp_loop.exit
  br label %omp.region.cont

omp.region.cont:                                  ; preds = %omp_loop.after
  br label %omp.par.pre_finalize

omp.par.pre_finalize:                             ; preds = %omp.region.cont
  br label %omp.par.outlined.exit.exitStub

omp_loop.body:                                    ; preds = %omp_loop.cond
  %15 = add i32 %omp_loop.iv, %11
  %16 = mul i32 %15, 1
  %17 = add i32 %16, 1
  br label %omp.wsloop.region

omp.wsloop.region:                                ; preds = %omp_loop.body
  store i32 %17, ptr %2, align 4, !tbaa !4
  %18 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %19 = sitofp i32 %18 to float
  %20 = fdiv contract float 1.000000e+00, %19
  %21 = fpext float %20 to double
  %22 = load { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, align 8, !tbaa !8
  store { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %22, ptr %loadgep_2, align 8, !tbaa !8
  %23 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i32 0, i32 7, i64 0, i32 0
  %24 = load i64, ptr %23, align 8, !tbaa !8
  %25 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i32 0, i32 7, i64 0, i32 1
  %26 = load i64, ptr %25, align 8, !tbaa !8
  %27 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i32 0, i32 7, i64 0, i32 2
  %28 = load i64, ptr %27, align 8, !tbaa !8
  %29 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i32 0, i32 0
  %30 = load ptr, ptr %29, align 8, !tbaa !8
  %31 = load i32, ptr %2, align 4, !tbaa !4
  %32 = sext i32 %31 to i64
  %33 = sub i64 %32, %24
  %34 = getelementptr double, ptr %30, i64 %33
  store double %21, ptr %34, align 8, !tbaa !4
  br label %omp.region.cont2

omp.region.cont2:                                 ; preds = %omp.wsloop.region
  br label %omp_loop.inc

omp_loop.inc:                                     ; preds = %omp.region.cont2
  %omp_loop.next = add nuw i32 %omp_loop.iv, 1
  br label %omp_loop.header

omp.par.outlined.exit.exitStub:                   ; preds = %omp.par.pre_finalize
  ret void
}

declare ptr @_FortranAioBeginExternalFormattedOutput(ptr, i64, ptr, i32, ptr, i32)

declare zeroext i1 @_FortranAioOutputAscii(ptr, ptr, i64)

declare zeroext i1 @_FortranAioOutputInteger32(ptr, i32)

declare zeroext i1 @_FortranAioOutputReal64(ptr, double)

declare i32 @_FortranAioEndIoStatement(ptr)

; Function Attrs: nocallback nofree nosync nounwind willreturn
declare ptr @llvm.stacksave() #1

; Function Attrs: nocallback nofree nosync nounwind willreturn
declare void @llvm.stackrestore(ptr) #1

; Function Attrs: nounwind
declare i32 @__kmpc_global_thread_num(ptr) #2

; Function Attrs: nounwind
declare void @__kmpc_for_static_init_4u(ptr, i32, i32, ptr, ptr, ptr, ptr, i32, i32) #2

; Function Attrs: nounwind
declare void @__kmpc_for_static_fini(ptr, i32) #2

; Function Attrs: convergent nounwind
declare void @__kmpc_barrier(ptr, i32) #3

; Function Attrs: nounwind
declare !callback !10 void @__kmpc_fork_call(ptr, i32, ptr, ...) #2

attributes #0 = { norecurse nounwind }
attributes #1 = { nocallback nofree nosync nounwind willreturn }
attributes #2 = { nounwind }
attributes #3 = { convergent nounwind }

!llvm.module.flags = !{!0, !1, !2, !3}

!0 = !{i32 2, !"Debug Info Version", i32 3}
!1 = !{i32 7, !"openmp", i32 11}
!2 = !{i32 8, !"PIC Level", i32 2}
!3 = !{i32 7, !"PIE Level", i32 2}
!4 = !{!5, !5, i64 0}
!5 = !{!"any data access", !6, i64 0}
!6 = !{!"any access", !7, i64 0}
!7 = !{!"Flang Type TBAA Root"}
!8 = !{!9, !9, i64 0}
!9 = !{!"descriptor member", !6, i64 0}
!10 = !{!11}
!11 = !{i64 2, i64 -1, i64 -1, i1 true}
*** IR Dump After ForceFunctionAttrsPass on [module] ***
; ModuleID = 'FIRModule'
source_filename = "FIRModule"
target datalayout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128"
target triple = "x86_64-unknown-linux-gnu"

%struct.ident_t = type { i32, i32, i32, i32, ptr }

@_QFEarr = internal global { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } { ptr null, i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), i32 20180515, i8 1, i8 28, i8 2, i8 0, [1 x [3 x i64]] [[3 x i64] [i64 1, i64 0, i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64)]] }
@_QQcl.68815510185ede6107d6524e77abf791 = internal constant [52 x i8] c"/g/g92/rydahl1/flangtests/src/array_descriptors.f90\00"
@_QQcl.28612C69372C612C6531332E36653229 = internal constant [16 x i8] c"(a,i7,a,e13.6e2)"
@_QQcl.54686520726573756C74206F6620286172722831292B61727228 = internal constant [26 x i8] c"The result of (arr(1)+arr("
@_QQcl.2920697320 = internal constant [5 x i8] c") is "
@_QQEnvironmentDefaults = constant ptr null
@0 = private unnamed_addr constant [23 x i8] c";unknown;unknown;0;0;;\00", align 1
@1 = private unnamed_addr constant %struct.ident_t { i32 0, i32 2, i32 0, i32 22, ptr @0 }, align 8
@2 = private unnamed_addr constant %struct.ident_t { i32 0, i32 66, i32 0, i32 22, ptr @0 }, align 8

declare ptr @malloc(i64)

declare void @free(ptr)

define void @_QQmain() {
  %structArg = alloca { ptr, ptr }, align 8
  %1 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %2 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %3 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %4 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %5 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %6 = alloca i32, i64 1, align 4
  %7 = alloca i32, i64 1, align 4
  store i32 1048576, ptr %7, align 4, !tbaa !4
  %8 = load i32, ptr %7, align 4, !tbaa !4
  %9 = sext i32 %8 to i64
  %10 = icmp sgt i64 %9, 0
  %11 = select i1 %10, i64 %9, i64 0
  %12 = mul i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), %11
  %13 = call ptr @malloc(i64 %12)
  %14 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } { ptr undef, i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), i32 20180515, i8 1, i8 28, i8 2, i8 0, [1 x [3 x i64]] [[3 x i64] [i64 1, i64 undef, i64 undef]] }, i64 %11, 7, 0, 1
  %15 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %14, i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), 7, 0, 2
  %16 = mul i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), %11
  %17 = mul i64 1, %11
  %18 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %15, ptr %13, 0
  store { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %18, ptr %5, align 8, !tbaa !8
  %19 = load { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, align 8, !tbaa !8
  store { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %19, ptr @_QFEarr, align 8, !tbaa !8
  br label %entry

entry:                                            ; preds = %0
  %omp_global_thread_num = call i32 @__kmpc_global_thread_num(ptr @1)
  br label %omp_parallel

omp_parallel:                                     ; preds = %entry
  %gep_ = getelementptr { ptr, ptr }, ptr %structArg, i32 0, i32 0
  store ptr %7, ptr %gep_, align 8
  %gep_5 = getelementptr { ptr, ptr }, ptr %structArg, i32 0, i32 1
  store ptr %4, ptr %gep_5, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr @1, i32 1, ptr @_QQmain..omp_par, ptr %structArg)
  br label %omp.par.outlined.exit

omp.par.outlined.exit:                            ; preds = %omp_parallel
  br label %omp.par.exit.split

omp.par.exit.split:                               ; preds = %omp.par.outlined.exit
  %20 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr @_QQcl.68815510185ede6107d6524e77abf791, i32 19)
  %21 = call i1 @_FortranAioOutputAscii(ptr %20, ptr @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %22 = load i32, ptr %7, align 4, !tbaa !4
  %23 = call i1 @_FortranAioOutputInteger32(ptr %20, i32 %22)
  %24 = call i1 @_FortranAioOutputAscii(ptr %20, ptr @_QQcl.2920697320, i64 5)
  %25 = load { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, align 8, !tbaa !8
  store { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %25, ptr %3, align 8, !tbaa !8
  %26 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i32 0, i32 7, i64 0, i32 0
  %27 = load i64, ptr %26, align 8, !tbaa !8
  %28 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i32 0, i32 7, i64 0, i32 1
  %29 = load i64, ptr %28, align 8, !tbaa !8
  %30 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i32 0, i32 7, i64 0, i32 2
  %31 = load i64, ptr %30, align 8, !tbaa !8
  %32 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i32 0, i32 0
  %33 = load ptr, ptr %32, align 8, !tbaa !8
  %34 = sub i64 1, %27
  %35 = getelementptr double, ptr %33, i64 %34
  %36 = load double, ptr %35, align 8, !tbaa !4
  %37 = load i32, ptr %7, align 4, !tbaa !4
  %38 = sext i32 %37 to i64
  %39 = sub i64 %38, %27
  %40 = getelementptr double, ptr %33, i64 %39
  %41 = load double, ptr %40, align 8, !tbaa !4
  %42 = fadd contract double %36, %41
  %43 = call i1 @_FortranAioOutputReal64(ptr %20, double %42)
  %44 = call i32 @_FortranAioEndIoStatement(ptr %20)
  %45 = load { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, align 8, !tbaa !8
  store { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %45, ptr %2, align 8, !tbaa !8
  %46 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %2, i32 0, i32 0
  %47 = load ptr, ptr %46, align 8, !tbaa !8
  call void @free(ptr %47)
  store { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } { ptr null, i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), i32 20180515, i8 1, i8 28, i8 2, i8 0, [1 x [3 x i64]] [[3 x i64] [i64 1, i64 0, i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64)]] }, ptr %1, align 8, !tbaa !8
  %48 = load { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %1, align 8, !tbaa !8
  store { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %48, ptr @_QFEarr, align 8, !tbaa !8
  ret void
}

; Function Attrs: norecurse nounwind
define internal void @_QQmain..omp_par(ptr noalias %tid.addr, ptr noalias %zero.addr, ptr %0) #0 {
omp.par.entry:
  %gep_ = getelementptr { ptr, ptr }, ptr %0, i32 0, i32 0
  %loadgep_ = load ptr, ptr %gep_, align 8
  %gep_1 = getelementptr { ptr, ptr }, ptr %0, i32 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %tid.addr.local = alloca i32, align 4
  %1 = load i32, ptr %tid.addr, align 4
  store i32 %1, ptr %tid.addr.local, align 4
  %tid = load i32, ptr %tid.addr.local, align 4
  %p.lastiter = alloca i32, align 4
  %p.lowerbound = alloca i32, align 4
  %p.upperbound = alloca i32, align 4
  %p.stride = alloca i32, align 4
  br label %omp.par.region

omp.par.region:                                   ; preds = %omp.par.entry
  br label %omp.par.region1

omp.par.region1:                                  ; preds = %omp.par.region
  %2 = alloca i32, i64 1, align 4
  %3 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %4 = select i1 false, i32 %3, i32 1
  %5 = select i1 false, i32 1, i32 %3
  %6 = sub nsw i32 %5, %4
  %7 = icmp slt i32 %5, %4
  %8 = udiv i32 %6, 1
  %9 = add i32 %8, 1
  %omp_loop.tripcount = select i1 %7, i32 0, i32 %9
  br label %omp_loop.preheader

omp_loop.preheader:                               ; preds = %omp.par.region1
  store i32 0, ptr %p.lowerbound, align 4
  %10 = sub i32 %omp_loop.tripcount, 1
  store i32 %10, ptr %p.upperbound, align 4
  store i32 1, ptr %p.stride, align 4
  %omp_global_thread_num3 = call i32 @__kmpc_global_thread_num(ptr @1)
  call void @__kmpc_for_static_init_4u(ptr @1, i32 %omp_global_thread_num3, i32 34, ptr %p.lastiter, ptr %p.lowerbound, ptr %p.upperbound, ptr %p.stride, i32 1, i32 0)
  %11 = load i32, ptr %p.lowerbound, align 4
  %12 = load i32, ptr %p.upperbound, align 4
  %13 = sub i32 %12, %11
  %14 = add i32 %13, 1
  br label %omp_loop.header

omp_loop.header:                                  ; preds = %omp_loop.inc, %omp_loop.preheader
  %omp_loop.iv = phi i32 [ 0, %omp_loop.preheader ], [ %omp_loop.next, %omp_loop.inc ]
  br label %omp_loop.cond

omp_loop.cond:                                    ; preds = %omp_loop.header
  %omp_loop.cmp = icmp ult i32 %omp_loop.iv, %14
  br i1 %omp_loop.cmp, label %omp_loop.body, label %omp_loop.exit

omp_loop.exit:                                    ; preds = %omp_loop.cond
  call void @__kmpc_for_static_fini(ptr @1, i32 %omp_global_thread_num3)
  %omp_global_thread_num4 = call i32 @__kmpc_global_thread_num(ptr @1)
  call void @__kmpc_barrier(ptr @2, i32 %omp_global_thread_num4)
  br label %omp_loop.after

omp_loop.after:                                   ; preds = %omp_loop.exit
  br label %omp.region.cont

omp.region.cont:                                  ; preds = %omp_loop.after
  br label %omp.par.pre_finalize

omp.par.pre_finalize:                             ; preds = %omp.region.cont
  br label %omp.par.outlined.exit.exitStub

omp_loop.body:                                    ; preds = %omp_loop.cond
  %15 = add i32 %omp_loop.iv, %11
  %16 = mul i32 %15, 1
  %17 = add i32 %16, 1
  br label %omp.wsloop.region

omp.wsloop.region:                                ; preds = %omp_loop.body
  store i32 %17, ptr %2, align 4, !tbaa !4
  %18 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %19 = sitofp i32 %18 to float
  %20 = fdiv contract float 1.000000e+00, %19
  %21 = fpext float %20 to double
  %22 = load { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, align 8, !tbaa !8
  store { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %22, ptr %loadgep_2, align 8, !tbaa !8
  %23 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i32 0, i32 7, i64 0, i32 0
  %24 = load i64, ptr %23, align 8, !tbaa !8
  %25 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i32 0, i32 7, i64 0, i32 1
  %26 = load i64, ptr %25, align 8, !tbaa !8
  %27 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i32 0, i32 7, i64 0, i32 2
  %28 = load i64, ptr %27, align 8, !tbaa !8
  %29 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i32 0, i32 0
  %30 = load ptr, ptr %29, align 8, !tbaa !8
  %31 = load i32, ptr %2, align 4, !tbaa !4
  %32 = sext i32 %31 to i64
  %33 = sub i64 %32, %24
  %34 = getelementptr double, ptr %30, i64 %33
  store double %21, ptr %34, align 8, !tbaa !4
  br label %omp.region.cont2

omp.region.cont2:                                 ; preds = %omp.wsloop.region
  br label %omp_loop.inc

omp_loop.inc:                                     ; preds = %omp.region.cont2
  %omp_loop.next = add nuw i32 %omp_loop.iv, 1
  br label %omp_loop.header

omp.par.outlined.exit.exitStub:                   ; preds = %omp.par.pre_finalize
  ret void
}

declare ptr @_FortranAioBeginExternalFormattedOutput(ptr, i64, ptr, i32, ptr, i32)

declare zeroext i1 @_FortranAioOutputAscii(ptr, ptr, i64)

declare zeroext i1 @_FortranAioOutputInteger32(ptr, i32)

declare zeroext i1 @_FortranAioOutputReal64(ptr, double)

declare i32 @_FortranAioEndIoStatement(ptr)

; Function Attrs: nocallback nofree nosync nounwind willreturn
declare ptr @llvm.stacksave() #1

; Function Attrs: nocallback nofree nosync nounwind willreturn
declare void @llvm.stackrestore(ptr) #1

; Function Attrs: nounwind
declare i32 @__kmpc_global_thread_num(ptr) #2

; Function Attrs: nounwind
declare void @__kmpc_for_static_init_4u(ptr, i32, i32, ptr, ptr, ptr, ptr, i32, i32) #2

; Function Attrs: nounwind
declare void @__kmpc_for_static_fini(ptr, i32) #2

; Function Attrs: convergent nounwind
declare void @__kmpc_barrier(ptr, i32) #3

; Function Attrs: nounwind
declare !callback !10 void @__kmpc_fork_call(ptr, i32, ptr, ...) #2

attributes #0 = { norecurse nounwind }
attributes #1 = { nocallback nofree nosync nounwind willreturn }
attributes #2 = { nounwind }
attributes #3 = { convergent nounwind }

!llvm.module.flags = !{!0, !1, !2, !3}

!0 = !{i32 2, !"Debug Info Version", i32 3}
!1 = !{i32 7, !"openmp", i32 11}
!2 = !{i32 8, !"PIC Level", i32 2}
!3 = !{i32 7, !"PIE Level", i32 2}
!4 = !{!5, !5, i64 0}
!5 = !{!"any data access", !6, i64 0}
!6 = !{!"any access", !7, i64 0}
!7 = !{!"Flang Type TBAA Root"}
!8 = !{!9, !9, i64 0}
!9 = !{!"descriptor member", !6, i64 0}
!10 = !{!11}
!11 = !{i64 2, i64 -1, i64 -1, i1 true}
*** IR Dump After InferFunctionAttrsPass on [module] ***
; ModuleID = 'FIRModule'
source_filename = "FIRModule"
target datalayout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128"
target triple = "x86_64-unknown-linux-gnu"

%struct.ident_t = type { i32, i32, i32, i32, ptr }

@_QFEarr = internal global { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } { ptr null, i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), i32 20180515, i8 1, i8 28, i8 2, i8 0, [1 x [3 x i64]] [[3 x i64] [i64 1, i64 0, i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64)]] }
@_QQcl.68815510185ede6107d6524e77abf791 = internal constant [52 x i8] c"/g/g92/rydahl1/flangtests/src/array_descriptors.f90\00"
@_QQcl.28612C69372C612C6531332E36653229 = internal constant [16 x i8] c"(a,i7,a,e13.6e2)"
@_QQcl.54686520726573756C74206F6620286172722831292B61727228 = internal constant [26 x i8] c"The result of (arr(1)+arr("
@_QQcl.2920697320 = internal constant [5 x i8] c") is "
@_QQEnvironmentDefaults = constant ptr null
@0 = private unnamed_addr constant [23 x i8] c";unknown;unknown;0;0;;\00", align 1
@1 = private unnamed_addr constant %struct.ident_t { i32 0, i32 2, i32 0, i32 22, ptr @0 }, align 8
@2 = private unnamed_addr constant %struct.ident_t { i32 0, i32 66, i32 0, i32 22, ptr @0 }, align 8

; Function Attrs: mustprogress nofree nounwind willreturn allockind("alloc,uninitialized") allocsize(0) memory(inaccessiblemem: readwrite)
declare noalias noundef ptr @malloc(i64 noundef) #0

; Function Attrs: mustprogress nounwind willreturn allockind("free") memory(argmem: readwrite, inaccessiblemem: readwrite)
declare void @free(ptr allocptr nocapture noundef) #1

define void @_QQmain() {
  %structArg = alloca { ptr, ptr }, align 8
  %1 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %2 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %3 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %4 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %5 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %6 = alloca i32, i64 1, align 4
  %7 = alloca i32, i64 1, align 4
  store i32 1048576, ptr %7, align 4, !tbaa !4
  %8 = load i32, ptr %7, align 4, !tbaa !4
  %9 = sext i32 %8 to i64
  %10 = icmp sgt i64 %9, 0
  %11 = select i1 %10, i64 %9, i64 0
  %12 = mul i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), %11
  %13 = call ptr @malloc(i64 %12)
  %14 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } { ptr undef, i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), i32 20180515, i8 1, i8 28, i8 2, i8 0, [1 x [3 x i64]] [[3 x i64] [i64 1, i64 undef, i64 undef]] }, i64 %11, 7, 0, 1
  %15 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %14, i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), 7, 0, 2
  %16 = mul i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), %11
  %17 = mul i64 1, %11
  %18 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %15, ptr %13, 0
  store { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %18, ptr %5, align 8, !tbaa !8
  %19 = load { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, align 8, !tbaa !8
  store { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %19, ptr @_QFEarr, align 8, !tbaa !8
  br label %entry

entry:                                            ; preds = %0
  %omp_global_thread_num = call i32 @__kmpc_global_thread_num(ptr @1)
  br label %omp_parallel

omp_parallel:                                     ; preds = %entry
  %gep_ = getelementptr { ptr, ptr }, ptr %structArg, i32 0, i32 0
  store ptr %7, ptr %gep_, align 8
  %gep_5 = getelementptr { ptr, ptr }, ptr %structArg, i32 0, i32 1
  store ptr %4, ptr %gep_5, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr @1, i32 1, ptr @_QQmain..omp_par, ptr %structArg)
  br label %omp.par.outlined.exit

omp.par.outlined.exit:                            ; preds = %omp_parallel
  br label %omp.par.exit.split

omp.par.exit.split:                               ; preds = %omp.par.outlined.exit
  %20 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr @_QQcl.68815510185ede6107d6524e77abf791, i32 19)
  %21 = call i1 @_FortranAioOutputAscii(ptr %20, ptr @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %22 = load i32, ptr %7, align 4, !tbaa !4
  %23 = call i1 @_FortranAioOutputInteger32(ptr %20, i32 %22)
  %24 = call i1 @_FortranAioOutputAscii(ptr %20, ptr @_QQcl.2920697320, i64 5)
  %25 = load { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, align 8, !tbaa !8
  store { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %25, ptr %3, align 8, !tbaa !8
  %26 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i32 0, i32 7, i64 0, i32 0
  %27 = load i64, ptr %26, align 8, !tbaa !8
  %28 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i32 0, i32 7, i64 0, i32 1
  %29 = load i64, ptr %28, align 8, !tbaa !8
  %30 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i32 0, i32 7, i64 0, i32 2
  %31 = load i64, ptr %30, align 8, !tbaa !8
  %32 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i32 0, i32 0
  %33 = load ptr, ptr %32, align 8, !tbaa !8
  %34 = sub i64 1, %27
  %35 = getelementptr double, ptr %33, i64 %34
  %36 = load double, ptr %35, align 8, !tbaa !4
  %37 = load i32, ptr %7, align 4, !tbaa !4
  %38 = sext i32 %37 to i64
  %39 = sub i64 %38, %27
  %40 = getelementptr double, ptr %33, i64 %39
  %41 = load double, ptr %40, align 8, !tbaa !4
  %42 = fadd contract double %36, %41
  %43 = call i1 @_FortranAioOutputReal64(ptr %20, double %42)
  %44 = call i32 @_FortranAioEndIoStatement(ptr %20)
  %45 = load { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, align 8, !tbaa !8
  store { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %45, ptr %2, align 8, !tbaa !8
  %46 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %2, i32 0, i32 0
  %47 = load ptr, ptr %46, align 8, !tbaa !8
  call void @free(ptr %47)
  store { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } { ptr null, i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), i32 20180515, i8 1, i8 28, i8 2, i8 0, [1 x [3 x i64]] [[3 x i64] [i64 1, i64 0, i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64)]] }, ptr %1, align 8, !tbaa !8
  %48 = load { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %1, align 8, !tbaa !8
  store { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %48, ptr @_QFEarr, align 8, !tbaa !8
  ret void
}

; Function Attrs: norecurse nounwind
define internal void @_QQmain..omp_par(ptr noalias %tid.addr, ptr noalias %zero.addr, ptr %0) #2 {
omp.par.entry:
  %gep_ = getelementptr { ptr, ptr }, ptr %0, i32 0, i32 0
  %loadgep_ = load ptr, ptr %gep_, align 8
  %gep_1 = getelementptr { ptr, ptr }, ptr %0, i32 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %tid.addr.local = alloca i32, align 4
  %1 = load i32, ptr %tid.addr, align 4
  store i32 %1, ptr %tid.addr.local, align 4
  %tid = load i32, ptr %tid.addr.local, align 4
  %p.lastiter = alloca i32, align 4
  %p.lowerbound = alloca i32, align 4
  %p.upperbound = alloca i32, align 4
  %p.stride = alloca i32, align 4
  br label %omp.par.region

omp.par.region:                                   ; preds = %omp.par.entry
  br label %omp.par.region1

omp.par.region1:                                  ; preds = %omp.par.region
  %2 = alloca i32, i64 1, align 4
  %3 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %4 = select i1 false, i32 %3, i32 1
  %5 = select i1 false, i32 1, i32 %3
  %6 = sub nsw i32 %5, %4
  %7 = icmp slt i32 %5, %4
  %8 = udiv i32 %6, 1
  %9 = add i32 %8, 1
  %omp_loop.tripcount = select i1 %7, i32 0, i32 %9
  br label %omp_loop.preheader

omp_loop.preheader:                               ; preds = %omp.par.region1
  store i32 0, ptr %p.lowerbound, align 4
  %10 = sub i32 %omp_loop.tripcount, 1
  store i32 %10, ptr %p.upperbound, align 4
  store i32 1, ptr %p.stride, align 4
  %omp_global_thread_num3 = call i32 @__kmpc_global_thread_num(ptr @1)
  call void @__kmpc_for_static_init_4u(ptr @1, i32 %omp_global_thread_num3, i32 34, ptr %p.lastiter, ptr %p.lowerbound, ptr %p.upperbound, ptr %p.stride, i32 1, i32 0)
  %11 = load i32, ptr %p.lowerbound, align 4
  %12 = load i32, ptr %p.upperbound, align 4
  %13 = sub i32 %12, %11
  %14 = add i32 %13, 1
  br label %omp_loop.header

omp_loop.header:                                  ; preds = %omp_loop.inc, %omp_loop.preheader
  %omp_loop.iv = phi i32 [ 0, %omp_loop.preheader ], [ %omp_loop.next, %omp_loop.inc ]
  br label %omp_loop.cond

omp_loop.cond:                                    ; preds = %omp_loop.header
  %omp_loop.cmp = icmp ult i32 %omp_loop.iv, %14
  br i1 %omp_loop.cmp, label %omp_loop.body, label %omp_loop.exit

omp_loop.exit:                                    ; preds = %omp_loop.cond
  call void @__kmpc_for_static_fini(ptr @1, i32 %omp_global_thread_num3)
  %omp_global_thread_num4 = call i32 @__kmpc_global_thread_num(ptr @1)
  call void @__kmpc_barrier(ptr @2, i32 %omp_global_thread_num4)
  br label %omp_loop.after

omp_loop.after:                                   ; preds = %omp_loop.exit
  br label %omp.region.cont

omp.region.cont:                                  ; preds = %omp_loop.after
  br label %omp.par.pre_finalize

omp.par.pre_finalize:                             ; preds = %omp.region.cont
  br label %omp.par.outlined.exit.exitStub

omp_loop.body:                                    ; preds = %omp_loop.cond
  %15 = add i32 %omp_loop.iv, %11
  %16 = mul i32 %15, 1
  %17 = add i32 %16, 1
  br label %omp.wsloop.region

omp.wsloop.region:                                ; preds = %omp_loop.body
  store i32 %17, ptr %2, align 4, !tbaa !4
  %18 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %19 = sitofp i32 %18 to float
  %20 = fdiv contract float 1.000000e+00, %19
  %21 = fpext float %20 to double
  %22 = load { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, align 8, !tbaa !8
  store { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %22, ptr %loadgep_2, align 8, !tbaa !8
  %23 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i32 0, i32 7, i64 0, i32 0
  %24 = load i64, ptr %23, align 8, !tbaa !8
  %25 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i32 0, i32 7, i64 0, i32 1
  %26 = load i64, ptr %25, align 8, !tbaa !8
  %27 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i32 0, i32 7, i64 0, i32 2
  %28 = load i64, ptr %27, align 8, !tbaa !8
  %29 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i32 0, i32 0
  %30 = load ptr, ptr %29, align 8, !tbaa !8
  %31 = load i32, ptr %2, align 4, !tbaa !4
  %32 = sext i32 %31 to i64
  %33 = sub i64 %32, %24
  %34 = getelementptr double, ptr %30, i64 %33
  store double %21, ptr %34, align 8, !tbaa !4
  br label %omp.region.cont2

omp.region.cont2:                                 ; preds = %omp.wsloop.region
  br label %omp_loop.inc

omp_loop.inc:                                     ; preds = %omp.region.cont2
  %omp_loop.next = add nuw i32 %omp_loop.iv, 1
  br label %omp_loop.header

omp.par.outlined.exit.exitStub:                   ; preds = %omp.par.pre_finalize
  ret void
}

declare ptr @_FortranAioBeginExternalFormattedOutput(ptr, i64, ptr, i32, ptr, i32)

declare zeroext i1 @_FortranAioOutputAscii(ptr, ptr, i64)

declare zeroext i1 @_FortranAioOutputInteger32(ptr, i32)

declare zeroext i1 @_FortranAioOutputReal64(ptr, double)

declare i32 @_FortranAioEndIoStatement(ptr)

; Function Attrs: mustprogress nocallback nofree nosync nounwind willreturn
declare ptr @llvm.stacksave() #3

; Function Attrs: mustprogress nocallback nofree nosync nounwind willreturn
declare void @llvm.stackrestore(ptr) #3

; Function Attrs: nounwind
declare i32 @__kmpc_global_thread_num(ptr) #4

; Function Attrs: nounwind
declare void @__kmpc_for_static_init_4u(ptr, i32, i32, ptr, ptr, ptr, ptr, i32, i32) #4

; Function Attrs: nounwind
declare void @__kmpc_for_static_fini(ptr, i32) #4

; Function Attrs: convergent nounwind
declare void @__kmpc_barrier(ptr, i32) #5

; Function Attrs: nounwind
declare !callback !10 void @__kmpc_fork_call(ptr, i32, ptr, ...) #4

attributes #0 = { mustprogress nofree nounwind willreturn allockind("alloc,uninitialized") allocsize(0) memory(inaccessiblemem: readwrite) "alloc-family"="malloc" }
attributes #1 = { mustprogress nounwind willreturn allockind("free") memory(argmem: readwrite, inaccessiblemem: readwrite) "alloc-family"="malloc" }
attributes #2 = { norecurse nounwind }
attributes #3 = { mustprogress nocallback nofree nosync nounwind willreturn }
attributes #4 = { nounwind }
attributes #5 = { convergent nounwind }

!llvm.module.flags = !{!0, !1, !2, !3}

!0 = !{i32 2, !"Debug Info Version", i32 3}
!1 = !{i32 7, !"openmp", i32 11}
!2 = !{i32 8, !"PIC Level", i32 2}
!3 = !{i32 7, !"PIE Level", i32 2}
!4 = !{!5, !5, i64 0}
!5 = !{!"any data access", !6, i64 0}
!6 = !{!"any access", !7, i64 0}
!7 = !{!"Flang Type TBAA Root"}
!8 = !{!9, !9, i64 0}
!9 = !{!"descriptor member", !6, i64 0}
!10 = !{!11}
!11 = !{i64 2, i64 -1, i64 -1, i1 true}
*** IR Dump After CoroEarlyPass on [module] ***
; ModuleID = 'FIRModule'
source_filename = "FIRModule"
target datalayout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128"
target triple = "x86_64-unknown-linux-gnu"

%struct.ident_t = type { i32, i32, i32, i32, ptr }

@_QFEarr = internal global { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } { ptr null, i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), i32 20180515, i8 1, i8 28, i8 2, i8 0, [1 x [3 x i64]] [[3 x i64] [i64 1, i64 0, i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64)]] }
@_QQcl.68815510185ede6107d6524e77abf791 = internal constant [52 x i8] c"/g/g92/rydahl1/flangtests/src/array_descriptors.f90\00"
@_QQcl.28612C69372C612C6531332E36653229 = internal constant [16 x i8] c"(a,i7,a,e13.6e2)"
@_QQcl.54686520726573756C74206F6620286172722831292B61727228 = internal constant [26 x i8] c"The result of (arr(1)+arr("
@_QQcl.2920697320 = internal constant [5 x i8] c") is "
@_QQEnvironmentDefaults = constant ptr null
@0 = private unnamed_addr constant [23 x i8] c";unknown;unknown;0;0;;\00", align 1
@1 = private unnamed_addr constant %struct.ident_t { i32 0, i32 2, i32 0, i32 22, ptr @0 }, align 8
@2 = private unnamed_addr constant %struct.ident_t { i32 0, i32 66, i32 0, i32 22, ptr @0 }, align 8

; Function Attrs: mustprogress nofree nounwind willreturn allockind("alloc,uninitialized") allocsize(0) memory(inaccessiblemem: readwrite)
declare noalias noundef ptr @malloc(i64 noundef) #0

; Function Attrs: mustprogress nounwind willreturn allockind("free") memory(argmem: readwrite, inaccessiblemem: readwrite)
declare void @free(ptr allocptr nocapture noundef) #1

define void @_QQmain() {
  %structArg = alloca { ptr, ptr }, align 8
  %1 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %2 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %3 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %4 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %5 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %6 = alloca i32, i64 1, align 4
  %7 = alloca i32, i64 1, align 4
  store i32 1048576, ptr %7, align 4, !tbaa !4
  %8 = load i32, ptr %7, align 4, !tbaa !4
  %9 = sext i32 %8 to i64
  %10 = icmp sgt i64 %9, 0
  %11 = select i1 %10, i64 %9, i64 0
  %12 = mul i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), %11
  %13 = call ptr @malloc(i64 %12)
  %14 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } { ptr undef, i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), i32 20180515, i8 1, i8 28, i8 2, i8 0, [1 x [3 x i64]] [[3 x i64] [i64 1, i64 undef, i64 undef]] }, i64 %11, 7, 0, 1
  %15 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %14, i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), 7, 0, 2
  %16 = mul i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), %11
  %17 = mul i64 1, %11
  %18 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %15, ptr %13, 0
  store { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %18, ptr %5, align 8, !tbaa !8
  %19 = load { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, align 8, !tbaa !8
  store { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %19, ptr @_QFEarr, align 8, !tbaa !8
  br label %entry

entry:                                            ; preds = %0
  %omp_global_thread_num = call i32 @__kmpc_global_thread_num(ptr @1)
  br label %omp_parallel

omp_parallel:                                     ; preds = %entry
  %gep_ = getelementptr { ptr, ptr }, ptr %structArg, i32 0, i32 0
  store ptr %7, ptr %gep_, align 8
  %gep_5 = getelementptr { ptr, ptr }, ptr %structArg, i32 0, i32 1
  store ptr %4, ptr %gep_5, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr @1, i32 1, ptr @_QQmain..omp_par, ptr %structArg)
  br label %omp.par.outlined.exit

omp.par.outlined.exit:                            ; preds = %omp_parallel
  br label %omp.par.exit.split

omp.par.exit.split:                               ; preds = %omp.par.outlined.exit
  %20 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr @_QQcl.68815510185ede6107d6524e77abf791, i32 19)
  %21 = call i1 @_FortranAioOutputAscii(ptr %20, ptr @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %22 = load i32, ptr %7, align 4, !tbaa !4
  %23 = call i1 @_FortranAioOutputInteger32(ptr %20, i32 %22)
  %24 = call i1 @_FortranAioOutputAscii(ptr %20, ptr @_QQcl.2920697320, i64 5)
  %25 = load { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, align 8, !tbaa !8
  store { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %25, ptr %3, align 8, !tbaa !8
  %26 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i32 0, i32 7, i64 0, i32 0
  %27 = load i64, ptr %26, align 8, !tbaa !8
  %28 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i32 0, i32 7, i64 0, i32 1
  %29 = load i64, ptr %28, align 8, !tbaa !8
  %30 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i32 0, i32 7, i64 0, i32 2
  %31 = load i64, ptr %30, align 8, !tbaa !8
  %32 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i32 0, i32 0
  %33 = load ptr, ptr %32, align 8, !tbaa !8
  %34 = sub i64 1, %27
  %35 = getelementptr double, ptr %33, i64 %34
  %36 = load double, ptr %35, align 8, !tbaa !4
  %37 = load i32, ptr %7, align 4, !tbaa !4
  %38 = sext i32 %37 to i64
  %39 = sub i64 %38, %27
  %40 = getelementptr double, ptr %33, i64 %39
  %41 = load double, ptr %40, align 8, !tbaa !4
  %42 = fadd contract double %36, %41
  %43 = call i1 @_FortranAioOutputReal64(ptr %20, double %42)
  %44 = call i32 @_FortranAioEndIoStatement(ptr %20)
  %45 = load { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, align 8, !tbaa !8
  store { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %45, ptr %2, align 8, !tbaa !8
  %46 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %2, i32 0, i32 0
  %47 = load ptr, ptr %46, align 8, !tbaa !8
  call void @free(ptr %47)
  store { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } { ptr null, i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), i32 20180515, i8 1, i8 28, i8 2, i8 0, [1 x [3 x i64]] [[3 x i64] [i64 1, i64 0, i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64)]] }, ptr %1, align 8, !tbaa !8
  %48 = load { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %1, align 8, !tbaa !8
  store { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %48, ptr @_QFEarr, align 8, !tbaa !8
  ret void
}

; Function Attrs: norecurse nounwind
define internal void @_QQmain..omp_par(ptr noalias %tid.addr, ptr noalias %zero.addr, ptr %0) #2 {
omp.par.entry:
  %gep_ = getelementptr { ptr, ptr }, ptr %0, i32 0, i32 0
  %loadgep_ = load ptr, ptr %gep_, align 8
  %gep_1 = getelementptr { ptr, ptr }, ptr %0, i32 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %tid.addr.local = alloca i32, align 4
  %1 = load i32, ptr %tid.addr, align 4
  store i32 %1, ptr %tid.addr.local, align 4
  %tid = load i32, ptr %tid.addr.local, align 4
  %p.lastiter = alloca i32, align 4
  %p.lowerbound = alloca i32, align 4
  %p.upperbound = alloca i32, align 4
  %p.stride = alloca i32, align 4
  br label %omp.par.region

omp.par.region:                                   ; preds = %omp.par.entry
  br label %omp.par.region1

omp.par.region1:                                  ; preds = %omp.par.region
  %2 = alloca i32, i64 1, align 4
  %3 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %4 = select i1 false, i32 %3, i32 1
  %5 = select i1 false, i32 1, i32 %3
  %6 = sub nsw i32 %5, %4
  %7 = icmp slt i32 %5, %4
  %8 = udiv i32 %6, 1
  %9 = add i32 %8, 1
  %omp_loop.tripcount = select i1 %7, i32 0, i32 %9
  br label %omp_loop.preheader

omp_loop.preheader:                               ; preds = %omp.par.region1
  store i32 0, ptr %p.lowerbound, align 4
  %10 = sub i32 %omp_loop.tripcount, 1
  store i32 %10, ptr %p.upperbound, align 4
  store i32 1, ptr %p.stride, align 4
  %omp_global_thread_num3 = call i32 @__kmpc_global_thread_num(ptr @1)
  call void @__kmpc_for_static_init_4u(ptr @1, i32 %omp_global_thread_num3, i32 34, ptr %p.lastiter, ptr %p.lowerbound, ptr %p.upperbound, ptr %p.stride, i32 1, i32 0)
  %11 = load i32, ptr %p.lowerbound, align 4
  %12 = load i32, ptr %p.upperbound, align 4
  %13 = sub i32 %12, %11
  %14 = add i32 %13, 1
  br label %omp_loop.header

omp_loop.header:                                  ; preds = %omp_loop.inc, %omp_loop.preheader
  %omp_loop.iv = phi i32 [ 0, %omp_loop.preheader ], [ %omp_loop.next, %omp_loop.inc ]
  br label %omp_loop.cond

omp_loop.cond:                                    ; preds = %omp_loop.header
  %omp_loop.cmp = icmp ult i32 %omp_loop.iv, %14
  br i1 %omp_loop.cmp, label %omp_loop.body, label %omp_loop.exit

omp_loop.exit:                                    ; preds = %omp_loop.cond
  call void @__kmpc_for_static_fini(ptr @1, i32 %omp_global_thread_num3)
  %omp_global_thread_num4 = call i32 @__kmpc_global_thread_num(ptr @1)
  call void @__kmpc_barrier(ptr @2, i32 %omp_global_thread_num4)
  br label %omp_loop.after

omp_loop.after:                                   ; preds = %omp_loop.exit
  br label %omp.region.cont

omp.region.cont:                                  ; preds = %omp_loop.after
  br label %omp.par.pre_finalize

omp.par.pre_finalize:                             ; preds = %omp.region.cont
  br label %omp.par.outlined.exit.exitStub

omp_loop.body:                                    ; preds = %omp_loop.cond
  %15 = add i32 %omp_loop.iv, %11
  %16 = mul i32 %15, 1
  %17 = add i32 %16, 1
  br label %omp.wsloop.region

omp.wsloop.region:                                ; preds = %omp_loop.body
  store i32 %17, ptr %2, align 4, !tbaa !4
  %18 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %19 = sitofp i32 %18 to float
  %20 = fdiv contract float 1.000000e+00, %19
  %21 = fpext float %20 to double
  %22 = load { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, align 8, !tbaa !8
  store { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %22, ptr %loadgep_2, align 8, !tbaa !8
  %23 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i32 0, i32 7, i64 0, i32 0
  %24 = load i64, ptr %23, align 8, !tbaa !8
  %25 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i32 0, i32 7, i64 0, i32 1
  %26 = load i64, ptr %25, align 8, !tbaa !8
  %27 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i32 0, i32 7, i64 0, i32 2
  %28 = load i64, ptr %27, align 8, !tbaa !8
  %29 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i32 0, i32 0
  %30 = load ptr, ptr %29, align 8, !tbaa !8
  %31 = load i32, ptr %2, align 4, !tbaa !4
  %32 = sext i32 %31 to i64
  %33 = sub i64 %32, %24
  %34 = getelementptr double, ptr %30, i64 %33
  store double %21, ptr %34, align 8, !tbaa !4
  br label %omp.region.cont2

omp.region.cont2:                                 ; preds = %omp.wsloop.region
  br label %omp_loop.inc

omp_loop.inc:                                     ; preds = %omp.region.cont2
  %omp_loop.next = add nuw i32 %omp_loop.iv, 1
  br label %omp_loop.header

omp.par.outlined.exit.exitStub:                   ; preds = %omp.par.pre_finalize
  ret void
}

declare ptr @_FortranAioBeginExternalFormattedOutput(ptr, i64, ptr, i32, ptr, i32)

declare zeroext i1 @_FortranAioOutputAscii(ptr, ptr, i64)

declare zeroext i1 @_FortranAioOutputInteger32(ptr, i32)

declare zeroext i1 @_FortranAioOutputReal64(ptr, double)

declare i32 @_FortranAioEndIoStatement(ptr)

; Function Attrs: mustprogress nocallback nofree nosync nounwind willreturn
declare ptr @llvm.stacksave() #3

; Function Attrs: mustprogress nocallback nofree nosync nounwind willreturn
declare void @llvm.stackrestore(ptr) #3

; Function Attrs: nounwind
declare i32 @__kmpc_global_thread_num(ptr) #4

; Function Attrs: nounwind
declare void @__kmpc_for_static_init_4u(ptr, i32, i32, ptr, ptr, ptr, ptr, i32, i32) #4

; Function Attrs: nounwind
declare void @__kmpc_for_static_fini(ptr, i32) #4

; Function Attrs: convergent nounwind
declare void @__kmpc_barrier(ptr, i32) #5

; Function Attrs: nounwind
declare !callback !10 void @__kmpc_fork_call(ptr, i32, ptr, ...) #4

attributes #0 = { mustprogress nofree nounwind willreturn allockind("alloc,uninitialized") allocsize(0) memory(inaccessiblemem: readwrite) "alloc-family"="malloc" }
attributes #1 = { mustprogress nounwind willreturn allockind("free") memory(argmem: readwrite, inaccessiblemem: readwrite) "alloc-family"="malloc" }
attributes #2 = { norecurse nounwind }
attributes #3 = { mustprogress nocallback nofree nosync nounwind willreturn }
attributes #4 = { nounwind }
attributes #5 = { convergent nounwind }

!llvm.module.flags = !{!0, !1, !2, !3}

!0 = !{i32 2, !"Debug Info Version", i32 3}
!1 = !{i32 7, !"openmp", i32 11}
!2 = !{i32 8, !"PIC Level", i32 2}
!3 = !{i32 7, !"PIE Level", i32 2}
!4 = !{!5, !5, i64 0}
!5 = !{!"any data access", !6, i64 0}
!6 = !{!"any access", !7, i64 0}
!7 = !{!"Flang Type TBAA Root"}
!8 = !{!9, !9, i64 0}
!9 = !{!"descriptor member", !6, i64 0}
!10 = !{!11}
!11 = !{i64 2, i64 -1, i64 -1, i1 true}
*** IR Dump After LowerExpectIntrinsicPass on _QQmain ***
define void @_QQmain() {
  %structArg = alloca { ptr, ptr }, align 8
  %1 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %2 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %3 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %4 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %5 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %6 = alloca i32, i64 1, align 4
  %7 = alloca i32, i64 1, align 4
  store i32 1048576, ptr %7, align 4, !tbaa !4
  %8 = load i32, ptr %7, align 4, !tbaa !4
  %9 = sext i32 %8 to i64
  %10 = icmp sgt i64 %9, 0
  %11 = select i1 %10, i64 %9, i64 0
  %12 = mul i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), %11
  %13 = call ptr @malloc(i64 %12)
  %14 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } { ptr undef, i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), i32 20180515, i8 1, i8 28, i8 2, i8 0, [1 x [3 x i64]] [[3 x i64] [i64 1, i64 undef, i64 undef]] }, i64 %11, 7, 0, 1
  %15 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %14, i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), 7, 0, 2
  %16 = mul i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), %11
  %17 = mul i64 1, %11
  %18 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %15, ptr %13, 0
  store { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %18, ptr %5, align 8, !tbaa !8
  %19 = load { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, align 8, !tbaa !8
  store { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %19, ptr @_QFEarr, align 8, !tbaa !8
  br label %entry

entry:                                            ; preds = %0
  %omp_global_thread_num = call i32 @__kmpc_global_thread_num(ptr @1)
  br label %omp_parallel

omp_parallel:                                     ; preds = %entry
  %gep_ = getelementptr { ptr, ptr }, ptr %structArg, i32 0, i32 0
  store ptr %7, ptr %gep_, align 8
  %gep_5 = getelementptr { ptr, ptr }, ptr %structArg, i32 0, i32 1
  store ptr %4, ptr %gep_5, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr @1, i32 1, ptr @_QQmain..omp_par, ptr %structArg)
  br label %omp.par.outlined.exit

omp.par.outlined.exit:                            ; preds = %omp_parallel
  br label %omp.par.exit.split

omp.par.exit.split:                               ; preds = %omp.par.outlined.exit
  %20 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr @_QQcl.68815510185ede6107d6524e77abf791, i32 19)
  %21 = call i1 @_FortranAioOutputAscii(ptr %20, ptr @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %22 = load i32, ptr %7, align 4, !tbaa !4
  %23 = call i1 @_FortranAioOutputInteger32(ptr %20, i32 %22)
  %24 = call i1 @_FortranAioOutputAscii(ptr %20, ptr @_QQcl.2920697320, i64 5)
  %25 = load { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, align 8, !tbaa !8
  store { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %25, ptr %3, align 8, !tbaa !8
  %26 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i32 0, i32 7, i64 0, i32 0
  %27 = load i64, ptr %26, align 8, !tbaa !8
  %28 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i32 0, i32 7, i64 0, i32 1
  %29 = load i64, ptr %28, align 8, !tbaa !8
  %30 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i32 0, i32 7, i64 0, i32 2
  %31 = load i64, ptr %30, align 8, !tbaa !8
  %32 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i32 0, i32 0
  %33 = load ptr, ptr %32, align 8, !tbaa !8
  %34 = sub i64 1, %27
  %35 = getelementptr double, ptr %33, i64 %34
  %36 = load double, ptr %35, align 8, !tbaa !4
  %37 = load i32, ptr %7, align 4, !tbaa !4
  %38 = sext i32 %37 to i64
  %39 = sub i64 %38, %27
  %40 = getelementptr double, ptr %33, i64 %39
  %41 = load double, ptr %40, align 8, !tbaa !4
  %42 = fadd contract double %36, %41
  %43 = call i1 @_FortranAioOutputReal64(ptr %20, double %42)
  %44 = call i32 @_FortranAioEndIoStatement(ptr %20)
  %45 = load { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, align 8, !tbaa !8
  store { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %45, ptr %2, align 8, !tbaa !8
  %46 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %2, i32 0, i32 0
  %47 = load ptr, ptr %46, align 8, !tbaa !8
  call void @free(ptr %47)
  store { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } { ptr null, i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), i32 20180515, i8 1, i8 28, i8 2, i8 0, [1 x [3 x i64]] [[3 x i64] [i64 1, i64 0, i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64)]] }, ptr %1, align 8, !tbaa !8
  %48 = load { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %1, align 8, !tbaa !8
  store { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %48, ptr @_QFEarr, align 8, !tbaa !8
  ret void
}
*** IR Dump After SimplifyCFGPass on _QQmain ***
define void @_QQmain() {
entry:
  %structArg = alloca { ptr, ptr }, align 8
  %0 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %1 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %2 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %3 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %4 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %5 = alloca i32, i64 1, align 4
  %6 = alloca i32, i64 1, align 4
  store i32 1048576, ptr %6, align 4, !tbaa !4
  %7 = load i32, ptr %6, align 4, !tbaa !4
  %8 = sext i32 %7 to i64
  %9 = icmp sgt i64 %8, 0
  %10 = select i1 %9, i64 %8, i64 0
  %11 = mul i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), %10
  %12 = call ptr @malloc(i64 %11)
  %13 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } { ptr undef, i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), i32 20180515, i8 1, i8 28, i8 2, i8 0, [1 x [3 x i64]] [[3 x i64] [i64 1, i64 undef, i64 undef]] }, i64 %10, 7, 0, 1
  %14 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %13, i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), 7, 0, 2
  %15 = mul i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), %10
  %16 = mul i64 1, %10
  %17 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %14, ptr %12, 0
  store { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %17, ptr %4, align 8, !tbaa !8
  %18 = load { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %4, align 8, !tbaa !8
  store { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %18, ptr @_QFEarr, align 8, !tbaa !8
  %omp_global_thread_num = call i32 @__kmpc_global_thread_num(ptr @1)
  %gep_ = getelementptr { ptr, ptr }, ptr %structArg, i32 0, i32 0
  store ptr %6, ptr %gep_, align 8
  %gep_5 = getelementptr { ptr, ptr }, ptr %structArg, i32 0, i32 1
  store ptr %3, ptr %gep_5, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr @1, i32 1, ptr @_QQmain..omp_par, ptr %structArg)
  %19 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr @_QQcl.68815510185ede6107d6524e77abf791, i32 19)
  %20 = call i1 @_FortranAioOutputAscii(ptr %19, ptr @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %21 = load i32, ptr %6, align 4, !tbaa !4
  %22 = call i1 @_FortranAioOutputInteger32(ptr %19, i32 %21)
  %23 = call i1 @_FortranAioOutputAscii(ptr %19, ptr @_QQcl.2920697320, i64 5)
  %24 = load { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, align 8, !tbaa !8
  store { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %24, ptr %2, align 8, !tbaa !8
  %25 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %2, i32 0, i32 7, i64 0, i32 0
  %26 = load i64, ptr %25, align 8, !tbaa !8
  %27 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %2, i32 0, i32 7, i64 0, i32 1
  %28 = load i64, ptr %27, align 8, !tbaa !8
  %29 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %2, i32 0, i32 7, i64 0, i32 2
  %30 = load i64, ptr %29, align 8, !tbaa !8
  %31 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %2, i32 0, i32 0
  %32 = load ptr, ptr %31, align 8, !tbaa !8
  %33 = sub i64 1, %26
  %34 = getelementptr double, ptr %32, i64 %33
  %35 = load double, ptr %34, align 8, !tbaa !4
  %36 = load i32, ptr %6, align 4, !tbaa !4
  %37 = sext i32 %36 to i64
  %38 = sub i64 %37, %26
  %39 = getelementptr double, ptr %32, i64 %38
  %40 = load double, ptr %39, align 8, !tbaa !4
  %41 = fadd contract double %35, %40
  %42 = call i1 @_FortranAioOutputReal64(ptr %19, double %41)
  %43 = call i32 @_FortranAioEndIoStatement(ptr %19)
  %44 = load { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, align 8, !tbaa !8
  store { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %44, ptr %1, align 8, !tbaa !8
  %45 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %1, i32 0, i32 0
  %46 = load ptr, ptr %45, align 8, !tbaa !8
  call void @free(ptr %46)
  store { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } { ptr null, i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), i32 20180515, i8 1, i8 28, i8 2, i8 0, [1 x [3 x i64]] [[3 x i64] [i64 1, i64 0, i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64)]] }, ptr %0, align 8, !tbaa !8
  %47 = load { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %0, align 8, !tbaa !8
  store { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %47, ptr @_QFEarr, align 8, !tbaa !8
  ret void
}
*** IR Dump After SROAPass on _QQmain ***
define void @_QQmain() {
entry:
  %structArg = alloca { ptr, ptr }, align 8
  %0 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %1 = alloca i32, i64 1, align 4
  store i32 1048576, ptr %1, align 4, !tbaa !4
  %2 = load i32, ptr %1, align 4, !tbaa !4
  %3 = sext i32 %2 to i64
  %4 = icmp sgt i64 %3, 0
  %5 = select i1 %4, i64 %3, i64 0
  %6 = mul i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), %5
  %7 = call ptr @malloc(i64 %6)
  %8 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } { ptr undef, i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), i32 20180515, i8 1, i8 28, i8 2, i8 0, [1 x [3 x i64]] [[3 x i64] [i64 1, i64 undef, i64 undef]] }, i64 %5, 7, 0, 1
  %9 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %8, i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), 7, 0, 2
  %10 = mul i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), %5
  %11 = mul i64 1, %5
  %12 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %9, ptr %7, 0
  %.fca.0.extract = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %12, 0
  %.fca.1.extract = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %12, 1
  %.fca.2.extract = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %12, 2
  %.fca.3.extract = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %12, 3
  %.fca.4.extract = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %12, 4
  %.fca.5.extract = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %12, 5
  %.fca.6.extract = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %12, 6
  %.fca.7.0.0.extract = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %12, 7, 0, 0
  %.fca.7.0.1.extract = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %12, 7, 0, 1
  %.fca.7.0.2.extract = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %12, 7, 0, 2
  %.fca.0.insert = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } poison, ptr %.fca.0.extract, 0
  %.fca.1.insert = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.0.insert, i64 %.fca.1.extract, 1
  %.fca.2.insert = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.1.insert, i32 %.fca.2.extract, 2
  %.fca.3.insert = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.2.insert, i8 %.fca.3.extract, 3
  %.fca.4.insert = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.3.insert, i8 %.fca.4.extract, 4
  %.fca.5.insert = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.4.insert, i8 %.fca.5.extract, 5
  %.fca.6.insert = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.5.insert, i8 %.fca.6.extract, 6
  %.fca.7.0.0.insert = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.6.insert, i64 %.fca.7.0.0.extract, 7, 0, 0
  %.fca.7.0.1.insert = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.7.0.0.insert, i64 %.fca.7.0.1.extract, 7, 0, 1
  %.fca.7.0.2.insert = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.7.0.1.insert, i64 %.fca.7.0.2.extract, 7, 0, 2
  store { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.7.0.2.insert, ptr @_QFEarr, align 8, !tbaa !8
  %omp_global_thread_num = call i32 @__kmpc_global_thread_num(ptr @1)
  %gep_ = getelementptr { ptr, ptr }, ptr %structArg, i32 0, i32 0
  store ptr %1, ptr %gep_, align 8
  %gep_5 = getelementptr { ptr, ptr }, ptr %structArg, i32 0, i32 1
  store ptr %0, ptr %gep_5, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr @1, i32 1, ptr @_QQmain..omp_par, ptr %structArg)
  %13 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr @_QQcl.68815510185ede6107d6524e77abf791, i32 19)
  %14 = call i1 @_FortranAioOutputAscii(ptr %13, ptr @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %15 = load i32, ptr %1, align 4, !tbaa !4
  %16 = call i1 @_FortranAioOutputInteger32(ptr %13, i32 %15)
  %17 = call i1 @_FortranAioOutputAscii(ptr %13, ptr @_QQcl.2920697320, i64 5)
  %18 = load { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, align 8, !tbaa !8
  %.fca.0.extract16 = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %18, 0
  %.fca.1.extract17 = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %18, 1
  %.fca.2.extract18 = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %18, 2
  %.fca.3.extract19 = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %18, 3
  %.fca.4.extract20 = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %18, 4
  %.fca.5.extract21 = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %18, 5
  %.fca.6.extract22 = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %18, 6
  %.fca.7.0.0.extract23 = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %18, 7, 0, 0
  %.fca.7.0.1.extract24 = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %18, 7, 0, 1
  %.fca.7.0.2.extract25 = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %18, 7, 0, 2
  %19 = sub i64 1, %.fca.7.0.0.extract23
  %20 = getelementptr double, ptr %.fca.0.extract16, i64 %19
  %21 = load double, ptr %20, align 8, !tbaa !4
  %22 = load i32, ptr %1, align 4, !tbaa !4
  %23 = sext i32 %22 to i64
  %24 = sub i64 %23, %.fca.7.0.0.extract23
  %25 = getelementptr double, ptr %.fca.0.extract16, i64 %24
  %26 = load double, ptr %25, align 8, !tbaa !4
  %27 = fadd contract double %21, %26
  %28 = call i1 @_FortranAioOutputReal64(ptr %13, double %27)
  %29 = call i32 @_FortranAioEndIoStatement(ptr %13)
  %30 = load { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, align 8, !tbaa !8
  %.fca.0.extract33 = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %30, 0
  %.fca.1.extract34 = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %30, 1
  %.fca.2.extract35 = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %30, 2
  %.fca.3.extract36 = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %30, 3
  %.fca.4.extract37 = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %30, 4
  %.fca.5.extract38 = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %30, 5
  %.fca.6.extract39 = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %30, 6
  %.fca.7.0.0.extract40 = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %30, 7, 0, 0
  %.fca.7.0.1.extract41 = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %30, 7, 0, 1
  %.fca.7.0.2.extract42 = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %30, 7, 0, 2
  call void @free(ptr %.fca.0.extract33)
  %.fca.0.insert53 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } poison, ptr null, 0
  %.fca.1.insert55 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.0.insert53, i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), 1
  %.fca.2.insert57 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.1.insert55, i32 20180515, 2
  %.fca.3.insert59 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.2.insert57, i8 1, 3
  %.fca.4.insert61 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.3.insert59, i8 28, 4
  %.fca.5.insert63 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.4.insert61, i8 2, 5
  %.fca.6.insert65 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.5.insert63, i8 0, 6
  %.fca.7.0.0.insert67 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.6.insert65, i64 1, 7, 0, 0
  %.fca.7.0.1.insert69 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.7.0.0.insert67, i64 0, 7, 0, 1
  %.fca.7.0.2.insert71 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.7.0.1.insert69, i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), 7, 0, 2
  store { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.7.0.2.insert71, ptr @_QFEarr, align 8, !tbaa !8
  ret void
}
*** IR Dump After EarlyCSEPass on _QQmain ***
define void @_QQmain() {
entry:
  %structArg = alloca { ptr, ptr }, align 8
  %0 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %1 = alloca i32, i64 1, align 4
  store i32 1048576, ptr %1, align 4, !tbaa !4
  %2 = call ptr @malloc(i64 mul (i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), i64 1048576))
  %3 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } { ptr undef, i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), i32 20180515, i8 1, i8 28, i8 2, i8 0, [1 x [3 x i64]] [[3 x i64] [i64 1, i64 1048576, i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64)]] }, ptr %2, 0
  %.fca.1.extract = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %3, 1
  %.fca.2.extract = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %3, 2
  %.fca.3.extract = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %3, 3
  %.fca.4.extract = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %3, 4
  %.fca.5.extract = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %3, 5
  %.fca.6.extract = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %3, 6
  %.fca.7.0.0.extract = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %3, 7, 0, 0
  %.fca.7.0.1.extract = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %3, 7, 0, 1
  %.fca.7.0.2.extract = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %3, 7, 0, 2
  %.fca.0.insert = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } poison, ptr %2, 0
  %.fca.1.insert = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.0.insert, i64 %.fca.1.extract, 1
  %.fca.2.insert = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.1.insert, i32 %.fca.2.extract, 2
  %.fca.3.insert = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.2.insert, i8 %.fca.3.extract, 3
  %.fca.4.insert = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.3.insert, i8 %.fca.4.extract, 4
  %.fca.5.insert = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.4.insert, i8 %.fca.5.extract, 5
  %.fca.6.insert = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.5.insert, i8 %.fca.6.extract, 6
  %.fca.7.0.0.insert = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.6.insert, i64 %.fca.7.0.0.extract, 7, 0, 0
  %.fca.7.0.1.insert = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.7.0.0.insert, i64 %.fca.7.0.1.extract, 7, 0, 1
  %.fca.7.0.2.insert = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.7.0.1.insert, i64 %.fca.7.0.2.extract, 7, 0, 2
  store { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.7.0.2.insert, ptr @_QFEarr, align 8, !tbaa !8
  %omp_global_thread_num = call i32 @__kmpc_global_thread_num(ptr @1)
  store ptr %1, ptr %structArg, align 8
  %gep_5 = getelementptr { ptr, ptr }, ptr %structArg, i32 0, i32 1
  store ptr %0, ptr %gep_5, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr @1, i32 1, ptr @_QQmain..omp_par, ptr %structArg)
  %4 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr @_QQcl.68815510185ede6107d6524e77abf791, i32 19)
  %5 = call i1 @_FortranAioOutputAscii(ptr %4, ptr @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %6 = load i32, ptr %1, align 4, !tbaa !4
  %7 = call i1 @_FortranAioOutputInteger32(ptr %4, i32 %6)
  %8 = call i1 @_FortranAioOutputAscii(ptr %4, ptr @_QQcl.2920697320, i64 5)
  %9 = load { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, align 8, !tbaa !8
  %.fca.0.extract16 = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %9, 0
  %.fca.7.0.0.extract23 = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %9, 7, 0, 0
  %10 = sub i64 1, %.fca.7.0.0.extract23
  %11 = getelementptr double, ptr %.fca.0.extract16, i64 %10
  %12 = load double, ptr %11, align 8, !tbaa !4
  %13 = load i32, ptr %1, align 4, !tbaa !4
  %14 = sext i32 %13 to i64
  %15 = sub i64 %14, %.fca.7.0.0.extract23
  %16 = getelementptr double, ptr %.fca.0.extract16, i64 %15
  %17 = load double, ptr %16, align 8, !tbaa !4
  %18 = fadd contract double %12, %17
  %19 = call i1 @_FortranAioOutputReal64(ptr %4, double %18)
  %20 = call i32 @_FortranAioEndIoStatement(ptr %4)
  %21 = load { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, align 8, !tbaa !8
  %.fca.0.extract33 = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %21, 0
  call void @free(ptr %.fca.0.extract33)
  store { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } { ptr null, i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), i32 20180515, i8 1, i8 28, i8 2, i8 0, [1 x [3 x i64]] [[3 x i64] [i64 1, i64 0, i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64)]] }, ptr @_QFEarr, align 8, !tbaa !8
  ret void
}
*** IR Dump After CallSiteSplittingPass on _QQmain ***
define void @_QQmain() {
entry:
  %structArg = alloca { ptr, ptr }, align 8
  %0 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %1 = alloca i32, i64 1, align 4
  store i32 1048576, ptr %1, align 4, !tbaa !4
  %2 = call ptr @malloc(i64 mul (i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), i64 1048576))
  %3 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } { ptr undef, i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), i32 20180515, i8 1, i8 28, i8 2, i8 0, [1 x [3 x i64]] [[3 x i64] [i64 1, i64 1048576, i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64)]] }, ptr %2, 0
  %.fca.1.extract = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %3, 1
  %.fca.2.extract = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %3, 2
  %.fca.3.extract = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %3, 3
  %.fca.4.extract = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %3, 4
  %.fca.5.extract = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %3, 5
  %.fca.6.extract = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %3, 6
  %.fca.7.0.0.extract = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %3, 7, 0, 0
  %.fca.7.0.1.extract = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %3, 7, 0, 1
  %.fca.7.0.2.extract = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %3, 7, 0, 2
  %.fca.0.insert = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } poison, ptr %2, 0
  %.fca.1.insert = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.0.insert, i64 %.fca.1.extract, 1
  %.fca.2.insert = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.1.insert, i32 %.fca.2.extract, 2
  %.fca.3.insert = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.2.insert, i8 %.fca.3.extract, 3
  %.fca.4.insert = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.3.insert, i8 %.fca.4.extract, 4
  %.fca.5.insert = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.4.insert, i8 %.fca.5.extract, 5
  %.fca.6.insert = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.5.insert, i8 %.fca.6.extract, 6
  %.fca.7.0.0.insert = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.6.insert, i64 %.fca.7.0.0.extract, 7, 0, 0
  %.fca.7.0.1.insert = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.7.0.0.insert, i64 %.fca.7.0.1.extract, 7, 0, 1
  %.fca.7.0.2.insert = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.7.0.1.insert, i64 %.fca.7.0.2.extract, 7, 0, 2
  store { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.7.0.2.insert, ptr @_QFEarr, align 8, !tbaa !8
  %omp_global_thread_num = call i32 @__kmpc_global_thread_num(ptr @1)
  store ptr %1, ptr %structArg, align 8
  %gep_5 = getelementptr { ptr, ptr }, ptr %structArg, i32 0, i32 1
  store ptr %0, ptr %gep_5, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr @1, i32 1, ptr @_QQmain..omp_par, ptr %structArg)
  %4 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr @_QQcl.68815510185ede6107d6524e77abf791, i32 19)
  %5 = call i1 @_FortranAioOutputAscii(ptr %4, ptr @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %6 = load i32, ptr %1, align 4, !tbaa !4
  %7 = call i1 @_FortranAioOutputInteger32(ptr %4, i32 %6)
  %8 = call i1 @_FortranAioOutputAscii(ptr %4, ptr @_QQcl.2920697320, i64 5)
  %9 = load { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, align 8, !tbaa !8
  %.fca.0.extract16 = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %9, 0
  %.fca.7.0.0.extract23 = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %9, 7, 0, 0
  %10 = sub i64 1, %.fca.7.0.0.extract23
  %11 = getelementptr double, ptr %.fca.0.extract16, i64 %10
  %12 = load double, ptr %11, align 8, !tbaa !4
  %13 = load i32, ptr %1, align 4, !tbaa !4
  %14 = sext i32 %13 to i64
  %15 = sub i64 %14, %.fca.7.0.0.extract23
  %16 = getelementptr double, ptr %.fca.0.extract16, i64 %15
  %17 = load double, ptr %16, align 8, !tbaa !4
  %18 = fadd contract double %12, %17
  %19 = call i1 @_FortranAioOutputReal64(ptr %4, double %18)
  %20 = call i32 @_FortranAioEndIoStatement(ptr %4)
  %21 = load { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, align 8, !tbaa !8
  %.fca.0.extract33 = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %21, 0
  call void @free(ptr %.fca.0.extract33)
  store { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } { ptr null, i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), i32 20180515, i8 1, i8 28, i8 2, i8 0, [1 x [3 x i64]] [[3 x i64] [i64 1, i64 0, i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64)]] }, ptr @_QFEarr, align 8, !tbaa !8
  ret void
}
*** IR Dump After LowerExpectIntrinsicPass on _QQmain..omp_par ***
; Function Attrs: norecurse nounwind
define internal void @_QQmain..omp_par(ptr noalias %tid.addr, ptr noalias %zero.addr, ptr %0) #2 {
omp.par.entry:
  %gep_ = getelementptr { ptr, ptr }, ptr %0, i32 0, i32 0
  %loadgep_ = load ptr, ptr %gep_, align 8
  %gep_1 = getelementptr { ptr, ptr }, ptr %0, i32 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %tid.addr.local = alloca i32, align 4
  %1 = load i32, ptr %tid.addr, align 4
  store i32 %1, ptr %tid.addr.local, align 4
  %tid = load i32, ptr %tid.addr.local, align 4
  %p.lastiter = alloca i32, align 4
  %p.lowerbound = alloca i32, align 4
  %p.upperbound = alloca i32, align 4
  %p.stride = alloca i32, align 4
  br label %omp.par.region

omp.par.region:                                   ; preds = %omp.par.entry
  br label %omp.par.region1

omp.par.region1:                                  ; preds = %omp.par.region
  %2 = alloca i32, i64 1, align 4
  %3 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %4 = select i1 false, i32 %3, i32 1
  %5 = select i1 false, i32 1, i32 %3
  %6 = sub nsw i32 %5, %4
  %7 = icmp slt i32 %5, %4
  %8 = udiv i32 %6, 1
  %9 = add i32 %8, 1
  %omp_loop.tripcount = select i1 %7, i32 0, i32 %9
  br label %omp_loop.preheader

omp_loop.preheader:                               ; preds = %omp.par.region1
  store i32 0, ptr %p.lowerbound, align 4
  %10 = sub i32 %omp_loop.tripcount, 1
  store i32 %10, ptr %p.upperbound, align 4
  store i32 1, ptr %p.stride, align 4
  %omp_global_thread_num3 = call i32 @__kmpc_global_thread_num(ptr @1)
  call void @__kmpc_for_static_init_4u(ptr @1, i32 %omp_global_thread_num3, i32 34, ptr %p.lastiter, ptr %p.lowerbound, ptr %p.upperbound, ptr %p.stride, i32 1, i32 0)
  %11 = load i32, ptr %p.lowerbound, align 4
  %12 = load i32, ptr %p.upperbound, align 4
  %13 = sub i32 %12, %11
  %14 = add i32 %13, 1
  br label %omp_loop.header

omp_loop.header:                                  ; preds = %omp_loop.inc, %omp_loop.preheader
  %omp_loop.iv = phi i32 [ 0, %omp_loop.preheader ], [ %omp_loop.next, %omp_loop.inc ]
  br label %omp_loop.cond

omp_loop.cond:                                    ; preds = %omp_loop.header
  %omp_loop.cmp = icmp ult i32 %omp_loop.iv, %14
  br i1 %omp_loop.cmp, label %omp_loop.body, label %omp_loop.exit

omp_loop.exit:                                    ; preds = %omp_loop.cond
  call void @__kmpc_for_static_fini(ptr @1, i32 %omp_global_thread_num3)
  %omp_global_thread_num4 = call i32 @__kmpc_global_thread_num(ptr @1)
  call void @__kmpc_barrier(ptr @2, i32 %omp_global_thread_num4)
  br label %omp_loop.after

omp_loop.after:                                   ; preds = %omp_loop.exit
  br label %omp.region.cont

omp.region.cont:                                  ; preds = %omp_loop.after
  br label %omp.par.pre_finalize

omp.par.pre_finalize:                             ; preds = %omp.region.cont
  br label %omp.par.outlined.exit.exitStub

omp_loop.body:                                    ; preds = %omp_loop.cond
  %15 = add i32 %omp_loop.iv, %11
  %16 = mul i32 %15, 1
  %17 = add i32 %16, 1
  br label %omp.wsloop.region

omp.wsloop.region:                                ; preds = %omp_loop.body
  store i32 %17, ptr %2, align 4, !tbaa !4
  %18 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %19 = sitofp i32 %18 to float
  %20 = fdiv contract float 1.000000e+00, %19
  %21 = fpext float %20 to double
  %22 = load { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, align 8, !tbaa !8
  store { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %22, ptr %loadgep_2, align 8, !tbaa !8
  %23 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i32 0, i32 7, i64 0, i32 0
  %24 = load i64, ptr %23, align 8, !tbaa !8
  %25 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i32 0, i32 7, i64 0, i32 1
  %26 = load i64, ptr %25, align 8, !tbaa !8
  %27 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i32 0, i32 7, i64 0, i32 2
  %28 = load i64, ptr %27, align 8, !tbaa !8
  %29 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i32 0, i32 0
  %30 = load ptr, ptr %29, align 8, !tbaa !8
  %31 = load i32, ptr %2, align 4, !tbaa !4
  %32 = sext i32 %31 to i64
  %33 = sub i64 %32, %24
  %34 = getelementptr double, ptr %30, i64 %33
  store double %21, ptr %34, align 8, !tbaa !4
  br label %omp.region.cont2

omp.region.cont2:                                 ; preds = %omp.wsloop.region
  br label %omp_loop.inc

omp_loop.inc:                                     ; preds = %omp.region.cont2
  %omp_loop.next = add nuw i32 %omp_loop.iv, 1
  br label %omp_loop.header

omp.par.outlined.exit.exitStub:                   ; preds = %omp.par.pre_finalize
  ret void
}
*** IR Dump After SimplifyCFGPass on _QQmain..omp_par ***
; Function Attrs: norecurse nounwind
define internal void @_QQmain..omp_par(ptr noalias %tid.addr, ptr noalias %zero.addr, ptr %0) #2 {
omp.par.entry:
  %gep_ = getelementptr { ptr, ptr }, ptr %0, i32 0, i32 0
  %loadgep_ = load ptr, ptr %gep_, align 8
  %gep_1 = getelementptr { ptr, ptr }, ptr %0, i32 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %tid.addr.local = alloca i32, align 4
  %1 = load i32, ptr %tid.addr, align 4
  store i32 %1, ptr %tid.addr.local, align 4
  %tid = load i32, ptr %tid.addr.local, align 4
  %p.lastiter = alloca i32, align 4
  %p.lowerbound = alloca i32, align 4
  %p.upperbound = alloca i32, align 4
  %p.stride = alloca i32, align 4
  %2 = alloca i32, i64 1, align 4
  %3 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %4 = select i1 false, i32 %3, i32 1
  %5 = select i1 false, i32 1, i32 %3
  %6 = sub nsw i32 %5, %4
  %7 = icmp slt i32 %5, %4
  %8 = udiv i32 %6, 1
  %9 = add i32 %8, 1
  %omp_loop.tripcount = select i1 %7, i32 0, i32 %9
  store i32 0, ptr %p.lowerbound, align 4
  %10 = sub i32 %omp_loop.tripcount, 1
  store i32 %10, ptr %p.upperbound, align 4
  store i32 1, ptr %p.stride, align 4
  %omp_global_thread_num3 = call i32 @__kmpc_global_thread_num(ptr @1)
  call void @__kmpc_for_static_init_4u(ptr @1, i32 %omp_global_thread_num3, i32 34, ptr %p.lastiter, ptr %p.lowerbound, ptr %p.upperbound, ptr %p.stride, i32 1, i32 0)
  %11 = load i32, ptr %p.lowerbound, align 4
  %12 = load i32, ptr %p.upperbound, align 4
  %13 = sub i32 %12, %11
  %14 = add i32 %13, 1
  br label %omp_loop.header

omp_loop.header:                                  ; preds = %omp_loop.body, %omp.par.entry
  %omp_loop.iv = phi i32 [ 0, %omp.par.entry ], [ %omp_loop.next, %omp_loop.body ]
  %omp_loop.cmp = icmp ult i32 %omp_loop.iv, %14
  br i1 %omp_loop.cmp, label %omp_loop.body, label %omp_loop.exit

omp_loop.exit:                                    ; preds = %omp_loop.header
  call void @__kmpc_for_static_fini(ptr @1, i32 %omp_global_thread_num3)
  %omp_global_thread_num4 = call i32 @__kmpc_global_thread_num(ptr @1)
  call void @__kmpc_barrier(ptr @2, i32 %omp_global_thread_num4)
  ret void

omp_loop.body:                                    ; preds = %omp_loop.header
  %15 = add i32 %omp_loop.iv, %11
  %16 = mul i32 %15, 1
  %17 = add i32 %16, 1
  store i32 %17, ptr %2, align 4, !tbaa !4
  %18 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %19 = sitofp i32 %18 to float
  %20 = fdiv contract float 1.000000e+00, %19
  %21 = fpext float %20 to double
  %22 = load { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, align 8, !tbaa !8
  store { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %22, ptr %loadgep_2, align 8, !tbaa !8
  %23 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i32 0, i32 7, i64 0, i32 0
  %24 = load i64, ptr %23, align 8, !tbaa !8
  %25 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i32 0, i32 7, i64 0, i32 1
  %26 = load i64, ptr %25, align 8, !tbaa !8
  %27 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i32 0, i32 7, i64 0, i32 2
  %28 = load i64, ptr %27, align 8, !tbaa !8
  %29 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i32 0, i32 0
  %30 = load ptr, ptr %29, align 8, !tbaa !8
  %31 = load i32, ptr %2, align 4, !tbaa !4
  %32 = sext i32 %31 to i64
  %33 = sub i64 %32, %24
  %34 = getelementptr double, ptr %30, i64 %33
  store double %21, ptr %34, align 8, !tbaa !4
  %omp_loop.next = add nuw i32 %omp_loop.iv, 1
  br label %omp_loop.header
}
*** IR Dump After SROAPass on _QQmain..omp_par ***
; Function Attrs: norecurse nounwind
define internal void @_QQmain..omp_par(ptr noalias %tid.addr, ptr noalias %zero.addr, ptr %0) #2 {
omp.par.entry:
  %gep_ = getelementptr { ptr, ptr }, ptr %0, i32 0, i32 0
  %loadgep_ = load ptr, ptr %gep_, align 8
  %gep_1 = getelementptr { ptr, ptr }, ptr %0, i32 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %1 = load i32, ptr %tid.addr, align 4
  %p.lastiter = alloca i32, align 4
  %p.lowerbound = alloca i32, align 4
  %p.upperbound = alloca i32, align 4
  %p.stride = alloca i32, align 4
  %2 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %3 = select i1 false, i32 %2, i32 1
  %4 = select i1 false, i32 1, i32 %2
  %5 = sub nsw i32 %4, %3
  %6 = icmp slt i32 %4, %3
  %7 = udiv i32 %5, 1
  %8 = add i32 %7, 1
  %omp_loop.tripcount = select i1 %6, i32 0, i32 %8
  store i32 0, ptr %p.lowerbound, align 4
  %9 = sub i32 %omp_loop.tripcount, 1
  store i32 %9, ptr %p.upperbound, align 4
  store i32 1, ptr %p.stride, align 4
  %omp_global_thread_num3 = call i32 @__kmpc_global_thread_num(ptr @1)
  call void @__kmpc_for_static_init_4u(ptr @1, i32 %omp_global_thread_num3, i32 34, ptr %p.lastiter, ptr %p.lowerbound, ptr %p.upperbound, ptr %p.stride, i32 1, i32 0)
  %10 = load i32, ptr %p.lowerbound, align 4
  %11 = load i32, ptr %p.upperbound, align 4
  %12 = sub i32 %11, %10
  %13 = add i32 %12, 1
  br label %omp_loop.header

omp_loop.header:                                  ; preds = %omp_loop.body, %omp.par.entry
  %omp_loop.iv = phi i32 [ 0, %omp.par.entry ], [ %omp_loop.next, %omp_loop.body ]
  %omp_loop.cmp = icmp ult i32 %omp_loop.iv, %13
  br i1 %omp_loop.cmp, label %omp_loop.body, label %omp_loop.exit

omp_loop.exit:                                    ; preds = %omp_loop.header
  call void @__kmpc_for_static_fini(ptr @1, i32 %omp_global_thread_num3)
  %omp_global_thread_num4 = call i32 @__kmpc_global_thread_num(ptr @1)
  call void @__kmpc_barrier(ptr @2, i32 %omp_global_thread_num4)
  ret void

omp_loop.body:                                    ; preds = %omp_loop.header
  %14 = add i32 %omp_loop.iv, %10
  %15 = mul i32 %14, 1
  %16 = add i32 %15, 1
  %17 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %18 = sitofp i32 %17 to float
  %19 = fdiv contract float 1.000000e+00, %18
  %20 = fpext float %19 to double
  %21 = load { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, align 8, !tbaa !8
  store { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %21, ptr %loadgep_2, align 8, !tbaa !8
  %22 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i32 0, i32 7, i64 0, i32 0
  %23 = load i64, ptr %22, align 8, !tbaa !8
  %24 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i32 0, i32 7, i64 0, i32 1
  %25 = load i64, ptr %24, align 8, !tbaa !8
  %26 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i32 0, i32 7, i64 0, i32 2
  %27 = load i64, ptr %26, align 8, !tbaa !8
  %28 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i32 0, i32 0
  %29 = load ptr, ptr %28, align 8, !tbaa !8
  %30 = sext i32 %16 to i64
  %31 = sub i64 %30, %23
  %32 = getelementptr double, ptr %29, i64 %31
  store double %20, ptr %32, align 8, !tbaa !4
  %omp_loop.next = add nuw i32 %omp_loop.iv, 1
  br label %omp_loop.header
}
*** IR Dump After EarlyCSEPass on _QQmain..omp_par ***
; Function Attrs: norecurse nounwind
define internal void @_QQmain..omp_par(ptr noalias %tid.addr, ptr noalias %zero.addr, ptr %0) #2 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr }, ptr %0, i32 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %p.lastiter = alloca i32, align 4
  %p.lowerbound = alloca i32, align 4
  %p.upperbound = alloca i32, align 4
  %p.stride = alloca i32, align 4
  %1 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %2 = sub nsw i32 %1, 1
  %3 = icmp slt i32 %1, 1
  %omp_loop.tripcount = select i1 %3, i32 0, i32 %1
  store i32 0, ptr %p.lowerbound, align 4
  %4 = sub i32 %omp_loop.tripcount, 1
  store i32 %4, ptr %p.upperbound, align 4
  store i32 1, ptr %p.stride, align 4
  %omp_global_thread_num3 = call i32 @__kmpc_global_thread_num(ptr @1)
  call void @__kmpc_for_static_init_4u(ptr @1, i32 %omp_global_thread_num3, i32 34, ptr %p.lastiter, ptr %p.lowerbound, ptr %p.upperbound, ptr %p.stride, i32 1, i32 0)
  %5 = load i32, ptr %p.lowerbound, align 4
  %6 = load i32, ptr %p.upperbound, align 4
  %7 = sub i32 %6, %5
  %8 = add i32 %7, 1
  br label %omp_loop.header

omp_loop.header:                                  ; preds = %omp_loop.body, %omp.par.entry
  %omp_loop.iv = phi i32 [ 0, %omp.par.entry ], [ %omp_loop.next, %omp_loop.body ]
  %omp_loop.cmp = icmp ult i32 %omp_loop.iv, %8
  br i1 %omp_loop.cmp, label %omp_loop.body, label %omp_loop.exit

omp_loop.exit:                                    ; preds = %omp_loop.header
  call void @__kmpc_for_static_fini(ptr @1, i32 %omp_global_thread_num3)
  %omp_global_thread_num4 = call i32 @__kmpc_global_thread_num(ptr @1)
  call void @__kmpc_barrier(ptr @2, i32 %omp_global_thread_num4)
  ret void

omp_loop.body:                                    ; preds = %omp_loop.header
  %9 = add i32 %omp_loop.iv, %5
  %10 = add i32 %9, 1
  %11 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %12 = sitofp i32 %11 to float
  %13 = fdiv contract float 1.000000e+00, %12
  %14 = fpext float %13 to double
  %15 = load { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, align 8, !tbaa !8
  store { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %15, ptr %loadgep_2, align 8, !tbaa !8
  %16 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i32 0, i32 7, i64 0, i32 0
  %17 = load i64, ptr %16, align 8, !tbaa !8
  %18 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i32 0, i32 7, i64 0, i32 1
  %19 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i32 0, i32 7, i64 0, i32 2
  %20 = load ptr, ptr %loadgep_2, align 8, !tbaa !8
  %21 = sext i32 %10 to i64
  %22 = sub i64 %21, %17
  %23 = getelementptr double, ptr %20, i64 %22
  store double %14, ptr %23, align 8, !tbaa !4
  %omp_loop.next = add nuw i32 %omp_loop.iv, 1
  br label %omp_loop.header
}
*** IR Dump After CallSiteSplittingPass on _QQmain..omp_par ***
; Function Attrs: norecurse nounwind
define internal void @_QQmain..omp_par(ptr noalias %tid.addr, ptr noalias %zero.addr, ptr %0) #2 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr }, ptr %0, i32 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %p.lastiter = alloca i32, align 4
  %p.lowerbound = alloca i32, align 4
  %p.upperbound = alloca i32, align 4
  %p.stride = alloca i32, align 4
  %1 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %2 = sub nsw i32 %1, 1
  %3 = icmp slt i32 %1, 1
  %omp_loop.tripcount = select i1 %3, i32 0, i32 %1
  store i32 0, ptr %p.lowerbound, align 4
  %4 = sub i32 %omp_loop.tripcount, 1
  store i32 %4, ptr %p.upperbound, align 4
  store i32 1, ptr %p.stride, align 4
  %omp_global_thread_num3 = call i32 @__kmpc_global_thread_num(ptr @1)
  call void @__kmpc_for_static_init_4u(ptr @1, i32 %omp_global_thread_num3, i32 34, ptr %p.lastiter, ptr %p.lowerbound, ptr %p.upperbound, ptr %p.stride, i32 1, i32 0)
  %5 = load i32, ptr %p.lowerbound, align 4
  %6 = load i32, ptr %p.upperbound, align 4
  %7 = sub i32 %6, %5
  %8 = add i32 %7, 1
  br label %omp_loop.header

omp_loop.header:                                  ; preds = %omp_loop.body, %omp.par.entry
  %omp_loop.iv = phi i32 [ 0, %omp.par.entry ], [ %omp_loop.next, %omp_loop.body ]
  %omp_loop.cmp = icmp ult i32 %omp_loop.iv, %8
  br i1 %omp_loop.cmp, label %omp_loop.body, label %omp_loop.exit

omp_loop.exit:                                    ; preds = %omp_loop.header
  call void @__kmpc_for_static_fini(ptr @1, i32 %omp_global_thread_num3)
  %omp_global_thread_num4 = call i32 @__kmpc_global_thread_num(ptr @1)
  call void @__kmpc_barrier(ptr @2, i32 %omp_global_thread_num4)
  ret void

omp_loop.body:                                    ; preds = %omp_loop.header
  %9 = add i32 %omp_loop.iv, %5
  %10 = add i32 %9, 1
  %11 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %12 = sitofp i32 %11 to float
  %13 = fdiv contract float 1.000000e+00, %12
  %14 = fpext float %13 to double
  %15 = load { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, align 8, !tbaa !8
  store { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %15, ptr %loadgep_2, align 8, !tbaa !8
  %16 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i32 0, i32 7, i64 0, i32 0
  %17 = load i64, ptr %16, align 8, !tbaa !8
  %18 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i32 0, i32 7, i64 0, i32 1
  %19 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i32 0, i32 7, i64 0, i32 2
  %20 = load ptr, ptr %loadgep_2, align 8, !tbaa !8
  %21 = sext i32 %10 to i64
  %22 = sub i64 %21, %17
  %23 = getelementptr double, ptr %20, i64 %22
  store double %14, ptr %23, align 8, !tbaa !4
  %omp_loop.next = add nuw i32 %omp_loop.iv, 1
  br label %omp_loop.header
}
*** IR Dump After OpenMPOptPass on [module] ***
; ModuleID = 'FIRModule'
source_filename = "FIRModule"
target datalayout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128"
target triple = "x86_64-unknown-linux-gnu"

%struct.ident_t = type { i32, i32, i32, i32, ptr }

@_QFEarr = internal global { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } { ptr null, i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), i32 20180515, i8 1, i8 28, i8 2, i8 0, [1 x [3 x i64]] [[3 x i64] [i64 1, i64 0, i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64)]] }
@_QQcl.68815510185ede6107d6524e77abf791 = internal constant [52 x i8] c"/g/g92/rydahl1/flangtests/src/array_descriptors.f90\00"
@_QQcl.28612C69372C612C6531332E36653229 = internal constant [16 x i8] c"(a,i7,a,e13.6e2)"
@_QQcl.54686520726573756C74206F6620286172722831292B61727228 = internal constant [26 x i8] c"The result of (arr(1)+arr("
@_QQcl.2920697320 = internal constant [5 x i8] c") is "
@_QQEnvironmentDefaults = constant ptr null
@0 = private unnamed_addr constant [23 x i8] c";unknown;unknown;0;0;;\00", align 1
@1 = private unnamed_addr constant %struct.ident_t { i32 0, i32 2, i32 0, i32 22, ptr @0 }, align 8
@2 = private unnamed_addr constant %struct.ident_t { i32 0, i32 66, i32 0, i32 22, ptr @0 }, align 8

; Function Attrs: mustprogress nofree nounwind willreturn allockind("alloc,uninitialized") allocsize(0) memory(inaccessiblemem: readwrite)
declare noalias noundef ptr @malloc(i64 noundef) #0

; Function Attrs: mustprogress nounwind willreturn allockind("free") memory(argmem: readwrite, inaccessiblemem: readwrite)
declare void @free(ptr allocptr nocapture noundef) #1

define void @_QQmain() {
entry:
  %structArg = alloca { ptr, ptr }, align 8
  %0 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %1 = alloca i32, i64 1, align 4
  store i32 1048576, ptr %1, align 4, !tbaa !4
  %2 = call ptr @malloc(i64 mul (i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), i64 1048576))
  %3 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } { ptr undef, i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), i32 20180515, i8 1, i8 28, i8 2, i8 0, [1 x [3 x i64]] [[3 x i64] [i64 1, i64 1048576, i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64)]] }, ptr %2, 0
  %.fca.1.extract = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %3, 1
  %.fca.2.extract = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %3, 2
  %.fca.3.extract = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %3, 3
  %.fca.4.extract = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %3, 4
  %.fca.5.extract = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %3, 5
  %.fca.6.extract = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %3, 6
  %.fca.7.0.0.extract = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %3, 7, 0, 0
  %.fca.7.0.1.extract = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %3, 7, 0, 1
  %.fca.7.0.2.extract = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %3, 7, 0, 2
  %.fca.0.insert = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } poison, ptr %2, 0
  %.fca.1.insert = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.0.insert, i64 %.fca.1.extract, 1
  %.fca.2.insert = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.1.insert, i32 %.fca.2.extract, 2
  %.fca.3.insert = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.2.insert, i8 %.fca.3.extract, 3
  %.fca.4.insert = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.3.insert, i8 %.fca.4.extract, 4
  %.fca.5.insert = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.4.insert, i8 %.fca.5.extract, 5
  %.fca.6.insert = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.5.insert, i8 %.fca.6.extract, 6
  %.fca.7.0.0.insert = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.6.insert, i64 %.fca.7.0.0.extract, 7, 0, 0
  %.fca.7.0.1.insert = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.7.0.0.insert, i64 %.fca.7.0.1.extract, 7, 0, 1
  %.fca.7.0.2.insert = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.7.0.1.insert, i64 %.fca.7.0.2.extract, 7, 0, 2
  store { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.7.0.2.insert, ptr @_QFEarr, align 8, !tbaa !8
  %omp_global_thread_num = call i32 @__kmpc_global_thread_num(ptr @1)
  store ptr %1, ptr %structArg, align 8
  %gep_5 = getelementptr { ptr, ptr }, ptr %structArg, i32 0, i32 1
  store ptr %0, ptr %gep_5, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr @1, i32 1, ptr @_QQmain..omp_par, ptr %structArg)
  %4 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr @_QQcl.68815510185ede6107d6524e77abf791, i32 19)
  %5 = call i1 @_FortranAioOutputAscii(ptr %4, ptr @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %6 = load i32, ptr %1, align 4, !tbaa !4
  %7 = call i1 @_FortranAioOutputInteger32(ptr %4, i32 %6)
  %8 = call i1 @_FortranAioOutputAscii(ptr %4, ptr @_QQcl.2920697320, i64 5)
  %9 = load { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, align 8, !tbaa !8
  %.fca.0.extract16 = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %9, 0
  %.fca.7.0.0.extract23 = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %9, 7, 0, 0
  %10 = sub i64 1, %.fca.7.0.0.extract23
  %11 = getelementptr double, ptr %.fca.0.extract16, i64 %10
  %12 = load double, ptr %11, align 8, !tbaa !4
  %13 = load i32, ptr %1, align 4, !tbaa !4
  %14 = sext i32 %13 to i64
  %15 = sub i64 %14, %.fca.7.0.0.extract23
  %16 = getelementptr double, ptr %.fca.0.extract16, i64 %15
  %17 = load double, ptr %16, align 8, !tbaa !4
  %18 = fadd contract double %12, %17
  %19 = call i1 @_FortranAioOutputReal64(ptr %4, double %18)
  %20 = call i32 @_FortranAioEndIoStatement(ptr %4)
  %21 = load { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, align 8, !tbaa !8
  %.fca.0.extract33 = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %21, 0
  call void @free(ptr %.fca.0.extract33)
  store { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } { ptr null, i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), i32 20180515, i8 1, i8 28, i8 2, i8 0, [1 x [3 x i64]] [[3 x i64] [i64 1, i64 0, i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64)]] }, ptr @_QFEarr, align 8, !tbaa !8
  ret void
}

; Function Attrs: norecurse nounwind
define internal void @_QQmain..omp_par(ptr noalias %tid.addr, ptr noalias %zero.addr, ptr %0) #2 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr }, ptr %0, i32 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %p.lastiter = alloca i32, align 4
  %p.lowerbound = alloca i32, align 4
  %p.upperbound = alloca i32, align 4
  %p.stride = alloca i32, align 4
  %1 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %2 = sub nsw i32 %1, 1
  %3 = icmp slt i32 %1, 1
  %omp_loop.tripcount = select i1 %3, i32 0, i32 %1
  store i32 0, ptr %p.lowerbound, align 4
  %4 = sub i32 %omp_loop.tripcount, 1
  store i32 %4, ptr %p.upperbound, align 4
  store i32 1, ptr %p.stride, align 4
  %omp_global_thread_num3 = call i32 @__kmpc_global_thread_num(ptr @1)
  call void @__kmpc_for_static_init_4u(ptr @1, i32 %omp_global_thread_num3, i32 34, ptr %p.lastiter, ptr %p.lowerbound, ptr %p.upperbound, ptr %p.stride, i32 1, i32 0)
  %5 = load i32, ptr %p.lowerbound, align 4
  %6 = load i32, ptr %p.upperbound, align 4
  %7 = sub i32 %6, %5
  %8 = add i32 %7, 1
  br label %omp_loop.header

omp_loop.header:                                  ; preds = %omp_loop.body, %omp.par.entry
  %omp_loop.iv = phi i32 [ 0, %omp.par.entry ], [ %omp_loop.next, %omp_loop.body ]
  %omp_loop.cmp = icmp ult i32 %omp_loop.iv, %8
  br i1 %omp_loop.cmp, label %omp_loop.body, label %omp_loop.exit

omp_loop.exit:                                    ; preds = %omp_loop.header
  call void @__kmpc_for_static_fini(ptr @1, i32 %omp_global_thread_num3)
  %omp_global_thread_num4 = call i32 @__kmpc_global_thread_num(ptr @1)
  call void @__kmpc_barrier(ptr @2, i32 %omp_global_thread_num4)
  ret void

omp_loop.body:                                    ; preds = %omp_loop.header
  %9 = add i32 %omp_loop.iv, %5
  %10 = add i32 %9, 1
  %11 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %12 = sitofp i32 %11 to float
  %13 = fdiv contract float 1.000000e+00, %12
  %14 = fpext float %13 to double
  %15 = load { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, align 8, !tbaa !8
  store { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %15, ptr %loadgep_2, align 8, !tbaa !8
  %16 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i32 0, i32 7, i64 0, i32 0
  %17 = load i64, ptr %16, align 8, !tbaa !8
  %18 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i32 0, i32 7, i64 0, i32 1
  %19 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i32 0, i32 7, i64 0, i32 2
  %20 = load ptr, ptr %loadgep_2, align 8, !tbaa !8
  %21 = sext i32 %10 to i64
  %22 = sub i64 %21, %17
  %23 = getelementptr double, ptr %20, i64 %22
  store double %14, ptr %23, align 8, !tbaa !4
  %omp_loop.next = add nuw i32 %omp_loop.iv, 1
  br label %omp_loop.header
}

declare ptr @_FortranAioBeginExternalFormattedOutput(ptr, i64, ptr, i32, ptr, i32)

declare zeroext i1 @_FortranAioOutputAscii(ptr, ptr, i64)

declare zeroext i1 @_FortranAioOutputInteger32(ptr, i32)

declare zeroext i1 @_FortranAioOutputReal64(ptr, double)

declare i32 @_FortranAioEndIoStatement(ptr)

; Function Attrs: mustprogress nocallback nofree nosync nounwind willreturn
declare ptr @llvm.stacksave() #3

; Function Attrs: mustprogress nocallback nofree nosync nounwind willreturn
declare void @llvm.stackrestore(ptr) #3

; Function Attrs: nounwind
declare i32 @__kmpc_global_thread_num(ptr) #4

; Function Attrs: nounwind
declare void @__kmpc_for_static_init_4u(ptr, i32, i32, ptr, ptr, ptr, ptr, i32, i32) #4

; Function Attrs: nounwind
declare void @__kmpc_for_static_fini(ptr, i32) #4

; Function Attrs: convergent nounwind
declare void @__kmpc_barrier(ptr, i32) #5

; Function Attrs: nounwind
declare !callback !10 void @__kmpc_fork_call(ptr, i32, ptr, ...) #4

attributes #0 = { mustprogress nofree nounwind willreturn allockind("alloc,uninitialized") allocsize(0) memory(inaccessiblemem: readwrite) "alloc-family"="malloc" }
attributes #1 = { mustprogress nounwind willreturn allockind("free") memory(argmem: readwrite, inaccessiblemem: readwrite) "alloc-family"="malloc" }
attributes #2 = { norecurse nounwind }
attributes #3 = { mustprogress nocallback nofree nosync nounwind willreturn }
attributes #4 = { nounwind }
attributes #5 = { convergent nounwind }

!llvm.module.flags = !{!0, !1, !2, !3}

!0 = !{i32 2, !"Debug Info Version", i32 3}
!1 = !{i32 7, !"openmp", i32 11}
!2 = !{i32 8, !"PIC Level", i32 2}
!3 = !{i32 7, !"PIE Level", i32 2}
!4 = !{!5, !5, i64 0}
!5 = !{!"any data access", !6, i64 0}
!6 = !{!"any access", !7, i64 0}
!7 = !{!"Flang Type TBAA Root"}
!8 = !{!9, !9, i64 0}
!9 = !{!"descriptor member", !6, i64 0}
!10 = !{!11}
!11 = !{i64 2, i64 -1, i64 -1, i1 true}
*** IR Dump After IPSCCPPass on [module] ***
; ModuleID = 'FIRModule'
source_filename = "FIRModule"
target datalayout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128"
target triple = "x86_64-unknown-linux-gnu"

%struct.ident_t = type { i32, i32, i32, i32, ptr }

@_QFEarr = internal global { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } { ptr null, i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), i32 20180515, i8 1, i8 28, i8 2, i8 0, [1 x [3 x i64]] [[3 x i64] [i64 1, i64 0, i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64)]] }
@_QQcl.68815510185ede6107d6524e77abf791 = internal constant [52 x i8] c"/g/g92/rydahl1/flangtests/src/array_descriptors.f90\00"
@_QQcl.28612C69372C612C6531332E36653229 = internal constant [16 x i8] c"(a,i7,a,e13.6e2)"
@_QQcl.54686520726573756C74206F6620286172722831292B61727228 = internal constant [26 x i8] c"The result of (arr(1)+arr("
@_QQcl.2920697320 = internal constant [5 x i8] c") is "
@_QQEnvironmentDefaults = constant ptr null
@0 = private unnamed_addr constant [23 x i8] c";unknown;unknown;0;0;;\00", align 1
@1 = private unnamed_addr constant %struct.ident_t { i32 0, i32 2, i32 0, i32 22, ptr @0 }, align 8
@2 = private unnamed_addr constant %struct.ident_t { i32 0, i32 66, i32 0, i32 22, ptr @0 }, align 8

; Function Attrs: mustprogress nofree nounwind willreturn allockind("alloc,uninitialized") allocsize(0) memory(inaccessiblemem: readwrite)
declare noalias noundef ptr @malloc(i64 noundef) #0

; Function Attrs: mustprogress nounwind willreturn allockind("free") memory(argmem: readwrite, inaccessiblemem: readwrite)
declare void @free(ptr allocptr nocapture noundef) #1

define void @_QQmain() {
entry:
  %structArg = alloca { ptr, ptr }, align 8
  %0 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %1 = alloca i32, i64 1, align 4
  store i32 1048576, ptr %1, align 4, !tbaa !4
  %2 = call ptr @malloc(i64 mul (i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), i64 1048576))
  %3 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } { ptr undef, i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), i32 20180515, i8 1, i8 28, i8 2, i8 0, [1 x [3 x i64]] [[3 x i64] [i64 1, i64 1048576, i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64)]] }, ptr %2, 0
  %.fca.7.0.0.extract = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %3, 7, 0, 0
  %.fca.7.0.1.extract = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %3, 7, 0, 1
  %.fca.7.0.2.extract = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %3, 7, 0, 2
  %.fca.0.insert = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } poison, ptr %2, 0
  %.fca.1.insert = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.0.insert, i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), 1
  %.fca.2.insert = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.1.insert, i32 20180515, 2
  %.fca.3.insert = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.2.insert, i8 1, 3
  %.fca.4.insert = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.3.insert, i8 28, 4
  %.fca.5.insert = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.4.insert, i8 2, 5
  %.fca.6.insert = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.5.insert, i8 0, 6
  %.fca.7.0.0.insert = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.6.insert, i64 %.fca.7.0.0.extract, 7, 0, 0
  %.fca.7.0.1.insert = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.7.0.0.insert, i64 %.fca.7.0.1.extract, 7, 0, 1
  %.fca.7.0.2.insert = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.7.0.1.insert, i64 %.fca.7.0.2.extract, 7, 0, 2
  store { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.7.0.2.insert, ptr @_QFEarr, align 8, !tbaa !8
  %omp_global_thread_num = call i32 @__kmpc_global_thread_num(ptr @1)
  store ptr %1, ptr %structArg, align 8
  %gep_5 = getelementptr { ptr, ptr }, ptr %structArg, i32 0, i32 1
  store ptr %0, ptr %gep_5, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr @1, i32 1, ptr @_QQmain..omp_par, ptr %structArg)
  %4 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr @_QQcl.68815510185ede6107d6524e77abf791, i32 19)
  %5 = call i1 @_FortranAioOutputAscii(ptr %4, ptr @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %6 = load i32, ptr %1, align 4, !tbaa !4
  %7 = call i1 @_FortranAioOutputInteger32(ptr %4, i32 %6)
  %8 = call i1 @_FortranAioOutputAscii(ptr %4, ptr @_QQcl.2920697320, i64 5)
  %9 = load { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, align 8, !tbaa !8
  %.fca.0.extract16 = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %9, 0
  %.fca.7.0.0.extract23 = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %9, 7, 0, 0
  %10 = sub i64 1, %.fca.7.0.0.extract23
  %11 = getelementptr double, ptr %.fca.0.extract16, i64 %10
  %12 = load double, ptr %11, align 8, !tbaa !4
  %13 = load i32, ptr %1, align 4, !tbaa !4
  %14 = sext i32 %13 to i64
  %15 = sub i64 %14, %.fca.7.0.0.extract23
  %16 = getelementptr double, ptr %.fca.0.extract16, i64 %15
  %17 = load double, ptr %16, align 8, !tbaa !4
  %18 = fadd contract double %12, %17
  %19 = call i1 @_FortranAioOutputReal64(ptr %4, double %18)
  %20 = call i32 @_FortranAioEndIoStatement(ptr %4)
  %21 = load { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, align 8, !tbaa !8
  %.fca.0.extract33 = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %21, 0
  call void @free(ptr %.fca.0.extract33)
  store { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } { ptr null, i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), i32 20180515, i8 1, i8 28, i8 2, i8 0, [1 x [3 x i64]] [[3 x i64] [i64 1, i64 0, i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64)]] }, ptr @_QFEarr, align 8, !tbaa !8
  ret void
}

; Function Attrs: norecurse nounwind
define internal void @_QQmain..omp_par(ptr noalias %tid.addr, ptr noalias %zero.addr, ptr %0) #2 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr }, ptr %0, i32 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %p.lastiter = alloca i32, align 4
  %p.lowerbound = alloca i32, align 4
  %p.upperbound = alloca i32, align 4
  %p.stride = alloca i32, align 4
  %1 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %2 = sub nsw i32 %1, 1
  %3 = icmp slt i32 %1, 1
  %omp_loop.tripcount = select i1 %3, i32 0, i32 %1
  store i32 0, ptr %p.lowerbound, align 4
  %4 = sub i32 %omp_loop.tripcount, 1
  store i32 %4, ptr %p.upperbound, align 4
  store i32 1, ptr %p.stride, align 4
  %omp_global_thread_num3 = call i32 @__kmpc_global_thread_num(ptr @1)
  call void @__kmpc_for_static_init_4u(ptr @1, i32 %omp_global_thread_num3, i32 34, ptr %p.lastiter, ptr %p.lowerbound, ptr %p.upperbound, ptr %p.stride, i32 1, i32 0)
  %5 = load i32, ptr %p.lowerbound, align 4
  %6 = load i32, ptr %p.upperbound, align 4
  %7 = sub i32 %6, %5
  %8 = add i32 %7, 1
  br label %omp_loop.header

omp_loop.header:                                  ; preds = %omp_loop.body, %omp.par.entry
  %omp_loop.iv = phi i32 [ 0, %omp.par.entry ], [ %omp_loop.next, %omp_loop.body ]
  %omp_loop.cmp = icmp ult i32 %omp_loop.iv, %8
  br i1 %omp_loop.cmp, label %omp_loop.body, label %omp_loop.exit

omp_loop.exit:                                    ; preds = %omp_loop.header
  call void @__kmpc_for_static_fini(ptr @1, i32 %omp_global_thread_num3)
  %omp_global_thread_num4 = call i32 @__kmpc_global_thread_num(ptr @1)
  call void @__kmpc_barrier(ptr @2, i32 %omp_global_thread_num4)
  ret void

omp_loop.body:                                    ; preds = %omp_loop.header
  %9 = add i32 %omp_loop.iv, %5
  %10 = add i32 %9, 1
  %11 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %12 = sitofp i32 %11 to float
  %13 = fdiv contract float 1.000000e+00, %12
  %14 = fpext float %13 to double
  %15 = load { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, align 8, !tbaa !8
  store { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %15, ptr %loadgep_2, align 8, !tbaa !8
  %16 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i32 0, i32 7, i64 0, i32 0
  %17 = load i64, ptr %16, align 8, !tbaa !8
  %18 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i32 0, i32 7, i64 0, i32 1
  %19 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i32 0, i32 7, i64 0, i32 2
  %20 = load ptr, ptr %loadgep_2, align 8, !tbaa !8
  %21 = sext i32 %10 to i64
  %22 = sub i64 %21, %17
  %23 = getelementptr double, ptr %20, i64 %22
  store double %14, ptr %23, align 8, !tbaa !4
  %omp_loop.next = add nuw i32 %omp_loop.iv, 1
  br label %omp_loop.header
}

declare ptr @_FortranAioBeginExternalFormattedOutput(ptr, i64, ptr, i32, ptr, i32)

declare zeroext i1 @_FortranAioOutputAscii(ptr, ptr, i64)

declare zeroext i1 @_FortranAioOutputInteger32(ptr, i32)

declare zeroext i1 @_FortranAioOutputReal64(ptr, double)

declare i32 @_FortranAioEndIoStatement(ptr)

; Function Attrs: mustprogress nocallback nofree nosync nounwind willreturn
declare ptr @llvm.stacksave() #3

; Function Attrs: mustprogress nocallback nofree nosync nounwind willreturn
declare void @llvm.stackrestore(ptr) #3

; Function Attrs: nounwind
declare i32 @__kmpc_global_thread_num(ptr) #4

; Function Attrs: nounwind
declare void @__kmpc_for_static_init_4u(ptr, i32, i32, ptr, ptr, ptr, ptr, i32, i32) #4

; Function Attrs: nounwind
declare void @__kmpc_for_static_fini(ptr, i32) #4

; Function Attrs: convergent nounwind
declare void @__kmpc_barrier(ptr, i32) #5

; Function Attrs: nounwind
declare !callback !10 void @__kmpc_fork_call(ptr, i32, ptr, ...) #4

attributes #0 = { mustprogress nofree nounwind willreturn allockind("alloc,uninitialized") allocsize(0) memory(inaccessiblemem: readwrite) "alloc-family"="malloc" }
attributes #1 = { mustprogress nounwind willreturn allockind("free") memory(argmem: readwrite, inaccessiblemem: readwrite) "alloc-family"="malloc" }
attributes #2 = { norecurse nounwind }
attributes #3 = { mustprogress nocallback nofree nosync nounwind willreturn }
attributes #4 = { nounwind }
attributes #5 = { convergent nounwind }

!llvm.module.flags = !{!0, !1, !2, !3}

!0 = !{i32 2, !"Debug Info Version", i32 3}
!1 = !{i32 7, !"openmp", i32 11}
!2 = !{i32 8, !"PIC Level", i32 2}
!3 = !{i32 7, !"PIE Level", i32 2}
!4 = !{!5, !5, i64 0}
!5 = !{!"any data access", !6, i64 0}
!6 = !{!"any access", !7, i64 0}
!7 = !{!"Flang Type TBAA Root"}
!8 = !{!9, !9, i64 0}
!9 = !{!"descriptor member", !6, i64 0}
!10 = !{!11}
!11 = !{i64 2, i64 -1, i64 -1, i1 true}
*** IR Dump After CalledValuePropagationPass on [module] ***
; ModuleID = 'FIRModule'
source_filename = "FIRModule"
target datalayout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128"
target triple = "x86_64-unknown-linux-gnu"

%struct.ident_t = type { i32, i32, i32, i32, ptr }

@_QFEarr = internal global { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } { ptr null, i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), i32 20180515, i8 1, i8 28, i8 2, i8 0, [1 x [3 x i64]] [[3 x i64] [i64 1, i64 0, i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64)]] }
@_QQcl.68815510185ede6107d6524e77abf791 = internal constant [52 x i8] c"/g/g92/rydahl1/flangtests/src/array_descriptors.f90\00"
@_QQcl.28612C69372C612C6531332E36653229 = internal constant [16 x i8] c"(a,i7,a,e13.6e2)"
@_QQcl.54686520726573756C74206F6620286172722831292B61727228 = internal constant [26 x i8] c"The result of (arr(1)+arr("
@_QQcl.2920697320 = internal constant [5 x i8] c") is "
@_QQEnvironmentDefaults = constant ptr null
@0 = private unnamed_addr constant [23 x i8] c";unknown;unknown;0;0;;\00", align 1
@1 = private unnamed_addr constant %struct.ident_t { i32 0, i32 2, i32 0, i32 22, ptr @0 }, align 8
@2 = private unnamed_addr constant %struct.ident_t { i32 0, i32 66, i32 0, i32 22, ptr @0 }, align 8

; Function Attrs: mustprogress nofree nounwind willreturn allockind("alloc,uninitialized") allocsize(0) memory(inaccessiblemem: readwrite)
declare noalias noundef ptr @malloc(i64 noundef) #0

; Function Attrs: mustprogress nounwind willreturn allockind("free") memory(argmem: readwrite, inaccessiblemem: readwrite)
declare void @free(ptr allocptr nocapture noundef) #1

define void @_QQmain() {
entry:
  %structArg = alloca { ptr, ptr }, align 8
  %0 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %1 = alloca i32, i64 1, align 4
  store i32 1048576, ptr %1, align 4, !tbaa !4
  %2 = call ptr @malloc(i64 mul (i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), i64 1048576))
  %3 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } { ptr undef, i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), i32 20180515, i8 1, i8 28, i8 2, i8 0, [1 x [3 x i64]] [[3 x i64] [i64 1, i64 1048576, i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64)]] }, ptr %2, 0
  %.fca.7.0.0.extract = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %3, 7, 0, 0
  %.fca.7.0.1.extract = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %3, 7, 0, 1
  %.fca.7.0.2.extract = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %3, 7, 0, 2
  %.fca.0.insert = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } poison, ptr %2, 0
  %.fca.1.insert = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.0.insert, i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), 1
  %.fca.2.insert = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.1.insert, i32 20180515, 2
  %.fca.3.insert = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.2.insert, i8 1, 3
  %.fca.4.insert = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.3.insert, i8 28, 4
  %.fca.5.insert = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.4.insert, i8 2, 5
  %.fca.6.insert = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.5.insert, i8 0, 6
  %.fca.7.0.0.insert = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.6.insert, i64 %.fca.7.0.0.extract, 7, 0, 0
  %.fca.7.0.1.insert = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.7.0.0.insert, i64 %.fca.7.0.1.extract, 7, 0, 1
  %.fca.7.0.2.insert = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.7.0.1.insert, i64 %.fca.7.0.2.extract, 7, 0, 2
  store { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.7.0.2.insert, ptr @_QFEarr, align 8, !tbaa !8
  %omp_global_thread_num = call i32 @__kmpc_global_thread_num(ptr @1)
  store ptr %1, ptr %structArg, align 8
  %gep_5 = getelementptr { ptr, ptr }, ptr %structArg, i32 0, i32 1
  store ptr %0, ptr %gep_5, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr @1, i32 1, ptr @_QQmain..omp_par, ptr %structArg)
  %4 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr @_QQcl.68815510185ede6107d6524e77abf791, i32 19)
  %5 = call i1 @_FortranAioOutputAscii(ptr %4, ptr @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %6 = load i32, ptr %1, align 4, !tbaa !4
  %7 = call i1 @_FortranAioOutputInteger32(ptr %4, i32 %6)
  %8 = call i1 @_FortranAioOutputAscii(ptr %4, ptr @_QQcl.2920697320, i64 5)
  %9 = load { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, align 8, !tbaa !8
  %.fca.0.extract16 = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %9, 0
  %.fca.7.0.0.extract23 = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %9, 7, 0, 0
  %10 = sub i64 1, %.fca.7.0.0.extract23
  %11 = getelementptr double, ptr %.fca.0.extract16, i64 %10
  %12 = load double, ptr %11, align 8, !tbaa !4
  %13 = load i32, ptr %1, align 4, !tbaa !4
  %14 = sext i32 %13 to i64
  %15 = sub i64 %14, %.fca.7.0.0.extract23
  %16 = getelementptr double, ptr %.fca.0.extract16, i64 %15
  %17 = load double, ptr %16, align 8, !tbaa !4
  %18 = fadd contract double %12, %17
  %19 = call i1 @_FortranAioOutputReal64(ptr %4, double %18)
  %20 = call i32 @_FortranAioEndIoStatement(ptr %4)
  %21 = load { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, align 8, !tbaa !8
  %.fca.0.extract33 = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %21, 0
  call void @free(ptr %.fca.0.extract33)
  store { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } { ptr null, i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), i32 20180515, i8 1, i8 28, i8 2, i8 0, [1 x [3 x i64]] [[3 x i64] [i64 1, i64 0, i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64)]] }, ptr @_QFEarr, align 8, !tbaa !8
  ret void
}

; Function Attrs: norecurse nounwind
define internal void @_QQmain..omp_par(ptr noalias %tid.addr, ptr noalias %zero.addr, ptr %0) #2 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr }, ptr %0, i32 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %p.lastiter = alloca i32, align 4
  %p.lowerbound = alloca i32, align 4
  %p.upperbound = alloca i32, align 4
  %p.stride = alloca i32, align 4
  %1 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %2 = sub nsw i32 %1, 1
  %3 = icmp slt i32 %1, 1
  %omp_loop.tripcount = select i1 %3, i32 0, i32 %1
  store i32 0, ptr %p.lowerbound, align 4
  %4 = sub i32 %omp_loop.tripcount, 1
  store i32 %4, ptr %p.upperbound, align 4
  store i32 1, ptr %p.stride, align 4
  %omp_global_thread_num3 = call i32 @__kmpc_global_thread_num(ptr @1)
  call void @__kmpc_for_static_init_4u(ptr @1, i32 %omp_global_thread_num3, i32 34, ptr %p.lastiter, ptr %p.lowerbound, ptr %p.upperbound, ptr %p.stride, i32 1, i32 0)
  %5 = load i32, ptr %p.lowerbound, align 4
  %6 = load i32, ptr %p.upperbound, align 4
  %7 = sub i32 %6, %5
  %8 = add i32 %7, 1
  br label %omp_loop.header

omp_loop.header:                                  ; preds = %omp_loop.body, %omp.par.entry
  %omp_loop.iv = phi i32 [ 0, %omp.par.entry ], [ %omp_loop.next, %omp_loop.body ]
  %omp_loop.cmp = icmp ult i32 %omp_loop.iv, %8
  br i1 %omp_loop.cmp, label %omp_loop.body, label %omp_loop.exit

omp_loop.exit:                                    ; preds = %omp_loop.header
  call void @__kmpc_for_static_fini(ptr @1, i32 %omp_global_thread_num3)
  %omp_global_thread_num4 = call i32 @__kmpc_global_thread_num(ptr @1)
  call void @__kmpc_barrier(ptr @2, i32 %omp_global_thread_num4)
  ret void

omp_loop.body:                                    ; preds = %omp_loop.header
  %9 = add i32 %omp_loop.iv, %5
  %10 = add i32 %9, 1
  %11 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %12 = sitofp i32 %11 to float
  %13 = fdiv contract float 1.000000e+00, %12
  %14 = fpext float %13 to double
  %15 = load { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, align 8, !tbaa !8
  store { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %15, ptr %loadgep_2, align 8, !tbaa !8
  %16 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i32 0, i32 7, i64 0, i32 0
  %17 = load i64, ptr %16, align 8, !tbaa !8
  %18 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i32 0, i32 7, i64 0, i32 1
  %19 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i32 0, i32 7, i64 0, i32 2
  %20 = load ptr, ptr %loadgep_2, align 8, !tbaa !8
  %21 = sext i32 %10 to i64
  %22 = sub i64 %21, %17
  %23 = getelementptr double, ptr %20, i64 %22
  store double %14, ptr %23, align 8, !tbaa !4
  %omp_loop.next = add nuw i32 %omp_loop.iv, 1
  br label %omp_loop.header
}

declare ptr @_FortranAioBeginExternalFormattedOutput(ptr, i64, ptr, i32, ptr, i32)

declare zeroext i1 @_FortranAioOutputAscii(ptr, ptr, i64)

declare zeroext i1 @_FortranAioOutputInteger32(ptr, i32)

declare zeroext i1 @_FortranAioOutputReal64(ptr, double)

declare i32 @_FortranAioEndIoStatement(ptr)

; Function Attrs: mustprogress nocallback nofree nosync nounwind willreturn
declare ptr @llvm.stacksave() #3

; Function Attrs: mustprogress nocallback nofree nosync nounwind willreturn
declare void @llvm.stackrestore(ptr) #3

; Function Attrs: nounwind
declare i32 @__kmpc_global_thread_num(ptr) #4

; Function Attrs: nounwind
declare void @__kmpc_for_static_init_4u(ptr, i32, i32, ptr, ptr, ptr, ptr, i32, i32) #4

; Function Attrs: nounwind
declare void @__kmpc_for_static_fini(ptr, i32) #4

; Function Attrs: convergent nounwind
declare void @__kmpc_barrier(ptr, i32) #5

; Function Attrs: nounwind
declare !callback !10 void @__kmpc_fork_call(ptr, i32, ptr, ...) #4

attributes #0 = { mustprogress nofree nounwind willreturn allockind("alloc,uninitialized") allocsize(0) memory(inaccessiblemem: readwrite) "alloc-family"="malloc" }
attributes #1 = { mustprogress nounwind willreturn allockind("free") memory(argmem: readwrite, inaccessiblemem: readwrite) "alloc-family"="malloc" }
attributes #2 = { norecurse nounwind }
attributes #3 = { mustprogress nocallback nofree nosync nounwind willreturn }
attributes #4 = { nounwind }
attributes #5 = { convergent nounwind }

!llvm.module.flags = !{!0, !1, !2, !3}

!0 = !{i32 2, !"Debug Info Version", i32 3}
!1 = !{i32 7, !"openmp", i32 11}
!2 = !{i32 8, !"PIC Level", i32 2}
!3 = !{i32 7, !"PIE Level", i32 2}
!4 = !{!5, !5, i64 0}
!5 = !{!"any data access", !6, i64 0}
!6 = !{!"any access", !7, i64 0}
!7 = !{!"Flang Type TBAA Root"}
!8 = !{!9, !9, i64 0}
!9 = !{!"descriptor member", !6, i64 0}
!10 = !{!11}
!11 = !{i64 2, i64 -1, i64 -1, i1 true}
*** IR Dump After GlobalOptPass on [module] ***
; ModuleID = 'FIRModule'
source_filename = "FIRModule"
target datalayout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128"
target triple = "x86_64-unknown-linux-gnu"

%struct.ident_t = type { i32, i32, i32, i32, ptr }

@_QFEarr = internal unnamed_addr global { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } { ptr null, i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), i32 20180515, i8 1, i8 28, i8 2, i8 0, [1 x [3 x i64]] [[3 x i64] [i64 1, i64 0, i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64)]] }
@_QQcl.68815510185ede6107d6524e77abf791 = internal constant [52 x i8] c"/g/g92/rydahl1/flangtests/src/array_descriptors.f90\00"
@_QQcl.28612C69372C612C6531332E36653229 = internal constant [16 x i8] c"(a,i7,a,e13.6e2)"
@_QQcl.54686520726573756C74206F6620286172722831292B61727228 = internal constant [26 x i8] c"The result of (arr(1)+arr("
@_QQcl.2920697320 = internal constant [5 x i8] c") is "
@_QQEnvironmentDefaults = local_unnamed_addr constant ptr null
@0 = private unnamed_addr constant [23 x i8] c";unknown;unknown;0;0;;\00", align 1
@1 = private unnamed_addr constant %struct.ident_t { i32 0, i32 2, i32 0, i32 22, ptr @0 }, align 8
@2 = private unnamed_addr constant %struct.ident_t { i32 0, i32 66, i32 0, i32 22, ptr @0 }, align 8

; Function Attrs: mustprogress nofree nounwind willreturn allockind("alloc,uninitialized") allocsize(0) memory(inaccessiblemem: readwrite)
declare noalias noundef ptr @malloc(i64 noundef) local_unnamed_addr #0

; Function Attrs: mustprogress nounwind willreturn allockind("free") memory(argmem: readwrite, inaccessiblemem: readwrite)
declare void @free(ptr allocptr nocapture noundef) local_unnamed_addr #1

define void @_QQmain() local_unnamed_addr {
entry:
  %structArg = alloca { ptr, ptr }, align 8
  %0 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %1 = alloca i32, i64 1, align 4
  store i32 1048576, ptr %1, align 4, !tbaa !4
  %2 = call ptr @malloc(i64 mul (i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), i64 1048576))
  %3 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } { ptr undef, i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), i32 20180515, i8 1, i8 28, i8 2, i8 0, [1 x [3 x i64]] [[3 x i64] [i64 1, i64 1048576, i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64)]] }, ptr %2, 0
  %.fca.7.0.0.extract = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %3, 7, 0, 0
  %.fca.7.0.1.extract = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %3, 7, 0, 1
  %.fca.7.0.2.extract = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %3, 7, 0, 2
  %.fca.0.insert = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } poison, ptr %2, 0
  %.fca.1.insert = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.0.insert, i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), 1
  %.fca.2.insert = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.1.insert, i32 20180515, 2
  %.fca.3.insert = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.2.insert, i8 1, 3
  %.fca.4.insert = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.3.insert, i8 28, 4
  %.fca.5.insert = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.4.insert, i8 2, 5
  %.fca.6.insert = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.5.insert, i8 0, 6
  %.fca.7.0.0.insert = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.6.insert, i64 %.fca.7.0.0.extract, 7, 0, 0
  %.fca.7.0.1.insert = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.7.0.0.insert, i64 %.fca.7.0.1.extract, 7, 0, 1
  %.fca.7.0.2.insert = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.7.0.1.insert, i64 %.fca.7.0.2.extract, 7, 0, 2
  store { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.7.0.2.insert, ptr @_QFEarr, align 8, !tbaa !8
  %omp_global_thread_num = call i32 @__kmpc_global_thread_num(ptr @1)
  store ptr %1, ptr %structArg, align 8
  %gep_5 = getelementptr { ptr, ptr }, ptr %structArg, i32 0, i32 1
  store ptr %0, ptr %gep_5, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr @1, i32 1, ptr @_QQmain..omp_par, ptr %structArg)
  %4 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr @_QQcl.68815510185ede6107d6524e77abf791, i32 19)
  %5 = call i1 @_FortranAioOutputAscii(ptr %4, ptr @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %6 = load i32, ptr %1, align 4, !tbaa !4
  %7 = call i1 @_FortranAioOutputInteger32(ptr %4, i32 %6)
  %8 = call i1 @_FortranAioOutputAscii(ptr %4, ptr @_QQcl.2920697320, i64 5)
  %9 = load { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, align 8, !tbaa !8
  %.fca.0.extract16 = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %9, 0
  %.fca.7.0.0.extract23 = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %9, 7, 0, 0
  %10 = sub i64 1, %.fca.7.0.0.extract23
  %11 = getelementptr double, ptr %.fca.0.extract16, i64 %10
  %12 = load double, ptr %11, align 8, !tbaa !4
  %13 = load i32, ptr %1, align 4, !tbaa !4
  %14 = sext i32 %13 to i64
  %15 = sub i64 %14, %.fca.7.0.0.extract23
  %16 = getelementptr double, ptr %.fca.0.extract16, i64 %15
  %17 = load double, ptr %16, align 8, !tbaa !4
  %18 = fadd contract double %12, %17
  %19 = call i1 @_FortranAioOutputReal64(ptr %4, double %18)
  %20 = call i32 @_FortranAioEndIoStatement(ptr %4)
  %21 = load { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, align 8, !tbaa !8
  %.fca.0.extract33 = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %21, 0
  call void @free(ptr %.fca.0.extract33)
  store { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } { ptr null, i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), i32 20180515, i8 1, i8 28, i8 2, i8 0, [1 x [3 x i64]] [[3 x i64] [i64 1, i64 0, i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64)]] }, ptr @_QFEarr, align 8, !tbaa !8
  ret void
}

; Function Attrs: norecurse nounwind
define internal void @_QQmain..omp_par(ptr noalias %tid.addr, ptr noalias %zero.addr, ptr %0) #2 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr }, ptr %0, i32 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %p.lastiter = alloca i32, align 4
  %p.lowerbound = alloca i32, align 4
  %p.upperbound = alloca i32, align 4
  %p.stride = alloca i32, align 4
  %1 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %2 = sub nsw i32 %1, 1
  %3 = icmp slt i32 %1, 1
  %omp_loop.tripcount = select i1 %3, i32 0, i32 %1
  store i32 0, ptr %p.lowerbound, align 4
  %4 = sub i32 %omp_loop.tripcount, 1
  store i32 %4, ptr %p.upperbound, align 4
  store i32 1, ptr %p.stride, align 4
  %omp_global_thread_num3 = call i32 @__kmpc_global_thread_num(ptr @1)
  call void @__kmpc_for_static_init_4u(ptr @1, i32 %omp_global_thread_num3, i32 34, ptr %p.lastiter, ptr %p.lowerbound, ptr %p.upperbound, ptr %p.stride, i32 1, i32 0)
  %5 = load i32, ptr %p.lowerbound, align 4
  %6 = load i32, ptr %p.upperbound, align 4
  %7 = sub i32 %6, %5
  %8 = add i32 %7, 1
  br label %omp_loop.header

omp_loop.header:                                  ; preds = %omp_loop.body, %omp.par.entry
  %omp_loop.iv = phi i32 [ 0, %omp.par.entry ], [ %omp_loop.next, %omp_loop.body ]
  %omp_loop.cmp = icmp ult i32 %omp_loop.iv, %8
  br i1 %omp_loop.cmp, label %omp_loop.body, label %omp_loop.exit

omp_loop.exit:                                    ; preds = %omp_loop.header
  call void @__kmpc_for_static_fini(ptr @1, i32 %omp_global_thread_num3)
  %omp_global_thread_num4 = call i32 @__kmpc_global_thread_num(ptr @1)
  call void @__kmpc_barrier(ptr @2, i32 %omp_global_thread_num4)
  ret void

omp_loop.body:                                    ; preds = %omp_loop.header
  %9 = add i32 %omp_loop.iv, %5
  %10 = add i32 %9, 1
  %11 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %12 = sitofp i32 %11 to float
  %13 = fdiv contract float 1.000000e+00, %12
  %14 = fpext float %13 to double
  %15 = load { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, align 8, !tbaa !8
  store { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %15, ptr %loadgep_2, align 8, !tbaa !8
  %16 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i32 0, i32 7, i64 0, i32 0
  %17 = load i64, ptr %16, align 8, !tbaa !8
  %18 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i32 0, i32 7, i64 0, i32 1
  %19 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i32 0, i32 7, i64 0, i32 2
  %20 = load ptr, ptr %loadgep_2, align 8, !tbaa !8
  %21 = sext i32 %10 to i64
  %22 = sub i64 %21, %17
  %23 = getelementptr double, ptr %20, i64 %22
  store double %14, ptr %23, align 8, !tbaa !4
  %omp_loop.next = add nuw i32 %omp_loop.iv, 1
  br label %omp_loop.header
}

declare ptr @_FortranAioBeginExternalFormattedOutput(ptr, i64, ptr, i32, ptr, i32) local_unnamed_addr

declare zeroext i1 @_FortranAioOutputAscii(ptr, ptr, i64) local_unnamed_addr

declare zeroext i1 @_FortranAioOutputInteger32(ptr, i32) local_unnamed_addr

declare zeroext i1 @_FortranAioOutputReal64(ptr, double) local_unnamed_addr

declare i32 @_FortranAioEndIoStatement(ptr) local_unnamed_addr

; Function Attrs: nounwind
declare i32 @__kmpc_global_thread_num(ptr) local_unnamed_addr #3

; Function Attrs: nounwind
declare void @__kmpc_for_static_init_4u(ptr, i32, i32, ptr, ptr, ptr, ptr, i32, i32) local_unnamed_addr #3

; Function Attrs: nounwind
declare void @__kmpc_for_static_fini(ptr, i32) local_unnamed_addr #3

; Function Attrs: convergent nounwind
declare void @__kmpc_barrier(ptr, i32) local_unnamed_addr #4

; Function Attrs: nounwind
declare !callback !10 void @__kmpc_fork_call(ptr, i32, ptr, ...) local_unnamed_addr #3

attributes #0 = { mustprogress nofree nounwind willreturn allockind("alloc,uninitialized") allocsize(0) memory(inaccessiblemem: readwrite) "alloc-family"="malloc" }
attributes #1 = { mustprogress nounwind willreturn allockind("free") memory(argmem: readwrite, inaccessiblemem: readwrite) "alloc-family"="malloc" }
attributes #2 = { norecurse nounwind }
attributes #3 = { nounwind }
attributes #4 = { convergent nounwind }

!llvm.module.flags = !{!0, !1, !2, !3}

!0 = !{i32 2, !"Debug Info Version", i32 3}
!1 = !{i32 7, !"openmp", i32 11}
!2 = !{i32 8, !"PIC Level", i32 2}
!3 = !{i32 7, !"PIE Level", i32 2}
!4 = !{!5, !5, i64 0}
!5 = !{!"any data access", !6, i64 0}
!6 = !{!"any access", !7, i64 0}
!7 = !{!"Flang Type TBAA Root"}
!8 = !{!9, !9, i64 0}
!9 = !{!"descriptor member", !6, i64 0}
!10 = !{!11}
!11 = !{i64 2, i64 -1, i64 -1, i1 true}
*** IR Dump After PromotePass on _QQmain ***
define void @_QQmain() local_unnamed_addr {
entry:
  %structArg = alloca { ptr, ptr }, align 8
  %0 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %1 = alloca i32, i64 1, align 4
  store i32 1048576, ptr %1, align 4, !tbaa !4
  %2 = call ptr @malloc(i64 mul (i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), i64 1048576))
  %3 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } { ptr undef, i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), i32 20180515, i8 1, i8 28, i8 2, i8 0, [1 x [3 x i64]] [[3 x i64] [i64 1, i64 1048576, i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64)]] }, ptr %2, 0
  %.fca.7.0.0.extract = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %3, 7, 0, 0
  %.fca.7.0.1.extract = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %3, 7, 0, 1
  %.fca.7.0.2.extract = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %3, 7, 0, 2
  %.fca.0.insert = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } poison, ptr %2, 0
  %.fca.1.insert = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.0.insert, i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), 1
  %.fca.2.insert = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.1.insert, i32 20180515, 2
  %.fca.3.insert = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.2.insert, i8 1, 3
  %.fca.4.insert = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.3.insert, i8 28, 4
  %.fca.5.insert = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.4.insert, i8 2, 5
  %.fca.6.insert = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.5.insert, i8 0, 6
  %.fca.7.0.0.insert = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.6.insert, i64 %.fca.7.0.0.extract, 7, 0, 0
  %.fca.7.0.1.insert = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.7.0.0.insert, i64 %.fca.7.0.1.extract, 7, 0, 1
  %.fca.7.0.2.insert = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.7.0.1.insert, i64 %.fca.7.0.2.extract, 7, 0, 2
  store { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.7.0.2.insert, ptr @_QFEarr, align 8, !tbaa !8
  %omp_global_thread_num = call i32 @__kmpc_global_thread_num(ptr @1)
  store ptr %1, ptr %structArg, align 8
  %gep_5 = getelementptr { ptr, ptr }, ptr %structArg, i32 0, i32 1
  store ptr %0, ptr %gep_5, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr @1, i32 1, ptr @_QQmain..omp_par, ptr %structArg)
  %4 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr @_QQcl.68815510185ede6107d6524e77abf791, i32 19)
  %5 = call i1 @_FortranAioOutputAscii(ptr %4, ptr @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %6 = load i32, ptr %1, align 4, !tbaa !4
  %7 = call i1 @_FortranAioOutputInteger32(ptr %4, i32 %6)
  %8 = call i1 @_FortranAioOutputAscii(ptr %4, ptr @_QQcl.2920697320, i64 5)
  %9 = load { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, align 8, !tbaa !8
  %.fca.0.extract16 = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %9, 0
  %.fca.7.0.0.extract23 = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %9, 7, 0, 0
  %10 = sub i64 1, %.fca.7.0.0.extract23
  %11 = getelementptr double, ptr %.fca.0.extract16, i64 %10
  %12 = load double, ptr %11, align 8, !tbaa !4
  %13 = load i32, ptr %1, align 4, !tbaa !4
  %14 = sext i32 %13 to i64
  %15 = sub i64 %14, %.fca.7.0.0.extract23
  %16 = getelementptr double, ptr %.fca.0.extract16, i64 %15
  %17 = load double, ptr %16, align 8, !tbaa !4
  %18 = fadd contract double %12, %17
  %19 = call i1 @_FortranAioOutputReal64(ptr %4, double %18)
  %20 = call i32 @_FortranAioEndIoStatement(ptr %4)
  %21 = load { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, align 8, !tbaa !8
  %.fca.0.extract33 = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %21, 0
  call void @free(ptr %.fca.0.extract33)
  store { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } { ptr null, i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), i32 20180515, i8 1, i8 28, i8 2, i8 0, [1 x [3 x i64]] [[3 x i64] [i64 1, i64 0, i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64)]] }, ptr @_QFEarr, align 8, !tbaa !8
  ret void
}
*** IR Dump After InstCombinePass on _QQmain ***
define void @_QQmain() local_unnamed_addr {
entry:
  %structArg = alloca { ptr, ptr }, align 8
  %0 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %1 = alloca i32, align 4
  store i32 1048576, ptr %1, align 4, !tbaa !4
  %2 = call dereferenceable_or_null(8388608) ptr @malloc(i64 8388608)
  store ptr %2, ptr @_QFEarr, align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  store i32 20180515, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  store i8 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  store i8 28, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  store i8 2, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  store i8 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  store i64 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  store i64 1048576, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  %omp_global_thread_num = call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %1, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %0, ptr %gep_5, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QQmain..omp_par, ptr nonnull %structArg)
  %3 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.68815510185ede6107d6524e77abf791, i32 19)
  %4 = call i1 @_FortranAioOutputAscii(ptr %3, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %5 = load i32, ptr %1, align 4, !tbaa !4
  %6 = call i1 @_FortranAioOutputInteger32(ptr %3, i32 %5)
  %7 = call i1 @_FortranAioOutputAscii(ptr %3, ptr nonnull @_QQcl.2920697320, i64 5)
  %.unpack = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  %.unpack95.unpack.unpack = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  %8 = sub i64 1, %.unpack95.unpack.unpack
  %9 = getelementptr double, ptr %.unpack, i64 %8
  %10 = load double, ptr %9, align 8, !tbaa !4
  %11 = load i32, ptr %1, align 4, !tbaa !4
  %12 = sext i32 %11 to i64
  %13 = sub i64 %12, %.unpack95.unpack.unpack
  %14 = getelementptr double, ptr %.unpack, i64 %13
  %15 = load double, ptr %14, align 8, !tbaa !4
  %16 = fadd contract double %10, %15
  %17 = call i1 @_FortranAioOutputReal64(ptr %3, double %16)
  %18 = call i32 @_FortranAioEndIoStatement(ptr %3)
  %.unpack100 = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  call void @free(ptr %.unpack100)
  store ptr null, ptr @_QFEarr, align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  store i32 20180515, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  store i8 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  store i8 28, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  store i8 2, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  store i8 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  store i64 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  store i64 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  ret void
}
*** IR Dump After SimplifyCFGPass on _QQmain ***
define void @_QQmain() local_unnamed_addr {
entry:
  %structArg = alloca { ptr, ptr }, align 8
  %0 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %1 = alloca i32, align 4
  store i32 1048576, ptr %1, align 4, !tbaa !4
  %2 = call dereferenceable_or_null(8388608) ptr @malloc(i64 8388608)
  store ptr %2, ptr @_QFEarr, align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  store i32 20180515, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  store i8 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  store i8 28, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  store i8 2, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  store i8 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  store i64 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  store i64 1048576, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  %omp_global_thread_num = call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %1, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %0, ptr %gep_5, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QQmain..omp_par, ptr nonnull %structArg)
  %3 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.68815510185ede6107d6524e77abf791, i32 19)
  %4 = call i1 @_FortranAioOutputAscii(ptr %3, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %5 = load i32, ptr %1, align 4, !tbaa !4
  %6 = call i1 @_FortranAioOutputInteger32(ptr %3, i32 %5)
  %7 = call i1 @_FortranAioOutputAscii(ptr %3, ptr nonnull @_QQcl.2920697320, i64 5)
  %.unpack = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  %.unpack95.unpack.unpack = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  %8 = sub i64 1, %.unpack95.unpack.unpack
  %9 = getelementptr double, ptr %.unpack, i64 %8
  %10 = load double, ptr %9, align 8, !tbaa !4
  %11 = load i32, ptr %1, align 4, !tbaa !4
  %12 = sext i32 %11 to i64
  %13 = sub i64 %12, %.unpack95.unpack.unpack
  %14 = getelementptr double, ptr %.unpack, i64 %13
  %15 = load double, ptr %14, align 8, !tbaa !4
  %16 = fadd contract double %10, %15
  %17 = call i1 @_FortranAioOutputReal64(ptr %3, double %16)
  %18 = call i32 @_FortranAioEndIoStatement(ptr %3)
  %.unpack100 = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  call void @free(ptr %.unpack100)
  store ptr null, ptr @_QFEarr, align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  store i32 20180515, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  store i8 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  store i8 28, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  store i8 2, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  store i8 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  store i64 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  store i64 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  ret void
}
*** IR Dump After PromotePass on _QQmain..omp_par ***
; Function Attrs: norecurse nounwind
define internal void @_QQmain..omp_par(ptr noalias %tid.addr, ptr noalias %zero.addr, ptr %0) #2 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr }, ptr %0, i32 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %p.lastiter = alloca i32, align 4
  %p.lowerbound = alloca i32, align 4
  %p.upperbound = alloca i32, align 4
  %p.stride = alloca i32, align 4
  %1 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %2 = sub nsw i32 %1, 1
  %3 = icmp slt i32 %1, 1
  %omp_loop.tripcount = select i1 %3, i32 0, i32 %1
  store i32 0, ptr %p.lowerbound, align 4
  %4 = sub i32 %omp_loop.tripcount, 1
  store i32 %4, ptr %p.upperbound, align 4
  store i32 1, ptr %p.stride, align 4
  %omp_global_thread_num3 = call i32 @__kmpc_global_thread_num(ptr @1)
  call void @__kmpc_for_static_init_4u(ptr @1, i32 %omp_global_thread_num3, i32 34, ptr %p.lastiter, ptr %p.lowerbound, ptr %p.upperbound, ptr %p.stride, i32 1, i32 0)
  %5 = load i32, ptr %p.lowerbound, align 4
  %6 = load i32, ptr %p.upperbound, align 4
  %7 = sub i32 %6, %5
  %8 = add i32 %7, 1
  br label %omp_loop.header

omp_loop.header:                                  ; preds = %omp_loop.body, %omp.par.entry
  %omp_loop.iv = phi i32 [ 0, %omp.par.entry ], [ %omp_loop.next, %omp_loop.body ]
  %omp_loop.cmp = icmp ult i32 %omp_loop.iv, %8
  br i1 %omp_loop.cmp, label %omp_loop.body, label %omp_loop.exit

omp_loop.exit:                                    ; preds = %omp_loop.header
  call void @__kmpc_for_static_fini(ptr @1, i32 %omp_global_thread_num3)
  %omp_global_thread_num4 = call i32 @__kmpc_global_thread_num(ptr @1)
  call void @__kmpc_barrier(ptr @2, i32 %omp_global_thread_num4)
  ret void

omp_loop.body:                                    ; preds = %omp_loop.header
  %9 = add i32 %omp_loop.iv, %5
  %10 = add i32 %9, 1
  %11 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %12 = sitofp i32 %11 to float
  %13 = fdiv contract float 1.000000e+00, %12
  %14 = fpext float %13 to double
  %15 = load { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, align 8, !tbaa !8
  store { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %15, ptr %loadgep_2, align 8, !tbaa !8
  %16 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i32 0, i32 7, i64 0, i32 0
  %17 = load i64, ptr %16, align 8, !tbaa !8
  %18 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i32 0, i32 7, i64 0, i32 1
  %19 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i32 0, i32 7, i64 0, i32 2
  %20 = load ptr, ptr %loadgep_2, align 8, !tbaa !8
  %21 = sext i32 %10 to i64
  %22 = sub i64 %21, %17
  %23 = getelementptr double, ptr %20, i64 %22
  store double %14, ptr %23, align 8, !tbaa !4
  %omp_loop.next = add nuw i32 %omp_loop.iv, 1
  br label %omp_loop.header
}
*** IR Dump After InstCombinePass on _QQmain..omp_par ***
; Function Attrs: norecurse nounwind
define internal void @_QQmain..omp_par(ptr noalias %tid.addr, ptr noalias %zero.addr, ptr %0) #2 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %p.lastiter = alloca i32, align 4
  %p.lowerbound = alloca i32, align 4
  %p.upperbound = alloca i32, align 4
  %p.stride = alloca i32, align 4
  %1 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %omp_loop.tripcount = call i32 @llvm.smax.i32(i32 %1, i32 0)
  store i32 0, ptr %p.lowerbound, align 4
  %2 = add nsw i32 %omp_loop.tripcount, -1
  store i32 %2, ptr %p.upperbound, align 4
  store i32 1, ptr %p.stride, align 4
  %omp_global_thread_num3 = call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  call void @__kmpc_for_static_init_4u(ptr nonnull @1, i32 %omp_global_thread_num3, i32 34, ptr nonnull %p.lastiter, ptr nonnull %p.lowerbound, ptr nonnull %p.upperbound, ptr nonnull %p.stride, i32 1, i32 0)
  %3 = load i32, ptr %p.lowerbound, align 4
  %4 = load i32, ptr %p.upperbound, align 4
  %5 = sub i32 %4, %3
  %6 = add i32 %5, 1
  br label %omp_loop.header

omp_loop.header:                                  ; preds = %omp_loop.body, %omp.par.entry
  %omp_loop.iv = phi i32 [ 0, %omp.par.entry ], [ %omp_loop.next, %omp_loop.body ]
  %omp_loop.cmp = icmp ult i32 %omp_loop.iv, %6
  br i1 %omp_loop.cmp, label %omp_loop.body, label %omp_loop.exit

omp_loop.exit:                                    ; preds = %omp_loop.header
  call void @__kmpc_for_static_fini(ptr nonnull @1, i32 %omp_global_thread_num3)
  %omp_global_thread_num4 = call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  call void @__kmpc_barrier(ptr nonnull @2, i32 %omp_global_thread_num4)
  ret void

omp_loop.body:                                    ; preds = %omp_loop.header
  %7 = add i32 %omp_loop.iv, %3
  %8 = add i32 %7, 1
  %9 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %10 = sitofp i32 %9 to float
  %11 = fdiv contract float 1.000000e+00, %10
  %12 = fpext float %11 to double
  %.unpack = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  %.unpack3 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  %.unpack4 = load i32, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  %.unpack5 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  %.unpack6 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  %.unpack7 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  %.unpack8 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  %.unpack9.unpack.unpack = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  %.unpack9.unpack.unpack11 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  %.unpack9.unpack.unpack12 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  store ptr %.unpack, ptr %loadgep_2, align 8, !tbaa !8
  %loadgep_2.repack14 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  store i64 %.unpack3, ptr %loadgep_2.repack14, align 8, !tbaa !8
  %loadgep_2.repack16 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  store i32 %.unpack4, ptr %loadgep_2.repack16, align 8, !tbaa !8
  %loadgep_2.repack18 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  store i8 %.unpack5, ptr %loadgep_2.repack18, align 4, !tbaa !8
  %loadgep_2.repack20 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  store i8 %.unpack6, ptr %loadgep_2.repack20, align 1, !tbaa !8
  %loadgep_2.repack22 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  store i8 %.unpack7, ptr %loadgep_2.repack22, align 2, !tbaa !8
  %loadgep_2.repack24 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  store i8 %.unpack8, ptr %loadgep_2.repack24, align 1, !tbaa !8
  %loadgep_2.repack26 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  store i64 %.unpack9.unpack.unpack, ptr %loadgep_2.repack26, align 8, !tbaa !8
  %loadgep_2.repack26.repack28 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack9.unpack.unpack11, ptr %loadgep_2.repack26.repack28, align 8, !tbaa !8
  %loadgep_2.repack26.repack30 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  store i64 %.unpack9.unpack.unpack12, ptr %loadgep_2.repack26.repack30, align 8, !tbaa !8
  %13 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 0
  %14 = load i64, ptr %13, align 8, !tbaa !8
  %15 = load ptr, ptr %loadgep_2, align 8, !tbaa !8
  %16 = sext i32 %8 to i64
  %17 = sub i64 %16, %14
  %18 = getelementptr double, ptr %15, i64 %17
  store double %12, ptr %18, align 8, !tbaa !4
  %omp_loop.next = add nuw i32 %omp_loop.iv, 1
  br label %omp_loop.header
}
*** IR Dump After SimplifyCFGPass on _QQmain..omp_par ***
; Function Attrs: norecurse nounwind
define internal void @_QQmain..omp_par(ptr noalias %tid.addr, ptr noalias %zero.addr, ptr %0) #2 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %p.lastiter = alloca i32, align 4
  %p.lowerbound = alloca i32, align 4
  %p.upperbound = alloca i32, align 4
  %p.stride = alloca i32, align 4
  %1 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %omp_loop.tripcount = call i32 @llvm.smax.i32(i32 %1, i32 0)
  store i32 0, ptr %p.lowerbound, align 4
  %2 = add nsw i32 %omp_loop.tripcount, -1
  store i32 %2, ptr %p.upperbound, align 4
  store i32 1, ptr %p.stride, align 4
  %omp_global_thread_num3 = call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  call void @__kmpc_for_static_init_4u(ptr nonnull @1, i32 %omp_global_thread_num3, i32 34, ptr nonnull %p.lastiter, ptr nonnull %p.lowerbound, ptr nonnull %p.upperbound, ptr nonnull %p.stride, i32 1, i32 0)
  %3 = load i32, ptr %p.lowerbound, align 4
  %4 = load i32, ptr %p.upperbound, align 4
  %5 = sub i32 %4, %3
  %6 = add i32 %5, 1
  br label %omp_loop.header

omp_loop.header:                                  ; preds = %omp_loop.body, %omp.par.entry
  %omp_loop.iv = phi i32 [ 0, %omp.par.entry ], [ %omp_loop.next, %omp_loop.body ]
  %omp_loop.cmp = icmp ult i32 %omp_loop.iv, %6
  br i1 %omp_loop.cmp, label %omp_loop.body, label %omp_loop.exit

omp_loop.exit:                                    ; preds = %omp_loop.header
  call void @__kmpc_for_static_fini(ptr nonnull @1, i32 %omp_global_thread_num3)
  %omp_global_thread_num4 = call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  call void @__kmpc_barrier(ptr nonnull @2, i32 %omp_global_thread_num4)
  ret void

omp_loop.body:                                    ; preds = %omp_loop.header
  %7 = add i32 %omp_loop.iv, %3
  %8 = add i32 %7, 1
  %9 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %10 = sitofp i32 %9 to float
  %11 = fdiv contract float 1.000000e+00, %10
  %12 = fpext float %11 to double
  %.unpack = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  %.unpack3 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  %.unpack4 = load i32, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  %.unpack5 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  %.unpack6 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  %.unpack7 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  %.unpack8 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  %.unpack9.unpack.unpack = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  %.unpack9.unpack.unpack11 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  %.unpack9.unpack.unpack12 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  store ptr %.unpack, ptr %loadgep_2, align 8, !tbaa !8
  %loadgep_2.repack14 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  store i64 %.unpack3, ptr %loadgep_2.repack14, align 8, !tbaa !8
  %loadgep_2.repack16 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  store i32 %.unpack4, ptr %loadgep_2.repack16, align 8, !tbaa !8
  %loadgep_2.repack18 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  store i8 %.unpack5, ptr %loadgep_2.repack18, align 4, !tbaa !8
  %loadgep_2.repack20 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  store i8 %.unpack6, ptr %loadgep_2.repack20, align 1, !tbaa !8
  %loadgep_2.repack22 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  store i8 %.unpack7, ptr %loadgep_2.repack22, align 2, !tbaa !8
  %loadgep_2.repack24 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  store i8 %.unpack8, ptr %loadgep_2.repack24, align 1, !tbaa !8
  %loadgep_2.repack26 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  store i64 %.unpack9.unpack.unpack, ptr %loadgep_2.repack26, align 8, !tbaa !8
  %loadgep_2.repack26.repack28 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack9.unpack.unpack11, ptr %loadgep_2.repack26.repack28, align 8, !tbaa !8
  %loadgep_2.repack26.repack30 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  store i64 %.unpack9.unpack.unpack12, ptr %loadgep_2.repack26.repack30, align 8, !tbaa !8
  %13 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 0
  %14 = load i64, ptr %13, align 8, !tbaa !8
  %15 = load ptr, ptr %loadgep_2, align 8, !tbaa !8
  %16 = sext i32 %8 to i64
  %17 = sub i64 %16, %14
  %18 = getelementptr double, ptr %15, i64 %17
  store double %12, ptr %18, align 8, !tbaa !4
  %omp_loop.next = add nuw i32 %omp_loop.iv, 1
  br label %omp_loop.header
}
*** IR Dump After RequireAnalysisPass<llvm::GlobalsAA, llvm::Module> on [module] ***
; ModuleID = 'FIRModule'
source_filename = "FIRModule"
target datalayout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128"
target triple = "x86_64-unknown-linux-gnu"

%struct.ident_t = type { i32, i32, i32, i32, ptr }

@_QFEarr = internal unnamed_addr global { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } { ptr null, i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), i32 20180515, i8 1, i8 28, i8 2, i8 0, [1 x [3 x i64]] [[3 x i64] [i64 1, i64 0, i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64)]] }
@_QQcl.68815510185ede6107d6524e77abf791 = internal constant [52 x i8] c"/g/g92/rydahl1/flangtests/src/array_descriptors.f90\00"
@_QQcl.28612C69372C612C6531332E36653229 = internal constant [16 x i8] c"(a,i7,a,e13.6e2)"
@_QQcl.54686520726573756C74206F6620286172722831292B61727228 = internal constant [26 x i8] c"The result of (arr(1)+arr("
@_QQcl.2920697320 = internal constant [5 x i8] c") is "
@_QQEnvironmentDefaults = local_unnamed_addr constant ptr null
@0 = private unnamed_addr constant [23 x i8] c";unknown;unknown;0;0;;\00", align 1
@1 = private unnamed_addr constant %struct.ident_t { i32 0, i32 2, i32 0, i32 22, ptr @0 }, align 8
@2 = private unnamed_addr constant %struct.ident_t { i32 0, i32 66, i32 0, i32 22, ptr @0 }, align 8

; Function Attrs: mustprogress nofree nounwind willreturn allockind("alloc,uninitialized") allocsize(0) memory(inaccessiblemem: readwrite)
declare noalias noundef ptr @malloc(i64 noundef) local_unnamed_addr #0

; Function Attrs: mustprogress nounwind willreturn allockind("free") memory(argmem: readwrite, inaccessiblemem: readwrite)
declare void @free(ptr allocptr nocapture noundef) local_unnamed_addr #1

define void @_QQmain() local_unnamed_addr {
entry:
  %structArg = alloca { ptr, ptr }, align 8
  %0 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %1 = alloca i32, align 4
  store i32 1048576, ptr %1, align 4, !tbaa !4
  %2 = call dereferenceable_or_null(8388608) ptr @malloc(i64 8388608)
  store ptr %2, ptr @_QFEarr, align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  store i32 20180515, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  store i8 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  store i8 28, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  store i8 2, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  store i8 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  store i64 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  store i64 1048576, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  %omp_global_thread_num = call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %1, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %0, ptr %gep_5, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QQmain..omp_par, ptr nonnull %structArg)
  %3 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.68815510185ede6107d6524e77abf791, i32 19)
  %4 = call i1 @_FortranAioOutputAscii(ptr %3, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %5 = load i32, ptr %1, align 4, !tbaa !4
  %6 = call i1 @_FortranAioOutputInteger32(ptr %3, i32 %5)
  %7 = call i1 @_FortranAioOutputAscii(ptr %3, ptr nonnull @_QQcl.2920697320, i64 5)
  %.unpack = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  %.unpack95.unpack.unpack = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  %8 = sub i64 1, %.unpack95.unpack.unpack
  %9 = getelementptr double, ptr %.unpack, i64 %8
  %10 = load double, ptr %9, align 8, !tbaa !4
  %11 = load i32, ptr %1, align 4, !tbaa !4
  %12 = sext i32 %11 to i64
  %13 = sub i64 %12, %.unpack95.unpack.unpack
  %14 = getelementptr double, ptr %.unpack, i64 %13
  %15 = load double, ptr %14, align 8, !tbaa !4
  %16 = fadd contract double %10, %15
  %17 = call i1 @_FortranAioOutputReal64(ptr %3, double %16)
  %18 = call i32 @_FortranAioEndIoStatement(ptr %3)
  %.unpack100 = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  call void @free(ptr %.unpack100)
  store ptr null, ptr @_QFEarr, align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  store i32 20180515, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  store i8 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  store i8 28, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  store i8 2, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  store i8 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  store i64 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  store i64 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  ret void
}

; Function Attrs: norecurse nounwind
define internal void @_QQmain..omp_par(ptr noalias %tid.addr, ptr noalias %zero.addr, ptr %0) #2 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %p.lastiter = alloca i32, align 4
  %p.lowerbound = alloca i32, align 4
  %p.upperbound = alloca i32, align 4
  %p.stride = alloca i32, align 4
  %1 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %omp_loop.tripcount = call i32 @llvm.smax.i32(i32 %1, i32 0)
  store i32 0, ptr %p.lowerbound, align 4
  %2 = add nsw i32 %omp_loop.tripcount, -1
  store i32 %2, ptr %p.upperbound, align 4
  store i32 1, ptr %p.stride, align 4
  %omp_global_thread_num3 = call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  call void @__kmpc_for_static_init_4u(ptr nonnull @1, i32 %omp_global_thread_num3, i32 34, ptr nonnull %p.lastiter, ptr nonnull %p.lowerbound, ptr nonnull %p.upperbound, ptr nonnull %p.stride, i32 1, i32 0)
  %3 = load i32, ptr %p.lowerbound, align 4
  %4 = load i32, ptr %p.upperbound, align 4
  %5 = sub i32 %4, %3
  %6 = add i32 %5, 1
  br label %omp_loop.header

omp_loop.header:                                  ; preds = %omp_loop.body, %omp.par.entry
  %omp_loop.iv = phi i32 [ 0, %omp.par.entry ], [ %omp_loop.next, %omp_loop.body ]
  %omp_loop.cmp = icmp ult i32 %omp_loop.iv, %6
  br i1 %omp_loop.cmp, label %omp_loop.body, label %omp_loop.exit

omp_loop.exit:                                    ; preds = %omp_loop.header
  call void @__kmpc_for_static_fini(ptr nonnull @1, i32 %omp_global_thread_num3)
  %omp_global_thread_num4 = call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  call void @__kmpc_barrier(ptr nonnull @2, i32 %omp_global_thread_num4)
  ret void

omp_loop.body:                                    ; preds = %omp_loop.header
  %7 = add i32 %omp_loop.iv, %3
  %8 = add i32 %7, 1
  %9 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %10 = sitofp i32 %9 to float
  %11 = fdiv contract float 1.000000e+00, %10
  %12 = fpext float %11 to double
  %.unpack = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  %.unpack3 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  %.unpack4 = load i32, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  %.unpack5 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  %.unpack6 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  %.unpack7 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  %.unpack8 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  %.unpack9.unpack.unpack = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  %.unpack9.unpack.unpack11 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  %.unpack9.unpack.unpack12 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  store ptr %.unpack, ptr %loadgep_2, align 8, !tbaa !8
  %loadgep_2.repack14 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  store i64 %.unpack3, ptr %loadgep_2.repack14, align 8, !tbaa !8
  %loadgep_2.repack16 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  store i32 %.unpack4, ptr %loadgep_2.repack16, align 8, !tbaa !8
  %loadgep_2.repack18 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  store i8 %.unpack5, ptr %loadgep_2.repack18, align 4, !tbaa !8
  %loadgep_2.repack20 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  store i8 %.unpack6, ptr %loadgep_2.repack20, align 1, !tbaa !8
  %loadgep_2.repack22 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  store i8 %.unpack7, ptr %loadgep_2.repack22, align 2, !tbaa !8
  %loadgep_2.repack24 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  store i8 %.unpack8, ptr %loadgep_2.repack24, align 1, !tbaa !8
  %loadgep_2.repack26 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  store i64 %.unpack9.unpack.unpack, ptr %loadgep_2.repack26, align 8, !tbaa !8
  %loadgep_2.repack26.repack28 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack9.unpack.unpack11, ptr %loadgep_2.repack26.repack28, align 8, !tbaa !8
  %loadgep_2.repack26.repack30 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  store i64 %.unpack9.unpack.unpack12, ptr %loadgep_2.repack26.repack30, align 8, !tbaa !8
  %13 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 0
  %14 = load i64, ptr %13, align 8, !tbaa !8
  %15 = load ptr, ptr %loadgep_2, align 8, !tbaa !8
  %16 = sext i32 %8 to i64
  %17 = sub i64 %16, %14
  %18 = getelementptr double, ptr %15, i64 %17
  store double %12, ptr %18, align 8, !tbaa !4
  %omp_loop.next = add nuw i32 %omp_loop.iv, 1
  br label %omp_loop.header
}

declare ptr @_FortranAioBeginExternalFormattedOutput(ptr, i64, ptr, i32, ptr, i32) local_unnamed_addr

declare zeroext i1 @_FortranAioOutputAscii(ptr, ptr, i64) local_unnamed_addr

declare zeroext i1 @_FortranAioOutputInteger32(ptr, i32) local_unnamed_addr

declare zeroext i1 @_FortranAioOutputReal64(ptr, double) local_unnamed_addr

declare i32 @_FortranAioEndIoStatement(ptr) local_unnamed_addr

; Function Attrs: nounwind
declare i32 @__kmpc_global_thread_num(ptr) local_unnamed_addr #3

; Function Attrs: nounwind
declare void @__kmpc_for_static_init_4u(ptr, i32, i32, ptr, ptr, ptr, ptr, i32, i32) local_unnamed_addr #3

; Function Attrs: nounwind
declare void @__kmpc_for_static_fini(ptr, i32) local_unnamed_addr #3

; Function Attrs: convergent nounwind
declare void @__kmpc_barrier(ptr, i32) local_unnamed_addr #4

; Function Attrs: nounwind
declare !callback !10 void @__kmpc_fork_call(ptr, i32, ptr, ...) local_unnamed_addr #3

; Function Attrs: nocallback nofree nosync nounwind speculatable willreturn memory(none)
declare i32 @llvm.smax.i32(i32, i32) #5

attributes #0 = { mustprogress nofree nounwind willreturn allockind("alloc,uninitialized") allocsize(0) memory(inaccessiblemem: readwrite) "alloc-family"="malloc" }
attributes #1 = { mustprogress nounwind willreturn allockind("free") memory(argmem: readwrite, inaccessiblemem: readwrite) "alloc-family"="malloc" }
attributes #2 = { norecurse nounwind }
attributes #3 = { nounwind }
attributes #4 = { convergent nounwind }
attributes #5 = { nocallback nofree nosync nounwind speculatable willreturn memory(none) }

!llvm.module.flags = !{!0, !1, !2, !3}

!0 = !{i32 2, !"Debug Info Version", i32 3}
!1 = !{i32 7, !"openmp", i32 11}
!2 = !{i32 8, !"PIC Level", i32 2}
!3 = !{i32 7, !"PIE Level", i32 2}
!4 = !{!5, !5, i64 0}
!5 = !{!"any data access", !6, i64 0}
!6 = !{!"any access", !7, i64 0}
!7 = !{!"Flang Type TBAA Root"}
!8 = !{!9, !9, i64 0}
!9 = !{!"descriptor member", !6, i64 0}
!10 = !{!11}
!11 = !{i64 2, i64 -1, i64 -1, i1 true}
*** IR Dump After InvalidateAnalysisPass<llvm::AAManager> on _QQmain ***
define void @_QQmain() local_unnamed_addr {
entry:
  %structArg = alloca { ptr, ptr }, align 8
  %0 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %1 = alloca i32, align 4
  store i32 1048576, ptr %1, align 4, !tbaa !4
  %2 = call dereferenceable_or_null(8388608) ptr @malloc(i64 8388608)
  store ptr %2, ptr @_QFEarr, align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  store i32 20180515, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  store i8 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  store i8 28, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  store i8 2, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  store i8 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  store i64 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  store i64 1048576, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  %omp_global_thread_num = call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %1, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %0, ptr %gep_5, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QQmain..omp_par, ptr nonnull %structArg)
  %3 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.68815510185ede6107d6524e77abf791, i32 19)
  %4 = call i1 @_FortranAioOutputAscii(ptr %3, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %5 = load i32, ptr %1, align 4, !tbaa !4
  %6 = call i1 @_FortranAioOutputInteger32(ptr %3, i32 %5)
  %7 = call i1 @_FortranAioOutputAscii(ptr %3, ptr nonnull @_QQcl.2920697320, i64 5)
  %.unpack = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  %.unpack95.unpack.unpack = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  %8 = sub i64 1, %.unpack95.unpack.unpack
  %9 = getelementptr double, ptr %.unpack, i64 %8
  %10 = load double, ptr %9, align 8, !tbaa !4
  %11 = load i32, ptr %1, align 4, !tbaa !4
  %12 = sext i32 %11 to i64
  %13 = sub i64 %12, %.unpack95.unpack.unpack
  %14 = getelementptr double, ptr %.unpack, i64 %13
  %15 = load double, ptr %14, align 8, !tbaa !4
  %16 = fadd contract double %10, %15
  %17 = call i1 @_FortranAioOutputReal64(ptr %3, double %16)
  %18 = call i32 @_FortranAioEndIoStatement(ptr %3)
  %.unpack100 = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  call void @free(ptr %.unpack100)
  store ptr null, ptr @_QFEarr, align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  store i32 20180515, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  store i8 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  store i8 28, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  store i8 2, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  store i8 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  store i64 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  store i64 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  ret void
}
*** IR Dump After InvalidateAnalysisPass<llvm::AAManager> on _QQmain..omp_par ***
; Function Attrs: norecurse nounwind
define internal void @_QQmain..omp_par(ptr noalias %tid.addr, ptr noalias %zero.addr, ptr %0) #2 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %p.lastiter = alloca i32, align 4
  %p.lowerbound = alloca i32, align 4
  %p.upperbound = alloca i32, align 4
  %p.stride = alloca i32, align 4
  %1 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %omp_loop.tripcount = call i32 @llvm.smax.i32(i32 %1, i32 0)
  store i32 0, ptr %p.lowerbound, align 4
  %2 = add nsw i32 %omp_loop.tripcount, -1
  store i32 %2, ptr %p.upperbound, align 4
  store i32 1, ptr %p.stride, align 4
  %omp_global_thread_num3 = call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  call void @__kmpc_for_static_init_4u(ptr nonnull @1, i32 %omp_global_thread_num3, i32 34, ptr nonnull %p.lastiter, ptr nonnull %p.lowerbound, ptr nonnull %p.upperbound, ptr nonnull %p.stride, i32 1, i32 0)
  %3 = load i32, ptr %p.lowerbound, align 4
  %4 = load i32, ptr %p.upperbound, align 4
  %5 = sub i32 %4, %3
  %6 = add i32 %5, 1
  br label %omp_loop.header

omp_loop.header:                                  ; preds = %omp_loop.body, %omp.par.entry
  %omp_loop.iv = phi i32 [ 0, %omp.par.entry ], [ %omp_loop.next, %omp_loop.body ]
  %omp_loop.cmp = icmp ult i32 %omp_loop.iv, %6
  br i1 %omp_loop.cmp, label %omp_loop.body, label %omp_loop.exit

omp_loop.exit:                                    ; preds = %omp_loop.header
  call void @__kmpc_for_static_fini(ptr nonnull @1, i32 %omp_global_thread_num3)
  %omp_global_thread_num4 = call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  call void @__kmpc_barrier(ptr nonnull @2, i32 %omp_global_thread_num4)
  ret void

omp_loop.body:                                    ; preds = %omp_loop.header
  %7 = add i32 %omp_loop.iv, %3
  %8 = add i32 %7, 1
  %9 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %10 = sitofp i32 %9 to float
  %11 = fdiv contract float 1.000000e+00, %10
  %12 = fpext float %11 to double
  %.unpack = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  %.unpack3 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  %.unpack4 = load i32, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  %.unpack5 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  %.unpack6 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  %.unpack7 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  %.unpack8 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  %.unpack9.unpack.unpack = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  %.unpack9.unpack.unpack11 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  %.unpack9.unpack.unpack12 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  store ptr %.unpack, ptr %loadgep_2, align 8, !tbaa !8
  %loadgep_2.repack14 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  store i64 %.unpack3, ptr %loadgep_2.repack14, align 8, !tbaa !8
  %loadgep_2.repack16 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  store i32 %.unpack4, ptr %loadgep_2.repack16, align 8, !tbaa !8
  %loadgep_2.repack18 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  store i8 %.unpack5, ptr %loadgep_2.repack18, align 4, !tbaa !8
  %loadgep_2.repack20 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  store i8 %.unpack6, ptr %loadgep_2.repack20, align 1, !tbaa !8
  %loadgep_2.repack22 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  store i8 %.unpack7, ptr %loadgep_2.repack22, align 2, !tbaa !8
  %loadgep_2.repack24 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  store i8 %.unpack8, ptr %loadgep_2.repack24, align 1, !tbaa !8
  %loadgep_2.repack26 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  store i64 %.unpack9.unpack.unpack, ptr %loadgep_2.repack26, align 8, !tbaa !8
  %loadgep_2.repack26.repack28 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack9.unpack.unpack11, ptr %loadgep_2.repack26.repack28, align 8, !tbaa !8
  %loadgep_2.repack26.repack30 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  store i64 %.unpack9.unpack.unpack12, ptr %loadgep_2.repack26.repack30, align 8, !tbaa !8
  %13 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 0
  %14 = load i64, ptr %13, align 8, !tbaa !8
  %15 = load ptr, ptr %loadgep_2, align 8, !tbaa !8
  %16 = sext i32 %8 to i64
  %17 = sub i64 %16, %14
  %18 = getelementptr double, ptr %15, i64 %17
  store double %12, ptr %18, align 8, !tbaa !4
  %omp_loop.next = add nuw i32 %omp_loop.iv, 1
  br label %omp_loop.header
}
*** IR Dump After RequireAnalysisPass<llvm::ProfileSummaryAnalysis, llvm::Module> on [module] ***
; ModuleID = 'FIRModule'
source_filename = "FIRModule"
target datalayout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128"
target triple = "x86_64-unknown-linux-gnu"

%struct.ident_t = type { i32, i32, i32, i32, ptr }

@_QFEarr = internal unnamed_addr global { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } { ptr null, i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), i32 20180515, i8 1, i8 28, i8 2, i8 0, [1 x [3 x i64]] [[3 x i64] [i64 1, i64 0, i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64)]] }
@_QQcl.68815510185ede6107d6524e77abf791 = internal constant [52 x i8] c"/g/g92/rydahl1/flangtests/src/array_descriptors.f90\00"
@_QQcl.28612C69372C612C6531332E36653229 = internal constant [16 x i8] c"(a,i7,a,e13.6e2)"
@_QQcl.54686520726573756C74206F6620286172722831292B61727228 = internal constant [26 x i8] c"The result of (arr(1)+arr("
@_QQcl.2920697320 = internal constant [5 x i8] c") is "
@_QQEnvironmentDefaults = local_unnamed_addr constant ptr null
@0 = private unnamed_addr constant [23 x i8] c";unknown;unknown;0;0;;\00", align 1
@1 = private unnamed_addr constant %struct.ident_t { i32 0, i32 2, i32 0, i32 22, ptr @0 }, align 8
@2 = private unnamed_addr constant %struct.ident_t { i32 0, i32 66, i32 0, i32 22, ptr @0 }, align 8

; Function Attrs: mustprogress nofree nounwind willreturn allockind("alloc,uninitialized") allocsize(0) memory(inaccessiblemem: readwrite)
declare noalias noundef ptr @malloc(i64 noundef) local_unnamed_addr #0

; Function Attrs: mustprogress nounwind willreturn allockind("free") memory(argmem: readwrite, inaccessiblemem: readwrite)
declare void @free(ptr allocptr nocapture noundef) local_unnamed_addr #1

define void @_QQmain() local_unnamed_addr {
entry:
  %structArg = alloca { ptr, ptr }, align 8
  %0 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %1 = alloca i32, align 4
  store i32 1048576, ptr %1, align 4, !tbaa !4
  %2 = call dereferenceable_or_null(8388608) ptr @malloc(i64 8388608)
  store ptr %2, ptr @_QFEarr, align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  store i32 20180515, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  store i8 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  store i8 28, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  store i8 2, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  store i8 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  store i64 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  store i64 1048576, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  %omp_global_thread_num = call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %1, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %0, ptr %gep_5, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QQmain..omp_par, ptr nonnull %structArg)
  %3 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.68815510185ede6107d6524e77abf791, i32 19)
  %4 = call i1 @_FortranAioOutputAscii(ptr %3, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %5 = load i32, ptr %1, align 4, !tbaa !4
  %6 = call i1 @_FortranAioOutputInteger32(ptr %3, i32 %5)
  %7 = call i1 @_FortranAioOutputAscii(ptr %3, ptr nonnull @_QQcl.2920697320, i64 5)
  %.unpack = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  %.unpack95.unpack.unpack = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  %8 = sub i64 1, %.unpack95.unpack.unpack
  %9 = getelementptr double, ptr %.unpack, i64 %8
  %10 = load double, ptr %9, align 8, !tbaa !4
  %11 = load i32, ptr %1, align 4, !tbaa !4
  %12 = sext i32 %11 to i64
  %13 = sub i64 %12, %.unpack95.unpack.unpack
  %14 = getelementptr double, ptr %.unpack, i64 %13
  %15 = load double, ptr %14, align 8, !tbaa !4
  %16 = fadd contract double %10, %15
  %17 = call i1 @_FortranAioOutputReal64(ptr %3, double %16)
  %18 = call i32 @_FortranAioEndIoStatement(ptr %3)
  %.unpack100 = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  call void @free(ptr %.unpack100)
  store ptr null, ptr @_QFEarr, align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  store i32 20180515, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  store i8 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  store i8 28, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  store i8 2, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  store i8 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  store i64 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  store i64 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  ret void
}

; Function Attrs: norecurse nounwind
define internal void @_QQmain..omp_par(ptr noalias %tid.addr, ptr noalias %zero.addr, ptr %0) #2 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %p.lastiter = alloca i32, align 4
  %p.lowerbound = alloca i32, align 4
  %p.upperbound = alloca i32, align 4
  %p.stride = alloca i32, align 4
  %1 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %omp_loop.tripcount = call i32 @llvm.smax.i32(i32 %1, i32 0)
  store i32 0, ptr %p.lowerbound, align 4
  %2 = add nsw i32 %omp_loop.tripcount, -1
  store i32 %2, ptr %p.upperbound, align 4
  store i32 1, ptr %p.stride, align 4
  %omp_global_thread_num3 = call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  call void @__kmpc_for_static_init_4u(ptr nonnull @1, i32 %omp_global_thread_num3, i32 34, ptr nonnull %p.lastiter, ptr nonnull %p.lowerbound, ptr nonnull %p.upperbound, ptr nonnull %p.stride, i32 1, i32 0)
  %3 = load i32, ptr %p.lowerbound, align 4
  %4 = load i32, ptr %p.upperbound, align 4
  %5 = sub i32 %4, %3
  %6 = add i32 %5, 1
  br label %omp_loop.header

omp_loop.header:                                  ; preds = %omp_loop.body, %omp.par.entry
  %omp_loop.iv = phi i32 [ 0, %omp.par.entry ], [ %omp_loop.next, %omp_loop.body ]
  %omp_loop.cmp = icmp ult i32 %omp_loop.iv, %6
  br i1 %omp_loop.cmp, label %omp_loop.body, label %omp_loop.exit

omp_loop.exit:                                    ; preds = %omp_loop.header
  call void @__kmpc_for_static_fini(ptr nonnull @1, i32 %omp_global_thread_num3)
  %omp_global_thread_num4 = call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  call void @__kmpc_barrier(ptr nonnull @2, i32 %omp_global_thread_num4)
  ret void

omp_loop.body:                                    ; preds = %omp_loop.header
  %7 = add i32 %omp_loop.iv, %3
  %8 = add i32 %7, 1
  %9 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %10 = sitofp i32 %9 to float
  %11 = fdiv contract float 1.000000e+00, %10
  %12 = fpext float %11 to double
  %.unpack = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  %.unpack3 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  %.unpack4 = load i32, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  %.unpack5 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  %.unpack6 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  %.unpack7 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  %.unpack8 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  %.unpack9.unpack.unpack = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  %.unpack9.unpack.unpack11 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  %.unpack9.unpack.unpack12 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  store ptr %.unpack, ptr %loadgep_2, align 8, !tbaa !8
  %loadgep_2.repack14 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  store i64 %.unpack3, ptr %loadgep_2.repack14, align 8, !tbaa !8
  %loadgep_2.repack16 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  store i32 %.unpack4, ptr %loadgep_2.repack16, align 8, !tbaa !8
  %loadgep_2.repack18 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  store i8 %.unpack5, ptr %loadgep_2.repack18, align 4, !tbaa !8
  %loadgep_2.repack20 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  store i8 %.unpack6, ptr %loadgep_2.repack20, align 1, !tbaa !8
  %loadgep_2.repack22 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  store i8 %.unpack7, ptr %loadgep_2.repack22, align 2, !tbaa !8
  %loadgep_2.repack24 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  store i8 %.unpack8, ptr %loadgep_2.repack24, align 1, !tbaa !8
  %loadgep_2.repack26 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  store i64 %.unpack9.unpack.unpack, ptr %loadgep_2.repack26, align 8, !tbaa !8
  %loadgep_2.repack26.repack28 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack9.unpack.unpack11, ptr %loadgep_2.repack26.repack28, align 8, !tbaa !8
  %loadgep_2.repack26.repack30 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  store i64 %.unpack9.unpack.unpack12, ptr %loadgep_2.repack26.repack30, align 8, !tbaa !8
  %13 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 0
  %14 = load i64, ptr %13, align 8, !tbaa !8
  %15 = load ptr, ptr %loadgep_2, align 8, !tbaa !8
  %16 = sext i32 %8 to i64
  %17 = sub i64 %16, %14
  %18 = getelementptr double, ptr %15, i64 %17
  store double %12, ptr %18, align 8, !tbaa !4
  %omp_loop.next = add nuw i32 %omp_loop.iv, 1
  br label %omp_loop.header
}

declare ptr @_FortranAioBeginExternalFormattedOutput(ptr, i64, ptr, i32, ptr, i32) local_unnamed_addr

declare zeroext i1 @_FortranAioOutputAscii(ptr, ptr, i64) local_unnamed_addr

declare zeroext i1 @_FortranAioOutputInteger32(ptr, i32) local_unnamed_addr

declare zeroext i1 @_FortranAioOutputReal64(ptr, double) local_unnamed_addr

declare i32 @_FortranAioEndIoStatement(ptr) local_unnamed_addr

; Function Attrs: nounwind
declare i32 @__kmpc_global_thread_num(ptr) local_unnamed_addr #3

; Function Attrs: nounwind
declare void @__kmpc_for_static_init_4u(ptr, i32, i32, ptr, ptr, ptr, ptr, i32, i32) local_unnamed_addr #3

; Function Attrs: nounwind
declare void @__kmpc_for_static_fini(ptr, i32) local_unnamed_addr #3

; Function Attrs: convergent nounwind
declare void @__kmpc_barrier(ptr, i32) local_unnamed_addr #4

; Function Attrs: nounwind
declare !callback !10 void @__kmpc_fork_call(ptr, i32, ptr, ...) local_unnamed_addr #3

; Function Attrs: nocallback nofree nosync nounwind speculatable willreturn memory(none)
declare i32 @llvm.smax.i32(i32, i32) #5

attributes #0 = { mustprogress nofree nounwind willreturn allockind("alloc,uninitialized") allocsize(0) memory(inaccessiblemem: readwrite) "alloc-family"="malloc" }
attributes #1 = { mustprogress nounwind willreturn allockind("free") memory(argmem: readwrite, inaccessiblemem: readwrite) "alloc-family"="malloc" }
attributes #2 = { norecurse nounwind }
attributes #3 = { nounwind }
attributes #4 = { convergent nounwind }
attributes #5 = { nocallback nofree nosync nounwind speculatable willreturn memory(none) }

!llvm.module.flags = !{!0, !1, !2, !3}

!0 = !{i32 2, !"Debug Info Version", i32 3}
!1 = !{i32 7, !"openmp", i32 11}
!2 = !{i32 8, !"PIC Level", i32 2}
!3 = !{i32 7, !"PIE Level", i32 2}
!4 = !{!5, !5, i64 0}
!5 = !{!"any data access", !6, i64 0}
!6 = !{!"any access", !7, i64 0}
!7 = !{!"Flang Type TBAA Root"}
!8 = !{!9, !9, i64 0}
!9 = !{!"descriptor member", !6, i64 0}
!10 = !{!11}
!11 = !{i64 2, i64 -1, i64 -1, i1 true}
*** IR Dump After InlinerPass on (_QQmain..omp_par) ***
; Function Attrs: norecurse nounwind
define internal void @_QQmain..omp_par(ptr noalias %tid.addr, ptr noalias %zero.addr, ptr %0) #2 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %p.lastiter = alloca i32, align 4
  %p.lowerbound = alloca i32, align 4
  %p.upperbound = alloca i32, align 4
  %p.stride = alloca i32, align 4
  %1 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %omp_loop.tripcount = call i32 @llvm.smax.i32(i32 %1, i32 0)
  store i32 0, ptr %p.lowerbound, align 4
  %2 = add nsw i32 %omp_loop.tripcount, -1
  store i32 %2, ptr %p.upperbound, align 4
  store i32 1, ptr %p.stride, align 4
  %omp_global_thread_num3 = call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  call void @__kmpc_for_static_init_4u(ptr nonnull @1, i32 %omp_global_thread_num3, i32 34, ptr nonnull %p.lastiter, ptr nonnull %p.lowerbound, ptr nonnull %p.upperbound, ptr nonnull %p.stride, i32 1, i32 0)
  %3 = load i32, ptr %p.lowerbound, align 4
  %4 = load i32, ptr %p.upperbound, align 4
  %5 = sub i32 %4, %3
  %6 = add i32 %5, 1
  br label %omp_loop.header

omp_loop.header:                                  ; preds = %omp_loop.body, %omp.par.entry
  %omp_loop.iv = phi i32 [ 0, %omp.par.entry ], [ %omp_loop.next, %omp_loop.body ]
  %omp_loop.cmp = icmp ult i32 %omp_loop.iv, %6
  br i1 %omp_loop.cmp, label %omp_loop.body, label %omp_loop.exit

omp_loop.exit:                                    ; preds = %omp_loop.header
  call void @__kmpc_for_static_fini(ptr nonnull @1, i32 %omp_global_thread_num3)
  %omp_global_thread_num4 = call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  call void @__kmpc_barrier(ptr nonnull @2, i32 %omp_global_thread_num4)
  ret void

omp_loop.body:                                    ; preds = %omp_loop.header
  %7 = add i32 %omp_loop.iv, %3
  %8 = add i32 %7, 1
  %9 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %10 = sitofp i32 %9 to float
  %11 = fdiv contract float 1.000000e+00, %10
  %12 = fpext float %11 to double
  %.unpack = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  %.unpack3 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  %.unpack4 = load i32, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  %.unpack5 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  %.unpack6 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  %.unpack7 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  %.unpack8 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  %.unpack9.unpack.unpack = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  %.unpack9.unpack.unpack11 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  %.unpack9.unpack.unpack12 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  store ptr %.unpack, ptr %loadgep_2, align 8, !tbaa !8
  %loadgep_2.repack14 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  store i64 %.unpack3, ptr %loadgep_2.repack14, align 8, !tbaa !8
  %loadgep_2.repack16 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  store i32 %.unpack4, ptr %loadgep_2.repack16, align 8, !tbaa !8
  %loadgep_2.repack18 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  store i8 %.unpack5, ptr %loadgep_2.repack18, align 4, !tbaa !8
  %loadgep_2.repack20 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  store i8 %.unpack6, ptr %loadgep_2.repack20, align 1, !tbaa !8
  %loadgep_2.repack22 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  store i8 %.unpack7, ptr %loadgep_2.repack22, align 2, !tbaa !8
  %loadgep_2.repack24 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  store i8 %.unpack8, ptr %loadgep_2.repack24, align 1, !tbaa !8
  %loadgep_2.repack26 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  store i64 %.unpack9.unpack.unpack, ptr %loadgep_2.repack26, align 8, !tbaa !8
  %loadgep_2.repack26.repack28 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack9.unpack.unpack11, ptr %loadgep_2.repack26.repack28, align 8, !tbaa !8
  %loadgep_2.repack26.repack30 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  store i64 %.unpack9.unpack.unpack12, ptr %loadgep_2.repack26.repack30, align 8, !tbaa !8
  %13 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 0
  %14 = load i64, ptr %13, align 8, !tbaa !8
  %15 = load ptr, ptr %loadgep_2, align 8, !tbaa !8
  %16 = sext i32 %8 to i64
  %17 = sub i64 %16, %14
  %18 = getelementptr double, ptr %15, i64 %17
  store double %12, ptr %18, align 8, !tbaa !4
  %omp_loop.next = add nuw i32 %omp_loop.iv, 1
  br label %omp_loop.header
}
*** IR Dump After InlinerPass on (_QQmain..omp_par) ***
; Function Attrs: norecurse nounwind
define internal void @_QQmain..omp_par(ptr noalias %tid.addr, ptr noalias %zero.addr, ptr %0) #2 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %p.lastiter = alloca i32, align 4
  %p.lowerbound = alloca i32, align 4
  %p.upperbound = alloca i32, align 4
  %p.stride = alloca i32, align 4
  %1 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %omp_loop.tripcount = call i32 @llvm.smax.i32(i32 %1, i32 0)
  store i32 0, ptr %p.lowerbound, align 4
  %2 = add nsw i32 %omp_loop.tripcount, -1
  store i32 %2, ptr %p.upperbound, align 4
  store i32 1, ptr %p.stride, align 4
  %omp_global_thread_num3 = call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  call void @__kmpc_for_static_init_4u(ptr nonnull @1, i32 %omp_global_thread_num3, i32 34, ptr nonnull %p.lastiter, ptr nonnull %p.lowerbound, ptr nonnull %p.upperbound, ptr nonnull %p.stride, i32 1, i32 0)
  %3 = load i32, ptr %p.lowerbound, align 4
  %4 = load i32, ptr %p.upperbound, align 4
  %5 = sub i32 %4, %3
  %6 = add i32 %5, 1
  br label %omp_loop.header

omp_loop.header:                                  ; preds = %omp_loop.body, %omp.par.entry
  %omp_loop.iv = phi i32 [ 0, %omp.par.entry ], [ %omp_loop.next, %omp_loop.body ]
  %omp_loop.cmp = icmp ult i32 %omp_loop.iv, %6
  br i1 %omp_loop.cmp, label %omp_loop.body, label %omp_loop.exit

omp_loop.exit:                                    ; preds = %omp_loop.header
  call void @__kmpc_for_static_fini(ptr nonnull @1, i32 %omp_global_thread_num3)
  %omp_global_thread_num4 = call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  call void @__kmpc_barrier(ptr nonnull @2, i32 %omp_global_thread_num4)
  ret void

omp_loop.body:                                    ; preds = %omp_loop.header
  %7 = add i32 %omp_loop.iv, %3
  %8 = add i32 %7, 1
  %9 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %10 = sitofp i32 %9 to float
  %11 = fdiv contract float 1.000000e+00, %10
  %12 = fpext float %11 to double
  %.unpack = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  %.unpack3 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  %.unpack4 = load i32, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  %.unpack5 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  %.unpack6 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  %.unpack7 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  %.unpack8 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  %.unpack9.unpack.unpack = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  %.unpack9.unpack.unpack11 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  %.unpack9.unpack.unpack12 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  store ptr %.unpack, ptr %loadgep_2, align 8, !tbaa !8
  %loadgep_2.repack14 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  store i64 %.unpack3, ptr %loadgep_2.repack14, align 8, !tbaa !8
  %loadgep_2.repack16 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  store i32 %.unpack4, ptr %loadgep_2.repack16, align 8, !tbaa !8
  %loadgep_2.repack18 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  store i8 %.unpack5, ptr %loadgep_2.repack18, align 4, !tbaa !8
  %loadgep_2.repack20 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  store i8 %.unpack6, ptr %loadgep_2.repack20, align 1, !tbaa !8
  %loadgep_2.repack22 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  store i8 %.unpack7, ptr %loadgep_2.repack22, align 2, !tbaa !8
  %loadgep_2.repack24 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  store i8 %.unpack8, ptr %loadgep_2.repack24, align 1, !tbaa !8
  %loadgep_2.repack26 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  store i64 %.unpack9.unpack.unpack, ptr %loadgep_2.repack26, align 8, !tbaa !8
  %loadgep_2.repack26.repack28 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack9.unpack.unpack11, ptr %loadgep_2.repack26.repack28, align 8, !tbaa !8
  %loadgep_2.repack26.repack30 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  store i64 %.unpack9.unpack.unpack12, ptr %loadgep_2.repack26.repack30, align 8, !tbaa !8
  %13 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 0
  %14 = load i64, ptr %13, align 8, !tbaa !8
  %15 = load ptr, ptr %loadgep_2, align 8, !tbaa !8
  %16 = sext i32 %8 to i64
  %17 = sub i64 %16, %14
  %18 = getelementptr double, ptr %15, i64 %17
  store double %12, ptr %18, align 8, !tbaa !4
  %omp_loop.next = add nuw i32 %omp_loop.iv, 1
  br label %omp_loop.header
}
*** IR Dump After PostOrderFunctionAttrsPass on (_QQmain..omp_par) ***
; Function Attrs: norecurse nounwind
define internal void @_QQmain..omp_par(ptr noalias %tid.addr, ptr noalias %zero.addr, ptr %0) #2 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %p.lastiter = alloca i32, align 4
  %p.lowerbound = alloca i32, align 4
  %p.upperbound = alloca i32, align 4
  %p.stride = alloca i32, align 4
  %1 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %omp_loop.tripcount = call i32 @llvm.smax.i32(i32 %1, i32 0)
  store i32 0, ptr %p.lowerbound, align 4
  %2 = add nsw i32 %omp_loop.tripcount, -1
  store i32 %2, ptr %p.upperbound, align 4
  store i32 1, ptr %p.stride, align 4
  %omp_global_thread_num3 = call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  call void @__kmpc_for_static_init_4u(ptr nonnull @1, i32 %omp_global_thread_num3, i32 34, ptr nonnull %p.lastiter, ptr nonnull %p.lowerbound, ptr nonnull %p.upperbound, ptr nonnull %p.stride, i32 1, i32 0)
  %3 = load i32, ptr %p.lowerbound, align 4
  %4 = load i32, ptr %p.upperbound, align 4
  %5 = sub i32 %4, %3
  %6 = add i32 %5, 1
  br label %omp_loop.header

omp_loop.header:                                  ; preds = %omp_loop.body, %omp.par.entry
  %omp_loop.iv = phi i32 [ 0, %omp.par.entry ], [ %omp_loop.next, %omp_loop.body ]
  %omp_loop.cmp = icmp ult i32 %omp_loop.iv, %6
  br i1 %omp_loop.cmp, label %omp_loop.body, label %omp_loop.exit

omp_loop.exit:                                    ; preds = %omp_loop.header
  call void @__kmpc_for_static_fini(ptr nonnull @1, i32 %omp_global_thread_num3)
  %omp_global_thread_num4 = call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  call void @__kmpc_barrier(ptr nonnull @2, i32 %omp_global_thread_num4)
  ret void

omp_loop.body:                                    ; preds = %omp_loop.header
  %7 = add i32 %omp_loop.iv, %3
  %8 = add i32 %7, 1
  %9 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %10 = sitofp i32 %9 to float
  %11 = fdiv contract float 1.000000e+00, %10
  %12 = fpext float %11 to double
  %.unpack = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  %.unpack3 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  %.unpack4 = load i32, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  %.unpack5 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  %.unpack6 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  %.unpack7 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  %.unpack8 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  %.unpack9.unpack.unpack = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  %.unpack9.unpack.unpack11 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  %.unpack9.unpack.unpack12 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  store ptr %.unpack, ptr %loadgep_2, align 8, !tbaa !8
  %loadgep_2.repack14 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  store i64 %.unpack3, ptr %loadgep_2.repack14, align 8, !tbaa !8
  %loadgep_2.repack16 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  store i32 %.unpack4, ptr %loadgep_2.repack16, align 8, !tbaa !8
  %loadgep_2.repack18 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  store i8 %.unpack5, ptr %loadgep_2.repack18, align 4, !tbaa !8
  %loadgep_2.repack20 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  store i8 %.unpack6, ptr %loadgep_2.repack20, align 1, !tbaa !8
  %loadgep_2.repack22 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  store i8 %.unpack7, ptr %loadgep_2.repack22, align 2, !tbaa !8
  %loadgep_2.repack24 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  store i8 %.unpack8, ptr %loadgep_2.repack24, align 1, !tbaa !8
  %loadgep_2.repack26 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  store i64 %.unpack9.unpack.unpack, ptr %loadgep_2.repack26, align 8, !tbaa !8
  %loadgep_2.repack26.repack28 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack9.unpack.unpack11, ptr %loadgep_2.repack26.repack28, align 8, !tbaa !8
  %loadgep_2.repack26.repack30 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  store i64 %.unpack9.unpack.unpack12, ptr %loadgep_2.repack26.repack30, align 8, !tbaa !8
  %13 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 0
  %14 = load i64, ptr %13, align 8, !tbaa !8
  %15 = load ptr, ptr %loadgep_2, align 8, !tbaa !8
  %16 = sext i32 %8 to i64
  %17 = sub i64 %16, %14
  %18 = getelementptr double, ptr %15, i64 %17
  store double %12, ptr %18, align 8, !tbaa !4
  %omp_loop.next = add nuw i32 %omp_loop.iv, 1
  br label %omp_loop.header
}
*** IR Dump After ArgumentPromotionPass on (_QQmain..omp_par) ***
; Function Attrs: norecurse nounwind
define internal void @_QQmain..omp_par(ptr noalias %tid.addr, ptr noalias %zero.addr, ptr %0) #2 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %p.lastiter = alloca i32, align 4
  %p.lowerbound = alloca i32, align 4
  %p.upperbound = alloca i32, align 4
  %p.stride = alloca i32, align 4
  %1 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %omp_loop.tripcount = call i32 @llvm.smax.i32(i32 %1, i32 0)
  store i32 0, ptr %p.lowerbound, align 4
  %2 = add nsw i32 %omp_loop.tripcount, -1
  store i32 %2, ptr %p.upperbound, align 4
  store i32 1, ptr %p.stride, align 4
  %omp_global_thread_num3 = call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  call void @__kmpc_for_static_init_4u(ptr nonnull @1, i32 %omp_global_thread_num3, i32 34, ptr nonnull %p.lastiter, ptr nonnull %p.lowerbound, ptr nonnull %p.upperbound, ptr nonnull %p.stride, i32 1, i32 0)
  %3 = load i32, ptr %p.lowerbound, align 4
  %4 = load i32, ptr %p.upperbound, align 4
  %5 = sub i32 %4, %3
  %6 = add i32 %5, 1
  br label %omp_loop.header

omp_loop.header:                                  ; preds = %omp_loop.body, %omp.par.entry
  %omp_loop.iv = phi i32 [ 0, %omp.par.entry ], [ %omp_loop.next, %omp_loop.body ]
  %omp_loop.cmp = icmp ult i32 %omp_loop.iv, %6
  br i1 %omp_loop.cmp, label %omp_loop.body, label %omp_loop.exit

omp_loop.exit:                                    ; preds = %omp_loop.header
  call void @__kmpc_for_static_fini(ptr nonnull @1, i32 %omp_global_thread_num3)
  %omp_global_thread_num4 = call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  call void @__kmpc_barrier(ptr nonnull @2, i32 %omp_global_thread_num4)
  ret void

omp_loop.body:                                    ; preds = %omp_loop.header
  %7 = add i32 %omp_loop.iv, %3
  %8 = add i32 %7, 1
  %9 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %10 = sitofp i32 %9 to float
  %11 = fdiv contract float 1.000000e+00, %10
  %12 = fpext float %11 to double
  %.unpack = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  %.unpack3 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  %.unpack4 = load i32, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  %.unpack5 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  %.unpack6 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  %.unpack7 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  %.unpack8 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  %.unpack9.unpack.unpack = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  %.unpack9.unpack.unpack11 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  %.unpack9.unpack.unpack12 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  store ptr %.unpack, ptr %loadgep_2, align 8, !tbaa !8
  %loadgep_2.repack14 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  store i64 %.unpack3, ptr %loadgep_2.repack14, align 8, !tbaa !8
  %loadgep_2.repack16 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  store i32 %.unpack4, ptr %loadgep_2.repack16, align 8, !tbaa !8
  %loadgep_2.repack18 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  store i8 %.unpack5, ptr %loadgep_2.repack18, align 4, !tbaa !8
  %loadgep_2.repack20 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  store i8 %.unpack6, ptr %loadgep_2.repack20, align 1, !tbaa !8
  %loadgep_2.repack22 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  store i8 %.unpack7, ptr %loadgep_2.repack22, align 2, !tbaa !8
  %loadgep_2.repack24 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  store i8 %.unpack8, ptr %loadgep_2.repack24, align 1, !tbaa !8
  %loadgep_2.repack26 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  store i64 %.unpack9.unpack.unpack, ptr %loadgep_2.repack26, align 8, !tbaa !8
  %loadgep_2.repack26.repack28 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack9.unpack.unpack11, ptr %loadgep_2.repack26.repack28, align 8, !tbaa !8
  %loadgep_2.repack26.repack30 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  store i64 %.unpack9.unpack.unpack12, ptr %loadgep_2.repack26.repack30, align 8, !tbaa !8
  %13 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 0
  %14 = load i64, ptr %13, align 8, !tbaa !8
  %15 = load ptr, ptr %loadgep_2, align 8, !tbaa !8
  %16 = sext i32 %8 to i64
  %17 = sub i64 %16, %14
  %18 = getelementptr double, ptr %15, i64 %17
  store double %12, ptr %18, align 8, !tbaa !4
  %omp_loop.next = add nuw i32 %omp_loop.iv, 1
  br label %omp_loop.header
}
*** IR Dump After OpenMPOptCGSCCPass on (_QQmain..omp_par) ***
; Function Attrs: norecurse nounwind
define internal void @_QQmain..omp_par(ptr noalias %tid.addr, ptr noalias %zero.addr, ptr %0) #2 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %p.lastiter = alloca i32, align 4
  %p.lowerbound = alloca i32, align 4
  %p.upperbound = alloca i32, align 4
  %p.stride = alloca i32, align 4
  %1 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %omp_loop.tripcount = call i32 @llvm.smax.i32(i32 %1, i32 0)
  store i32 0, ptr %p.lowerbound, align 4
  %2 = add nsw i32 %omp_loop.tripcount, -1
  store i32 %2, ptr %p.upperbound, align 4
  store i32 1, ptr %p.stride, align 4
  %omp_global_thread_num4 = call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  call void @__kmpc_for_static_init_4u(ptr nonnull @1, i32 %omp_global_thread_num4, i32 34, ptr nonnull %p.lastiter, ptr nonnull %p.lowerbound, ptr nonnull %p.upperbound, ptr nonnull %p.stride, i32 1, i32 0)
  %3 = load i32, ptr %p.lowerbound, align 4
  %4 = load i32, ptr %p.upperbound, align 4
  %5 = sub i32 %4, %3
  %6 = add i32 %5, 1
  br label %omp_loop.header

omp_loop.header:                                  ; preds = %omp_loop.body, %omp.par.entry
  %omp_loop.iv = phi i32 [ 0, %omp.par.entry ], [ %omp_loop.next, %omp_loop.body ]
  %omp_loop.cmp = icmp ult i32 %omp_loop.iv, %6
  br i1 %omp_loop.cmp, label %omp_loop.body, label %omp_loop.exit

omp_loop.exit:                                    ; preds = %omp_loop.header
  call void @__kmpc_for_static_fini(ptr nonnull @1, i32 %omp_global_thread_num4)
  call void @__kmpc_barrier(ptr nonnull @2, i32 %omp_global_thread_num4)
  ret void

omp_loop.body:                                    ; preds = %omp_loop.header
  %7 = add i32 %omp_loop.iv, %3
  %8 = add i32 %7, 1
  %9 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %10 = sitofp i32 %9 to float
  %11 = fdiv contract float 1.000000e+00, %10
  %12 = fpext float %11 to double
  %.unpack = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  %.unpack3 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  %.unpack4 = load i32, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  %.unpack5 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  %.unpack6 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  %.unpack7 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  %.unpack8 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  %.unpack9.unpack.unpack = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  %.unpack9.unpack.unpack11 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  %.unpack9.unpack.unpack12 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  store ptr %.unpack, ptr %loadgep_2, align 8, !tbaa !8
  %loadgep_2.repack14 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  store i64 %.unpack3, ptr %loadgep_2.repack14, align 8, !tbaa !8
  %loadgep_2.repack16 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  store i32 %.unpack4, ptr %loadgep_2.repack16, align 8, !tbaa !8
  %loadgep_2.repack18 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  store i8 %.unpack5, ptr %loadgep_2.repack18, align 4, !tbaa !8
  %loadgep_2.repack20 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  store i8 %.unpack6, ptr %loadgep_2.repack20, align 1, !tbaa !8
  %loadgep_2.repack22 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  store i8 %.unpack7, ptr %loadgep_2.repack22, align 2, !tbaa !8
  %loadgep_2.repack24 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  store i8 %.unpack8, ptr %loadgep_2.repack24, align 1, !tbaa !8
  %loadgep_2.repack26 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  store i64 %.unpack9.unpack.unpack, ptr %loadgep_2.repack26, align 8, !tbaa !8
  %loadgep_2.repack26.repack28 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack9.unpack.unpack11, ptr %loadgep_2.repack26.repack28, align 8, !tbaa !8
  %loadgep_2.repack26.repack30 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  store i64 %.unpack9.unpack.unpack12, ptr %loadgep_2.repack26.repack30, align 8, !tbaa !8
  %13 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 0
  %14 = load i64, ptr %13, align 8, !tbaa !8
  %15 = load ptr, ptr %loadgep_2, align 8, !tbaa !8
  %16 = sext i32 %8 to i64
  %17 = sub i64 %16, %14
  %18 = getelementptr double, ptr %15, i64 %17
  store double %12, ptr %18, align 8, !tbaa !4
  %omp_loop.next = add nuw i32 %omp_loop.iv, 1
  br label %omp_loop.header
}
*** IR Dump After SROAPass on _QQmain..omp_par ***
; Function Attrs: norecurse nounwind
define internal void @_QQmain..omp_par(ptr noalias %tid.addr, ptr noalias %zero.addr, ptr %0) #2 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %p.lastiter = alloca i32, align 4
  %p.lowerbound = alloca i32, align 4
  %p.upperbound = alloca i32, align 4
  %p.stride = alloca i32, align 4
  %1 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %omp_loop.tripcount = call i32 @llvm.smax.i32(i32 %1, i32 0)
  store i32 0, ptr %p.lowerbound, align 4
  %2 = add nsw i32 %omp_loop.tripcount, -1
  store i32 %2, ptr %p.upperbound, align 4
  store i32 1, ptr %p.stride, align 4
  %omp_global_thread_num4 = call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  call void @__kmpc_for_static_init_4u(ptr nonnull @1, i32 %omp_global_thread_num4, i32 34, ptr nonnull %p.lastiter, ptr nonnull %p.lowerbound, ptr nonnull %p.upperbound, ptr nonnull %p.stride, i32 1, i32 0)
  %3 = load i32, ptr %p.lowerbound, align 4
  %4 = load i32, ptr %p.upperbound, align 4
  %5 = sub i32 %4, %3
  %6 = add i32 %5, 1
  br label %omp_loop.header

omp_loop.header:                                  ; preds = %omp_loop.body, %omp.par.entry
  %omp_loop.iv = phi i32 [ 0, %omp.par.entry ], [ %omp_loop.next, %omp_loop.body ]
  %omp_loop.cmp = icmp ult i32 %omp_loop.iv, %6
  br i1 %omp_loop.cmp, label %omp_loop.body, label %omp_loop.exit

omp_loop.exit:                                    ; preds = %omp_loop.header
  call void @__kmpc_for_static_fini(ptr nonnull @1, i32 %omp_global_thread_num4)
  call void @__kmpc_barrier(ptr nonnull @2, i32 %omp_global_thread_num4)
  ret void

omp_loop.body:                                    ; preds = %omp_loop.header
  %7 = add i32 %omp_loop.iv, %3
  %8 = add i32 %7, 1
  %9 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %10 = sitofp i32 %9 to float
  %11 = fdiv contract float 1.000000e+00, %10
  %12 = fpext float %11 to double
  %.unpack = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  %.unpack3 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  %.unpack4 = load i32, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  %.unpack5 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  %.unpack6 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  %.unpack7 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  %.unpack8 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  %.unpack9.unpack.unpack = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  %.unpack9.unpack.unpack11 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  %.unpack9.unpack.unpack12 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  store ptr %.unpack, ptr %loadgep_2, align 8, !tbaa !8
  %loadgep_2.repack14 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  store i64 %.unpack3, ptr %loadgep_2.repack14, align 8, !tbaa !8
  %loadgep_2.repack16 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  store i32 %.unpack4, ptr %loadgep_2.repack16, align 8, !tbaa !8
  %loadgep_2.repack18 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  store i8 %.unpack5, ptr %loadgep_2.repack18, align 4, !tbaa !8
  %loadgep_2.repack20 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  store i8 %.unpack6, ptr %loadgep_2.repack20, align 1, !tbaa !8
  %loadgep_2.repack22 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  store i8 %.unpack7, ptr %loadgep_2.repack22, align 2, !tbaa !8
  %loadgep_2.repack24 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  store i8 %.unpack8, ptr %loadgep_2.repack24, align 1, !tbaa !8
  %loadgep_2.repack26 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  store i64 %.unpack9.unpack.unpack, ptr %loadgep_2.repack26, align 8, !tbaa !8
  %loadgep_2.repack26.repack28 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack9.unpack.unpack11, ptr %loadgep_2.repack26.repack28, align 8, !tbaa !8
  %loadgep_2.repack26.repack30 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  store i64 %.unpack9.unpack.unpack12, ptr %loadgep_2.repack26.repack30, align 8, !tbaa !8
  %13 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 0
  %14 = load i64, ptr %13, align 8, !tbaa !8
  %15 = load ptr, ptr %loadgep_2, align 8, !tbaa !8
  %16 = sext i32 %8 to i64
  %17 = sub i64 %16, %14
  %18 = getelementptr double, ptr %15, i64 %17
  store double %12, ptr %18, align 8, !tbaa !4
  %omp_loop.next = add nuw i32 %omp_loop.iv, 1
  br label %omp_loop.header
}
*** IR Dump After EarlyCSEPass on _QQmain..omp_par ***
; Function Attrs: norecurse nounwind
define internal void @_QQmain..omp_par(ptr noalias %tid.addr, ptr noalias %zero.addr, ptr %0) #2 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %p.lastiter = alloca i32, align 4
  %p.lowerbound = alloca i32, align 4
  %p.upperbound = alloca i32, align 4
  %p.stride = alloca i32, align 4
  %1 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %omp_loop.tripcount = call i32 @llvm.smax.i32(i32 %1, i32 0)
  store i32 0, ptr %p.lowerbound, align 4
  %2 = add nsw i32 %omp_loop.tripcount, -1
  store i32 %2, ptr %p.upperbound, align 4
  store i32 1, ptr %p.stride, align 4
  %omp_global_thread_num4 = call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  call void @__kmpc_for_static_init_4u(ptr nonnull @1, i32 %omp_global_thread_num4, i32 34, ptr nonnull %p.lastiter, ptr nonnull %p.lowerbound, ptr nonnull %p.upperbound, ptr nonnull %p.stride, i32 1, i32 0)
  %3 = load i32, ptr %p.lowerbound, align 4
  %4 = load i32, ptr %p.upperbound, align 4
  %5 = sub i32 %4, %3
  %6 = add i32 %5, 1
  br label %omp_loop.header

omp_loop.header:                                  ; preds = %omp_loop.body, %omp.par.entry
  %omp_loop.iv = phi i32 [ 0, %omp.par.entry ], [ %omp_loop.next, %omp_loop.body ]
  %omp_loop.cmp = icmp ult i32 %omp_loop.iv, %6
  br i1 %omp_loop.cmp, label %omp_loop.body, label %omp_loop.exit

omp_loop.exit:                                    ; preds = %omp_loop.header
  call void @__kmpc_for_static_fini(ptr nonnull @1, i32 %omp_global_thread_num4)
  call void @__kmpc_barrier(ptr nonnull @2, i32 %omp_global_thread_num4)
  ret void

omp_loop.body:                                    ; preds = %omp_loop.header
  %7 = add i32 %omp_loop.iv, %3
  %8 = add i32 %7, 1
  %9 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %10 = sitofp i32 %9 to float
  %11 = fdiv contract float 1.000000e+00, %10
  %12 = fpext float %11 to double
  %.unpack = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  %.unpack3 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  %.unpack4 = load i32, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  %.unpack5 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  %.unpack6 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  %.unpack7 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  %.unpack8 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  %.unpack9.unpack.unpack = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  %.unpack9.unpack.unpack11 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  %.unpack9.unpack.unpack12 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  store ptr %.unpack, ptr %loadgep_2, align 8, !tbaa !8
  %loadgep_2.repack14 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  store i64 %.unpack3, ptr %loadgep_2.repack14, align 8, !tbaa !8
  %loadgep_2.repack16 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  store i32 %.unpack4, ptr %loadgep_2.repack16, align 8, !tbaa !8
  %loadgep_2.repack18 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  store i8 %.unpack5, ptr %loadgep_2.repack18, align 4, !tbaa !8
  %loadgep_2.repack20 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  store i8 %.unpack6, ptr %loadgep_2.repack20, align 1, !tbaa !8
  %loadgep_2.repack22 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  store i8 %.unpack7, ptr %loadgep_2.repack22, align 2, !tbaa !8
  %loadgep_2.repack24 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  store i8 %.unpack8, ptr %loadgep_2.repack24, align 1, !tbaa !8
  %loadgep_2.repack26 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  store i64 %.unpack9.unpack.unpack, ptr %loadgep_2.repack26, align 8, !tbaa !8
  %loadgep_2.repack26.repack28 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack9.unpack.unpack11, ptr %loadgep_2.repack26.repack28, align 8, !tbaa !8
  %loadgep_2.repack26.repack30 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  store i64 %.unpack9.unpack.unpack12, ptr %loadgep_2.repack26.repack30, align 8, !tbaa !8
  %13 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 0
  %14 = load i64, ptr %13, align 8, !tbaa !8
  %15 = sext i32 %8 to i64
  %16 = sub i64 %15, %14
  %17 = getelementptr double, ptr %.unpack, i64 %16
  store double %12, ptr %17, align 8, !tbaa !4
  %omp_loop.next = add nuw i32 %omp_loop.iv, 1
  br label %omp_loop.header
}
*** IR Dump After SpeculativeExecutionPass on _QQmain..omp_par ***
; Function Attrs: norecurse nounwind
define internal void @_QQmain..omp_par(ptr noalias %tid.addr, ptr noalias %zero.addr, ptr %0) #2 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %p.lastiter = alloca i32, align 4
  %p.lowerbound = alloca i32, align 4
  %p.upperbound = alloca i32, align 4
  %p.stride = alloca i32, align 4
  %1 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %omp_loop.tripcount = call i32 @llvm.smax.i32(i32 %1, i32 0)
  store i32 0, ptr %p.lowerbound, align 4
  %2 = add nsw i32 %omp_loop.tripcount, -1
  store i32 %2, ptr %p.upperbound, align 4
  store i32 1, ptr %p.stride, align 4
  %omp_global_thread_num4 = call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  call void @__kmpc_for_static_init_4u(ptr nonnull @1, i32 %omp_global_thread_num4, i32 34, ptr nonnull %p.lastiter, ptr nonnull %p.lowerbound, ptr nonnull %p.upperbound, ptr nonnull %p.stride, i32 1, i32 0)
  %3 = load i32, ptr %p.lowerbound, align 4
  %4 = load i32, ptr %p.upperbound, align 4
  %5 = sub i32 %4, %3
  %6 = add i32 %5, 1
  br label %omp_loop.header

omp_loop.header:                                  ; preds = %omp_loop.body, %omp.par.entry
  %omp_loop.iv = phi i32 [ 0, %omp.par.entry ], [ %omp_loop.next, %omp_loop.body ]
  %omp_loop.cmp = icmp ult i32 %omp_loop.iv, %6
  br i1 %omp_loop.cmp, label %omp_loop.body, label %omp_loop.exit

omp_loop.exit:                                    ; preds = %omp_loop.header
  call void @__kmpc_for_static_fini(ptr nonnull @1, i32 %omp_global_thread_num4)
  call void @__kmpc_barrier(ptr nonnull @2, i32 %omp_global_thread_num4)
  ret void

omp_loop.body:                                    ; preds = %omp_loop.header
  %7 = add i32 %omp_loop.iv, %3
  %8 = add i32 %7, 1
  %9 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %10 = sitofp i32 %9 to float
  %11 = fdiv contract float 1.000000e+00, %10
  %12 = fpext float %11 to double
  %.unpack = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  %.unpack3 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  %.unpack4 = load i32, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  %.unpack5 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  %.unpack6 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  %.unpack7 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  %.unpack8 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  %.unpack9.unpack.unpack = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  %.unpack9.unpack.unpack11 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  %.unpack9.unpack.unpack12 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  store ptr %.unpack, ptr %loadgep_2, align 8, !tbaa !8
  %loadgep_2.repack14 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  store i64 %.unpack3, ptr %loadgep_2.repack14, align 8, !tbaa !8
  %loadgep_2.repack16 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  store i32 %.unpack4, ptr %loadgep_2.repack16, align 8, !tbaa !8
  %loadgep_2.repack18 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  store i8 %.unpack5, ptr %loadgep_2.repack18, align 4, !tbaa !8
  %loadgep_2.repack20 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  store i8 %.unpack6, ptr %loadgep_2.repack20, align 1, !tbaa !8
  %loadgep_2.repack22 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  store i8 %.unpack7, ptr %loadgep_2.repack22, align 2, !tbaa !8
  %loadgep_2.repack24 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  store i8 %.unpack8, ptr %loadgep_2.repack24, align 1, !tbaa !8
  %loadgep_2.repack26 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  store i64 %.unpack9.unpack.unpack, ptr %loadgep_2.repack26, align 8, !tbaa !8
  %loadgep_2.repack26.repack28 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack9.unpack.unpack11, ptr %loadgep_2.repack26.repack28, align 8, !tbaa !8
  %loadgep_2.repack26.repack30 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  store i64 %.unpack9.unpack.unpack12, ptr %loadgep_2.repack26.repack30, align 8, !tbaa !8
  %13 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 0
  %14 = load i64, ptr %13, align 8, !tbaa !8
  %15 = sext i32 %8 to i64
  %16 = sub i64 %15, %14
  %17 = getelementptr double, ptr %.unpack, i64 %16
  store double %12, ptr %17, align 8, !tbaa !4
  %omp_loop.next = add nuw i32 %omp_loop.iv, 1
  br label %omp_loop.header
}
*** IR Dump After JumpThreadingPass on _QQmain..omp_par ***
; Function Attrs: norecurse nounwind
define internal void @_QQmain..omp_par(ptr noalias %tid.addr, ptr noalias %zero.addr, ptr %0) #2 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %p.lastiter = alloca i32, align 4
  %p.lowerbound = alloca i32, align 4
  %p.upperbound = alloca i32, align 4
  %p.stride = alloca i32, align 4
  %1 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %omp_loop.tripcount = call i32 @llvm.smax.i32(i32 %1, i32 0)
  store i32 0, ptr %p.lowerbound, align 4
  %2 = add nsw i32 %omp_loop.tripcount, -1
  store i32 %2, ptr %p.upperbound, align 4
  store i32 1, ptr %p.stride, align 4
  %omp_global_thread_num4 = call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  call void @__kmpc_for_static_init_4u(ptr nonnull @1, i32 %omp_global_thread_num4, i32 34, ptr nonnull %p.lastiter, ptr nonnull %p.lowerbound, ptr nonnull %p.upperbound, ptr nonnull %p.stride, i32 1, i32 0)
  %3 = load i32, ptr %p.lowerbound, align 4
  %4 = load i32, ptr %p.upperbound, align 4
  %5 = sub i32 %4, %3
  %6 = add i32 %5, 1
  br label %omp_loop.header

omp_loop.header:                                  ; preds = %omp_loop.body, %omp.par.entry
  %omp_loop.iv = phi i32 [ 0, %omp.par.entry ], [ %omp_loop.next, %omp_loop.body ]
  %omp_loop.cmp = icmp ult i32 %omp_loop.iv, %6
  br i1 %omp_loop.cmp, label %omp_loop.body, label %omp_loop.exit

omp_loop.exit:                                    ; preds = %omp_loop.header
  call void @__kmpc_for_static_fini(ptr nonnull @1, i32 %omp_global_thread_num4)
  call void @__kmpc_barrier(ptr nonnull @2, i32 %omp_global_thread_num4)
  ret void

omp_loop.body:                                    ; preds = %omp_loop.header
  %7 = add i32 %omp_loop.iv, %3
  %8 = add i32 %7, 1
  %9 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %10 = sitofp i32 %9 to float
  %11 = fdiv contract float 1.000000e+00, %10
  %12 = fpext float %11 to double
  %.unpack = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  %.unpack3 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  %.unpack4 = load i32, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  %.unpack5 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  %.unpack6 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  %.unpack7 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  %.unpack8 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  %.unpack9.unpack.unpack = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  %.unpack9.unpack.unpack11 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  %.unpack9.unpack.unpack12 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  store ptr %.unpack, ptr %loadgep_2, align 8, !tbaa !8
  %loadgep_2.repack14 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  store i64 %.unpack3, ptr %loadgep_2.repack14, align 8, !tbaa !8
  %loadgep_2.repack16 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  store i32 %.unpack4, ptr %loadgep_2.repack16, align 8, !tbaa !8
  %loadgep_2.repack18 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  store i8 %.unpack5, ptr %loadgep_2.repack18, align 4, !tbaa !8
  %loadgep_2.repack20 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  store i8 %.unpack6, ptr %loadgep_2.repack20, align 1, !tbaa !8
  %loadgep_2.repack22 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  store i8 %.unpack7, ptr %loadgep_2.repack22, align 2, !tbaa !8
  %loadgep_2.repack24 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  store i8 %.unpack8, ptr %loadgep_2.repack24, align 1, !tbaa !8
  %loadgep_2.repack26 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  store i64 %.unpack9.unpack.unpack, ptr %loadgep_2.repack26, align 8, !tbaa !8
  %loadgep_2.repack26.repack28 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack9.unpack.unpack11, ptr %loadgep_2.repack26.repack28, align 8, !tbaa !8
  %loadgep_2.repack26.repack30 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  store i64 %.unpack9.unpack.unpack12, ptr %loadgep_2.repack26.repack30, align 8, !tbaa !8
  %13 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 0
  %14 = load i64, ptr %13, align 8, !tbaa !8
  %15 = sext i32 %8 to i64
  %16 = sub i64 %15, %14
  %17 = getelementptr double, ptr %.unpack, i64 %16
  store double %12, ptr %17, align 8, !tbaa !4
  %omp_loop.next = add nuw i32 %omp_loop.iv, 1
  br label %omp_loop.header
}
*** IR Dump After CorrelatedValuePropagationPass on _QQmain..omp_par ***
; Function Attrs: norecurse nounwind
define internal void @_QQmain..omp_par(ptr noalias %tid.addr, ptr noalias %zero.addr, ptr %0) #2 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %p.lastiter = alloca i32, align 4
  %p.lowerbound = alloca i32, align 4
  %p.upperbound = alloca i32, align 4
  %p.stride = alloca i32, align 4
  %1 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %omp_loop.tripcount = call i32 @llvm.smax.i32(i32 %1, i32 0)
  store i32 0, ptr %p.lowerbound, align 4
  %2 = add nsw i32 %omp_loop.tripcount, -1
  store i32 %2, ptr %p.upperbound, align 4
  store i32 1, ptr %p.stride, align 4
  %omp_global_thread_num4 = call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  call void @__kmpc_for_static_init_4u(ptr nonnull @1, i32 %omp_global_thread_num4, i32 34, ptr nonnull %p.lastiter, ptr nonnull %p.lowerbound, ptr nonnull %p.upperbound, ptr nonnull %p.stride, i32 1, i32 0)
  %3 = load i32, ptr %p.lowerbound, align 4
  %4 = load i32, ptr %p.upperbound, align 4
  %5 = sub i32 %4, %3
  %6 = add i32 %5, 1
  br label %omp_loop.header

omp_loop.header:                                  ; preds = %omp_loop.body, %omp.par.entry
  %omp_loop.iv = phi i32 [ 0, %omp.par.entry ], [ %omp_loop.next, %omp_loop.body ]
  %omp_loop.cmp = icmp ult i32 %omp_loop.iv, %6
  br i1 %omp_loop.cmp, label %omp_loop.body, label %omp_loop.exit

omp_loop.exit:                                    ; preds = %omp_loop.header
  call void @__kmpc_for_static_fini(ptr nonnull @1, i32 %omp_global_thread_num4)
  call void @__kmpc_barrier(ptr nonnull @2, i32 %omp_global_thread_num4)
  ret void

omp_loop.body:                                    ; preds = %omp_loop.header
  %7 = add i32 %omp_loop.iv, %3
  %8 = add i32 %7, 1
  %9 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %10 = sitofp i32 %9 to float
  %11 = fdiv contract float 1.000000e+00, %10
  %12 = fpext float %11 to double
  %.unpack = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  %.unpack3 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  %.unpack4 = load i32, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  %.unpack5 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  %.unpack6 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  %.unpack7 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  %.unpack8 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  %.unpack9.unpack.unpack = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  %.unpack9.unpack.unpack11 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  %.unpack9.unpack.unpack12 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  store ptr %.unpack, ptr %loadgep_2, align 8, !tbaa !8
  %loadgep_2.repack14 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  store i64 %.unpack3, ptr %loadgep_2.repack14, align 8, !tbaa !8
  %loadgep_2.repack16 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  store i32 %.unpack4, ptr %loadgep_2.repack16, align 8, !tbaa !8
  %loadgep_2.repack18 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  store i8 %.unpack5, ptr %loadgep_2.repack18, align 4, !tbaa !8
  %loadgep_2.repack20 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  store i8 %.unpack6, ptr %loadgep_2.repack20, align 1, !tbaa !8
  %loadgep_2.repack22 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  store i8 %.unpack7, ptr %loadgep_2.repack22, align 2, !tbaa !8
  %loadgep_2.repack24 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  store i8 %.unpack8, ptr %loadgep_2.repack24, align 1, !tbaa !8
  %loadgep_2.repack26 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  store i64 %.unpack9.unpack.unpack, ptr %loadgep_2.repack26, align 8, !tbaa !8
  %loadgep_2.repack26.repack28 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack9.unpack.unpack11, ptr %loadgep_2.repack26.repack28, align 8, !tbaa !8
  %loadgep_2.repack26.repack30 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  store i64 %.unpack9.unpack.unpack12, ptr %loadgep_2.repack26.repack30, align 8, !tbaa !8
  %13 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 0
  %14 = load i64, ptr %13, align 8, !tbaa !8
  %15 = sext i32 %8 to i64
  %16 = sub i64 %15, %14
  %17 = getelementptr double, ptr %.unpack, i64 %16
  store double %12, ptr %17, align 8, !tbaa !4
  %omp_loop.next = add nuw i32 %omp_loop.iv, 1
  br label %omp_loop.header
}
*** IR Dump After SimplifyCFGPass on _QQmain..omp_par ***
; Function Attrs: norecurse nounwind
define internal void @_QQmain..omp_par(ptr noalias %tid.addr, ptr noalias %zero.addr, ptr %0) #2 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %p.lastiter = alloca i32, align 4
  %p.lowerbound = alloca i32, align 4
  %p.upperbound = alloca i32, align 4
  %p.stride = alloca i32, align 4
  %1 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %omp_loop.tripcount = call i32 @llvm.smax.i32(i32 %1, i32 0)
  store i32 0, ptr %p.lowerbound, align 4
  %2 = add nsw i32 %omp_loop.tripcount, -1
  store i32 %2, ptr %p.upperbound, align 4
  store i32 1, ptr %p.stride, align 4
  %omp_global_thread_num4 = call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  call void @__kmpc_for_static_init_4u(ptr nonnull @1, i32 %omp_global_thread_num4, i32 34, ptr nonnull %p.lastiter, ptr nonnull %p.lowerbound, ptr nonnull %p.upperbound, ptr nonnull %p.stride, i32 1, i32 0)
  %3 = load i32, ptr %p.lowerbound, align 4
  %4 = load i32, ptr %p.upperbound, align 4
  %5 = sub i32 %4, %3
  %6 = add i32 %5, 1
  br label %omp_loop.header

omp_loop.header:                                  ; preds = %omp_loop.body, %omp.par.entry
  %omp_loop.iv = phi i32 [ 0, %omp.par.entry ], [ %omp_loop.next, %omp_loop.body ]
  %omp_loop.cmp = icmp ult i32 %omp_loop.iv, %6
  br i1 %omp_loop.cmp, label %omp_loop.body, label %omp_loop.exit

omp_loop.exit:                                    ; preds = %omp_loop.header
  call void @__kmpc_for_static_fini(ptr nonnull @1, i32 %omp_global_thread_num4)
  call void @__kmpc_barrier(ptr nonnull @2, i32 %omp_global_thread_num4)
  ret void

omp_loop.body:                                    ; preds = %omp_loop.header
  %7 = add i32 %omp_loop.iv, %3
  %8 = add i32 %7, 1
  %9 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %10 = sitofp i32 %9 to float
  %11 = fdiv contract float 1.000000e+00, %10
  %12 = fpext float %11 to double
  %.unpack = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  %.unpack3 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  %.unpack4 = load i32, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  %.unpack5 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  %.unpack6 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  %.unpack7 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  %.unpack8 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  %.unpack9.unpack.unpack = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  %.unpack9.unpack.unpack11 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  %.unpack9.unpack.unpack12 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  store ptr %.unpack, ptr %loadgep_2, align 8, !tbaa !8
  %loadgep_2.repack14 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  store i64 %.unpack3, ptr %loadgep_2.repack14, align 8, !tbaa !8
  %loadgep_2.repack16 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  store i32 %.unpack4, ptr %loadgep_2.repack16, align 8, !tbaa !8
  %loadgep_2.repack18 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  store i8 %.unpack5, ptr %loadgep_2.repack18, align 4, !tbaa !8
  %loadgep_2.repack20 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  store i8 %.unpack6, ptr %loadgep_2.repack20, align 1, !tbaa !8
  %loadgep_2.repack22 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  store i8 %.unpack7, ptr %loadgep_2.repack22, align 2, !tbaa !8
  %loadgep_2.repack24 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  store i8 %.unpack8, ptr %loadgep_2.repack24, align 1, !tbaa !8
  %loadgep_2.repack26 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  store i64 %.unpack9.unpack.unpack, ptr %loadgep_2.repack26, align 8, !tbaa !8
  %loadgep_2.repack26.repack28 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack9.unpack.unpack11, ptr %loadgep_2.repack26.repack28, align 8, !tbaa !8
  %loadgep_2.repack26.repack30 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  store i64 %.unpack9.unpack.unpack12, ptr %loadgep_2.repack26.repack30, align 8, !tbaa !8
  %13 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 0
  %14 = load i64, ptr %13, align 8, !tbaa !8
  %15 = sext i32 %8 to i64
  %16 = sub i64 %15, %14
  %17 = getelementptr double, ptr %.unpack, i64 %16
  store double %12, ptr %17, align 8, !tbaa !4
  %omp_loop.next = add nuw i32 %omp_loop.iv, 1
  br label %omp_loop.header
}
*** IR Dump After InstCombinePass on _QQmain..omp_par ***
; Function Attrs: norecurse nounwind
define internal void @_QQmain..omp_par(ptr noalias %tid.addr, ptr noalias %zero.addr, ptr %0) #2 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %p.lastiter = alloca i32, align 4
  %p.lowerbound = alloca i32, align 4
  %p.upperbound = alloca i32, align 4
  %p.stride = alloca i32, align 4
  %1 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %omp_loop.tripcount = call i32 @llvm.smax.i32(i32 %1, i32 0)
  store i32 0, ptr %p.lowerbound, align 4
  %2 = add nsw i32 %omp_loop.tripcount, -1
  store i32 %2, ptr %p.upperbound, align 4
  store i32 1, ptr %p.stride, align 4
  %omp_global_thread_num4 = call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  call void @__kmpc_for_static_init_4u(ptr nonnull @1, i32 %omp_global_thread_num4, i32 34, ptr nonnull %p.lastiter, ptr nonnull %p.lowerbound, ptr nonnull %p.upperbound, ptr nonnull %p.stride, i32 1, i32 0)
  %3 = load i32, ptr %p.lowerbound, align 4
  %4 = load i32, ptr %p.upperbound, align 4
  %5 = sub i32 %4, %3
  %6 = add i32 %5, 1
  br label %omp_loop.header

omp_loop.header:                                  ; preds = %omp_loop.body, %omp.par.entry
  %omp_loop.iv = phi i32 [ 0, %omp.par.entry ], [ %omp_loop.next, %omp_loop.body ]
  %omp_loop.cmp = icmp ult i32 %omp_loop.iv, %6
  br i1 %omp_loop.cmp, label %omp_loop.body, label %omp_loop.exit

omp_loop.exit:                                    ; preds = %omp_loop.header
  call void @__kmpc_for_static_fini(ptr nonnull @1, i32 %omp_global_thread_num4)
  call void @__kmpc_barrier(ptr nonnull @2, i32 %omp_global_thread_num4)
  ret void

omp_loop.body:                                    ; preds = %omp_loop.header
  %7 = add i32 %omp_loop.iv, %3
  %8 = add i32 %7, 1
  %9 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %10 = sitofp i32 %9 to float
  %11 = fdiv contract float 1.000000e+00, %10
  %12 = fpext float %11 to double
  %.unpack = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  %.unpack3 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  %.unpack4 = load i32, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  %.unpack5 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  %.unpack6 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  %.unpack7 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  %.unpack8 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  %.unpack9.unpack.unpack = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  %.unpack9.unpack.unpack11 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  %.unpack9.unpack.unpack12 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  store ptr %.unpack, ptr %loadgep_2, align 8, !tbaa !8
  %loadgep_2.repack14 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  store i64 %.unpack3, ptr %loadgep_2.repack14, align 8, !tbaa !8
  %loadgep_2.repack16 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  store i32 %.unpack4, ptr %loadgep_2.repack16, align 8, !tbaa !8
  %loadgep_2.repack18 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  store i8 %.unpack5, ptr %loadgep_2.repack18, align 4, !tbaa !8
  %loadgep_2.repack20 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  store i8 %.unpack6, ptr %loadgep_2.repack20, align 1, !tbaa !8
  %loadgep_2.repack22 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  store i8 %.unpack7, ptr %loadgep_2.repack22, align 2, !tbaa !8
  %loadgep_2.repack24 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  store i8 %.unpack8, ptr %loadgep_2.repack24, align 1, !tbaa !8
  %loadgep_2.repack26 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  store i64 %.unpack9.unpack.unpack, ptr %loadgep_2.repack26, align 8, !tbaa !8
  %loadgep_2.repack26.repack28 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack9.unpack.unpack11, ptr %loadgep_2.repack26.repack28, align 8, !tbaa !8
  %loadgep_2.repack26.repack30 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  store i64 %.unpack9.unpack.unpack12, ptr %loadgep_2.repack26.repack30, align 8, !tbaa !8
  %13 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 0
  %14 = load i64, ptr %13, align 8, !tbaa !8
  %15 = sext i32 %8 to i64
  %16 = sub i64 %15, %14
  %17 = getelementptr double, ptr %.unpack, i64 %16
  store double %12, ptr %17, align 8, !tbaa !4
  %omp_loop.next = add nuw i32 %omp_loop.iv, 1
  br label %omp_loop.header
}
*** IR Dump After AggressiveInstCombinePass on _QQmain..omp_par ***
; Function Attrs: norecurse nounwind
define internal void @_QQmain..omp_par(ptr noalias %tid.addr, ptr noalias %zero.addr, ptr %0) #2 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %p.lastiter = alloca i32, align 4
  %p.lowerbound = alloca i32, align 4
  %p.upperbound = alloca i32, align 4
  %p.stride = alloca i32, align 4
  %1 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %omp_loop.tripcount = call i32 @llvm.smax.i32(i32 %1, i32 0)
  store i32 0, ptr %p.lowerbound, align 4
  %2 = add nsw i32 %omp_loop.tripcount, -1
  store i32 %2, ptr %p.upperbound, align 4
  store i32 1, ptr %p.stride, align 4
  %omp_global_thread_num4 = call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  call void @__kmpc_for_static_init_4u(ptr nonnull @1, i32 %omp_global_thread_num4, i32 34, ptr nonnull %p.lastiter, ptr nonnull %p.lowerbound, ptr nonnull %p.upperbound, ptr nonnull %p.stride, i32 1, i32 0)
  %3 = load i32, ptr %p.lowerbound, align 4
  %4 = load i32, ptr %p.upperbound, align 4
  %5 = sub i32 %4, %3
  %6 = add i32 %5, 1
  br label %omp_loop.header

omp_loop.header:                                  ; preds = %omp_loop.body, %omp.par.entry
  %omp_loop.iv = phi i32 [ 0, %omp.par.entry ], [ %omp_loop.next, %omp_loop.body ]
  %omp_loop.cmp = icmp ult i32 %omp_loop.iv, %6
  br i1 %omp_loop.cmp, label %omp_loop.body, label %omp_loop.exit

omp_loop.exit:                                    ; preds = %omp_loop.header
  call void @__kmpc_for_static_fini(ptr nonnull @1, i32 %omp_global_thread_num4)
  call void @__kmpc_barrier(ptr nonnull @2, i32 %omp_global_thread_num4)
  ret void

omp_loop.body:                                    ; preds = %omp_loop.header
  %7 = add i32 %omp_loop.iv, %3
  %8 = add i32 %7, 1
  %9 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %10 = sitofp i32 %9 to float
  %11 = fdiv contract float 1.000000e+00, %10
  %12 = fpext float %11 to double
  %.unpack = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  %.unpack3 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  %.unpack4 = load i32, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  %.unpack5 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  %.unpack6 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  %.unpack7 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  %.unpack8 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  %.unpack9.unpack.unpack = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  %.unpack9.unpack.unpack11 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  %.unpack9.unpack.unpack12 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  store ptr %.unpack, ptr %loadgep_2, align 8, !tbaa !8
  %loadgep_2.repack14 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  store i64 %.unpack3, ptr %loadgep_2.repack14, align 8, !tbaa !8
  %loadgep_2.repack16 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  store i32 %.unpack4, ptr %loadgep_2.repack16, align 8, !tbaa !8
  %loadgep_2.repack18 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  store i8 %.unpack5, ptr %loadgep_2.repack18, align 4, !tbaa !8
  %loadgep_2.repack20 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  store i8 %.unpack6, ptr %loadgep_2.repack20, align 1, !tbaa !8
  %loadgep_2.repack22 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  store i8 %.unpack7, ptr %loadgep_2.repack22, align 2, !tbaa !8
  %loadgep_2.repack24 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  store i8 %.unpack8, ptr %loadgep_2.repack24, align 1, !tbaa !8
  %loadgep_2.repack26 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  store i64 %.unpack9.unpack.unpack, ptr %loadgep_2.repack26, align 8, !tbaa !8
  %loadgep_2.repack26.repack28 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack9.unpack.unpack11, ptr %loadgep_2.repack26.repack28, align 8, !tbaa !8
  %loadgep_2.repack26.repack30 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  store i64 %.unpack9.unpack.unpack12, ptr %loadgep_2.repack26.repack30, align 8, !tbaa !8
  %13 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 0
  %14 = load i64, ptr %13, align 8, !tbaa !8
  %15 = sext i32 %8 to i64
  %16 = sub i64 %15, %14
  %17 = getelementptr double, ptr %.unpack, i64 %16
  store double %12, ptr %17, align 8, !tbaa !4
  %omp_loop.next = add nuw i32 %omp_loop.iv, 1
  br label %omp_loop.header
}
*** IR Dump After ConstraintEliminationPass on _QQmain..omp_par ***
; Function Attrs: norecurse nounwind
define internal void @_QQmain..omp_par(ptr noalias %tid.addr, ptr noalias %zero.addr, ptr %0) #2 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %p.lastiter = alloca i32, align 4
  %p.lowerbound = alloca i32, align 4
  %p.upperbound = alloca i32, align 4
  %p.stride = alloca i32, align 4
  %1 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %omp_loop.tripcount = call i32 @llvm.smax.i32(i32 %1, i32 0)
  store i32 0, ptr %p.lowerbound, align 4
  %2 = add nsw i32 %omp_loop.tripcount, -1
  store i32 %2, ptr %p.upperbound, align 4
  store i32 1, ptr %p.stride, align 4
  %omp_global_thread_num4 = call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  call void @__kmpc_for_static_init_4u(ptr nonnull @1, i32 %omp_global_thread_num4, i32 34, ptr nonnull %p.lastiter, ptr nonnull %p.lowerbound, ptr nonnull %p.upperbound, ptr nonnull %p.stride, i32 1, i32 0)
  %3 = load i32, ptr %p.lowerbound, align 4
  %4 = load i32, ptr %p.upperbound, align 4
  %5 = sub i32 %4, %3
  %6 = add i32 %5, 1
  br label %omp_loop.header

omp_loop.header:                                  ; preds = %omp_loop.body, %omp.par.entry
  %omp_loop.iv = phi i32 [ 0, %omp.par.entry ], [ %omp_loop.next, %omp_loop.body ]
  %omp_loop.cmp = icmp ult i32 %omp_loop.iv, %6
  br i1 %omp_loop.cmp, label %omp_loop.body, label %omp_loop.exit

omp_loop.exit:                                    ; preds = %omp_loop.header
  call void @__kmpc_for_static_fini(ptr nonnull @1, i32 %omp_global_thread_num4)
  call void @__kmpc_barrier(ptr nonnull @2, i32 %omp_global_thread_num4)
  ret void

omp_loop.body:                                    ; preds = %omp_loop.header
  %7 = add i32 %omp_loop.iv, %3
  %8 = add i32 %7, 1
  %9 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %10 = sitofp i32 %9 to float
  %11 = fdiv contract float 1.000000e+00, %10
  %12 = fpext float %11 to double
  %.unpack = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  %.unpack3 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  %.unpack4 = load i32, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  %.unpack5 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  %.unpack6 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  %.unpack7 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  %.unpack8 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  %.unpack9.unpack.unpack = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  %.unpack9.unpack.unpack11 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  %.unpack9.unpack.unpack12 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  store ptr %.unpack, ptr %loadgep_2, align 8, !tbaa !8
  %loadgep_2.repack14 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  store i64 %.unpack3, ptr %loadgep_2.repack14, align 8, !tbaa !8
  %loadgep_2.repack16 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  store i32 %.unpack4, ptr %loadgep_2.repack16, align 8, !tbaa !8
  %loadgep_2.repack18 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  store i8 %.unpack5, ptr %loadgep_2.repack18, align 4, !tbaa !8
  %loadgep_2.repack20 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  store i8 %.unpack6, ptr %loadgep_2.repack20, align 1, !tbaa !8
  %loadgep_2.repack22 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  store i8 %.unpack7, ptr %loadgep_2.repack22, align 2, !tbaa !8
  %loadgep_2.repack24 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  store i8 %.unpack8, ptr %loadgep_2.repack24, align 1, !tbaa !8
  %loadgep_2.repack26 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  store i64 %.unpack9.unpack.unpack, ptr %loadgep_2.repack26, align 8, !tbaa !8
  %loadgep_2.repack26.repack28 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack9.unpack.unpack11, ptr %loadgep_2.repack26.repack28, align 8, !tbaa !8
  %loadgep_2.repack26.repack30 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  store i64 %.unpack9.unpack.unpack12, ptr %loadgep_2.repack26.repack30, align 8, !tbaa !8
  %13 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 0
  %14 = load i64, ptr %13, align 8, !tbaa !8
  %15 = sext i32 %8 to i64
  %16 = sub i64 %15, %14
  %17 = getelementptr double, ptr %.unpack, i64 %16
  store double %12, ptr %17, align 8, !tbaa !4
  %omp_loop.next = add nuw i32 %omp_loop.iv, 1
  br label %omp_loop.header
}
*** IR Dump After LibCallsShrinkWrapPass on _QQmain..omp_par ***
; Function Attrs: norecurse nounwind
define internal void @_QQmain..omp_par(ptr noalias %tid.addr, ptr noalias %zero.addr, ptr %0) #2 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %p.lastiter = alloca i32, align 4
  %p.lowerbound = alloca i32, align 4
  %p.upperbound = alloca i32, align 4
  %p.stride = alloca i32, align 4
  %1 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %omp_loop.tripcount = call i32 @llvm.smax.i32(i32 %1, i32 0)
  store i32 0, ptr %p.lowerbound, align 4
  %2 = add nsw i32 %omp_loop.tripcount, -1
  store i32 %2, ptr %p.upperbound, align 4
  store i32 1, ptr %p.stride, align 4
  %omp_global_thread_num4 = call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  call void @__kmpc_for_static_init_4u(ptr nonnull @1, i32 %omp_global_thread_num4, i32 34, ptr nonnull %p.lastiter, ptr nonnull %p.lowerbound, ptr nonnull %p.upperbound, ptr nonnull %p.stride, i32 1, i32 0)
  %3 = load i32, ptr %p.lowerbound, align 4
  %4 = load i32, ptr %p.upperbound, align 4
  %5 = sub i32 %4, %3
  %6 = add i32 %5, 1
  br label %omp_loop.header

omp_loop.header:                                  ; preds = %omp_loop.body, %omp.par.entry
  %omp_loop.iv = phi i32 [ 0, %omp.par.entry ], [ %omp_loop.next, %omp_loop.body ]
  %omp_loop.cmp = icmp ult i32 %omp_loop.iv, %6
  br i1 %omp_loop.cmp, label %omp_loop.body, label %omp_loop.exit

omp_loop.exit:                                    ; preds = %omp_loop.header
  call void @__kmpc_for_static_fini(ptr nonnull @1, i32 %omp_global_thread_num4)
  call void @__kmpc_barrier(ptr nonnull @2, i32 %omp_global_thread_num4)
  ret void

omp_loop.body:                                    ; preds = %omp_loop.header
  %7 = add i32 %omp_loop.iv, %3
  %8 = add i32 %7, 1
  %9 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %10 = sitofp i32 %9 to float
  %11 = fdiv contract float 1.000000e+00, %10
  %12 = fpext float %11 to double
  %.unpack = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  %.unpack3 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  %.unpack4 = load i32, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  %.unpack5 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  %.unpack6 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  %.unpack7 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  %.unpack8 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  %.unpack9.unpack.unpack = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  %.unpack9.unpack.unpack11 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  %.unpack9.unpack.unpack12 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  store ptr %.unpack, ptr %loadgep_2, align 8, !tbaa !8
  %loadgep_2.repack14 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  store i64 %.unpack3, ptr %loadgep_2.repack14, align 8, !tbaa !8
  %loadgep_2.repack16 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  store i32 %.unpack4, ptr %loadgep_2.repack16, align 8, !tbaa !8
  %loadgep_2.repack18 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  store i8 %.unpack5, ptr %loadgep_2.repack18, align 4, !tbaa !8
  %loadgep_2.repack20 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  store i8 %.unpack6, ptr %loadgep_2.repack20, align 1, !tbaa !8
  %loadgep_2.repack22 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  store i8 %.unpack7, ptr %loadgep_2.repack22, align 2, !tbaa !8
  %loadgep_2.repack24 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  store i8 %.unpack8, ptr %loadgep_2.repack24, align 1, !tbaa !8
  %loadgep_2.repack26 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  store i64 %.unpack9.unpack.unpack, ptr %loadgep_2.repack26, align 8, !tbaa !8
  %loadgep_2.repack26.repack28 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack9.unpack.unpack11, ptr %loadgep_2.repack26.repack28, align 8, !tbaa !8
  %loadgep_2.repack26.repack30 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  store i64 %.unpack9.unpack.unpack12, ptr %loadgep_2.repack26.repack30, align 8, !tbaa !8
  %13 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 0
  %14 = load i64, ptr %13, align 8, !tbaa !8
  %15 = sext i32 %8 to i64
  %16 = sub i64 %15, %14
  %17 = getelementptr double, ptr %.unpack, i64 %16
  store double %12, ptr %17, align 8, !tbaa !4
  %omp_loop.next = add nuw i32 %omp_loop.iv, 1
  br label %omp_loop.header
}
*** IR Dump After TailCallElimPass on _QQmain..omp_par ***
; Function Attrs: norecurse nounwind
define internal void @_QQmain..omp_par(ptr noalias %tid.addr, ptr noalias %zero.addr, ptr %0) #2 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %p.lastiter = alloca i32, align 4
  %p.lowerbound = alloca i32, align 4
  %p.upperbound = alloca i32, align 4
  %p.stride = alloca i32, align 4
  %1 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %omp_loop.tripcount = tail call i32 @llvm.smax.i32(i32 %1, i32 0)
  store i32 0, ptr %p.lowerbound, align 4
  %2 = add nsw i32 %omp_loop.tripcount, -1
  store i32 %2, ptr %p.upperbound, align 4
  store i32 1, ptr %p.stride, align 4
  %omp_global_thread_num4 = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  call void @__kmpc_for_static_init_4u(ptr nonnull @1, i32 %omp_global_thread_num4, i32 34, ptr nonnull %p.lastiter, ptr nonnull %p.lowerbound, ptr nonnull %p.upperbound, ptr nonnull %p.stride, i32 1, i32 0)
  %3 = load i32, ptr %p.lowerbound, align 4
  %4 = load i32, ptr %p.upperbound, align 4
  %5 = sub i32 %4, %3
  %6 = add i32 %5, 1
  br label %omp_loop.header

omp_loop.header:                                  ; preds = %omp_loop.body, %omp.par.entry
  %omp_loop.iv = phi i32 [ 0, %omp.par.entry ], [ %omp_loop.next, %omp_loop.body ]
  %omp_loop.cmp = icmp ult i32 %omp_loop.iv, %6
  br i1 %omp_loop.cmp, label %omp_loop.body, label %omp_loop.exit

omp_loop.exit:                                    ; preds = %omp_loop.header
  call void @__kmpc_for_static_fini(ptr nonnull @1, i32 %omp_global_thread_num4)
  call void @__kmpc_barrier(ptr nonnull @2, i32 %omp_global_thread_num4)
  ret void

omp_loop.body:                                    ; preds = %omp_loop.header
  %7 = add i32 %omp_loop.iv, %3
  %8 = add i32 %7, 1
  %9 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %10 = sitofp i32 %9 to float
  %11 = fdiv contract float 1.000000e+00, %10
  %12 = fpext float %11 to double
  %.unpack = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  %.unpack3 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  %.unpack4 = load i32, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  %.unpack5 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  %.unpack6 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  %.unpack7 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  %.unpack8 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  %.unpack9.unpack.unpack = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  %.unpack9.unpack.unpack11 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  %.unpack9.unpack.unpack12 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  store ptr %.unpack, ptr %loadgep_2, align 8, !tbaa !8
  %loadgep_2.repack14 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  store i64 %.unpack3, ptr %loadgep_2.repack14, align 8, !tbaa !8
  %loadgep_2.repack16 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  store i32 %.unpack4, ptr %loadgep_2.repack16, align 8, !tbaa !8
  %loadgep_2.repack18 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  store i8 %.unpack5, ptr %loadgep_2.repack18, align 4, !tbaa !8
  %loadgep_2.repack20 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  store i8 %.unpack6, ptr %loadgep_2.repack20, align 1, !tbaa !8
  %loadgep_2.repack22 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  store i8 %.unpack7, ptr %loadgep_2.repack22, align 2, !tbaa !8
  %loadgep_2.repack24 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  store i8 %.unpack8, ptr %loadgep_2.repack24, align 1, !tbaa !8
  %loadgep_2.repack26 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  store i64 %.unpack9.unpack.unpack, ptr %loadgep_2.repack26, align 8, !tbaa !8
  %loadgep_2.repack26.repack28 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack9.unpack.unpack11, ptr %loadgep_2.repack26.repack28, align 8, !tbaa !8
  %loadgep_2.repack26.repack30 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  store i64 %.unpack9.unpack.unpack12, ptr %loadgep_2.repack26.repack30, align 8, !tbaa !8
  %13 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 0
  %14 = load i64, ptr %13, align 8, !tbaa !8
  %15 = sext i32 %8 to i64
  %16 = sub i64 %15, %14
  %17 = getelementptr double, ptr %.unpack, i64 %16
  store double %12, ptr %17, align 8, !tbaa !4
  %omp_loop.next = add nuw i32 %omp_loop.iv, 1
  br label %omp_loop.header
}
*** IR Dump After SimplifyCFGPass on _QQmain..omp_par ***
; Function Attrs: norecurse nounwind
define internal void @_QQmain..omp_par(ptr noalias %tid.addr, ptr noalias %zero.addr, ptr %0) #2 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %p.lastiter = alloca i32, align 4
  %p.lowerbound = alloca i32, align 4
  %p.upperbound = alloca i32, align 4
  %p.stride = alloca i32, align 4
  %1 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %omp_loop.tripcount = tail call i32 @llvm.smax.i32(i32 %1, i32 0)
  store i32 0, ptr %p.lowerbound, align 4
  %2 = add nsw i32 %omp_loop.tripcount, -1
  store i32 %2, ptr %p.upperbound, align 4
  store i32 1, ptr %p.stride, align 4
  %omp_global_thread_num4 = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  call void @__kmpc_for_static_init_4u(ptr nonnull @1, i32 %omp_global_thread_num4, i32 34, ptr nonnull %p.lastiter, ptr nonnull %p.lowerbound, ptr nonnull %p.upperbound, ptr nonnull %p.stride, i32 1, i32 0)
  %3 = load i32, ptr %p.lowerbound, align 4
  %4 = load i32, ptr %p.upperbound, align 4
  %5 = sub i32 %4, %3
  %6 = add i32 %5, 1
  br label %omp_loop.header

omp_loop.header:                                  ; preds = %omp_loop.body, %omp.par.entry
  %omp_loop.iv = phi i32 [ 0, %omp.par.entry ], [ %omp_loop.next, %omp_loop.body ]
  %omp_loop.cmp = icmp ult i32 %omp_loop.iv, %6
  br i1 %omp_loop.cmp, label %omp_loop.body, label %omp_loop.exit

omp_loop.exit:                                    ; preds = %omp_loop.header
  call void @__kmpc_for_static_fini(ptr nonnull @1, i32 %omp_global_thread_num4)
  call void @__kmpc_barrier(ptr nonnull @2, i32 %omp_global_thread_num4)
  ret void

omp_loop.body:                                    ; preds = %omp_loop.header
  %7 = add i32 %omp_loop.iv, %3
  %8 = add i32 %7, 1
  %9 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %10 = sitofp i32 %9 to float
  %11 = fdiv contract float 1.000000e+00, %10
  %12 = fpext float %11 to double
  %.unpack = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  %.unpack3 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  %.unpack4 = load i32, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  %.unpack5 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  %.unpack6 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  %.unpack7 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  %.unpack8 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  %.unpack9.unpack.unpack = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  %.unpack9.unpack.unpack11 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  %.unpack9.unpack.unpack12 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  store ptr %.unpack, ptr %loadgep_2, align 8, !tbaa !8
  %loadgep_2.repack14 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  store i64 %.unpack3, ptr %loadgep_2.repack14, align 8, !tbaa !8
  %loadgep_2.repack16 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  store i32 %.unpack4, ptr %loadgep_2.repack16, align 8, !tbaa !8
  %loadgep_2.repack18 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  store i8 %.unpack5, ptr %loadgep_2.repack18, align 4, !tbaa !8
  %loadgep_2.repack20 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  store i8 %.unpack6, ptr %loadgep_2.repack20, align 1, !tbaa !8
  %loadgep_2.repack22 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  store i8 %.unpack7, ptr %loadgep_2.repack22, align 2, !tbaa !8
  %loadgep_2.repack24 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  store i8 %.unpack8, ptr %loadgep_2.repack24, align 1, !tbaa !8
  %loadgep_2.repack26 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  store i64 %.unpack9.unpack.unpack, ptr %loadgep_2.repack26, align 8, !tbaa !8
  %loadgep_2.repack26.repack28 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack9.unpack.unpack11, ptr %loadgep_2.repack26.repack28, align 8, !tbaa !8
  %loadgep_2.repack26.repack30 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  store i64 %.unpack9.unpack.unpack12, ptr %loadgep_2.repack26.repack30, align 8, !tbaa !8
  %13 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 0
  %14 = load i64, ptr %13, align 8, !tbaa !8
  %15 = sext i32 %8 to i64
  %16 = sub i64 %15, %14
  %17 = getelementptr double, ptr %.unpack, i64 %16
  store double %12, ptr %17, align 8, !tbaa !4
  %omp_loop.next = add nuw i32 %omp_loop.iv, 1
  br label %omp_loop.header
}
*** IR Dump After ReassociatePass on _QQmain..omp_par ***
; Function Attrs: norecurse nounwind
define internal void @_QQmain..omp_par(ptr noalias %tid.addr, ptr noalias %zero.addr, ptr %0) #2 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %p.lastiter = alloca i32, align 4
  %p.lowerbound = alloca i32, align 4
  %p.upperbound = alloca i32, align 4
  %p.stride = alloca i32, align 4
  %1 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %omp_loop.tripcount = tail call i32 @llvm.smax.i32(i32 %1, i32 0)
  store i32 0, ptr %p.lowerbound, align 4
  %2 = add nsw i32 %omp_loop.tripcount, -1
  store i32 %2, ptr %p.upperbound, align 4
  store i32 1, ptr %p.stride, align 4
  %omp_global_thread_num4 = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  call void @__kmpc_for_static_init_4u(ptr nonnull @1, i32 %omp_global_thread_num4, i32 34, ptr nonnull %p.lastiter, ptr nonnull %p.lowerbound, ptr nonnull %p.upperbound, ptr nonnull %p.stride, i32 1, i32 0)
  %3 = load i32, ptr %p.lowerbound, align 4
  %4 = load i32, ptr %p.upperbound, align 4
  %.neg = sub i32 0, %3
  %5 = add i32 %.neg, 1
  %6 = add i32 %5, %4
  br label %omp_loop.header

omp_loop.header:                                  ; preds = %omp_loop.body, %omp.par.entry
  %omp_loop.iv = phi i32 [ 0, %omp.par.entry ], [ %omp_loop.next, %omp_loop.body ]
  %omp_loop.cmp = icmp ult i32 %omp_loop.iv, %6
  br i1 %omp_loop.cmp, label %omp_loop.body, label %omp_loop.exit

omp_loop.exit:                                    ; preds = %omp_loop.header
  call void @__kmpc_for_static_fini(ptr nonnull @1, i32 %omp_global_thread_num4)
  call void @__kmpc_barrier(ptr nonnull @2, i32 %omp_global_thread_num4)
  ret void

omp_loop.body:                                    ; preds = %omp_loop.header
  %7 = add i32 %omp_loop.iv, 1
  %8 = add i32 %7, %3
  %9 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %10 = sitofp i32 %9 to float
  %11 = fdiv contract float 1.000000e+00, %10
  %12 = fpext float %11 to double
  %.unpack = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  %.unpack3 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  %.unpack4 = load i32, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  %.unpack5 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  %.unpack6 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  %.unpack7 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  %.unpack8 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  %.unpack9.unpack.unpack = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  %.unpack9.unpack.unpack11 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  %.unpack9.unpack.unpack12 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  store ptr %.unpack, ptr %loadgep_2, align 8, !tbaa !8
  %loadgep_2.repack14 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  store i64 %.unpack3, ptr %loadgep_2.repack14, align 8, !tbaa !8
  %loadgep_2.repack16 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  store i32 %.unpack4, ptr %loadgep_2.repack16, align 8, !tbaa !8
  %loadgep_2.repack18 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  store i8 %.unpack5, ptr %loadgep_2.repack18, align 4, !tbaa !8
  %loadgep_2.repack20 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  store i8 %.unpack6, ptr %loadgep_2.repack20, align 1, !tbaa !8
  %loadgep_2.repack22 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  store i8 %.unpack7, ptr %loadgep_2.repack22, align 2, !tbaa !8
  %loadgep_2.repack24 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  store i8 %.unpack8, ptr %loadgep_2.repack24, align 1, !tbaa !8
  %loadgep_2.repack26 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  store i64 %.unpack9.unpack.unpack, ptr %loadgep_2.repack26, align 8, !tbaa !8
  %loadgep_2.repack26.repack28 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack9.unpack.unpack11, ptr %loadgep_2.repack26.repack28, align 8, !tbaa !8
  %loadgep_2.repack26.repack30 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  store i64 %.unpack9.unpack.unpack12, ptr %loadgep_2.repack26.repack30, align 8, !tbaa !8
  %13 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 0
  %14 = load i64, ptr %13, align 8, !tbaa !8
  %15 = sext i32 %8 to i64
  %16 = sub i64 %15, %14
  %17 = getelementptr double, ptr %.unpack, i64 %16
  store double %12, ptr %17, align 8, !tbaa !4
  %omp_loop.next = add nuw i32 %omp_loop.iv, 1
  br label %omp_loop.header
}
*** IR Dump After LoopSimplifyPass on _QQmain..omp_par ***
; Function Attrs: norecurse nounwind
define internal void @_QQmain..omp_par(ptr noalias %tid.addr, ptr noalias %zero.addr, ptr %0) #2 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %p.lastiter = alloca i32, align 4
  %p.lowerbound = alloca i32, align 4
  %p.upperbound = alloca i32, align 4
  %p.stride = alloca i32, align 4
  %1 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %omp_loop.tripcount = tail call i32 @llvm.smax.i32(i32 %1, i32 0)
  store i32 0, ptr %p.lowerbound, align 4
  %2 = add nsw i32 %omp_loop.tripcount, -1
  store i32 %2, ptr %p.upperbound, align 4
  store i32 1, ptr %p.stride, align 4
  %omp_global_thread_num4 = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  call void @__kmpc_for_static_init_4u(ptr nonnull @1, i32 %omp_global_thread_num4, i32 34, ptr nonnull %p.lastiter, ptr nonnull %p.lowerbound, ptr nonnull %p.upperbound, ptr nonnull %p.stride, i32 1, i32 0)
  %3 = load i32, ptr %p.lowerbound, align 4
  %4 = load i32, ptr %p.upperbound, align 4
  %.neg = sub i32 0, %3
  %5 = add i32 %.neg, 1
  %6 = add i32 %5, %4
  br label %omp_loop.header

omp_loop.header:                                  ; preds = %omp_loop.body, %omp.par.entry
  %omp_loop.iv = phi i32 [ 0, %omp.par.entry ], [ %omp_loop.next, %omp_loop.body ]
  %omp_loop.cmp = icmp ult i32 %omp_loop.iv, %6
  br i1 %omp_loop.cmp, label %omp_loop.body, label %omp_loop.exit

omp_loop.exit:                                    ; preds = %omp_loop.header
  call void @__kmpc_for_static_fini(ptr nonnull @1, i32 %omp_global_thread_num4)
  call void @__kmpc_barrier(ptr nonnull @2, i32 %omp_global_thread_num4)
  ret void

omp_loop.body:                                    ; preds = %omp_loop.header
  %7 = add i32 %omp_loop.iv, 1
  %8 = add i32 %7, %3
  %9 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %10 = sitofp i32 %9 to float
  %11 = fdiv contract float 1.000000e+00, %10
  %12 = fpext float %11 to double
  %.unpack = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  %.unpack3 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  %.unpack4 = load i32, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  %.unpack5 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  %.unpack6 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  %.unpack7 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  %.unpack8 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  %.unpack9.unpack.unpack = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  %.unpack9.unpack.unpack11 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  %.unpack9.unpack.unpack12 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  store ptr %.unpack, ptr %loadgep_2, align 8, !tbaa !8
  %loadgep_2.repack14 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  store i64 %.unpack3, ptr %loadgep_2.repack14, align 8, !tbaa !8
  %loadgep_2.repack16 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  store i32 %.unpack4, ptr %loadgep_2.repack16, align 8, !tbaa !8
  %loadgep_2.repack18 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  store i8 %.unpack5, ptr %loadgep_2.repack18, align 4, !tbaa !8
  %loadgep_2.repack20 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  store i8 %.unpack6, ptr %loadgep_2.repack20, align 1, !tbaa !8
  %loadgep_2.repack22 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  store i8 %.unpack7, ptr %loadgep_2.repack22, align 2, !tbaa !8
  %loadgep_2.repack24 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  store i8 %.unpack8, ptr %loadgep_2.repack24, align 1, !tbaa !8
  %loadgep_2.repack26 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  store i64 %.unpack9.unpack.unpack, ptr %loadgep_2.repack26, align 8, !tbaa !8
  %loadgep_2.repack26.repack28 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack9.unpack.unpack11, ptr %loadgep_2.repack26.repack28, align 8, !tbaa !8
  %loadgep_2.repack26.repack30 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  store i64 %.unpack9.unpack.unpack12, ptr %loadgep_2.repack26.repack30, align 8, !tbaa !8
  %13 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 0
  %14 = load i64, ptr %13, align 8, !tbaa !8
  %15 = sext i32 %8 to i64
  %16 = sub i64 %15, %14
  %17 = getelementptr double, ptr %.unpack, i64 %16
  store double %12, ptr %17, align 8, !tbaa !4
  %omp_loop.next = add nuw i32 %omp_loop.iv, 1
  br label %omp_loop.header
}
*** IR Dump After LCSSAPass on _QQmain..omp_par ***
; Function Attrs: norecurse nounwind
define internal void @_QQmain..omp_par(ptr noalias %tid.addr, ptr noalias %zero.addr, ptr %0) #2 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %p.lastiter = alloca i32, align 4
  %p.lowerbound = alloca i32, align 4
  %p.upperbound = alloca i32, align 4
  %p.stride = alloca i32, align 4
  %1 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %omp_loop.tripcount = tail call i32 @llvm.smax.i32(i32 %1, i32 0)
  store i32 0, ptr %p.lowerbound, align 4
  %2 = add nsw i32 %omp_loop.tripcount, -1
  store i32 %2, ptr %p.upperbound, align 4
  store i32 1, ptr %p.stride, align 4
  %omp_global_thread_num4 = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  call void @__kmpc_for_static_init_4u(ptr nonnull @1, i32 %omp_global_thread_num4, i32 34, ptr nonnull %p.lastiter, ptr nonnull %p.lowerbound, ptr nonnull %p.upperbound, ptr nonnull %p.stride, i32 1, i32 0)
  %3 = load i32, ptr %p.lowerbound, align 4
  %4 = load i32, ptr %p.upperbound, align 4
  %.neg = sub i32 0, %3
  %5 = add i32 %.neg, 1
  %6 = add i32 %5, %4
  br label %omp_loop.header

omp_loop.header:                                  ; preds = %omp_loop.body, %omp.par.entry
  %omp_loop.iv = phi i32 [ 0, %omp.par.entry ], [ %omp_loop.next, %omp_loop.body ]
  %omp_loop.cmp = icmp ult i32 %omp_loop.iv, %6
  br i1 %omp_loop.cmp, label %omp_loop.body, label %omp_loop.exit

omp_loop.exit:                                    ; preds = %omp_loop.header
  call void @__kmpc_for_static_fini(ptr nonnull @1, i32 %omp_global_thread_num4)
  call void @__kmpc_barrier(ptr nonnull @2, i32 %omp_global_thread_num4)
  ret void

omp_loop.body:                                    ; preds = %omp_loop.header
  %7 = add i32 %omp_loop.iv, 1
  %8 = add i32 %7, %3
  %9 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %10 = sitofp i32 %9 to float
  %11 = fdiv contract float 1.000000e+00, %10
  %12 = fpext float %11 to double
  %.unpack = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  %.unpack3 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  %.unpack4 = load i32, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  %.unpack5 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  %.unpack6 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  %.unpack7 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  %.unpack8 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  %.unpack9.unpack.unpack = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  %.unpack9.unpack.unpack11 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  %.unpack9.unpack.unpack12 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  store ptr %.unpack, ptr %loadgep_2, align 8, !tbaa !8
  %loadgep_2.repack14 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  store i64 %.unpack3, ptr %loadgep_2.repack14, align 8, !tbaa !8
  %loadgep_2.repack16 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  store i32 %.unpack4, ptr %loadgep_2.repack16, align 8, !tbaa !8
  %loadgep_2.repack18 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  store i8 %.unpack5, ptr %loadgep_2.repack18, align 4, !tbaa !8
  %loadgep_2.repack20 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  store i8 %.unpack6, ptr %loadgep_2.repack20, align 1, !tbaa !8
  %loadgep_2.repack22 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  store i8 %.unpack7, ptr %loadgep_2.repack22, align 2, !tbaa !8
  %loadgep_2.repack24 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  store i8 %.unpack8, ptr %loadgep_2.repack24, align 1, !tbaa !8
  %loadgep_2.repack26 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  store i64 %.unpack9.unpack.unpack, ptr %loadgep_2.repack26, align 8, !tbaa !8
  %loadgep_2.repack26.repack28 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack9.unpack.unpack11, ptr %loadgep_2.repack26.repack28, align 8, !tbaa !8
  %loadgep_2.repack26.repack30 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  store i64 %.unpack9.unpack.unpack12, ptr %loadgep_2.repack26.repack30, align 8, !tbaa !8
  %13 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 0
  %14 = load i64, ptr %13, align 8, !tbaa !8
  %15 = sext i32 %8 to i64
  %16 = sub i64 %15, %14
  %17 = getelementptr double, ptr %.unpack, i64 %16
  store double %12, ptr %17, align 8, !tbaa !4
  %omp_loop.next = add nuw i32 %omp_loop.iv, 1
  br label %omp_loop.header
}
*** IR Dump After LoopInstSimplifyPass on omp_loop.header ***

; Preheader:
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %p.lastiter = alloca i32, align 4
  %p.lowerbound = alloca i32, align 4
  %p.upperbound = alloca i32, align 4
  %p.stride = alloca i32, align 4
  %1 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %omp_loop.tripcount = tail call i32 @llvm.smax.i32(i32 %1, i32 0)
  store i32 0, ptr %p.lowerbound, align 4
  %2 = add nsw i32 %omp_loop.tripcount, -1
  store i32 %2, ptr %p.upperbound, align 4
  store i32 1, ptr %p.stride, align 4
  %omp_global_thread_num4 = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  call void @__kmpc_for_static_init_4u(ptr nonnull @1, i32 %omp_global_thread_num4, i32 34, ptr nonnull %p.lastiter, ptr nonnull %p.lowerbound, ptr nonnull %p.upperbound, ptr nonnull %p.stride, i32 1, i32 0)
  %3 = load i32, ptr %p.lowerbound, align 4
  %4 = load i32, ptr %p.upperbound, align 4
  %.neg = sub i32 0, %3
  %5 = add i32 %.neg, 1
  %6 = add i32 %5, %4
  br label %omp_loop.header

; Loop:
omp_loop.header:                                  ; preds = %omp_loop.body, %omp.par.entry
  %omp_loop.iv = phi i32 [ 0, %omp.par.entry ], [ %omp_loop.next, %omp_loop.body ]
  %omp_loop.cmp = icmp ult i32 %omp_loop.iv, %6
  br i1 %omp_loop.cmp, label %omp_loop.body, label %omp_loop.exit

omp_loop.body:                                    ; preds = %omp_loop.header
  %7 = add i32 %omp_loop.iv, 1
  %8 = add i32 %7, %3
  %9 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %10 = sitofp i32 %9 to float
  %11 = fdiv contract float 1.000000e+00, %10
  %12 = fpext float %11 to double
  %.unpack = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  %.unpack3 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  %.unpack4 = load i32, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  %.unpack5 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  %.unpack6 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  %.unpack7 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  %.unpack8 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  %.unpack9.unpack.unpack = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  %.unpack9.unpack.unpack11 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  %.unpack9.unpack.unpack12 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  store ptr %.unpack, ptr %loadgep_2, align 8, !tbaa !8
  %loadgep_2.repack14 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  store i64 %.unpack3, ptr %loadgep_2.repack14, align 8, !tbaa !8
  %loadgep_2.repack16 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  store i32 %.unpack4, ptr %loadgep_2.repack16, align 8, !tbaa !8
  %loadgep_2.repack18 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  store i8 %.unpack5, ptr %loadgep_2.repack18, align 4, !tbaa !8
  %loadgep_2.repack20 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  store i8 %.unpack6, ptr %loadgep_2.repack20, align 1, !tbaa !8
  %loadgep_2.repack22 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  store i8 %.unpack7, ptr %loadgep_2.repack22, align 2, !tbaa !8
  %loadgep_2.repack24 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  store i8 %.unpack8, ptr %loadgep_2.repack24, align 1, !tbaa !8
  %loadgep_2.repack26 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  store i64 %.unpack9.unpack.unpack, ptr %loadgep_2.repack26, align 8, !tbaa !8
  %loadgep_2.repack26.repack28 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack9.unpack.unpack11, ptr %loadgep_2.repack26.repack28, align 8, !tbaa !8
  %loadgep_2.repack26.repack30 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  store i64 %.unpack9.unpack.unpack12, ptr %loadgep_2.repack26.repack30, align 8, !tbaa !8
  %13 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 0
  %14 = load i64, ptr %13, align 8, !tbaa !8
  %15 = sext i32 %8 to i64
  %16 = sub i64 %15, %14
  %17 = getelementptr double, ptr %.unpack, i64 %16
  store double %12, ptr %17, align 8, !tbaa !4
  %omp_loop.next = add nuw i32 %omp_loop.iv, 1
  br label %omp_loop.header

; Exit blocks
omp_loop.exit:                                    ; preds = %omp_loop.header
  call void @__kmpc_for_static_fini(ptr nonnull @1, i32 %omp_global_thread_num4)
  call void @__kmpc_barrier(ptr nonnull @2, i32 %omp_global_thread_num4)
  ret void
*** IR Dump After LoopSimplifyCFGPass on omp_loop.header ***

; Preheader:
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %p.lastiter = alloca i32, align 4
  %p.lowerbound = alloca i32, align 4
  %p.upperbound = alloca i32, align 4
  %p.stride = alloca i32, align 4
  %1 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %omp_loop.tripcount = tail call i32 @llvm.smax.i32(i32 %1, i32 0)
  store i32 0, ptr %p.lowerbound, align 4
  %2 = add nsw i32 %omp_loop.tripcount, -1
  store i32 %2, ptr %p.upperbound, align 4
  store i32 1, ptr %p.stride, align 4
  %omp_global_thread_num4 = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  call void @__kmpc_for_static_init_4u(ptr nonnull @1, i32 %omp_global_thread_num4, i32 34, ptr nonnull %p.lastiter, ptr nonnull %p.lowerbound, ptr nonnull %p.upperbound, ptr nonnull %p.stride, i32 1, i32 0)
  %3 = load i32, ptr %p.lowerbound, align 4
  %4 = load i32, ptr %p.upperbound, align 4
  %.neg = sub i32 0, %3
  %5 = add i32 %.neg, 1
  %6 = add i32 %5, %4
  br label %omp_loop.header

; Loop:
omp_loop.header:                                  ; preds = %omp_loop.body, %omp.par.entry
  %omp_loop.iv = phi i32 [ 0, %omp.par.entry ], [ %omp_loop.next, %omp_loop.body ]
  %omp_loop.cmp = icmp ult i32 %omp_loop.iv, %6
  br i1 %omp_loop.cmp, label %omp_loop.body, label %omp_loop.exit

omp_loop.body:                                    ; preds = %omp_loop.header
  %7 = add i32 %omp_loop.iv, 1
  %8 = add i32 %7, %3
  %9 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %10 = sitofp i32 %9 to float
  %11 = fdiv contract float 1.000000e+00, %10
  %12 = fpext float %11 to double
  %.unpack = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  %.unpack3 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  %.unpack4 = load i32, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  %.unpack5 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  %.unpack6 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  %.unpack7 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  %.unpack8 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  %.unpack9.unpack.unpack = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  %.unpack9.unpack.unpack11 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  %.unpack9.unpack.unpack12 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  store ptr %.unpack, ptr %loadgep_2, align 8, !tbaa !8
  %loadgep_2.repack14 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  store i64 %.unpack3, ptr %loadgep_2.repack14, align 8, !tbaa !8
  %loadgep_2.repack16 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  store i32 %.unpack4, ptr %loadgep_2.repack16, align 8, !tbaa !8
  %loadgep_2.repack18 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  store i8 %.unpack5, ptr %loadgep_2.repack18, align 4, !tbaa !8
  %loadgep_2.repack20 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  store i8 %.unpack6, ptr %loadgep_2.repack20, align 1, !tbaa !8
  %loadgep_2.repack22 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  store i8 %.unpack7, ptr %loadgep_2.repack22, align 2, !tbaa !8
  %loadgep_2.repack24 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  store i8 %.unpack8, ptr %loadgep_2.repack24, align 1, !tbaa !8
  %loadgep_2.repack26 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  store i64 %.unpack9.unpack.unpack, ptr %loadgep_2.repack26, align 8, !tbaa !8
  %loadgep_2.repack26.repack28 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack9.unpack.unpack11, ptr %loadgep_2.repack26.repack28, align 8, !tbaa !8
  %loadgep_2.repack26.repack30 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  store i64 %.unpack9.unpack.unpack12, ptr %loadgep_2.repack26.repack30, align 8, !tbaa !8
  %13 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 0
  %14 = load i64, ptr %13, align 8, !tbaa !8
  %15 = sext i32 %8 to i64
  %16 = sub i64 %15, %14
  %17 = getelementptr double, ptr %.unpack, i64 %16
  store double %12, ptr %17, align 8, !tbaa !4
  %omp_loop.next = add nuw i32 %omp_loop.iv, 1
  br label %omp_loop.header

; Exit blocks
omp_loop.exit:                                    ; preds = %omp_loop.header
  call void @__kmpc_for_static_fini(ptr nonnull @1, i32 %omp_global_thread_num4)
  call void @__kmpc_barrier(ptr nonnull @2, i32 %omp_global_thread_num4)
  ret void
*** IR Dump After LICMPass on omp_loop.header ***

; Preheader:
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %p.lastiter = alloca i32, align 4
  %p.lowerbound = alloca i32, align 4
  %p.upperbound = alloca i32, align 4
  %p.stride = alloca i32, align 4
  %1 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %omp_loop.tripcount = tail call i32 @llvm.smax.i32(i32 %1, i32 0)
  store i32 0, ptr %p.lowerbound, align 4
  %2 = add nsw i32 %omp_loop.tripcount, -1
  store i32 %2, ptr %p.upperbound, align 4
  store i32 1, ptr %p.stride, align 4
  %omp_global_thread_num4 = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  call void @__kmpc_for_static_init_4u(ptr nonnull @1, i32 %omp_global_thread_num4, i32 34, ptr nonnull %p.lastiter, ptr nonnull %p.lowerbound, ptr nonnull %p.upperbound, ptr nonnull %p.stride, i32 1, i32 0)
  %3 = load i32, ptr %p.lowerbound, align 4
  %4 = load i32, ptr %p.upperbound, align 4
  %.neg = sub i32 0, %3
  %5 = add i32 %.neg, 1
  %6 = add i32 %5, %4
  br label %omp_loop.header

; Loop:
omp_loop.header:                                  ; preds = %omp_loop.body, %omp.par.entry
  %omp_loop.iv = phi i32 [ 0, %omp.par.entry ], [ %omp_loop.next, %omp_loop.body ]
  %omp_loop.cmp = icmp ult i32 %omp_loop.iv, %6
  br i1 %omp_loop.cmp, label %omp_loop.body, label %omp_loop.exit

omp_loop.body:                                    ; preds = %omp_loop.header
  %7 = add i32 %omp_loop.iv, 1
  %8 = add i32 %7, %3
  %9 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %10 = sitofp i32 %9 to float
  %11 = fdiv contract float 1.000000e+00, %10
  %12 = fpext float %11 to double
  %.unpack = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  %.unpack3 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  %.unpack4 = load i32, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  %.unpack5 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  %.unpack6 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  %.unpack7 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  %.unpack8 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  %.unpack9.unpack.unpack = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  %.unpack9.unpack.unpack11 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  %.unpack9.unpack.unpack12 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  store ptr %.unpack, ptr %loadgep_2, align 8, !tbaa !8
  %loadgep_2.repack14 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  store i64 %.unpack3, ptr %loadgep_2.repack14, align 8, !tbaa !8
  %loadgep_2.repack16 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  store i32 %.unpack4, ptr %loadgep_2.repack16, align 8, !tbaa !8
  %loadgep_2.repack18 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  store i8 %.unpack5, ptr %loadgep_2.repack18, align 4, !tbaa !8
  %loadgep_2.repack20 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  store i8 %.unpack6, ptr %loadgep_2.repack20, align 1, !tbaa !8
  %loadgep_2.repack22 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  store i8 %.unpack7, ptr %loadgep_2.repack22, align 2, !tbaa !8
  %loadgep_2.repack24 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  store i8 %.unpack8, ptr %loadgep_2.repack24, align 1, !tbaa !8
  %loadgep_2.repack26 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  store i64 %.unpack9.unpack.unpack, ptr %loadgep_2.repack26, align 8, !tbaa !8
  %loadgep_2.repack26.repack28 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack9.unpack.unpack11, ptr %loadgep_2.repack26.repack28, align 8, !tbaa !8
  %loadgep_2.repack26.repack30 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  store i64 %.unpack9.unpack.unpack12, ptr %loadgep_2.repack26.repack30, align 8, !tbaa !8
  %13 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 0
  %14 = load i64, ptr %13, align 8, !tbaa !8
  %15 = sext i32 %8 to i64
  %16 = sub i64 %15, %14
  %17 = getelementptr double, ptr %.unpack, i64 %16
  store double %12, ptr %17, align 8, !tbaa !4
  %omp_loop.next = add nuw i32 %omp_loop.iv, 1
  br label %omp_loop.header

; Exit blocks
omp_loop.exit:                                    ; preds = %omp_loop.header
  call void @__kmpc_for_static_fini(ptr nonnull @1, i32 %omp_global_thread_num4)
  call void @__kmpc_barrier(ptr nonnull @2, i32 %omp_global_thread_num4)
  ret void
*** IR Dump After LoopRotatePass on omp_loop.header ***

; Preheader:
omp_loop.body.lr.ph:                              ; preds = %omp.par.entry
  br label %omp_loop.body

; Loop:
omp_loop.body:                                    ; preds = %omp_loop.body.lr.ph, %omp_loop.body
  %omp_loop.iv33 = phi i32 [ 0, %omp_loop.body.lr.ph ], [ %omp_loop.next, %omp_loop.body ]
  %7 = add i32 %omp_loop.iv33, 1
  %8 = add i32 %7, %3
  %9 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %10 = sitofp i32 %9 to float
  %11 = fdiv contract float 1.000000e+00, %10
  %12 = fpext float %11 to double
  %.unpack = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  %.unpack3 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  %.unpack4 = load i32, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  %.unpack5 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  %.unpack6 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  %.unpack7 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  %.unpack8 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  %.unpack9.unpack.unpack = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  %.unpack9.unpack.unpack11 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  %.unpack9.unpack.unpack12 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  store ptr %.unpack, ptr %loadgep_2, align 8, !tbaa !8
  %loadgep_2.repack14 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  store i64 %.unpack3, ptr %loadgep_2.repack14, align 8, !tbaa !8
  %loadgep_2.repack16 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  store i32 %.unpack4, ptr %loadgep_2.repack16, align 8, !tbaa !8
  %loadgep_2.repack18 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  store i8 %.unpack5, ptr %loadgep_2.repack18, align 4, !tbaa !8
  %loadgep_2.repack20 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  store i8 %.unpack6, ptr %loadgep_2.repack20, align 1, !tbaa !8
  %loadgep_2.repack22 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  store i8 %.unpack7, ptr %loadgep_2.repack22, align 2, !tbaa !8
  %loadgep_2.repack24 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  store i8 %.unpack8, ptr %loadgep_2.repack24, align 1, !tbaa !8
  %loadgep_2.repack26 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  store i64 %.unpack9.unpack.unpack, ptr %loadgep_2.repack26, align 8, !tbaa !8
  %loadgep_2.repack26.repack28 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack9.unpack.unpack11, ptr %loadgep_2.repack26.repack28, align 8, !tbaa !8
  %loadgep_2.repack26.repack30 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  store i64 %.unpack9.unpack.unpack12, ptr %loadgep_2.repack26.repack30, align 8, !tbaa !8
  %13 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 0
  %14 = load i64, ptr %13, align 8, !tbaa !8
  %15 = sext i32 %8 to i64
  %16 = sub i64 %15, %14
  %17 = getelementptr double, ptr %.unpack, i64 %16
  store double %12, ptr %17, align 8, !tbaa !4
  %omp_loop.next = add nuw i32 %omp_loop.iv33, 1
  %omp_loop.cmp = icmp ult i32 %omp_loop.next, %6
  br i1 %omp_loop.cmp, label %omp_loop.body, label %omp_loop.header.omp_loop.exit_crit_edge

; Exit blocks
omp_loop.header.omp_loop.exit_crit_edge:          ; preds = %omp_loop.body
  br label %omp_loop.exit
*** IR Dump After LICMPass on omp_loop.body ***

; Preheader:
omp_loop.body.lr.ph:                              ; preds = %omp.par.entry
  %.unpack = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  %.unpack3 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  %.unpack4 = load i32, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  %.unpack5 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  %.unpack6 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  %.unpack7 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  %.unpack8 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  %.unpack9.unpack.unpack = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  %.unpack9.unpack.unpack11 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  %.unpack9.unpack.unpack12 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  %loadgep_2.repack14 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  %loadgep_2.repack16 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  %loadgep_2.repack18 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  %loadgep_2.repack20 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  %loadgep_2.repack22 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  %loadgep_2.repack24 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  %loadgep_2.repack26 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  %loadgep_2.repack26.repack28 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  %loadgep_2.repack26.repack30 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  %7 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 0
  br label %omp_loop.body

; Loop:
omp_loop.body:                                    ; preds = %omp_loop.body.lr.ph, %omp_loop.body
  %omp_loop.iv33 = phi i32 [ 0, %omp_loop.body.lr.ph ], [ %omp_loop.next, %omp_loop.body ]
  %8 = add i32 %omp_loop.iv33, 1
  %9 = add i32 %8, %3
  %10 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %11 = sitofp i32 %10 to float
  %12 = fdiv contract float 1.000000e+00, %11
  %13 = fpext float %12 to double
  %14 = sext i32 %9 to i64
  %15 = sub i64 %14, %.unpack9.unpack.unpack
  %16 = getelementptr double, ptr %.unpack, i64 %15
  store double %13, ptr %16, align 8, !tbaa !4
  %omp_loop.next = add nuw i32 %omp_loop.iv33, 1
  %omp_loop.cmp = icmp ult i32 %omp_loop.next, %6
  br i1 %omp_loop.cmp, label %omp_loop.body, label %omp_loop.header.omp_loop.exit_crit_edge

; Exit blocks
omp_loop.header.omp_loop.exit_crit_edge:          ; preds = %omp_loop.body
  store ptr %.unpack, ptr %loadgep_2, align 8, !tbaa !8
  store i64 %.unpack3, ptr %loadgep_2.repack14, align 8, !tbaa !8
  store i32 %.unpack4, ptr %loadgep_2.repack16, align 8, !tbaa !8
  store i8 %.unpack5, ptr %loadgep_2.repack18, align 4, !tbaa !8
  store i8 %.unpack6, ptr %loadgep_2.repack20, align 1, !tbaa !8
  store i8 %.unpack7, ptr %loadgep_2.repack22, align 2, !tbaa !8
  store i8 %.unpack8, ptr %loadgep_2.repack24, align 1, !tbaa !8
  store i64 %.unpack9.unpack.unpack, ptr %loadgep_2.repack26, align 8, !tbaa !8
  store i64 %.unpack9.unpack.unpack11, ptr %loadgep_2.repack26.repack28, align 8, !tbaa !8
  store i64 %.unpack9.unpack.unpack12, ptr %loadgep_2.repack26.repack30, align 8, !tbaa !8
  br label %omp_loop.exit
*** IR Dump After SimpleLoopUnswitchPass on omp_loop.body ***

; Preheader:
omp_loop.body.lr.ph:                              ; preds = %omp.par.entry
  %.unpack = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  %.unpack3 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  %.unpack4 = load i32, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  %.unpack5 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  %.unpack6 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  %.unpack7 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  %.unpack8 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  %.unpack9.unpack.unpack = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  %.unpack9.unpack.unpack11 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  %.unpack9.unpack.unpack12 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  %loadgep_2.repack14 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  %loadgep_2.repack16 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  %loadgep_2.repack18 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  %loadgep_2.repack20 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  %loadgep_2.repack22 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  %loadgep_2.repack24 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  %loadgep_2.repack26 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  %loadgep_2.repack26.repack28 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  %loadgep_2.repack26.repack30 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  %7 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 0
  br label %omp_loop.body

; Loop:
omp_loop.body:                                    ; preds = %omp_loop.body.lr.ph, %omp_loop.body
  %omp_loop.iv33 = phi i32 [ 0, %omp_loop.body.lr.ph ], [ %omp_loop.next, %omp_loop.body ]
  %8 = add i32 %omp_loop.iv33, 1
  %9 = add i32 %8, %3
  %10 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %11 = sitofp i32 %10 to float
  %12 = fdiv contract float 1.000000e+00, %11
  %13 = fpext float %12 to double
  %14 = sext i32 %9 to i64
  %15 = sub i64 %14, %.unpack9.unpack.unpack
  %16 = getelementptr double, ptr %.unpack, i64 %15
  store double %13, ptr %16, align 8, !tbaa !4
  %omp_loop.next = add nuw i32 %omp_loop.iv33, 1
  %omp_loop.cmp = icmp ult i32 %omp_loop.next, %6
  br i1 %omp_loop.cmp, label %omp_loop.body, label %omp_loop.header.omp_loop.exit_crit_edge

; Exit blocks
omp_loop.header.omp_loop.exit_crit_edge:          ; preds = %omp_loop.body
  store ptr %.unpack, ptr %loadgep_2, align 8, !tbaa !8
  store i64 %.unpack3, ptr %loadgep_2.repack14, align 8, !tbaa !8
  store i32 %.unpack4, ptr %loadgep_2.repack16, align 8, !tbaa !8
  store i8 %.unpack5, ptr %loadgep_2.repack18, align 4, !tbaa !8
  store i8 %.unpack6, ptr %loadgep_2.repack20, align 1, !tbaa !8
  store i8 %.unpack7, ptr %loadgep_2.repack22, align 2, !tbaa !8
  store i8 %.unpack8, ptr %loadgep_2.repack24, align 1, !tbaa !8
  store i64 %.unpack9.unpack.unpack, ptr %loadgep_2.repack26, align 8, !tbaa !8
  store i64 %.unpack9.unpack.unpack11, ptr %loadgep_2.repack26.repack28, align 8, !tbaa !8
  store i64 %.unpack9.unpack.unpack12, ptr %loadgep_2.repack26.repack30, align 8, !tbaa !8
  br label %omp_loop.exit
*** IR Dump After SimplifyCFGPass on _QQmain..omp_par ***
; Function Attrs: norecurse nounwind
define internal void @_QQmain..omp_par(ptr noalias %tid.addr, ptr noalias %zero.addr, ptr %0) #2 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %p.lastiter = alloca i32, align 4
  %p.lowerbound = alloca i32, align 4
  %p.upperbound = alloca i32, align 4
  %p.stride = alloca i32, align 4
  %1 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %omp_loop.tripcount = tail call i32 @llvm.smax.i32(i32 %1, i32 0)
  store i32 0, ptr %p.lowerbound, align 4
  %2 = add nsw i32 %omp_loop.tripcount, -1
  store i32 %2, ptr %p.upperbound, align 4
  store i32 1, ptr %p.stride, align 4
  %omp_global_thread_num4 = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  call void @__kmpc_for_static_init_4u(ptr nonnull @1, i32 %omp_global_thread_num4, i32 34, ptr nonnull %p.lastiter, ptr nonnull %p.lowerbound, ptr nonnull %p.upperbound, ptr nonnull %p.stride, i32 1, i32 0)
  %3 = load i32, ptr %p.lowerbound, align 4
  %4 = load i32, ptr %p.upperbound, align 4
  %.neg = sub i32 0, %3
  %5 = add i32 %.neg, 1
  %6 = add i32 %5, %4
  %omp_loop.cmp32 = icmp ult i32 0, %6
  br i1 %omp_loop.cmp32, label %omp_loop.body.lr.ph, label %omp_loop.exit

omp_loop.body.lr.ph:                              ; preds = %omp.par.entry
  %.unpack = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  %.unpack3 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  %.unpack4 = load i32, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  %.unpack5 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  %.unpack6 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  %.unpack7 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  %.unpack8 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  %.unpack9.unpack.unpack = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  %.unpack9.unpack.unpack11 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  %.unpack9.unpack.unpack12 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  %loadgep_2.repack14 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  %loadgep_2.repack16 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  %loadgep_2.repack18 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  %loadgep_2.repack20 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  %loadgep_2.repack22 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  %loadgep_2.repack24 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  %loadgep_2.repack26 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  %loadgep_2.repack26.repack28 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  %loadgep_2.repack26.repack30 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  %7 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 0
  br label %omp_loop.body

omp_loop.header.omp_loop.exit_crit_edge:          ; preds = %omp_loop.body
  store ptr %.unpack, ptr %loadgep_2, align 8, !tbaa !8
  store i64 %.unpack3, ptr %loadgep_2.repack14, align 8, !tbaa !8
  store i32 %.unpack4, ptr %loadgep_2.repack16, align 8, !tbaa !8
  store i8 %.unpack5, ptr %loadgep_2.repack18, align 4, !tbaa !8
  store i8 %.unpack6, ptr %loadgep_2.repack20, align 1, !tbaa !8
  store i8 %.unpack7, ptr %loadgep_2.repack22, align 2, !tbaa !8
  store i8 %.unpack8, ptr %loadgep_2.repack24, align 1, !tbaa !8
  store i64 %.unpack9.unpack.unpack, ptr %loadgep_2.repack26, align 8, !tbaa !8
  store i64 %.unpack9.unpack.unpack11, ptr %loadgep_2.repack26.repack28, align 8, !tbaa !8
  store i64 %.unpack9.unpack.unpack12, ptr %loadgep_2.repack26.repack30, align 8, !tbaa !8
  br label %omp_loop.exit

omp_loop.exit:                                    ; preds = %omp_loop.header.omp_loop.exit_crit_edge, %omp.par.entry
  call void @__kmpc_for_static_fini(ptr nonnull @1, i32 %omp_global_thread_num4)
  call void @__kmpc_barrier(ptr nonnull @2, i32 %omp_global_thread_num4)
  ret void

omp_loop.body:                                    ; preds = %omp_loop.body.lr.ph, %omp_loop.body
  %omp_loop.iv33 = phi i32 [ 0, %omp_loop.body.lr.ph ], [ %omp_loop.next, %omp_loop.body ]
  %8 = add i32 %omp_loop.iv33, 1
  %9 = add i32 %8, %3
  %10 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %11 = sitofp i32 %10 to float
  %12 = fdiv contract float 1.000000e+00, %11
  %13 = fpext float %12 to double
  %14 = sext i32 %9 to i64
  %15 = sub i64 %14, %.unpack9.unpack.unpack
  %16 = getelementptr double, ptr %.unpack, i64 %15
  store double %13, ptr %16, align 8, !tbaa !4
  %omp_loop.next = add nuw i32 %omp_loop.iv33, 1
  %omp_loop.cmp = icmp ult i32 %omp_loop.next, %6
  br i1 %omp_loop.cmp, label %omp_loop.body, label %omp_loop.header.omp_loop.exit_crit_edge
}
*** IR Dump After InstCombinePass on _QQmain..omp_par ***
; Function Attrs: norecurse nounwind
define internal void @_QQmain..omp_par(ptr noalias %tid.addr, ptr noalias %zero.addr, ptr %0) #2 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %p.lastiter = alloca i32, align 4
  %p.lowerbound = alloca i32, align 4
  %p.upperbound = alloca i32, align 4
  %p.stride = alloca i32, align 4
  %1 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %omp_loop.tripcount = tail call i32 @llvm.smax.i32(i32 %1, i32 0)
  store i32 0, ptr %p.lowerbound, align 4
  %2 = add nsw i32 %omp_loop.tripcount, -1
  store i32 %2, ptr %p.upperbound, align 4
  store i32 1, ptr %p.stride, align 4
  %omp_global_thread_num4 = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  call void @__kmpc_for_static_init_4u(ptr nonnull @1, i32 %omp_global_thread_num4, i32 34, ptr nonnull %p.lastiter, ptr nonnull %p.lowerbound, ptr nonnull %p.upperbound, ptr nonnull %p.stride, i32 1, i32 0)
  %3 = load i32, ptr %p.lowerbound, align 4
  %4 = load i32, ptr %p.upperbound, align 4
  %reass.sub = sub i32 %4, %3
  %5 = add i32 %reass.sub, 1
  %omp_loop.cmp32.not = icmp eq i32 %5, 0
  br i1 %omp_loop.cmp32.not, label %omp_loop.exit, label %omp_loop.body.lr.ph

omp_loop.body.lr.ph:                              ; preds = %omp.par.entry
  %.unpack = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  %.unpack3 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  %.unpack4 = load i32, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  %.unpack5 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  %.unpack6 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  %.unpack7 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  %.unpack8 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  %.unpack9.unpack.unpack = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  %.unpack9.unpack.unpack11 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  %.unpack9.unpack.unpack12 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  %loadgep_2.repack14 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  %loadgep_2.repack16 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  %loadgep_2.repack18 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  %loadgep_2.repack20 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  %loadgep_2.repack22 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  %loadgep_2.repack24 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  %loadgep_2.repack26 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  %loadgep_2.repack26.repack28 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  %loadgep_2.repack26.repack30 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  br label %omp_loop.body

omp_loop.header.omp_loop.exit_crit_edge:          ; preds = %omp_loop.body
  store ptr %.unpack, ptr %loadgep_2, align 8, !tbaa !8
  store i64 %.unpack3, ptr %loadgep_2.repack14, align 8, !tbaa !8
  store i32 %.unpack4, ptr %loadgep_2.repack16, align 8, !tbaa !8
  store i8 %.unpack5, ptr %loadgep_2.repack18, align 4, !tbaa !8
  store i8 %.unpack6, ptr %loadgep_2.repack20, align 1, !tbaa !8
  store i8 %.unpack7, ptr %loadgep_2.repack22, align 2, !tbaa !8
  store i8 %.unpack8, ptr %loadgep_2.repack24, align 1, !tbaa !8
  store i64 %.unpack9.unpack.unpack, ptr %loadgep_2.repack26, align 8, !tbaa !8
  store i64 %.unpack9.unpack.unpack11, ptr %loadgep_2.repack26.repack28, align 8, !tbaa !8
  store i64 %.unpack9.unpack.unpack12, ptr %loadgep_2.repack26.repack30, align 8, !tbaa !8
  br label %omp_loop.exit

omp_loop.exit:                                    ; preds = %omp_loop.header.omp_loop.exit_crit_edge, %omp.par.entry
  call void @__kmpc_for_static_fini(ptr nonnull @1, i32 %omp_global_thread_num4)
  call void @__kmpc_barrier(ptr nonnull @2, i32 %omp_global_thread_num4)
  ret void

omp_loop.body:                                    ; preds = %omp_loop.body.lr.ph, %omp_loop.body
  %omp_loop.iv33 = phi i32 [ 0, %omp_loop.body.lr.ph ], [ %omp_loop.next, %omp_loop.body ]
  %6 = add i32 %omp_loop.iv33, 1
  %7 = add i32 %6, %3
  %8 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %9 = sitofp i32 %8 to float
  %10 = fdiv contract float 1.000000e+00, %9
  %11 = fpext float %10 to double
  %12 = sext i32 %7 to i64
  %13 = sub i64 %12, %.unpack9.unpack.unpack
  %14 = getelementptr double, ptr %.unpack, i64 %13
  store double %11, ptr %14, align 8, !tbaa !4
  %omp_loop.next = add nuw i32 %omp_loop.iv33, 1
  %omp_loop.cmp = icmp ult i32 %omp_loop.next, %5
  br i1 %omp_loop.cmp, label %omp_loop.body, label %omp_loop.header.omp_loop.exit_crit_edge
}
*** IR Dump After LoopSimplifyPass on _QQmain..omp_par ***
; Function Attrs: norecurse nounwind
define internal void @_QQmain..omp_par(ptr noalias %tid.addr, ptr noalias %zero.addr, ptr %0) #2 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %p.lastiter = alloca i32, align 4
  %p.lowerbound = alloca i32, align 4
  %p.upperbound = alloca i32, align 4
  %p.stride = alloca i32, align 4
  %1 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %omp_loop.tripcount = tail call i32 @llvm.smax.i32(i32 %1, i32 0)
  store i32 0, ptr %p.lowerbound, align 4
  %2 = add nsw i32 %omp_loop.tripcount, -1
  store i32 %2, ptr %p.upperbound, align 4
  store i32 1, ptr %p.stride, align 4
  %omp_global_thread_num4 = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  call void @__kmpc_for_static_init_4u(ptr nonnull @1, i32 %omp_global_thread_num4, i32 34, ptr nonnull %p.lastiter, ptr nonnull %p.lowerbound, ptr nonnull %p.upperbound, ptr nonnull %p.stride, i32 1, i32 0)
  %3 = load i32, ptr %p.lowerbound, align 4
  %4 = load i32, ptr %p.upperbound, align 4
  %reass.sub = sub i32 %4, %3
  %5 = add i32 %reass.sub, 1
  %omp_loop.cmp32.not = icmp eq i32 %5, 0
  br i1 %omp_loop.cmp32.not, label %omp_loop.exit, label %omp_loop.body.lr.ph

omp_loop.body.lr.ph:                              ; preds = %omp.par.entry
  %.unpack = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  %.unpack3 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  %.unpack4 = load i32, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  %.unpack5 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  %.unpack6 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  %.unpack7 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  %.unpack8 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  %.unpack9.unpack.unpack = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  %.unpack9.unpack.unpack11 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  %.unpack9.unpack.unpack12 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  %loadgep_2.repack14 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  %loadgep_2.repack16 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  %loadgep_2.repack18 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  %loadgep_2.repack20 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  %loadgep_2.repack22 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  %loadgep_2.repack24 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  %loadgep_2.repack26 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  %loadgep_2.repack26.repack28 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  %loadgep_2.repack26.repack30 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  br label %omp_loop.body

omp_loop.header.omp_loop.exit_crit_edge:          ; preds = %omp_loop.body
  store ptr %.unpack, ptr %loadgep_2, align 8, !tbaa !8
  store i64 %.unpack3, ptr %loadgep_2.repack14, align 8, !tbaa !8
  store i32 %.unpack4, ptr %loadgep_2.repack16, align 8, !tbaa !8
  store i8 %.unpack5, ptr %loadgep_2.repack18, align 4, !tbaa !8
  store i8 %.unpack6, ptr %loadgep_2.repack20, align 1, !tbaa !8
  store i8 %.unpack7, ptr %loadgep_2.repack22, align 2, !tbaa !8
  store i8 %.unpack8, ptr %loadgep_2.repack24, align 1, !tbaa !8
  store i64 %.unpack9.unpack.unpack, ptr %loadgep_2.repack26, align 8, !tbaa !8
  store i64 %.unpack9.unpack.unpack11, ptr %loadgep_2.repack26.repack28, align 8, !tbaa !8
  store i64 %.unpack9.unpack.unpack12, ptr %loadgep_2.repack26.repack30, align 8, !tbaa !8
  br label %omp_loop.exit

omp_loop.exit:                                    ; preds = %omp_loop.header.omp_loop.exit_crit_edge, %omp.par.entry
  call void @__kmpc_for_static_fini(ptr nonnull @1, i32 %omp_global_thread_num4)
  call void @__kmpc_barrier(ptr nonnull @2, i32 %omp_global_thread_num4)
  ret void

omp_loop.body:                                    ; preds = %omp_loop.body.lr.ph, %omp_loop.body
  %omp_loop.iv33 = phi i32 [ 0, %omp_loop.body.lr.ph ], [ %omp_loop.next, %omp_loop.body ]
  %6 = add i32 %omp_loop.iv33, 1
  %7 = add i32 %6, %3
  %8 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %9 = sitofp i32 %8 to float
  %10 = fdiv contract float 1.000000e+00, %9
  %11 = fpext float %10 to double
  %12 = sext i32 %7 to i64
  %13 = sub i64 %12, %.unpack9.unpack.unpack
  %14 = getelementptr double, ptr %.unpack, i64 %13
  store double %11, ptr %14, align 8, !tbaa !4
  %omp_loop.next = add nuw i32 %omp_loop.iv33, 1
  %omp_loop.cmp = icmp ult i32 %omp_loop.next, %5
  br i1 %omp_loop.cmp, label %omp_loop.body, label %omp_loop.header.omp_loop.exit_crit_edge
}
*** IR Dump After LCSSAPass on _QQmain..omp_par ***
; Function Attrs: norecurse nounwind
define internal void @_QQmain..omp_par(ptr noalias %tid.addr, ptr noalias %zero.addr, ptr %0) #2 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %p.lastiter = alloca i32, align 4
  %p.lowerbound = alloca i32, align 4
  %p.upperbound = alloca i32, align 4
  %p.stride = alloca i32, align 4
  %1 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %omp_loop.tripcount = tail call i32 @llvm.smax.i32(i32 %1, i32 0)
  store i32 0, ptr %p.lowerbound, align 4
  %2 = add nsw i32 %omp_loop.tripcount, -1
  store i32 %2, ptr %p.upperbound, align 4
  store i32 1, ptr %p.stride, align 4
  %omp_global_thread_num4 = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  call void @__kmpc_for_static_init_4u(ptr nonnull @1, i32 %omp_global_thread_num4, i32 34, ptr nonnull %p.lastiter, ptr nonnull %p.lowerbound, ptr nonnull %p.upperbound, ptr nonnull %p.stride, i32 1, i32 0)
  %3 = load i32, ptr %p.lowerbound, align 4
  %4 = load i32, ptr %p.upperbound, align 4
  %reass.sub = sub i32 %4, %3
  %5 = add i32 %reass.sub, 1
  %omp_loop.cmp32.not = icmp eq i32 %5, 0
  br i1 %omp_loop.cmp32.not, label %omp_loop.exit, label %omp_loop.body.lr.ph

omp_loop.body.lr.ph:                              ; preds = %omp.par.entry
  %.unpack = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  %.unpack3 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  %.unpack4 = load i32, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  %.unpack5 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  %.unpack6 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  %.unpack7 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  %.unpack8 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  %.unpack9.unpack.unpack = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  %.unpack9.unpack.unpack11 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  %.unpack9.unpack.unpack12 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  %loadgep_2.repack14 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  %loadgep_2.repack16 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  %loadgep_2.repack18 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  %loadgep_2.repack20 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  %loadgep_2.repack22 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  %loadgep_2.repack24 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  %loadgep_2.repack26 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  %loadgep_2.repack26.repack28 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  %loadgep_2.repack26.repack30 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  br label %omp_loop.body

omp_loop.header.omp_loop.exit_crit_edge:          ; preds = %omp_loop.body
  store ptr %.unpack, ptr %loadgep_2, align 8, !tbaa !8
  store i64 %.unpack3, ptr %loadgep_2.repack14, align 8, !tbaa !8
  store i32 %.unpack4, ptr %loadgep_2.repack16, align 8, !tbaa !8
  store i8 %.unpack5, ptr %loadgep_2.repack18, align 4, !tbaa !8
  store i8 %.unpack6, ptr %loadgep_2.repack20, align 1, !tbaa !8
  store i8 %.unpack7, ptr %loadgep_2.repack22, align 2, !tbaa !8
  store i8 %.unpack8, ptr %loadgep_2.repack24, align 1, !tbaa !8
  store i64 %.unpack9.unpack.unpack, ptr %loadgep_2.repack26, align 8, !tbaa !8
  store i64 %.unpack9.unpack.unpack11, ptr %loadgep_2.repack26.repack28, align 8, !tbaa !8
  store i64 %.unpack9.unpack.unpack12, ptr %loadgep_2.repack26.repack30, align 8, !tbaa !8
  br label %omp_loop.exit

omp_loop.exit:                                    ; preds = %omp_loop.header.omp_loop.exit_crit_edge, %omp.par.entry
  call void @__kmpc_for_static_fini(ptr nonnull @1, i32 %omp_global_thread_num4)
  call void @__kmpc_barrier(ptr nonnull @2, i32 %omp_global_thread_num4)
  ret void

omp_loop.body:                                    ; preds = %omp_loop.body.lr.ph, %omp_loop.body
  %omp_loop.iv33 = phi i32 [ 0, %omp_loop.body.lr.ph ], [ %omp_loop.next, %omp_loop.body ]
  %6 = add i32 %omp_loop.iv33, 1
  %7 = add i32 %6, %3
  %8 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %9 = sitofp i32 %8 to float
  %10 = fdiv contract float 1.000000e+00, %9
  %11 = fpext float %10 to double
  %12 = sext i32 %7 to i64
  %13 = sub i64 %12, %.unpack9.unpack.unpack
  %14 = getelementptr double, ptr %.unpack, i64 %13
  store double %11, ptr %14, align 8, !tbaa !4
  %omp_loop.next = add nuw i32 %omp_loop.iv33, 1
  %omp_loop.cmp = icmp ult i32 %omp_loop.next, %5
  br i1 %omp_loop.cmp, label %omp_loop.body, label %omp_loop.header.omp_loop.exit_crit_edge
}
*** IR Dump After LoopIdiomRecognizePass on omp_loop.body ***

; Preheader:
omp_loop.body.lr.ph:                              ; preds = %omp.par.entry
  %.unpack = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  %.unpack3 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  %.unpack4 = load i32, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  %.unpack5 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  %.unpack6 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  %.unpack7 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  %.unpack8 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  %.unpack9.unpack.unpack = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  %.unpack9.unpack.unpack11 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  %.unpack9.unpack.unpack12 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  %loadgep_2.repack14 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  %loadgep_2.repack16 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  %loadgep_2.repack18 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  %loadgep_2.repack20 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  %loadgep_2.repack22 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  %loadgep_2.repack24 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  %loadgep_2.repack26 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  %loadgep_2.repack26.repack28 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  %loadgep_2.repack26.repack30 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  br label %omp_loop.body

; Loop:
omp_loop.body:                                    ; preds = %omp_loop.body.lr.ph, %omp_loop.body
  %omp_loop.iv33 = phi i32 [ 0, %omp_loop.body.lr.ph ], [ %omp_loop.next, %omp_loop.body ]
  %6 = add i32 %omp_loop.iv33, 1
  %7 = add i32 %6, %3
  %8 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %9 = sitofp i32 %8 to float
  %10 = fdiv contract float 1.000000e+00, %9
  %11 = fpext float %10 to double
  %12 = sext i32 %7 to i64
  %13 = sub i64 %12, %.unpack9.unpack.unpack
  %14 = getelementptr double, ptr %.unpack, i64 %13
  store double %11, ptr %14, align 8, !tbaa !4
  %omp_loop.next = add nuw i32 %omp_loop.iv33, 1
  %omp_loop.cmp = icmp ult i32 %omp_loop.next, %5
  br i1 %omp_loop.cmp, label %omp_loop.body, label %omp_loop.header.omp_loop.exit_crit_edge

; Exit blocks
omp_loop.header.omp_loop.exit_crit_edge:          ; preds = %omp_loop.body
  store ptr %.unpack, ptr %loadgep_2, align 8, !tbaa !8
  store i64 %.unpack3, ptr %loadgep_2.repack14, align 8, !tbaa !8
  store i32 %.unpack4, ptr %loadgep_2.repack16, align 8, !tbaa !8
  store i8 %.unpack5, ptr %loadgep_2.repack18, align 4, !tbaa !8
  store i8 %.unpack6, ptr %loadgep_2.repack20, align 1, !tbaa !8
  store i8 %.unpack7, ptr %loadgep_2.repack22, align 2, !tbaa !8
  store i8 %.unpack8, ptr %loadgep_2.repack24, align 1, !tbaa !8
  store i64 %.unpack9.unpack.unpack, ptr %loadgep_2.repack26, align 8, !tbaa !8
  store i64 %.unpack9.unpack.unpack11, ptr %loadgep_2.repack26.repack28, align 8, !tbaa !8
  store i64 %.unpack9.unpack.unpack12, ptr %loadgep_2.repack26.repack30, align 8, !tbaa !8
  br label %omp_loop.exit
*** IR Dump After IndVarSimplifyPass on omp_loop.body ***

; Preheader:
omp_loop.body.lr.ph:                              ; preds = %omp.par.entry
  %.unpack = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  %.unpack3 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  %.unpack4 = load i32, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  %.unpack5 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  %.unpack6 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  %.unpack7 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  %.unpack8 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  %.unpack9.unpack.unpack = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  %.unpack9.unpack.unpack11 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  %.unpack9.unpack.unpack12 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  %loadgep_2.repack16 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  %loadgep_2.repack20 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  %loadgep_2.repack24 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  %loadgep_2.repack26.repack28 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  br label %omp_loop.body

; Loop:
omp_loop.body:                                    ; preds = %omp_loop.body.lr.ph, %omp_loop.body
  %omp_loop.iv33 = phi i32 [ 0, %omp_loop.body.lr.ph ], [ %omp_loop.next, %omp_loop.body ]
  %6 = add nuw i32 %omp_loop.iv33, 1
  %7 = add i32 %6, %3
  %8 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %9 = sitofp i32 %8 to float
  %10 = fdiv contract float 1.000000e+00, %9
  %11 = fpext float %10 to double
  %12 = sext i32 %7 to i64
  %13 = sub i64 %12, %.unpack9.unpack.unpack
  %14 = getelementptr double, ptr %.unpack, i64 %13
  store double %11, ptr %14, align 8, !tbaa !4
  %omp_loop.next = add nuw i32 %omp_loop.iv33, 1
  %exitcond = icmp ne i32 %omp_loop.next, %5
  br i1 %exitcond, label %omp_loop.body, label %omp_loop.header.omp_loop.exit_crit_edge

; Exit blocks
omp_loop.header.omp_loop.exit_crit_edge:          ; preds = %omp_loop.body
  %loadgep_2.repack14 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  %loadgep_2.repack18 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  %loadgep_2.repack22 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  %loadgep_2.repack26 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  %loadgep_2.repack26.repack30 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  store ptr %.unpack, ptr %loadgep_2, align 8, !tbaa !8
  store i64 %.unpack3, ptr %loadgep_2.repack14, align 8, !tbaa !8
  store i32 %.unpack4, ptr %loadgep_2.repack16, align 8, !tbaa !8
  store i8 %.unpack5, ptr %loadgep_2.repack18, align 4, !tbaa !8
  store i8 %.unpack6, ptr %loadgep_2.repack20, align 1, !tbaa !8
  store i8 %.unpack7, ptr %loadgep_2.repack22, align 2, !tbaa !8
  store i8 %.unpack8, ptr %loadgep_2.repack24, align 1, !tbaa !8
  store i64 %.unpack9.unpack.unpack, ptr %loadgep_2.repack26, align 8, !tbaa !8
  store i64 %.unpack9.unpack.unpack11, ptr %loadgep_2.repack26.repack28, align 8, !tbaa !8
  store i64 %.unpack9.unpack.unpack12, ptr %loadgep_2.repack26.repack30, align 8, !tbaa !8
  br label %omp_loop.exit
*** IR Dump After LoopDeletionPass on omp_loop.body ***

; Preheader:
omp_loop.body.lr.ph:                              ; preds = %omp.par.entry
  %.unpack = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  %.unpack3 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  %.unpack4 = load i32, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  %.unpack5 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  %.unpack6 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  %.unpack7 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  %.unpack8 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  %.unpack9.unpack.unpack = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  %.unpack9.unpack.unpack11 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  %.unpack9.unpack.unpack12 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  %loadgep_2.repack16 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  %loadgep_2.repack20 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  %loadgep_2.repack24 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  %loadgep_2.repack26.repack28 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  br label %omp_loop.body

; Loop:
omp_loop.body:                                    ; preds = %omp_loop.body.lr.ph, %omp_loop.body
  %omp_loop.iv33 = phi i32 [ 0, %omp_loop.body.lr.ph ], [ %omp_loop.next, %omp_loop.body ]
  %6 = add nuw i32 %omp_loop.iv33, 1
  %7 = add i32 %6, %3
  %8 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %9 = sitofp i32 %8 to float
  %10 = fdiv contract float 1.000000e+00, %9
  %11 = fpext float %10 to double
  %12 = sext i32 %7 to i64
  %13 = sub i64 %12, %.unpack9.unpack.unpack
  %14 = getelementptr double, ptr %.unpack, i64 %13
  store double %11, ptr %14, align 8, !tbaa !4
  %omp_loop.next = add nuw i32 %omp_loop.iv33, 1
  %exitcond = icmp ne i32 %omp_loop.next, %5
  br i1 %exitcond, label %omp_loop.body, label %omp_loop.header.omp_loop.exit_crit_edge

; Exit blocks
omp_loop.header.omp_loop.exit_crit_edge:          ; preds = %omp_loop.body
  %loadgep_2.repack14 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  %loadgep_2.repack18 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  %loadgep_2.repack22 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  %loadgep_2.repack26 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  %loadgep_2.repack26.repack30 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  store ptr %.unpack, ptr %loadgep_2, align 8, !tbaa !8
  store i64 %.unpack3, ptr %loadgep_2.repack14, align 8, !tbaa !8
  store i32 %.unpack4, ptr %loadgep_2.repack16, align 8, !tbaa !8
  store i8 %.unpack5, ptr %loadgep_2.repack18, align 4, !tbaa !8
  store i8 %.unpack6, ptr %loadgep_2.repack20, align 1, !tbaa !8
  store i8 %.unpack7, ptr %loadgep_2.repack22, align 2, !tbaa !8
  store i8 %.unpack8, ptr %loadgep_2.repack24, align 1, !tbaa !8
  store i64 %.unpack9.unpack.unpack, ptr %loadgep_2.repack26, align 8, !tbaa !8
  store i64 %.unpack9.unpack.unpack11, ptr %loadgep_2.repack26.repack28, align 8, !tbaa !8
  store i64 %.unpack9.unpack.unpack12, ptr %loadgep_2.repack26.repack30, align 8, !tbaa !8
  br label %omp_loop.exit
*** IR Dump After LoopFullUnrollPass on omp_loop.body ***

; Preheader:
omp_loop.body.lr.ph:                              ; preds = %omp.par.entry
  %.unpack = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  %.unpack3 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  %.unpack4 = load i32, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  %.unpack5 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  %.unpack6 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  %.unpack7 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  %.unpack8 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  %.unpack9.unpack.unpack = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  %.unpack9.unpack.unpack11 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  %.unpack9.unpack.unpack12 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  %loadgep_2.repack16 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  %loadgep_2.repack20 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  %loadgep_2.repack24 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  %loadgep_2.repack26.repack28 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  br label %omp_loop.body

; Loop:
omp_loop.body:                                    ; preds = %omp_loop.body.lr.ph, %omp_loop.body
  %omp_loop.iv33 = phi i32 [ 0, %omp_loop.body.lr.ph ], [ %omp_loop.next, %omp_loop.body ]
  %6 = add nuw i32 %omp_loop.iv33, 1
  %7 = add i32 %6, %3
  %8 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %9 = sitofp i32 %8 to float
  %10 = fdiv contract float 1.000000e+00, %9
  %11 = fpext float %10 to double
  %12 = sext i32 %7 to i64
  %13 = sub i64 %12, %.unpack9.unpack.unpack
  %14 = getelementptr double, ptr %.unpack, i64 %13
  store double %11, ptr %14, align 8, !tbaa !4
  %omp_loop.next = add nuw i32 %omp_loop.iv33, 1
  %exitcond = icmp ne i32 %omp_loop.next, %5
  br i1 %exitcond, label %omp_loop.body, label %omp_loop.header.omp_loop.exit_crit_edge

; Exit blocks
omp_loop.header.omp_loop.exit_crit_edge:          ; preds = %omp_loop.body
  %loadgep_2.repack14 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  %loadgep_2.repack18 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  %loadgep_2.repack22 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  %loadgep_2.repack26 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  %loadgep_2.repack26.repack30 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  store ptr %.unpack, ptr %loadgep_2, align 8, !tbaa !8
  store i64 %.unpack3, ptr %loadgep_2.repack14, align 8, !tbaa !8
  store i32 %.unpack4, ptr %loadgep_2.repack16, align 8, !tbaa !8
  store i8 %.unpack5, ptr %loadgep_2.repack18, align 4, !tbaa !8
  store i8 %.unpack6, ptr %loadgep_2.repack20, align 1, !tbaa !8
  store i8 %.unpack7, ptr %loadgep_2.repack22, align 2, !tbaa !8
  store i8 %.unpack8, ptr %loadgep_2.repack24, align 1, !tbaa !8
  store i64 %.unpack9.unpack.unpack, ptr %loadgep_2.repack26, align 8, !tbaa !8
  store i64 %.unpack9.unpack.unpack11, ptr %loadgep_2.repack26.repack28, align 8, !tbaa !8
  store i64 %.unpack9.unpack.unpack12, ptr %loadgep_2.repack26.repack30, align 8, !tbaa !8
  br label %omp_loop.exit
*** IR Dump After SROAPass on _QQmain..omp_par ***
; Function Attrs: norecurse nounwind
define internal void @_QQmain..omp_par(ptr noalias %tid.addr, ptr noalias %zero.addr, ptr %0) #2 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %p.lastiter = alloca i32, align 4
  %p.lowerbound = alloca i32, align 4
  %p.upperbound = alloca i32, align 4
  %p.stride = alloca i32, align 4
  %1 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %omp_loop.tripcount = tail call i32 @llvm.smax.i32(i32 %1, i32 0)
  store i32 0, ptr %p.lowerbound, align 4
  %2 = add nsw i32 %omp_loop.tripcount, -1
  store i32 %2, ptr %p.upperbound, align 4
  store i32 1, ptr %p.stride, align 4
  %omp_global_thread_num4 = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  call void @__kmpc_for_static_init_4u(ptr nonnull @1, i32 %omp_global_thread_num4, i32 34, ptr nonnull %p.lastiter, ptr nonnull %p.lowerbound, ptr nonnull %p.upperbound, ptr nonnull %p.stride, i32 1, i32 0)
  %3 = load i32, ptr %p.lowerbound, align 4
  %4 = load i32, ptr %p.upperbound, align 4
  %reass.sub = sub i32 %4, %3
  %5 = add i32 %reass.sub, 1
  %omp_loop.cmp32.not = icmp eq i32 %5, 0
  br i1 %omp_loop.cmp32.not, label %omp_loop.exit, label %omp_loop.body.lr.ph

omp_loop.body.lr.ph:                              ; preds = %omp.par.entry
  %.unpack = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  %.unpack3 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  %.unpack4 = load i32, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  %.unpack5 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  %.unpack6 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  %.unpack7 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  %.unpack8 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  %.unpack9.unpack.unpack = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  %.unpack9.unpack.unpack11 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  %.unpack9.unpack.unpack12 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  %loadgep_2.repack16 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  %loadgep_2.repack20 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  %loadgep_2.repack24 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  %loadgep_2.repack26.repack28 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  br label %omp_loop.body

omp_loop.header.omp_loop.exit_crit_edge:          ; preds = %omp_loop.body
  %loadgep_2.repack14 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  %loadgep_2.repack18 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  %loadgep_2.repack22 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  %loadgep_2.repack26 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  %loadgep_2.repack26.repack30 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  store ptr %.unpack, ptr %loadgep_2, align 8, !tbaa !8
  store i64 %.unpack3, ptr %loadgep_2.repack14, align 8, !tbaa !8
  store i32 %.unpack4, ptr %loadgep_2.repack16, align 8, !tbaa !8
  store i8 %.unpack5, ptr %loadgep_2.repack18, align 4, !tbaa !8
  store i8 %.unpack6, ptr %loadgep_2.repack20, align 1, !tbaa !8
  store i8 %.unpack7, ptr %loadgep_2.repack22, align 2, !tbaa !8
  store i8 %.unpack8, ptr %loadgep_2.repack24, align 1, !tbaa !8
  store i64 %.unpack9.unpack.unpack, ptr %loadgep_2.repack26, align 8, !tbaa !8
  store i64 %.unpack9.unpack.unpack11, ptr %loadgep_2.repack26.repack28, align 8, !tbaa !8
  store i64 %.unpack9.unpack.unpack12, ptr %loadgep_2.repack26.repack30, align 8, !tbaa !8
  br label %omp_loop.exit

omp_loop.exit:                                    ; preds = %omp_loop.header.omp_loop.exit_crit_edge, %omp.par.entry
  call void @__kmpc_for_static_fini(ptr nonnull @1, i32 %omp_global_thread_num4)
  call void @__kmpc_barrier(ptr nonnull @2, i32 %omp_global_thread_num4)
  ret void

omp_loop.body:                                    ; preds = %omp_loop.body.lr.ph, %omp_loop.body
  %omp_loop.iv33 = phi i32 [ 0, %omp_loop.body.lr.ph ], [ %omp_loop.next, %omp_loop.body ]
  %6 = add nuw i32 %omp_loop.iv33, 1
  %7 = add i32 %6, %3
  %8 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %9 = sitofp i32 %8 to float
  %10 = fdiv contract float 1.000000e+00, %9
  %11 = fpext float %10 to double
  %12 = sext i32 %7 to i64
  %13 = sub i64 %12, %.unpack9.unpack.unpack
  %14 = getelementptr double, ptr %.unpack, i64 %13
  store double %11, ptr %14, align 8, !tbaa !4
  %omp_loop.next = add nuw i32 %omp_loop.iv33, 1
  %exitcond = icmp ne i32 %omp_loop.next, %5
  br i1 %exitcond, label %omp_loop.body, label %omp_loop.header.omp_loop.exit_crit_edge
}
*** IR Dump After VectorCombinePass on _QQmain..omp_par ***
; Function Attrs: norecurse nounwind
define internal void @_QQmain..omp_par(ptr noalias %tid.addr, ptr noalias %zero.addr, ptr %0) #2 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %p.lastiter = alloca i32, align 4
  %p.lowerbound = alloca i32, align 4
  %p.upperbound = alloca i32, align 4
  %p.stride = alloca i32, align 4
  %1 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %omp_loop.tripcount = tail call i32 @llvm.smax.i32(i32 %1, i32 0)
  store i32 0, ptr %p.lowerbound, align 4
  %2 = add nsw i32 %omp_loop.tripcount, -1
  store i32 %2, ptr %p.upperbound, align 4
  store i32 1, ptr %p.stride, align 4
  %omp_global_thread_num4 = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  call void @__kmpc_for_static_init_4u(ptr nonnull @1, i32 %omp_global_thread_num4, i32 34, ptr nonnull %p.lastiter, ptr nonnull %p.lowerbound, ptr nonnull %p.upperbound, ptr nonnull %p.stride, i32 1, i32 0)
  %3 = load i32, ptr %p.lowerbound, align 4
  %4 = load i32, ptr %p.upperbound, align 4
  %reass.sub = sub i32 %4, %3
  %5 = add i32 %reass.sub, 1
  %omp_loop.cmp32.not = icmp eq i32 %5, 0
  br i1 %omp_loop.cmp32.not, label %omp_loop.exit, label %omp_loop.body.lr.ph

omp_loop.body.lr.ph:                              ; preds = %omp.par.entry
  %.unpack = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  %.unpack3 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  %.unpack4 = load i32, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  %.unpack5 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  %.unpack6 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  %.unpack7 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  %.unpack8 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  %.unpack9.unpack.unpack = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  %.unpack9.unpack.unpack11 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  %.unpack9.unpack.unpack12 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  %loadgep_2.repack16 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  %loadgep_2.repack20 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  %loadgep_2.repack24 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  %loadgep_2.repack26.repack28 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  br label %omp_loop.body

omp_loop.header.omp_loop.exit_crit_edge:          ; preds = %omp_loop.body
  %loadgep_2.repack14 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  %loadgep_2.repack18 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  %loadgep_2.repack22 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  %loadgep_2.repack26 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  %loadgep_2.repack26.repack30 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  store ptr %.unpack, ptr %loadgep_2, align 8, !tbaa !8
  store i64 %.unpack3, ptr %loadgep_2.repack14, align 8, !tbaa !8
  store i32 %.unpack4, ptr %loadgep_2.repack16, align 8, !tbaa !8
  store i8 %.unpack5, ptr %loadgep_2.repack18, align 4, !tbaa !8
  store i8 %.unpack6, ptr %loadgep_2.repack20, align 1, !tbaa !8
  store i8 %.unpack7, ptr %loadgep_2.repack22, align 2, !tbaa !8
  store i8 %.unpack8, ptr %loadgep_2.repack24, align 1, !tbaa !8
  store i64 %.unpack9.unpack.unpack, ptr %loadgep_2.repack26, align 8, !tbaa !8
  store i64 %.unpack9.unpack.unpack11, ptr %loadgep_2.repack26.repack28, align 8, !tbaa !8
  store i64 %.unpack9.unpack.unpack12, ptr %loadgep_2.repack26.repack30, align 8, !tbaa !8
  br label %omp_loop.exit

omp_loop.exit:                                    ; preds = %omp_loop.header.omp_loop.exit_crit_edge, %omp.par.entry
  call void @__kmpc_for_static_fini(ptr nonnull @1, i32 %omp_global_thread_num4)
  call void @__kmpc_barrier(ptr nonnull @2, i32 %omp_global_thread_num4)
  ret void

omp_loop.body:                                    ; preds = %omp_loop.body.lr.ph, %omp_loop.body
  %omp_loop.iv33 = phi i32 [ 0, %omp_loop.body.lr.ph ], [ %omp_loop.next, %omp_loop.body ]
  %6 = add nuw i32 %omp_loop.iv33, 1
  %7 = add i32 %6, %3
  %8 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %9 = sitofp i32 %8 to float
  %10 = fdiv contract float 1.000000e+00, %9
  %11 = fpext float %10 to double
  %12 = sext i32 %7 to i64
  %13 = sub i64 %12, %.unpack9.unpack.unpack
  %14 = getelementptr double, ptr %.unpack, i64 %13
  store double %11, ptr %14, align 8, !tbaa !4
  %omp_loop.next = add nuw i32 %omp_loop.iv33, 1
  %exitcond = icmp ne i32 %omp_loop.next, %5
  br i1 %exitcond, label %omp_loop.body, label %omp_loop.header.omp_loop.exit_crit_edge
}
*** IR Dump After MergedLoadStoreMotionPass on _QQmain..omp_par ***
; Function Attrs: norecurse nounwind
define internal void @_QQmain..omp_par(ptr noalias %tid.addr, ptr noalias %zero.addr, ptr %0) #2 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %p.lastiter = alloca i32, align 4
  %p.lowerbound = alloca i32, align 4
  %p.upperbound = alloca i32, align 4
  %p.stride = alloca i32, align 4
  %1 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %omp_loop.tripcount = tail call i32 @llvm.smax.i32(i32 %1, i32 0)
  store i32 0, ptr %p.lowerbound, align 4
  %2 = add nsw i32 %omp_loop.tripcount, -1
  store i32 %2, ptr %p.upperbound, align 4
  store i32 1, ptr %p.stride, align 4
  %omp_global_thread_num4 = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  call void @__kmpc_for_static_init_4u(ptr nonnull @1, i32 %omp_global_thread_num4, i32 34, ptr nonnull %p.lastiter, ptr nonnull %p.lowerbound, ptr nonnull %p.upperbound, ptr nonnull %p.stride, i32 1, i32 0)
  %3 = load i32, ptr %p.lowerbound, align 4
  %4 = load i32, ptr %p.upperbound, align 4
  %reass.sub = sub i32 %4, %3
  %5 = add i32 %reass.sub, 1
  %omp_loop.cmp32.not = icmp eq i32 %5, 0
  br i1 %omp_loop.cmp32.not, label %omp_loop.exit, label %omp_loop.body.lr.ph

omp_loop.body.lr.ph:                              ; preds = %omp.par.entry
  %.unpack = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  %.unpack3 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  %.unpack4 = load i32, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  %.unpack5 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  %.unpack6 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  %.unpack7 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  %.unpack8 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  %.unpack9.unpack.unpack = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  %.unpack9.unpack.unpack11 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  %.unpack9.unpack.unpack12 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  %loadgep_2.repack16 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  %loadgep_2.repack20 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  %loadgep_2.repack24 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  %loadgep_2.repack26.repack28 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  br label %omp_loop.body

omp_loop.header.omp_loop.exit_crit_edge:          ; preds = %omp_loop.body
  %loadgep_2.repack14 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  %loadgep_2.repack18 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  %loadgep_2.repack22 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  %loadgep_2.repack26 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  %loadgep_2.repack26.repack30 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  store ptr %.unpack, ptr %loadgep_2, align 8, !tbaa !8
  store i64 %.unpack3, ptr %loadgep_2.repack14, align 8, !tbaa !8
  store i32 %.unpack4, ptr %loadgep_2.repack16, align 8, !tbaa !8
  store i8 %.unpack5, ptr %loadgep_2.repack18, align 4, !tbaa !8
  store i8 %.unpack6, ptr %loadgep_2.repack20, align 1, !tbaa !8
  store i8 %.unpack7, ptr %loadgep_2.repack22, align 2, !tbaa !8
  store i8 %.unpack8, ptr %loadgep_2.repack24, align 1, !tbaa !8
  store i64 %.unpack9.unpack.unpack, ptr %loadgep_2.repack26, align 8, !tbaa !8
  store i64 %.unpack9.unpack.unpack11, ptr %loadgep_2.repack26.repack28, align 8, !tbaa !8
  store i64 %.unpack9.unpack.unpack12, ptr %loadgep_2.repack26.repack30, align 8, !tbaa !8
  br label %omp_loop.exit

omp_loop.exit:                                    ; preds = %omp_loop.header.omp_loop.exit_crit_edge, %omp.par.entry
  call void @__kmpc_for_static_fini(ptr nonnull @1, i32 %omp_global_thread_num4)
  call void @__kmpc_barrier(ptr nonnull @2, i32 %omp_global_thread_num4)
  ret void

omp_loop.body:                                    ; preds = %omp_loop.body.lr.ph, %omp_loop.body
  %omp_loop.iv33 = phi i32 [ 0, %omp_loop.body.lr.ph ], [ %omp_loop.next, %omp_loop.body ]
  %6 = add nuw i32 %omp_loop.iv33, 1
  %7 = add i32 %6, %3
  %8 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %9 = sitofp i32 %8 to float
  %10 = fdiv contract float 1.000000e+00, %9
  %11 = fpext float %10 to double
  %12 = sext i32 %7 to i64
  %13 = sub i64 %12, %.unpack9.unpack.unpack
  %14 = getelementptr double, ptr %.unpack, i64 %13
  store double %11, ptr %14, align 8, !tbaa !4
  %omp_loop.next = add nuw i32 %omp_loop.iv33, 1
  %exitcond = icmp ne i32 %omp_loop.next, %5
  br i1 %exitcond, label %omp_loop.body, label %omp_loop.header.omp_loop.exit_crit_edge
}
*** IR Dump After GVNPass on _QQmain..omp_par ***
; Function Attrs: norecurse nounwind
define internal void @_QQmain..omp_par(ptr noalias %tid.addr, ptr noalias %zero.addr, ptr %0) #2 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %p.lastiter = alloca i32, align 4
  %p.lowerbound = alloca i32, align 4
  %p.upperbound = alloca i32, align 4
  %p.stride = alloca i32, align 4
  %1 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %omp_loop.tripcount = tail call i32 @llvm.smax.i32(i32 %1, i32 0)
  store i32 0, ptr %p.lowerbound, align 4
  %2 = add nsw i32 %omp_loop.tripcount, -1
  store i32 %2, ptr %p.upperbound, align 4
  store i32 1, ptr %p.stride, align 4
  %omp_global_thread_num4 = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  call void @__kmpc_for_static_init_4u(ptr nonnull @1, i32 %omp_global_thread_num4, i32 34, ptr nonnull %p.lastiter, ptr nonnull %p.lowerbound, ptr nonnull %p.upperbound, ptr nonnull %p.stride, i32 1, i32 0)
  %3 = load i32, ptr %p.lowerbound, align 4
  %4 = load i32, ptr %p.upperbound, align 4
  %reass.sub = sub i32 %4, %3
  %5 = add i32 %reass.sub, 1
  %omp_loop.cmp32.not = icmp eq i32 %5, 0
  br i1 %omp_loop.cmp32.not, label %omp_loop.exit, label %omp_loop.body.lr.ph

omp_loop.body.lr.ph:                              ; preds = %omp.par.entry
  %.unpack = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  %.unpack3 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  %.unpack4 = load i32, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  %.unpack5 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  %.unpack6 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  %.unpack7 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  %.unpack8 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  %.unpack9.unpack.unpack = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  %.unpack9.unpack.unpack11 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  %.unpack9.unpack.unpack12 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  %loadgep_2.repack16 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  %loadgep_2.repack20 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  %loadgep_2.repack24 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  %loadgep_2.repack26.repack28 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  br label %omp_loop.body

omp_loop.header.omp_loop.exit_crit_edge:          ; preds = %omp_loop.body
  %loadgep_2.repack14 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  %loadgep_2.repack18 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  %loadgep_2.repack22 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  %loadgep_2.repack26 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  %loadgep_2.repack26.repack30 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  store ptr %.unpack, ptr %loadgep_2, align 8, !tbaa !8
  store i64 %.unpack3, ptr %loadgep_2.repack14, align 8, !tbaa !8
  store i32 %.unpack4, ptr %loadgep_2.repack16, align 8, !tbaa !8
  store i8 %.unpack5, ptr %loadgep_2.repack18, align 4, !tbaa !8
  store i8 %.unpack6, ptr %loadgep_2.repack20, align 1, !tbaa !8
  store i8 %.unpack7, ptr %loadgep_2.repack22, align 2, !tbaa !8
  store i8 %.unpack8, ptr %loadgep_2.repack24, align 1, !tbaa !8
  store i64 %.unpack9.unpack.unpack, ptr %loadgep_2.repack26, align 8, !tbaa !8
  store i64 %.unpack9.unpack.unpack11, ptr %loadgep_2.repack26.repack28, align 8, !tbaa !8
  store i64 %.unpack9.unpack.unpack12, ptr %loadgep_2.repack26.repack30, align 8, !tbaa !8
  br label %omp_loop.exit

omp_loop.exit:                                    ; preds = %omp_loop.header.omp_loop.exit_crit_edge, %omp.par.entry
  call void @__kmpc_for_static_fini(ptr nonnull @1, i32 %omp_global_thread_num4)
  call void @__kmpc_barrier(ptr nonnull @2, i32 %omp_global_thread_num4)
  ret void

omp_loop.body:                                    ; preds = %omp_loop.body.lr.ph, %omp_loop.body
  %omp_loop.iv33 = phi i32 [ 0, %omp_loop.body.lr.ph ], [ %6, %omp_loop.body ]
  %6 = add nuw i32 %omp_loop.iv33, 1
  %7 = add i32 %6, %3
  %8 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %9 = sitofp i32 %8 to float
  %10 = fdiv contract float 1.000000e+00, %9
  %11 = fpext float %10 to double
  %12 = sext i32 %7 to i64
  %13 = sub i64 %12, %.unpack9.unpack.unpack
  %14 = getelementptr double, ptr %.unpack, i64 %13
  store double %11, ptr %14, align 8, !tbaa !4
  %exitcond = icmp ne i32 %6, %5
  br i1 %exitcond, label %omp_loop.body, label %omp_loop.header.omp_loop.exit_crit_edge
}
*** IR Dump After SCCPPass on _QQmain..omp_par ***
; Function Attrs: norecurse nounwind
define internal void @_QQmain..omp_par(ptr noalias %tid.addr, ptr noalias %zero.addr, ptr %0) #2 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %p.lastiter = alloca i32, align 4
  %p.lowerbound = alloca i32, align 4
  %p.upperbound = alloca i32, align 4
  %p.stride = alloca i32, align 4
  %1 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %omp_loop.tripcount = tail call i32 @llvm.smax.i32(i32 %1, i32 0)
  store i32 0, ptr %p.lowerbound, align 4
  %2 = add nsw i32 %omp_loop.tripcount, -1
  store i32 %2, ptr %p.upperbound, align 4
  store i32 1, ptr %p.stride, align 4
  %omp_global_thread_num4 = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  call void @__kmpc_for_static_init_4u(ptr nonnull @1, i32 %omp_global_thread_num4, i32 34, ptr nonnull %p.lastiter, ptr nonnull %p.lowerbound, ptr nonnull %p.upperbound, ptr nonnull %p.stride, i32 1, i32 0)
  %3 = load i32, ptr %p.lowerbound, align 4
  %4 = load i32, ptr %p.upperbound, align 4
  %reass.sub = sub i32 %4, %3
  %5 = add i32 %reass.sub, 1
  %omp_loop.cmp32.not = icmp eq i32 %5, 0
  br i1 %omp_loop.cmp32.not, label %omp_loop.exit, label %omp_loop.body.lr.ph

omp_loop.body.lr.ph:                              ; preds = %omp.par.entry
  %.unpack = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  %.unpack3 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  %.unpack4 = load i32, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  %.unpack5 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  %.unpack6 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  %.unpack7 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  %.unpack8 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  %.unpack9.unpack.unpack = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  %.unpack9.unpack.unpack11 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  %.unpack9.unpack.unpack12 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  %loadgep_2.repack16 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  %loadgep_2.repack20 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  %loadgep_2.repack24 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  %loadgep_2.repack26.repack28 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  br label %omp_loop.body

omp_loop.header.omp_loop.exit_crit_edge:          ; preds = %omp_loop.body
  %loadgep_2.repack14 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  %loadgep_2.repack18 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  %loadgep_2.repack22 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  %loadgep_2.repack26 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  %loadgep_2.repack26.repack30 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  store ptr %.unpack, ptr %loadgep_2, align 8, !tbaa !8
  store i64 %.unpack3, ptr %loadgep_2.repack14, align 8, !tbaa !8
  store i32 %.unpack4, ptr %loadgep_2.repack16, align 8, !tbaa !8
  store i8 %.unpack5, ptr %loadgep_2.repack18, align 4, !tbaa !8
  store i8 %.unpack6, ptr %loadgep_2.repack20, align 1, !tbaa !8
  store i8 %.unpack7, ptr %loadgep_2.repack22, align 2, !tbaa !8
  store i8 %.unpack8, ptr %loadgep_2.repack24, align 1, !tbaa !8
  store i64 %.unpack9.unpack.unpack, ptr %loadgep_2.repack26, align 8, !tbaa !8
  store i64 %.unpack9.unpack.unpack11, ptr %loadgep_2.repack26.repack28, align 8, !tbaa !8
  store i64 %.unpack9.unpack.unpack12, ptr %loadgep_2.repack26.repack30, align 8, !tbaa !8
  br label %omp_loop.exit

omp_loop.exit:                                    ; preds = %omp_loop.header.omp_loop.exit_crit_edge, %omp.par.entry
  call void @__kmpc_for_static_fini(ptr nonnull @1, i32 %omp_global_thread_num4)
  call void @__kmpc_barrier(ptr nonnull @2, i32 %omp_global_thread_num4)
  ret void

omp_loop.body:                                    ; preds = %omp_loop.body.lr.ph, %omp_loop.body
  %omp_loop.iv33 = phi i32 [ 0, %omp_loop.body.lr.ph ], [ %6, %omp_loop.body ]
  %6 = add nuw i32 %omp_loop.iv33, 1
  %7 = add i32 %6, %3
  %8 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %9 = sitofp i32 %8 to float
  %10 = fdiv contract float 1.000000e+00, %9
  %11 = fpext float %10 to double
  %12 = sext i32 %7 to i64
  %13 = sub i64 %12, %.unpack9.unpack.unpack
  %14 = getelementptr double, ptr %.unpack, i64 %13
  store double %11, ptr %14, align 8, !tbaa !4
  %exitcond = icmp ne i32 %6, %5
  br i1 %exitcond, label %omp_loop.body, label %omp_loop.header.omp_loop.exit_crit_edge
}
*** IR Dump After BDCEPass on _QQmain..omp_par ***
; Function Attrs: norecurse nounwind
define internal void @_QQmain..omp_par(ptr noalias %tid.addr, ptr noalias %zero.addr, ptr %0) #2 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %p.lastiter = alloca i32, align 4
  %p.lowerbound = alloca i32, align 4
  %p.upperbound = alloca i32, align 4
  %p.stride = alloca i32, align 4
  %1 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %omp_loop.tripcount = tail call i32 @llvm.smax.i32(i32 %1, i32 0)
  store i32 0, ptr %p.lowerbound, align 4
  %2 = add nsw i32 %omp_loop.tripcount, -1
  store i32 %2, ptr %p.upperbound, align 4
  store i32 1, ptr %p.stride, align 4
  %omp_global_thread_num4 = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  call void @__kmpc_for_static_init_4u(ptr nonnull @1, i32 %omp_global_thread_num4, i32 34, ptr nonnull %p.lastiter, ptr nonnull %p.lowerbound, ptr nonnull %p.upperbound, ptr nonnull %p.stride, i32 1, i32 0)
  %3 = load i32, ptr %p.lowerbound, align 4
  %4 = load i32, ptr %p.upperbound, align 4
  %reass.sub = sub i32 %4, %3
  %5 = add i32 %reass.sub, 1
  %omp_loop.cmp32.not = icmp eq i32 %5, 0
  br i1 %omp_loop.cmp32.not, label %omp_loop.exit, label %omp_loop.body.lr.ph

omp_loop.body.lr.ph:                              ; preds = %omp.par.entry
  %.unpack = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  %.unpack3 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  %.unpack4 = load i32, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  %.unpack5 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  %.unpack6 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  %.unpack7 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  %.unpack8 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  %.unpack9.unpack.unpack = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  %.unpack9.unpack.unpack11 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  %.unpack9.unpack.unpack12 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  %loadgep_2.repack16 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  %loadgep_2.repack20 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  %loadgep_2.repack24 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  %loadgep_2.repack26.repack28 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  br label %omp_loop.body

omp_loop.header.omp_loop.exit_crit_edge:          ; preds = %omp_loop.body
  %loadgep_2.repack14 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  %loadgep_2.repack18 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  %loadgep_2.repack22 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  %loadgep_2.repack26 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  %loadgep_2.repack26.repack30 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  store ptr %.unpack, ptr %loadgep_2, align 8, !tbaa !8
  store i64 %.unpack3, ptr %loadgep_2.repack14, align 8, !tbaa !8
  store i32 %.unpack4, ptr %loadgep_2.repack16, align 8, !tbaa !8
  store i8 %.unpack5, ptr %loadgep_2.repack18, align 4, !tbaa !8
  store i8 %.unpack6, ptr %loadgep_2.repack20, align 1, !tbaa !8
  store i8 %.unpack7, ptr %loadgep_2.repack22, align 2, !tbaa !8
  store i8 %.unpack8, ptr %loadgep_2.repack24, align 1, !tbaa !8
  store i64 %.unpack9.unpack.unpack, ptr %loadgep_2.repack26, align 8, !tbaa !8
  store i64 %.unpack9.unpack.unpack11, ptr %loadgep_2.repack26.repack28, align 8, !tbaa !8
  store i64 %.unpack9.unpack.unpack12, ptr %loadgep_2.repack26.repack30, align 8, !tbaa !8
  br label %omp_loop.exit

omp_loop.exit:                                    ; preds = %omp_loop.header.omp_loop.exit_crit_edge, %omp.par.entry
  call void @__kmpc_for_static_fini(ptr nonnull @1, i32 %omp_global_thread_num4)
  call void @__kmpc_barrier(ptr nonnull @2, i32 %omp_global_thread_num4)
  ret void

omp_loop.body:                                    ; preds = %omp_loop.body.lr.ph, %omp_loop.body
  %omp_loop.iv33 = phi i32 [ 0, %omp_loop.body.lr.ph ], [ %6, %omp_loop.body ]
  %6 = add nuw i32 %omp_loop.iv33, 1
  %7 = add i32 %6, %3
  %8 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %9 = sitofp i32 %8 to float
  %10 = fdiv contract float 1.000000e+00, %9
  %11 = fpext float %10 to double
  %12 = sext i32 %7 to i64
  %13 = sub i64 %12, %.unpack9.unpack.unpack
  %14 = getelementptr double, ptr %.unpack, i64 %13
  store double %11, ptr %14, align 8, !tbaa !4
  %exitcond = icmp ne i32 %6, %5
  br i1 %exitcond, label %omp_loop.body, label %omp_loop.header.omp_loop.exit_crit_edge
}
*** IR Dump After InstCombinePass on _QQmain..omp_par ***
; Function Attrs: norecurse nounwind
define internal void @_QQmain..omp_par(ptr noalias %tid.addr, ptr noalias %zero.addr, ptr %0) #2 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %p.lastiter = alloca i32, align 4
  %p.lowerbound = alloca i32, align 4
  %p.upperbound = alloca i32, align 4
  %p.stride = alloca i32, align 4
  %1 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %omp_loop.tripcount = tail call i32 @llvm.smax.i32(i32 %1, i32 0)
  store i32 0, ptr %p.lowerbound, align 4
  %2 = add nsw i32 %omp_loop.tripcount, -1
  store i32 %2, ptr %p.upperbound, align 4
  store i32 1, ptr %p.stride, align 4
  %omp_global_thread_num4 = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  call void @__kmpc_for_static_init_4u(ptr nonnull @1, i32 %omp_global_thread_num4, i32 34, ptr nonnull %p.lastiter, ptr nonnull %p.lowerbound, ptr nonnull %p.upperbound, ptr nonnull %p.stride, i32 1, i32 0)
  %3 = load i32, ptr %p.lowerbound, align 4
  %4 = load i32, ptr %p.upperbound, align 4
  %reass.sub = sub i32 %4, %3
  %omp_loop.cmp32.not = icmp eq i32 %reass.sub, -1
  br i1 %omp_loop.cmp32.not, label %omp_loop.exit, label %omp_loop.body.lr.ph

omp_loop.body.lr.ph:                              ; preds = %omp.par.entry
  %.unpack = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  %.unpack3 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  %.unpack4 = load i32, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  %.unpack5 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  %.unpack6 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  %.unpack7 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  %.unpack8 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  %.unpack9.unpack.unpack = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  %.unpack9.unpack.unpack11 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  %.unpack9.unpack.unpack12 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  %loadgep_2.repack16 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  %loadgep_2.repack20 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  %loadgep_2.repack24 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  %loadgep_2.repack26.repack28 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  br label %omp_loop.body

omp_loop.header.omp_loop.exit_crit_edge:          ; preds = %omp_loop.body
  %loadgep_2.repack14 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  %loadgep_2.repack18 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  %loadgep_2.repack22 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  %loadgep_2.repack26 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  %loadgep_2.repack26.repack30 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  store ptr %.unpack, ptr %loadgep_2, align 8, !tbaa !8
  store i64 %.unpack3, ptr %loadgep_2.repack14, align 8, !tbaa !8
  store i32 %.unpack4, ptr %loadgep_2.repack16, align 8, !tbaa !8
  store i8 %.unpack5, ptr %loadgep_2.repack18, align 4, !tbaa !8
  store i8 %.unpack6, ptr %loadgep_2.repack20, align 1, !tbaa !8
  store i8 %.unpack7, ptr %loadgep_2.repack22, align 2, !tbaa !8
  store i8 %.unpack8, ptr %loadgep_2.repack24, align 1, !tbaa !8
  store i64 %.unpack9.unpack.unpack, ptr %loadgep_2.repack26, align 8, !tbaa !8
  store i64 %.unpack9.unpack.unpack11, ptr %loadgep_2.repack26.repack28, align 8, !tbaa !8
  store i64 %.unpack9.unpack.unpack12, ptr %loadgep_2.repack26.repack30, align 8, !tbaa !8
  br label %omp_loop.exit

omp_loop.exit:                                    ; preds = %omp_loop.header.omp_loop.exit_crit_edge, %omp.par.entry
  call void @__kmpc_for_static_fini(ptr nonnull @1, i32 %omp_global_thread_num4)
  call void @__kmpc_barrier(ptr nonnull @2, i32 %omp_global_thread_num4)
  ret void

omp_loop.body:                                    ; preds = %omp_loop.body.lr.ph, %omp_loop.body
  %omp_loop.iv33 = phi i32 [ 0, %omp_loop.body.lr.ph ], [ %5, %omp_loop.body ]
  %5 = add nuw i32 %omp_loop.iv33, 1
  %6 = add i32 %5, %3
  %7 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %8 = sitofp i32 %7 to float
  %9 = fdiv contract float 1.000000e+00, %8
  %10 = fpext float %9 to double
  %11 = sext i32 %6 to i64
  %12 = sub i64 %11, %.unpack9.unpack.unpack
  %13 = getelementptr double, ptr %.unpack, i64 %12
  store double %10, ptr %13, align 8, !tbaa !4
  %exitcond.not = icmp eq i32 %omp_loop.iv33, %reass.sub
  br i1 %exitcond.not, label %omp_loop.header.omp_loop.exit_crit_edge, label %omp_loop.body
}
*** IR Dump After JumpThreadingPass on _QQmain..omp_par ***
; Function Attrs: norecurse nounwind
define internal void @_QQmain..omp_par(ptr noalias %tid.addr, ptr noalias %zero.addr, ptr %0) #2 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %p.lastiter = alloca i32, align 4
  %p.lowerbound = alloca i32, align 4
  %p.upperbound = alloca i32, align 4
  %p.stride = alloca i32, align 4
  %1 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %omp_loop.tripcount = tail call i32 @llvm.smax.i32(i32 %1, i32 0)
  store i32 0, ptr %p.lowerbound, align 4
  %2 = add nsw i32 %omp_loop.tripcount, -1
  store i32 %2, ptr %p.upperbound, align 4
  store i32 1, ptr %p.stride, align 4
  %omp_global_thread_num4 = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  call void @__kmpc_for_static_init_4u(ptr nonnull @1, i32 %omp_global_thread_num4, i32 34, ptr nonnull %p.lastiter, ptr nonnull %p.lowerbound, ptr nonnull %p.upperbound, ptr nonnull %p.stride, i32 1, i32 0)
  %3 = load i32, ptr %p.lowerbound, align 4
  %4 = load i32, ptr %p.upperbound, align 4
  %reass.sub = sub i32 %4, %3
  %omp_loop.cmp32.not = icmp eq i32 %reass.sub, -1
  br i1 %omp_loop.cmp32.not, label %omp_loop.exit, label %omp_loop.body.lr.ph

omp_loop.body.lr.ph:                              ; preds = %omp.par.entry
  %.unpack = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  %.unpack3 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  %.unpack4 = load i32, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  %.unpack5 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  %.unpack6 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  %.unpack7 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  %.unpack8 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  %.unpack9.unpack.unpack = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  %.unpack9.unpack.unpack11 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  %.unpack9.unpack.unpack12 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  %loadgep_2.repack16 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  %loadgep_2.repack20 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  %loadgep_2.repack24 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  %loadgep_2.repack26.repack28 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  br label %omp_loop.body

omp_loop.header.omp_loop.exit_crit_edge:          ; preds = %omp_loop.body
  %loadgep_2.repack14 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  %loadgep_2.repack18 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  %loadgep_2.repack22 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  %loadgep_2.repack26 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  %loadgep_2.repack26.repack30 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  store ptr %.unpack, ptr %loadgep_2, align 8, !tbaa !8
  store i64 %.unpack3, ptr %loadgep_2.repack14, align 8, !tbaa !8
  store i32 %.unpack4, ptr %loadgep_2.repack16, align 8, !tbaa !8
  store i8 %.unpack5, ptr %loadgep_2.repack18, align 4, !tbaa !8
  store i8 %.unpack6, ptr %loadgep_2.repack20, align 1, !tbaa !8
  store i8 %.unpack7, ptr %loadgep_2.repack22, align 2, !tbaa !8
  store i8 %.unpack8, ptr %loadgep_2.repack24, align 1, !tbaa !8
  store i64 %.unpack9.unpack.unpack, ptr %loadgep_2.repack26, align 8, !tbaa !8
  store i64 %.unpack9.unpack.unpack11, ptr %loadgep_2.repack26.repack28, align 8, !tbaa !8
  store i64 %.unpack9.unpack.unpack12, ptr %loadgep_2.repack26.repack30, align 8, !tbaa !8
  br label %omp_loop.exit

omp_loop.exit:                                    ; preds = %omp_loop.header.omp_loop.exit_crit_edge, %omp.par.entry
  call void @__kmpc_for_static_fini(ptr nonnull @1, i32 %omp_global_thread_num4)
  call void @__kmpc_barrier(ptr nonnull @2, i32 %omp_global_thread_num4)
  ret void

omp_loop.body:                                    ; preds = %omp_loop.body.lr.ph, %omp_loop.body
  %omp_loop.iv33 = phi i32 [ 0, %omp_loop.body.lr.ph ], [ %5, %omp_loop.body ]
  %5 = add nuw i32 %omp_loop.iv33, 1
  %6 = add i32 %5, %3
  %7 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %8 = sitofp i32 %7 to float
  %9 = fdiv contract float 1.000000e+00, %8
  %10 = fpext float %9 to double
  %11 = sext i32 %6 to i64
  %12 = sub i64 %11, %.unpack9.unpack.unpack
  %13 = getelementptr double, ptr %.unpack, i64 %12
  store double %10, ptr %13, align 8, !tbaa !4
  %exitcond.not = icmp eq i32 %omp_loop.iv33, %reass.sub
  br i1 %exitcond.not, label %omp_loop.header.omp_loop.exit_crit_edge, label %omp_loop.body
}
*** IR Dump After CorrelatedValuePropagationPass on _QQmain..omp_par ***
; Function Attrs: norecurse nounwind
define internal void @_QQmain..omp_par(ptr noalias %tid.addr, ptr noalias %zero.addr, ptr %0) #2 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %p.lastiter = alloca i32, align 4
  %p.lowerbound = alloca i32, align 4
  %p.upperbound = alloca i32, align 4
  %p.stride = alloca i32, align 4
  %1 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %omp_loop.tripcount = tail call i32 @llvm.smax.i32(i32 %1, i32 0)
  store i32 0, ptr %p.lowerbound, align 4
  %2 = add nsw i32 %omp_loop.tripcount, -1
  store i32 %2, ptr %p.upperbound, align 4
  store i32 1, ptr %p.stride, align 4
  %omp_global_thread_num4 = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  call void @__kmpc_for_static_init_4u(ptr nonnull @1, i32 %omp_global_thread_num4, i32 34, ptr nonnull %p.lastiter, ptr nonnull %p.lowerbound, ptr nonnull %p.upperbound, ptr nonnull %p.stride, i32 1, i32 0)
  %3 = load i32, ptr %p.lowerbound, align 4
  %4 = load i32, ptr %p.upperbound, align 4
  %reass.sub = sub i32 %4, %3
  %omp_loop.cmp32.not = icmp eq i32 %reass.sub, -1
  br i1 %omp_loop.cmp32.not, label %omp_loop.exit, label %omp_loop.body.lr.ph

omp_loop.body.lr.ph:                              ; preds = %omp.par.entry
  %.unpack = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  %.unpack3 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  %.unpack4 = load i32, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  %.unpack5 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  %.unpack6 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  %.unpack7 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  %.unpack8 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  %.unpack9.unpack.unpack = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  %.unpack9.unpack.unpack11 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  %.unpack9.unpack.unpack12 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  %loadgep_2.repack16 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  %loadgep_2.repack20 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  %loadgep_2.repack24 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  %loadgep_2.repack26.repack28 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  br label %omp_loop.body

omp_loop.header.omp_loop.exit_crit_edge:          ; preds = %omp_loop.body
  %loadgep_2.repack14 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  %loadgep_2.repack18 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  %loadgep_2.repack22 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  %loadgep_2.repack26 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  %loadgep_2.repack26.repack30 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  store ptr %.unpack, ptr %loadgep_2, align 8, !tbaa !8
  store i64 %.unpack3, ptr %loadgep_2.repack14, align 8, !tbaa !8
  store i32 %.unpack4, ptr %loadgep_2.repack16, align 8, !tbaa !8
  store i8 %.unpack5, ptr %loadgep_2.repack18, align 4, !tbaa !8
  store i8 %.unpack6, ptr %loadgep_2.repack20, align 1, !tbaa !8
  store i8 %.unpack7, ptr %loadgep_2.repack22, align 2, !tbaa !8
  store i8 %.unpack8, ptr %loadgep_2.repack24, align 1, !tbaa !8
  store i64 %.unpack9.unpack.unpack, ptr %loadgep_2.repack26, align 8, !tbaa !8
  store i64 %.unpack9.unpack.unpack11, ptr %loadgep_2.repack26.repack28, align 8, !tbaa !8
  store i64 %.unpack9.unpack.unpack12, ptr %loadgep_2.repack26.repack30, align 8, !tbaa !8
  br label %omp_loop.exit

omp_loop.exit:                                    ; preds = %omp_loop.header.omp_loop.exit_crit_edge, %omp.par.entry
  call void @__kmpc_for_static_fini(ptr nonnull @1, i32 %omp_global_thread_num4)
  call void @__kmpc_barrier(ptr nonnull @2, i32 %omp_global_thread_num4)
  ret void

omp_loop.body:                                    ; preds = %omp_loop.body.lr.ph, %omp_loop.body
  %omp_loop.iv33 = phi i32 [ 0, %omp_loop.body.lr.ph ], [ %5, %omp_loop.body ]
  %5 = add nuw i32 %omp_loop.iv33, 1
  %6 = add i32 %5, %3
  %7 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %8 = sitofp i32 %7 to float
  %9 = fdiv contract float 1.000000e+00, %8
  %10 = fpext float %9 to double
  %11 = sext i32 %6 to i64
  %12 = sub i64 %11, %.unpack9.unpack.unpack
  %13 = getelementptr double, ptr %.unpack, i64 %12
  store double %10, ptr %13, align 8, !tbaa !4
  %exitcond.not = icmp eq i32 %omp_loop.iv33, %reass.sub
  br i1 %exitcond.not, label %omp_loop.header.omp_loop.exit_crit_edge, label %omp_loop.body
}
*** IR Dump After ADCEPass on _QQmain..omp_par ***
; Function Attrs: norecurse nounwind
define internal void @_QQmain..omp_par(ptr noalias %tid.addr, ptr noalias %zero.addr, ptr %0) #2 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %p.lastiter = alloca i32, align 4
  %p.lowerbound = alloca i32, align 4
  %p.upperbound = alloca i32, align 4
  %p.stride = alloca i32, align 4
  %1 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %omp_loop.tripcount = tail call i32 @llvm.smax.i32(i32 %1, i32 0)
  store i32 0, ptr %p.lowerbound, align 4
  %2 = add nsw i32 %omp_loop.tripcount, -1
  store i32 %2, ptr %p.upperbound, align 4
  store i32 1, ptr %p.stride, align 4
  %omp_global_thread_num4 = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  call void @__kmpc_for_static_init_4u(ptr nonnull @1, i32 %omp_global_thread_num4, i32 34, ptr nonnull %p.lastiter, ptr nonnull %p.lowerbound, ptr nonnull %p.upperbound, ptr nonnull %p.stride, i32 1, i32 0)
  %3 = load i32, ptr %p.lowerbound, align 4
  %4 = load i32, ptr %p.upperbound, align 4
  %reass.sub = sub i32 %4, %3
  %omp_loop.cmp32.not = icmp eq i32 %reass.sub, -1
  br i1 %omp_loop.cmp32.not, label %omp_loop.exit, label %omp_loop.body.lr.ph

omp_loop.body.lr.ph:                              ; preds = %omp.par.entry
  %.unpack = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  %.unpack3 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  %.unpack4 = load i32, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  %.unpack5 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  %.unpack6 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  %.unpack7 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  %.unpack8 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  %.unpack9.unpack.unpack = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  %.unpack9.unpack.unpack11 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  %.unpack9.unpack.unpack12 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  %loadgep_2.repack16 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  %loadgep_2.repack20 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  %loadgep_2.repack24 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  %loadgep_2.repack26.repack28 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  br label %omp_loop.body

omp_loop.header.omp_loop.exit_crit_edge:          ; preds = %omp_loop.body
  %loadgep_2.repack14 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  %loadgep_2.repack18 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  %loadgep_2.repack22 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  %loadgep_2.repack26 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  %loadgep_2.repack26.repack30 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  store ptr %.unpack, ptr %loadgep_2, align 8, !tbaa !8
  store i64 %.unpack3, ptr %loadgep_2.repack14, align 8, !tbaa !8
  store i32 %.unpack4, ptr %loadgep_2.repack16, align 8, !tbaa !8
  store i8 %.unpack5, ptr %loadgep_2.repack18, align 4, !tbaa !8
  store i8 %.unpack6, ptr %loadgep_2.repack20, align 1, !tbaa !8
  store i8 %.unpack7, ptr %loadgep_2.repack22, align 2, !tbaa !8
  store i8 %.unpack8, ptr %loadgep_2.repack24, align 1, !tbaa !8
  store i64 %.unpack9.unpack.unpack, ptr %loadgep_2.repack26, align 8, !tbaa !8
  store i64 %.unpack9.unpack.unpack11, ptr %loadgep_2.repack26.repack28, align 8, !tbaa !8
  store i64 %.unpack9.unpack.unpack12, ptr %loadgep_2.repack26.repack30, align 8, !tbaa !8
  br label %omp_loop.exit

omp_loop.exit:                                    ; preds = %omp_loop.header.omp_loop.exit_crit_edge, %omp.par.entry
  call void @__kmpc_for_static_fini(ptr nonnull @1, i32 %omp_global_thread_num4)
  call void @__kmpc_barrier(ptr nonnull @2, i32 %omp_global_thread_num4)
  ret void

omp_loop.body:                                    ; preds = %omp_loop.body.lr.ph, %omp_loop.body
  %omp_loop.iv33 = phi i32 [ 0, %omp_loop.body.lr.ph ], [ %5, %omp_loop.body ]
  %5 = add nuw i32 %omp_loop.iv33, 1
  %6 = add i32 %5, %3
  %7 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %8 = sitofp i32 %7 to float
  %9 = fdiv contract float 1.000000e+00, %8
  %10 = fpext float %9 to double
  %11 = sext i32 %6 to i64
  %12 = sub i64 %11, %.unpack9.unpack.unpack
  %13 = getelementptr double, ptr %.unpack, i64 %12
  store double %10, ptr %13, align 8, !tbaa !4
  %exitcond.not = icmp eq i32 %omp_loop.iv33, %reass.sub
  br i1 %exitcond.not, label %omp_loop.header.omp_loop.exit_crit_edge, label %omp_loop.body
}
*** IR Dump After MemCpyOptPass on _QQmain..omp_par ***
; Function Attrs: norecurse nounwind
define internal void @_QQmain..omp_par(ptr noalias %tid.addr, ptr noalias %zero.addr, ptr %0) #2 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %p.lastiter = alloca i32, align 4
  %p.lowerbound = alloca i32, align 4
  %p.upperbound = alloca i32, align 4
  %p.stride = alloca i32, align 4
  %1 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %omp_loop.tripcount = tail call i32 @llvm.smax.i32(i32 %1, i32 0)
  store i32 0, ptr %p.lowerbound, align 4
  %2 = add nsw i32 %omp_loop.tripcount, -1
  store i32 %2, ptr %p.upperbound, align 4
  store i32 1, ptr %p.stride, align 4
  %omp_global_thread_num4 = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  call void @__kmpc_for_static_init_4u(ptr nonnull @1, i32 %omp_global_thread_num4, i32 34, ptr nonnull %p.lastiter, ptr nonnull %p.lowerbound, ptr nonnull %p.upperbound, ptr nonnull %p.stride, i32 1, i32 0)
  %3 = load i32, ptr %p.lowerbound, align 4
  %4 = load i32, ptr %p.upperbound, align 4
  %reass.sub = sub i32 %4, %3
  %omp_loop.cmp32.not = icmp eq i32 %reass.sub, -1
  br i1 %omp_loop.cmp32.not, label %omp_loop.exit, label %omp_loop.body.lr.ph

omp_loop.body.lr.ph:                              ; preds = %omp.par.entry
  %.unpack = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  %.unpack3 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  %.unpack4 = load i32, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  %.unpack5 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  %.unpack6 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  %.unpack7 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  %.unpack8 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  %.unpack9.unpack.unpack = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  %.unpack9.unpack.unpack11 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  %.unpack9.unpack.unpack12 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  %loadgep_2.repack16 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  %loadgep_2.repack20 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  %loadgep_2.repack24 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  %loadgep_2.repack26.repack28 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  br label %omp_loop.body

omp_loop.header.omp_loop.exit_crit_edge:          ; preds = %omp_loop.body
  %loadgep_2.repack14 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  %loadgep_2.repack18 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  %loadgep_2.repack22 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  %loadgep_2.repack26 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  %loadgep_2.repack26.repack30 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  store ptr %.unpack, ptr %loadgep_2, align 8, !tbaa !8
  store i64 %.unpack3, ptr %loadgep_2.repack14, align 8, !tbaa !8
  store i32 %.unpack4, ptr %loadgep_2.repack16, align 8, !tbaa !8
  store i8 %.unpack5, ptr %loadgep_2.repack18, align 4, !tbaa !8
  store i8 %.unpack6, ptr %loadgep_2.repack20, align 1, !tbaa !8
  store i8 %.unpack7, ptr %loadgep_2.repack22, align 2, !tbaa !8
  store i8 %.unpack8, ptr %loadgep_2.repack24, align 1, !tbaa !8
  store i64 %.unpack9.unpack.unpack, ptr %loadgep_2.repack26, align 8, !tbaa !8
  store i64 %.unpack9.unpack.unpack11, ptr %loadgep_2.repack26.repack28, align 8, !tbaa !8
  store i64 %.unpack9.unpack.unpack12, ptr %loadgep_2.repack26.repack30, align 8, !tbaa !8
  br label %omp_loop.exit

omp_loop.exit:                                    ; preds = %omp_loop.header.omp_loop.exit_crit_edge, %omp.par.entry
  call void @__kmpc_for_static_fini(ptr nonnull @1, i32 %omp_global_thread_num4)
  call void @__kmpc_barrier(ptr nonnull @2, i32 %omp_global_thread_num4)
  ret void

omp_loop.body:                                    ; preds = %omp_loop.body.lr.ph, %omp_loop.body
  %omp_loop.iv33 = phi i32 [ 0, %omp_loop.body.lr.ph ], [ %5, %omp_loop.body ]
  %5 = add nuw i32 %omp_loop.iv33, 1
  %6 = add i32 %5, %3
  %7 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %8 = sitofp i32 %7 to float
  %9 = fdiv contract float 1.000000e+00, %8
  %10 = fpext float %9 to double
  %11 = sext i32 %6 to i64
  %12 = sub i64 %11, %.unpack9.unpack.unpack
  %13 = getelementptr double, ptr %.unpack, i64 %12
  store double %10, ptr %13, align 8, !tbaa !4
  %exitcond.not = icmp eq i32 %omp_loop.iv33, %reass.sub
  br i1 %exitcond.not, label %omp_loop.header.omp_loop.exit_crit_edge, label %omp_loop.body
}
*** IR Dump After DSEPass on _QQmain..omp_par ***
; Function Attrs: norecurse nounwind
define internal void @_QQmain..omp_par(ptr noalias %tid.addr, ptr noalias %zero.addr, ptr %0) #2 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %p.lastiter = alloca i32, align 4
  %p.lowerbound = alloca i32, align 4
  %p.upperbound = alloca i32, align 4
  %p.stride = alloca i32, align 4
  %1 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %omp_loop.tripcount = tail call i32 @llvm.smax.i32(i32 %1, i32 0)
  store i32 0, ptr %p.lowerbound, align 4
  %2 = add nsw i32 %omp_loop.tripcount, -1
  store i32 %2, ptr %p.upperbound, align 4
  store i32 1, ptr %p.stride, align 4
  %omp_global_thread_num4 = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  call void @__kmpc_for_static_init_4u(ptr nonnull @1, i32 %omp_global_thread_num4, i32 34, ptr nonnull %p.lastiter, ptr nonnull %p.lowerbound, ptr nonnull %p.upperbound, ptr nonnull %p.stride, i32 1, i32 0)
  %3 = load i32, ptr %p.lowerbound, align 4
  %4 = load i32, ptr %p.upperbound, align 4
  %reass.sub = sub i32 %4, %3
  %omp_loop.cmp32.not = icmp eq i32 %reass.sub, -1
  br i1 %omp_loop.cmp32.not, label %omp_loop.exit, label %omp_loop.body.lr.ph

omp_loop.body.lr.ph:                              ; preds = %omp.par.entry
  %.unpack = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  %.unpack3 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  %.unpack4 = load i32, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  %.unpack5 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  %.unpack6 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  %.unpack7 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  %.unpack8 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  %.unpack9.unpack.unpack = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  %.unpack9.unpack.unpack11 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  %.unpack9.unpack.unpack12 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  %loadgep_2.repack16 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  %loadgep_2.repack20 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  %loadgep_2.repack24 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  %loadgep_2.repack26.repack28 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  br label %omp_loop.body

omp_loop.header.omp_loop.exit_crit_edge:          ; preds = %omp_loop.body
  %loadgep_2.repack14 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  %loadgep_2.repack18 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  %loadgep_2.repack22 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  %loadgep_2.repack26 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  %loadgep_2.repack26.repack30 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  store ptr %.unpack, ptr %loadgep_2, align 8, !tbaa !8
  store i64 %.unpack3, ptr %loadgep_2.repack14, align 8, !tbaa !8
  store i32 %.unpack4, ptr %loadgep_2.repack16, align 8, !tbaa !8
  store i8 %.unpack5, ptr %loadgep_2.repack18, align 4, !tbaa !8
  store i8 %.unpack6, ptr %loadgep_2.repack20, align 1, !tbaa !8
  store i8 %.unpack7, ptr %loadgep_2.repack22, align 2, !tbaa !8
  store i8 %.unpack8, ptr %loadgep_2.repack24, align 1, !tbaa !8
  store i64 %.unpack9.unpack.unpack, ptr %loadgep_2.repack26, align 8, !tbaa !8
  store i64 %.unpack9.unpack.unpack11, ptr %loadgep_2.repack26.repack28, align 8, !tbaa !8
  store i64 %.unpack9.unpack.unpack12, ptr %loadgep_2.repack26.repack30, align 8, !tbaa !8
  br label %omp_loop.exit

omp_loop.exit:                                    ; preds = %omp_loop.header.omp_loop.exit_crit_edge, %omp.par.entry
  call void @__kmpc_for_static_fini(ptr nonnull @1, i32 %omp_global_thread_num4)
  call void @__kmpc_barrier(ptr nonnull @2, i32 %omp_global_thread_num4)
  ret void

omp_loop.body:                                    ; preds = %omp_loop.body.lr.ph, %omp_loop.body
  %omp_loop.iv33 = phi i32 [ 0, %omp_loop.body.lr.ph ], [ %5, %omp_loop.body ]
  %5 = add nuw i32 %omp_loop.iv33, 1
  %6 = add i32 %5, %3
  %7 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %8 = sitofp i32 %7 to float
  %9 = fdiv contract float 1.000000e+00, %8
  %10 = fpext float %9 to double
  %11 = sext i32 %6 to i64
  %12 = sub i64 %11, %.unpack9.unpack.unpack
  %13 = getelementptr double, ptr %.unpack, i64 %12
  store double %10, ptr %13, align 8, !tbaa !4
  %exitcond.not = icmp eq i32 %omp_loop.iv33, %reass.sub
  br i1 %exitcond.not, label %omp_loop.header.omp_loop.exit_crit_edge, label %omp_loop.body
}
*** IR Dump After MoveAutoInitPass on _QQmain..omp_par ***
; Function Attrs: norecurse nounwind
define internal void @_QQmain..omp_par(ptr noalias %tid.addr, ptr noalias %zero.addr, ptr %0) #2 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %p.lastiter = alloca i32, align 4
  %p.lowerbound = alloca i32, align 4
  %p.upperbound = alloca i32, align 4
  %p.stride = alloca i32, align 4
  %1 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %omp_loop.tripcount = tail call i32 @llvm.smax.i32(i32 %1, i32 0)
  store i32 0, ptr %p.lowerbound, align 4
  %2 = add nsw i32 %omp_loop.tripcount, -1
  store i32 %2, ptr %p.upperbound, align 4
  store i32 1, ptr %p.stride, align 4
  %omp_global_thread_num4 = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  call void @__kmpc_for_static_init_4u(ptr nonnull @1, i32 %omp_global_thread_num4, i32 34, ptr nonnull %p.lastiter, ptr nonnull %p.lowerbound, ptr nonnull %p.upperbound, ptr nonnull %p.stride, i32 1, i32 0)
  %3 = load i32, ptr %p.lowerbound, align 4
  %4 = load i32, ptr %p.upperbound, align 4
  %reass.sub = sub i32 %4, %3
  %omp_loop.cmp32.not = icmp eq i32 %reass.sub, -1
  br i1 %omp_loop.cmp32.not, label %omp_loop.exit, label %omp_loop.body.lr.ph

omp_loop.body.lr.ph:                              ; preds = %omp.par.entry
  %.unpack = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  %.unpack3 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  %.unpack4 = load i32, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  %.unpack5 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  %.unpack6 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  %.unpack7 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  %.unpack8 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  %.unpack9.unpack.unpack = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  %.unpack9.unpack.unpack11 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  %.unpack9.unpack.unpack12 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  %loadgep_2.repack16 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  %loadgep_2.repack20 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  %loadgep_2.repack24 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  %loadgep_2.repack26.repack28 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  br label %omp_loop.body

omp_loop.header.omp_loop.exit_crit_edge:          ; preds = %omp_loop.body
  %loadgep_2.repack14 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  %loadgep_2.repack18 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  %loadgep_2.repack22 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  %loadgep_2.repack26 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  %loadgep_2.repack26.repack30 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  store ptr %.unpack, ptr %loadgep_2, align 8, !tbaa !8
  store i64 %.unpack3, ptr %loadgep_2.repack14, align 8, !tbaa !8
  store i32 %.unpack4, ptr %loadgep_2.repack16, align 8, !tbaa !8
  store i8 %.unpack5, ptr %loadgep_2.repack18, align 4, !tbaa !8
  store i8 %.unpack6, ptr %loadgep_2.repack20, align 1, !tbaa !8
  store i8 %.unpack7, ptr %loadgep_2.repack22, align 2, !tbaa !8
  store i8 %.unpack8, ptr %loadgep_2.repack24, align 1, !tbaa !8
  store i64 %.unpack9.unpack.unpack, ptr %loadgep_2.repack26, align 8, !tbaa !8
  store i64 %.unpack9.unpack.unpack11, ptr %loadgep_2.repack26.repack28, align 8, !tbaa !8
  store i64 %.unpack9.unpack.unpack12, ptr %loadgep_2.repack26.repack30, align 8, !tbaa !8
  br label %omp_loop.exit

omp_loop.exit:                                    ; preds = %omp_loop.header.omp_loop.exit_crit_edge, %omp.par.entry
  call void @__kmpc_for_static_fini(ptr nonnull @1, i32 %omp_global_thread_num4)
  call void @__kmpc_barrier(ptr nonnull @2, i32 %omp_global_thread_num4)
  ret void

omp_loop.body:                                    ; preds = %omp_loop.body.lr.ph, %omp_loop.body
  %omp_loop.iv33 = phi i32 [ 0, %omp_loop.body.lr.ph ], [ %5, %omp_loop.body ]
  %5 = add nuw i32 %omp_loop.iv33, 1
  %6 = add i32 %5, %3
  %7 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %8 = sitofp i32 %7 to float
  %9 = fdiv contract float 1.000000e+00, %8
  %10 = fpext float %9 to double
  %11 = sext i32 %6 to i64
  %12 = sub i64 %11, %.unpack9.unpack.unpack
  %13 = getelementptr double, ptr %.unpack, i64 %12
  store double %10, ptr %13, align 8, !tbaa !4
  %exitcond.not = icmp eq i32 %omp_loop.iv33, %reass.sub
  br i1 %exitcond.not, label %omp_loop.header.omp_loop.exit_crit_edge, label %omp_loop.body
}
*** IR Dump After LoopSimplifyPass on _QQmain..omp_par ***
; Function Attrs: norecurse nounwind
define internal void @_QQmain..omp_par(ptr noalias %tid.addr, ptr noalias %zero.addr, ptr %0) #2 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %p.lastiter = alloca i32, align 4
  %p.lowerbound = alloca i32, align 4
  %p.upperbound = alloca i32, align 4
  %p.stride = alloca i32, align 4
  %1 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %omp_loop.tripcount = tail call i32 @llvm.smax.i32(i32 %1, i32 0)
  store i32 0, ptr %p.lowerbound, align 4
  %2 = add nsw i32 %omp_loop.tripcount, -1
  store i32 %2, ptr %p.upperbound, align 4
  store i32 1, ptr %p.stride, align 4
  %omp_global_thread_num4 = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  call void @__kmpc_for_static_init_4u(ptr nonnull @1, i32 %omp_global_thread_num4, i32 34, ptr nonnull %p.lastiter, ptr nonnull %p.lowerbound, ptr nonnull %p.upperbound, ptr nonnull %p.stride, i32 1, i32 0)
  %3 = load i32, ptr %p.lowerbound, align 4
  %4 = load i32, ptr %p.upperbound, align 4
  %reass.sub = sub i32 %4, %3
  %omp_loop.cmp32.not = icmp eq i32 %reass.sub, -1
  br i1 %omp_loop.cmp32.not, label %omp_loop.exit, label %omp_loop.body.lr.ph

omp_loop.body.lr.ph:                              ; preds = %omp.par.entry
  %.unpack = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  %.unpack3 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  %.unpack4 = load i32, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  %.unpack5 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  %.unpack6 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  %.unpack7 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  %.unpack8 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  %.unpack9.unpack.unpack = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  %.unpack9.unpack.unpack11 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  %.unpack9.unpack.unpack12 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  %loadgep_2.repack16 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  %loadgep_2.repack20 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  %loadgep_2.repack24 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  %loadgep_2.repack26.repack28 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  br label %omp_loop.body

omp_loop.header.omp_loop.exit_crit_edge:          ; preds = %omp_loop.body
  %loadgep_2.repack14 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  %loadgep_2.repack18 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  %loadgep_2.repack22 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  %loadgep_2.repack26 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  %loadgep_2.repack26.repack30 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  store ptr %.unpack, ptr %loadgep_2, align 8, !tbaa !8
  store i64 %.unpack3, ptr %loadgep_2.repack14, align 8, !tbaa !8
  store i32 %.unpack4, ptr %loadgep_2.repack16, align 8, !tbaa !8
  store i8 %.unpack5, ptr %loadgep_2.repack18, align 4, !tbaa !8
  store i8 %.unpack6, ptr %loadgep_2.repack20, align 1, !tbaa !8
  store i8 %.unpack7, ptr %loadgep_2.repack22, align 2, !tbaa !8
  store i8 %.unpack8, ptr %loadgep_2.repack24, align 1, !tbaa !8
  store i64 %.unpack9.unpack.unpack, ptr %loadgep_2.repack26, align 8, !tbaa !8
  store i64 %.unpack9.unpack.unpack11, ptr %loadgep_2.repack26.repack28, align 8, !tbaa !8
  store i64 %.unpack9.unpack.unpack12, ptr %loadgep_2.repack26.repack30, align 8, !tbaa !8
  br label %omp_loop.exit

omp_loop.exit:                                    ; preds = %omp_loop.header.omp_loop.exit_crit_edge, %omp.par.entry
  call void @__kmpc_for_static_fini(ptr nonnull @1, i32 %omp_global_thread_num4)
  call void @__kmpc_barrier(ptr nonnull @2, i32 %omp_global_thread_num4)
  ret void

omp_loop.body:                                    ; preds = %omp_loop.body.lr.ph, %omp_loop.body
  %omp_loop.iv33 = phi i32 [ 0, %omp_loop.body.lr.ph ], [ %5, %omp_loop.body ]
  %5 = add nuw i32 %omp_loop.iv33, 1
  %6 = add i32 %5, %3
  %7 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %8 = sitofp i32 %7 to float
  %9 = fdiv contract float 1.000000e+00, %8
  %10 = fpext float %9 to double
  %11 = sext i32 %6 to i64
  %12 = sub i64 %11, %.unpack9.unpack.unpack
  %13 = getelementptr double, ptr %.unpack, i64 %12
  store double %10, ptr %13, align 8, !tbaa !4
  %exitcond.not = icmp eq i32 %omp_loop.iv33, %reass.sub
  br i1 %exitcond.not, label %omp_loop.header.omp_loop.exit_crit_edge, label %omp_loop.body
}
*** IR Dump After LCSSAPass on _QQmain..omp_par ***
; Function Attrs: norecurse nounwind
define internal void @_QQmain..omp_par(ptr noalias %tid.addr, ptr noalias %zero.addr, ptr %0) #2 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %p.lastiter = alloca i32, align 4
  %p.lowerbound = alloca i32, align 4
  %p.upperbound = alloca i32, align 4
  %p.stride = alloca i32, align 4
  %1 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %omp_loop.tripcount = tail call i32 @llvm.smax.i32(i32 %1, i32 0)
  store i32 0, ptr %p.lowerbound, align 4
  %2 = add nsw i32 %omp_loop.tripcount, -1
  store i32 %2, ptr %p.upperbound, align 4
  store i32 1, ptr %p.stride, align 4
  %omp_global_thread_num4 = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  call void @__kmpc_for_static_init_4u(ptr nonnull @1, i32 %omp_global_thread_num4, i32 34, ptr nonnull %p.lastiter, ptr nonnull %p.lowerbound, ptr nonnull %p.upperbound, ptr nonnull %p.stride, i32 1, i32 0)
  %3 = load i32, ptr %p.lowerbound, align 4
  %4 = load i32, ptr %p.upperbound, align 4
  %reass.sub = sub i32 %4, %3
  %omp_loop.cmp32.not = icmp eq i32 %reass.sub, -1
  br i1 %omp_loop.cmp32.not, label %omp_loop.exit, label %omp_loop.body.lr.ph

omp_loop.body.lr.ph:                              ; preds = %omp.par.entry
  %.unpack = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  %.unpack3 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  %.unpack4 = load i32, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  %.unpack5 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  %.unpack6 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  %.unpack7 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  %.unpack8 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  %.unpack9.unpack.unpack = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  %.unpack9.unpack.unpack11 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  %.unpack9.unpack.unpack12 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  %loadgep_2.repack16 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  %loadgep_2.repack20 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  %loadgep_2.repack24 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  %loadgep_2.repack26.repack28 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  br label %omp_loop.body

omp_loop.header.omp_loop.exit_crit_edge:          ; preds = %omp_loop.body
  %loadgep_2.repack14 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  %loadgep_2.repack18 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  %loadgep_2.repack22 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  %loadgep_2.repack26 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  %loadgep_2.repack26.repack30 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  store ptr %.unpack, ptr %loadgep_2, align 8, !tbaa !8
  store i64 %.unpack3, ptr %loadgep_2.repack14, align 8, !tbaa !8
  store i32 %.unpack4, ptr %loadgep_2.repack16, align 8, !tbaa !8
  store i8 %.unpack5, ptr %loadgep_2.repack18, align 4, !tbaa !8
  store i8 %.unpack6, ptr %loadgep_2.repack20, align 1, !tbaa !8
  store i8 %.unpack7, ptr %loadgep_2.repack22, align 2, !tbaa !8
  store i8 %.unpack8, ptr %loadgep_2.repack24, align 1, !tbaa !8
  store i64 %.unpack9.unpack.unpack, ptr %loadgep_2.repack26, align 8, !tbaa !8
  store i64 %.unpack9.unpack.unpack11, ptr %loadgep_2.repack26.repack28, align 8, !tbaa !8
  store i64 %.unpack9.unpack.unpack12, ptr %loadgep_2.repack26.repack30, align 8, !tbaa !8
  br label %omp_loop.exit

omp_loop.exit:                                    ; preds = %omp_loop.header.omp_loop.exit_crit_edge, %omp.par.entry
  call void @__kmpc_for_static_fini(ptr nonnull @1, i32 %omp_global_thread_num4)
  call void @__kmpc_barrier(ptr nonnull @2, i32 %omp_global_thread_num4)
  ret void

omp_loop.body:                                    ; preds = %omp_loop.body.lr.ph, %omp_loop.body
  %omp_loop.iv33 = phi i32 [ 0, %omp_loop.body.lr.ph ], [ %5, %omp_loop.body ]
  %5 = add nuw i32 %omp_loop.iv33, 1
  %6 = add i32 %5, %3
  %7 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %8 = sitofp i32 %7 to float
  %9 = fdiv contract float 1.000000e+00, %8
  %10 = fpext float %9 to double
  %11 = sext i32 %6 to i64
  %12 = sub i64 %11, %.unpack9.unpack.unpack
  %13 = getelementptr double, ptr %.unpack, i64 %12
  store double %10, ptr %13, align 8, !tbaa !4
  %exitcond.not = icmp eq i32 %omp_loop.iv33, %reass.sub
  br i1 %exitcond.not, label %omp_loop.header.omp_loop.exit_crit_edge, label %omp_loop.body
}
*** IR Dump After LICMPass on omp_loop.body ***

; Preheader:
omp_loop.body.lr.ph:                              ; preds = %omp.par.entry
  %.unpack = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  %.unpack3 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  %.unpack4 = load i32, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  %.unpack5 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  %.unpack6 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  %.unpack7 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  %.unpack8 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  %.unpack9.unpack.unpack = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  %.unpack9.unpack.unpack11 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  %.unpack9.unpack.unpack12 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  %loadgep_2.repack16 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  %loadgep_2.repack20 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  %loadgep_2.repack24 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  %loadgep_2.repack26.repack28 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  br label %omp_loop.body

; Loop:
omp_loop.body:                                    ; preds = %omp_loop.body.lr.ph, %omp_loop.body
  %omp_loop.iv33 = phi i32 [ 0, %omp_loop.body.lr.ph ], [ %5, %omp_loop.body ]
  %5 = add nuw i32 %omp_loop.iv33, 1
  %6 = add i32 %5, %3
  %7 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %8 = sitofp i32 %7 to float
  %9 = fdiv contract float 1.000000e+00, %8
  %10 = fpext float %9 to double
  %11 = sext i32 %6 to i64
  %12 = sub i64 %11, %.unpack9.unpack.unpack
  %13 = getelementptr double, ptr %.unpack, i64 %12
  store double %10, ptr %13, align 8, !tbaa !4
  %exitcond.not = icmp eq i32 %omp_loop.iv33, %reass.sub
  br i1 %exitcond.not, label %omp_loop.header.omp_loop.exit_crit_edge, label %omp_loop.body

; Exit blocks
omp_loop.header.omp_loop.exit_crit_edge:          ; preds = %omp_loop.body
  %loadgep_2.repack14 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  %loadgep_2.repack18 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  %loadgep_2.repack22 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  %loadgep_2.repack26 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  %loadgep_2.repack26.repack30 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  store ptr %.unpack, ptr %loadgep_2, align 8, !tbaa !8
  store i64 %.unpack3, ptr %loadgep_2.repack14, align 8, !tbaa !8
  store i32 %.unpack4, ptr %loadgep_2.repack16, align 8, !tbaa !8
  store i8 %.unpack5, ptr %loadgep_2.repack18, align 4, !tbaa !8
  store i8 %.unpack6, ptr %loadgep_2.repack20, align 1, !tbaa !8
  store i8 %.unpack7, ptr %loadgep_2.repack22, align 2, !tbaa !8
  store i8 %.unpack8, ptr %loadgep_2.repack24, align 1, !tbaa !8
  store i64 %.unpack9.unpack.unpack, ptr %loadgep_2.repack26, align 8, !tbaa !8
  store i64 %.unpack9.unpack.unpack11, ptr %loadgep_2.repack26.repack28, align 8, !tbaa !8
  store i64 %.unpack9.unpack.unpack12, ptr %loadgep_2.repack26.repack30, align 8, !tbaa !8
  br label %omp_loop.exit
*** IR Dump After CoroElidePass on _QQmain..omp_par ***
; Function Attrs: norecurse nounwind
define internal void @_QQmain..omp_par(ptr noalias %tid.addr, ptr noalias %zero.addr, ptr %0) #2 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %p.lastiter = alloca i32, align 4
  %p.lowerbound = alloca i32, align 4
  %p.upperbound = alloca i32, align 4
  %p.stride = alloca i32, align 4
  %1 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %omp_loop.tripcount = tail call i32 @llvm.smax.i32(i32 %1, i32 0)
  store i32 0, ptr %p.lowerbound, align 4
  %2 = add nsw i32 %omp_loop.tripcount, -1
  store i32 %2, ptr %p.upperbound, align 4
  store i32 1, ptr %p.stride, align 4
  %omp_global_thread_num4 = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  call void @__kmpc_for_static_init_4u(ptr nonnull @1, i32 %omp_global_thread_num4, i32 34, ptr nonnull %p.lastiter, ptr nonnull %p.lowerbound, ptr nonnull %p.upperbound, ptr nonnull %p.stride, i32 1, i32 0)
  %3 = load i32, ptr %p.lowerbound, align 4
  %4 = load i32, ptr %p.upperbound, align 4
  %reass.sub = sub i32 %4, %3
  %omp_loop.cmp32.not = icmp eq i32 %reass.sub, -1
  br i1 %omp_loop.cmp32.not, label %omp_loop.exit, label %omp_loop.body.lr.ph

omp_loop.body.lr.ph:                              ; preds = %omp.par.entry
  %.unpack = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  %.unpack3 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  %.unpack4 = load i32, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  %.unpack5 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  %.unpack6 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  %.unpack7 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  %.unpack8 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  %.unpack9.unpack.unpack = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  %.unpack9.unpack.unpack11 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  %.unpack9.unpack.unpack12 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  %loadgep_2.repack16 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  %loadgep_2.repack20 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  %loadgep_2.repack24 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  %loadgep_2.repack26.repack28 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  br label %omp_loop.body

omp_loop.header.omp_loop.exit_crit_edge:          ; preds = %omp_loop.body
  %loadgep_2.repack14 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  %loadgep_2.repack18 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  %loadgep_2.repack22 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  %loadgep_2.repack26 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  %loadgep_2.repack26.repack30 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  store ptr %.unpack, ptr %loadgep_2, align 8, !tbaa !8
  store i64 %.unpack3, ptr %loadgep_2.repack14, align 8, !tbaa !8
  store i32 %.unpack4, ptr %loadgep_2.repack16, align 8, !tbaa !8
  store i8 %.unpack5, ptr %loadgep_2.repack18, align 4, !tbaa !8
  store i8 %.unpack6, ptr %loadgep_2.repack20, align 1, !tbaa !8
  store i8 %.unpack7, ptr %loadgep_2.repack22, align 2, !tbaa !8
  store i8 %.unpack8, ptr %loadgep_2.repack24, align 1, !tbaa !8
  store i64 %.unpack9.unpack.unpack, ptr %loadgep_2.repack26, align 8, !tbaa !8
  store i64 %.unpack9.unpack.unpack11, ptr %loadgep_2.repack26.repack28, align 8, !tbaa !8
  store i64 %.unpack9.unpack.unpack12, ptr %loadgep_2.repack26.repack30, align 8, !tbaa !8
  br label %omp_loop.exit

omp_loop.exit:                                    ; preds = %omp_loop.header.omp_loop.exit_crit_edge, %omp.par.entry
  call void @__kmpc_for_static_fini(ptr nonnull @1, i32 %omp_global_thread_num4)
  call void @__kmpc_barrier(ptr nonnull @2, i32 %omp_global_thread_num4)
  ret void

omp_loop.body:                                    ; preds = %omp_loop.body.lr.ph, %omp_loop.body
  %omp_loop.iv33 = phi i32 [ 0, %omp_loop.body.lr.ph ], [ %5, %omp_loop.body ]
  %5 = add nuw i32 %omp_loop.iv33, 1
  %6 = add i32 %5, %3
  %7 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %8 = sitofp i32 %7 to float
  %9 = fdiv contract float 1.000000e+00, %8
  %10 = fpext float %9 to double
  %11 = sext i32 %6 to i64
  %12 = sub i64 %11, %.unpack9.unpack.unpack
  %13 = getelementptr double, ptr %.unpack, i64 %12
  store double %10, ptr %13, align 8, !tbaa !4
  %exitcond.not = icmp eq i32 %omp_loop.iv33, %reass.sub
  br i1 %exitcond.not, label %omp_loop.header.omp_loop.exit_crit_edge, label %omp_loop.body
}
*** IR Dump After SimplifyCFGPass on _QQmain..omp_par ***
; Function Attrs: norecurse nounwind
define internal void @_QQmain..omp_par(ptr noalias %tid.addr, ptr noalias %zero.addr, ptr %0) #2 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %p.lastiter = alloca i32, align 4
  %p.lowerbound = alloca i32, align 4
  %p.upperbound = alloca i32, align 4
  %p.stride = alloca i32, align 4
  %1 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %omp_loop.tripcount = tail call i32 @llvm.smax.i32(i32 %1, i32 0)
  store i32 0, ptr %p.lowerbound, align 4
  %2 = add nsw i32 %omp_loop.tripcount, -1
  store i32 %2, ptr %p.upperbound, align 4
  store i32 1, ptr %p.stride, align 4
  %omp_global_thread_num4 = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  call void @__kmpc_for_static_init_4u(ptr nonnull @1, i32 %omp_global_thread_num4, i32 34, ptr nonnull %p.lastiter, ptr nonnull %p.lowerbound, ptr nonnull %p.upperbound, ptr nonnull %p.stride, i32 1, i32 0)
  %3 = load i32, ptr %p.lowerbound, align 4
  %4 = load i32, ptr %p.upperbound, align 4
  %reass.sub = sub i32 %4, %3
  %omp_loop.cmp32.not = icmp eq i32 %reass.sub, -1
  br i1 %omp_loop.cmp32.not, label %omp_loop.exit, label %omp_loop.body.lr.ph

omp_loop.body.lr.ph:                              ; preds = %omp.par.entry
  %.unpack = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  %.unpack3 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  %.unpack4 = load i32, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  %.unpack5 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  %.unpack6 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  %.unpack7 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  %.unpack8 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  %.unpack9.unpack.unpack = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  %.unpack9.unpack.unpack11 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  %.unpack9.unpack.unpack12 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  %loadgep_2.repack16 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  %loadgep_2.repack20 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  %loadgep_2.repack24 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  %loadgep_2.repack26.repack28 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  br label %omp_loop.body

omp_loop.header.omp_loop.exit_crit_edge:          ; preds = %omp_loop.body
  %loadgep_2.repack14 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  %loadgep_2.repack18 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  %loadgep_2.repack22 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  %loadgep_2.repack26 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  %loadgep_2.repack26.repack30 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  store ptr %.unpack, ptr %loadgep_2, align 8, !tbaa !8
  store i64 %.unpack3, ptr %loadgep_2.repack14, align 8, !tbaa !8
  store i32 %.unpack4, ptr %loadgep_2.repack16, align 8, !tbaa !8
  store i8 %.unpack5, ptr %loadgep_2.repack18, align 4, !tbaa !8
  store i8 %.unpack6, ptr %loadgep_2.repack20, align 1, !tbaa !8
  store i8 %.unpack7, ptr %loadgep_2.repack22, align 2, !tbaa !8
  store i8 %.unpack8, ptr %loadgep_2.repack24, align 1, !tbaa !8
  store i64 %.unpack9.unpack.unpack, ptr %loadgep_2.repack26, align 8, !tbaa !8
  store i64 %.unpack9.unpack.unpack11, ptr %loadgep_2.repack26.repack28, align 8, !tbaa !8
  store i64 %.unpack9.unpack.unpack12, ptr %loadgep_2.repack26.repack30, align 8, !tbaa !8
  br label %omp_loop.exit

omp_loop.exit:                                    ; preds = %omp_loop.header.omp_loop.exit_crit_edge, %omp.par.entry
  call void @__kmpc_for_static_fini(ptr nonnull @1, i32 %omp_global_thread_num4)
  call void @__kmpc_barrier(ptr nonnull @2, i32 %omp_global_thread_num4)
  ret void

omp_loop.body:                                    ; preds = %omp_loop.body.lr.ph, %omp_loop.body
  %omp_loop.iv33 = phi i32 [ 0, %omp_loop.body.lr.ph ], [ %5, %omp_loop.body ]
  %5 = add nuw i32 %omp_loop.iv33, 1
  %6 = add i32 %5, %3
  %7 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %8 = sitofp i32 %7 to float
  %9 = fdiv contract float 1.000000e+00, %8
  %10 = fpext float %9 to double
  %11 = sext i32 %6 to i64
  %12 = sub i64 %11, %.unpack9.unpack.unpack
  %13 = getelementptr double, ptr %.unpack, i64 %12
  store double %10, ptr %13, align 8, !tbaa !4
  %exitcond.not = icmp eq i32 %omp_loop.iv33, %reass.sub
  br i1 %exitcond.not, label %omp_loop.header.omp_loop.exit_crit_edge, label %omp_loop.body
}
*** IR Dump After InstCombinePass on _QQmain..omp_par ***
; Function Attrs: norecurse nounwind
define internal void @_QQmain..omp_par(ptr noalias %tid.addr, ptr noalias %zero.addr, ptr %0) #2 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %p.lastiter = alloca i32, align 4
  %p.lowerbound = alloca i32, align 4
  %p.upperbound = alloca i32, align 4
  %p.stride = alloca i32, align 4
  %1 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %omp_loop.tripcount = tail call i32 @llvm.smax.i32(i32 %1, i32 0)
  store i32 0, ptr %p.lowerbound, align 4
  %2 = add nsw i32 %omp_loop.tripcount, -1
  store i32 %2, ptr %p.upperbound, align 4
  store i32 1, ptr %p.stride, align 4
  %omp_global_thread_num4 = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  call void @__kmpc_for_static_init_4u(ptr nonnull @1, i32 %omp_global_thread_num4, i32 34, ptr nonnull %p.lastiter, ptr nonnull %p.lowerbound, ptr nonnull %p.upperbound, ptr nonnull %p.stride, i32 1, i32 0)
  %3 = load i32, ptr %p.lowerbound, align 4
  %4 = load i32, ptr %p.upperbound, align 4
  %reass.sub = sub i32 %4, %3
  %omp_loop.cmp32.not = icmp eq i32 %reass.sub, -1
  br i1 %omp_loop.cmp32.not, label %omp_loop.exit, label %omp_loop.body.lr.ph

omp_loop.body.lr.ph:                              ; preds = %omp.par.entry
  %.unpack = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  %.unpack3 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  %.unpack4 = load i32, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  %.unpack5 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  %.unpack6 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  %.unpack7 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  %.unpack8 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  %.unpack9.unpack.unpack = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  %.unpack9.unpack.unpack11 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  %.unpack9.unpack.unpack12 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  %loadgep_2.repack16 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  %loadgep_2.repack20 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  %loadgep_2.repack24 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  %loadgep_2.repack26.repack28 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  br label %omp_loop.body

omp_loop.header.omp_loop.exit_crit_edge:          ; preds = %omp_loop.body
  %loadgep_2.repack14 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  %loadgep_2.repack18 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  %loadgep_2.repack22 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  %loadgep_2.repack26 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  %loadgep_2.repack26.repack30 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  store ptr %.unpack, ptr %loadgep_2, align 8, !tbaa !8
  store i64 %.unpack3, ptr %loadgep_2.repack14, align 8, !tbaa !8
  store i32 %.unpack4, ptr %loadgep_2.repack16, align 8, !tbaa !8
  store i8 %.unpack5, ptr %loadgep_2.repack18, align 4, !tbaa !8
  store i8 %.unpack6, ptr %loadgep_2.repack20, align 1, !tbaa !8
  store i8 %.unpack7, ptr %loadgep_2.repack22, align 2, !tbaa !8
  store i8 %.unpack8, ptr %loadgep_2.repack24, align 1, !tbaa !8
  store i64 %.unpack9.unpack.unpack, ptr %loadgep_2.repack26, align 8, !tbaa !8
  store i64 %.unpack9.unpack.unpack11, ptr %loadgep_2.repack26.repack28, align 8, !tbaa !8
  store i64 %.unpack9.unpack.unpack12, ptr %loadgep_2.repack26.repack30, align 8, !tbaa !8
  br label %omp_loop.exit

omp_loop.exit:                                    ; preds = %omp_loop.header.omp_loop.exit_crit_edge, %omp.par.entry
  call void @__kmpc_for_static_fini(ptr nonnull @1, i32 %omp_global_thread_num4)
  call void @__kmpc_barrier(ptr nonnull @2, i32 %omp_global_thread_num4)
  ret void

omp_loop.body:                                    ; preds = %omp_loop.body.lr.ph, %omp_loop.body
  %omp_loop.iv33 = phi i32 [ 0, %omp_loop.body.lr.ph ], [ %5, %omp_loop.body ]
  %5 = add nuw i32 %omp_loop.iv33, 1
  %6 = add i32 %5, %3
  %7 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %8 = sitofp i32 %7 to float
  %9 = fdiv contract float 1.000000e+00, %8
  %10 = fpext float %9 to double
  %11 = sext i32 %6 to i64
  %12 = sub i64 %11, %.unpack9.unpack.unpack
  %13 = getelementptr double, ptr %.unpack, i64 %12
  store double %10, ptr %13, align 8, !tbaa !4
  %exitcond.not = icmp eq i32 %omp_loop.iv33, %reass.sub
  br i1 %exitcond.not, label %omp_loop.header.omp_loop.exit_crit_edge, label %omp_loop.body
}
*** IR Dump After PostOrderFunctionAttrsPass on (_QQmain..omp_par) ***
; Function Attrs: norecurse nounwind
define internal void @_QQmain..omp_par(ptr noalias nocapture readnone %tid.addr, ptr noalias nocapture readnone %zero.addr, ptr nocapture readonly %0) #2 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %p.lastiter = alloca i32, align 4
  %p.lowerbound = alloca i32, align 4
  %p.upperbound = alloca i32, align 4
  %p.stride = alloca i32, align 4
  %1 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %omp_loop.tripcount = tail call i32 @llvm.smax.i32(i32 %1, i32 0)
  store i32 0, ptr %p.lowerbound, align 4
  %2 = add nsw i32 %omp_loop.tripcount, -1
  store i32 %2, ptr %p.upperbound, align 4
  store i32 1, ptr %p.stride, align 4
  %omp_global_thread_num4 = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  call void @__kmpc_for_static_init_4u(ptr nonnull @1, i32 %omp_global_thread_num4, i32 34, ptr nonnull %p.lastiter, ptr nonnull %p.lowerbound, ptr nonnull %p.upperbound, ptr nonnull %p.stride, i32 1, i32 0)
  %3 = load i32, ptr %p.lowerbound, align 4
  %4 = load i32, ptr %p.upperbound, align 4
  %reass.sub = sub i32 %4, %3
  %omp_loop.cmp32.not = icmp eq i32 %reass.sub, -1
  br i1 %omp_loop.cmp32.not, label %omp_loop.exit, label %omp_loop.body.lr.ph

omp_loop.body.lr.ph:                              ; preds = %omp.par.entry
  %.unpack = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  %.unpack3 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  %.unpack4 = load i32, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  %.unpack5 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  %.unpack6 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  %.unpack7 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  %.unpack8 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  %.unpack9.unpack.unpack = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  %.unpack9.unpack.unpack11 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  %.unpack9.unpack.unpack12 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  %loadgep_2.repack16 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  %loadgep_2.repack20 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  %loadgep_2.repack24 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  %loadgep_2.repack26.repack28 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  br label %omp_loop.body

omp_loop.header.omp_loop.exit_crit_edge:          ; preds = %omp_loop.body
  %loadgep_2.repack14 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  %loadgep_2.repack18 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  %loadgep_2.repack22 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  %loadgep_2.repack26 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  %loadgep_2.repack26.repack30 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  store ptr %.unpack, ptr %loadgep_2, align 8, !tbaa !8
  store i64 %.unpack3, ptr %loadgep_2.repack14, align 8, !tbaa !8
  store i32 %.unpack4, ptr %loadgep_2.repack16, align 8, !tbaa !8
  store i8 %.unpack5, ptr %loadgep_2.repack18, align 4, !tbaa !8
  store i8 %.unpack6, ptr %loadgep_2.repack20, align 1, !tbaa !8
  store i8 %.unpack7, ptr %loadgep_2.repack22, align 2, !tbaa !8
  store i8 %.unpack8, ptr %loadgep_2.repack24, align 1, !tbaa !8
  store i64 %.unpack9.unpack.unpack, ptr %loadgep_2.repack26, align 8, !tbaa !8
  store i64 %.unpack9.unpack.unpack11, ptr %loadgep_2.repack26.repack28, align 8, !tbaa !8
  store i64 %.unpack9.unpack.unpack12, ptr %loadgep_2.repack26.repack30, align 8, !tbaa !8
  br label %omp_loop.exit

omp_loop.exit:                                    ; preds = %omp_loop.header.omp_loop.exit_crit_edge, %omp.par.entry
  call void @__kmpc_for_static_fini(ptr nonnull @1, i32 %omp_global_thread_num4)
  call void @__kmpc_barrier(ptr nonnull @2, i32 %omp_global_thread_num4)
  ret void

omp_loop.body:                                    ; preds = %omp_loop.body.lr.ph, %omp_loop.body
  %omp_loop.iv33 = phi i32 [ 0, %omp_loop.body.lr.ph ], [ %5, %omp_loop.body ]
  %5 = add nuw i32 %omp_loop.iv33, 1
  %6 = add i32 %5, %3
  %7 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %8 = sitofp i32 %7 to float
  %9 = fdiv contract float 1.000000e+00, %8
  %10 = fpext float %9 to double
  %11 = sext i32 %6 to i64
  %12 = sub i64 %11, %.unpack9.unpack.unpack
  %13 = getelementptr double, ptr %.unpack, i64 %12
  store double %10, ptr %13, align 8, !tbaa !4
  %exitcond.not = icmp eq i32 %omp_loop.iv33, %reass.sub
  br i1 %exitcond.not, label %omp_loop.header.omp_loop.exit_crit_edge, label %omp_loop.body
}
*** IR Dump After RequireAnalysisPass<llvm::ShouldNotRunFunctionPassesAnalysis, llvm::Function> on _QQmain..omp_par ***
; Function Attrs: norecurse nounwind
define internal void @_QQmain..omp_par(ptr noalias nocapture readnone %tid.addr, ptr noalias nocapture readnone %zero.addr, ptr nocapture readonly %0) #2 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %p.lastiter = alloca i32, align 4
  %p.lowerbound = alloca i32, align 4
  %p.upperbound = alloca i32, align 4
  %p.stride = alloca i32, align 4
  %1 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %omp_loop.tripcount = tail call i32 @llvm.smax.i32(i32 %1, i32 0)
  store i32 0, ptr %p.lowerbound, align 4
  %2 = add nsw i32 %omp_loop.tripcount, -1
  store i32 %2, ptr %p.upperbound, align 4
  store i32 1, ptr %p.stride, align 4
  %omp_global_thread_num4 = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  call void @__kmpc_for_static_init_4u(ptr nonnull @1, i32 %omp_global_thread_num4, i32 34, ptr nonnull %p.lastiter, ptr nonnull %p.lowerbound, ptr nonnull %p.upperbound, ptr nonnull %p.stride, i32 1, i32 0)
  %3 = load i32, ptr %p.lowerbound, align 4
  %4 = load i32, ptr %p.upperbound, align 4
  %reass.sub = sub i32 %4, %3
  %omp_loop.cmp32.not = icmp eq i32 %reass.sub, -1
  br i1 %omp_loop.cmp32.not, label %omp_loop.exit, label %omp_loop.body.lr.ph

omp_loop.body.lr.ph:                              ; preds = %omp.par.entry
  %.unpack = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  %.unpack3 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  %.unpack4 = load i32, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  %.unpack5 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  %.unpack6 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  %.unpack7 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  %.unpack8 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  %.unpack9.unpack.unpack = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  %.unpack9.unpack.unpack11 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  %.unpack9.unpack.unpack12 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  %loadgep_2.repack16 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  %loadgep_2.repack20 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  %loadgep_2.repack24 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  %loadgep_2.repack26.repack28 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  br label %omp_loop.body

omp_loop.header.omp_loop.exit_crit_edge:          ; preds = %omp_loop.body
  %loadgep_2.repack14 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  %loadgep_2.repack18 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  %loadgep_2.repack22 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  %loadgep_2.repack26 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  %loadgep_2.repack26.repack30 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  store ptr %.unpack, ptr %loadgep_2, align 8, !tbaa !8
  store i64 %.unpack3, ptr %loadgep_2.repack14, align 8, !tbaa !8
  store i32 %.unpack4, ptr %loadgep_2.repack16, align 8, !tbaa !8
  store i8 %.unpack5, ptr %loadgep_2.repack18, align 4, !tbaa !8
  store i8 %.unpack6, ptr %loadgep_2.repack20, align 1, !tbaa !8
  store i8 %.unpack7, ptr %loadgep_2.repack22, align 2, !tbaa !8
  store i8 %.unpack8, ptr %loadgep_2.repack24, align 1, !tbaa !8
  store i64 %.unpack9.unpack.unpack, ptr %loadgep_2.repack26, align 8, !tbaa !8
  store i64 %.unpack9.unpack.unpack11, ptr %loadgep_2.repack26.repack28, align 8, !tbaa !8
  store i64 %.unpack9.unpack.unpack12, ptr %loadgep_2.repack26.repack30, align 8, !tbaa !8
  br label %omp_loop.exit

omp_loop.exit:                                    ; preds = %omp_loop.header.omp_loop.exit_crit_edge, %omp.par.entry
  call void @__kmpc_for_static_fini(ptr nonnull @1, i32 %omp_global_thread_num4)
  call void @__kmpc_barrier(ptr nonnull @2, i32 %omp_global_thread_num4)
  ret void

omp_loop.body:                                    ; preds = %omp_loop.body.lr.ph, %omp_loop.body
  %omp_loop.iv33 = phi i32 [ 0, %omp_loop.body.lr.ph ], [ %5, %omp_loop.body ]
  %5 = add nuw i32 %omp_loop.iv33, 1
  %6 = add i32 %5, %3
  %7 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %8 = sitofp i32 %7 to float
  %9 = fdiv contract float 1.000000e+00, %8
  %10 = fpext float %9 to double
  %11 = sext i32 %6 to i64
  %12 = sub i64 %11, %.unpack9.unpack.unpack
  %13 = getelementptr double, ptr %.unpack, i64 %12
  store double %10, ptr %13, align 8, !tbaa !4
  %exitcond.not = icmp eq i32 %omp_loop.iv33, %reass.sub
  br i1 %exitcond.not, label %omp_loop.header.omp_loop.exit_crit_edge, label %omp_loop.body
}
*** IR Dump After CoroSplitPass on (_QQmain..omp_par) ***
; Function Attrs: norecurse nounwind
define internal void @_QQmain..omp_par(ptr noalias nocapture readnone %tid.addr, ptr noalias nocapture readnone %zero.addr, ptr nocapture readonly %0) #2 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %p.lastiter = alloca i32, align 4
  %p.lowerbound = alloca i32, align 4
  %p.upperbound = alloca i32, align 4
  %p.stride = alloca i32, align 4
  %1 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %omp_loop.tripcount = tail call i32 @llvm.smax.i32(i32 %1, i32 0)
  store i32 0, ptr %p.lowerbound, align 4
  %2 = add nsw i32 %omp_loop.tripcount, -1
  store i32 %2, ptr %p.upperbound, align 4
  store i32 1, ptr %p.stride, align 4
  %omp_global_thread_num4 = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  call void @__kmpc_for_static_init_4u(ptr nonnull @1, i32 %omp_global_thread_num4, i32 34, ptr nonnull %p.lastiter, ptr nonnull %p.lowerbound, ptr nonnull %p.upperbound, ptr nonnull %p.stride, i32 1, i32 0)
  %3 = load i32, ptr %p.lowerbound, align 4
  %4 = load i32, ptr %p.upperbound, align 4
  %reass.sub = sub i32 %4, %3
  %omp_loop.cmp32.not = icmp eq i32 %reass.sub, -1
  br i1 %omp_loop.cmp32.not, label %omp_loop.exit, label %omp_loop.body.lr.ph

omp_loop.body.lr.ph:                              ; preds = %omp.par.entry
  %.unpack = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  %.unpack3 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  %.unpack4 = load i32, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  %.unpack5 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  %.unpack6 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  %.unpack7 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  %.unpack8 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  %.unpack9.unpack.unpack = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  %.unpack9.unpack.unpack11 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  %.unpack9.unpack.unpack12 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  %loadgep_2.repack16 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  %loadgep_2.repack20 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  %loadgep_2.repack24 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  %loadgep_2.repack26.repack28 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  br label %omp_loop.body

omp_loop.header.omp_loop.exit_crit_edge:          ; preds = %omp_loop.body
  %loadgep_2.repack14 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  %loadgep_2.repack18 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  %loadgep_2.repack22 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  %loadgep_2.repack26 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  %loadgep_2.repack26.repack30 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  store ptr %.unpack, ptr %loadgep_2, align 8, !tbaa !8
  store i64 %.unpack3, ptr %loadgep_2.repack14, align 8, !tbaa !8
  store i32 %.unpack4, ptr %loadgep_2.repack16, align 8, !tbaa !8
  store i8 %.unpack5, ptr %loadgep_2.repack18, align 4, !tbaa !8
  store i8 %.unpack6, ptr %loadgep_2.repack20, align 1, !tbaa !8
  store i8 %.unpack7, ptr %loadgep_2.repack22, align 2, !tbaa !8
  store i8 %.unpack8, ptr %loadgep_2.repack24, align 1, !tbaa !8
  store i64 %.unpack9.unpack.unpack, ptr %loadgep_2.repack26, align 8, !tbaa !8
  store i64 %.unpack9.unpack.unpack11, ptr %loadgep_2.repack26.repack28, align 8, !tbaa !8
  store i64 %.unpack9.unpack.unpack12, ptr %loadgep_2.repack26.repack30, align 8, !tbaa !8
  br label %omp_loop.exit

omp_loop.exit:                                    ; preds = %omp_loop.header.omp_loop.exit_crit_edge, %omp.par.entry
  call void @__kmpc_for_static_fini(ptr nonnull @1, i32 %omp_global_thread_num4)
  call void @__kmpc_barrier(ptr nonnull @2, i32 %omp_global_thread_num4)
  ret void

omp_loop.body:                                    ; preds = %omp_loop.body.lr.ph, %omp_loop.body
  %omp_loop.iv33 = phi i32 [ 0, %omp_loop.body.lr.ph ], [ %5, %omp_loop.body ]
  %5 = add nuw i32 %omp_loop.iv33, 1
  %6 = add i32 %5, %3
  %7 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %8 = sitofp i32 %7 to float
  %9 = fdiv contract float 1.000000e+00, %8
  %10 = fpext float %9 to double
  %11 = sext i32 %6 to i64
  %12 = sub i64 %11, %.unpack9.unpack.unpack
  %13 = getelementptr double, ptr %.unpack, i64 %12
  store double %10, ptr %13, align 8, !tbaa !4
  %exitcond.not = icmp eq i32 %omp_loop.iv33, %reass.sub
  br i1 %exitcond.not, label %omp_loop.header.omp_loop.exit_crit_edge, label %omp_loop.body
}
*** IR Dump After InlinerPass on (_QQmain) ***
define void @_QQmain() local_unnamed_addr {
entry:
  %structArg = alloca { ptr, ptr }, align 8
  %0 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %1 = alloca i32, align 4
  store i32 1048576, ptr %1, align 4, !tbaa !4
  %2 = call dereferenceable_or_null(8388608) ptr @malloc(i64 8388608)
  store ptr %2, ptr @_QFEarr, align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  store i32 20180515, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  store i8 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  store i8 28, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  store i8 2, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  store i8 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  store i64 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  store i64 1048576, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  %omp_global_thread_num = call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %1, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %0, ptr %gep_5, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QQmain..omp_par, ptr nonnull %structArg)
  %3 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.68815510185ede6107d6524e77abf791, i32 19)
  %4 = call i1 @_FortranAioOutputAscii(ptr %3, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %5 = load i32, ptr %1, align 4, !tbaa !4
  %6 = call i1 @_FortranAioOutputInteger32(ptr %3, i32 %5)
  %7 = call i1 @_FortranAioOutputAscii(ptr %3, ptr nonnull @_QQcl.2920697320, i64 5)
  %.unpack = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  %.unpack95.unpack.unpack = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  %8 = sub i64 1, %.unpack95.unpack.unpack
  %9 = getelementptr double, ptr %.unpack, i64 %8
  %10 = load double, ptr %9, align 8, !tbaa !4
  %11 = load i32, ptr %1, align 4, !tbaa !4
  %12 = sext i32 %11 to i64
  %13 = sub i64 %12, %.unpack95.unpack.unpack
  %14 = getelementptr double, ptr %.unpack, i64 %13
  %15 = load double, ptr %14, align 8, !tbaa !4
  %16 = fadd contract double %10, %15
  %17 = call i1 @_FortranAioOutputReal64(ptr %3, double %16)
  %18 = call i32 @_FortranAioEndIoStatement(ptr %3)
  %.unpack100 = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  call void @free(ptr %.unpack100)
  store ptr null, ptr @_QFEarr, align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  store i32 20180515, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  store i8 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  store i8 28, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  store i8 2, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  store i8 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  store i64 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  store i64 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  ret void
}
*** IR Dump After InlinerPass on (_QQmain) ***
define void @_QQmain() local_unnamed_addr {
entry:
  %structArg = alloca { ptr, ptr }, align 8
  %0 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %1 = alloca i32, align 4
  store i32 1048576, ptr %1, align 4, !tbaa !4
  %2 = call dereferenceable_or_null(8388608) ptr @malloc(i64 8388608)
  store ptr %2, ptr @_QFEarr, align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  store i32 20180515, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  store i8 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  store i8 28, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  store i8 2, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  store i8 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  store i64 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  store i64 1048576, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  %omp_global_thread_num = call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %1, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %0, ptr %gep_5, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QQmain..omp_par, ptr nonnull %structArg)
  %3 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.68815510185ede6107d6524e77abf791, i32 19)
  %4 = call i1 @_FortranAioOutputAscii(ptr %3, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %5 = load i32, ptr %1, align 4, !tbaa !4
  %6 = call i1 @_FortranAioOutputInteger32(ptr %3, i32 %5)
  %7 = call i1 @_FortranAioOutputAscii(ptr %3, ptr nonnull @_QQcl.2920697320, i64 5)
  %.unpack = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  %.unpack95.unpack.unpack = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  %8 = sub i64 1, %.unpack95.unpack.unpack
  %9 = getelementptr double, ptr %.unpack, i64 %8
  %10 = load double, ptr %9, align 8, !tbaa !4
  %11 = load i32, ptr %1, align 4, !tbaa !4
  %12 = sext i32 %11 to i64
  %13 = sub i64 %12, %.unpack95.unpack.unpack
  %14 = getelementptr double, ptr %.unpack, i64 %13
  %15 = load double, ptr %14, align 8, !tbaa !4
  %16 = fadd contract double %10, %15
  %17 = call i1 @_FortranAioOutputReal64(ptr %3, double %16)
  %18 = call i32 @_FortranAioEndIoStatement(ptr %3)
  %.unpack100 = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  call void @free(ptr %.unpack100)
  store ptr null, ptr @_QFEarr, align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  store i32 20180515, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  store i8 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  store i8 28, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  store i8 2, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  store i8 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  store i64 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  store i64 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  ret void
}
*** IR Dump After PostOrderFunctionAttrsPass on (_QQmain) ***
define void @_QQmain() local_unnamed_addr {
entry:
  %structArg = alloca { ptr, ptr }, align 8
  %0 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %1 = alloca i32, align 4
  store i32 1048576, ptr %1, align 4, !tbaa !4
  %2 = call dereferenceable_or_null(8388608) ptr @malloc(i64 8388608)
  store ptr %2, ptr @_QFEarr, align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  store i32 20180515, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  store i8 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  store i8 28, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  store i8 2, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  store i8 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  store i64 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  store i64 1048576, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  %omp_global_thread_num = call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %1, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %0, ptr %gep_5, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QQmain..omp_par, ptr nonnull %structArg)
  %3 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.68815510185ede6107d6524e77abf791, i32 19)
  %4 = call i1 @_FortranAioOutputAscii(ptr %3, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %5 = load i32, ptr %1, align 4, !tbaa !4
  %6 = call i1 @_FortranAioOutputInteger32(ptr %3, i32 %5)
  %7 = call i1 @_FortranAioOutputAscii(ptr %3, ptr nonnull @_QQcl.2920697320, i64 5)
  %.unpack = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  %.unpack95.unpack.unpack = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  %8 = sub i64 1, %.unpack95.unpack.unpack
  %9 = getelementptr double, ptr %.unpack, i64 %8
  %10 = load double, ptr %9, align 8, !tbaa !4
  %11 = load i32, ptr %1, align 4, !tbaa !4
  %12 = sext i32 %11 to i64
  %13 = sub i64 %12, %.unpack95.unpack.unpack
  %14 = getelementptr double, ptr %.unpack, i64 %13
  %15 = load double, ptr %14, align 8, !tbaa !4
  %16 = fadd contract double %10, %15
  %17 = call i1 @_FortranAioOutputReal64(ptr %3, double %16)
  %18 = call i32 @_FortranAioEndIoStatement(ptr %3)
  %.unpack100 = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  call void @free(ptr %.unpack100)
  store ptr null, ptr @_QFEarr, align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  store i32 20180515, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  store i8 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  store i8 28, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  store i8 2, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  store i8 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  store i64 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  store i64 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  ret void
}
*** IR Dump After ArgumentPromotionPass on (_QQmain) ***
define void @_QQmain() local_unnamed_addr {
entry:
  %structArg = alloca { ptr, ptr }, align 8
  %0 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %1 = alloca i32, align 4
  store i32 1048576, ptr %1, align 4, !tbaa !4
  %2 = call dereferenceable_or_null(8388608) ptr @malloc(i64 8388608)
  store ptr %2, ptr @_QFEarr, align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  store i32 20180515, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  store i8 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  store i8 28, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  store i8 2, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  store i8 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  store i64 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  store i64 1048576, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  %omp_global_thread_num = call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %1, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %0, ptr %gep_5, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QQmain..omp_par, ptr nonnull %structArg)
  %3 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.68815510185ede6107d6524e77abf791, i32 19)
  %4 = call i1 @_FortranAioOutputAscii(ptr %3, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %5 = load i32, ptr %1, align 4, !tbaa !4
  %6 = call i1 @_FortranAioOutputInteger32(ptr %3, i32 %5)
  %7 = call i1 @_FortranAioOutputAscii(ptr %3, ptr nonnull @_QQcl.2920697320, i64 5)
  %.unpack = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  %.unpack95.unpack.unpack = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  %8 = sub i64 1, %.unpack95.unpack.unpack
  %9 = getelementptr double, ptr %.unpack, i64 %8
  %10 = load double, ptr %9, align 8, !tbaa !4
  %11 = load i32, ptr %1, align 4, !tbaa !4
  %12 = sext i32 %11 to i64
  %13 = sub i64 %12, %.unpack95.unpack.unpack
  %14 = getelementptr double, ptr %.unpack, i64 %13
  %15 = load double, ptr %14, align 8, !tbaa !4
  %16 = fadd contract double %10, %15
  %17 = call i1 @_FortranAioOutputReal64(ptr %3, double %16)
  %18 = call i32 @_FortranAioEndIoStatement(ptr %3)
  %.unpack100 = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  call void @free(ptr %.unpack100)
  store ptr null, ptr @_QFEarr, align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  store i32 20180515, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  store i8 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  store i8 28, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  store i8 2, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  store i8 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  store i64 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  store i64 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  ret void
}
*** IR Dump After OpenMPOptCGSCCPass on (_QQmain) ***
define void @_QQmain() local_unnamed_addr {
entry:
  %structArg = alloca { ptr, ptr }, align 8
  %0 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %1 = alloca i32, align 4
  store i32 1048576, ptr %1, align 4, !tbaa !4
  %2 = call dereferenceable_or_null(8388608) ptr @malloc(i64 8388608)
  store ptr %2, ptr @_QFEarr, align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  store i32 20180515, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  store i8 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  store i8 28, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  store i8 2, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  store i8 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  store i64 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  store i64 1048576, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  %omp_global_thread_num = call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %1, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %0, ptr %gep_5, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QQmain..omp_par, ptr nonnull %structArg)
  %3 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.68815510185ede6107d6524e77abf791, i32 19)
  %4 = call i1 @_FortranAioOutputAscii(ptr %3, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %5 = load i32, ptr %1, align 4, !tbaa !4
  %6 = call i1 @_FortranAioOutputInteger32(ptr %3, i32 %5)
  %7 = call i1 @_FortranAioOutputAscii(ptr %3, ptr nonnull @_QQcl.2920697320, i64 5)
  %.unpack = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  %.unpack95.unpack.unpack = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  %8 = sub i64 1, %.unpack95.unpack.unpack
  %9 = getelementptr double, ptr %.unpack, i64 %8
  %10 = load double, ptr %9, align 8, !tbaa !4
  %11 = load i32, ptr %1, align 4, !tbaa !4
  %12 = sext i32 %11 to i64
  %13 = sub i64 %12, %.unpack95.unpack.unpack
  %14 = getelementptr double, ptr %.unpack, i64 %13
  %15 = load double, ptr %14, align 8, !tbaa !4
  %16 = fadd contract double %10, %15
  %17 = call i1 @_FortranAioOutputReal64(ptr %3, double %16)
  %18 = call i32 @_FortranAioEndIoStatement(ptr %3)
  %.unpack100 = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  call void @free(ptr %.unpack100)
  store ptr null, ptr @_QFEarr, align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  store i32 20180515, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  store i8 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  store i8 28, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  store i8 2, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  store i8 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  store i64 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  store i64 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  ret void
}
*** IR Dump After SROAPass on _QQmain ***
define void @_QQmain() local_unnamed_addr {
entry:
  %structArg = alloca { ptr, ptr }, align 8
  %0 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %1 = alloca i32, align 4
  store i32 1048576, ptr %1, align 4, !tbaa !4
  %2 = call dereferenceable_or_null(8388608) ptr @malloc(i64 8388608)
  store ptr %2, ptr @_QFEarr, align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  store i32 20180515, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  store i8 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  store i8 28, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  store i8 2, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  store i8 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  store i64 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  store i64 1048576, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  %omp_global_thread_num = call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %1, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %0, ptr %gep_5, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QQmain..omp_par, ptr nonnull %structArg)
  %3 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.68815510185ede6107d6524e77abf791, i32 19)
  %4 = call i1 @_FortranAioOutputAscii(ptr %3, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %5 = load i32, ptr %1, align 4, !tbaa !4
  %6 = call i1 @_FortranAioOutputInteger32(ptr %3, i32 %5)
  %7 = call i1 @_FortranAioOutputAscii(ptr %3, ptr nonnull @_QQcl.2920697320, i64 5)
  %.unpack = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  %.unpack95.unpack.unpack = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  %8 = sub i64 1, %.unpack95.unpack.unpack
  %9 = getelementptr double, ptr %.unpack, i64 %8
  %10 = load double, ptr %9, align 8, !tbaa !4
  %11 = load i32, ptr %1, align 4, !tbaa !4
  %12 = sext i32 %11 to i64
  %13 = sub i64 %12, %.unpack95.unpack.unpack
  %14 = getelementptr double, ptr %.unpack, i64 %13
  %15 = load double, ptr %14, align 8, !tbaa !4
  %16 = fadd contract double %10, %15
  %17 = call i1 @_FortranAioOutputReal64(ptr %3, double %16)
  %18 = call i32 @_FortranAioEndIoStatement(ptr %3)
  %.unpack100 = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  call void @free(ptr %.unpack100)
  store ptr null, ptr @_QFEarr, align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  store i32 20180515, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  store i8 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  store i8 28, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  store i8 2, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  store i8 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  store i64 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  store i64 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  ret void
}
*** IR Dump After EarlyCSEPass on _QQmain ***
define void @_QQmain() local_unnamed_addr {
entry:
  %structArg = alloca { ptr, ptr }, align 8
  %0 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %1 = alloca i32, align 4
  store i32 1048576, ptr %1, align 4, !tbaa !4
  %2 = call dereferenceable_or_null(8388608) ptr @malloc(i64 8388608)
  store ptr %2, ptr @_QFEarr, align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  store i32 20180515, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  store i8 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  store i8 28, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  store i8 2, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  store i8 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  store i64 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  store i64 1048576, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  %omp_global_thread_num = call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %1, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %0, ptr %gep_5, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QQmain..omp_par, ptr nonnull %structArg)
  %3 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.68815510185ede6107d6524e77abf791, i32 19)
  %4 = call i1 @_FortranAioOutputAscii(ptr %3, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %5 = load i32, ptr %1, align 4, !tbaa !4
  %6 = call i1 @_FortranAioOutputInteger32(ptr %3, i32 %5)
  %7 = call i1 @_FortranAioOutputAscii(ptr %3, ptr nonnull @_QQcl.2920697320, i64 5)
  %.unpack = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  %.unpack95.unpack.unpack = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  %8 = sub i64 1, %.unpack95.unpack.unpack
  %9 = getelementptr double, ptr %.unpack, i64 %8
  %10 = load double, ptr %9, align 8, !tbaa !4
  %11 = load i32, ptr %1, align 4, !tbaa !4
  %12 = sext i32 %11 to i64
  %13 = sub i64 %12, %.unpack95.unpack.unpack
  %14 = getelementptr double, ptr %.unpack, i64 %13
  %15 = load double, ptr %14, align 8, !tbaa !4
  %16 = fadd contract double %10, %15
  %17 = call i1 @_FortranAioOutputReal64(ptr %3, double %16)
  %18 = call i32 @_FortranAioEndIoStatement(ptr %3)
  %.unpack100 = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  call void @free(ptr %.unpack100)
  store ptr null, ptr @_QFEarr, align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  store i32 20180515, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  store i8 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  store i8 28, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  store i8 2, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  store i8 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  store i64 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  store i64 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  ret void
}
*** IR Dump After SpeculativeExecutionPass on _QQmain ***
define void @_QQmain() local_unnamed_addr {
entry:
  %structArg = alloca { ptr, ptr }, align 8
  %0 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %1 = alloca i32, align 4
  store i32 1048576, ptr %1, align 4, !tbaa !4
  %2 = call dereferenceable_or_null(8388608) ptr @malloc(i64 8388608)
  store ptr %2, ptr @_QFEarr, align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  store i32 20180515, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  store i8 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  store i8 28, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  store i8 2, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  store i8 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  store i64 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  store i64 1048576, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  %omp_global_thread_num = call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %1, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %0, ptr %gep_5, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QQmain..omp_par, ptr nonnull %structArg)
  %3 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.68815510185ede6107d6524e77abf791, i32 19)
  %4 = call i1 @_FortranAioOutputAscii(ptr %3, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %5 = load i32, ptr %1, align 4, !tbaa !4
  %6 = call i1 @_FortranAioOutputInteger32(ptr %3, i32 %5)
  %7 = call i1 @_FortranAioOutputAscii(ptr %3, ptr nonnull @_QQcl.2920697320, i64 5)
  %.unpack = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  %.unpack95.unpack.unpack = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  %8 = sub i64 1, %.unpack95.unpack.unpack
  %9 = getelementptr double, ptr %.unpack, i64 %8
  %10 = load double, ptr %9, align 8, !tbaa !4
  %11 = load i32, ptr %1, align 4, !tbaa !4
  %12 = sext i32 %11 to i64
  %13 = sub i64 %12, %.unpack95.unpack.unpack
  %14 = getelementptr double, ptr %.unpack, i64 %13
  %15 = load double, ptr %14, align 8, !tbaa !4
  %16 = fadd contract double %10, %15
  %17 = call i1 @_FortranAioOutputReal64(ptr %3, double %16)
  %18 = call i32 @_FortranAioEndIoStatement(ptr %3)
  %.unpack100 = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  call void @free(ptr %.unpack100)
  store ptr null, ptr @_QFEarr, align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  store i32 20180515, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  store i8 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  store i8 28, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  store i8 2, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  store i8 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  store i64 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  store i64 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  ret void
}
*** IR Dump After JumpThreadingPass on _QQmain ***
define void @_QQmain() local_unnamed_addr {
entry:
  %structArg = alloca { ptr, ptr }, align 8
  %0 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %1 = alloca i32, align 4
  store i32 1048576, ptr %1, align 4, !tbaa !4
  %2 = call dereferenceable_or_null(8388608) ptr @malloc(i64 8388608)
  store ptr %2, ptr @_QFEarr, align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  store i32 20180515, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  store i8 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  store i8 28, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  store i8 2, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  store i8 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  store i64 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  store i64 1048576, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  %omp_global_thread_num = call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %1, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %0, ptr %gep_5, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QQmain..omp_par, ptr nonnull %structArg)
  %3 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.68815510185ede6107d6524e77abf791, i32 19)
  %4 = call i1 @_FortranAioOutputAscii(ptr %3, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %5 = load i32, ptr %1, align 4, !tbaa !4
  %6 = call i1 @_FortranAioOutputInteger32(ptr %3, i32 %5)
  %7 = call i1 @_FortranAioOutputAscii(ptr %3, ptr nonnull @_QQcl.2920697320, i64 5)
  %.unpack = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  %.unpack95.unpack.unpack = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  %8 = sub i64 1, %.unpack95.unpack.unpack
  %9 = getelementptr double, ptr %.unpack, i64 %8
  %10 = load double, ptr %9, align 8, !tbaa !4
  %11 = load i32, ptr %1, align 4, !tbaa !4
  %12 = sext i32 %11 to i64
  %13 = sub i64 %12, %.unpack95.unpack.unpack
  %14 = getelementptr double, ptr %.unpack, i64 %13
  %15 = load double, ptr %14, align 8, !tbaa !4
  %16 = fadd contract double %10, %15
  %17 = call i1 @_FortranAioOutputReal64(ptr %3, double %16)
  %18 = call i32 @_FortranAioEndIoStatement(ptr %3)
  %.unpack100 = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  call void @free(ptr %.unpack100)
  store ptr null, ptr @_QFEarr, align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  store i32 20180515, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  store i8 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  store i8 28, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  store i8 2, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  store i8 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  store i64 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  store i64 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  ret void
}
*** IR Dump After CorrelatedValuePropagationPass on _QQmain ***
define void @_QQmain() local_unnamed_addr {
entry:
  %structArg = alloca { ptr, ptr }, align 8
  %0 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %1 = alloca i32, align 4
  store i32 1048576, ptr %1, align 4, !tbaa !4
  %2 = call dereferenceable_or_null(8388608) ptr @malloc(i64 8388608)
  store ptr %2, ptr @_QFEarr, align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  store i32 20180515, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  store i8 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  store i8 28, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  store i8 2, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  store i8 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  store i64 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  store i64 1048576, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  %omp_global_thread_num = call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %1, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %0, ptr %gep_5, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QQmain..omp_par, ptr nonnull %structArg)
  %3 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.68815510185ede6107d6524e77abf791, i32 19)
  %4 = call i1 @_FortranAioOutputAscii(ptr %3, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %5 = load i32, ptr %1, align 4, !tbaa !4
  %6 = call i1 @_FortranAioOutputInteger32(ptr %3, i32 %5)
  %7 = call i1 @_FortranAioOutputAscii(ptr %3, ptr nonnull @_QQcl.2920697320, i64 5)
  %.unpack = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  %.unpack95.unpack.unpack = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  %8 = sub i64 1, %.unpack95.unpack.unpack
  %9 = getelementptr double, ptr %.unpack, i64 %8
  %10 = load double, ptr %9, align 8, !tbaa !4
  %11 = load i32, ptr %1, align 4, !tbaa !4
  %12 = sext i32 %11 to i64
  %13 = sub i64 %12, %.unpack95.unpack.unpack
  %14 = getelementptr double, ptr %.unpack, i64 %13
  %15 = load double, ptr %14, align 8, !tbaa !4
  %16 = fadd contract double %10, %15
  %17 = call i1 @_FortranAioOutputReal64(ptr %3, double %16)
  %18 = call i32 @_FortranAioEndIoStatement(ptr %3)
  %.unpack100 = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  call void @free(ptr %.unpack100)
  store ptr null, ptr @_QFEarr, align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  store i32 20180515, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  store i8 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  store i8 28, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  store i8 2, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  store i8 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  store i64 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  store i64 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  ret void
}
*** IR Dump After SimplifyCFGPass on _QQmain ***
define void @_QQmain() local_unnamed_addr {
entry:
  %structArg = alloca { ptr, ptr }, align 8
  %0 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %1 = alloca i32, align 4
  store i32 1048576, ptr %1, align 4, !tbaa !4
  %2 = call dereferenceable_or_null(8388608) ptr @malloc(i64 8388608)
  store ptr %2, ptr @_QFEarr, align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  store i32 20180515, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  store i8 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  store i8 28, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  store i8 2, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  store i8 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  store i64 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  store i64 1048576, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  %omp_global_thread_num = call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %1, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %0, ptr %gep_5, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QQmain..omp_par, ptr nonnull %structArg)
  %3 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.68815510185ede6107d6524e77abf791, i32 19)
  %4 = call i1 @_FortranAioOutputAscii(ptr %3, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %5 = load i32, ptr %1, align 4, !tbaa !4
  %6 = call i1 @_FortranAioOutputInteger32(ptr %3, i32 %5)
  %7 = call i1 @_FortranAioOutputAscii(ptr %3, ptr nonnull @_QQcl.2920697320, i64 5)
  %.unpack = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  %.unpack95.unpack.unpack = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  %8 = sub i64 1, %.unpack95.unpack.unpack
  %9 = getelementptr double, ptr %.unpack, i64 %8
  %10 = load double, ptr %9, align 8, !tbaa !4
  %11 = load i32, ptr %1, align 4, !tbaa !4
  %12 = sext i32 %11 to i64
  %13 = sub i64 %12, %.unpack95.unpack.unpack
  %14 = getelementptr double, ptr %.unpack, i64 %13
  %15 = load double, ptr %14, align 8, !tbaa !4
  %16 = fadd contract double %10, %15
  %17 = call i1 @_FortranAioOutputReal64(ptr %3, double %16)
  %18 = call i32 @_FortranAioEndIoStatement(ptr %3)
  %.unpack100 = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  call void @free(ptr %.unpack100)
  store ptr null, ptr @_QFEarr, align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  store i32 20180515, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  store i8 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  store i8 28, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  store i8 2, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  store i8 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  store i64 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  store i64 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  ret void
}
*** IR Dump After InstCombinePass on _QQmain ***
define void @_QQmain() local_unnamed_addr {
entry:
  %structArg = alloca { ptr, ptr }, align 8
  %0 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %1 = alloca i32, align 4
  store i32 1048576, ptr %1, align 4, !tbaa !4
  %2 = call dereferenceable_or_null(8388608) ptr @malloc(i64 8388608)
  store ptr %2, ptr @_QFEarr, align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  store i32 20180515, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  store i8 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  store i8 28, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  store i8 2, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  store i8 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  store i64 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  store i64 1048576, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  %omp_global_thread_num = call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %1, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %0, ptr %gep_5, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QQmain..omp_par, ptr nonnull %structArg)
  %3 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.68815510185ede6107d6524e77abf791, i32 19)
  %4 = call i1 @_FortranAioOutputAscii(ptr %3, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %5 = load i32, ptr %1, align 4, !tbaa !4
  %6 = call i1 @_FortranAioOutputInteger32(ptr %3, i32 %5)
  %7 = call i1 @_FortranAioOutputAscii(ptr %3, ptr nonnull @_QQcl.2920697320, i64 5)
  %.unpack = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  %.unpack95.unpack.unpack = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  %8 = sub i64 1, %.unpack95.unpack.unpack
  %9 = getelementptr double, ptr %.unpack, i64 %8
  %10 = load double, ptr %9, align 8, !tbaa !4
  %11 = load i32, ptr %1, align 4, !tbaa !4
  %12 = sext i32 %11 to i64
  %13 = sub i64 %12, %.unpack95.unpack.unpack
  %14 = getelementptr double, ptr %.unpack, i64 %13
  %15 = load double, ptr %14, align 8, !tbaa !4
  %16 = fadd contract double %10, %15
  %17 = call i1 @_FortranAioOutputReal64(ptr %3, double %16)
  %18 = call i32 @_FortranAioEndIoStatement(ptr %3)
  %.unpack100 = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  call void @free(ptr %.unpack100)
  store ptr null, ptr @_QFEarr, align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  store i32 20180515, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  store i8 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  store i8 28, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  store i8 2, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  store i8 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  store i64 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  store i64 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  ret void
}
*** IR Dump After AggressiveInstCombinePass on _QQmain ***
define void @_QQmain() local_unnamed_addr {
entry:
  %structArg = alloca { ptr, ptr }, align 8
  %0 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %1 = alloca i32, align 4
  store i32 1048576, ptr %1, align 4, !tbaa !4
  %2 = call dereferenceable_or_null(8388608) ptr @malloc(i64 8388608)
  store ptr %2, ptr @_QFEarr, align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  store i32 20180515, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  store i8 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  store i8 28, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  store i8 2, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  store i8 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  store i64 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  store i64 1048576, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  %omp_global_thread_num = call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %1, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %0, ptr %gep_5, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QQmain..omp_par, ptr nonnull %structArg)
  %3 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.68815510185ede6107d6524e77abf791, i32 19)
  %4 = call i1 @_FortranAioOutputAscii(ptr %3, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %5 = load i32, ptr %1, align 4, !tbaa !4
  %6 = call i1 @_FortranAioOutputInteger32(ptr %3, i32 %5)
  %7 = call i1 @_FortranAioOutputAscii(ptr %3, ptr nonnull @_QQcl.2920697320, i64 5)
  %.unpack = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  %.unpack95.unpack.unpack = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  %8 = sub i64 1, %.unpack95.unpack.unpack
  %9 = getelementptr double, ptr %.unpack, i64 %8
  %10 = load double, ptr %9, align 8, !tbaa !4
  %11 = load i32, ptr %1, align 4, !tbaa !4
  %12 = sext i32 %11 to i64
  %13 = sub i64 %12, %.unpack95.unpack.unpack
  %14 = getelementptr double, ptr %.unpack, i64 %13
  %15 = load double, ptr %14, align 8, !tbaa !4
  %16 = fadd contract double %10, %15
  %17 = call i1 @_FortranAioOutputReal64(ptr %3, double %16)
  %18 = call i32 @_FortranAioEndIoStatement(ptr %3)
  %.unpack100 = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  call void @free(ptr %.unpack100)
  store ptr null, ptr @_QFEarr, align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  store i32 20180515, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  store i8 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  store i8 28, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  store i8 2, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  store i8 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  store i64 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  store i64 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  ret void
}
*** IR Dump After ConstraintEliminationPass on _QQmain ***
define void @_QQmain() local_unnamed_addr {
entry:
  %structArg = alloca { ptr, ptr }, align 8
  %0 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %1 = alloca i32, align 4
  store i32 1048576, ptr %1, align 4, !tbaa !4
  %2 = call dereferenceable_or_null(8388608) ptr @malloc(i64 8388608)
  store ptr %2, ptr @_QFEarr, align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  store i32 20180515, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  store i8 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  store i8 28, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  store i8 2, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  store i8 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  store i64 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  store i64 1048576, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  %omp_global_thread_num = call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %1, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %0, ptr %gep_5, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QQmain..omp_par, ptr nonnull %structArg)
  %3 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.68815510185ede6107d6524e77abf791, i32 19)
  %4 = call i1 @_FortranAioOutputAscii(ptr %3, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %5 = load i32, ptr %1, align 4, !tbaa !4
  %6 = call i1 @_FortranAioOutputInteger32(ptr %3, i32 %5)
  %7 = call i1 @_FortranAioOutputAscii(ptr %3, ptr nonnull @_QQcl.2920697320, i64 5)
  %.unpack = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  %.unpack95.unpack.unpack = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  %8 = sub i64 1, %.unpack95.unpack.unpack
  %9 = getelementptr double, ptr %.unpack, i64 %8
  %10 = load double, ptr %9, align 8, !tbaa !4
  %11 = load i32, ptr %1, align 4, !tbaa !4
  %12 = sext i32 %11 to i64
  %13 = sub i64 %12, %.unpack95.unpack.unpack
  %14 = getelementptr double, ptr %.unpack, i64 %13
  %15 = load double, ptr %14, align 8, !tbaa !4
  %16 = fadd contract double %10, %15
  %17 = call i1 @_FortranAioOutputReal64(ptr %3, double %16)
  %18 = call i32 @_FortranAioEndIoStatement(ptr %3)
  %.unpack100 = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  call void @free(ptr %.unpack100)
  store ptr null, ptr @_QFEarr, align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  store i32 20180515, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  store i8 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  store i8 28, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  store i8 2, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  store i8 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  store i64 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  store i64 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  ret void
}
*** IR Dump After LibCallsShrinkWrapPass on _QQmain ***
define void @_QQmain() local_unnamed_addr {
entry:
  %structArg = alloca { ptr, ptr }, align 8
  %0 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %1 = alloca i32, align 4
  store i32 1048576, ptr %1, align 4, !tbaa !4
  %2 = call dereferenceable_or_null(8388608) ptr @malloc(i64 8388608)
  store ptr %2, ptr @_QFEarr, align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  store i32 20180515, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  store i8 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  store i8 28, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  store i8 2, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  store i8 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  store i64 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  store i64 1048576, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  %omp_global_thread_num = call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %1, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %0, ptr %gep_5, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QQmain..omp_par, ptr nonnull %structArg)
  %3 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.68815510185ede6107d6524e77abf791, i32 19)
  %4 = call i1 @_FortranAioOutputAscii(ptr %3, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %5 = load i32, ptr %1, align 4, !tbaa !4
  %6 = call i1 @_FortranAioOutputInteger32(ptr %3, i32 %5)
  %7 = call i1 @_FortranAioOutputAscii(ptr %3, ptr nonnull @_QQcl.2920697320, i64 5)
  %.unpack = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  %.unpack95.unpack.unpack = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  %8 = sub i64 1, %.unpack95.unpack.unpack
  %9 = getelementptr double, ptr %.unpack, i64 %8
  %10 = load double, ptr %9, align 8, !tbaa !4
  %11 = load i32, ptr %1, align 4, !tbaa !4
  %12 = sext i32 %11 to i64
  %13 = sub i64 %12, %.unpack95.unpack.unpack
  %14 = getelementptr double, ptr %.unpack, i64 %13
  %15 = load double, ptr %14, align 8, !tbaa !4
  %16 = fadd contract double %10, %15
  %17 = call i1 @_FortranAioOutputReal64(ptr %3, double %16)
  %18 = call i32 @_FortranAioEndIoStatement(ptr %3)
  %.unpack100 = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  call void @free(ptr %.unpack100)
  store ptr null, ptr @_QFEarr, align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  store i32 20180515, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  store i8 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  store i8 28, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  store i8 2, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  store i8 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  store i64 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  store i64 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  ret void
}
*** IR Dump After TailCallElimPass on _QQmain ***
define void @_QQmain() local_unnamed_addr {
entry:
  %structArg = alloca { ptr, ptr }, align 8
  %0 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %1 = alloca i32, align 4
  store i32 1048576, ptr %1, align 4, !tbaa !4
  %2 = tail call dereferenceable_or_null(8388608) ptr @malloc(i64 8388608)
  store ptr %2, ptr @_QFEarr, align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  store i32 20180515, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  store i8 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  store i8 28, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  store i8 2, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  store i8 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  store i64 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  store i64 1048576, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  %omp_global_thread_num = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %1, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %0, ptr %gep_5, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QQmain..omp_par, ptr nonnull %structArg)
  %3 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.68815510185ede6107d6524e77abf791, i32 19)
  %4 = call i1 @_FortranAioOutputAscii(ptr %3, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %5 = load i32, ptr %1, align 4, !tbaa !4
  %6 = call i1 @_FortranAioOutputInteger32(ptr %3, i32 %5)
  %7 = call i1 @_FortranAioOutputAscii(ptr %3, ptr nonnull @_QQcl.2920697320, i64 5)
  %.unpack = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  %.unpack95.unpack.unpack = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  %8 = sub i64 1, %.unpack95.unpack.unpack
  %9 = getelementptr double, ptr %.unpack, i64 %8
  %10 = load double, ptr %9, align 8, !tbaa !4
  %11 = load i32, ptr %1, align 4, !tbaa !4
  %12 = sext i32 %11 to i64
  %13 = sub i64 %12, %.unpack95.unpack.unpack
  %14 = getelementptr double, ptr %.unpack, i64 %13
  %15 = load double, ptr %14, align 8, !tbaa !4
  %16 = fadd contract double %10, %15
  %17 = call i1 @_FortranAioOutputReal64(ptr %3, double %16)
  %18 = call i32 @_FortranAioEndIoStatement(ptr %3)
  %.unpack100 = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  call void @free(ptr %.unpack100)
  store ptr null, ptr @_QFEarr, align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  store i32 20180515, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  store i8 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  store i8 28, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  store i8 2, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  store i8 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  store i64 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  store i64 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  ret void
}
*** IR Dump After SimplifyCFGPass on _QQmain ***
define void @_QQmain() local_unnamed_addr {
entry:
  %structArg = alloca { ptr, ptr }, align 8
  %0 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %1 = alloca i32, align 4
  store i32 1048576, ptr %1, align 4, !tbaa !4
  %2 = tail call dereferenceable_or_null(8388608) ptr @malloc(i64 8388608)
  store ptr %2, ptr @_QFEarr, align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  store i32 20180515, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  store i8 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  store i8 28, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  store i8 2, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  store i8 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  store i64 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  store i64 1048576, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  %omp_global_thread_num = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %1, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %0, ptr %gep_5, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QQmain..omp_par, ptr nonnull %structArg)
  %3 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.68815510185ede6107d6524e77abf791, i32 19)
  %4 = call i1 @_FortranAioOutputAscii(ptr %3, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %5 = load i32, ptr %1, align 4, !tbaa !4
  %6 = call i1 @_FortranAioOutputInteger32(ptr %3, i32 %5)
  %7 = call i1 @_FortranAioOutputAscii(ptr %3, ptr nonnull @_QQcl.2920697320, i64 5)
  %.unpack = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  %.unpack95.unpack.unpack = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  %8 = sub i64 1, %.unpack95.unpack.unpack
  %9 = getelementptr double, ptr %.unpack, i64 %8
  %10 = load double, ptr %9, align 8, !tbaa !4
  %11 = load i32, ptr %1, align 4, !tbaa !4
  %12 = sext i32 %11 to i64
  %13 = sub i64 %12, %.unpack95.unpack.unpack
  %14 = getelementptr double, ptr %.unpack, i64 %13
  %15 = load double, ptr %14, align 8, !tbaa !4
  %16 = fadd contract double %10, %15
  %17 = call i1 @_FortranAioOutputReal64(ptr %3, double %16)
  %18 = call i32 @_FortranAioEndIoStatement(ptr %3)
  %.unpack100 = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  call void @free(ptr %.unpack100)
  store ptr null, ptr @_QFEarr, align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  store i32 20180515, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  store i8 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  store i8 28, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  store i8 2, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  store i8 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  store i64 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  store i64 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  ret void
}
*** IR Dump After ReassociatePass on _QQmain ***
define void @_QQmain() local_unnamed_addr {
entry:
  %structArg = alloca { ptr, ptr }, align 8
  %0 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %1 = alloca i32, align 4
  store i32 1048576, ptr %1, align 4, !tbaa !4
  %2 = tail call dereferenceable_or_null(8388608) ptr @malloc(i64 8388608)
  store ptr %2, ptr @_QFEarr, align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  store i32 20180515, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  store i8 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  store i8 28, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  store i8 2, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  store i8 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  store i64 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  store i64 1048576, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  %omp_global_thread_num = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %1, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %0, ptr %gep_5, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QQmain..omp_par, ptr nonnull %structArg)
  %3 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.68815510185ede6107d6524e77abf791, i32 19)
  %4 = call i1 @_FortranAioOutputAscii(ptr %3, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %5 = load i32, ptr %1, align 4, !tbaa !4
  %6 = call i1 @_FortranAioOutputInteger32(ptr %3, i32 %5)
  %7 = call i1 @_FortranAioOutputAscii(ptr %3, ptr nonnull @_QQcl.2920697320, i64 5)
  %.unpack = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  %.unpack95.unpack.unpack = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  %8 = sub i64 1, %.unpack95.unpack.unpack
  %9 = getelementptr double, ptr %.unpack, i64 %8
  %10 = load double, ptr %9, align 8, !tbaa !4
  %11 = load i32, ptr %1, align 4, !tbaa !4
  %12 = sext i32 %11 to i64
  %13 = sub i64 %12, %.unpack95.unpack.unpack
  %14 = getelementptr double, ptr %.unpack, i64 %13
  %15 = load double, ptr %14, align 8, !tbaa !4
  %16 = fadd contract double %10, %15
  %17 = call i1 @_FortranAioOutputReal64(ptr %3, double %16)
  %18 = call i32 @_FortranAioEndIoStatement(ptr %3)
  %.unpack100 = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  call void @free(ptr %.unpack100)
  store ptr null, ptr @_QFEarr, align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  store i32 20180515, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  store i8 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  store i8 28, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  store i8 2, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  store i8 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  store i64 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  store i64 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  ret void
}
*** IR Dump After LoopSimplifyPass on _QQmain ***
define void @_QQmain() local_unnamed_addr {
entry:
  %structArg = alloca { ptr, ptr }, align 8
  %0 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %1 = alloca i32, align 4
  store i32 1048576, ptr %1, align 4, !tbaa !4
  %2 = tail call dereferenceable_or_null(8388608) ptr @malloc(i64 8388608)
  store ptr %2, ptr @_QFEarr, align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  store i32 20180515, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  store i8 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  store i8 28, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  store i8 2, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  store i8 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  store i64 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  store i64 1048576, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  %omp_global_thread_num = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %1, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %0, ptr %gep_5, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QQmain..omp_par, ptr nonnull %structArg)
  %3 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.68815510185ede6107d6524e77abf791, i32 19)
  %4 = call i1 @_FortranAioOutputAscii(ptr %3, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %5 = load i32, ptr %1, align 4, !tbaa !4
  %6 = call i1 @_FortranAioOutputInteger32(ptr %3, i32 %5)
  %7 = call i1 @_FortranAioOutputAscii(ptr %3, ptr nonnull @_QQcl.2920697320, i64 5)
  %.unpack = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  %.unpack95.unpack.unpack = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  %8 = sub i64 1, %.unpack95.unpack.unpack
  %9 = getelementptr double, ptr %.unpack, i64 %8
  %10 = load double, ptr %9, align 8, !tbaa !4
  %11 = load i32, ptr %1, align 4, !tbaa !4
  %12 = sext i32 %11 to i64
  %13 = sub i64 %12, %.unpack95.unpack.unpack
  %14 = getelementptr double, ptr %.unpack, i64 %13
  %15 = load double, ptr %14, align 8, !tbaa !4
  %16 = fadd contract double %10, %15
  %17 = call i1 @_FortranAioOutputReal64(ptr %3, double %16)
  %18 = call i32 @_FortranAioEndIoStatement(ptr %3)
  %.unpack100 = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  call void @free(ptr %.unpack100)
  store ptr null, ptr @_QFEarr, align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  store i32 20180515, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  store i8 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  store i8 28, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  store i8 2, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  store i8 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  store i64 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  store i64 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  ret void
}
*** IR Dump After LCSSAPass on _QQmain ***
define void @_QQmain() local_unnamed_addr {
entry:
  %structArg = alloca { ptr, ptr }, align 8
  %0 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %1 = alloca i32, align 4
  store i32 1048576, ptr %1, align 4, !tbaa !4
  %2 = tail call dereferenceable_or_null(8388608) ptr @malloc(i64 8388608)
  store ptr %2, ptr @_QFEarr, align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  store i32 20180515, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  store i8 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  store i8 28, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  store i8 2, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  store i8 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  store i64 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  store i64 1048576, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  %omp_global_thread_num = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %1, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %0, ptr %gep_5, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QQmain..omp_par, ptr nonnull %structArg)
  %3 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.68815510185ede6107d6524e77abf791, i32 19)
  %4 = call i1 @_FortranAioOutputAscii(ptr %3, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %5 = load i32, ptr %1, align 4, !tbaa !4
  %6 = call i1 @_FortranAioOutputInteger32(ptr %3, i32 %5)
  %7 = call i1 @_FortranAioOutputAscii(ptr %3, ptr nonnull @_QQcl.2920697320, i64 5)
  %.unpack = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  %.unpack95.unpack.unpack = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  %8 = sub i64 1, %.unpack95.unpack.unpack
  %9 = getelementptr double, ptr %.unpack, i64 %8
  %10 = load double, ptr %9, align 8, !tbaa !4
  %11 = load i32, ptr %1, align 4, !tbaa !4
  %12 = sext i32 %11 to i64
  %13 = sub i64 %12, %.unpack95.unpack.unpack
  %14 = getelementptr double, ptr %.unpack, i64 %13
  %15 = load double, ptr %14, align 8, !tbaa !4
  %16 = fadd contract double %10, %15
  %17 = call i1 @_FortranAioOutputReal64(ptr %3, double %16)
  %18 = call i32 @_FortranAioEndIoStatement(ptr %3)
  %.unpack100 = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  call void @free(ptr %.unpack100)
  store ptr null, ptr @_QFEarr, align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  store i32 20180515, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  store i8 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  store i8 28, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  store i8 2, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  store i8 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  store i64 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  store i64 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  ret void
}
*** IR Dump After SimplifyCFGPass on _QQmain ***
define void @_QQmain() local_unnamed_addr {
entry:
  %structArg = alloca { ptr, ptr }, align 8
  %0 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %1 = alloca i32, align 4
  store i32 1048576, ptr %1, align 4, !tbaa !4
  %2 = tail call dereferenceable_or_null(8388608) ptr @malloc(i64 8388608)
  store ptr %2, ptr @_QFEarr, align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  store i32 20180515, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  store i8 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  store i8 28, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  store i8 2, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  store i8 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  store i64 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  store i64 1048576, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  %omp_global_thread_num = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %1, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %0, ptr %gep_5, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QQmain..omp_par, ptr nonnull %structArg)
  %3 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.68815510185ede6107d6524e77abf791, i32 19)
  %4 = call i1 @_FortranAioOutputAscii(ptr %3, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %5 = load i32, ptr %1, align 4, !tbaa !4
  %6 = call i1 @_FortranAioOutputInteger32(ptr %3, i32 %5)
  %7 = call i1 @_FortranAioOutputAscii(ptr %3, ptr nonnull @_QQcl.2920697320, i64 5)
  %.unpack = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  %.unpack95.unpack.unpack = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  %8 = sub i64 1, %.unpack95.unpack.unpack
  %9 = getelementptr double, ptr %.unpack, i64 %8
  %10 = load double, ptr %9, align 8, !tbaa !4
  %11 = load i32, ptr %1, align 4, !tbaa !4
  %12 = sext i32 %11 to i64
  %13 = sub i64 %12, %.unpack95.unpack.unpack
  %14 = getelementptr double, ptr %.unpack, i64 %13
  %15 = load double, ptr %14, align 8, !tbaa !4
  %16 = fadd contract double %10, %15
  %17 = call i1 @_FortranAioOutputReal64(ptr %3, double %16)
  %18 = call i32 @_FortranAioEndIoStatement(ptr %3)
  %.unpack100 = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  call void @free(ptr %.unpack100)
  store ptr null, ptr @_QFEarr, align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  store i32 20180515, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  store i8 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  store i8 28, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  store i8 2, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  store i8 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  store i64 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  store i64 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  ret void
}
*** IR Dump After InstCombinePass on _QQmain ***
define void @_QQmain() local_unnamed_addr {
entry:
  %structArg = alloca { ptr, ptr }, align 8
  %0 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %1 = alloca i32, align 4
  store i32 1048576, ptr %1, align 4, !tbaa !4
  %2 = tail call dereferenceable_or_null(8388608) ptr @malloc(i64 8388608)
  store ptr %2, ptr @_QFEarr, align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  store i32 20180515, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  store i8 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  store i8 28, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  store i8 2, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  store i8 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  store i64 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  store i64 1048576, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  %omp_global_thread_num = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %1, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %0, ptr %gep_5, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QQmain..omp_par, ptr nonnull %structArg)
  %3 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.68815510185ede6107d6524e77abf791, i32 19)
  %4 = call i1 @_FortranAioOutputAscii(ptr %3, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %5 = load i32, ptr %1, align 4, !tbaa !4
  %6 = call i1 @_FortranAioOutputInteger32(ptr %3, i32 %5)
  %7 = call i1 @_FortranAioOutputAscii(ptr %3, ptr nonnull @_QQcl.2920697320, i64 5)
  %.unpack = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  %.unpack95.unpack.unpack = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  %8 = sub i64 1, %.unpack95.unpack.unpack
  %9 = getelementptr double, ptr %.unpack, i64 %8
  %10 = load double, ptr %9, align 8, !tbaa !4
  %11 = load i32, ptr %1, align 4, !tbaa !4
  %12 = sext i32 %11 to i64
  %13 = sub i64 %12, %.unpack95.unpack.unpack
  %14 = getelementptr double, ptr %.unpack, i64 %13
  %15 = load double, ptr %14, align 8, !tbaa !4
  %16 = fadd contract double %10, %15
  %17 = call i1 @_FortranAioOutputReal64(ptr %3, double %16)
  %18 = call i32 @_FortranAioEndIoStatement(ptr %3)
  %.unpack100 = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  call void @free(ptr %.unpack100)
  store ptr null, ptr @_QFEarr, align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  store i32 20180515, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  store i8 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  store i8 28, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  store i8 2, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  store i8 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  store i64 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  store i64 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  ret void
}
*** IR Dump After LoopSimplifyPass on _QQmain ***
define void @_QQmain() local_unnamed_addr {
entry:
  %structArg = alloca { ptr, ptr }, align 8
  %0 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %1 = alloca i32, align 4
  store i32 1048576, ptr %1, align 4, !tbaa !4
  %2 = tail call dereferenceable_or_null(8388608) ptr @malloc(i64 8388608)
  store ptr %2, ptr @_QFEarr, align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  store i32 20180515, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  store i8 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  store i8 28, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  store i8 2, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  store i8 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  store i64 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  store i64 1048576, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  %omp_global_thread_num = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %1, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %0, ptr %gep_5, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QQmain..omp_par, ptr nonnull %structArg)
  %3 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.68815510185ede6107d6524e77abf791, i32 19)
  %4 = call i1 @_FortranAioOutputAscii(ptr %3, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %5 = load i32, ptr %1, align 4, !tbaa !4
  %6 = call i1 @_FortranAioOutputInteger32(ptr %3, i32 %5)
  %7 = call i1 @_FortranAioOutputAscii(ptr %3, ptr nonnull @_QQcl.2920697320, i64 5)
  %.unpack = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  %.unpack95.unpack.unpack = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  %8 = sub i64 1, %.unpack95.unpack.unpack
  %9 = getelementptr double, ptr %.unpack, i64 %8
  %10 = load double, ptr %9, align 8, !tbaa !4
  %11 = load i32, ptr %1, align 4, !tbaa !4
  %12 = sext i32 %11 to i64
  %13 = sub i64 %12, %.unpack95.unpack.unpack
  %14 = getelementptr double, ptr %.unpack, i64 %13
  %15 = load double, ptr %14, align 8, !tbaa !4
  %16 = fadd contract double %10, %15
  %17 = call i1 @_FortranAioOutputReal64(ptr %3, double %16)
  %18 = call i32 @_FortranAioEndIoStatement(ptr %3)
  %.unpack100 = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  call void @free(ptr %.unpack100)
  store ptr null, ptr @_QFEarr, align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  store i32 20180515, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  store i8 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  store i8 28, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  store i8 2, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  store i8 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  store i64 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  store i64 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  ret void
}
*** IR Dump After LCSSAPass on _QQmain ***
define void @_QQmain() local_unnamed_addr {
entry:
  %structArg = alloca { ptr, ptr }, align 8
  %0 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %1 = alloca i32, align 4
  store i32 1048576, ptr %1, align 4, !tbaa !4
  %2 = tail call dereferenceable_or_null(8388608) ptr @malloc(i64 8388608)
  store ptr %2, ptr @_QFEarr, align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  store i32 20180515, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  store i8 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  store i8 28, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  store i8 2, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  store i8 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  store i64 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  store i64 1048576, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  %omp_global_thread_num = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %1, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %0, ptr %gep_5, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QQmain..omp_par, ptr nonnull %structArg)
  %3 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.68815510185ede6107d6524e77abf791, i32 19)
  %4 = call i1 @_FortranAioOutputAscii(ptr %3, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %5 = load i32, ptr %1, align 4, !tbaa !4
  %6 = call i1 @_FortranAioOutputInteger32(ptr %3, i32 %5)
  %7 = call i1 @_FortranAioOutputAscii(ptr %3, ptr nonnull @_QQcl.2920697320, i64 5)
  %.unpack = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  %.unpack95.unpack.unpack = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  %8 = sub i64 1, %.unpack95.unpack.unpack
  %9 = getelementptr double, ptr %.unpack, i64 %8
  %10 = load double, ptr %9, align 8, !tbaa !4
  %11 = load i32, ptr %1, align 4, !tbaa !4
  %12 = sext i32 %11 to i64
  %13 = sub i64 %12, %.unpack95.unpack.unpack
  %14 = getelementptr double, ptr %.unpack, i64 %13
  %15 = load double, ptr %14, align 8, !tbaa !4
  %16 = fadd contract double %10, %15
  %17 = call i1 @_FortranAioOutputReal64(ptr %3, double %16)
  %18 = call i32 @_FortranAioEndIoStatement(ptr %3)
  %.unpack100 = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  call void @free(ptr %.unpack100)
  store ptr null, ptr @_QFEarr, align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  store i32 20180515, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  store i8 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  store i8 28, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  store i8 2, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  store i8 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  store i64 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  store i64 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  ret void
}
*** IR Dump After SROAPass on _QQmain ***
define void @_QQmain() local_unnamed_addr {
entry:
  %structArg = alloca { ptr, ptr }, align 8
  %0 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %1 = alloca i32, align 4
  store i32 1048576, ptr %1, align 4, !tbaa !4
  %2 = tail call dereferenceable_or_null(8388608) ptr @malloc(i64 8388608)
  store ptr %2, ptr @_QFEarr, align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  store i32 20180515, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  store i8 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  store i8 28, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  store i8 2, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  store i8 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  store i64 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  store i64 1048576, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  %omp_global_thread_num = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %1, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %0, ptr %gep_5, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QQmain..omp_par, ptr nonnull %structArg)
  %3 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.68815510185ede6107d6524e77abf791, i32 19)
  %4 = call i1 @_FortranAioOutputAscii(ptr %3, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %5 = load i32, ptr %1, align 4, !tbaa !4
  %6 = call i1 @_FortranAioOutputInteger32(ptr %3, i32 %5)
  %7 = call i1 @_FortranAioOutputAscii(ptr %3, ptr nonnull @_QQcl.2920697320, i64 5)
  %.unpack = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  %.unpack95.unpack.unpack = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  %8 = sub i64 1, %.unpack95.unpack.unpack
  %9 = getelementptr double, ptr %.unpack, i64 %8
  %10 = load double, ptr %9, align 8, !tbaa !4
  %11 = load i32, ptr %1, align 4, !tbaa !4
  %12 = sext i32 %11 to i64
  %13 = sub i64 %12, %.unpack95.unpack.unpack
  %14 = getelementptr double, ptr %.unpack, i64 %13
  %15 = load double, ptr %14, align 8, !tbaa !4
  %16 = fadd contract double %10, %15
  %17 = call i1 @_FortranAioOutputReal64(ptr %3, double %16)
  %18 = call i32 @_FortranAioEndIoStatement(ptr %3)
  %.unpack100 = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  call void @free(ptr %.unpack100)
  store ptr null, ptr @_QFEarr, align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  store i32 20180515, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  store i8 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  store i8 28, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  store i8 2, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  store i8 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  store i64 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  store i64 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  ret void
}
*** IR Dump After VectorCombinePass on _QQmain ***
define void @_QQmain() local_unnamed_addr {
entry:
  %structArg = alloca { ptr, ptr }, align 8
  %0 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %1 = alloca i32, align 4
  store i32 1048576, ptr %1, align 4, !tbaa !4
  %2 = tail call dereferenceable_or_null(8388608) ptr @malloc(i64 8388608)
  store ptr %2, ptr @_QFEarr, align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  store i32 20180515, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  store i8 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  store i8 28, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  store i8 2, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  store i8 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  store i64 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  store i64 1048576, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  %omp_global_thread_num = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %1, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %0, ptr %gep_5, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QQmain..omp_par, ptr nonnull %structArg)
  %3 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.68815510185ede6107d6524e77abf791, i32 19)
  %4 = call i1 @_FortranAioOutputAscii(ptr %3, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %5 = load i32, ptr %1, align 4, !tbaa !4
  %6 = call i1 @_FortranAioOutputInteger32(ptr %3, i32 %5)
  %7 = call i1 @_FortranAioOutputAscii(ptr %3, ptr nonnull @_QQcl.2920697320, i64 5)
  %.unpack = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  %.unpack95.unpack.unpack = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  %8 = sub i64 1, %.unpack95.unpack.unpack
  %9 = getelementptr double, ptr %.unpack, i64 %8
  %10 = load double, ptr %9, align 8, !tbaa !4
  %11 = load i32, ptr %1, align 4, !tbaa !4
  %12 = sext i32 %11 to i64
  %13 = sub i64 %12, %.unpack95.unpack.unpack
  %14 = getelementptr double, ptr %.unpack, i64 %13
  %15 = load double, ptr %14, align 8, !tbaa !4
  %16 = fadd contract double %10, %15
  %17 = call i1 @_FortranAioOutputReal64(ptr %3, double %16)
  %18 = call i32 @_FortranAioEndIoStatement(ptr %3)
  %.unpack100 = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  call void @free(ptr %.unpack100)
  store ptr null, ptr @_QFEarr, align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  store i32 20180515, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  store i8 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  store i8 28, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  store i8 2, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  store i8 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  store i64 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  store i64 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  ret void
}
*** IR Dump After MergedLoadStoreMotionPass on _QQmain ***
define void @_QQmain() local_unnamed_addr {
entry:
  %structArg = alloca { ptr, ptr }, align 8
  %0 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %1 = alloca i32, align 4
  store i32 1048576, ptr %1, align 4, !tbaa !4
  %2 = tail call dereferenceable_or_null(8388608) ptr @malloc(i64 8388608)
  store ptr %2, ptr @_QFEarr, align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  store i32 20180515, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  store i8 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  store i8 28, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  store i8 2, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  store i8 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  store i64 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  store i64 1048576, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  %omp_global_thread_num = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %1, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %0, ptr %gep_5, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QQmain..omp_par, ptr nonnull %structArg)
  %3 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.68815510185ede6107d6524e77abf791, i32 19)
  %4 = call i1 @_FortranAioOutputAscii(ptr %3, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %5 = load i32, ptr %1, align 4, !tbaa !4
  %6 = call i1 @_FortranAioOutputInteger32(ptr %3, i32 %5)
  %7 = call i1 @_FortranAioOutputAscii(ptr %3, ptr nonnull @_QQcl.2920697320, i64 5)
  %.unpack = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  %.unpack95.unpack.unpack = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  %8 = sub i64 1, %.unpack95.unpack.unpack
  %9 = getelementptr double, ptr %.unpack, i64 %8
  %10 = load double, ptr %9, align 8, !tbaa !4
  %11 = load i32, ptr %1, align 4, !tbaa !4
  %12 = sext i32 %11 to i64
  %13 = sub i64 %12, %.unpack95.unpack.unpack
  %14 = getelementptr double, ptr %.unpack, i64 %13
  %15 = load double, ptr %14, align 8, !tbaa !4
  %16 = fadd contract double %10, %15
  %17 = call i1 @_FortranAioOutputReal64(ptr %3, double %16)
  %18 = call i32 @_FortranAioEndIoStatement(ptr %3)
  %.unpack100 = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  call void @free(ptr %.unpack100)
  store ptr null, ptr @_QFEarr, align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  store i32 20180515, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  store i8 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  store i8 28, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  store i8 2, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  store i8 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  store i64 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  store i64 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  ret void
}
*** IR Dump After GVNPass on _QQmain ***
define void @_QQmain() local_unnamed_addr {
entry:
  %structArg = alloca { ptr, ptr }, align 8
  %0 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %1 = alloca i32, align 4
  store i32 1048576, ptr %1, align 4, !tbaa !4
  %2 = tail call dereferenceable_or_null(8388608) ptr @malloc(i64 8388608)
  store ptr %2, ptr @_QFEarr, align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  store i32 20180515, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  store i8 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  store i8 28, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  store i8 2, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  store i8 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  store i64 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  store i64 1048576, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  %omp_global_thread_num = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %1, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %0, ptr %gep_5, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QQmain..omp_par, ptr nonnull %structArg)
  %3 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.68815510185ede6107d6524e77abf791, i32 19)
  %4 = call i1 @_FortranAioOutputAscii(ptr %3, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %5 = load i32, ptr %1, align 4, !tbaa !4
  %6 = call i1 @_FortranAioOutputInteger32(ptr %3, i32 %5)
  %7 = call i1 @_FortranAioOutputAscii(ptr %3, ptr nonnull @_QQcl.2920697320, i64 5)
  %.unpack = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  %.unpack95.unpack.unpack = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  %8 = sub i64 1, %.unpack95.unpack.unpack
  %9 = getelementptr double, ptr %.unpack, i64 %8
  %10 = load double, ptr %9, align 8, !tbaa !4
  %11 = load i32, ptr %1, align 4, !tbaa !4
  %12 = sext i32 %11 to i64
  %13 = sub i64 %12, %.unpack95.unpack.unpack
  %14 = getelementptr double, ptr %.unpack, i64 %13
  %15 = load double, ptr %14, align 8, !tbaa !4
  %16 = fadd contract double %10, %15
  %17 = call i1 @_FortranAioOutputReal64(ptr %3, double %16)
  %18 = call i32 @_FortranAioEndIoStatement(ptr %3)
  %.unpack100 = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  call void @free(ptr %.unpack100)
  store ptr null, ptr @_QFEarr, align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  store i32 20180515, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  store i8 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  store i8 28, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  store i8 2, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  store i8 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  store i64 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  store i64 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  ret void
}
*** IR Dump After SCCPPass on _QQmain ***
define void @_QQmain() local_unnamed_addr {
entry:
  %structArg = alloca { ptr, ptr }, align 8
  %0 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %1 = alloca i32, align 4
  store i32 1048576, ptr %1, align 4, !tbaa !4
  %2 = tail call dereferenceable_or_null(8388608) ptr @malloc(i64 8388608)
  store ptr %2, ptr @_QFEarr, align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  store i32 20180515, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  store i8 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  store i8 28, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  store i8 2, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  store i8 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  store i64 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  store i64 1048576, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  %omp_global_thread_num = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %1, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %0, ptr %gep_5, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QQmain..omp_par, ptr nonnull %structArg)
  %3 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.68815510185ede6107d6524e77abf791, i32 19)
  %4 = call i1 @_FortranAioOutputAscii(ptr %3, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %5 = load i32, ptr %1, align 4, !tbaa !4
  %6 = call i1 @_FortranAioOutputInteger32(ptr %3, i32 %5)
  %7 = call i1 @_FortranAioOutputAscii(ptr %3, ptr nonnull @_QQcl.2920697320, i64 5)
  %.unpack = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  %.unpack95.unpack.unpack = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  %8 = sub i64 1, %.unpack95.unpack.unpack
  %9 = getelementptr double, ptr %.unpack, i64 %8
  %10 = load double, ptr %9, align 8, !tbaa !4
  %11 = load i32, ptr %1, align 4, !tbaa !4
  %12 = sext i32 %11 to i64
  %13 = sub i64 %12, %.unpack95.unpack.unpack
  %14 = getelementptr double, ptr %.unpack, i64 %13
  %15 = load double, ptr %14, align 8, !tbaa !4
  %16 = fadd contract double %10, %15
  %17 = call i1 @_FortranAioOutputReal64(ptr %3, double %16)
  %18 = call i32 @_FortranAioEndIoStatement(ptr %3)
  %.unpack100 = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  call void @free(ptr %.unpack100)
  store ptr null, ptr @_QFEarr, align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  store i32 20180515, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  store i8 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  store i8 28, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  store i8 2, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  store i8 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  store i64 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  store i64 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  ret void
}
*** IR Dump After BDCEPass on _QQmain ***
define void @_QQmain() local_unnamed_addr {
entry:
  %structArg = alloca { ptr, ptr }, align 8
  %0 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %1 = alloca i32, align 4
  store i32 1048576, ptr %1, align 4, !tbaa !4
  %2 = tail call dereferenceable_or_null(8388608) ptr @malloc(i64 8388608)
  store ptr %2, ptr @_QFEarr, align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  store i32 20180515, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  store i8 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  store i8 28, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  store i8 2, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  store i8 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  store i64 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  store i64 1048576, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  %omp_global_thread_num = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %1, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %0, ptr %gep_5, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QQmain..omp_par, ptr nonnull %structArg)
  %3 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.68815510185ede6107d6524e77abf791, i32 19)
  %4 = call i1 @_FortranAioOutputAscii(ptr %3, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %5 = load i32, ptr %1, align 4, !tbaa !4
  %6 = call i1 @_FortranAioOutputInteger32(ptr %3, i32 %5)
  %7 = call i1 @_FortranAioOutputAscii(ptr %3, ptr nonnull @_QQcl.2920697320, i64 5)
  %.unpack = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  %.unpack95.unpack.unpack = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  %8 = sub i64 1, %.unpack95.unpack.unpack
  %9 = getelementptr double, ptr %.unpack, i64 %8
  %10 = load double, ptr %9, align 8, !tbaa !4
  %11 = load i32, ptr %1, align 4, !tbaa !4
  %12 = sext i32 %11 to i64
  %13 = sub i64 %12, %.unpack95.unpack.unpack
  %14 = getelementptr double, ptr %.unpack, i64 %13
  %15 = load double, ptr %14, align 8, !tbaa !4
  %16 = fadd contract double %10, %15
  %17 = call i1 @_FortranAioOutputReal64(ptr %3, double %16)
  %18 = call i32 @_FortranAioEndIoStatement(ptr %3)
  %.unpack100 = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  call void @free(ptr %.unpack100)
  store ptr null, ptr @_QFEarr, align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  store i32 20180515, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  store i8 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  store i8 28, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  store i8 2, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  store i8 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  store i64 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  store i64 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  ret void
}
*** IR Dump After InstCombinePass on _QQmain ***
define void @_QQmain() local_unnamed_addr {
entry:
  %structArg = alloca { ptr, ptr }, align 8
  %0 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %1 = alloca i32, align 4
  store i32 1048576, ptr %1, align 4, !tbaa !4
  %2 = tail call dereferenceable_or_null(8388608) ptr @malloc(i64 8388608)
  store ptr %2, ptr @_QFEarr, align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  store i32 20180515, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  store i8 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  store i8 28, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  store i8 2, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  store i8 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  store i64 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  store i64 1048576, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  %omp_global_thread_num = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %1, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %0, ptr %gep_5, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QQmain..omp_par, ptr nonnull %structArg)
  %3 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.68815510185ede6107d6524e77abf791, i32 19)
  %4 = call i1 @_FortranAioOutputAscii(ptr %3, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %5 = load i32, ptr %1, align 4, !tbaa !4
  %6 = call i1 @_FortranAioOutputInteger32(ptr %3, i32 %5)
  %7 = call i1 @_FortranAioOutputAscii(ptr %3, ptr nonnull @_QQcl.2920697320, i64 5)
  %.unpack = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  %.unpack95.unpack.unpack = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  %8 = sub i64 1, %.unpack95.unpack.unpack
  %9 = getelementptr double, ptr %.unpack, i64 %8
  %10 = load double, ptr %9, align 8, !tbaa !4
  %11 = load i32, ptr %1, align 4, !tbaa !4
  %12 = sext i32 %11 to i64
  %13 = sub i64 %12, %.unpack95.unpack.unpack
  %14 = getelementptr double, ptr %.unpack, i64 %13
  %15 = load double, ptr %14, align 8, !tbaa !4
  %16 = fadd contract double %10, %15
  %17 = call i1 @_FortranAioOutputReal64(ptr %3, double %16)
  %18 = call i32 @_FortranAioEndIoStatement(ptr %3)
  %.unpack100 = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  call void @free(ptr %.unpack100)
  store ptr null, ptr @_QFEarr, align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  store i32 20180515, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  store i8 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  store i8 28, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  store i8 2, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  store i8 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  store i64 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  store i64 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  ret void
}
*** IR Dump After JumpThreadingPass on _QQmain ***
define void @_QQmain() local_unnamed_addr {
entry:
  %structArg = alloca { ptr, ptr }, align 8
  %0 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %1 = alloca i32, align 4
  store i32 1048576, ptr %1, align 4, !tbaa !4
  %2 = tail call dereferenceable_or_null(8388608) ptr @malloc(i64 8388608)
  store ptr %2, ptr @_QFEarr, align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  store i32 20180515, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  store i8 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  store i8 28, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  store i8 2, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  store i8 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  store i64 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  store i64 1048576, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  %omp_global_thread_num = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %1, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %0, ptr %gep_5, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QQmain..omp_par, ptr nonnull %structArg)
  %3 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.68815510185ede6107d6524e77abf791, i32 19)
  %4 = call i1 @_FortranAioOutputAscii(ptr %3, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %5 = load i32, ptr %1, align 4, !tbaa !4
  %6 = call i1 @_FortranAioOutputInteger32(ptr %3, i32 %5)
  %7 = call i1 @_FortranAioOutputAscii(ptr %3, ptr nonnull @_QQcl.2920697320, i64 5)
  %.unpack = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  %.unpack95.unpack.unpack = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  %8 = sub i64 1, %.unpack95.unpack.unpack
  %9 = getelementptr double, ptr %.unpack, i64 %8
  %10 = load double, ptr %9, align 8, !tbaa !4
  %11 = load i32, ptr %1, align 4, !tbaa !4
  %12 = sext i32 %11 to i64
  %13 = sub i64 %12, %.unpack95.unpack.unpack
  %14 = getelementptr double, ptr %.unpack, i64 %13
  %15 = load double, ptr %14, align 8, !tbaa !4
  %16 = fadd contract double %10, %15
  %17 = call i1 @_FortranAioOutputReal64(ptr %3, double %16)
  %18 = call i32 @_FortranAioEndIoStatement(ptr %3)
  %.unpack100 = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  call void @free(ptr %.unpack100)
  store ptr null, ptr @_QFEarr, align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  store i32 20180515, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  store i8 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  store i8 28, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  store i8 2, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  store i8 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  store i64 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  store i64 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  ret void
}
*** IR Dump After CorrelatedValuePropagationPass on _QQmain ***
define void @_QQmain() local_unnamed_addr {
entry:
  %structArg = alloca { ptr, ptr }, align 8
  %0 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %1 = alloca i32, align 4
  store i32 1048576, ptr %1, align 4, !tbaa !4
  %2 = tail call dereferenceable_or_null(8388608) ptr @malloc(i64 8388608)
  store ptr %2, ptr @_QFEarr, align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  store i32 20180515, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  store i8 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  store i8 28, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  store i8 2, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  store i8 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  store i64 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  store i64 1048576, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  %omp_global_thread_num = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %1, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %0, ptr %gep_5, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QQmain..omp_par, ptr nonnull %structArg)
  %3 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.68815510185ede6107d6524e77abf791, i32 19)
  %4 = call i1 @_FortranAioOutputAscii(ptr %3, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %5 = load i32, ptr %1, align 4, !tbaa !4
  %6 = call i1 @_FortranAioOutputInteger32(ptr %3, i32 %5)
  %7 = call i1 @_FortranAioOutputAscii(ptr %3, ptr nonnull @_QQcl.2920697320, i64 5)
  %.unpack = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  %.unpack95.unpack.unpack = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  %8 = sub i64 1, %.unpack95.unpack.unpack
  %9 = getelementptr double, ptr %.unpack, i64 %8
  %10 = load double, ptr %9, align 8, !tbaa !4
  %11 = load i32, ptr %1, align 4, !tbaa !4
  %12 = sext i32 %11 to i64
  %13 = sub i64 %12, %.unpack95.unpack.unpack
  %14 = getelementptr double, ptr %.unpack, i64 %13
  %15 = load double, ptr %14, align 8, !tbaa !4
  %16 = fadd contract double %10, %15
  %17 = call i1 @_FortranAioOutputReal64(ptr %3, double %16)
  %18 = call i32 @_FortranAioEndIoStatement(ptr %3)
  %.unpack100 = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  call void @free(ptr %.unpack100)
  store ptr null, ptr @_QFEarr, align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  store i32 20180515, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  store i8 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  store i8 28, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  store i8 2, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  store i8 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  store i64 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  store i64 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  ret void
}
*** IR Dump After ADCEPass on _QQmain ***
define void @_QQmain() local_unnamed_addr {
entry:
  %structArg = alloca { ptr, ptr }, align 8
  %0 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %1 = alloca i32, align 4
  store i32 1048576, ptr %1, align 4, !tbaa !4
  %2 = tail call dereferenceable_or_null(8388608) ptr @malloc(i64 8388608)
  store ptr %2, ptr @_QFEarr, align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  store i32 20180515, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  store i8 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  store i8 28, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  store i8 2, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  store i8 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  store i64 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  store i64 1048576, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  %omp_global_thread_num = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %1, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %0, ptr %gep_5, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QQmain..omp_par, ptr nonnull %structArg)
  %3 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.68815510185ede6107d6524e77abf791, i32 19)
  %4 = call i1 @_FortranAioOutputAscii(ptr %3, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %5 = load i32, ptr %1, align 4, !tbaa !4
  %6 = call i1 @_FortranAioOutputInteger32(ptr %3, i32 %5)
  %7 = call i1 @_FortranAioOutputAscii(ptr %3, ptr nonnull @_QQcl.2920697320, i64 5)
  %.unpack = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  %.unpack95.unpack.unpack = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  %8 = sub i64 1, %.unpack95.unpack.unpack
  %9 = getelementptr double, ptr %.unpack, i64 %8
  %10 = load double, ptr %9, align 8, !tbaa !4
  %11 = load i32, ptr %1, align 4, !tbaa !4
  %12 = sext i32 %11 to i64
  %13 = sub i64 %12, %.unpack95.unpack.unpack
  %14 = getelementptr double, ptr %.unpack, i64 %13
  %15 = load double, ptr %14, align 8, !tbaa !4
  %16 = fadd contract double %10, %15
  %17 = call i1 @_FortranAioOutputReal64(ptr %3, double %16)
  %18 = call i32 @_FortranAioEndIoStatement(ptr %3)
  %.unpack100 = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  call void @free(ptr %.unpack100)
  store ptr null, ptr @_QFEarr, align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  store i32 20180515, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  store i8 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  store i8 28, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  store i8 2, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  store i8 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  store i64 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  store i64 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  ret void
}
*** IR Dump After MemCpyOptPass on _QQmain ***
define void @_QQmain() local_unnamed_addr {
entry:
  %structArg = alloca { ptr, ptr }, align 8
  %0 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %1 = alloca i32, align 4
  store i32 1048576, ptr %1, align 4, !tbaa !4
  %2 = tail call dereferenceable_or_null(8388608) ptr @malloc(i64 8388608)
  store ptr %2, ptr @_QFEarr, align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  store i32 20180515, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  store i8 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  store i8 28, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  store i8 2, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  store i8 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  store i64 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  store i64 1048576, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  %omp_global_thread_num = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %1, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %0, ptr %gep_5, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QQmain..omp_par, ptr nonnull %structArg)
  %3 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.68815510185ede6107d6524e77abf791, i32 19)
  %4 = call i1 @_FortranAioOutputAscii(ptr %3, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %5 = load i32, ptr %1, align 4, !tbaa !4
  %6 = call i1 @_FortranAioOutputInteger32(ptr %3, i32 %5)
  %7 = call i1 @_FortranAioOutputAscii(ptr %3, ptr nonnull @_QQcl.2920697320, i64 5)
  %.unpack = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  %.unpack95.unpack.unpack = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  %8 = sub i64 1, %.unpack95.unpack.unpack
  %9 = getelementptr double, ptr %.unpack, i64 %8
  %10 = load double, ptr %9, align 8, !tbaa !4
  %11 = load i32, ptr %1, align 4, !tbaa !4
  %12 = sext i32 %11 to i64
  %13 = sub i64 %12, %.unpack95.unpack.unpack
  %14 = getelementptr double, ptr %.unpack, i64 %13
  %15 = load double, ptr %14, align 8, !tbaa !4
  %16 = fadd contract double %10, %15
  %17 = call i1 @_FortranAioOutputReal64(ptr %3, double %16)
  %18 = call i32 @_FortranAioEndIoStatement(ptr %3)
  %.unpack100 = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  call void @free(ptr %.unpack100)
  store ptr null, ptr @_QFEarr, align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  store i32 20180515, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  store i8 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  store i8 28, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  store i8 2, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  store i8 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  store i64 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  store i64 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  ret void
}
*** IR Dump After DSEPass on _QQmain ***
define void @_QQmain() local_unnamed_addr {
entry:
  %structArg = alloca { ptr, ptr }, align 8
  %0 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %1 = alloca i32, align 4
  store i32 1048576, ptr %1, align 4, !tbaa !4
  %2 = tail call dereferenceable_or_null(8388608) ptr @malloc(i64 8388608)
  store ptr %2, ptr @_QFEarr, align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  store i32 20180515, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  store i8 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  store i8 28, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  store i8 2, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  store i8 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  store i64 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  store i64 1048576, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  %omp_global_thread_num = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %1, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %0, ptr %gep_5, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QQmain..omp_par, ptr nonnull %structArg)
  %3 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.68815510185ede6107d6524e77abf791, i32 19)
  %4 = call i1 @_FortranAioOutputAscii(ptr %3, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %5 = load i32, ptr %1, align 4, !tbaa !4
  %6 = call i1 @_FortranAioOutputInteger32(ptr %3, i32 %5)
  %7 = call i1 @_FortranAioOutputAscii(ptr %3, ptr nonnull @_QQcl.2920697320, i64 5)
  %.unpack = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  %.unpack95.unpack.unpack = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  %8 = sub i64 1, %.unpack95.unpack.unpack
  %9 = getelementptr double, ptr %.unpack, i64 %8
  %10 = load double, ptr %9, align 8, !tbaa !4
  %11 = load i32, ptr %1, align 4, !tbaa !4
  %12 = sext i32 %11 to i64
  %13 = sub i64 %12, %.unpack95.unpack.unpack
  %14 = getelementptr double, ptr %.unpack, i64 %13
  %15 = load double, ptr %14, align 8, !tbaa !4
  %16 = fadd contract double %10, %15
  %17 = call i1 @_FortranAioOutputReal64(ptr %3, double %16)
  %18 = call i32 @_FortranAioEndIoStatement(ptr %3)
  %.unpack100 = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  call void @free(ptr %.unpack100)
  store ptr null, ptr @_QFEarr, align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  store i32 20180515, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  store i8 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  store i8 28, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  store i8 2, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  store i8 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  store i64 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  store i64 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  ret void
}
*** IR Dump After MoveAutoInitPass on _QQmain ***
define void @_QQmain() local_unnamed_addr {
entry:
  %structArg = alloca { ptr, ptr }, align 8
  %0 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %1 = alloca i32, align 4
  store i32 1048576, ptr %1, align 4, !tbaa !4
  %2 = tail call dereferenceable_or_null(8388608) ptr @malloc(i64 8388608)
  store ptr %2, ptr @_QFEarr, align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  store i32 20180515, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  store i8 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  store i8 28, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  store i8 2, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  store i8 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  store i64 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  store i64 1048576, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  %omp_global_thread_num = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %1, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %0, ptr %gep_5, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QQmain..omp_par, ptr nonnull %structArg)
  %3 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.68815510185ede6107d6524e77abf791, i32 19)
  %4 = call i1 @_FortranAioOutputAscii(ptr %3, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %5 = load i32, ptr %1, align 4, !tbaa !4
  %6 = call i1 @_FortranAioOutputInteger32(ptr %3, i32 %5)
  %7 = call i1 @_FortranAioOutputAscii(ptr %3, ptr nonnull @_QQcl.2920697320, i64 5)
  %.unpack = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  %.unpack95.unpack.unpack = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  %8 = sub i64 1, %.unpack95.unpack.unpack
  %9 = getelementptr double, ptr %.unpack, i64 %8
  %10 = load double, ptr %9, align 8, !tbaa !4
  %11 = load i32, ptr %1, align 4, !tbaa !4
  %12 = sext i32 %11 to i64
  %13 = sub i64 %12, %.unpack95.unpack.unpack
  %14 = getelementptr double, ptr %.unpack, i64 %13
  %15 = load double, ptr %14, align 8, !tbaa !4
  %16 = fadd contract double %10, %15
  %17 = call i1 @_FortranAioOutputReal64(ptr %3, double %16)
  %18 = call i32 @_FortranAioEndIoStatement(ptr %3)
  %.unpack100 = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  call void @free(ptr %.unpack100)
  store ptr null, ptr @_QFEarr, align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  store i32 20180515, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  store i8 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  store i8 28, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  store i8 2, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  store i8 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  store i64 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  store i64 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  ret void
}
*** IR Dump After LoopSimplifyPass on _QQmain ***
define void @_QQmain() local_unnamed_addr {
entry:
  %structArg = alloca { ptr, ptr }, align 8
  %0 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %1 = alloca i32, align 4
  store i32 1048576, ptr %1, align 4, !tbaa !4
  %2 = tail call dereferenceable_or_null(8388608) ptr @malloc(i64 8388608)
  store ptr %2, ptr @_QFEarr, align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  store i32 20180515, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  store i8 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  store i8 28, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  store i8 2, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  store i8 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  store i64 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  store i64 1048576, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  %omp_global_thread_num = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %1, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %0, ptr %gep_5, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QQmain..omp_par, ptr nonnull %structArg)
  %3 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.68815510185ede6107d6524e77abf791, i32 19)
  %4 = call i1 @_FortranAioOutputAscii(ptr %3, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %5 = load i32, ptr %1, align 4, !tbaa !4
  %6 = call i1 @_FortranAioOutputInteger32(ptr %3, i32 %5)
  %7 = call i1 @_FortranAioOutputAscii(ptr %3, ptr nonnull @_QQcl.2920697320, i64 5)
  %.unpack = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  %.unpack95.unpack.unpack = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  %8 = sub i64 1, %.unpack95.unpack.unpack
  %9 = getelementptr double, ptr %.unpack, i64 %8
  %10 = load double, ptr %9, align 8, !tbaa !4
  %11 = load i32, ptr %1, align 4, !tbaa !4
  %12 = sext i32 %11 to i64
  %13 = sub i64 %12, %.unpack95.unpack.unpack
  %14 = getelementptr double, ptr %.unpack, i64 %13
  %15 = load double, ptr %14, align 8, !tbaa !4
  %16 = fadd contract double %10, %15
  %17 = call i1 @_FortranAioOutputReal64(ptr %3, double %16)
  %18 = call i32 @_FortranAioEndIoStatement(ptr %3)
  %.unpack100 = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  call void @free(ptr %.unpack100)
  store ptr null, ptr @_QFEarr, align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  store i32 20180515, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  store i8 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  store i8 28, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  store i8 2, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  store i8 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  store i64 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  store i64 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  ret void
}
*** IR Dump After LCSSAPass on _QQmain ***
define void @_QQmain() local_unnamed_addr {
entry:
  %structArg = alloca { ptr, ptr }, align 8
  %0 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %1 = alloca i32, align 4
  store i32 1048576, ptr %1, align 4, !tbaa !4
  %2 = tail call dereferenceable_or_null(8388608) ptr @malloc(i64 8388608)
  store ptr %2, ptr @_QFEarr, align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  store i32 20180515, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  store i8 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  store i8 28, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  store i8 2, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  store i8 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  store i64 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  store i64 1048576, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  %omp_global_thread_num = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %1, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %0, ptr %gep_5, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QQmain..omp_par, ptr nonnull %structArg)
  %3 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.68815510185ede6107d6524e77abf791, i32 19)
  %4 = call i1 @_FortranAioOutputAscii(ptr %3, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %5 = load i32, ptr %1, align 4, !tbaa !4
  %6 = call i1 @_FortranAioOutputInteger32(ptr %3, i32 %5)
  %7 = call i1 @_FortranAioOutputAscii(ptr %3, ptr nonnull @_QQcl.2920697320, i64 5)
  %.unpack = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  %.unpack95.unpack.unpack = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  %8 = sub i64 1, %.unpack95.unpack.unpack
  %9 = getelementptr double, ptr %.unpack, i64 %8
  %10 = load double, ptr %9, align 8, !tbaa !4
  %11 = load i32, ptr %1, align 4, !tbaa !4
  %12 = sext i32 %11 to i64
  %13 = sub i64 %12, %.unpack95.unpack.unpack
  %14 = getelementptr double, ptr %.unpack, i64 %13
  %15 = load double, ptr %14, align 8, !tbaa !4
  %16 = fadd contract double %10, %15
  %17 = call i1 @_FortranAioOutputReal64(ptr %3, double %16)
  %18 = call i32 @_FortranAioEndIoStatement(ptr %3)
  %.unpack100 = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  call void @free(ptr %.unpack100)
  store ptr null, ptr @_QFEarr, align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  store i32 20180515, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  store i8 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  store i8 28, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  store i8 2, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  store i8 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  store i64 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  store i64 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  ret void
}
*** IR Dump After CoroElidePass on _QQmain ***
define void @_QQmain() local_unnamed_addr {
entry:
  %structArg = alloca { ptr, ptr }, align 8
  %0 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %1 = alloca i32, align 4
  store i32 1048576, ptr %1, align 4, !tbaa !4
  %2 = tail call dereferenceable_or_null(8388608) ptr @malloc(i64 8388608)
  store ptr %2, ptr @_QFEarr, align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  store i32 20180515, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  store i8 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  store i8 28, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  store i8 2, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  store i8 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  store i64 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  store i64 1048576, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  %omp_global_thread_num = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %1, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %0, ptr %gep_5, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QQmain..omp_par, ptr nonnull %structArg)
  %3 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.68815510185ede6107d6524e77abf791, i32 19)
  %4 = call i1 @_FortranAioOutputAscii(ptr %3, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %5 = load i32, ptr %1, align 4, !tbaa !4
  %6 = call i1 @_FortranAioOutputInteger32(ptr %3, i32 %5)
  %7 = call i1 @_FortranAioOutputAscii(ptr %3, ptr nonnull @_QQcl.2920697320, i64 5)
  %.unpack = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  %.unpack95.unpack.unpack = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  %8 = sub i64 1, %.unpack95.unpack.unpack
  %9 = getelementptr double, ptr %.unpack, i64 %8
  %10 = load double, ptr %9, align 8, !tbaa !4
  %11 = load i32, ptr %1, align 4, !tbaa !4
  %12 = sext i32 %11 to i64
  %13 = sub i64 %12, %.unpack95.unpack.unpack
  %14 = getelementptr double, ptr %.unpack, i64 %13
  %15 = load double, ptr %14, align 8, !tbaa !4
  %16 = fadd contract double %10, %15
  %17 = call i1 @_FortranAioOutputReal64(ptr %3, double %16)
  %18 = call i32 @_FortranAioEndIoStatement(ptr %3)
  %.unpack100 = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  call void @free(ptr %.unpack100)
  store ptr null, ptr @_QFEarr, align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  store i32 20180515, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  store i8 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  store i8 28, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  store i8 2, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  store i8 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  store i64 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  store i64 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  ret void
}
*** IR Dump After SimplifyCFGPass on _QQmain ***
define void @_QQmain() local_unnamed_addr {
entry:
  %structArg = alloca { ptr, ptr }, align 8
  %0 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %1 = alloca i32, align 4
  store i32 1048576, ptr %1, align 4, !tbaa !4
  %2 = tail call dereferenceable_or_null(8388608) ptr @malloc(i64 8388608)
  store ptr %2, ptr @_QFEarr, align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  store i32 20180515, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  store i8 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  store i8 28, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  store i8 2, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  store i8 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  store i64 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  store i64 1048576, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  %omp_global_thread_num = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %1, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %0, ptr %gep_5, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QQmain..omp_par, ptr nonnull %structArg)
  %3 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.68815510185ede6107d6524e77abf791, i32 19)
  %4 = call i1 @_FortranAioOutputAscii(ptr %3, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %5 = load i32, ptr %1, align 4, !tbaa !4
  %6 = call i1 @_FortranAioOutputInteger32(ptr %3, i32 %5)
  %7 = call i1 @_FortranAioOutputAscii(ptr %3, ptr nonnull @_QQcl.2920697320, i64 5)
  %.unpack = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  %.unpack95.unpack.unpack = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  %8 = sub i64 1, %.unpack95.unpack.unpack
  %9 = getelementptr double, ptr %.unpack, i64 %8
  %10 = load double, ptr %9, align 8, !tbaa !4
  %11 = load i32, ptr %1, align 4, !tbaa !4
  %12 = sext i32 %11 to i64
  %13 = sub i64 %12, %.unpack95.unpack.unpack
  %14 = getelementptr double, ptr %.unpack, i64 %13
  %15 = load double, ptr %14, align 8, !tbaa !4
  %16 = fadd contract double %10, %15
  %17 = call i1 @_FortranAioOutputReal64(ptr %3, double %16)
  %18 = call i32 @_FortranAioEndIoStatement(ptr %3)
  %.unpack100 = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  call void @free(ptr %.unpack100)
  store ptr null, ptr @_QFEarr, align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  store i32 20180515, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  store i8 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  store i8 28, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  store i8 2, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  store i8 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  store i64 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  store i64 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  ret void
}
*** IR Dump After InstCombinePass on _QQmain ***
define void @_QQmain() local_unnamed_addr {
entry:
  %structArg = alloca { ptr, ptr }, align 8
  %0 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %1 = alloca i32, align 4
  store i32 1048576, ptr %1, align 4, !tbaa !4
  %2 = tail call dereferenceable_or_null(8388608) ptr @malloc(i64 8388608)
  store ptr %2, ptr @_QFEarr, align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  store i32 20180515, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  store i8 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  store i8 28, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  store i8 2, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  store i8 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  store i64 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  store i64 1048576, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  %omp_global_thread_num = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %1, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %0, ptr %gep_5, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QQmain..omp_par, ptr nonnull %structArg)
  %3 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.68815510185ede6107d6524e77abf791, i32 19)
  %4 = call i1 @_FortranAioOutputAscii(ptr %3, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %5 = load i32, ptr %1, align 4, !tbaa !4
  %6 = call i1 @_FortranAioOutputInteger32(ptr %3, i32 %5)
  %7 = call i1 @_FortranAioOutputAscii(ptr %3, ptr nonnull @_QQcl.2920697320, i64 5)
  %.unpack = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  %.unpack95.unpack.unpack = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  %8 = sub i64 1, %.unpack95.unpack.unpack
  %9 = getelementptr double, ptr %.unpack, i64 %8
  %10 = load double, ptr %9, align 8, !tbaa !4
  %11 = load i32, ptr %1, align 4, !tbaa !4
  %12 = sext i32 %11 to i64
  %13 = sub i64 %12, %.unpack95.unpack.unpack
  %14 = getelementptr double, ptr %.unpack, i64 %13
  %15 = load double, ptr %14, align 8, !tbaa !4
  %16 = fadd contract double %10, %15
  %17 = call i1 @_FortranAioOutputReal64(ptr %3, double %16)
  %18 = call i32 @_FortranAioEndIoStatement(ptr %3)
  %.unpack100 = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  call void @free(ptr %.unpack100)
  store ptr null, ptr @_QFEarr, align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  store i32 20180515, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  store i8 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  store i8 28, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  store i8 2, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  store i8 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  store i64 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  store i64 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  ret void
}
*** IR Dump After PostOrderFunctionAttrsPass on (_QQmain) ***
define void @_QQmain() local_unnamed_addr {
entry:
  %structArg = alloca { ptr, ptr }, align 8
  %0 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %1 = alloca i32, align 4
  store i32 1048576, ptr %1, align 4, !tbaa !4
  %2 = tail call dereferenceable_or_null(8388608) ptr @malloc(i64 8388608)
  store ptr %2, ptr @_QFEarr, align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  store i32 20180515, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  store i8 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  store i8 28, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  store i8 2, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  store i8 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  store i64 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  store i64 1048576, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  %omp_global_thread_num = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %1, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %0, ptr %gep_5, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QQmain..omp_par, ptr nonnull %structArg)
  %3 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.68815510185ede6107d6524e77abf791, i32 19)
  %4 = call i1 @_FortranAioOutputAscii(ptr %3, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %5 = load i32, ptr %1, align 4, !tbaa !4
  %6 = call i1 @_FortranAioOutputInteger32(ptr %3, i32 %5)
  %7 = call i1 @_FortranAioOutputAscii(ptr %3, ptr nonnull @_QQcl.2920697320, i64 5)
  %.unpack = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  %.unpack95.unpack.unpack = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  %8 = sub i64 1, %.unpack95.unpack.unpack
  %9 = getelementptr double, ptr %.unpack, i64 %8
  %10 = load double, ptr %9, align 8, !tbaa !4
  %11 = load i32, ptr %1, align 4, !tbaa !4
  %12 = sext i32 %11 to i64
  %13 = sub i64 %12, %.unpack95.unpack.unpack
  %14 = getelementptr double, ptr %.unpack, i64 %13
  %15 = load double, ptr %14, align 8, !tbaa !4
  %16 = fadd contract double %10, %15
  %17 = call i1 @_FortranAioOutputReal64(ptr %3, double %16)
  %18 = call i32 @_FortranAioEndIoStatement(ptr %3)
  %.unpack100 = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  call void @free(ptr %.unpack100)
  store ptr null, ptr @_QFEarr, align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  store i32 20180515, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  store i8 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  store i8 28, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  store i8 2, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  store i8 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  store i64 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  store i64 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  ret void
}
*** IR Dump After RequireAnalysisPass<llvm::ShouldNotRunFunctionPassesAnalysis, llvm::Function> on _QQmain ***
define void @_QQmain() local_unnamed_addr {
entry:
  %structArg = alloca { ptr, ptr }, align 8
  %0 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %1 = alloca i32, align 4
  store i32 1048576, ptr %1, align 4, !tbaa !4
  %2 = tail call dereferenceable_or_null(8388608) ptr @malloc(i64 8388608)
  store ptr %2, ptr @_QFEarr, align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  store i32 20180515, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  store i8 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  store i8 28, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  store i8 2, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  store i8 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  store i64 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  store i64 1048576, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  %omp_global_thread_num = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %1, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %0, ptr %gep_5, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QQmain..omp_par, ptr nonnull %structArg)
  %3 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.68815510185ede6107d6524e77abf791, i32 19)
  %4 = call i1 @_FortranAioOutputAscii(ptr %3, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %5 = load i32, ptr %1, align 4, !tbaa !4
  %6 = call i1 @_FortranAioOutputInteger32(ptr %3, i32 %5)
  %7 = call i1 @_FortranAioOutputAscii(ptr %3, ptr nonnull @_QQcl.2920697320, i64 5)
  %.unpack = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  %.unpack95.unpack.unpack = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  %8 = sub i64 1, %.unpack95.unpack.unpack
  %9 = getelementptr double, ptr %.unpack, i64 %8
  %10 = load double, ptr %9, align 8, !tbaa !4
  %11 = load i32, ptr %1, align 4, !tbaa !4
  %12 = sext i32 %11 to i64
  %13 = sub i64 %12, %.unpack95.unpack.unpack
  %14 = getelementptr double, ptr %.unpack, i64 %13
  %15 = load double, ptr %14, align 8, !tbaa !4
  %16 = fadd contract double %10, %15
  %17 = call i1 @_FortranAioOutputReal64(ptr %3, double %16)
  %18 = call i32 @_FortranAioEndIoStatement(ptr %3)
  %.unpack100 = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  call void @free(ptr %.unpack100)
  store ptr null, ptr @_QFEarr, align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  store i32 20180515, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  store i8 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  store i8 28, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  store i8 2, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  store i8 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  store i64 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  store i64 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  ret void
}
*** IR Dump After CoroSplitPass on (_QQmain) ***
define void @_QQmain() local_unnamed_addr {
entry:
  %structArg = alloca { ptr, ptr }, align 8
  %0 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %1 = alloca i32, align 4
  store i32 1048576, ptr %1, align 4, !tbaa !4
  %2 = tail call dereferenceable_or_null(8388608) ptr @malloc(i64 8388608)
  store ptr %2, ptr @_QFEarr, align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  store i32 20180515, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  store i8 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  store i8 28, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  store i8 2, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  store i8 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  store i64 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  store i64 1048576, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  %omp_global_thread_num = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %1, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %0, ptr %gep_5, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QQmain..omp_par, ptr nonnull %structArg)
  %3 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.68815510185ede6107d6524e77abf791, i32 19)
  %4 = call i1 @_FortranAioOutputAscii(ptr %3, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %5 = load i32, ptr %1, align 4, !tbaa !4
  %6 = call i1 @_FortranAioOutputInteger32(ptr %3, i32 %5)
  %7 = call i1 @_FortranAioOutputAscii(ptr %3, ptr nonnull @_QQcl.2920697320, i64 5)
  %.unpack = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  %.unpack95.unpack.unpack = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  %8 = sub i64 1, %.unpack95.unpack.unpack
  %9 = getelementptr double, ptr %.unpack, i64 %8
  %10 = load double, ptr %9, align 8, !tbaa !4
  %11 = load i32, ptr %1, align 4, !tbaa !4
  %12 = sext i32 %11 to i64
  %13 = sub i64 %12, %.unpack95.unpack.unpack
  %14 = getelementptr double, ptr %.unpack, i64 %13
  %15 = load double, ptr %14, align 8, !tbaa !4
  %16 = fadd contract double %10, %15
  %17 = call i1 @_FortranAioOutputReal64(ptr %3, double %16)
  %18 = call i32 @_FortranAioEndIoStatement(ptr %3)
  %.unpack100 = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  call void @free(ptr %.unpack100)
  store ptr null, ptr @_QFEarr, align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  store i32 20180515, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  store i8 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  store i8 28, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  store i8 2, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  store i8 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  store i64 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  store i64 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  ret void
}
*** IR Dump After InvalidateAnalysisPass<llvm::ShouldNotRunFunctionPassesAnalysis> on _QQmain ***
define void @_QQmain() local_unnamed_addr {
entry:
  %structArg = alloca { ptr, ptr }, align 8
  %0 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %1 = alloca i32, align 4
  store i32 1048576, ptr %1, align 4, !tbaa !4
  %2 = tail call dereferenceable_or_null(8388608) ptr @malloc(i64 8388608)
  store ptr %2, ptr @_QFEarr, align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  store i32 20180515, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  store i8 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  store i8 28, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  store i8 2, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  store i8 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  store i64 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  store i64 1048576, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  %omp_global_thread_num = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %1, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %0, ptr %gep_5, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QQmain..omp_par, ptr nonnull %structArg)
  %3 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.68815510185ede6107d6524e77abf791, i32 19)
  %4 = call i1 @_FortranAioOutputAscii(ptr %3, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %5 = load i32, ptr %1, align 4, !tbaa !4
  %6 = call i1 @_FortranAioOutputInteger32(ptr %3, i32 %5)
  %7 = call i1 @_FortranAioOutputAscii(ptr %3, ptr nonnull @_QQcl.2920697320, i64 5)
  %.unpack = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  %.unpack95.unpack.unpack = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  %8 = sub i64 1, %.unpack95.unpack.unpack
  %9 = getelementptr double, ptr %.unpack, i64 %8
  %10 = load double, ptr %9, align 8, !tbaa !4
  %11 = load i32, ptr %1, align 4, !tbaa !4
  %12 = sext i32 %11 to i64
  %13 = sub i64 %12, %.unpack95.unpack.unpack
  %14 = getelementptr double, ptr %.unpack, i64 %13
  %15 = load double, ptr %14, align 8, !tbaa !4
  %16 = fadd contract double %10, %15
  %17 = call i1 @_FortranAioOutputReal64(ptr %3, double %16)
  %18 = call i32 @_FortranAioEndIoStatement(ptr %3)
  %.unpack100 = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  call void @free(ptr %.unpack100)
  store ptr null, ptr @_QFEarr, align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  store i32 20180515, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  store i8 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  store i8 28, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  store i8 2, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  store i8 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  store i64 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  store i64 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  ret void
}
*** IR Dump After InvalidateAnalysisPass<llvm::ShouldNotRunFunctionPassesAnalysis> on _QQmain..omp_par ***
; Function Attrs: norecurse nounwind
define internal void @_QQmain..omp_par(ptr noalias nocapture readnone %tid.addr, ptr noalias nocapture readnone %zero.addr, ptr nocapture readonly %0) #2 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %p.lastiter = alloca i32, align 4
  %p.lowerbound = alloca i32, align 4
  %p.upperbound = alloca i32, align 4
  %p.stride = alloca i32, align 4
  %1 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %omp_loop.tripcount = tail call i32 @llvm.smax.i32(i32 %1, i32 0)
  store i32 0, ptr %p.lowerbound, align 4
  %2 = add nsw i32 %omp_loop.tripcount, -1
  store i32 %2, ptr %p.upperbound, align 4
  store i32 1, ptr %p.stride, align 4
  %omp_global_thread_num4 = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  call void @__kmpc_for_static_init_4u(ptr nonnull @1, i32 %omp_global_thread_num4, i32 34, ptr nonnull %p.lastiter, ptr nonnull %p.lowerbound, ptr nonnull %p.upperbound, ptr nonnull %p.stride, i32 1, i32 0)
  %3 = load i32, ptr %p.lowerbound, align 4
  %4 = load i32, ptr %p.upperbound, align 4
  %reass.sub = sub i32 %4, %3
  %omp_loop.cmp32.not = icmp eq i32 %reass.sub, -1
  br i1 %omp_loop.cmp32.not, label %omp_loop.exit, label %omp_loop.body.lr.ph

omp_loop.body.lr.ph:                              ; preds = %omp.par.entry
  %.unpack = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  %.unpack3 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  %.unpack4 = load i32, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  %.unpack5 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  %.unpack6 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  %.unpack7 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  %.unpack8 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  %.unpack9.unpack.unpack = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  %.unpack9.unpack.unpack11 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  %.unpack9.unpack.unpack12 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  %loadgep_2.repack16 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  %loadgep_2.repack20 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  %loadgep_2.repack24 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  %loadgep_2.repack26.repack28 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  br label %omp_loop.body

omp_loop.header.omp_loop.exit_crit_edge:          ; preds = %omp_loop.body
  %loadgep_2.repack14 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  %loadgep_2.repack18 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  %loadgep_2.repack22 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  %loadgep_2.repack26 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  %loadgep_2.repack26.repack30 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  store ptr %.unpack, ptr %loadgep_2, align 8, !tbaa !8
  store i64 %.unpack3, ptr %loadgep_2.repack14, align 8, !tbaa !8
  store i32 %.unpack4, ptr %loadgep_2.repack16, align 8, !tbaa !8
  store i8 %.unpack5, ptr %loadgep_2.repack18, align 4, !tbaa !8
  store i8 %.unpack6, ptr %loadgep_2.repack20, align 1, !tbaa !8
  store i8 %.unpack7, ptr %loadgep_2.repack22, align 2, !tbaa !8
  store i8 %.unpack8, ptr %loadgep_2.repack24, align 1, !tbaa !8
  store i64 %.unpack9.unpack.unpack, ptr %loadgep_2.repack26, align 8, !tbaa !8
  store i64 %.unpack9.unpack.unpack11, ptr %loadgep_2.repack26.repack28, align 8, !tbaa !8
  store i64 %.unpack9.unpack.unpack12, ptr %loadgep_2.repack26.repack30, align 8, !tbaa !8
  br label %omp_loop.exit

omp_loop.exit:                                    ; preds = %omp_loop.header.omp_loop.exit_crit_edge, %omp.par.entry
  call void @__kmpc_for_static_fini(ptr nonnull @1, i32 %omp_global_thread_num4)
  call void @__kmpc_barrier(ptr nonnull @2, i32 %omp_global_thread_num4)
  ret void

omp_loop.body:                                    ; preds = %omp_loop.body.lr.ph, %omp_loop.body
  %omp_loop.iv33 = phi i32 [ 0, %omp_loop.body.lr.ph ], [ %5, %omp_loop.body ]
  %5 = add nuw i32 %omp_loop.iv33, 1
  %6 = add i32 %5, %3
  %7 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %8 = sitofp i32 %7 to float
  %9 = fdiv contract float 1.000000e+00, %8
  %10 = fpext float %9 to double
  %11 = sext i32 %6 to i64
  %12 = sub i64 %11, %.unpack9.unpack.unpack
  %13 = getelementptr double, ptr %.unpack, i64 %12
  store double %10, ptr %13, align 8, !tbaa !4
  %exitcond.not = icmp eq i32 %omp_loop.iv33, %reass.sub
  br i1 %exitcond.not, label %omp_loop.header.omp_loop.exit_crit_edge, label %omp_loop.body
}
*** IR Dump After DeadArgumentEliminationPass on [module] ***
; ModuleID = 'FIRModule'
source_filename = "FIRModule"
target datalayout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128"
target triple = "x86_64-unknown-linux-gnu"

%struct.ident_t = type { i32, i32, i32, i32, ptr }

@_QFEarr = internal unnamed_addr global { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } { ptr null, i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), i32 20180515, i8 1, i8 28, i8 2, i8 0, [1 x [3 x i64]] [[3 x i64] [i64 1, i64 0, i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64)]] }
@_QQcl.68815510185ede6107d6524e77abf791 = internal constant [52 x i8] c"/g/g92/rydahl1/flangtests/src/array_descriptors.f90\00"
@_QQcl.28612C69372C612C6531332E36653229 = internal constant [16 x i8] c"(a,i7,a,e13.6e2)"
@_QQcl.54686520726573756C74206F6620286172722831292B61727228 = internal constant [26 x i8] c"The result of (arr(1)+arr("
@_QQcl.2920697320 = internal constant [5 x i8] c") is "
@_QQEnvironmentDefaults = local_unnamed_addr constant ptr null
@0 = private unnamed_addr constant [23 x i8] c";unknown;unknown;0;0;;\00", align 1
@1 = private unnamed_addr constant %struct.ident_t { i32 0, i32 2, i32 0, i32 22, ptr @0 }, align 8
@2 = private unnamed_addr constant %struct.ident_t { i32 0, i32 66, i32 0, i32 22, ptr @0 }, align 8

; Function Attrs: mustprogress nofree nounwind willreturn allockind("alloc,uninitialized") allocsize(0) memory(inaccessiblemem: readwrite)
declare noalias noundef ptr @malloc(i64 noundef) local_unnamed_addr #0

; Function Attrs: mustprogress nounwind willreturn allockind("free") memory(argmem: readwrite, inaccessiblemem: readwrite)
declare void @free(ptr allocptr nocapture noundef) local_unnamed_addr #1

define void @_QQmain() local_unnamed_addr {
entry:
  %structArg = alloca { ptr, ptr }, align 8
  %0 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %1 = alloca i32, align 4
  store i32 1048576, ptr %1, align 4, !tbaa !4
  %2 = tail call dereferenceable_or_null(8388608) ptr @malloc(i64 8388608)
  store ptr %2, ptr @_QFEarr, align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  store i32 20180515, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  store i8 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  store i8 28, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  store i8 2, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  store i8 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  store i64 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  store i64 1048576, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  %omp_global_thread_num = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %1, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %0, ptr %gep_5, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QQmain..omp_par, ptr nonnull %structArg)
  %3 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.68815510185ede6107d6524e77abf791, i32 19)
  %4 = call i1 @_FortranAioOutputAscii(ptr %3, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %5 = load i32, ptr %1, align 4, !tbaa !4
  %6 = call i1 @_FortranAioOutputInteger32(ptr %3, i32 %5)
  %7 = call i1 @_FortranAioOutputAscii(ptr %3, ptr nonnull @_QQcl.2920697320, i64 5)
  %.unpack = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  %.unpack95.unpack.unpack = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  %8 = sub i64 1, %.unpack95.unpack.unpack
  %9 = getelementptr double, ptr %.unpack, i64 %8
  %10 = load double, ptr %9, align 8, !tbaa !4
  %11 = load i32, ptr %1, align 4, !tbaa !4
  %12 = sext i32 %11 to i64
  %13 = sub i64 %12, %.unpack95.unpack.unpack
  %14 = getelementptr double, ptr %.unpack, i64 %13
  %15 = load double, ptr %14, align 8, !tbaa !4
  %16 = fadd contract double %10, %15
  %17 = call i1 @_FortranAioOutputReal64(ptr %3, double %16)
  %18 = call i32 @_FortranAioEndIoStatement(ptr %3)
  %.unpack100 = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  call void @free(ptr %.unpack100)
  store ptr null, ptr @_QFEarr, align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  store i32 20180515, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  store i8 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  store i8 28, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  store i8 2, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  store i8 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  store i64 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  store i64 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  ret void
}

; Function Attrs: norecurse nounwind
define internal void @_QQmain..omp_par(ptr noalias nocapture readnone %tid.addr, ptr noalias nocapture readnone %zero.addr, ptr nocapture readonly %0) #2 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %p.lastiter = alloca i32, align 4
  %p.lowerbound = alloca i32, align 4
  %p.upperbound = alloca i32, align 4
  %p.stride = alloca i32, align 4
  %1 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %omp_loop.tripcount = tail call i32 @llvm.smax.i32(i32 %1, i32 0)
  store i32 0, ptr %p.lowerbound, align 4
  %2 = add nsw i32 %omp_loop.tripcount, -1
  store i32 %2, ptr %p.upperbound, align 4
  store i32 1, ptr %p.stride, align 4
  %omp_global_thread_num4 = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  call void @__kmpc_for_static_init_4u(ptr nonnull @1, i32 %omp_global_thread_num4, i32 34, ptr nonnull %p.lastiter, ptr nonnull %p.lowerbound, ptr nonnull %p.upperbound, ptr nonnull %p.stride, i32 1, i32 0)
  %3 = load i32, ptr %p.lowerbound, align 4
  %4 = load i32, ptr %p.upperbound, align 4
  %reass.sub = sub i32 %4, %3
  %omp_loop.cmp32.not = icmp eq i32 %reass.sub, -1
  br i1 %omp_loop.cmp32.not, label %omp_loop.exit, label %omp_loop.body.lr.ph

omp_loop.body.lr.ph:                              ; preds = %omp.par.entry
  %.unpack = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  %.unpack3 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  %.unpack4 = load i32, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  %.unpack5 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  %.unpack6 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  %.unpack7 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  %.unpack8 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  %.unpack9.unpack.unpack = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  %.unpack9.unpack.unpack11 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  %.unpack9.unpack.unpack12 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  %loadgep_2.repack16 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  %loadgep_2.repack20 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  %loadgep_2.repack24 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  %loadgep_2.repack26.repack28 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  br label %omp_loop.body

omp_loop.header.omp_loop.exit_crit_edge:          ; preds = %omp_loop.body
  %loadgep_2.repack14 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  %loadgep_2.repack18 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  %loadgep_2.repack22 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  %loadgep_2.repack26 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  %loadgep_2.repack26.repack30 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  store ptr %.unpack, ptr %loadgep_2, align 8, !tbaa !8
  store i64 %.unpack3, ptr %loadgep_2.repack14, align 8, !tbaa !8
  store i32 %.unpack4, ptr %loadgep_2.repack16, align 8, !tbaa !8
  store i8 %.unpack5, ptr %loadgep_2.repack18, align 4, !tbaa !8
  store i8 %.unpack6, ptr %loadgep_2.repack20, align 1, !tbaa !8
  store i8 %.unpack7, ptr %loadgep_2.repack22, align 2, !tbaa !8
  store i8 %.unpack8, ptr %loadgep_2.repack24, align 1, !tbaa !8
  store i64 %.unpack9.unpack.unpack, ptr %loadgep_2.repack26, align 8, !tbaa !8
  store i64 %.unpack9.unpack.unpack11, ptr %loadgep_2.repack26.repack28, align 8, !tbaa !8
  store i64 %.unpack9.unpack.unpack12, ptr %loadgep_2.repack26.repack30, align 8, !tbaa !8
  br label %omp_loop.exit

omp_loop.exit:                                    ; preds = %omp_loop.header.omp_loop.exit_crit_edge, %omp.par.entry
  call void @__kmpc_for_static_fini(ptr nonnull @1, i32 %omp_global_thread_num4)
  call void @__kmpc_barrier(ptr nonnull @2, i32 %omp_global_thread_num4)
  ret void

omp_loop.body:                                    ; preds = %omp_loop.body.lr.ph, %omp_loop.body
  %omp_loop.iv33 = phi i32 [ 0, %omp_loop.body.lr.ph ], [ %5, %omp_loop.body ]
  %5 = add nuw i32 %omp_loop.iv33, 1
  %6 = add i32 %5, %3
  %7 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %8 = sitofp i32 %7 to float
  %9 = fdiv contract float 1.000000e+00, %8
  %10 = fpext float %9 to double
  %11 = sext i32 %6 to i64
  %12 = sub i64 %11, %.unpack9.unpack.unpack
  %13 = getelementptr double, ptr %.unpack, i64 %12
  store double %10, ptr %13, align 8, !tbaa !4
  %exitcond.not = icmp eq i32 %omp_loop.iv33, %reass.sub
  br i1 %exitcond.not, label %omp_loop.header.omp_loop.exit_crit_edge, label %omp_loop.body
}

declare ptr @_FortranAioBeginExternalFormattedOutput(ptr, i64, ptr, i32, ptr, i32) local_unnamed_addr

declare zeroext i1 @_FortranAioOutputAscii(ptr, ptr, i64) local_unnamed_addr

declare zeroext i1 @_FortranAioOutputInteger32(ptr, i32) local_unnamed_addr

declare zeroext i1 @_FortranAioOutputReal64(ptr, double) local_unnamed_addr

declare i32 @_FortranAioEndIoStatement(ptr) local_unnamed_addr

; Function Attrs: nounwind
declare i32 @__kmpc_global_thread_num(ptr) local_unnamed_addr #3

; Function Attrs: nounwind
declare void @__kmpc_for_static_init_4u(ptr, i32, i32, ptr, ptr, ptr, ptr, i32, i32) local_unnamed_addr #3

; Function Attrs: nounwind
declare void @__kmpc_for_static_fini(ptr, i32) local_unnamed_addr #3

; Function Attrs: convergent nounwind
declare void @__kmpc_barrier(ptr, i32) local_unnamed_addr #4

; Function Attrs: nounwind
declare !callback !10 void @__kmpc_fork_call(ptr, i32, ptr, ...) local_unnamed_addr #3

; Function Attrs: nocallback nofree nosync nounwind speculatable willreturn memory(none)
declare i32 @llvm.smax.i32(i32, i32) #5

attributes #0 = { mustprogress nofree nounwind willreturn allockind("alloc,uninitialized") allocsize(0) memory(inaccessiblemem: readwrite) "alloc-family"="malloc" }
attributes #1 = { mustprogress nounwind willreturn allockind("free") memory(argmem: readwrite, inaccessiblemem: readwrite) "alloc-family"="malloc" }
attributes #2 = { norecurse nounwind }
attributes #3 = { nounwind }
attributes #4 = { convergent nounwind }
attributes #5 = { nocallback nofree nosync nounwind speculatable willreturn memory(none) }

!llvm.module.flags = !{!0, !1, !2, !3}

!0 = !{i32 2, !"Debug Info Version", i32 3}
!1 = !{i32 7, !"openmp", i32 11}
!2 = !{i32 8, !"PIC Level", i32 2}
!3 = !{i32 7, !"PIE Level", i32 2}
!4 = !{!5, !5, i64 0}
!5 = !{!"any data access", !6, i64 0}
!6 = !{!"any access", !7, i64 0}
!7 = !{!"Flang Type TBAA Root"}
!8 = !{!9, !9, i64 0}
!9 = !{!"descriptor member", !6, i64 0}
!10 = !{!11}
!11 = !{i64 2, i64 -1, i64 -1, i1 true}
*** IR Dump After CoroCleanupPass on [module] ***
; ModuleID = 'FIRModule'
source_filename = "FIRModule"
target datalayout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128"
target triple = "x86_64-unknown-linux-gnu"

%struct.ident_t = type { i32, i32, i32, i32, ptr }

@_QFEarr = internal unnamed_addr global { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } { ptr null, i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), i32 20180515, i8 1, i8 28, i8 2, i8 0, [1 x [3 x i64]] [[3 x i64] [i64 1, i64 0, i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64)]] }
@_QQcl.68815510185ede6107d6524e77abf791 = internal constant [52 x i8] c"/g/g92/rydahl1/flangtests/src/array_descriptors.f90\00"
@_QQcl.28612C69372C612C6531332E36653229 = internal constant [16 x i8] c"(a,i7,a,e13.6e2)"
@_QQcl.54686520726573756C74206F6620286172722831292B61727228 = internal constant [26 x i8] c"The result of (arr(1)+arr("
@_QQcl.2920697320 = internal constant [5 x i8] c") is "
@_QQEnvironmentDefaults = local_unnamed_addr constant ptr null
@0 = private unnamed_addr constant [23 x i8] c";unknown;unknown;0;0;;\00", align 1
@1 = private unnamed_addr constant %struct.ident_t { i32 0, i32 2, i32 0, i32 22, ptr @0 }, align 8
@2 = private unnamed_addr constant %struct.ident_t { i32 0, i32 66, i32 0, i32 22, ptr @0 }, align 8

; Function Attrs: mustprogress nofree nounwind willreturn allockind("alloc,uninitialized") allocsize(0) memory(inaccessiblemem: readwrite)
declare noalias noundef ptr @malloc(i64 noundef) local_unnamed_addr #0

; Function Attrs: mustprogress nounwind willreturn allockind("free") memory(argmem: readwrite, inaccessiblemem: readwrite)
declare void @free(ptr allocptr nocapture noundef) local_unnamed_addr #1

define void @_QQmain() local_unnamed_addr {
entry:
  %structArg = alloca { ptr, ptr }, align 8
  %0 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %1 = alloca i32, align 4
  store i32 1048576, ptr %1, align 4, !tbaa !4
  %2 = tail call dereferenceable_or_null(8388608) ptr @malloc(i64 8388608)
  store ptr %2, ptr @_QFEarr, align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  store i32 20180515, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  store i8 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  store i8 28, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  store i8 2, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  store i8 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  store i64 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  store i64 1048576, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  %omp_global_thread_num = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %1, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %0, ptr %gep_5, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QQmain..omp_par, ptr nonnull %structArg)
  %3 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.68815510185ede6107d6524e77abf791, i32 19)
  %4 = call i1 @_FortranAioOutputAscii(ptr %3, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %5 = load i32, ptr %1, align 4, !tbaa !4
  %6 = call i1 @_FortranAioOutputInteger32(ptr %3, i32 %5)
  %7 = call i1 @_FortranAioOutputAscii(ptr %3, ptr nonnull @_QQcl.2920697320, i64 5)
  %.unpack = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  %.unpack95.unpack.unpack = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  %8 = sub i64 1, %.unpack95.unpack.unpack
  %9 = getelementptr double, ptr %.unpack, i64 %8
  %10 = load double, ptr %9, align 8, !tbaa !4
  %11 = load i32, ptr %1, align 4, !tbaa !4
  %12 = sext i32 %11 to i64
  %13 = sub i64 %12, %.unpack95.unpack.unpack
  %14 = getelementptr double, ptr %.unpack, i64 %13
  %15 = load double, ptr %14, align 8, !tbaa !4
  %16 = fadd contract double %10, %15
  %17 = call i1 @_FortranAioOutputReal64(ptr %3, double %16)
  %18 = call i32 @_FortranAioEndIoStatement(ptr %3)
  %.unpack100 = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  call void @free(ptr %.unpack100)
  store ptr null, ptr @_QFEarr, align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  store i32 20180515, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  store i8 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  store i8 28, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  store i8 2, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  store i8 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  store i64 1, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  store i64 0, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  store i64 8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  ret void
}

; Function Attrs: norecurse nounwind
define internal void @_QQmain..omp_par(ptr noalias nocapture readnone %tid.addr, ptr noalias nocapture readnone %zero.addr, ptr nocapture readonly %0) #2 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %p.lastiter = alloca i32, align 4
  %p.lowerbound = alloca i32, align 4
  %p.upperbound = alloca i32, align 4
  %p.stride = alloca i32, align 4
  %1 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %omp_loop.tripcount = tail call i32 @llvm.smax.i32(i32 %1, i32 0)
  store i32 0, ptr %p.lowerbound, align 4
  %2 = add nsw i32 %omp_loop.tripcount, -1
  store i32 %2, ptr %p.upperbound, align 4
  store i32 1, ptr %p.stride, align 4
  %omp_global_thread_num4 = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  call void @__kmpc_for_static_init_4u(ptr nonnull @1, i32 %omp_global_thread_num4, i32 34, ptr nonnull %p.lastiter, ptr nonnull %p.lowerbound, ptr nonnull %p.upperbound, ptr nonnull %p.stride, i32 1, i32 0)
  %3 = load i32, ptr %p.lowerbound, align 4
  %4 = load i32, ptr %p.upperbound, align 4
  %reass.sub = sub i32 %4, %3
  %omp_loop.cmp32.not = icmp eq i32 %reass.sub, -1
  br i1 %omp_loop.cmp32.not, label %omp_loop.exit, label %omp_loop.body.lr.ph

omp_loop.body.lr.ph:                              ; preds = %omp.par.entry
  %.unpack = load ptr, ptr @_QFEarr, align 16, !tbaa !8
  %.unpack3 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 1), align 8, !tbaa !8
  %.unpack4 = load i32, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 2), align 16, !tbaa !8
  %.unpack5 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 3), align 4, !tbaa !8
  %.unpack6 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 4), align 1, !tbaa !8
  %.unpack7 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 5), align 2, !tbaa !8
  %.unpack8 = load i8, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 6), align 1, !tbaa !8
  %.unpack9.unpack.unpack = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7), align 8, !tbaa !8
  %.unpack9.unpack.unpack11 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 1), align 16, !tbaa !8
  %.unpack9.unpack.unpack12 = load i64, ptr getelementptr inbounds ({ ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr @_QFEarr, i64 0, i32 7, i64 0, i64 2), align 8, !tbaa !8
  %loadgep_2.repack16 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  %loadgep_2.repack20 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  %loadgep_2.repack24 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  %loadgep_2.repack26.repack28 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  br label %omp_loop.body

omp_loop.header.omp_loop.exit_crit_edge:          ; preds = %omp_loop.body
  %loadgep_2.repack14 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  %loadgep_2.repack18 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  %loadgep_2.repack22 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  %loadgep_2.repack26 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  %loadgep_2.repack26.repack30 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  store ptr %.unpack, ptr %loadgep_2, align 8, !tbaa !8
  store i64 %.unpack3, ptr %loadgep_2.repack14, align 8, !tbaa !8
  store i32 %.unpack4, ptr %loadgep_2.repack16, align 8, !tbaa !8
  store i8 %.unpack5, ptr %loadgep_2.repack18, align 4, !tbaa !8
  store i8 %.unpack6, ptr %loadgep_2.repack20, align 1, !tbaa !8
  store i8 %.unpack7, ptr %loadgep_2.repack22, align 2, !tbaa !8
  store i8 %.unpack8, ptr %loadgep_2.repack24, align 1, !tbaa !8
  store i64 %.unpack9.unpack.unpack, ptr %loadgep_2.repack26, align 8, !tbaa !8
  store i64 %.unpack9.unpack.unpack11, ptr %loadgep_2.repack26.repack28, align 8, !tbaa !8
  store i64 %.unpack9.unpack.unpack12, ptr %loadgep_2.repack26.repack30, align 8, !tbaa !8
  br label %omp_loop.exit

omp_loop.exit:                                    ; preds = %omp_loop.header.omp_loop.exit_crit_edge, %omp.par.entry
  call void @__kmpc_for_static_fini(ptr nonnull @1, i32 %omp_global_thread_num4)
  call void @__kmpc_barrier(ptr nonnull @2, i32 %omp_global_thread_num4)
  ret void

omp_loop.body:                                    ; preds = %omp_loop.body.lr.ph, %omp_loop.body
  %omp_loop.iv33 = phi i32 [ 0, %omp_loop.body.lr.ph ], [ %5, %omp_loop.body ]
  %5 = add nuw i32 %omp_loop.iv33, 1
  %6 = add i32 %5, %3
  %7 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %8 = sitofp i32 %7 to float
  %9 = fdiv contract float 1.000000e+00, %8
  %10 = fpext float %9 to double
  %11 = sext i32 %6 to i64
  %12 = sub i64 %11, %.unpack9.unpack.unpack
  %13 = getelementptr double, ptr %.unpack, i64 %12
  store double %10, ptr %13, align 8, !tbaa !4
  %exitcond.not = icmp eq i32 %omp_loop.iv33, %reass.sub
  br i1 %exitcond.not, label %omp_loop.header.omp_loop.exit_crit_edge, label %omp_loop.body
}

declare ptr @_FortranAioBeginExternalFormattedOutput(ptr, i64, ptr, i32, ptr, i32) local_unnamed_addr

declare zeroext i1 @_FortranAioOutputAscii(ptr, ptr, i64) local_unnamed_addr

declare zeroext i1 @_FortranAioOutputInteger32(ptr, i32) local_unnamed_addr

declare zeroext i1 @_FortranAioOutputReal64(ptr, double) local_unnamed_addr

declare i32 @_FortranAioEndIoStatement(ptr) local_unnamed_addr

; Function Attrs: nounwind
declare i32 @__kmpc_global_thread_num(ptr) local_unnamed_addr #3

; Function Attrs: nounwind
declare void @__kmpc_for_static_init_4u(ptr, i32, i32, ptr, ptr, ptr, ptr, i32, i32) local_unnamed_addr #3

; Function Attrs: nounwind
declare void @__kmpc_for_static_fini(ptr, i32) local_unnamed_addr #3

; Function Attrs: convergent nounwind
declare void @__kmpc_barrier(ptr, i32) local_unnamed_addr #4

; Function Attrs: nounwind
declare !callback !10 void @__kmpc_fork_call(ptr, i32, ptr, ...) local_unnamed_addr #3

; Function Attrs: nocallback nofree nosync nounwind speculatable willreturn memory(none)
declare i32 @llvm.smax.i32(i32, i32) #5

attributes #0 = { mustprogress nofree nounwind willreturn allockind("alloc,uninitialized") allocsize(0) memory(inaccessiblemem: readwrite) "alloc-family"="malloc" }
attributes #1 = { mustprogress nounwind willreturn allockind("free") memory(argmem: readwrite, inaccessiblemem: readwrite) "alloc-family"="malloc" }
attributes #2 = { norecurse nounwind }
attributes #3 = { nounwind }
attributes #4 = { convergent nounwind }
attributes #5 = { nocallback nofree nosync nounwind speculatable willreturn memory(none) }

!llvm.module.flags = !{!0, !1, !2, !3}

!0 = !{i32 2, !"Debug Info Version", i32 3}
!1 = !{i32 7, !"openmp", i32 11}
!2 = !{i32 8, !"PIC Level", i32 2}
!3 = !{i32 7, !"PIE Level", i32 2}
!4 = !{!5, !5, i64 0}
!5 = !{!"any data access", !6, i64 0}
!6 = !{!"any access", !7, i64 0}
!7 = !{!"Flang Type TBAA Root"}
!8 = !{!9, !9, i64 0}
!9 = !{!"descriptor member", !6, i64 0}
!10 = !{!11}
!11 = !{i64 2, i64 -1, i64 -1, i1 true}
*** IR Dump After GlobalOptPass on [module] ***
; ModuleID = 'FIRModule'
source_filename = "FIRModule"
target datalayout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128"
target triple = "x86_64-unknown-linux-gnu"

%struct.ident_t = type { i32, i32, i32, i32, ptr }

@_QFEarr.0 = internal unnamed_addr global ptr null
@_QFEarr.8 = internal unnamed_addr global i1 false
@_QQcl.68815510185ede6107d6524e77abf791 = internal constant [52 x i8] c"/g/g92/rydahl1/flangtests/src/array_descriptors.f90\00"
@_QQcl.28612C69372C612C6531332E36653229 = internal constant [16 x i8] c"(a,i7,a,e13.6e2)"
@_QQcl.54686520726573756C74206F6620286172722831292B61727228 = internal constant [26 x i8] c"The result of (arr(1)+arr("
@_QQcl.2920697320 = internal constant [5 x i8] c") is "
@_QQEnvironmentDefaults = local_unnamed_addr constant ptr null
@0 = private unnamed_addr constant [23 x i8] c";unknown;unknown;0;0;;\00", align 1
@1 = private unnamed_addr constant %struct.ident_t { i32 0, i32 2, i32 0, i32 22, ptr @0 }, align 8
@2 = private unnamed_addr constant %struct.ident_t { i32 0, i32 66, i32 0, i32 22, ptr @0 }, align 8

; Function Attrs: mustprogress nofree nounwind willreturn allockind("alloc,uninitialized") allocsize(0) memory(inaccessiblemem: readwrite)
declare noalias noundef ptr @malloc(i64 noundef) local_unnamed_addr #0

; Function Attrs: mustprogress nounwind willreturn allockind("free") memory(argmem: readwrite, inaccessiblemem: readwrite)
declare void @free(ptr allocptr nocapture noundef) local_unnamed_addr #1

define void @_QQmain() local_unnamed_addr {
entry:
  %structArg = alloca { ptr, ptr }, align 8
  %0 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %1 = alloca i32, align 4
  store i32 1048576, ptr %1, align 4, !tbaa !4
  %2 = tail call dereferenceable_or_null(8388608) ptr @malloc(i64 8388608)
  store ptr %2, ptr @_QFEarr.0, align 8, !tbaa !8
  store i1 true, ptr @_QFEarr.8, align 1
  %omp_global_thread_num = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %1, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %0, ptr %gep_5, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QQmain..omp_par, ptr nonnull %structArg)
  %3 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.68815510185ede6107d6524e77abf791, i32 19)
  %4 = call i1 @_FortranAioOutputAscii(ptr %3, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %5 = load i32, ptr %1, align 4, !tbaa !4
  %6 = call i1 @_FortranAioOutputInteger32(ptr %3, i32 %5)
  %7 = call i1 @_FortranAioOutputAscii(ptr %3, ptr nonnull @_QQcl.2920697320, i64 5)
  %.unpack = load ptr, ptr @_QFEarr.0, align 8, !tbaa !8
  %8 = sub i64 1, 1
  %9 = getelementptr double, ptr %.unpack, i64 %8
  %10 = load double, ptr %9, align 8, !tbaa !4
  %11 = load i32, ptr %1, align 4, !tbaa !4
  %12 = sext i32 %11 to i64
  %13 = sub i64 %12, 1
  %14 = getelementptr double, ptr %.unpack, i64 %13
  %15 = load double, ptr %14, align 8, !tbaa !4
  %16 = fadd contract double %10, %15
  %17 = call i1 @_FortranAioOutputReal64(ptr %3, double %16)
  %18 = call i32 @_FortranAioEndIoStatement(ptr %3)
  %.unpack100 = load ptr, ptr @_QFEarr.0, align 8, !tbaa !8
  call void @free(ptr %.unpack100)
  store ptr null, ptr @_QFEarr.0, align 8, !tbaa !8
  store i1 false, ptr @_QFEarr.8, align 1
  ret void
}

; Function Attrs: norecurse nounwind
define internal void @_QQmain..omp_par(ptr noalias nocapture readnone %tid.addr, ptr noalias nocapture readnone %zero.addr, ptr nocapture readonly %0) #2 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %p.lastiter = alloca i32, align 4
  %p.lowerbound = alloca i32, align 4
  %p.upperbound = alloca i32, align 4
  %p.stride = alloca i32, align 4
  %1 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %omp_loop.tripcount = tail call i32 @llvm.smax.i32(i32 %1, i32 0)
  store i32 0, ptr %p.lowerbound, align 4
  %2 = add nsw i32 %omp_loop.tripcount, -1
  store i32 %2, ptr %p.upperbound, align 4
  store i32 1, ptr %p.stride, align 4
  %omp_global_thread_num4 = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  call void @__kmpc_for_static_init_4u(ptr nonnull @1, i32 %omp_global_thread_num4, i32 34, ptr nonnull %p.lastiter, ptr nonnull %p.lowerbound, ptr nonnull %p.upperbound, ptr nonnull %p.stride, i32 1, i32 0)
  %3 = load i32, ptr %p.lowerbound, align 4
  %4 = load i32, ptr %p.upperbound, align 4
  %reass.sub = sub i32 %4, %3
  %omp_loop.cmp32.not = icmp eq i32 %reass.sub, -1
  br i1 %omp_loop.cmp32.not, label %omp_loop.exit, label %omp_loop.body.lr.ph

omp_loop.body.lr.ph:                              ; preds = %omp.par.entry
  %.unpack = load ptr, ptr @_QFEarr.0, align 8, !tbaa !8
  %.unpack9.unpack.unpack11.b = load i1, ptr @_QFEarr.8, align 1
  %.unpack9.unpack.unpack11 = select i1 %.unpack9.unpack.unpack11.b, i64 1048576, i64 0
  %loadgep_2.repack16 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  %loadgep_2.repack20 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  %loadgep_2.repack24 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  %loadgep_2.repack26.repack28 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  br label %omp_loop.body

omp_loop.header.omp_loop.exit_crit_edge:          ; preds = %omp_loop.body
  %loadgep_2.repack14 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  %loadgep_2.repack18 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  %loadgep_2.repack22 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  %loadgep_2.repack26 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  %loadgep_2.repack26.repack30 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  store ptr %.unpack, ptr %loadgep_2, align 8, !tbaa !8
  store i64 8, ptr %loadgep_2.repack14, align 8, !tbaa !8
  store i32 20180515, ptr %loadgep_2.repack16, align 8, !tbaa !8
  store i8 1, ptr %loadgep_2.repack18, align 4, !tbaa !8
  store i8 28, ptr %loadgep_2.repack20, align 1, !tbaa !8
  store i8 2, ptr %loadgep_2.repack22, align 2, !tbaa !8
  store i8 0, ptr %loadgep_2.repack24, align 1, !tbaa !8
  store i64 1, ptr %loadgep_2.repack26, align 8, !tbaa !8
  store i64 %.unpack9.unpack.unpack11, ptr %loadgep_2.repack26.repack28, align 8, !tbaa !8
  store i64 8, ptr %loadgep_2.repack26.repack30, align 8, !tbaa !8
  br label %omp_loop.exit

omp_loop.exit:                                    ; preds = %omp_loop.header.omp_loop.exit_crit_edge, %omp.par.entry
  call void @__kmpc_for_static_fini(ptr nonnull @1, i32 %omp_global_thread_num4)
  call void @__kmpc_barrier(ptr nonnull @2, i32 %omp_global_thread_num4)
  ret void

omp_loop.body:                                    ; preds = %omp_loop.body.lr.ph, %omp_loop.body
  %omp_loop.iv33 = phi i32 [ 0, %omp_loop.body.lr.ph ], [ %5, %omp_loop.body ]
  %5 = add nuw i32 %omp_loop.iv33, 1
  %6 = add i32 %5, %3
  %7 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %8 = sitofp i32 %7 to float
  %9 = fdiv contract float 1.000000e+00, %8
  %10 = fpext float %9 to double
  %11 = sext i32 %6 to i64
  %12 = sub i64 %11, 1
  %13 = getelementptr double, ptr %.unpack, i64 %12
  store double %10, ptr %13, align 8, !tbaa !4
  %exitcond.not = icmp eq i32 %omp_loop.iv33, %reass.sub
  br i1 %exitcond.not, label %omp_loop.header.omp_loop.exit_crit_edge, label %omp_loop.body
}

declare ptr @_FortranAioBeginExternalFormattedOutput(ptr, i64, ptr, i32, ptr, i32) local_unnamed_addr

declare zeroext i1 @_FortranAioOutputAscii(ptr, ptr, i64) local_unnamed_addr

declare zeroext i1 @_FortranAioOutputInteger32(ptr, i32) local_unnamed_addr

declare zeroext i1 @_FortranAioOutputReal64(ptr, double) local_unnamed_addr

declare i32 @_FortranAioEndIoStatement(ptr) local_unnamed_addr

; Function Attrs: nounwind
declare i32 @__kmpc_global_thread_num(ptr) local_unnamed_addr #3

; Function Attrs: nounwind
declare void @__kmpc_for_static_init_4u(ptr, i32, i32, ptr, ptr, ptr, ptr, i32, i32) local_unnamed_addr #3

; Function Attrs: nounwind
declare void @__kmpc_for_static_fini(ptr, i32) local_unnamed_addr #3

; Function Attrs: convergent nounwind
declare void @__kmpc_barrier(ptr, i32) local_unnamed_addr #4

; Function Attrs: nounwind
declare !callback !10 void @__kmpc_fork_call(ptr, i32, ptr, ...) local_unnamed_addr #3

; Function Attrs: nocallback nofree nosync nounwind speculatable willreturn memory(none)
declare i32 @llvm.smax.i32(i32, i32) #5

attributes #0 = { mustprogress nofree nounwind willreturn allockind("alloc,uninitialized") allocsize(0) memory(inaccessiblemem: readwrite) "alloc-family"="malloc" }
attributes #1 = { mustprogress nounwind willreturn allockind("free") memory(argmem: readwrite, inaccessiblemem: readwrite) "alloc-family"="malloc" }
attributes #2 = { norecurse nounwind }
attributes #3 = { nounwind }
attributes #4 = { convergent nounwind }
attributes #5 = { nocallback nofree nosync nounwind speculatable willreturn memory(none) }

!llvm.module.flags = !{!0, !1, !2, !3}

!0 = !{i32 2, !"Debug Info Version", i32 3}
!1 = !{i32 7, !"openmp", i32 11}
!2 = !{i32 8, !"PIC Level", i32 2}
!3 = !{i32 7, !"PIE Level", i32 2}
!4 = !{!5, !5, i64 0}
!5 = !{!"any data access", !6, i64 0}
!6 = !{!"any access", !7, i64 0}
!7 = !{!"Flang Type TBAA Root"}
!8 = !{!9, !9, i64 0}
!9 = !{!"descriptor member", !6, i64 0}
!10 = !{!11}
!11 = !{i64 2, i64 -1, i64 -1, i1 true}
*** IR Dump After GlobalDCEPass on [module] ***
; ModuleID = 'FIRModule'
source_filename = "FIRModule"
target datalayout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128"
target triple = "x86_64-unknown-linux-gnu"

%struct.ident_t = type { i32, i32, i32, i32, ptr }

@_QFEarr.0 = internal unnamed_addr global ptr null
@_QFEarr.8 = internal unnamed_addr global i1 false
@_QQcl.68815510185ede6107d6524e77abf791 = internal constant [52 x i8] c"/g/g92/rydahl1/flangtests/src/array_descriptors.f90\00"
@_QQcl.28612C69372C612C6531332E36653229 = internal constant [16 x i8] c"(a,i7,a,e13.6e2)"
@_QQcl.54686520726573756C74206F6620286172722831292B61727228 = internal constant [26 x i8] c"The result of (arr(1)+arr("
@_QQcl.2920697320 = internal constant [5 x i8] c") is "
@_QQEnvironmentDefaults = local_unnamed_addr constant ptr null
@0 = private unnamed_addr constant [23 x i8] c";unknown;unknown;0;0;;\00", align 1
@1 = private unnamed_addr constant %struct.ident_t { i32 0, i32 2, i32 0, i32 22, ptr @0 }, align 8
@2 = private unnamed_addr constant %struct.ident_t { i32 0, i32 66, i32 0, i32 22, ptr @0 }, align 8

; Function Attrs: mustprogress nofree nounwind willreturn allockind("alloc,uninitialized") allocsize(0) memory(inaccessiblemem: readwrite)
declare noalias noundef ptr @malloc(i64 noundef) local_unnamed_addr #0

; Function Attrs: mustprogress nounwind willreturn allockind("free") memory(argmem: readwrite, inaccessiblemem: readwrite)
declare void @free(ptr allocptr nocapture noundef) local_unnamed_addr #1

define void @_QQmain() local_unnamed_addr {
entry:
  %structArg = alloca { ptr, ptr }, align 8
  %0 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %1 = alloca i32, align 4
  store i32 1048576, ptr %1, align 4, !tbaa !4
  %2 = tail call dereferenceable_or_null(8388608) ptr @malloc(i64 8388608)
  store ptr %2, ptr @_QFEarr.0, align 8, !tbaa !8
  store i1 true, ptr @_QFEarr.8, align 1
  %omp_global_thread_num = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %1, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %0, ptr %gep_5, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QQmain..omp_par, ptr nonnull %structArg)
  %3 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.68815510185ede6107d6524e77abf791, i32 19)
  %4 = call i1 @_FortranAioOutputAscii(ptr %3, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %5 = load i32, ptr %1, align 4, !tbaa !4
  %6 = call i1 @_FortranAioOutputInteger32(ptr %3, i32 %5)
  %7 = call i1 @_FortranAioOutputAscii(ptr %3, ptr nonnull @_QQcl.2920697320, i64 5)
  %.unpack = load ptr, ptr @_QFEarr.0, align 8, !tbaa !8
  %8 = sub i64 1, 1
  %9 = getelementptr double, ptr %.unpack, i64 %8
  %10 = load double, ptr %9, align 8, !tbaa !4
  %11 = load i32, ptr %1, align 4, !tbaa !4
  %12 = sext i32 %11 to i64
  %13 = sub i64 %12, 1
  %14 = getelementptr double, ptr %.unpack, i64 %13
  %15 = load double, ptr %14, align 8, !tbaa !4
  %16 = fadd contract double %10, %15
  %17 = call i1 @_FortranAioOutputReal64(ptr %3, double %16)
  %18 = call i32 @_FortranAioEndIoStatement(ptr %3)
  %.unpack100 = load ptr, ptr @_QFEarr.0, align 8, !tbaa !8
  call void @free(ptr %.unpack100)
  store ptr null, ptr @_QFEarr.0, align 8, !tbaa !8
  store i1 false, ptr @_QFEarr.8, align 1
  ret void
}

; Function Attrs: norecurse nounwind
define internal void @_QQmain..omp_par(ptr noalias nocapture readnone %tid.addr, ptr noalias nocapture readnone %zero.addr, ptr nocapture readonly %0) #2 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %p.lastiter = alloca i32, align 4
  %p.lowerbound = alloca i32, align 4
  %p.upperbound = alloca i32, align 4
  %p.stride = alloca i32, align 4
  %1 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %omp_loop.tripcount = tail call i32 @llvm.smax.i32(i32 %1, i32 0)
  store i32 0, ptr %p.lowerbound, align 4
  %2 = add nsw i32 %omp_loop.tripcount, -1
  store i32 %2, ptr %p.upperbound, align 4
  store i32 1, ptr %p.stride, align 4
  %omp_global_thread_num4 = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  call void @__kmpc_for_static_init_4u(ptr nonnull @1, i32 %omp_global_thread_num4, i32 34, ptr nonnull %p.lastiter, ptr nonnull %p.lowerbound, ptr nonnull %p.upperbound, ptr nonnull %p.stride, i32 1, i32 0)
  %3 = load i32, ptr %p.lowerbound, align 4
  %4 = load i32, ptr %p.upperbound, align 4
  %reass.sub = sub i32 %4, %3
  %omp_loop.cmp32.not = icmp eq i32 %reass.sub, -1
  br i1 %omp_loop.cmp32.not, label %omp_loop.exit, label %omp_loop.body.lr.ph

omp_loop.body.lr.ph:                              ; preds = %omp.par.entry
  %.unpack = load ptr, ptr @_QFEarr.0, align 8, !tbaa !8
  %.unpack9.unpack.unpack11.b = load i1, ptr @_QFEarr.8, align 1
  %.unpack9.unpack.unpack11 = select i1 %.unpack9.unpack.unpack11.b, i64 1048576, i64 0
  %loadgep_2.repack16 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  %loadgep_2.repack20 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  %loadgep_2.repack24 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  %loadgep_2.repack26.repack28 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  br label %omp_loop.body

omp_loop.header.omp_loop.exit_crit_edge:          ; preds = %omp_loop.body
  %loadgep_2.repack14 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  %loadgep_2.repack18 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  %loadgep_2.repack22 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  %loadgep_2.repack26 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  %loadgep_2.repack26.repack30 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  store ptr %.unpack, ptr %loadgep_2, align 8, !tbaa !8
  store i64 8, ptr %loadgep_2.repack14, align 8, !tbaa !8
  store i32 20180515, ptr %loadgep_2.repack16, align 8, !tbaa !8
  store i8 1, ptr %loadgep_2.repack18, align 4, !tbaa !8
  store i8 28, ptr %loadgep_2.repack20, align 1, !tbaa !8
  store i8 2, ptr %loadgep_2.repack22, align 2, !tbaa !8
  store i8 0, ptr %loadgep_2.repack24, align 1, !tbaa !8
  store i64 1, ptr %loadgep_2.repack26, align 8, !tbaa !8
  store i64 %.unpack9.unpack.unpack11, ptr %loadgep_2.repack26.repack28, align 8, !tbaa !8
  store i64 8, ptr %loadgep_2.repack26.repack30, align 8, !tbaa !8
  br label %omp_loop.exit

omp_loop.exit:                                    ; preds = %omp_loop.header.omp_loop.exit_crit_edge, %omp.par.entry
  call void @__kmpc_for_static_fini(ptr nonnull @1, i32 %omp_global_thread_num4)
  call void @__kmpc_barrier(ptr nonnull @2, i32 %omp_global_thread_num4)
  ret void

omp_loop.body:                                    ; preds = %omp_loop.body.lr.ph, %omp_loop.body
  %omp_loop.iv33 = phi i32 [ 0, %omp_loop.body.lr.ph ], [ %5, %omp_loop.body ]
  %5 = add nuw i32 %omp_loop.iv33, 1
  %6 = add i32 %5, %3
  %7 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %8 = sitofp i32 %7 to float
  %9 = fdiv contract float 1.000000e+00, %8
  %10 = fpext float %9 to double
  %11 = sext i32 %6 to i64
  %12 = sub i64 %11, 1
  %13 = getelementptr double, ptr %.unpack, i64 %12
  store double %10, ptr %13, align 8, !tbaa !4
  %exitcond.not = icmp eq i32 %omp_loop.iv33, %reass.sub
  br i1 %exitcond.not, label %omp_loop.header.omp_loop.exit_crit_edge, label %omp_loop.body
}

declare ptr @_FortranAioBeginExternalFormattedOutput(ptr, i64, ptr, i32, ptr, i32) local_unnamed_addr

declare zeroext i1 @_FortranAioOutputAscii(ptr, ptr, i64) local_unnamed_addr

declare zeroext i1 @_FortranAioOutputInteger32(ptr, i32) local_unnamed_addr

declare zeroext i1 @_FortranAioOutputReal64(ptr, double) local_unnamed_addr

declare i32 @_FortranAioEndIoStatement(ptr) local_unnamed_addr

; Function Attrs: nounwind
declare i32 @__kmpc_global_thread_num(ptr) local_unnamed_addr #3

; Function Attrs: nounwind
declare void @__kmpc_for_static_init_4u(ptr, i32, i32, ptr, ptr, ptr, ptr, i32, i32) local_unnamed_addr #3

; Function Attrs: nounwind
declare void @__kmpc_for_static_fini(ptr, i32) local_unnamed_addr #3

; Function Attrs: convergent nounwind
declare void @__kmpc_barrier(ptr, i32) local_unnamed_addr #4

; Function Attrs: nounwind
declare !callback !10 void @__kmpc_fork_call(ptr, i32, ptr, ...) local_unnamed_addr #3

; Function Attrs: nocallback nofree nosync nounwind speculatable willreturn memory(none)
declare i32 @llvm.smax.i32(i32, i32) #5

attributes #0 = { mustprogress nofree nounwind willreturn allockind("alloc,uninitialized") allocsize(0) memory(inaccessiblemem: readwrite) "alloc-family"="malloc" }
attributes #1 = { mustprogress nounwind willreturn allockind("free") memory(argmem: readwrite, inaccessiblemem: readwrite) "alloc-family"="malloc" }
attributes #2 = { norecurse nounwind }
attributes #3 = { nounwind }
attributes #4 = { convergent nounwind }
attributes #5 = { nocallback nofree nosync nounwind speculatable willreturn memory(none) }

!llvm.module.flags = !{!0, !1, !2, !3}

!0 = !{i32 2, !"Debug Info Version", i32 3}
!1 = !{i32 7, !"openmp", i32 11}
!2 = !{i32 8, !"PIC Level", i32 2}
!3 = !{i32 7, !"PIE Level", i32 2}
!4 = !{!5, !5, i64 0}
!5 = !{!"any data access", !6, i64 0}
!6 = !{!"any access", !7, i64 0}
!7 = !{!"Flang Type TBAA Root"}
!8 = !{!9, !9, i64 0}
!9 = !{!"descriptor member", !6, i64 0}
!10 = !{!11}
!11 = !{i64 2, i64 -1, i64 -1, i1 true}
*** IR Dump After EliminateAvailableExternallyPass on [module] ***
; ModuleID = 'FIRModule'
source_filename = "FIRModule"
target datalayout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128"
target triple = "x86_64-unknown-linux-gnu"

%struct.ident_t = type { i32, i32, i32, i32, ptr }

@_QFEarr.0 = internal unnamed_addr global ptr null
@_QFEarr.8 = internal unnamed_addr global i1 false
@_QQcl.68815510185ede6107d6524e77abf791 = internal constant [52 x i8] c"/g/g92/rydahl1/flangtests/src/array_descriptors.f90\00"
@_QQcl.28612C69372C612C6531332E36653229 = internal constant [16 x i8] c"(a,i7,a,e13.6e2)"
@_QQcl.54686520726573756C74206F6620286172722831292B61727228 = internal constant [26 x i8] c"The result of (arr(1)+arr("
@_QQcl.2920697320 = internal constant [5 x i8] c") is "
@_QQEnvironmentDefaults = local_unnamed_addr constant ptr null
@0 = private unnamed_addr constant [23 x i8] c";unknown;unknown;0;0;;\00", align 1
@1 = private unnamed_addr constant %struct.ident_t { i32 0, i32 2, i32 0, i32 22, ptr @0 }, align 8
@2 = private unnamed_addr constant %struct.ident_t { i32 0, i32 66, i32 0, i32 22, ptr @0 }, align 8

; Function Attrs: mustprogress nofree nounwind willreturn allockind("alloc,uninitialized") allocsize(0) memory(inaccessiblemem: readwrite)
declare noalias noundef ptr @malloc(i64 noundef) local_unnamed_addr #0

; Function Attrs: mustprogress nounwind willreturn allockind("free") memory(argmem: readwrite, inaccessiblemem: readwrite)
declare void @free(ptr allocptr nocapture noundef) local_unnamed_addr #1

define void @_QQmain() local_unnamed_addr {
entry:
  %structArg = alloca { ptr, ptr }, align 8
  %0 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %1 = alloca i32, align 4
  store i32 1048576, ptr %1, align 4, !tbaa !4
  %2 = tail call dereferenceable_or_null(8388608) ptr @malloc(i64 8388608)
  store ptr %2, ptr @_QFEarr.0, align 8, !tbaa !8
  store i1 true, ptr @_QFEarr.8, align 1
  %omp_global_thread_num = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %1, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %0, ptr %gep_5, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QQmain..omp_par, ptr nonnull %structArg)
  %3 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.68815510185ede6107d6524e77abf791, i32 19)
  %4 = call i1 @_FortranAioOutputAscii(ptr %3, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %5 = load i32, ptr %1, align 4, !tbaa !4
  %6 = call i1 @_FortranAioOutputInteger32(ptr %3, i32 %5)
  %7 = call i1 @_FortranAioOutputAscii(ptr %3, ptr nonnull @_QQcl.2920697320, i64 5)
  %.unpack = load ptr, ptr @_QFEarr.0, align 8, !tbaa !8
  %8 = sub i64 1, 1
  %9 = getelementptr double, ptr %.unpack, i64 %8
  %10 = load double, ptr %9, align 8, !tbaa !4
  %11 = load i32, ptr %1, align 4, !tbaa !4
  %12 = sext i32 %11 to i64
  %13 = sub i64 %12, 1
  %14 = getelementptr double, ptr %.unpack, i64 %13
  %15 = load double, ptr %14, align 8, !tbaa !4
  %16 = fadd contract double %10, %15
  %17 = call i1 @_FortranAioOutputReal64(ptr %3, double %16)
  %18 = call i32 @_FortranAioEndIoStatement(ptr %3)
  %.unpack100 = load ptr, ptr @_QFEarr.0, align 8, !tbaa !8
  call void @free(ptr %.unpack100)
  store ptr null, ptr @_QFEarr.0, align 8, !tbaa !8
  store i1 false, ptr @_QFEarr.8, align 1
  ret void
}

; Function Attrs: norecurse nounwind
define internal void @_QQmain..omp_par(ptr noalias nocapture readnone %tid.addr, ptr noalias nocapture readnone %zero.addr, ptr nocapture readonly %0) #2 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %p.lastiter = alloca i32, align 4
  %p.lowerbound = alloca i32, align 4
  %p.upperbound = alloca i32, align 4
  %p.stride = alloca i32, align 4
  %1 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %omp_loop.tripcount = tail call i32 @llvm.smax.i32(i32 %1, i32 0)
  store i32 0, ptr %p.lowerbound, align 4
  %2 = add nsw i32 %omp_loop.tripcount, -1
  store i32 %2, ptr %p.upperbound, align 4
  store i32 1, ptr %p.stride, align 4
  %omp_global_thread_num4 = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  call void @__kmpc_for_static_init_4u(ptr nonnull @1, i32 %omp_global_thread_num4, i32 34, ptr nonnull %p.lastiter, ptr nonnull %p.lowerbound, ptr nonnull %p.upperbound, ptr nonnull %p.stride, i32 1, i32 0)
  %3 = load i32, ptr %p.lowerbound, align 4
  %4 = load i32, ptr %p.upperbound, align 4
  %reass.sub = sub i32 %4, %3
  %omp_loop.cmp32.not = icmp eq i32 %reass.sub, -1
  br i1 %omp_loop.cmp32.not, label %omp_loop.exit, label %omp_loop.body.lr.ph

omp_loop.body.lr.ph:                              ; preds = %omp.par.entry
  %.unpack = load ptr, ptr @_QFEarr.0, align 8, !tbaa !8
  %.unpack9.unpack.unpack11.b = load i1, ptr @_QFEarr.8, align 1
  %.unpack9.unpack.unpack11 = select i1 %.unpack9.unpack.unpack11.b, i64 1048576, i64 0
  %loadgep_2.repack16 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  %loadgep_2.repack20 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  %loadgep_2.repack24 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  %loadgep_2.repack26.repack28 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  br label %omp_loop.body

omp_loop.header.omp_loop.exit_crit_edge:          ; preds = %omp_loop.body
  %loadgep_2.repack14 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  %loadgep_2.repack18 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  %loadgep_2.repack22 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  %loadgep_2.repack26 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  %loadgep_2.repack26.repack30 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  store ptr %.unpack, ptr %loadgep_2, align 8, !tbaa !8
  store i64 8, ptr %loadgep_2.repack14, align 8, !tbaa !8
  store i32 20180515, ptr %loadgep_2.repack16, align 8, !tbaa !8
  store i8 1, ptr %loadgep_2.repack18, align 4, !tbaa !8
  store i8 28, ptr %loadgep_2.repack20, align 1, !tbaa !8
  store i8 2, ptr %loadgep_2.repack22, align 2, !tbaa !8
  store i8 0, ptr %loadgep_2.repack24, align 1, !tbaa !8
  store i64 1, ptr %loadgep_2.repack26, align 8, !tbaa !8
  store i64 %.unpack9.unpack.unpack11, ptr %loadgep_2.repack26.repack28, align 8, !tbaa !8
  store i64 8, ptr %loadgep_2.repack26.repack30, align 8, !tbaa !8
  br label %omp_loop.exit

omp_loop.exit:                                    ; preds = %omp_loop.header.omp_loop.exit_crit_edge, %omp.par.entry
  call void @__kmpc_for_static_fini(ptr nonnull @1, i32 %omp_global_thread_num4)
  call void @__kmpc_barrier(ptr nonnull @2, i32 %omp_global_thread_num4)
  ret void

omp_loop.body:                                    ; preds = %omp_loop.body.lr.ph, %omp_loop.body
  %omp_loop.iv33 = phi i32 [ 0, %omp_loop.body.lr.ph ], [ %5, %omp_loop.body ]
  %5 = add nuw i32 %omp_loop.iv33, 1
  %6 = add i32 %5, %3
  %7 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %8 = sitofp i32 %7 to float
  %9 = fdiv contract float 1.000000e+00, %8
  %10 = fpext float %9 to double
  %11 = sext i32 %6 to i64
  %12 = sub i64 %11, 1
  %13 = getelementptr double, ptr %.unpack, i64 %12
  store double %10, ptr %13, align 8, !tbaa !4
  %exitcond.not = icmp eq i32 %omp_loop.iv33, %reass.sub
  br i1 %exitcond.not, label %omp_loop.header.omp_loop.exit_crit_edge, label %omp_loop.body
}

declare ptr @_FortranAioBeginExternalFormattedOutput(ptr, i64, ptr, i32, ptr, i32) local_unnamed_addr

declare zeroext i1 @_FortranAioOutputAscii(ptr, ptr, i64) local_unnamed_addr

declare zeroext i1 @_FortranAioOutputInteger32(ptr, i32) local_unnamed_addr

declare zeroext i1 @_FortranAioOutputReal64(ptr, double) local_unnamed_addr

declare i32 @_FortranAioEndIoStatement(ptr) local_unnamed_addr

; Function Attrs: nounwind
declare i32 @__kmpc_global_thread_num(ptr) local_unnamed_addr #3

; Function Attrs: nounwind
declare void @__kmpc_for_static_init_4u(ptr, i32, i32, ptr, ptr, ptr, ptr, i32, i32) local_unnamed_addr #3

; Function Attrs: nounwind
declare void @__kmpc_for_static_fini(ptr, i32) local_unnamed_addr #3

; Function Attrs: convergent nounwind
declare void @__kmpc_barrier(ptr, i32) local_unnamed_addr #4

; Function Attrs: nounwind
declare !callback !10 void @__kmpc_fork_call(ptr, i32, ptr, ...) local_unnamed_addr #3

; Function Attrs: nocallback nofree nosync nounwind speculatable willreturn memory(none)
declare i32 @llvm.smax.i32(i32, i32) #5

attributes #0 = { mustprogress nofree nounwind willreturn allockind("alloc,uninitialized") allocsize(0) memory(inaccessiblemem: readwrite) "alloc-family"="malloc" }
attributes #1 = { mustprogress nounwind willreturn allockind("free") memory(argmem: readwrite, inaccessiblemem: readwrite) "alloc-family"="malloc" }
attributes #2 = { norecurse nounwind }
attributes #3 = { nounwind }
attributes #4 = { convergent nounwind }
attributes #5 = { nocallback nofree nosync nounwind speculatable willreturn memory(none) }

!llvm.module.flags = !{!0, !1, !2, !3}

!0 = !{i32 2, !"Debug Info Version", i32 3}
!1 = !{i32 7, !"openmp", i32 11}
!2 = !{i32 8, !"PIC Level", i32 2}
!3 = !{i32 7, !"PIE Level", i32 2}
!4 = !{!5, !5, i64 0}
!5 = !{!"any data access", !6, i64 0}
!6 = !{!"any access", !7, i64 0}
!7 = !{!"Flang Type TBAA Root"}
!8 = !{!9, !9, i64 0}
!9 = !{!"descriptor member", !6, i64 0}
!10 = !{!11}
!11 = !{i64 2, i64 -1, i64 -1, i1 true}
*** IR Dump After ReversePostOrderFunctionAttrsPass on [module] ***
; ModuleID = 'FIRModule'
source_filename = "FIRModule"
target datalayout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128"
target triple = "x86_64-unknown-linux-gnu"

%struct.ident_t = type { i32, i32, i32, i32, ptr }

@_QFEarr.0 = internal unnamed_addr global ptr null
@_QFEarr.8 = internal unnamed_addr global i1 false
@_QQcl.68815510185ede6107d6524e77abf791 = internal constant [52 x i8] c"/g/g92/rydahl1/flangtests/src/array_descriptors.f90\00"
@_QQcl.28612C69372C612C6531332E36653229 = internal constant [16 x i8] c"(a,i7,a,e13.6e2)"
@_QQcl.54686520726573756C74206F6620286172722831292B61727228 = internal constant [26 x i8] c"The result of (arr(1)+arr("
@_QQcl.2920697320 = internal constant [5 x i8] c") is "
@_QQEnvironmentDefaults = local_unnamed_addr constant ptr null
@0 = private unnamed_addr constant [23 x i8] c";unknown;unknown;0;0;;\00", align 1
@1 = private unnamed_addr constant %struct.ident_t { i32 0, i32 2, i32 0, i32 22, ptr @0 }, align 8
@2 = private unnamed_addr constant %struct.ident_t { i32 0, i32 66, i32 0, i32 22, ptr @0 }, align 8

; Function Attrs: mustprogress nofree nounwind willreturn allockind("alloc,uninitialized") allocsize(0) memory(inaccessiblemem: readwrite)
declare noalias noundef ptr @malloc(i64 noundef) local_unnamed_addr #0

; Function Attrs: mustprogress nounwind willreturn allockind("free") memory(argmem: readwrite, inaccessiblemem: readwrite)
declare void @free(ptr allocptr nocapture noundef) local_unnamed_addr #1

define void @_QQmain() local_unnamed_addr {
entry:
  %structArg = alloca { ptr, ptr }, align 8
  %0 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %1 = alloca i32, align 4
  store i32 1048576, ptr %1, align 4, !tbaa !4
  %2 = tail call dereferenceable_or_null(8388608) ptr @malloc(i64 8388608)
  store ptr %2, ptr @_QFEarr.0, align 8, !tbaa !8
  store i1 true, ptr @_QFEarr.8, align 1
  %omp_global_thread_num = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %1, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %0, ptr %gep_5, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QQmain..omp_par, ptr nonnull %structArg)
  %3 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.68815510185ede6107d6524e77abf791, i32 19)
  %4 = call i1 @_FortranAioOutputAscii(ptr %3, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %5 = load i32, ptr %1, align 4, !tbaa !4
  %6 = call i1 @_FortranAioOutputInteger32(ptr %3, i32 %5)
  %7 = call i1 @_FortranAioOutputAscii(ptr %3, ptr nonnull @_QQcl.2920697320, i64 5)
  %.unpack = load ptr, ptr @_QFEarr.0, align 8, !tbaa !8
  %8 = sub i64 1, 1
  %9 = getelementptr double, ptr %.unpack, i64 %8
  %10 = load double, ptr %9, align 8, !tbaa !4
  %11 = load i32, ptr %1, align 4, !tbaa !4
  %12 = sext i32 %11 to i64
  %13 = sub i64 %12, 1
  %14 = getelementptr double, ptr %.unpack, i64 %13
  %15 = load double, ptr %14, align 8, !tbaa !4
  %16 = fadd contract double %10, %15
  %17 = call i1 @_FortranAioOutputReal64(ptr %3, double %16)
  %18 = call i32 @_FortranAioEndIoStatement(ptr %3)
  %.unpack100 = load ptr, ptr @_QFEarr.0, align 8, !tbaa !8
  call void @free(ptr %.unpack100)
  store ptr null, ptr @_QFEarr.0, align 8, !tbaa !8
  store i1 false, ptr @_QFEarr.8, align 1
  ret void
}

; Function Attrs: norecurse nounwind
define internal void @_QQmain..omp_par(ptr noalias nocapture readnone %tid.addr, ptr noalias nocapture readnone %zero.addr, ptr nocapture readonly %0) #2 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %p.lastiter = alloca i32, align 4
  %p.lowerbound = alloca i32, align 4
  %p.upperbound = alloca i32, align 4
  %p.stride = alloca i32, align 4
  %1 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %omp_loop.tripcount = tail call i32 @llvm.smax.i32(i32 %1, i32 0)
  store i32 0, ptr %p.lowerbound, align 4
  %2 = add nsw i32 %omp_loop.tripcount, -1
  store i32 %2, ptr %p.upperbound, align 4
  store i32 1, ptr %p.stride, align 4
  %omp_global_thread_num4 = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  call void @__kmpc_for_static_init_4u(ptr nonnull @1, i32 %omp_global_thread_num4, i32 34, ptr nonnull %p.lastiter, ptr nonnull %p.lowerbound, ptr nonnull %p.upperbound, ptr nonnull %p.stride, i32 1, i32 0)
  %3 = load i32, ptr %p.lowerbound, align 4
  %4 = load i32, ptr %p.upperbound, align 4
  %reass.sub = sub i32 %4, %3
  %omp_loop.cmp32.not = icmp eq i32 %reass.sub, -1
  br i1 %omp_loop.cmp32.not, label %omp_loop.exit, label %omp_loop.body.lr.ph

omp_loop.body.lr.ph:                              ; preds = %omp.par.entry
  %.unpack = load ptr, ptr @_QFEarr.0, align 8, !tbaa !8
  %.unpack9.unpack.unpack11.b = load i1, ptr @_QFEarr.8, align 1
  %.unpack9.unpack.unpack11 = select i1 %.unpack9.unpack.unpack11.b, i64 1048576, i64 0
  %loadgep_2.repack16 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  %loadgep_2.repack20 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  %loadgep_2.repack24 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  %loadgep_2.repack26.repack28 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  br label %omp_loop.body

omp_loop.header.omp_loop.exit_crit_edge:          ; preds = %omp_loop.body
  %loadgep_2.repack14 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  %loadgep_2.repack18 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  %loadgep_2.repack22 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  %loadgep_2.repack26 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  %loadgep_2.repack26.repack30 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  store ptr %.unpack, ptr %loadgep_2, align 8, !tbaa !8
  store i64 8, ptr %loadgep_2.repack14, align 8, !tbaa !8
  store i32 20180515, ptr %loadgep_2.repack16, align 8, !tbaa !8
  store i8 1, ptr %loadgep_2.repack18, align 4, !tbaa !8
  store i8 28, ptr %loadgep_2.repack20, align 1, !tbaa !8
  store i8 2, ptr %loadgep_2.repack22, align 2, !tbaa !8
  store i8 0, ptr %loadgep_2.repack24, align 1, !tbaa !8
  store i64 1, ptr %loadgep_2.repack26, align 8, !tbaa !8
  store i64 %.unpack9.unpack.unpack11, ptr %loadgep_2.repack26.repack28, align 8, !tbaa !8
  store i64 8, ptr %loadgep_2.repack26.repack30, align 8, !tbaa !8
  br label %omp_loop.exit

omp_loop.exit:                                    ; preds = %omp_loop.header.omp_loop.exit_crit_edge, %omp.par.entry
  call void @__kmpc_for_static_fini(ptr nonnull @1, i32 %omp_global_thread_num4)
  call void @__kmpc_barrier(ptr nonnull @2, i32 %omp_global_thread_num4)
  ret void

omp_loop.body:                                    ; preds = %omp_loop.body.lr.ph, %omp_loop.body
  %omp_loop.iv33 = phi i32 [ 0, %omp_loop.body.lr.ph ], [ %5, %omp_loop.body ]
  %5 = add nuw i32 %omp_loop.iv33, 1
  %6 = add i32 %5, %3
  %7 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %8 = sitofp i32 %7 to float
  %9 = fdiv contract float 1.000000e+00, %8
  %10 = fpext float %9 to double
  %11 = sext i32 %6 to i64
  %12 = sub i64 %11, 1
  %13 = getelementptr double, ptr %.unpack, i64 %12
  store double %10, ptr %13, align 8, !tbaa !4
  %exitcond.not = icmp eq i32 %omp_loop.iv33, %reass.sub
  br i1 %exitcond.not, label %omp_loop.header.omp_loop.exit_crit_edge, label %omp_loop.body
}

declare ptr @_FortranAioBeginExternalFormattedOutput(ptr, i64, ptr, i32, ptr, i32) local_unnamed_addr

declare zeroext i1 @_FortranAioOutputAscii(ptr, ptr, i64) local_unnamed_addr

declare zeroext i1 @_FortranAioOutputInteger32(ptr, i32) local_unnamed_addr

declare zeroext i1 @_FortranAioOutputReal64(ptr, double) local_unnamed_addr

declare i32 @_FortranAioEndIoStatement(ptr) local_unnamed_addr

; Function Attrs: nounwind
declare i32 @__kmpc_global_thread_num(ptr) local_unnamed_addr #3

; Function Attrs: nounwind
declare void @__kmpc_for_static_init_4u(ptr, i32, i32, ptr, ptr, ptr, ptr, i32, i32) local_unnamed_addr #3

; Function Attrs: nounwind
declare void @__kmpc_for_static_fini(ptr, i32) local_unnamed_addr #3

; Function Attrs: convergent nounwind
declare void @__kmpc_barrier(ptr, i32) local_unnamed_addr #4

; Function Attrs: nounwind
declare !callback !10 void @__kmpc_fork_call(ptr, i32, ptr, ...) local_unnamed_addr #3

; Function Attrs: nocallback nofree nosync nounwind speculatable willreturn memory(none)
declare i32 @llvm.smax.i32(i32, i32) #5

attributes #0 = { mustprogress nofree nounwind willreturn allockind("alloc,uninitialized") allocsize(0) memory(inaccessiblemem: readwrite) "alloc-family"="malloc" }
attributes #1 = { mustprogress nounwind willreturn allockind("free") memory(argmem: readwrite, inaccessiblemem: readwrite) "alloc-family"="malloc" }
attributes #2 = { norecurse nounwind }
attributes #3 = { nounwind }
attributes #4 = { convergent nounwind }
attributes #5 = { nocallback nofree nosync nounwind speculatable willreturn memory(none) }

!llvm.module.flags = !{!0, !1, !2, !3}

!0 = !{i32 2, !"Debug Info Version", i32 3}
!1 = !{i32 7, !"openmp", i32 11}
!2 = !{i32 8, !"PIC Level", i32 2}
!3 = !{i32 7, !"PIE Level", i32 2}
!4 = !{!5, !5, i64 0}
!5 = !{!"any data access", !6, i64 0}
!6 = !{!"any access", !7, i64 0}
!7 = !{!"Flang Type TBAA Root"}
!8 = !{!9, !9, i64 0}
!9 = !{!"descriptor member", !6, i64 0}
!10 = !{!11}
!11 = !{i64 2, i64 -1, i64 -1, i1 true}
*** IR Dump After RecomputeGlobalsAAPass on [module] ***
; ModuleID = 'FIRModule'
source_filename = "FIRModule"
target datalayout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128"
target triple = "x86_64-unknown-linux-gnu"

%struct.ident_t = type { i32, i32, i32, i32, ptr }

@_QFEarr.0 = internal unnamed_addr global ptr null
@_QFEarr.8 = internal unnamed_addr global i1 false
@_QQcl.68815510185ede6107d6524e77abf791 = internal constant [52 x i8] c"/g/g92/rydahl1/flangtests/src/array_descriptors.f90\00"
@_QQcl.28612C69372C612C6531332E36653229 = internal constant [16 x i8] c"(a,i7,a,e13.6e2)"
@_QQcl.54686520726573756C74206F6620286172722831292B61727228 = internal constant [26 x i8] c"The result of (arr(1)+arr("
@_QQcl.2920697320 = internal constant [5 x i8] c") is "
@_QQEnvironmentDefaults = local_unnamed_addr constant ptr null
@0 = private unnamed_addr constant [23 x i8] c";unknown;unknown;0;0;;\00", align 1
@1 = private unnamed_addr constant %struct.ident_t { i32 0, i32 2, i32 0, i32 22, ptr @0 }, align 8
@2 = private unnamed_addr constant %struct.ident_t { i32 0, i32 66, i32 0, i32 22, ptr @0 }, align 8

; Function Attrs: mustprogress nofree nounwind willreturn allockind("alloc,uninitialized") allocsize(0) memory(inaccessiblemem: readwrite)
declare noalias noundef ptr @malloc(i64 noundef) local_unnamed_addr #0

; Function Attrs: mustprogress nounwind willreturn allockind("free") memory(argmem: readwrite, inaccessiblemem: readwrite)
declare void @free(ptr allocptr nocapture noundef) local_unnamed_addr #1

define void @_QQmain() local_unnamed_addr {
entry:
  %structArg = alloca { ptr, ptr }, align 8
  %0 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %1 = alloca i32, align 4
  store i32 1048576, ptr %1, align 4, !tbaa !4
  %2 = tail call dereferenceable_or_null(8388608) ptr @malloc(i64 8388608)
  store ptr %2, ptr @_QFEarr.0, align 8, !tbaa !8
  store i1 true, ptr @_QFEarr.8, align 1
  %omp_global_thread_num = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %1, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %0, ptr %gep_5, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QQmain..omp_par, ptr nonnull %structArg)
  %3 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.68815510185ede6107d6524e77abf791, i32 19)
  %4 = call i1 @_FortranAioOutputAscii(ptr %3, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %5 = load i32, ptr %1, align 4, !tbaa !4
  %6 = call i1 @_FortranAioOutputInteger32(ptr %3, i32 %5)
  %7 = call i1 @_FortranAioOutputAscii(ptr %3, ptr nonnull @_QQcl.2920697320, i64 5)
  %.unpack = load ptr, ptr @_QFEarr.0, align 8, !tbaa !8
  %8 = sub i64 1, 1
  %9 = getelementptr double, ptr %.unpack, i64 %8
  %10 = load double, ptr %9, align 8, !tbaa !4
  %11 = load i32, ptr %1, align 4, !tbaa !4
  %12 = sext i32 %11 to i64
  %13 = sub i64 %12, 1
  %14 = getelementptr double, ptr %.unpack, i64 %13
  %15 = load double, ptr %14, align 8, !tbaa !4
  %16 = fadd contract double %10, %15
  %17 = call i1 @_FortranAioOutputReal64(ptr %3, double %16)
  %18 = call i32 @_FortranAioEndIoStatement(ptr %3)
  %.unpack100 = load ptr, ptr @_QFEarr.0, align 8, !tbaa !8
  call void @free(ptr %.unpack100)
  store ptr null, ptr @_QFEarr.0, align 8, !tbaa !8
  store i1 false, ptr @_QFEarr.8, align 1
  ret void
}

; Function Attrs: norecurse nounwind
define internal void @_QQmain..omp_par(ptr noalias nocapture readnone %tid.addr, ptr noalias nocapture readnone %zero.addr, ptr nocapture readonly %0) #2 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %p.lastiter = alloca i32, align 4
  %p.lowerbound = alloca i32, align 4
  %p.upperbound = alloca i32, align 4
  %p.stride = alloca i32, align 4
  %1 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %omp_loop.tripcount = tail call i32 @llvm.smax.i32(i32 %1, i32 0)
  store i32 0, ptr %p.lowerbound, align 4
  %2 = add nsw i32 %omp_loop.tripcount, -1
  store i32 %2, ptr %p.upperbound, align 4
  store i32 1, ptr %p.stride, align 4
  %omp_global_thread_num4 = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  call void @__kmpc_for_static_init_4u(ptr nonnull @1, i32 %omp_global_thread_num4, i32 34, ptr nonnull %p.lastiter, ptr nonnull %p.lowerbound, ptr nonnull %p.upperbound, ptr nonnull %p.stride, i32 1, i32 0)
  %3 = load i32, ptr %p.lowerbound, align 4
  %4 = load i32, ptr %p.upperbound, align 4
  %reass.sub = sub i32 %4, %3
  %omp_loop.cmp32.not = icmp eq i32 %reass.sub, -1
  br i1 %omp_loop.cmp32.not, label %omp_loop.exit, label %omp_loop.body.lr.ph

omp_loop.body.lr.ph:                              ; preds = %omp.par.entry
  %.unpack = load ptr, ptr @_QFEarr.0, align 8, !tbaa !8
  %.unpack9.unpack.unpack11.b = load i1, ptr @_QFEarr.8, align 1
  %.unpack9.unpack.unpack11 = select i1 %.unpack9.unpack.unpack11.b, i64 1048576, i64 0
  %loadgep_2.repack16 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  %loadgep_2.repack20 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  %loadgep_2.repack24 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  %loadgep_2.repack26.repack28 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  br label %omp_loop.body

omp_loop.header.omp_loop.exit_crit_edge:          ; preds = %omp_loop.body
  %loadgep_2.repack14 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  %loadgep_2.repack18 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  %loadgep_2.repack22 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  %loadgep_2.repack26 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  %loadgep_2.repack26.repack30 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  store ptr %.unpack, ptr %loadgep_2, align 8, !tbaa !8
  store i64 8, ptr %loadgep_2.repack14, align 8, !tbaa !8
  store i32 20180515, ptr %loadgep_2.repack16, align 8, !tbaa !8
  store i8 1, ptr %loadgep_2.repack18, align 4, !tbaa !8
  store i8 28, ptr %loadgep_2.repack20, align 1, !tbaa !8
  store i8 2, ptr %loadgep_2.repack22, align 2, !tbaa !8
  store i8 0, ptr %loadgep_2.repack24, align 1, !tbaa !8
  store i64 1, ptr %loadgep_2.repack26, align 8, !tbaa !8
  store i64 %.unpack9.unpack.unpack11, ptr %loadgep_2.repack26.repack28, align 8, !tbaa !8
  store i64 8, ptr %loadgep_2.repack26.repack30, align 8, !tbaa !8
  br label %omp_loop.exit

omp_loop.exit:                                    ; preds = %omp_loop.header.omp_loop.exit_crit_edge, %omp.par.entry
  call void @__kmpc_for_static_fini(ptr nonnull @1, i32 %omp_global_thread_num4)
  call void @__kmpc_barrier(ptr nonnull @2, i32 %omp_global_thread_num4)
  ret void

omp_loop.body:                                    ; preds = %omp_loop.body.lr.ph, %omp_loop.body
  %omp_loop.iv33 = phi i32 [ 0, %omp_loop.body.lr.ph ], [ %5, %omp_loop.body ]
  %5 = add nuw i32 %omp_loop.iv33, 1
  %6 = add i32 %5, %3
  %7 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %8 = sitofp i32 %7 to float
  %9 = fdiv contract float 1.000000e+00, %8
  %10 = fpext float %9 to double
  %11 = sext i32 %6 to i64
  %12 = sub i64 %11, 1
  %13 = getelementptr double, ptr %.unpack, i64 %12
  store double %10, ptr %13, align 8, !tbaa !4
  %exitcond.not = icmp eq i32 %omp_loop.iv33, %reass.sub
  br i1 %exitcond.not, label %omp_loop.header.omp_loop.exit_crit_edge, label %omp_loop.body
}

declare ptr @_FortranAioBeginExternalFormattedOutput(ptr, i64, ptr, i32, ptr, i32) local_unnamed_addr

declare zeroext i1 @_FortranAioOutputAscii(ptr, ptr, i64) local_unnamed_addr

declare zeroext i1 @_FortranAioOutputInteger32(ptr, i32) local_unnamed_addr

declare zeroext i1 @_FortranAioOutputReal64(ptr, double) local_unnamed_addr

declare i32 @_FortranAioEndIoStatement(ptr) local_unnamed_addr

; Function Attrs: nounwind
declare i32 @__kmpc_global_thread_num(ptr) local_unnamed_addr #3

; Function Attrs: nounwind
declare void @__kmpc_for_static_init_4u(ptr, i32, i32, ptr, ptr, ptr, ptr, i32, i32) local_unnamed_addr #3

; Function Attrs: nounwind
declare void @__kmpc_for_static_fini(ptr, i32) local_unnamed_addr #3

; Function Attrs: convergent nounwind
declare void @__kmpc_barrier(ptr, i32) local_unnamed_addr #4

; Function Attrs: nounwind
declare !callback !10 void @__kmpc_fork_call(ptr, i32, ptr, ...) local_unnamed_addr #3

; Function Attrs: nocallback nofree nosync nounwind speculatable willreturn memory(none)
declare i32 @llvm.smax.i32(i32, i32) #5

attributes #0 = { mustprogress nofree nounwind willreturn allockind("alloc,uninitialized") allocsize(0) memory(inaccessiblemem: readwrite) "alloc-family"="malloc" }
attributes #1 = { mustprogress nounwind willreturn allockind("free") memory(argmem: readwrite, inaccessiblemem: readwrite) "alloc-family"="malloc" }
attributes #2 = { norecurse nounwind }
attributes #3 = { nounwind }
attributes #4 = { convergent nounwind }
attributes #5 = { nocallback nofree nosync nounwind speculatable willreturn memory(none) }

!llvm.module.flags = !{!0, !1, !2, !3}

!0 = !{i32 2, !"Debug Info Version", i32 3}
!1 = !{i32 7, !"openmp", i32 11}
!2 = !{i32 8, !"PIC Level", i32 2}
!3 = !{i32 7, !"PIE Level", i32 2}
!4 = !{!5, !5, i64 0}
!5 = !{!"any data access", !6, i64 0}
!6 = !{!"any access", !7, i64 0}
!7 = !{!"Flang Type TBAA Root"}
!8 = !{!9, !9, i64 0}
!9 = !{!"descriptor member", !6, i64 0}
!10 = !{!11}
!11 = !{i64 2, i64 -1, i64 -1, i1 true}
*** IR Dump After Float2IntPass on _QQmain ***
define void @_QQmain() local_unnamed_addr {
entry:
  %structArg = alloca { ptr, ptr }, align 8
  %0 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %1 = alloca i32, align 4
  store i32 1048576, ptr %1, align 4, !tbaa !4
  %2 = tail call dereferenceable_or_null(8388608) ptr @malloc(i64 8388608)
  store ptr %2, ptr @_QFEarr.0, align 8, !tbaa !8
  store i1 true, ptr @_QFEarr.8, align 1
  %omp_global_thread_num = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %1, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %0, ptr %gep_5, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QQmain..omp_par, ptr nonnull %structArg)
  %3 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.68815510185ede6107d6524e77abf791, i32 19)
  %4 = call i1 @_FortranAioOutputAscii(ptr %3, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %5 = load i32, ptr %1, align 4, !tbaa !4
  %6 = call i1 @_FortranAioOutputInteger32(ptr %3, i32 %5)
  %7 = call i1 @_FortranAioOutputAscii(ptr %3, ptr nonnull @_QQcl.2920697320, i64 5)
  %.unpack = load ptr, ptr @_QFEarr.0, align 8, !tbaa !8
  %8 = sub i64 1, 1
  %9 = getelementptr double, ptr %.unpack, i64 %8
  %10 = load double, ptr %9, align 8, !tbaa !4
  %11 = load i32, ptr %1, align 4, !tbaa !4
  %12 = sext i32 %11 to i64
  %13 = sub i64 %12, 1
  %14 = getelementptr double, ptr %.unpack, i64 %13
  %15 = load double, ptr %14, align 8, !tbaa !4
  %16 = fadd contract double %10, %15
  %17 = call i1 @_FortranAioOutputReal64(ptr %3, double %16)
  %18 = call i32 @_FortranAioEndIoStatement(ptr %3)
  %.unpack100 = load ptr, ptr @_QFEarr.0, align 8, !tbaa !8
  call void @free(ptr %.unpack100)
  store ptr null, ptr @_QFEarr.0, align 8, !tbaa !8
  store i1 false, ptr @_QFEarr.8, align 1
  ret void
}
*** IR Dump After LowerConstantIntrinsicsPass on _QQmain ***
define void @_QQmain() local_unnamed_addr {
entry:
  %structArg = alloca { ptr, ptr }, align 8
  %0 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %1 = alloca i32, align 4
  store i32 1048576, ptr %1, align 4, !tbaa !4
  %2 = tail call dereferenceable_or_null(8388608) ptr @malloc(i64 8388608)
  store ptr %2, ptr @_QFEarr.0, align 8, !tbaa !8
  store i1 true, ptr @_QFEarr.8, align 1
  %omp_global_thread_num = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %1, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %0, ptr %gep_5, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QQmain..omp_par, ptr nonnull %structArg)
  %3 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.68815510185ede6107d6524e77abf791, i32 19)
  %4 = call i1 @_FortranAioOutputAscii(ptr %3, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %5 = load i32, ptr %1, align 4, !tbaa !4
  %6 = call i1 @_FortranAioOutputInteger32(ptr %3, i32 %5)
  %7 = call i1 @_FortranAioOutputAscii(ptr %3, ptr nonnull @_QQcl.2920697320, i64 5)
  %.unpack = load ptr, ptr @_QFEarr.0, align 8, !tbaa !8
  %8 = sub i64 1, 1
  %9 = getelementptr double, ptr %.unpack, i64 %8
  %10 = load double, ptr %9, align 8, !tbaa !4
  %11 = load i32, ptr %1, align 4, !tbaa !4
  %12 = sext i32 %11 to i64
  %13 = sub i64 %12, 1
  %14 = getelementptr double, ptr %.unpack, i64 %13
  %15 = load double, ptr %14, align 8, !tbaa !4
  %16 = fadd contract double %10, %15
  %17 = call i1 @_FortranAioOutputReal64(ptr %3, double %16)
  %18 = call i32 @_FortranAioEndIoStatement(ptr %3)
  %.unpack100 = load ptr, ptr @_QFEarr.0, align 8, !tbaa !8
  call void @free(ptr %.unpack100)
  store ptr null, ptr @_QFEarr.0, align 8, !tbaa !8
  store i1 false, ptr @_QFEarr.8, align 1
  ret void
}
*** IR Dump After ControlHeightReductionPass on _QQmain ***
define void @_QQmain() local_unnamed_addr {
entry:
  %structArg = alloca { ptr, ptr }, align 8
  %0 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %1 = alloca i32, align 4
  store i32 1048576, ptr %1, align 4, !tbaa !4
  %2 = tail call dereferenceable_or_null(8388608) ptr @malloc(i64 8388608)
  store ptr %2, ptr @_QFEarr.0, align 8, !tbaa !8
  store i1 true, ptr @_QFEarr.8, align 1
  %omp_global_thread_num = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %1, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %0, ptr %gep_5, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QQmain..omp_par, ptr nonnull %structArg)
  %3 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.68815510185ede6107d6524e77abf791, i32 19)
  %4 = call i1 @_FortranAioOutputAscii(ptr %3, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %5 = load i32, ptr %1, align 4, !tbaa !4
  %6 = call i1 @_FortranAioOutputInteger32(ptr %3, i32 %5)
  %7 = call i1 @_FortranAioOutputAscii(ptr %3, ptr nonnull @_QQcl.2920697320, i64 5)
  %.unpack = load ptr, ptr @_QFEarr.0, align 8, !tbaa !8
  %8 = sub i64 1, 1
  %9 = getelementptr double, ptr %.unpack, i64 %8
  %10 = load double, ptr %9, align 8, !tbaa !4
  %11 = load i32, ptr %1, align 4, !tbaa !4
  %12 = sext i32 %11 to i64
  %13 = sub i64 %12, 1
  %14 = getelementptr double, ptr %.unpack, i64 %13
  %15 = load double, ptr %14, align 8, !tbaa !4
  %16 = fadd contract double %10, %15
  %17 = call i1 @_FortranAioOutputReal64(ptr %3, double %16)
  %18 = call i32 @_FortranAioEndIoStatement(ptr %3)
  %.unpack100 = load ptr, ptr @_QFEarr.0, align 8, !tbaa !8
  call void @free(ptr %.unpack100)
  store ptr null, ptr @_QFEarr.0, align 8, !tbaa !8
  store i1 false, ptr @_QFEarr.8, align 1
  ret void
}
*** IR Dump After LoopSimplifyPass on _QQmain ***
define void @_QQmain() local_unnamed_addr {
entry:
  %structArg = alloca { ptr, ptr }, align 8
  %0 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %1 = alloca i32, align 4
  store i32 1048576, ptr %1, align 4, !tbaa !4
  %2 = tail call dereferenceable_or_null(8388608) ptr @malloc(i64 8388608)
  store ptr %2, ptr @_QFEarr.0, align 8, !tbaa !8
  store i1 true, ptr @_QFEarr.8, align 1
  %omp_global_thread_num = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %1, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %0, ptr %gep_5, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QQmain..omp_par, ptr nonnull %structArg)
  %3 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.68815510185ede6107d6524e77abf791, i32 19)
  %4 = call i1 @_FortranAioOutputAscii(ptr %3, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %5 = load i32, ptr %1, align 4, !tbaa !4
  %6 = call i1 @_FortranAioOutputInteger32(ptr %3, i32 %5)
  %7 = call i1 @_FortranAioOutputAscii(ptr %3, ptr nonnull @_QQcl.2920697320, i64 5)
  %.unpack = load ptr, ptr @_QFEarr.0, align 8, !tbaa !8
  %8 = sub i64 1, 1
  %9 = getelementptr double, ptr %.unpack, i64 %8
  %10 = load double, ptr %9, align 8, !tbaa !4
  %11 = load i32, ptr %1, align 4, !tbaa !4
  %12 = sext i32 %11 to i64
  %13 = sub i64 %12, 1
  %14 = getelementptr double, ptr %.unpack, i64 %13
  %15 = load double, ptr %14, align 8, !tbaa !4
  %16 = fadd contract double %10, %15
  %17 = call i1 @_FortranAioOutputReal64(ptr %3, double %16)
  %18 = call i32 @_FortranAioEndIoStatement(ptr %3)
  %.unpack100 = load ptr, ptr @_QFEarr.0, align 8, !tbaa !8
  call void @free(ptr %.unpack100)
  store ptr null, ptr @_QFEarr.0, align 8, !tbaa !8
  store i1 false, ptr @_QFEarr.8, align 1
  ret void
}
*** IR Dump After LCSSAPass on _QQmain ***
define void @_QQmain() local_unnamed_addr {
entry:
  %structArg = alloca { ptr, ptr }, align 8
  %0 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %1 = alloca i32, align 4
  store i32 1048576, ptr %1, align 4, !tbaa !4
  %2 = tail call dereferenceable_or_null(8388608) ptr @malloc(i64 8388608)
  store ptr %2, ptr @_QFEarr.0, align 8, !tbaa !8
  store i1 true, ptr @_QFEarr.8, align 1
  %omp_global_thread_num = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %1, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %0, ptr %gep_5, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QQmain..omp_par, ptr nonnull %structArg)
  %3 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.68815510185ede6107d6524e77abf791, i32 19)
  %4 = call i1 @_FortranAioOutputAscii(ptr %3, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %5 = load i32, ptr %1, align 4, !tbaa !4
  %6 = call i1 @_FortranAioOutputInteger32(ptr %3, i32 %5)
  %7 = call i1 @_FortranAioOutputAscii(ptr %3, ptr nonnull @_QQcl.2920697320, i64 5)
  %.unpack = load ptr, ptr @_QFEarr.0, align 8, !tbaa !8
  %8 = sub i64 1, 1
  %9 = getelementptr double, ptr %.unpack, i64 %8
  %10 = load double, ptr %9, align 8, !tbaa !4
  %11 = load i32, ptr %1, align 4, !tbaa !4
  %12 = sext i32 %11 to i64
  %13 = sub i64 %12, 1
  %14 = getelementptr double, ptr %.unpack, i64 %13
  %15 = load double, ptr %14, align 8, !tbaa !4
  %16 = fadd contract double %10, %15
  %17 = call i1 @_FortranAioOutputReal64(ptr %3, double %16)
  %18 = call i32 @_FortranAioEndIoStatement(ptr %3)
  %.unpack100 = load ptr, ptr @_QFEarr.0, align 8, !tbaa !8
  call void @free(ptr %.unpack100)
  store ptr null, ptr @_QFEarr.0, align 8, !tbaa !8
  store i1 false, ptr @_QFEarr.8, align 1
  ret void
}
*** IR Dump After LoopDistributePass on _QQmain ***
define void @_QQmain() local_unnamed_addr {
entry:
  %structArg = alloca { ptr, ptr }, align 8
  %0 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %1 = alloca i32, align 4
  store i32 1048576, ptr %1, align 4, !tbaa !4
  %2 = tail call dereferenceable_or_null(8388608) ptr @malloc(i64 8388608)
  store ptr %2, ptr @_QFEarr.0, align 8, !tbaa !8
  store i1 true, ptr @_QFEarr.8, align 1
  %omp_global_thread_num = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %1, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %0, ptr %gep_5, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QQmain..omp_par, ptr nonnull %structArg)
  %3 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.68815510185ede6107d6524e77abf791, i32 19)
  %4 = call i1 @_FortranAioOutputAscii(ptr %3, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %5 = load i32, ptr %1, align 4, !tbaa !4
  %6 = call i1 @_FortranAioOutputInteger32(ptr %3, i32 %5)
  %7 = call i1 @_FortranAioOutputAscii(ptr %3, ptr nonnull @_QQcl.2920697320, i64 5)
  %.unpack = load ptr, ptr @_QFEarr.0, align 8, !tbaa !8
  %8 = sub i64 1, 1
  %9 = getelementptr double, ptr %.unpack, i64 %8
  %10 = load double, ptr %9, align 8, !tbaa !4
  %11 = load i32, ptr %1, align 4, !tbaa !4
  %12 = sext i32 %11 to i64
  %13 = sub i64 %12, 1
  %14 = getelementptr double, ptr %.unpack, i64 %13
  %15 = load double, ptr %14, align 8, !tbaa !4
  %16 = fadd contract double %10, %15
  %17 = call i1 @_FortranAioOutputReal64(ptr %3, double %16)
  %18 = call i32 @_FortranAioEndIoStatement(ptr %3)
  %.unpack100 = load ptr, ptr @_QFEarr.0, align 8, !tbaa !8
  call void @free(ptr %.unpack100)
  store ptr null, ptr @_QFEarr.0, align 8, !tbaa !8
  store i1 false, ptr @_QFEarr.8, align 1
  ret void
}
*** IR Dump After InjectTLIMappings on _QQmain ***
define void @_QQmain() local_unnamed_addr {
entry:
  %structArg = alloca { ptr, ptr }, align 8
  %0 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %1 = alloca i32, align 4
  store i32 1048576, ptr %1, align 4, !tbaa !4
  %2 = tail call dereferenceable_or_null(8388608) ptr @malloc(i64 8388608)
  store ptr %2, ptr @_QFEarr.0, align 8, !tbaa !8
  store i1 true, ptr @_QFEarr.8, align 1
  %omp_global_thread_num = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %1, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %0, ptr %gep_5, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QQmain..omp_par, ptr nonnull %structArg)
  %3 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.68815510185ede6107d6524e77abf791, i32 19)
  %4 = call i1 @_FortranAioOutputAscii(ptr %3, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %5 = load i32, ptr %1, align 4, !tbaa !4
  %6 = call i1 @_FortranAioOutputInteger32(ptr %3, i32 %5)
  %7 = call i1 @_FortranAioOutputAscii(ptr %3, ptr nonnull @_QQcl.2920697320, i64 5)
  %.unpack = load ptr, ptr @_QFEarr.0, align 8, !tbaa !8
  %8 = sub i64 1, 1
  %9 = getelementptr double, ptr %.unpack, i64 %8
  %10 = load double, ptr %9, align 8, !tbaa !4
  %11 = load i32, ptr %1, align 4, !tbaa !4
  %12 = sext i32 %11 to i64
  %13 = sub i64 %12, 1
  %14 = getelementptr double, ptr %.unpack, i64 %13
  %15 = load double, ptr %14, align 8, !tbaa !4
  %16 = fadd contract double %10, %15
  %17 = call i1 @_FortranAioOutputReal64(ptr %3, double %16)
  %18 = call i32 @_FortranAioEndIoStatement(ptr %3)
  %.unpack100 = load ptr, ptr @_QFEarr.0, align 8, !tbaa !8
  call void @free(ptr %.unpack100)
  store ptr null, ptr @_QFEarr.0, align 8, !tbaa !8
  store i1 false, ptr @_QFEarr.8, align 1
  ret void
}
*** IR Dump After LoopVectorizePass on _QQmain ***
define void @_QQmain() local_unnamed_addr {
entry:
  %structArg = alloca { ptr, ptr }, align 8
  %0 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %1 = alloca i32, align 4
  store i32 1048576, ptr %1, align 4, !tbaa !4
  %2 = tail call dereferenceable_or_null(8388608) ptr @malloc(i64 8388608)
  store ptr %2, ptr @_QFEarr.0, align 8, !tbaa !8
  store i1 true, ptr @_QFEarr.8, align 1
  %omp_global_thread_num = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %1, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %0, ptr %gep_5, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QQmain..omp_par, ptr nonnull %structArg)
  %3 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.68815510185ede6107d6524e77abf791, i32 19)
  %4 = call i1 @_FortranAioOutputAscii(ptr %3, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %5 = load i32, ptr %1, align 4, !tbaa !4
  %6 = call i1 @_FortranAioOutputInteger32(ptr %3, i32 %5)
  %7 = call i1 @_FortranAioOutputAscii(ptr %3, ptr nonnull @_QQcl.2920697320, i64 5)
  %.unpack = load ptr, ptr @_QFEarr.0, align 8, !tbaa !8
  %8 = sub i64 1, 1
  %9 = getelementptr double, ptr %.unpack, i64 %8
  %10 = load double, ptr %9, align 8, !tbaa !4
  %11 = load i32, ptr %1, align 4, !tbaa !4
  %12 = sext i32 %11 to i64
  %13 = sub i64 %12, 1
  %14 = getelementptr double, ptr %.unpack, i64 %13
  %15 = load double, ptr %14, align 8, !tbaa !4
  %16 = fadd contract double %10, %15
  %17 = call i1 @_FortranAioOutputReal64(ptr %3, double %16)
  %18 = call i32 @_FortranAioEndIoStatement(ptr %3)
  %.unpack100 = load ptr, ptr @_QFEarr.0, align 8, !tbaa !8
  call void @free(ptr %.unpack100)
  store ptr null, ptr @_QFEarr.0, align 8, !tbaa !8
  store i1 false, ptr @_QFEarr.8, align 1
  ret void
}
*** IR Dump After LoopLoadEliminationPass on _QQmain ***
define void @_QQmain() local_unnamed_addr {
entry:
  %structArg = alloca { ptr, ptr }, align 8
  %0 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %1 = alloca i32, align 4
  store i32 1048576, ptr %1, align 4, !tbaa !4
  %2 = tail call dereferenceable_or_null(8388608) ptr @malloc(i64 8388608)
  store ptr %2, ptr @_QFEarr.0, align 8, !tbaa !8
  store i1 true, ptr @_QFEarr.8, align 1
  %omp_global_thread_num = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %1, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %0, ptr %gep_5, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QQmain..omp_par, ptr nonnull %structArg)
  %3 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.68815510185ede6107d6524e77abf791, i32 19)
  %4 = call i1 @_FortranAioOutputAscii(ptr %3, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %5 = load i32, ptr %1, align 4, !tbaa !4
  %6 = call i1 @_FortranAioOutputInteger32(ptr %3, i32 %5)
  %7 = call i1 @_FortranAioOutputAscii(ptr %3, ptr nonnull @_QQcl.2920697320, i64 5)
  %.unpack = load ptr, ptr @_QFEarr.0, align 8, !tbaa !8
  %8 = sub i64 1, 1
  %9 = getelementptr double, ptr %.unpack, i64 %8
  %10 = load double, ptr %9, align 8, !tbaa !4
  %11 = load i32, ptr %1, align 4, !tbaa !4
  %12 = sext i32 %11 to i64
  %13 = sub i64 %12, 1
  %14 = getelementptr double, ptr %.unpack, i64 %13
  %15 = load double, ptr %14, align 8, !tbaa !4
  %16 = fadd contract double %10, %15
  %17 = call i1 @_FortranAioOutputReal64(ptr %3, double %16)
  %18 = call i32 @_FortranAioEndIoStatement(ptr %3)
  %.unpack100 = load ptr, ptr @_QFEarr.0, align 8, !tbaa !8
  call void @free(ptr %.unpack100)
  store ptr null, ptr @_QFEarr.0, align 8, !tbaa !8
  store i1 false, ptr @_QFEarr.8, align 1
  ret void
}
*** IR Dump After InstCombinePass on _QQmain ***
define void @_QQmain() local_unnamed_addr {
entry:
  %structArg = alloca { ptr, ptr }, align 8
  %0 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %1 = alloca i32, align 4
  store i32 1048576, ptr %1, align 4, !tbaa !4
  %2 = tail call dereferenceable_or_null(8388608) ptr @malloc(i64 8388608)
  store ptr %2, ptr @_QFEarr.0, align 8, !tbaa !8
  store i1 true, ptr @_QFEarr.8, align 1
  %omp_global_thread_num = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %1, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %0, ptr %gep_5, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QQmain..omp_par, ptr nonnull %structArg)
  %3 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.68815510185ede6107d6524e77abf791, i32 19)
  %4 = call i1 @_FortranAioOutputAscii(ptr %3, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %5 = load i32, ptr %1, align 4, !tbaa !4
  %6 = call i1 @_FortranAioOutputInteger32(ptr %3, i32 %5)
  %7 = call i1 @_FortranAioOutputAscii(ptr %3, ptr nonnull @_QQcl.2920697320, i64 5)
  %.unpack = load ptr, ptr @_QFEarr.0, align 8, !tbaa !8
  %8 = load double, ptr %.unpack, align 8, !tbaa !4
  %9 = load i32, ptr %1, align 4, !tbaa !4
  %10 = sext i32 %9 to i64
  %11 = add nsw i64 %10, -1
  %12 = getelementptr double, ptr %.unpack, i64 %11
  %13 = load double, ptr %12, align 8, !tbaa !4
  %14 = fadd contract double %8, %13
  %15 = call i1 @_FortranAioOutputReal64(ptr %3, double %14)
  %16 = call i32 @_FortranAioEndIoStatement(ptr %3)
  %.unpack100 = load ptr, ptr @_QFEarr.0, align 8, !tbaa !8
  call void @free(ptr %.unpack100)
  store ptr null, ptr @_QFEarr.0, align 8, !tbaa !8
  store i1 false, ptr @_QFEarr.8, align 1
  ret void
}
*** IR Dump After SimplifyCFGPass on _QQmain ***
define void @_QQmain() local_unnamed_addr {
entry:
  %structArg = alloca { ptr, ptr }, align 8
  %0 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %1 = alloca i32, align 4
  store i32 1048576, ptr %1, align 4, !tbaa !4
  %2 = tail call dereferenceable_or_null(8388608) ptr @malloc(i64 8388608)
  store ptr %2, ptr @_QFEarr.0, align 8, !tbaa !8
  store i1 true, ptr @_QFEarr.8, align 1
  %omp_global_thread_num = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %1, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %0, ptr %gep_5, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QQmain..omp_par, ptr nonnull %structArg)
  %3 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.68815510185ede6107d6524e77abf791, i32 19)
  %4 = call i1 @_FortranAioOutputAscii(ptr %3, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %5 = load i32, ptr %1, align 4, !tbaa !4
  %6 = call i1 @_FortranAioOutputInteger32(ptr %3, i32 %5)
  %7 = call i1 @_FortranAioOutputAscii(ptr %3, ptr nonnull @_QQcl.2920697320, i64 5)
  %.unpack = load ptr, ptr @_QFEarr.0, align 8, !tbaa !8
  %8 = load double, ptr %.unpack, align 8, !tbaa !4
  %9 = load i32, ptr %1, align 4, !tbaa !4
  %10 = sext i32 %9 to i64
  %11 = add nsw i64 %10, -1
  %12 = getelementptr double, ptr %.unpack, i64 %11
  %13 = load double, ptr %12, align 8, !tbaa !4
  %14 = fadd contract double %8, %13
  %15 = call i1 @_FortranAioOutputReal64(ptr %3, double %14)
  %16 = call i32 @_FortranAioEndIoStatement(ptr %3)
  %.unpack100 = load ptr, ptr @_QFEarr.0, align 8, !tbaa !8
  call void @free(ptr %.unpack100)
  store ptr null, ptr @_QFEarr.0, align 8, !tbaa !8
  store i1 false, ptr @_QFEarr.8, align 1
  ret void
}
*** IR Dump After VectorCombinePass on _QQmain ***
define void @_QQmain() local_unnamed_addr {
entry:
  %structArg = alloca { ptr, ptr }, align 8
  %0 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %1 = alloca i32, align 4
  store i32 1048576, ptr %1, align 4, !tbaa !4
  %2 = tail call dereferenceable_or_null(8388608) ptr @malloc(i64 8388608)
  store ptr %2, ptr @_QFEarr.0, align 8, !tbaa !8
  store i1 true, ptr @_QFEarr.8, align 1
  %omp_global_thread_num = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %1, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %0, ptr %gep_5, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QQmain..omp_par, ptr nonnull %structArg)
  %3 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.68815510185ede6107d6524e77abf791, i32 19)
  %4 = call i1 @_FortranAioOutputAscii(ptr %3, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %5 = load i32, ptr %1, align 4, !tbaa !4
  %6 = call i1 @_FortranAioOutputInteger32(ptr %3, i32 %5)
  %7 = call i1 @_FortranAioOutputAscii(ptr %3, ptr nonnull @_QQcl.2920697320, i64 5)
  %.unpack = load ptr, ptr @_QFEarr.0, align 8, !tbaa !8
  %8 = load double, ptr %.unpack, align 8, !tbaa !4
  %9 = load i32, ptr %1, align 4, !tbaa !4
  %10 = sext i32 %9 to i64
  %11 = add nsw i64 %10, -1
  %12 = getelementptr double, ptr %.unpack, i64 %11
  %13 = load double, ptr %12, align 8, !tbaa !4
  %14 = fadd contract double %8, %13
  %15 = call i1 @_FortranAioOutputReal64(ptr %3, double %14)
  %16 = call i32 @_FortranAioEndIoStatement(ptr %3)
  %.unpack100 = load ptr, ptr @_QFEarr.0, align 8, !tbaa !8
  call void @free(ptr %.unpack100)
  store ptr null, ptr @_QFEarr.0, align 8, !tbaa !8
  store i1 false, ptr @_QFEarr.8, align 1
  ret void
}
*** IR Dump After InstCombinePass on _QQmain ***
define void @_QQmain() local_unnamed_addr {
entry:
  %structArg = alloca { ptr, ptr }, align 8
  %0 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %1 = alloca i32, align 4
  store i32 1048576, ptr %1, align 4, !tbaa !4
  %2 = tail call dereferenceable_or_null(8388608) ptr @malloc(i64 8388608)
  store ptr %2, ptr @_QFEarr.0, align 8, !tbaa !8
  store i1 true, ptr @_QFEarr.8, align 1
  %omp_global_thread_num = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %1, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %0, ptr %gep_5, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QQmain..omp_par, ptr nonnull %structArg)
  %3 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.68815510185ede6107d6524e77abf791, i32 19)
  %4 = call i1 @_FortranAioOutputAscii(ptr %3, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %5 = load i32, ptr %1, align 4, !tbaa !4
  %6 = call i1 @_FortranAioOutputInteger32(ptr %3, i32 %5)
  %7 = call i1 @_FortranAioOutputAscii(ptr %3, ptr nonnull @_QQcl.2920697320, i64 5)
  %.unpack = load ptr, ptr @_QFEarr.0, align 8, !tbaa !8
  %8 = load double, ptr %.unpack, align 8, !tbaa !4
  %9 = load i32, ptr %1, align 4, !tbaa !4
  %10 = sext i32 %9 to i64
  %11 = add nsw i64 %10, -1
  %12 = getelementptr double, ptr %.unpack, i64 %11
  %13 = load double, ptr %12, align 8, !tbaa !4
  %14 = fadd contract double %8, %13
  %15 = call i1 @_FortranAioOutputReal64(ptr %3, double %14)
  %16 = call i32 @_FortranAioEndIoStatement(ptr %3)
  %.unpack100 = load ptr, ptr @_QFEarr.0, align 8, !tbaa !8
  call void @free(ptr %.unpack100)
  store ptr null, ptr @_QFEarr.0, align 8, !tbaa !8
  store i1 false, ptr @_QFEarr.8, align 1
  ret void
}
*** IR Dump After LoopUnrollPass on _QQmain ***
define void @_QQmain() local_unnamed_addr {
entry:
  %structArg = alloca { ptr, ptr }, align 8
  %0 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %1 = alloca i32, align 4
  store i32 1048576, ptr %1, align 4, !tbaa !4
  %2 = tail call dereferenceable_or_null(8388608) ptr @malloc(i64 8388608)
  store ptr %2, ptr @_QFEarr.0, align 8, !tbaa !8
  store i1 true, ptr @_QFEarr.8, align 1
  %omp_global_thread_num = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %1, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %0, ptr %gep_5, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QQmain..omp_par, ptr nonnull %structArg)
  %3 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.68815510185ede6107d6524e77abf791, i32 19)
  %4 = call i1 @_FortranAioOutputAscii(ptr %3, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %5 = load i32, ptr %1, align 4, !tbaa !4
  %6 = call i1 @_FortranAioOutputInteger32(ptr %3, i32 %5)
  %7 = call i1 @_FortranAioOutputAscii(ptr %3, ptr nonnull @_QQcl.2920697320, i64 5)
  %.unpack = load ptr, ptr @_QFEarr.0, align 8, !tbaa !8
  %8 = load double, ptr %.unpack, align 8, !tbaa !4
  %9 = load i32, ptr %1, align 4, !tbaa !4
  %10 = sext i32 %9 to i64
  %11 = add nsw i64 %10, -1
  %12 = getelementptr double, ptr %.unpack, i64 %11
  %13 = load double, ptr %12, align 8, !tbaa !4
  %14 = fadd contract double %8, %13
  %15 = call i1 @_FortranAioOutputReal64(ptr %3, double %14)
  %16 = call i32 @_FortranAioEndIoStatement(ptr %3)
  %.unpack100 = load ptr, ptr @_QFEarr.0, align 8, !tbaa !8
  call void @free(ptr %.unpack100)
  store ptr null, ptr @_QFEarr.0, align 8, !tbaa !8
  store i1 false, ptr @_QFEarr.8, align 1
  ret void
}
*** IR Dump After WarnMissedTransformationsPass on _QQmain ***
define void @_QQmain() local_unnamed_addr {
entry:
  %structArg = alloca { ptr, ptr }, align 8
  %0 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %1 = alloca i32, align 4
  store i32 1048576, ptr %1, align 4, !tbaa !4
  %2 = tail call dereferenceable_or_null(8388608) ptr @malloc(i64 8388608)
  store ptr %2, ptr @_QFEarr.0, align 8, !tbaa !8
  store i1 true, ptr @_QFEarr.8, align 1
  %omp_global_thread_num = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %1, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %0, ptr %gep_5, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QQmain..omp_par, ptr nonnull %structArg)
  %3 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.68815510185ede6107d6524e77abf791, i32 19)
  %4 = call i1 @_FortranAioOutputAscii(ptr %3, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %5 = load i32, ptr %1, align 4, !tbaa !4
  %6 = call i1 @_FortranAioOutputInteger32(ptr %3, i32 %5)
  %7 = call i1 @_FortranAioOutputAscii(ptr %3, ptr nonnull @_QQcl.2920697320, i64 5)
  %.unpack = load ptr, ptr @_QFEarr.0, align 8, !tbaa !8
  %8 = load double, ptr %.unpack, align 8, !tbaa !4
  %9 = load i32, ptr %1, align 4, !tbaa !4
  %10 = sext i32 %9 to i64
  %11 = add nsw i64 %10, -1
  %12 = getelementptr double, ptr %.unpack, i64 %11
  %13 = load double, ptr %12, align 8, !tbaa !4
  %14 = fadd contract double %8, %13
  %15 = call i1 @_FortranAioOutputReal64(ptr %3, double %14)
  %16 = call i32 @_FortranAioEndIoStatement(ptr %3)
  %.unpack100 = load ptr, ptr @_QFEarr.0, align 8, !tbaa !8
  call void @free(ptr %.unpack100)
  store ptr null, ptr @_QFEarr.0, align 8, !tbaa !8
  store i1 false, ptr @_QFEarr.8, align 1
  ret void
}
*** IR Dump After SROAPass on _QQmain ***
define void @_QQmain() local_unnamed_addr {
entry:
  %structArg = alloca { ptr, ptr }, align 8
  %0 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %1 = alloca i32, align 4
  store i32 1048576, ptr %1, align 4, !tbaa !4
  %2 = tail call dereferenceable_or_null(8388608) ptr @malloc(i64 8388608)
  store ptr %2, ptr @_QFEarr.0, align 8, !tbaa !8
  store i1 true, ptr @_QFEarr.8, align 1
  %omp_global_thread_num = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %1, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %0, ptr %gep_5, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QQmain..omp_par, ptr nonnull %structArg)
  %3 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.68815510185ede6107d6524e77abf791, i32 19)
  %4 = call i1 @_FortranAioOutputAscii(ptr %3, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %5 = load i32, ptr %1, align 4, !tbaa !4
  %6 = call i1 @_FortranAioOutputInteger32(ptr %3, i32 %5)
  %7 = call i1 @_FortranAioOutputAscii(ptr %3, ptr nonnull @_QQcl.2920697320, i64 5)
  %.unpack = load ptr, ptr @_QFEarr.0, align 8, !tbaa !8
  %8 = load double, ptr %.unpack, align 8, !tbaa !4
  %9 = load i32, ptr %1, align 4, !tbaa !4
  %10 = sext i32 %9 to i64
  %11 = add nsw i64 %10, -1
  %12 = getelementptr double, ptr %.unpack, i64 %11
  %13 = load double, ptr %12, align 8, !tbaa !4
  %14 = fadd contract double %8, %13
  %15 = call i1 @_FortranAioOutputReal64(ptr %3, double %14)
  %16 = call i32 @_FortranAioEndIoStatement(ptr %3)
  %.unpack100 = load ptr, ptr @_QFEarr.0, align 8, !tbaa !8
  call void @free(ptr %.unpack100)
  store ptr null, ptr @_QFEarr.0, align 8, !tbaa !8
  store i1 false, ptr @_QFEarr.8, align 1
  ret void
}
*** IR Dump After InstCombinePass on _QQmain ***
define void @_QQmain() local_unnamed_addr {
entry:
  %structArg = alloca { ptr, ptr }, align 8
  %0 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %1 = alloca i32, align 4
  store i32 1048576, ptr %1, align 4, !tbaa !4
  %2 = tail call dereferenceable_or_null(8388608) ptr @malloc(i64 8388608)
  store ptr %2, ptr @_QFEarr.0, align 8, !tbaa !8
  store i1 true, ptr @_QFEarr.8, align 1
  %omp_global_thread_num = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %1, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %0, ptr %gep_5, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QQmain..omp_par, ptr nonnull %structArg)
  %3 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.68815510185ede6107d6524e77abf791, i32 19)
  %4 = call i1 @_FortranAioOutputAscii(ptr %3, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %5 = load i32, ptr %1, align 4, !tbaa !4
  %6 = call i1 @_FortranAioOutputInteger32(ptr %3, i32 %5)
  %7 = call i1 @_FortranAioOutputAscii(ptr %3, ptr nonnull @_QQcl.2920697320, i64 5)
  %.unpack = load ptr, ptr @_QFEarr.0, align 8, !tbaa !8
  %8 = load double, ptr %.unpack, align 8, !tbaa !4
  %9 = load i32, ptr %1, align 4, !tbaa !4
  %10 = sext i32 %9 to i64
  %11 = add nsw i64 %10, -1
  %12 = getelementptr double, ptr %.unpack, i64 %11
  %13 = load double, ptr %12, align 8, !tbaa !4
  %14 = fadd contract double %8, %13
  %15 = call i1 @_FortranAioOutputReal64(ptr %3, double %14)
  %16 = call i32 @_FortranAioEndIoStatement(ptr %3)
  %.unpack100 = load ptr, ptr @_QFEarr.0, align 8, !tbaa !8
  call void @free(ptr %.unpack100)
  store ptr null, ptr @_QFEarr.0, align 8, !tbaa !8
  store i1 false, ptr @_QFEarr.8, align 1
  ret void
}
*** IR Dump After LoopSimplifyPass on _QQmain ***
define void @_QQmain() local_unnamed_addr {
entry:
  %structArg = alloca { ptr, ptr }, align 8
  %0 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %1 = alloca i32, align 4
  store i32 1048576, ptr %1, align 4, !tbaa !4
  %2 = tail call dereferenceable_or_null(8388608) ptr @malloc(i64 8388608)
  store ptr %2, ptr @_QFEarr.0, align 8, !tbaa !8
  store i1 true, ptr @_QFEarr.8, align 1
  %omp_global_thread_num = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %1, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %0, ptr %gep_5, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QQmain..omp_par, ptr nonnull %structArg)
  %3 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.68815510185ede6107d6524e77abf791, i32 19)
  %4 = call i1 @_FortranAioOutputAscii(ptr %3, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %5 = load i32, ptr %1, align 4, !tbaa !4
  %6 = call i1 @_FortranAioOutputInteger32(ptr %3, i32 %5)
  %7 = call i1 @_FortranAioOutputAscii(ptr %3, ptr nonnull @_QQcl.2920697320, i64 5)
  %.unpack = load ptr, ptr @_QFEarr.0, align 8, !tbaa !8
  %8 = load double, ptr %.unpack, align 8, !tbaa !4
  %9 = load i32, ptr %1, align 4, !tbaa !4
  %10 = sext i32 %9 to i64
  %11 = add nsw i64 %10, -1
  %12 = getelementptr double, ptr %.unpack, i64 %11
  %13 = load double, ptr %12, align 8, !tbaa !4
  %14 = fadd contract double %8, %13
  %15 = call i1 @_FortranAioOutputReal64(ptr %3, double %14)
  %16 = call i32 @_FortranAioEndIoStatement(ptr %3)
  %.unpack100 = load ptr, ptr @_QFEarr.0, align 8, !tbaa !8
  call void @free(ptr %.unpack100)
  store ptr null, ptr @_QFEarr.0, align 8, !tbaa !8
  store i1 false, ptr @_QFEarr.8, align 1
  ret void
}
*** IR Dump After LCSSAPass on _QQmain ***
define void @_QQmain() local_unnamed_addr {
entry:
  %structArg = alloca { ptr, ptr }, align 8
  %0 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %1 = alloca i32, align 4
  store i32 1048576, ptr %1, align 4, !tbaa !4
  %2 = tail call dereferenceable_or_null(8388608) ptr @malloc(i64 8388608)
  store ptr %2, ptr @_QFEarr.0, align 8, !tbaa !8
  store i1 true, ptr @_QFEarr.8, align 1
  %omp_global_thread_num = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %1, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %0, ptr %gep_5, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QQmain..omp_par, ptr nonnull %structArg)
  %3 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.68815510185ede6107d6524e77abf791, i32 19)
  %4 = call i1 @_FortranAioOutputAscii(ptr %3, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %5 = load i32, ptr %1, align 4, !tbaa !4
  %6 = call i1 @_FortranAioOutputInteger32(ptr %3, i32 %5)
  %7 = call i1 @_FortranAioOutputAscii(ptr %3, ptr nonnull @_QQcl.2920697320, i64 5)
  %.unpack = load ptr, ptr @_QFEarr.0, align 8, !tbaa !8
  %8 = load double, ptr %.unpack, align 8, !tbaa !4
  %9 = load i32, ptr %1, align 4, !tbaa !4
  %10 = sext i32 %9 to i64
  %11 = add nsw i64 %10, -1
  %12 = getelementptr double, ptr %.unpack, i64 %11
  %13 = load double, ptr %12, align 8, !tbaa !4
  %14 = fadd contract double %8, %13
  %15 = call i1 @_FortranAioOutputReal64(ptr %3, double %14)
  %16 = call i32 @_FortranAioEndIoStatement(ptr %3)
  %.unpack100 = load ptr, ptr @_QFEarr.0, align 8, !tbaa !8
  call void @free(ptr %.unpack100)
  store ptr null, ptr @_QFEarr.0, align 8, !tbaa !8
  store i1 false, ptr @_QFEarr.8, align 1
  ret void
}
*** IR Dump After AlignmentFromAssumptionsPass on _QQmain ***
define void @_QQmain() local_unnamed_addr {
entry:
  %structArg = alloca { ptr, ptr }, align 8
  %0 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %1 = alloca i32, align 4
  store i32 1048576, ptr %1, align 4, !tbaa !4
  %2 = tail call dereferenceable_or_null(8388608) ptr @malloc(i64 8388608)
  store ptr %2, ptr @_QFEarr.0, align 8, !tbaa !8
  store i1 true, ptr @_QFEarr.8, align 1
  %omp_global_thread_num = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %1, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %0, ptr %gep_5, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QQmain..omp_par, ptr nonnull %structArg)
  %3 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.68815510185ede6107d6524e77abf791, i32 19)
  %4 = call i1 @_FortranAioOutputAscii(ptr %3, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %5 = load i32, ptr %1, align 4, !tbaa !4
  %6 = call i1 @_FortranAioOutputInteger32(ptr %3, i32 %5)
  %7 = call i1 @_FortranAioOutputAscii(ptr %3, ptr nonnull @_QQcl.2920697320, i64 5)
  %.unpack = load ptr, ptr @_QFEarr.0, align 8, !tbaa !8
  %8 = load double, ptr %.unpack, align 8, !tbaa !4
  %9 = load i32, ptr %1, align 4, !tbaa !4
  %10 = sext i32 %9 to i64
  %11 = add nsw i64 %10, -1
  %12 = getelementptr double, ptr %.unpack, i64 %11
  %13 = load double, ptr %12, align 8, !tbaa !4
  %14 = fadd contract double %8, %13
  %15 = call i1 @_FortranAioOutputReal64(ptr %3, double %14)
  %16 = call i32 @_FortranAioEndIoStatement(ptr %3)
  %.unpack100 = load ptr, ptr @_QFEarr.0, align 8, !tbaa !8
  call void @free(ptr %.unpack100)
  store ptr null, ptr @_QFEarr.0, align 8, !tbaa !8
  store i1 false, ptr @_QFEarr.8, align 1
  ret void
}
*** IR Dump After LoopSinkPass on _QQmain ***
define void @_QQmain() local_unnamed_addr {
entry:
  %structArg = alloca { ptr, ptr }, align 8
  %0 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %1 = alloca i32, align 4
  store i32 1048576, ptr %1, align 4, !tbaa !4
  %2 = tail call dereferenceable_or_null(8388608) ptr @malloc(i64 8388608)
  store ptr %2, ptr @_QFEarr.0, align 8, !tbaa !8
  store i1 true, ptr @_QFEarr.8, align 1
  %omp_global_thread_num = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %1, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %0, ptr %gep_5, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QQmain..omp_par, ptr nonnull %structArg)
  %3 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.68815510185ede6107d6524e77abf791, i32 19)
  %4 = call i1 @_FortranAioOutputAscii(ptr %3, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %5 = load i32, ptr %1, align 4, !tbaa !4
  %6 = call i1 @_FortranAioOutputInteger32(ptr %3, i32 %5)
  %7 = call i1 @_FortranAioOutputAscii(ptr %3, ptr nonnull @_QQcl.2920697320, i64 5)
  %.unpack = load ptr, ptr @_QFEarr.0, align 8, !tbaa !8
  %8 = load double, ptr %.unpack, align 8, !tbaa !4
  %9 = load i32, ptr %1, align 4, !tbaa !4
  %10 = sext i32 %9 to i64
  %11 = add nsw i64 %10, -1
  %12 = getelementptr double, ptr %.unpack, i64 %11
  %13 = load double, ptr %12, align 8, !tbaa !4
  %14 = fadd contract double %8, %13
  %15 = call i1 @_FortranAioOutputReal64(ptr %3, double %14)
  %16 = call i32 @_FortranAioEndIoStatement(ptr %3)
  %.unpack100 = load ptr, ptr @_QFEarr.0, align 8, !tbaa !8
  call void @free(ptr %.unpack100)
  store ptr null, ptr @_QFEarr.0, align 8, !tbaa !8
  store i1 false, ptr @_QFEarr.8, align 1
  ret void
}
*** IR Dump After InstSimplifyPass on _QQmain ***
define void @_QQmain() local_unnamed_addr {
entry:
  %structArg = alloca { ptr, ptr }, align 8
  %0 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %1 = alloca i32, align 4
  store i32 1048576, ptr %1, align 4, !tbaa !4
  %2 = tail call dereferenceable_or_null(8388608) ptr @malloc(i64 8388608)
  store ptr %2, ptr @_QFEarr.0, align 8, !tbaa !8
  store i1 true, ptr @_QFEarr.8, align 1
  %omp_global_thread_num = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %1, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %0, ptr %gep_5, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QQmain..omp_par, ptr nonnull %structArg)
  %3 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.68815510185ede6107d6524e77abf791, i32 19)
  %4 = call i1 @_FortranAioOutputAscii(ptr %3, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %5 = load i32, ptr %1, align 4, !tbaa !4
  %6 = call i1 @_FortranAioOutputInteger32(ptr %3, i32 %5)
  %7 = call i1 @_FortranAioOutputAscii(ptr %3, ptr nonnull @_QQcl.2920697320, i64 5)
  %.unpack = load ptr, ptr @_QFEarr.0, align 8, !tbaa !8
  %8 = load double, ptr %.unpack, align 8, !tbaa !4
  %9 = load i32, ptr %1, align 4, !tbaa !4
  %10 = sext i32 %9 to i64
  %11 = add nsw i64 %10, -1
  %12 = getelementptr double, ptr %.unpack, i64 %11
  %13 = load double, ptr %12, align 8, !tbaa !4
  %14 = fadd contract double %8, %13
  %15 = call i1 @_FortranAioOutputReal64(ptr %3, double %14)
  %16 = call i32 @_FortranAioEndIoStatement(ptr %3)
  %.unpack100 = load ptr, ptr @_QFEarr.0, align 8, !tbaa !8
  call void @free(ptr %.unpack100)
  store ptr null, ptr @_QFEarr.0, align 8, !tbaa !8
  store i1 false, ptr @_QFEarr.8, align 1
  ret void
}
*** IR Dump After DivRemPairsPass on _QQmain ***
define void @_QQmain() local_unnamed_addr {
entry:
  %structArg = alloca { ptr, ptr }, align 8
  %0 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %1 = alloca i32, align 4
  store i32 1048576, ptr %1, align 4, !tbaa !4
  %2 = tail call dereferenceable_or_null(8388608) ptr @malloc(i64 8388608)
  store ptr %2, ptr @_QFEarr.0, align 8, !tbaa !8
  store i1 true, ptr @_QFEarr.8, align 1
  %omp_global_thread_num = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %1, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %0, ptr %gep_5, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QQmain..omp_par, ptr nonnull %structArg)
  %3 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.68815510185ede6107d6524e77abf791, i32 19)
  %4 = call i1 @_FortranAioOutputAscii(ptr %3, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %5 = load i32, ptr %1, align 4, !tbaa !4
  %6 = call i1 @_FortranAioOutputInteger32(ptr %3, i32 %5)
  %7 = call i1 @_FortranAioOutputAscii(ptr %3, ptr nonnull @_QQcl.2920697320, i64 5)
  %.unpack = load ptr, ptr @_QFEarr.0, align 8, !tbaa !8
  %8 = load double, ptr %.unpack, align 8, !tbaa !4
  %9 = load i32, ptr %1, align 4, !tbaa !4
  %10 = sext i32 %9 to i64
  %11 = add nsw i64 %10, -1
  %12 = getelementptr double, ptr %.unpack, i64 %11
  %13 = load double, ptr %12, align 8, !tbaa !4
  %14 = fadd contract double %8, %13
  %15 = call i1 @_FortranAioOutputReal64(ptr %3, double %14)
  %16 = call i32 @_FortranAioEndIoStatement(ptr %3)
  %.unpack100 = load ptr, ptr @_QFEarr.0, align 8, !tbaa !8
  call void @free(ptr %.unpack100)
  store ptr null, ptr @_QFEarr.0, align 8, !tbaa !8
  store i1 false, ptr @_QFEarr.8, align 1
  ret void
}
*** IR Dump After TailCallElimPass on _QQmain ***
define void @_QQmain() local_unnamed_addr {
entry:
  %structArg = alloca { ptr, ptr }, align 8
  %0 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %1 = alloca i32, align 4
  store i32 1048576, ptr %1, align 4, !tbaa !4
  %2 = tail call dereferenceable_or_null(8388608) ptr @malloc(i64 8388608)
  store ptr %2, ptr @_QFEarr.0, align 8, !tbaa !8
  store i1 true, ptr @_QFEarr.8, align 1
  %omp_global_thread_num = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %1, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %0, ptr %gep_5, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QQmain..omp_par, ptr nonnull %structArg)
  %3 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.68815510185ede6107d6524e77abf791, i32 19)
  %4 = call i1 @_FortranAioOutputAscii(ptr %3, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %5 = load i32, ptr %1, align 4, !tbaa !4
  %6 = call i1 @_FortranAioOutputInteger32(ptr %3, i32 %5)
  %7 = call i1 @_FortranAioOutputAscii(ptr %3, ptr nonnull @_QQcl.2920697320, i64 5)
  %.unpack = load ptr, ptr @_QFEarr.0, align 8, !tbaa !8
  %8 = load double, ptr %.unpack, align 8, !tbaa !4
  %9 = load i32, ptr %1, align 4, !tbaa !4
  %10 = sext i32 %9 to i64
  %11 = add nsw i64 %10, -1
  %12 = getelementptr double, ptr %.unpack, i64 %11
  %13 = load double, ptr %12, align 8, !tbaa !4
  %14 = fadd contract double %8, %13
  %15 = call i1 @_FortranAioOutputReal64(ptr %3, double %14)
  %16 = call i32 @_FortranAioEndIoStatement(ptr %3)
  %.unpack100 = load ptr, ptr @_QFEarr.0, align 8, !tbaa !8
  call void @free(ptr %.unpack100)
  store ptr null, ptr @_QFEarr.0, align 8, !tbaa !8
  store i1 false, ptr @_QFEarr.8, align 1
  ret void
}
*** IR Dump After SimplifyCFGPass on _QQmain ***
define void @_QQmain() local_unnamed_addr {
entry:
  %structArg = alloca { ptr, ptr }, align 8
  %0 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %1 = alloca i32, align 4
  store i32 1048576, ptr %1, align 4, !tbaa !4
  %2 = tail call dereferenceable_or_null(8388608) ptr @malloc(i64 8388608)
  store ptr %2, ptr @_QFEarr.0, align 8, !tbaa !8
  store i1 true, ptr @_QFEarr.8, align 1
  %omp_global_thread_num = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %1, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %0, ptr %gep_5, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QQmain..omp_par, ptr nonnull %structArg)
  %3 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.68815510185ede6107d6524e77abf791, i32 19)
  %4 = call i1 @_FortranAioOutputAscii(ptr %3, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %5 = load i32, ptr %1, align 4, !tbaa !4
  %6 = call i1 @_FortranAioOutputInteger32(ptr %3, i32 %5)
  %7 = call i1 @_FortranAioOutputAscii(ptr %3, ptr nonnull @_QQcl.2920697320, i64 5)
  %.unpack = load ptr, ptr @_QFEarr.0, align 8, !tbaa !8
  %8 = load double, ptr %.unpack, align 8, !tbaa !4
  %9 = load i32, ptr %1, align 4, !tbaa !4
  %10 = sext i32 %9 to i64
  %11 = add nsw i64 %10, -1
  %12 = getelementptr double, ptr %.unpack, i64 %11
  %13 = load double, ptr %12, align 8, !tbaa !4
  %14 = fadd contract double %8, %13
  %15 = call i1 @_FortranAioOutputReal64(ptr %3, double %14)
  %16 = call i32 @_FortranAioEndIoStatement(ptr %3)
  %.unpack100 = load ptr, ptr @_QFEarr.0, align 8, !tbaa !8
  call void @free(ptr %.unpack100)
  store ptr null, ptr @_QFEarr.0, align 8, !tbaa !8
  store i1 false, ptr @_QFEarr.8, align 1
  ret void
}
*** IR Dump After Float2IntPass on _QQmain..omp_par ***
; Function Attrs: norecurse nounwind
define internal void @_QQmain..omp_par(ptr noalias nocapture readnone %tid.addr, ptr noalias nocapture readnone %zero.addr, ptr nocapture readonly %0) #2 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %p.lastiter = alloca i32, align 4
  %p.lowerbound = alloca i32, align 4
  %p.upperbound = alloca i32, align 4
  %p.stride = alloca i32, align 4
  %1 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %omp_loop.tripcount = tail call i32 @llvm.smax.i32(i32 %1, i32 0)
  store i32 0, ptr %p.lowerbound, align 4
  %2 = add nsw i32 %omp_loop.tripcount, -1
  store i32 %2, ptr %p.upperbound, align 4
  store i32 1, ptr %p.stride, align 4
  %omp_global_thread_num4 = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  call void @__kmpc_for_static_init_4u(ptr nonnull @1, i32 %omp_global_thread_num4, i32 34, ptr nonnull %p.lastiter, ptr nonnull %p.lowerbound, ptr nonnull %p.upperbound, ptr nonnull %p.stride, i32 1, i32 0)
  %3 = load i32, ptr %p.lowerbound, align 4
  %4 = load i32, ptr %p.upperbound, align 4
  %reass.sub = sub i32 %4, %3
  %omp_loop.cmp32.not = icmp eq i32 %reass.sub, -1
  br i1 %omp_loop.cmp32.not, label %omp_loop.exit, label %omp_loop.body.lr.ph

omp_loop.body.lr.ph:                              ; preds = %omp.par.entry
  %.unpack = load ptr, ptr @_QFEarr.0, align 8, !tbaa !8
  %.unpack9.unpack.unpack11.b = load i1, ptr @_QFEarr.8, align 1
  %.unpack9.unpack.unpack11 = select i1 %.unpack9.unpack.unpack11.b, i64 1048576, i64 0
  %loadgep_2.repack16 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  %loadgep_2.repack20 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  %loadgep_2.repack24 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  %loadgep_2.repack26.repack28 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  br label %omp_loop.body

omp_loop.header.omp_loop.exit_crit_edge:          ; preds = %omp_loop.body
  %loadgep_2.repack14 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  %loadgep_2.repack18 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  %loadgep_2.repack22 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  %loadgep_2.repack26 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  %loadgep_2.repack26.repack30 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  store ptr %.unpack, ptr %loadgep_2, align 8, !tbaa !8
  store i64 8, ptr %loadgep_2.repack14, align 8, !tbaa !8
  store i32 20180515, ptr %loadgep_2.repack16, align 8, !tbaa !8
  store i8 1, ptr %loadgep_2.repack18, align 4, !tbaa !8
  store i8 28, ptr %loadgep_2.repack20, align 1, !tbaa !8
  store i8 2, ptr %loadgep_2.repack22, align 2, !tbaa !8
  store i8 0, ptr %loadgep_2.repack24, align 1, !tbaa !8
  store i64 1, ptr %loadgep_2.repack26, align 8, !tbaa !8
  store i64 %.unpack9.unpack.unpack11, ptr %loadgep_2.repack26.repack28, align 8, !tbaa !8
  store i64 8, ptr %loadgep_2.repack26.repack30, align 8, !tbaa !8
  br label %omp_loop.exit

omp_loop.exit:                                    ; preds = %omp_loop.header.omp_loop.exit_crit_edge, %omp.par.entry
  call void @__kmpc_for_static_fini(ptr nonnull @1, i32 %omp_global_thread_num4)
  call void @__kmpc_barrier(ptr nonnull @2, i32 %omp_global_thread_num4)
  ret void

omp_loop.body:                                    ; preds = %omp_loop.body.lr.ph, %omp_loop.body
  %omp_loop.iv33 = phi i32 [ 0, %omp_loop.body.lr.ph ], [ %5, %omp_loop.body ]
  %5 = add nuw i32 %omp_loop.iv33, 1
  %6 = add i32 %5, %3
  %7 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %8 = sitofp i32 %7 to float
  %9 = fdiv contract float 1.000000e+00, %8
  %10 = fpext float %9 to double
  %11 = sext i32 %6 to i64
  %12 = sub i64 %11, 1
  %13 = getelementptr double, ptr %.unpack, i64 %12
  store double %10, ptr %13, align 8, !tbaa !4
  %exitcond.not = icmp eq i32 %omp_loop.iv33, %reass.sub
  br i1 %exitcond.not, label %omp_loop.header.omp_loop.exit_crit_edge, label %omp_loop.body
}
*** IR Dump After LowerConstantIntrinsicsPass on _QQmain..omp_par ***
; Function Attrs: norecurse nounwind
define internal void @_QQmain..omp_par(ptr noalias nocapture readnone %tid.addr, ptr noalias nocapture readnone %zero.addr, ptr nocapture readonly %0) #2 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %p.lastiter = alloca i32, align 4
  %p.lowerbound = alloca i32, align 4
  %p.upperbound = alloca i32, align 4
  %p.stride = alloca i32, align 4
  %1 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %omp_loop.tripcount = tail call i32 @llvm.smax.i32(i32 %1, i32 0)
  store i32 0, ptr %p.lowerbound, align 4
  %2 = add nsw i32 %omp_loop.tripcount, -1
  store i32 %2, ptr %p.upperbound, align 4
  store i32 1, ptr %p.stride, align 4
  %omp_global_thread_num4 = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  call void @__kmpc_for_static_init_4u(ptr nonnull @1, i32 %omp_global_thread_num4, i32 34, ptr nonnull %p.lastiter, ptr nonnull %p.lowerbound, ptr nonnull %p.upperbound, ptr nonnull %p.stride, i32 1, i32 0)
  %3 = load i32, ptr %p.lowerbound, align 4
  %4 = load i32, ptr %p.upperbound, align 4
  %reass.sub = sub i32 %4, %3
  %omp_loop.cmp32.not = icmp eq i32 %reass.sub, -1
  br i1 %omp_loop.cmp32.not, label %omp_loop.exit, label %omp_loop.body.lr.ph

omp_loop.body.lr.ph:                              ; preds = %omp.par.entry
  %.unpack = load ptr, ptr @_QFEarr.0, align 8, !tbaa !8
  %.unpack9.unpack.unpack11.b = load i1, ptr @_QFEarr.8, align 1
  %.unpack9.unpack.unpack11 = select i1 %.unpack9.unpack.unpack11.b, i64 1048576, i64 0
  %loadgep_2.repack16 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  %loadgep_2.repack20 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  %loadgep_2.repack24 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  %loadgep_2.repack26.repack28 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  br label %omp_loop.body

omp_loop.header.omp_loop.exit_crit_edge:          ; preds = %omp_loop.body
  %loadgep_2.repack14 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  %loadgep_2.repack18 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  %loadgep_2.repack22 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  %loadgep_2.repack26 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  %loadgep_2.repack26.repack30 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  store ptr %.unpack, ptr %loadgep_2, align 8, !tbaa !8
  store i64 8, ptr %loadgep_2.repack14, align 8, !tbaa !8
  store i32 20180515, ptr %loadgep_2.repack16, align 8, !tbaa !8
  store i8 1, ptr %loadgep_2.repack18, align 4, !tbaa !8
  store i8 28, ptr %loadgep_2.repack20, align 1, !tbaa !8
  store i8 2, ptr %loadgep_2.repack22, align 2, !tbaa !8
  store i8 0, ptr %loadgep_2.repack24, align 1, !tbaa !8
  store i64 1, ptr %loadgep_2.repack26, align 8, !tbaa !8
  store i64 %.unpack9.unpack.unpack11, ptr %loadgep_2.repack26.repack28, align 8, !tbaa !8
  store i64 8, ptr %loadgep_2.repack26.repack30, align 8, !tbaa !8
  br label %omp_loop.exit

omp_loop.exit:                                    ; preds = %omp_loop.header.omp_loop.exit_crit_edge, %omp.par.entry
  call void @__kmpc_for_static_fini(ptr nonnull @1, i32 %omp_global_thread_num4)
  call void @__kmpc_barrier(ptr nonnull @2, i32 %omp_global_thread_num4)
  ret void

omp_loop.body:                                    ; preds = %omp_loop.body.lr.ph, %omp_loop.body
  %omp_loop.iv33 = phi i32 [ 0, %omp_loop.body.lr.ph ], [ %5, %omp_loop.body ]
  %5 = add nuw i32 %omp_loop.iv33, 1
  %6 = add i32 %5, %3
  %7 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %8 = sitofp i32 %7 to float
  %9 = fdiv contract float 1.000000e+00, %8
  %10 = fpext float %9 to double
  %11 = sext i32 %6 to i64
  %12 = sub i64 %11, 1
  %13 = getelementptr double, ptr %.unpack, i64 %12
  store double %10, ptr %13, align 8, !tbaa !4
  %exitcond.not = icmp eq i32 %omp_loop.iv33, %reass.sub
  br i1 %exitcond.not, label %omp_loop.header.omp_loop.exit_crit_edge, label %omp_loop.body
}
*** IR Dump After ControlHeightReductionPass on _QQmain..omp_par ***
; Function Attrs: norecurse nounwind
define internal void @_QQmain..omp_par(ptr noalias nocapture readnone %tid.addr, ptr noalias nocapture readnone %zero.addr, ptr nocapture readonly %0) #2 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %p.lastiter = alloca i32, align 4
  %p.lowerbound = alloca i32, align 4
  %p.upperbound = alloca i32, align 4
  %p.stride = alloca i32, align 4
  %1 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %omp_loop.tripcount = tail call i32 @llvm.smax.i32(i32 %1, i32 0)
  store i32 0, ptr %p.lowerbound, align 4
  %2 = add nsw i32 %omp_loop.tripcount, -1
  store i32 %2, ptr %p.upperbound, align 4
  store i32 1, ptr %p.stride, align 4
  %omp_global_thread_num4 = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  call void @__kmpc_for_static_init_4u(ptr nonnull @1, i32 %omp_global_thread_num4, i32 34, ptr nonnull %p.lastiter, ptr nonnull %p.lowerbound, ptr nonnull %p.upperbound, ptr nonnull %p.stride, i32 1, i32 0)
  %3 = load i32, ptr %p.lowerbound, align 4
  %4 = load i32, ptr %p.upperbound, align 4
  %reass.sub = sub i32 %4, %3
  %omp_loop.cmp32.not = icmp eq i32 %reass.sub, -1
  br i1 %omp_loop.cmp32.not, label %omp_loop.exit, label %omp_loop.body.lr.ph

omp_loop.body.lr.ph:                              ; preds = %omp.par.entry
  %.unpack = load ptr, ptr @_QFEarr.0, align 8, !tbaa !8
  %.unpack9.unpack.unpack11.b = load i1, ptr @_QFEarr.8, align 1
  %.unpack9.unpack.unpack11 = select i1 %.unpack9.unpack.unpack11.b, i64 1048576, i64 0
  %loadgep_2.repack16 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  %loadgep_2.repack20 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  %loadgep_2.repack24 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  %loadgep_2.repack26.repack28 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  br label %omp_loop.body

omp_loop.header.omp_loop.exit_crit_edge:          ; preds = %omp_loop.body
  %loadgep_2.repack14 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  %loadgep_2.repack18 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  %loadgep_2.repack22 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  %loadgep_2.repack26 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  %loadgep_2.repack26.repack30 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  store ptr %.unpack, ptr %loadgep_2, align 8, !tbaa !8
  store i64 8, ptr %loadgep_2.repack14, align 8, !tbaa !8
  store i32 20180515, ptr %loadgep_2.repack16, align 8, !tbaa !8
  store i8 1, ptr %loadgep_2.repack18, align 4, !tbaa !8
  store i8 28, ptr %loadgep_2.repack20, align 1, !tbaa !8
  store i8 2, ptr %loadgep_2.repack22, align 2, !tbaa !8
  store i8 0, ptr %loadgep_2.repack24, align 1, !tbaa !8
  store i64 1, ptr %loadgep_2.repack26, align 8, !tbaa !8
  store i64 %.unpack9.unpack.unpack11, ptr %loadgep_2.repack26.repack28, align 8, !tbaa !8
  store i64 8, ptr %loadgep_2.repack26.repack30, align 8, !tbaa !8
  br label %omp_loop.exit

omp_loop.exit:                                    ; preds = %omp_loop.header.omp_loop.exit_crit_edge, %omp.par.entry
  call void @__kmpc_for_static_fini(ptr nonnull @1, i32 %omp_global_thread_num4)
  call void @__kmpc_barrier(ptr nonnull @2, i32 %omp_global_thread_num4)
  ret void

omp_loop.body:                                    ; preds = %omp_loop.body.lr.ph, %omp_loop.body
  %omp_loop.iv33 = phi i32 [ 0, %omp_loop.body.lr.ph ], [ %5, %omp_loop.body ]
  %5 = add nuw i32 %omp_loop.iv33, 1
  %6 = add i32 %5, %3
  %7 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %8 = sitofp i32 %7 to float
  %9 = fdiv contract float 1.000000e+00, %8
  %10 = fpext float %9 to double
  %11 = sext i32 %6 to i64
  %12 = sub i64 %11, 1
  %13 = getelementptr double, ptr %.unpack, i64 %12
  store double %10, ptr %13, align 8, !tbaa !4
  %exitcond.not = icmp eq i32 %omp_loop.iv33, %reass.sub
  br i1 %exitcond.not, label %omp_loop.header.omp_loop.exit_crit_edge, label %omp_loop.body
}
*** IR Dump After LoopSimplifyPass on _QQmain..omp_par ***
; Function Attrs: norecurse nounwind
define internal void @_QQmain..omp_par(ptr noalias nocapture readnone %tid.addr, ptr noalias nocapture readnone %zero.addr, ptr nocapture readonly %0) #2 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %p.lastiter = alloca i32, align 4
  %p.lowerbound = alloca i32, align 4
  %p.upperbound = alloca i32, align 4
  %p.stride = alloca i32, align 4
  %1 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %omp_loop.tripcount = tail call i32 @llvm.smax.i32(i32 %1, i32 0)
  store i32 0, ptr %p.lowerbound, align 4
  %2 = add nsw i32 %omp_loop.tripcount, -1
  store i32 %2, ptr %p.upperbound, align 4
  store i32 1, ptr %p.stride, align 4
  %omp_global_thread_num4 = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  call void @__kmpc_for_static_init_4u(ptr nonnull @1, i32 %omp_global_thread_num4, i32 34, ptr nonnull %p.lastiter, ptr nonnull %p.lowerbound, ptr nonnull %p.upperbound, ptr nonnull %p.stride, i32 1, i32 0)
  %3 = load i32, ptr %p.lowerbound, align 4
  %4 = load i32, ptr %p.upperbound, align 4
  %reass.sub = sub i32 %4, %3
  %omp_loop.cmp32.not = icmp eq i32 %reass.sub, -1
  br i1 %omp_loop.cmp32.not, label %omp_loop.exit, label %omp_loop.body.lr.ph

omp_loop.body.lr.ph:                              ; preds = %omp.par.entry
  %.unpack = load ptr, ptr @_QFEarr.0, align 8, !tbaa !8
  %.unpack9.unpack.unpack11.b = load i1, ptr @_QFEarr.8, align 1
  %.unpack9.unpack.unpack11 = select i1 %.unpack9.unpack.unpack11.b, i64 1048576, i64 0
  %loadgep_2.repack16 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  %loadgep_2.repack20 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  %loadgep_2.repack24 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  %loadgep_2.repack26.repack28 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  br label %omp_loop.body

omp_loop.header.omp_loop.exit_crit_edge:          ; preds = %omp_loop.body
  %loadgep_2.repack14 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  %loadgep_2.repack18 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  %loadgep_2.repack22 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  %loadgep_2.repack26 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  %loadgep_2.repack26.repack30 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  store ptr %.unpack, ptr %loadgep_2, align 8, !tbaa !8
  store i64 8, ptr %loadgep_2.repack14, align 8, !tbaa !8
  store i32 20180515, ptr %loadgep_2.repack16, align 8, !tbaa !8
  store i8 1, ptr %loadgep_2.repack18, align 4, !tbaa !8
  store i8 28, ptr %loadgep_2.repack20, align 1, !tbaa !8
  store i8 2, ptr %loadgep_2.repack22, align 2, !tbaa !8
  store i8 0, ptr %loadgep_2.repack24, align 1, !tbaa !8
  store i64 1, ptr %loadgep_2.repack26, align 8, !tbaa !8
  store i64 %.unpack9.unpack.unpack11, ptr %loadgep_2.repack26.repack28, align 8, !tbaa !8
  store i64 8, ptr %loadgep_2.repack26.repack30, align 8, !tbaa !8
  br label %omp_loop.exit

omp_loop.exit:                                    ; preds = %omp_loop.header.omp_loop.exit_crit_edge, %omp.par.entry
  call void @__kmpc_for_static_fini(ptr nonnull @1, i32 %omp_global_thread_num4)
  call void @__kmpc_barrier(ptr nonnull @2, i32 %omp_global_thread_num4)
  ret void

omp_loop.body:                                    ; preds = %omp_loop.body.lr.ph, %omp_loop.body
  %omp_loop.iv33 = phi i32 [ 0, %omp_loop.body.lr.ph ], [ %5, %omp_loop.body ]
  %5 = add nuw i32 %omp_loop.iv33, 1
  %6 = add i32 %5, %3
  %7 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %8 = sitofp i32 %7 to float
  %9 = fdiv contract float 1.000000e+00, %8
  %10 = fpext float %9 to double
  %11 = sext i32 %6 to i64
  %12 = sub i64 %11, 1
  %13 = getelementptr double, ptr %.unpack, i64 %12
  store double %10, ptr %13, align 8, !tbaa !4
  %exitcond.not = icmp eq i32 %omp_loop.iv33, %reass.sub
  br i1 %exitcond.not, label %omp_loop.header.omp_loop.exit_crit_edge, label %omp_loop.body
}
*** IR Dump After LCSSAPass on _QQmain..omp_par ***
; Function Attrs: norecurse nounwind
define internal void @_QQmain..omp_par(ptr noalias nocapture readnone %tid.addr, ptr noalias nocapture readnone %zero.addr, ptr nocapture readonly %0) #2 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %p.lastiter = alloca i32, align 4
  %p.lowerbound = alloca i32, align 4
  %p.upperbound = alloca i32, align 4
  %p.stride = alloca i32, align 4
  %1 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %omp_loop.tripcount = tail call i32 @llvm.smax.i32(i32 %1, i32 0)
  store i32 0, ptr %p.lowerbound, align 4
  %2 = add nsw i32 %omp_loop.tripcount, -1
  store i32 %2, ptr %p.upperbound, align 4
  store i32 1, ptr %p.stride, align 4
  %omp_global_thread_num4 = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  call void @__kmpc_for_static_init_4u(ptr nonnull @1, i32 %omp_global_thread_num4, i32 34, ptr nonnull %p.lastiter, ptr nonnull %p.lowerbound, ptr nonnull %p.upperbound, ptr nonnull %p.stride, i32 1, i32 0)
  %3 = load i32, ptr %p.lowerbound, align 4
  %4 = load i32, ptr %p.upperbound, align 4
  %reass.sub = sub i32 %4, %3
  %omp_loop.cmp32.not = icmp eq i32 %reass.sub, -1
  br i1 %omp_loop.cmp32.not, label %omp_loop.exit, label %omp_loop.body.lr.ph

omp_loop.body.lr.ph:                              ; preds = %omp.par.entry
  %.unpack = load ptr, ptr @_QFEarr.0, align 8, !tbaa !8
  %.unpack9.unpack.unpack11.b = load i1, ptr @_QFEarr.8, align 1
  %.unpack9.unpack.unpack11 = select i1 %.unpack9.unpack.unpack11.b, i64 1048576, i64 0
  %loadgep_2.repack16 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  %loadgep_2.repack20 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  %loadgep_2.repack24 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  %loadgep_2.repack26.repack28 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  br label %omp_loop.body

omp_loop.header.omp_loop.exit_crit_edge:          ; preds = %omp_loop.body
  %loadgep_2.repack14 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  %loadgep_2.repack18 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  %loadgep_2.repack22 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  %loadgep_2.repack26 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  %loadgep_2.repack26.repack30 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  store ptr %.unpack, ptr %loadgep_2, align 8, !tbaa !8
  store i64 8, ptr %loadgep_2.repack14, align 8, !tbaa !8
  store i32 20180515, ptr %loadgep_2.repack16, align 8, !tbaa !8
  store i8 1, ptr %loadgep_2.repack18, align 4, !tbaa !8
  store i8 28, ptr %loadgep_2.repack20, align 1, !tbaa !8
  store i8 2, ptr %loadgep_2.repack22, align 2, !tbaa !8
  store i8 0, ptr %loadgep_2.repack24, align 1, !tbaa !8
  store i64 1, ptr %loadgep_2.repack26, align 8, !tbaa !8
  store i64 %.unpack9.unpack.unpack11, ptr %loadgep_2.repack26.repack28, align 8, !tbaa !8
  store i64 8, ptr %loadgep_2.repack26.repack30, align 8, !tbaa !8
  br label %omp_loop.exit

omp_loop.exit:                                    ; preds = %omp_loop.header.omp_loop.exit_crit_edge, %omp.par.entry
  call void @__kmpc_for_static_fini(ptr nonnull @1, i32 %omp_global_thread_num4)
  call void @__kmpc_barrier(ptr nonnull @2, i32 %omp_global_thread_num4)
  ret void

omp_loop.body:                                    ; preds = %omp_loop.body.lr.ph, %omp_loop.body
  %omp_loop.iv33 = phi i32 [ 0, %omp_loop.body.lr.ph ], [ %5, %omp_loop.body ]
  %5 = add nuw i32 %omp_loop.iv33, 1
  %6 = add i32 %5, %3
  %7 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %8 = sitofp i32 %7 to float
  %9 = fdiv contract float 1.000000e+00, %8
  %10 = fpext float %9 to double
  %11 = sext i32 %6 to i64
  %12 = sub i64 %11, 1
  %13 = getelementptr double, ptr %.unpack, i64 %12
  store double %10, ptr %13, align 8, !tbaa !4
  %exitcond.not = icmp eq i32 %omp_loop.iv33, %reass.sub
  br i1 %exitcond.not, label %omp_loop.header.omp_loop.exit_crit_edge, label %omp_loop.body
}
*** IR Dump After LoopRotatePass on omp_loop.body ***

; Preheader:
omp_loop.body.lr.ph:                              ; preds = %omp.par.entry
  %.unpack = load ptr, ptr @_QFEarr.0, align 8, !tbaa !8
  %.unpack9.unpack.unpack11.b = load i1, ptr @_QFEarr.8, align 1
  %.unpack9.unpack.unpack11 = select i1 %.unpack9.unpack.unpack11.b, i64 1048576, i64 0
  %loadgep_2.repack16 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  %loadgep_2.repack20 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  %loadgep_2.repack24 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  %loadgep_2.repack26.repack28 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  br label %omp_loop.body

; Loop:
omp_loop.body:                                    ; preds = %omp_loop.body.lr.ph, %omp_loop.body
  %omp_loop.iv33 = phi i32 [ 0, %omp_loop.body.lr.ph ], [ %5, %omp_loop.body ]
  %5 = add nuw i32 %omp_loop.iv33, 1
  %6 = add i32 %5, %3
  %7 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %8 = sitofp i32 %7 to float
  %9 = fdiv contract float 1.000000e+00, %8
  %10 = fpext float %9 to double
  %11 = sext i32 %6 to i64
  %12 = sub i64 %11, 1
  %13 = getelementptr double, ptr %.unpack, i64 %12
  store double %10, ptr %13, align 8, !tbaa !4
  %exitcond.not = icmp eq i32 %omp_loop.iv33, %reass.sub
  br i1 %exitcond.not, label %omp_loop.header.omp_loop.exit_crit_edge, label %omp_loop.body

; Exit blocks
omp_loop.header.omp_loop.exit_crit_edge:          ; preds = %omp_loop.body
  %loadgep_2.repack14 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  %loadgep_2.repack18 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  %loadgep_2.repack22 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  %loadgep_2.repack26 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  %loadgep_2.repack26.repack30 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  store ptr %.unpack, ptr %loadgep_2, align 8, !tbaa !8
  store i64 8, ptr %loadgep_2.repack14, align 8, !tbaa !8
  store i32 20180515, ptr %loadgep_2.repack16, align 8, !tbaa !8
  store i8 1, ptr %loadgep_2.repack18, align 4, !tbaa !8
  store i8 28, ptr %loadgep_2.repack20, align 1, !tbaa !8
  store i8 2, ptr %loadgep_2.repack22, align 2, !tbaa !8
  store i8 0, ptr %loadgep_2.repack24, align 1, !tbaa !8
  store i64 1, ptr %loadgep_2.repack26, align 8, !tbaa !8
  store i64 %.unpack9.unpack.unpack11, ptr %loadgep_2.repack26.repack28, align 8, !tbaa !8
  store i64 8, ptr %loadgep_2.repack26.repack30, align 8, !tbaa !8
  br label %omp_loop.exit
*** IR Dump After LoopDeletionPass on omp_loop.body ***

; Preheader:
omp_loop.body.lr.ph:                              ; preds = %omp.par.entry
  %.unpack = load ptr, ptr @_QFEarr.0, align 8, !tbaa !8
  %.unpack9.unpack.unpack11.b = load i1, ptr @_QFEarr.8, align 1
  %.unpack9.unpack.unpack11 = select i1 %.unpack9.unpack.unpack11.b, i64 1048576, i64 0
  %loadgep_2.repack16 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  %loadgep_2.repack20 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  %loadgep_2.repack24 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  %loadgep_2.repack26.repack28 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  br label %omp_loop.body

; Loop:
omp_loop.body:                                    ; preds = %omp_loop.body.lr.ph, %omp_loop.body
  %omp_loop.iv33 = phi i32 [ 0, %omp_loop.body.lr.ph ], [ %5, %omp_loop.body ]
  %5 = add nuw i32 %omp_loop.iv33, 1
  %6 = add i32 %5, %3
  %7 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %8 = sitofp i32 %7 to float
  %9 = fdiv contract float 1.000000e+00, %8
  %10 = fpext float %9 to double
  %11 = sext i32 %6 to i64
  %12 = sub i64 %11, 1
  %13 = getelementptr double, ptr %.unpack, i64 %12
  store double %10, ptr %13, align 8, !tbaa !4
  %exitcond.not = icmp eq i32 %omp_loop.iv33, %reass.sub
  br i1 %exitcond.not, label %omp_loop.header.omp_loop.exit_crit_edge, label %omp_loop.body

; Exit blocks
omp_loop.header.omp_loop.exit_crit_edge:          ; preds = %omp_loop.body
  %loadgep_2.repack14 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  %loadgep_2.repack18 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  %loadgep_2.repack22 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  %loadgep_2.repack26 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  %loadgep_2.repack26.repack30 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  store ptr %.unpack, ptr %loadgep_2, align 8, !tbaa !8
  store i64 8, ptr %loadgep_2.repack14, align 8, !tbaa !8
  store i32 20180515, ptr %loadgep_2.repack16, align 8, !tbaa !8
  store i8 1, ptr %loadgep_2.repack18, align 4, !tbaa !8
  store i8 28, ptr %loadgep_2.repack20, align 1, !tbaa !8
  store i8 2, ptr %loadgep_2.repack22, align 2, !tbaa !8
  store i8 0, ptr %loadgep_2.repack24, align 1, !tbaa !8
  store i64 1, ptr %loadgep_2.repack26, align 8, !tbaa !8
  store i64 %.unpack9.unpack.unpack11, ptr %loadgep_2.repack26.repack28, align 8, !tbaa !8
  store i64 8, ptr %loadgep_2.repack26.repack30, align 8, !tbaa !8
  br label %omp_loop.exit
*** IR Dump After LoopDistributePass on _QQmain..omp_par ***
; Function Attrs: norecurse nounwind
define internal void @_QQmain..omp_par(ptr noalias nocapture readnone %tid.addr, ptr noalias nocapture readnone %zero.addr, ptr nocapture readonly %0) #2 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %p.lastiter = alloca i32, align 4
  %p.lowerbound = alloca i32, align 4
  %p.upperbound = alloca i32, align 4
  %p.stride = alloca i32, align 4
  %1 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %omp_loop.tripcount = tail call i32 @llvm.smax.i32(i32 %1, i32 0)
  store i32 0, ptr %p.lowerbound, align 4
  %2 = add nsw i32 %omp_loop.tripcount, -1
  store i32 %2, ptr %p.upperbound, align 4
  store i32 1, ptr %p.stride, align 4
  %omp_global_thread_num4 = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  call void @__kmpc_for_static_init_4u(ptr nonnull @1, i32 %omp_global_thread_num4, i32 34, ptr nonnull %p.lastiter, ptr nonnull %p.lowerbound, ptr nonnull %p.upperbound, ptr nonnull %p.stride, i32 1, i32 0)
  %3 = load i32, ptr %p.lowerbound, align 4
  %4 = load i32, ptr %p.upperbound, align 4
  %reass.sub = sub i32 %4, %3
  %omp_loop.cmp32.not = icmp eq i32 %reass.sub, -1
  br i1 %omp_loop.cmp32.not, label %omp_loop.exit, label %omp_loop.body.lr.ph

omp_loop.body.lr.ph:                              ; preds = %omp.par.entry
  %.unpack = load ptr, ptr @_QFEarr.0, align 8, !tbaa !8
  %.unpack9.unpack.unpack11.b = load i1, ptr @_QFEarr.8, align 1
  %.unpack9.unpack.unpack11 = select i1 %.unpack9.unpack.unpack11.b, i64 1048576, i64 0
  %loadgep_2.repack16 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  %loadgep_2.repack20 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  %loadgep_2.repack24 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  %loadgep_2.repack26.repack28 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  br label %omp_loop.body

omp_loop.header.omp_loop.exit_crit_edge:          ; preds = %omp_loop.body
  %loadgep_2.repack14 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  %loadgep_2.repack18 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  %loadgep_2.repack22 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  %loadgep_2.repack26 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  %loadgep_2.repack26.repack30 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  store ptr %.unpack, ptr %loadgep_2, align 8, !tbaa !8
  store i64 8, ptr %loadgep_2.repack14, align 8, !tbaa !8
  store i32 20180515, ptr %loadgep_2.repack16, align 8, !tbaa !8
  store i8 1, ptr %loadgep_2.repack18, align 4, !tbaa !8
  store i8 28, ptr %loadgep_2.repack20, align 1, !tbaa !8
  store i8 2, ptr %loadgep_2.repack22, align 2, !tbaa !8
  store i8 0, ptr %loadgep_2.repack24, align 1, !tbaa !8
  store i64 1, ptr %loadgep_2.repack26, align 8, !tbaa !8
  store i64 %.unpack9.unpack.unpack11, ptr %loadgep_2.repack26.repack28, align 8, !tbaa !8
  store i64 8, ptr %loadgep_2.repack26.repack30, align 8, !tbaa !8
  br label %omp_loop.exit

omp_loop.exit:                                    ; preds = %omp_loop.header.omp_loop.exit_crit_edge, %omp.par.entry
  call void @__kmpc_for_static_fini(ptr nonnull @1, i32 %omp_global_thread_num4)
  call void @__kmpc_barrier(ptr nonnull @2, i32 %omp_global_thread_num4)
  ret void

omp_loop.body:                                    ; preds = %omp_loop.body.lr.ph, %omp_loop.body
  %omp_loop.iv33 = phi i32 [ 0, %omp_loop.body.lr.ph ], [ %5, %omp_loop.body ]
  %5 = add nuw i32 %omp_loop.iv33, 1
  %6 = add i32 %5, %3
  %7 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %8 = sitofp i32 %7 to float
  %9 = fdiv contract float 1.000000e+00, %8
  %10 = fpext float %9 to double
  %11 = sext i32 %6 to i64
  %12 = sub i64 %11, 1
  %13 = getelementptr double, ptr %.unpack, i64 %12
  store double %10, ptr %13, align 8, !tbaa !4
  %exitcond.not = icmp eq i32 %omp_loop.iv33, %reass.sub
  br i1 %exitcond.not, label %omp_loop.header.omp_loop.exit_crit_edge, label %omp_loop.body
}
*** IR Dump After InjectTLIMappings on _QQmain..omp_par ***
; Function Attrs: norecurse nounwind
define internal void @_QQmain..omp_par(ptr noalias nocapture readnone %tid.addr, ptr noalias nocapture readnone %zero.addr, ptr nocapture readonly %0) #2 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %p.lastiter = alloca i32, align 4
  %p.lowerbound = alloca i32, align 4
  %p.upperbound = alloca i32, align 4
  %p.stride = alloca i32, align 4
  %1 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %omp_loop.tripcount = tail call i32 @llvm.smax.i32(i32 %1, i32 0)
  store i32 0, ptr %p.lowerbound, align 4
  %2 = add nsw i32 %omp_loop.tripcount, -1
  store i32 %2, ptr %p.upperbound, align 4
  store i32 1, ptr %p.stride, align 4
  %omp_global_thread_num4 = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  call void @__kmpc_for_static_init_4u(ptr nonnull @1, i32 %omp_global_thread_num4, i32 34, ptr nonnull %p.lastiter, ptr nonnull %p.lowerbound, ptr nonnull %p.upperbound, ptr nonnull %p.stride, i32 1, i32 0)
  %3 = load i32, ptr %p.lowerbound, align 4
  %4 = load i32, ptr %p.upperbound, align 4
  %reass.sub = sub i32 %4, %3
  %omp_loop.cmp32.not = icmp eq i32 %reass.sub, -1
  br i1 %omp_loop.cmp32.not, label %omp_loop.exit, label %omp_loop.body.lr.ph

omp_loop.body.lr.ph:                              ; preds = %omp.par.entry
  %.unpack = load ptr, ptr @_QFEarr.0, align 8, !tbaa !8
  %.unpack9.unpack.unpack11.b = load i1, ptr @_QFEarr.8, align 1
  %.unpack9.unpack.unpack11 = select i1 %.unpack9.unpack.unpack11.b, i64 1048576, i64 0
  %loadgep_2.repack16 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  %loadgep_2.repack20 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  %loadgep_2.repack24 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  %loadgep_2.repack26.repack28 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  br label %omp_loop.body

omp_loop.header.omp_loop.exit_crit_edge:          ; preds = %omp_loop.body
  %loadgep_2.repack14 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  %loadgep_2.repack18 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  %loadgep_2.repack22 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  %loadgep_2.repack26 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  %loadgep_2.repack26.repack30 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  store ptr %.unpack, ptr %loadgep_2, align 8, !tbaa !8
  store i64 8, ptr %loadgep_2.repack14, align 8, !tbaa !8
  store i32 20180515, ptr %loadgep_2.repack16, align 8, !tbaa !8
  store i8 1, ptr %loadgep_2.repack18, align 4, !tbaa !8
  store i8 28, ptr %loadgep_2.repack20, align 1, !tbaa !8
  store i8 2, ptr %loadgep_2.repack22, align 2, !tbaa !8
  store i8 0, ptr %loadgep_2.repack24, align 1, !tbaa !8
  store i64 1, ptr %loadgep_2.repack26, align 8, !tbaa !8
  store i64 %.unpack9.unpack.unpack11, ptr %loadgep_2.repack26.repack28, align 8, !tbaa !8
  store i64 8, ptr %loadgep_2.repack26.repack30, align 8, !tbaa !8
  br label %omp_loop.exit

omp_loop.exit:                                    ; preds = %omp_loop.header.omp_loop.exit_crit_edge, %omp.par.entry
  call void @__kmpc_for_static_fini(ptr nonnull @1, i32 %omp_global_thread_num4)
  call void @__kmpc_barrier(ptr nonnull @2, i32 %omp_global_thread_num4)
  ret void

omp_loop.body:                                    ; preds = %omp_loop.body.lr.ph, %omp_loop.body
  %omp_loop.iv33 = phi i32 [ 0, %omp_loop.body.lr.ph ], [ %5, %omp_loop.body ]
  %5 = add nuw i32 %omp_loop.iv33, 1
  %6 = add i32 %5, %3
  %7 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %8 = sitofp i32 %7 to float
  %9 = fdiv contract float 1.000000e+00, %8
  %10 = fpext float %9 to double
  %11 = sext i32 %6 to i64
  %12 = sub i64 %11, 1
  %13 = getelementptr double, ptr %.unpack, i64 %12
  store double %10, ptr %13, align 8, !tbaa !4
  %exitcond.not = icmp eq i32 %omp_loop.iv33, %reass.sub
  br i1 %exitcond.not, label %omp_loop.header.omp_loop.exit_crit_edge, label %omp_loop.body
}
*** IR Dump After LoopVectorizePass on _QQmain..omp_par ***
; Function Attrs: norecurse nounwind
define internal void @_QQmain..omp_par(ptr noalias nocapture readnone %tid.addr, ptr noalias nocapture readnone %zero.addr, ptr nocapture readonly %0) #2 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %p.lastiter = alloca i32, align 4
  %p.lowerbound = alloca i32, align 4
  %p.upperbound = alloca i32, align 4
  %p.stride = alloca i32, align 4
  %1 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %omp_loop.tripcount = tail call i32 @llvm.smax.i32(i32 %1, i32 0)
  store i32 0, ptr %p.lowerbound, align 4
  %2 = add nsw i32 %omp_loop.tripcount, -1
  store i32 %2, ptr %p.upperbound, align 4
  store i32 1, ptr %p.stride, align 4
  %omp_global_thread_num4 = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  call void @__kmpc_for_static_init_4u(ptr nonnull @1, i32 %omp_global_thread_num4, i32 34, ptr nonnull %p.lastiter, ptr nonnull %p.lowerbound, ptr nonnull %p.upperbound, ptr nonnull %p.stride, i32 1, i32 0)
  %3 = load i32, ptr %p.lowerbound, align 4
  %4 = load i32, ptr %p.upperbound, align 4
  %reass.sub = sub i32 %4, %3
  %omp_loop.cmp32.not = icmp eq i32 %reass.sub, -1
  br i1 %omp_loop.cmp32.not, label %omp_loop.exit, label %omp_loop.body.lr.ph

omp_loop.body.lr.ph:                              ; preds = %omp.par.entry
  %.unpack = load ptr, ptr @_QFEarr.0, align 8, !tbaa !8
  %.unpack9.unpack.unpack11.b = load i1, ptr @_QFEarr.8, align 1
  %.unpack9.unpack.unpack11 = select i1 %.unpack9.unpack.unpack11.b, i64 1048576, i64 0
  %loadgep_2.repack16 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  %loadgep_2.repack20 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  %loadgep_2.repack24 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  %loadgep_2.repack26.repack28 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  %5 = add i32 %4, 1
  %6 = sub i32 %5, %3
  %min.iters.check = icmp ult i32 %6, 4
  br i1 %min.iters.check, label %scalar.ph, label %vector.scevcheck

vector.scevcheck:                                 ; preds = %omp_loop.body.lr.ph
  %7 = add i32 %3, 1
  %8 = add i32 %7, %reass.sub
  %9 = icmp slt i32 %8, %7
  br i1 %9, label %scalar.ph, label %vector.memcheck

vector.memcheck:                                  ; preds = %vector.scevcheck
  %scevgep = getelementptr i8, ptr %loadgep_, i64 4
  %10 = add i32 %3, 1
  %11 = sext i32 %10 to i64
  %12 = shl nsw i64 %11, 3
  %13 = add nsw i64 %12, -8
  %scevgep34 = getelementptr i8, ptr %.unpack, i64 %13
  %14 = zext i32 %reass.sub to i64
  %15 = shl nuw nsw i64 %14, 3
  %16 = add i64 %12, %15
  %scevgep35 = getelementptr i8, ptr %.unpack, i64 %16
  %bound0 = icmp ult ptr %loadgep_, %scevgep35
  %bound1 = icmp ult ptr %scevgep34, %scevgep
  %found.conflict = and i1 %bound0, %bound1
  br i1 %found.conflict, label %scalar.ph, label %vector.ph

vector.ph:                                        ; preds = %vector.memcheck
  %n.mod.vf = urem i32 %6, 2
  %n.vec = sub i32 %6, %n.mod.vf
  br label %vector.body

vector.body:                                      ; preds = %vector.body, %vector.ph
  %index = phi i32 [ 0, %vector.ph ], [ %index.next, %vector.body ]
  %17 = add i32 %index, 0
  %18 = add nuw i32 %17, 1
  %19 = add i32 %18, %3
  %20 = load i32, ptr %loadgep_, align 4, !tbaa !4, !alias.scope !10, !noalias !13
  %broadcast.splatinsert = insertelement <2 x i32> poison, i32 %20, i64 0
  %broadcast.splat = shufflevector <2 x i32> %broadcast.splatinsert, <2 x i32> poison, <2 x i32> zeroinitializer
  %21 = sitofp <2 x i32> %broadcast.splat to <2 x float>
  %22 = fdiv contract <2 x float> <float 1.000000e+00, float 1.000000e+00>, %21
  %23 = fpext <2 x float> %22 to <2 x double>
  %24 = sext i32 %19 to i64
  %25 = sub i64 %24, 1
  %26 = getelementptr double, ptr %.unpack, i64 %25
  %27 = getelementptr double, ptr %26, i32 0
  store <2 x double> %23, ptr %27, align 8, !tbaa !4, !alias.scope !13
  %index.next = add nuw i32 %index, 2
  %28 = icmp eq i32 %index.next, %n.vec
  br i1 %28, label %middle.block, label %vector.body, !llvm.loop !15

middle.block:                                     ; preds = %vector.body
  %cmp.n = icmp eq i32 %6, %n.vec
  br i1 %cmp.n, label %omp_loop.header.omp_loop.exit_crit_edge, label %scalar.ph

scalar.ph:                                        ; preds = %vector.memcheck, %vector.scevcheck, %omp_loop.body.lr.ph, %middle.block
  %bc.resume.val = phi i32 [ %n.vec, %middle.block ], [ 0, %omp_loop.body.lr.ph ], [ 0, %vector.scevcheck ], [ 0, %vector.memcheck ]
  br label %omp_loop.body

omp_loop.header.omp_loop.exit_crit_edge:          ; preds = %middle.block, %omp_loop.body
  %loadgep_2.repack14 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  %loadgep_2.repack18 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  %loadgep_2.repack22 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  %loadgep_2.repack26 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  %loadgep_2.repack26.repack30 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  store ptr %.unpack, ptr %loadgep_2, align 8, !tbaa !8
  store i64 8, ptr %loadgep_2.repack14, align 8, !tbaa !8
  store i32 20180515, ptr %loadgep_2.repack16, align 8, !tbaa !8
  store i8 1, ptr %loadgep_2.repack18, align 4, !tbaa !8
  store i8 28, ptr %loadgep_2.repack20, align 1, !tbaa !8
  store i8 2, ptr %loadgep_2.repack22, align 2, !tbaa !8
  store i8 0, ptr %loadgep_2.repack24, align 1, !tbaa !8
  store i64 1, ptr %loadgep_2.repack26, align 8, !tbaa !8
  store i64 %.unpack9.unpack.unpack11, ptr %loadgep_2.repack26.repack28, align 8, !tbaa !8
  store i64 8, ptr %loadgep_2.repack26.repack30, align 8, !tbaa !8
  br label %omp_loop.exit

omp_loop.exit:                                    ; preds = %omp_loop.header.omp_loop.exit_crit_edge, %omp.par.entry
  call void @__kmpc_for_static_fini(ptr nonnull @1, i32 %omp_global_thread_num4)
  call void @__kmpc_barrier(ptr nonnull @2, i32 %omp_global_thread_num4)
  ret void

omp_loop.body:                                    ; preds = %scalar.ph, %omp_loop.body
  %omp_loop.iv33 = phi i32 [ %bc.resume.val, %scalar.ph ], [ %29, %omp_loop.body ]
  %29 = add nuw i32 %omp_loop.iv33, 1
  %30 = add i32 %29, %3
  %31 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %32 = sitofp i32 %31 to float
  %33 = fdiv contract float 1.000000e+00, %32
  %34 = fpext float %33 to double
  %35 = sext i32 %30 to i64
  %36 = sub i64 %35, 1
  %37 = getelementptr double, ptr %.unpack, i64 %36
  store double %34, ptr %37, align 8, !tbaa !4
  %exitcond.not = icmp eq i32 %omp_loop.iv33, %reass.sub
  br i1 %exitcond.not, label %omp_loop.header.omp_loop.exit_crit_edge, label %omp_loop.body, !llvm.loop !18
}
*** IR Dump After LoopLoadEliminationPass on _QQmain..omp_par ***
; Function Attrs: norecurse nounwind
define internal void @_QQmain..omp_par(ptr noalias nocapture readnone %tid.addr, ptr noalias nocapture readnone %zero.addr, ptr nocapture readonly %0) #2 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %p.lastiter = alloca i32, align 4
  %p.lowerbound = alloca i32, align 4
  %p.upperbound = alloca i32, align 4
  %p.stride = alloca i32, align 4
  %1 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %omp_loop.tripcount = tail call i32 @llvm.smax.i32(i32 %1, i32 0)
  store i32 0, ptr %p.lowerbound, align 4
  %2 = add nsw i32 %omp_loop.tripcount, -1
  store i32 %2, ptr %p.upperbound, align 4
  store i32 1, ptr %p.stride, align 4
  %omp_global_thread_num4 = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  call void @__kmpc_for_static_init_4u(ptr nonnull @1, i32 %omp_global_thread_num4, i32 34, ptr nonnull %p.lastiter, ptr nonnull %p.lowerbound, ptr nonnull %p.upperbound, ptr nonnull %p.stride, i32 1, i32 0)
  %3 = load i32, ptr %p.lowerbound, align 4
  %4 = load i32, ptr %p.upperbound, align 4
  %reass.sub = sub i32 %4, %3
  %omp_loop.cmp32.not = icmp eq i32 %reass.sub, -1
  br i1 %omp_loop.cmp32.not, label %omp_loop.exit, label %omp_loop.body.lr.ph

omp_loop.body.lr.ph:                              ; preds = %omp.par.entry
  %.unpack = load ptr, ptr @_QFEarr.0, align 8, !tbaa !8
  %.unpack9.unpack.unpack11.b = load i1, ptr @_QFEarr.8, align 1
  %.unpack9.unpack.unpack11 = select i1 %.unpack9.unpack.unpack11.b, i64 1048576, i64 0
  %loadgep_2.repack16 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  %loadgep_2.repack20 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  %loadgep_2.repack24 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  %loadgep_2.repack26.repack28 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  %5 = add i32 %4, 1
  %6 = sub i32 %5, %3
  %min.iters.check = icmp ult i32 %6, 4
  br i1 %min.iters.check, label %scalar.ph, label %vector.scevcheck

vector.scevcheck:                                 ; preds = %omp_loop.body.lr.ph
  %7 = add i32 %3, 1
  %8 = add i32 %7, %reass.sub
  %9 = icmp slt i32 %8, %7
  br i1 %9, label %scalar.ph, label %vector.memcheck

vector.memcheck:                                  ; preds = %vector.scevcheck
  %scevgep = getelementptr i8, ptr %loadgep_, i64 4
  %10 = add i32 %3, 1
  %11 = sext i32 %10 to i64
  %12 = shl nsw i64 %11, 3
  %13 = add nsw i64 %12, -8
  %scevgep34 = getelementptr i8, ptr %.unpack, i64 %13
  %14 = zext i32 %reass.sub to i64
  %15 = shl nuw nsw i64 %14, 3
  %16 = add i64 %12, %15
  %scevgep35 = getelementptr i8, ptr %.unpack, i64 %16
  %bound0 = icmp ult ptr %loadgep_, %scevgep35
  %bound1 = icmp ult ptr %scevgep34, %scevgep
  %found.conflict = and i1 %bound0, %bound1
  br i1 %found.conflict, label %scalar.ph, label %vector.ph

vector.ph:                                        ; preds = %vector.memcheck
  %n.mod.vf = urem i32 %6, 2
  %n.vec = sub i32 %6, %n.mod.vf
  br label %vector.body

vector.body:                                      ; preds = %vector.body, %vector.ph
  %index = phi i32 [ 0, %vector.ph ], [ %index.next, %vector.body ]
  %17 = add i32 %index, 0
  %18 = add nuw i32 %17, 1
  %19 = add i32 %18, %3
  %20 = load i32, ptr %loadgep_, align 4, !tbaa !4, !alias.scope !10, !noalias !13
  %broadcast.splatinsert = insertelement <2 x i32> poison, i32 %20, i64 0
  %broadcast.splat = shufflevector <2 x i32> %broadcast.splatinsert, <2 x i32> poison, <2 x i32> zeroinitializer
  %21 = sitofp <2 x i32> %broadcast.splat to <2 x float>
  %22 = fdiv contract <2 x float> <float 1.000000e+00, float 1.000000e+00>, %21
  %23 = fpext <2 x float> %22 to <2 x double>
  %24 = sext i32 %19 to i64
  %25 = sub i64 %24, 1
  %26 = getelementptr double, ptr %.unpack, i64 %25
  %27 = getelementptr double, ptr %26, i32 0
  store <2 x double> %23, ptr %27, align 8, !tbaa !4, !alias.scope !13
  %index.next = add nuw i32 %index, 2
  %28 = icmp eq i32 %index.next, %n.vec
  br i1 %28, label %middle.block, label %vector.body, !llvm.loop !15

middle.block:                                     ; preds = %vector.body
  %cmp.n = icmp eq i32 %6, %n.vec
  br i1 %cmp.n, label %omp_loop.header.omp_loop.exit_crit_edge, label %scalar.ph

scalar.ph:                                        ; preds = %vector.memcheck, %vector.scevcheck, %omp_loop.body.lr.ph, %middle.block
  %bc.resume.val = phi i32 [ %n.vec, %middle.block ], [ 0, %omp_loop.body.lr.ph ], [ 0, %vector.scevcheck ], [ 0, %vector.memcheck ]
  br label %omp_loop.body

omp_loop.header.omp_loop.exit_crit_edge.loopexit: ; preds = %omp_loop.body
  br label %omp_loop.header.omp_loop.exit_crit_edge

omp_loop.header.omp_loop.exit_crit_edge:          ; preds = %omp_loop.header.omp_loop.exit_crit_edge.loopexit, %middle.block
  %loadgep_2.repack14 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  %loadgep_2.repack18 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  %loadgep_2.repack22 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  %loadgep_2.repack26 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  %loadgep_2.repack26.repack30 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  store ptr %.unpack, ptr %loadgep_2, align 8, !tbaa !8
  store i64 8, ptr %loadgep_2.repack14, align 8, !tbaa !8
  store i32 20180515, ptr %loadgep_2.repack16, align 8, !tbaa !8
  store i8 1, ptr %loadgep_2.repack18, align 4, !tbaa !8
  store i8 28, ptr %loadgep_2.repack20, align 1, !tbaa !8
  store i8 2, ptr %loadgep_2.repack22, align 2, !tbaa !8
  store i8 0, ptr %loadgep_2.repack24, align 1, !tbaa !8
  store i64 1, ptr %loadgep_2.repack26, align 8, !tbaa !8
  store i64 %.unpack9.unpack.unpack11, ptr %loadgep_2.repack26.repack28, align 8, !tbaa !8
  store i64 8, ptr %loadgep_2.repack26.repack30, align 8, !tbaa !8
  br label %omp_loop.exit

omp_loop.exit:                                    ; preds = %omp_loop.header.omp_loop.exit_crit_edge, %omp.par.entry
  call void @__kmpc_for_static_fini(ptr nonnull @1, i32 %omp_global_thread_num4)
  call void @__kmpc_barrier(ptr nonnull @2, i32 %omp_global_thread_num4)
  ret void

omp_loop.body:                                    ; preds = %scalar.ph, %omp_loop.body
  %omp_loop.iv33 = phi i32 [ %bc.resume.val, %scalar.ph ], [ %29, %omp_loop.body ]
  %29 = add nuw i32 %omp_loop.iv33, 1
  %30 = add i32 %29, %3
  %31 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %32 = sitofp i32 %31 to float
  %33 = fdiv contract float 1.000000e+00, %32
  %34 = fpext float %33 to double
  %35 = sext i32 %30 to i64
  %36 = sub i64 %35, 1
  %37 = getelementptr double, ptr %.unpack, i64 %36
  store double %34, ptr %37, align 8, !tbaa !4
  %exitcond.not = icmp eq i32 %omp_loop.iv33, %reass.sub
  br i1 %exitcond.not, label %omp_loop.header.omp_loop.exit_crit_edge.loopexit, label %omp_loop.body, !llvm.loop !18
}
*** IR Dump After InstCombinePass on _QQmain..omp_par ***
; Function Attrs: norecurse nounwind
define internal void @_QQmain..omp_par(ptr noalias nocapture readnone %tid.addr, ptr noalias nocapture readnone %zero.addr, ptr nocapture readonly %0) #2 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %p.lastiter = alloca i32, align 4
  %p.lowerbound = alloca i32, align 4
  %p.upperbound = alloca i32, align 4
  %p.stride = alloca i32, align 4
  %1 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %omp_loop.tripcount = tail call i32 @llvm.smax.i32(i32 %1, i32 0)
  store i32 0, ptr %p.lowerbound, align 4
  %2 = add nsw i32 %omp_loop.tripcount, -1
  store i32 %2, ptr %p.upperbound, align 4
  store i32 1, ptr %p.stride, align 4
  %omp_global_thread_num4 = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  call void @__kmpc_for_static_init_4u(ptr nonnull @1, i32 %omp_global_thread_num4, i32 34, ptr nonnull %p.lastiter, ptr nonnull %p.lowerbound, ptr nonnull %p.upperbound, ptr nonnull %p.stride, i32 1, i32 0)
  %3 = load i32, ptr %p.lowerbound, align 4
  %4 = load i32, ptr %p.upperbound, align 4
  %reass.sub = sub i32 %4, %3
  %omp_loop.cmp32.not = icmp eq i32 %reass.sub, -1
  br i1 %omp_loop.cmp32.not, label %omp_loop.exit, label %omp_loop.body.lr.ph

omp_loop.body.lr.ph:                              ; preds = %omp.par.entry
  %.unpack = load ptr, ptr @_QFEarr.0, align 8, !tbaa !8
  %.unpack9.unpack.unpack11.b = load i1, ptr @_QFEarr.8, align 1
  %.unpack9.unpack.unpack11 = select i1 %.unpack9.unpack.unpack11.b, i64 1048576, i64 0
  %loadgep_2.repack16 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  %loadgep_2.repack20 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  %loadgep_2.repack24 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  %loadgep_2.repack26.repack28 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  %5 = add i32 %4, 1
  %6 = sub i32 %5, %3
  %min.iters.check = icmp ult i32 %6, 4
  br i1 %min.iters.check, label %scalar.ph, label %vector.scevcheck

vector.scevcheck:                                 ; preds = %omp_loop.body.lr.ph
  %7 = add i32 %3, 1
  %8 = add i32 %4, 1
  %9 = icmp slt i32 %8, %7
  br i1 %9, label %scalar.ph, label %vector.memcheck

vector.memcheck:                                  ; preds = %vector.scevcheck
  %scevgep = getelementptr i8, ptr %loadgep_, i64 4
  %10 = add i32 %3, 1
  %11 = sext i32 %10 to i64
  %12 = shl nsw i64 %11, 3
  %13 = add nsw i64 %12, -8
  %scevgep34 = getelementptr i8, ptr %.unpack, i64 %13
  %14 = zext i32 %reass.sub to i64
  %15 = add nsw i64 %11, %14
  %16 = shl nsw i64 %15, 3
  %scevgep35 = getelementptr i8, ptr %.unpack, i64 %16
  %bound0 = icmp ult ptr %loadgep_, %scevgep35
  %bound1 = icmp ult ptr %scevgep34, %scevgep
  %found.conflict = and i1 %bound0, %bound1
  br i1 %found.conflict, label %scalar.ph, label %vector.ph

vector.ph:                                        ; preds = %vector.memcheck
  %n.vec = and i32 %6, -2
  br label %vector.body

vector.body:                                      ; preds = %vector.body, %vector.ph
  %index = phi i32 [ 0, %vector.ph ], [ %index.next, %vector.body ]
  %17 = or i32 %index, 1
  %18 = add i32 %17, %3
  %19 = load i32, ptr %loadgep_, align 4, !tbaa !4, !alias.scope !10, !noalias !13
  %broadcast.splatinsert = insertelement <2 x i32> poison, i32 %19, i64 0
  %20 = sitofp <2 x i32> %broadcast.splatinsert to <2 x float>
  %21 = fdiv contract <2 x float> <float 1.000000e+00, float poison>, %20
  %22 = shufflevector <2 x float> %21, <2 x float> poison, <2 x i32> zeroinitializer
  %23 = fpext <2 x float> %22 to <2 x double>
  %24 = sext i32 %18 to i64
  %25 = add nsw i64 %24, -1
  %26 = getelementptr double, ptr %.unpack, i64 %25
  store <2 x double> %23, ptr %26, align 8, !tbaa !4, !alias.scope !13
  %index.next = add nuw i32 %index, 2
  %27 = icmp eq i32 %index.next, %n.vec
  br i1 %27, label %middle.block, label %vector.body, !llvm.loop !15

middle.block:                                     ; preds = %vector.body
  %cmp.n = icmp eq i32 %6, %n.vec
  br i1 %cmp.n, label %omp_loop.header.omp_loop.exit_crit_edge, label %scalar.ph

scalar.ph:                                        ; preds = %vector.memcheck, %vector.scevcheck, %omp_loop.body.lr.ph, %middle.block
  %bc.resume.val = phi i32 [ %n.vec, %middle.block ], [ 0, %omp_loop.body.lr.ph ], [ 0, %vector.scevcheck ], [ 0, %vector.memcheck ]
  br label %omp_loop.body

omp_loop.header.omp_loop.exit_crit_edge.loopexit: ; preds = %omp_loop.body
  br label %omp_loop.header.omp_loop.exit_crit_edge

omp_loop.header.omp_loop.exit_crit_edge:          ; preds = %omp_loop.header.omp_loop.exit_crit_edge.loopexit, %middle.block
  %loadgep_2.repack14 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  %loadgep_2.repack18 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  %loadgep_2.repack22 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  %loadgep_2.repack26 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  %loadgep_2.repack26.repack30 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  store ptr %.unpack, ptr %loadgep_2, align 8, !tbaa !8
  store i64 8, ptr %loadgep_2.repack14, align 8, !tbaa !8
  store i32 20180515, ptr %loadgep_2.repack16, align 8, !tbaa !8
  store i8 1, ptr %loadgep_2.repack18, align 4, !tbaa !8
  store i8 28, ptr %loadgep_2.repack20, align 1, !tbaa !8
  store i8 2, ptr %loadgep_2.repack22, align 2, !tbaa !8
  store i8 0, ptr %loadgep_2.repack24, align 1, !tbaa !8
  store i64 1, ptr %loadgep_2.repack26, align 8, !tbaa !8
  store i64 %.unpack9.unpack.unpack11, ptr %loadgep_2.repack26.repack28, align 8, !tbaa !8
  store i64 8, ptr %loadgep_2.repack26.repack30, align 8, !tbaa !8
  br label %omp_loop.exit

omp_loop.exit:                                    ; preds = %omp_loop.header.omp_loop.exit_crit_edge, %omp.par.entry
  call void @__kmpc_for_static_fini(ptr nonnull @1, i32 %omp_global_thread_num4)
  call void @__kmpc_barrier(ptr nonnull @2, i32 %omp_global_thread_num4)
  ret void

omp_loop.body:                                    ; preds = %scalar.ph, %omp_loop.body
  %omp_loop.iv33 = phi i32 [ %bc.resume.val, %scalar.ph ], [ %28, %omp_loop.body ]
  %28 = add nuw i32 %omp_loop.iv33, 1
  %29 = add i32 %28, %3
  %30 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %31 = sitofp i32 %30 to float
  %32 = fdiv contract float 1.000000e+00, %31
  %33 = fpext float %32 to double
  %34 = sext i32 %29 to i64
  %35 = add nsw i64 %34, -1
  %36 = getelementptr double, ptr %.unpack, i64 %35
  store double %33, ptr %36, align 8, !tbaa !4
  %exitcond.not = icmp eq i32 %omp_loop.iv33, %reass.sub
  br i1 %exitcond.not, label %omp_loop.header.omp_loop.exit_crit_edge.loopexit, label %omp_loop.body, !llvm.loop !18
}
*** IR Dump After SimplifyCFGPass on _QQmain..omp_par ***
; Function Attrs: norecurse nounwind
define internal void @_QQmain..omp_par(ptr noalias nocapture readnone %tid.addr, ptr noalias nocapture readnone %zero.addr, ptr nocapture readonly %0) #2 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %p.lastiter = alloca i32, align 4
  %p.lowerbound = alloca i32, align 4
  %p.upperbound = alloca i32, align 4
  %p.stride = alloca i32, align 4
  %1 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %omp_loop.tripcount = tail call i32 @llvm.smax.i32(i32 %1, i32 0)
  store i32 0, ptr %p.lowerbound, align 4
  %2 = add nsw i32 %omp_loop.tripcount, -1
  store i32 %2, ptr %p.upperbound, align 4
  store i32 1, ptr %p.stride, align 4
  %omp_global_thread_num4 = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  call void @__kmpc_for_static_init_4u(ptr nonnull @1, i32 %omp_global_thread_num4, i32 34, ptr nonnull %p.lastiter, ptr nonnull %p.lowerbound, ptr nonnull %p.upperbound, ptr nonnull %p.stride, i32 1, i32 0)
  %3 = load i32, ptr %p.lowerbound, align 4
  %4 = load i32, ptr %p.upperbound, align 4
  %reass.sub = sub i32 %4, %3
  %omp_loop.cmp32.not = icmp eq i32 %reass.sub, -1
  br i1 %omp_loop.cmp32.not, label %omp_loop.exit, label %omp_loop.body.lr.ph

omp_loop.body.lr.ph:                              ; preds = %omp.par.entry
  %.unpack = load ptr, ptr @_QFEarr.0, align 8, !tbaa !8
  %.unpack9.unpack.unpack11.b = load i1, ptr @_QFEarr.8, align 1
  %.unpack9.unpack.unpack11 = select i1 %.unpack9.unpack.unpack11.b, i64 1048576, i64 0
  %loadgep_2.repack16 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  %loadgep_2.repack20 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  %loadgep_2.repack24 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  %loadgep_2.repack26.repack28 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  %5 = add i32 %4, 1
  %6 = sub i32 %5, %3
  %min.iters.check = icmp ult i32 %6, 4
  br i1 %min.iters.check, label %omp_loop.body, label %vector.scevcheck

vector.scevcheck:                                 ; preds = %omp_loop.body.lr.ph
  %7 = add i32 %3, 1
  %8 = add i32 %4, 1
  %9 = icmp slt i32 %8, %7
  br i1 %9, label %omp_loop.body, label %vector.memcheck

vector.memcheck:                                  ; preds = %vector.scevcheck
  %scevgep = getelementptr i8, ptr %loadgep_, i64 4
  %10 = add i32 %3, 1
  %11 = sext i32 %10 to i64
  %12 = shl nsw i64 %11, 3
  %13 = add nsw i64 %12, -8
  %scevgep34 = getelementptr i8, ptr %.unpack, i64 %13
  %14 = zext i32 %reass.sub to i64
  %15 = add nsw i64 %11, %14
  %16 = shl nsw i64 %15, 3
  %scevgep35 = getelementptr i8, ptr %.unpack, i64 %16
  %bound0 = icmp ult ptr %loadgep_, %scevgep35
  %bound1 = icmp ult ptr %scevgep34, %scevgep
  %found.conflict = and i1 %bound0, %bound1
  br i1 %found.conflict, label %omp_loop.body, label %vector.ph

vector.ph:                                        ; preds = %vector.memcheck
  %n.vec = and i32 %6, -2
  br label %vector.body

vector.body:                                      ; preds = %vector.body, %vector.ph
  %index = phi i32 [ 0, %vector.ph ], [ %index.next, %vector.body ]
  %17 = or i32 %index, 1
  %18 = add i32 %17, %3
  %19 = load i32, ptr %loadgep_, align 4, !tbaa !4, !alias.scope !10, !noalias !13
  %broadcast.splatinsert = insertelement <2 x i32> poison, i32 %19, i64 0
  %20 = sitofp <2 x i32> %broadcast.splatinsert to <2 x float>
  %21 = fdiv contract <2 x float> <float 1.000000e+00, float poison>, %20
  %22 = shufflevector <2 x float> %21, <2 x float> poison, <2 x i32> zeroinitializer
  %23 = fpext <2 x float> %22 to <2 x double>
  %24 = sext i32 %18 to i64
  %25 = add nsw i64 %24, -1
  %26 = getelementptr double, ptr %.unpack, i64 %25
  store <2 x double> %23, ptr %26, align 8, !tbaa !4, !alias.scope !13
  %index.next = add nuw i32 %index, 2
  %27 = icmp eq i32 %index.next, %n.vec
  br i1 %27, label %middle.block, label %vector.body, !llvm.loop !15

middle.block:                                     ; preds = %vector.body
  %cmp.n = icmp eq i32 %6, %n.vec
  br i1 %cmp.n, label %omp_loop.header.omp_loop.exit_crit_edge, label %omp_loop.body

omp_loop.header.omp_loop.exit_crit_edge:          ; preds = %omp_loop.body, %middle.block
  %loadgep_2.repack14 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  %loadgep_2.repack18 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  %loadgep_2.repack22 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  %loadgep_2.repack26 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  %loadgep_2.repack26.repack30 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  store ptr %.unpack, ptr %loadgep_2, align 8, !tbaa !8
  store i64 8, ptr %loadgep_2.repack14, align 8, !tbaa !8
  store i32 20180515, ptr %loadgep_2.repack16, align 8, !tbaa !8
  store i8 1, ptr %loadgep_2.repack18, align 4, !tbaa !8
  store i8 28, ptr %loadgep_2.repack20, align 1, !tbaa !8
  store i8 2, ptr %loadgep_2.repack22, align 2, !tbaa !8
  store i8 0, ptr %loadgep_2.repack24, align 1, !tbaa !8
  store i64 1, ptr %loadgep_2.repack26, align 8, !tbaa !8
  store i64 %.unpack9.unpack.unpack11, ptr %loadgep_2.repack26.repack28, align 8, !tbaa !8
  store i64 8, ptr %loadgep_2.repack26.repack30, align 8, !tbaa !8
  br label %omp_loop.exit

omp_loop.exit:                                    ; preds = %omp_loop.header.omp_loop.exit_crit_edge, %omp.par.entry
  call void @__kmpc_for_static_fini(ptr nonnull @1, i32 %omp_global_thread_num4)
  call void @__kmpc_barrier(ptr nonnull @2, i32 %omp_global_thread_num4)
  ret void

omp_loop.body:                                    ; preds = %middle.block, %omp_loop.body.lr.ph, %vector.scevcheck, %vector.memcheck, %omp_loop.body
  %omp_loop.iv33 = phi i32 [ %28, %omp_loop.body ], [ %n.vec, %middle.block ], [ 0, %omp_loop.body.lr.ph ], [ 0, %vector.scevcheck ], [ 0, %vector.memcheck ]
  %28 = add nuw i32 %omp_loop.iv33, 1
  %29 = add i32 %28, %3
  %30 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %31 = sitofp i32 %30 to float
  %32 = fdiv contract float 1.000000e+00, %31
  %33 = fpext float %32 to double
  %34 = sext i32 %29 to i64
  %35 = add nsw i64 %34, -1
  %36 = getelementptr double, ptr %.unpack, i64 %35
  store double %33, ptr %36, align 8, !tbaa !4
  %exitcond.not = icmp eq i32 %omp_loop.iv33, %reass.sub
  br i1 %exitcond.not, label %omp_loop.header.omp_loop.exit_crit_edge, label %omp_loop.body, !llvm.loop !18
}
*** IR Dump After VectorCombinePass on _QQmain..omp_par ***
; Function Attrs: norecurse nounwind
define internal void @_QQmain..omp_par(ptr noalias nocapture readnone %tid.addr, ptr noalias nocapture readnone %zero.addr, ptr nocapture readonly %0) #2 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %p.lastiter = alloca i32, align 4
  %p.lowerbound = alloca i32, align 4
  %p.upperbound = alloca i32, align 4
  %p.stride = alloca i32, align 4
  %1 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %omp_loop.tripcount = tail call i32 @llvm.smax.i32(i32 %1, i32 0)
  store i32 0, ptr %p.lowerbound, align 4
  %2 = add nsw i32 %omp_loop.tripcount, -1
  store i32 %2, ptr %p.upperbound, align 4
  store i32 1, ptr %p.stride, align 4
  %omp_global_thread_num4 = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  call void @__kmpc_for_static_init_4u(ptr nonnull @1, i32 %omp_global_thread_num4, i32 34, ptr nonnull %p.lastiter, ptr nonnull %p.lowerbound, ptr nonnull %p.upperbound, ptr nonnull %p.stride, i32 1, i32 0)
  %3 = load i32, ptr %p.lowerbound, align 4
  %4 = load i32, ptr %p.upperbound, align 4
  %reass.sub = sub i32 %4, %3
  %omp_loop.cmp32.not = icmp eq i32 %reass.sub, -1
  br i1 %omp_loop.cmp32.not, label %omp_loop.exit, label %omp_loop.body.lr.ph

omp_loop.body.lr.ph:                              ; preds = %omp.par.entry
  %.unpack = load ptr, ptr @_QFEarr.0, align 8, !tbaa !8
  %.unpack9.unpack.unpack11.b = load i1, ptr @_QFEarr.8, align 1
  %.unpack9.unpack.unpack11 = select i1 %.unpack9.unpack.unpack11.b, i64 1048576, i64 0
  %loadgep_2.repack16 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  %loadgep_2.repack20 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  %loadgep_2.repack24 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  %loadgep_2.repack26.repack28 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  %5 = add i32 %4, 1
  %6 = sub i32 %5, %3
  %min.iters.check = icmp ult i32 %6, 4
  br i1 %min.iters.check, label %omp_loop.body, label %vector.scevcheck

vector.scevcheck:                                 ; preds = %omp_loop.body.lr.ph
  %7 = add i32 %3, 1
  %8 = add i32 %4, 1
  %9 = icmp slt i32 %8, %7
  br i1 %9, label %omp_loop.body, label %vector.memcheck

vector.memcheck:                                  ; preds = %vector.scevcheck
  %scevgep = getelementptr i8, ptr %loadgep_, i64 4
  %10 = add i32 %3, 1
  %11 = sext i32 %10 to i64
  %12 = shl nsw i64 %11, 3
  %13 = add nsw i64 %12, -8
  %scevgep34 = getelementptr i8, ptr %.unpack, i64 %13
  %14 = zext i32 %reass.sub to i64
  %15 = add nsw i64 %11, %14
  %16 = shl nsw i64 %15, 3
  %scevgep35 = getelementptr i8, ptr %.unpack, i64 %16
  %bound0 = icmp ult ptr %loadgep_, %scevgep35
  %bound1 = icmp ult ptr %scevgep34, %scevgep
  %found.conflict = and i1 %bound0, %bound1
  br i1 %found.conflict, label %omp_loop.body, label %vector.ph

vector.ph:                                        ; preds = %vector.memcheck
  %n.vec = and i32 %6, -2
  br label %vector.body

vector.body:                                      ; preds = %vector.body, %vector.ph
  %index = phi i32 [ 0, %vector.ph ], [ %index.next, %vector.body ]
  %17 = or i32 %index, 1
  %18 = add i32 %17, %3
  %19 = load i32, ptr %loadgep_, align 4, !tbaa !4, !alias.scope !10, !noalias !13
  %broadcast.splatinsert = insertelement <2 x i32> poison, i32 %19, i64 0
  %20 = sitofp <2 x i32> %broadcast.splatinsert to <2 x float>
  %21 = fdiv contract <2 x float> <float 1.000000e+00, float poison>, %20
  %22 = shufflevector <2 x float> %21, <2 x float> poison, <2 x i32> zeroinitializer
  %23 = fpext <2 x float> %22 to <2 x double>
  %24 = sext i32 %18 to i64
  %25 = add nsw i64 %24, -1
  %26 = getelementptr double, ptr %.unpack, i64 %25
  store <2 x double> %23, ptr %26, align 8, !tbaa !4, !alias.scope !13
  %index.next = add nuw i32 %index, 2
  %27 = icmp eq i32 %index.next, %n.vec
  br i1 %27, label %middle.block, label %vector.body, !llvm.loop !15

middle.block:                                     ; preds = %vector.body
  %cmp.n = icmp eq i32 %6, %n.vec
  br i1 %cmp.n, label %omp_loop.header.omp_loop.exit_crit_edge, label %omp_loop.body

omp_loop.header.omp_loop.exit_crit_edge:          ; preds = %omp_loop.body, %middle.block
  %loadgep_2.repack14 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  %loadgep_2.repack18 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  %loadgep_2.repack22 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  %loadgep_2.repack26 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  %loadgep_2.repack26.repack30 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  store ptr %.unpack, ptr %loadgep_2, align 8, !tbaa !8
  store i64 8, ptr %loadgep_2.repack14, align 8, !tbaa !8
  store i32 20180515, ptr %loadgep_2.repack16, align 8, !tbaa !8
  store i8 1, ptr %loadgep_2.repack18, align 4, !tbaa !8
  store i8 28, ptr %loadgep_2.repack20, align 1, !tbaa !8
  store i8 2, ptr %loadgep_2.repack22, align 2, !tbaa !8
  store i8 0, ptr %loadgep_2.repack24, align 1, !tbaa !8
  store i64 1, ptr %loadgep_2.repack26, align 8, !tbaa !8
  store i64 %.unpack9.unpack.unpack11, ptr %loadgep_2.repack26.repack28, align 8, !tbaa !8
  store i64 8, ptr %loadgep_2.repack26.repack30, align 8, !tbaa !8
  br label %omp_loop.exit

omp_loop.exit:                                    ; preds = %omp_loop.header.omp_loop.exit_crit_edge, %omp.par.entry
  call void @__kmpc_for_static_fini(ptr nonnull @1, i32 %omp_global_thread_num4)
  call void @__kmpc_barrier(ptr nonnull @2, i32 %omp_global_thread_num4)
  ret void

omp_loop.body:                                    ; preds = %middle.block, %omp_loop.body.lr.ph, %vector.scevcheck, %vector.memcheck, %omp_loop.body
  %omp_loop.iv33 = phi i32 [ %28, %omp_loop.body ], [ %n.vec, %middle.block ], [ 0, %omp_loop.body.lr.ph ], [ 0, %vector.scevcheck ], [ 0, %vector.memcheck ]
  %28 = add nuw i32 %omp_loop.iv33, 1
  %29 = add i32 %28, %3
  %30 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %31 = sitofp i32 %30 to float
  %32 = fdiv contract float 1.000000e+00, %31
  %33 = fpext float %32 to double
  %34 = sext i32 %29 to i64
  %35 = add nsw i64 %34, -1
  %36 = getelementptr double, ptr %.unpack, i64 %35
  store double %33, ptr %36, align 8, !tbaa !4
  %exitcond.not = icmp eq i32 %omp_loop.iv33, %reass.sub
  br i1 %exitcond.not, label %omp_loop.header.omp_loop.exit_crit_edge, label %omp_loop.body, !llvm.loop !18
}
*** IR Dump After InstCombinePass on _QQmain..omp_par ***
; Function Attrs: norecurse nounwind
define internal void @_QQmain..omp_par(ptr noalias nocapture readnone %tid.addr, ptr noalias nocapture readnone %zero.addr, ptr nocapture readonly %0) #2 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %p.lastiter = alloca i32, align 4
  %p.lowerbound = alloca i32, align 4
  %p.upperbound = alloca i32, align 4
  %p.stride = alloca i32, align 4
  %1 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %omp_loop.tripcount = tail call i32 @llvm.smax.i32(i32 %1, i32 0)
  store i32 0, ptr %p.lowerbound, align 4
  %2 = add nsw i32 %omp_loop.tripcount, -1
  store i32 %2, ptr %p.upperbound, align 4
  store i32 1, ptr %p.stride, align 4
  %omp_global_thread_num4 = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  call void @__kmpc_for_static_init_4u(ptr nonnull @1, i32 %omp_global_thread_num4, i32 34, ptr nonnull %p.lastiter, ptr nonnull %p.lowerbound, ptr nonnull %p.upperbound, ptr nonnull %p.stride, i32 1, i32 0)
  %3 = load i32, ptr %p.lowerbound, align 4
  %4 = load i32, ptr %p.upperbound, align 4
  %reass.sub = sub i32 %4, %3
  %omp_loop.cmp32.not = icmp eq i32 %reass.sub, -1
  br i1 %omp_loop.cmp32.not, label %omp_loop.exit, label %omp_loop.body.lr.ph

omp_loop.body.lr.ph:                              ; preds = %omp.par.entry
  %.unpack = load ptr, ptr @_QFEarr.0, align 8, !tbaa !8
  %.unpack9.unpack.unpack11.b = load i1, ptr @_QFEarr.8, align 1
  %.unpack9.unpack.unpack11 = select i1 %.unpack9.unpack.unpack11.b, i64 1048576, i64 0
  %loadgep_2.repack16 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  %loadgep_2.repack20 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  %loadgep_2.repack24 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  %loadgep_2.repack26.repack28 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  %5 = add i32 %4, 1
  %6 = sub i32 %5, %3
  %min.iters.check = icmp ult i32 %6, 4
  br i1 %min.iters.check, label %omp_loop.body, label %vector.scevcheck

vector.scevcheck:                                 ; preds = %omp_loop.body.lr.ph
  %7 = add i32 %3, 1
  %8 = add i32 %4, 1
  %9 = icmp slt i32 %8, %7
  br i1 %9, label %omp_loop.body, label %vector.memcheck

vector.memcheck:                                  ; preds = %vector.scevcheck
  %scevgep = getelementptr i8, ptr %loadgep_, i64 4
  %10 = add i32 %3, 1
  %11 = sext i32 %10 to i64
  %12 = shl nsw i64 %11, 3
  %13 = add nsw i64 %12, -8
  %scevgep34 = getelementptr i8, ptr %.unpack, i64 %13
  %14 = zext i32 %reass.sub to i64
  %15 = add nsw i64 %11, %14
  %16 = shl nsw i64 %15, 3
  %scevgep35 = getelementptr i8, ptr %.unpack, i64 %16
  %bound0 = icmp ult ptr %loadgep_, %scevgep35
  %bound1 = icmp ult ptr %scevgep34, %scevgep
  %found.conflict = and i1 %bound0, %bound1
  br i1 %found.conflict, label %omp_loop.body, label %vector.ph

vector.ph:                                        ; preds = %vector.memcheck
  %n.vec = and i32 %6, -2
  br label %vector.body

vector.body:                                      ; preds = %vector.body, %vector.ph
  %index = phi i32 [ 0, %vector.ph ], [ %index.next, %vector.body ]
  %17 = or i32 %index, 1
  %18 = add i32 %17, %3
  %19 = load i32, ptr %loadgep_, align 4, !tbaa !4, !alias.scope !10, !noalias !13
  %broadcast.splatinsert = insertelement <2 x i32> poison, i32 %19, i64 0
  %20 = sitofp <2 x i32> %broadcast.splatinsert to <2 x float>
  %21 = fdiv contract <2 x float> <float 1.000000e+00, float poison>, %20
  %22 = shufflevector <2 x float> %21, <2 x float> poison, <2 x i32> zeroinitializer
  %23 = fpext <2 x float> %22 to <2 x double>
  %24 = sext i32 %18 to i64
  %25 = add nsw i64 %24, -1
  %26 = getelementptr double, ptr %.unpack, i64 %25
  store <2 x double> %23, ptr %26, align 8, !tbaa !4, !alias.scope !13
  %index.next = add nuw i32 %index, 2
  %27 = icmp eq i32 %index.next, %n.vec
  br i1 %27, label %middle.block, label %vector.body, !llvm.loop !15

middle.block:                                     ; preds = %vector.body
  %cmp.n = icmp eq i32 %6, %n.vec
  br i1 %cmp.n, label %omp_loop.header.omp_loop.exit_crit_edge, label %omp_loop.body

omp_loop.header.omp_loop.exit_crit_edge:          ; preds = %omp_loop.body, %middle.block
  %loadgep_2.repack14 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  %loadgep_2.repack18 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  %loadgep_2.repack22 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  %loadgep_2.repack26 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  %loadgep_2.repack26.repack30 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  store ptr %.unpack, ptr %loadgep_2, align 8, !tbaa !8
  store i64 8, ptr %loadgep_2.repack14, align 8, !tbaa !8
  store i32 20180515, ptr %loadgep_2.repack16, align 8, !tbaa !8
  store i8 1, ptr %loadgep_2.repack18, align 4, !tbaa !8
  store i8 28, ptr %loadgep_2.repack20, align 1, !tbaa !8
  store i8 2, ptr %loadgep_2.repack22, align 2, !tbaa !8
  store i8 0, ptr %loadgep_2.repack24, align 1, !tbaa !8
  store i64 1, ptr %loadgep_2.repack26, align 8, !tbaa !8
  store i64 %.unpack9.unpack.unpack11, ptr %loadgep_2.repack26.repack28, align 8, !tbaa !8
  store i64 8, ptr %loadgep_2.repack26.repack30, align 8, !tbaa !8
  br label %omp_loop.exit

omp_loop.exit:                                    ; preds = %omp_loop.header.omp_loop.exit_crit_edge, %omp.par.entry
  call void @__kmpc_for_static_fini(ptr nonnull @1, i32 %omp_global_thread_num4)
  call void @__kmpc_barrier(ptr nonnull @2, i32 %omp_global_thread_num4)
  ret void

omp_loop.body:                                    ; preds = %middle.block, %omp_loop.body.lr.ph, %vector.scevcheck, %vector.memcheck, %omp_loop.body
  %omp_loop.iv33 = phi i32 [ %28, %omp_loop.body ], [ %n.vec, %middle.block ], [ 0, %omp_loop.body.lr.ph ], [ 0, %vector.scevcheck ], [ 0, %vector.memcheck ]
  %28 = add nuw i32 %omp_loop.iv33, 1
  %29 = add i32 %28, %3
  %30 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %31 = sitofp i32 %30 to float
  %32 = fdiv contract float 1.000000e+00, %31
  %33 = fpext float %32 to double
  %34 = sext i32 %29 to i64
  %35 = add nsw i64 %34, -1
  %36 = getelementptr double, ptr %.unpack, i64 %35
  store double %33, ptr %36, align 8, !tbaa !4
  %exitcond.not = icmp eq i32 %omp_loop.iv33, %reass.sub
  br i1 %exitcond.not, label %omp_loop.header.omp_loop.exit_crit_edge, label %omp_loop.body, !llvm.loop !18
}
*** IR Dump After LoopUnrollPass on _QQmain..omp_par ***
; Function Attrs: norecurse nounwind
define internal void @_QQmain..omp_par(ptr noalias nocapture readnone %tid.addr, ptr noalias nocapture readnone %zero.addr, ptr nocapture readonly %0) #2 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %p.lastiter = alloca i32, align 4
  %p.lowerbound = alloca i32, align 4
  %p.upperbound = alloca i32, align 4
  %p.stride = alloca i32, align 4
  %1 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %omp_loop.tripcount = tail call i32 @llvm.smax.i32(i32 %1, i32 0)
  store i32 0, ptr %p.lowerbound, align 4
  %2 = add nsw i32 %omp_loop.tripcount, -1
  store i32 %2, ptr %p.upperbound, align 4
  store i32 1, ptr %p.stride, align 4
  %omp_global_thread_num4 = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  call void @__kmpc_for_static_init_4u(ptr nonnull @1, i32 %omp_global_thread_num4, i32 34, ptr nonnull %p.lastiter, ptr nonnull %p.lowerbound, ptr nonnull %p.upperbound, ptr nonnull %p.stride, i32 1, i32 0)
  %3 = load i32, ptr %p.lowerbound, align 4
  %4 = load i32, ptr %p.upperbound, align 4
  %reass.sub = sub i32 %4, %3
  %omp_loop.cmp32.not = icmp eq i32 %reass.sub, -1
  br i1 %omp_loop.cmp32.not, label %omp_loop.exit, label %omp_loop.body.lr.ph

omp_loop.body.lr.ph:                              ; preds = %omp.par.entry
  %.unpack = load ptr, ptr @_QFEarr.0, align 8, !tbaa !8
  %.unpack9.unpack.unpack11.b = load i1, ptr @_QFEarr.8, align 1
  %.unpack9.unpack.unpack11 = select i1 %.unpack9.unpack.unpack11.b, i64 1048576, i64 0
  %loadgep_2.repack16 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  %loadgep_2.repack20 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  %loadgep_2.repack24 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  %loadgep_2.repack26.repack28 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  %5 = add i32 %4, 1
  %6 = sub i32 %5, %3
  %min.iters.check = icmp ult i32 %6, 4
  br i1 %min.iters.check, label %omp_loop.body.preheader, label %vector.scevcheck

vector.scevcheck:                                 ; preds = %omp_loop.body.lr.ph
  %7 = add i32 %3, 1
  %8 = add i32 %4, 1
  %9 = icmp slt i32 %8, %7
  br i1 %9, label %omp_loop.body.preheader, label %vector.memcheck

vector.memcheck:                                  ; preds = %vector.scevcheck
  %scevgep = getelementptr i8, ptr %loadgep_, i64 4
  %10 = add i32 %3, 1
  %11 = sext i32 %10 to i64
  %12 = shl nsw i64 %11, 3
  %13 = add nsw i64 %12, -8
  %scevgep34 = getelementptr i8, ptr %.unpack, i64 %13
  %14 = zext i32 %reass.sub to i64
  %15 = add nsw i64 %11, %14
  %16 = shl nsw i64 %15, 3
  %scevgep35 = getelementptr i8, ptr %.unpack, i64 %16
  %bound0 = icmp ult ptr %loadgep_, %scevgep35
  %bound1 = icmp ult ptr %scevgep34, %scevgep
  %found.conflict = and i1 %bound0, %bound1
  br i1 %found.conflict, label %omp_loop.body.preheader, label %vector.ph

vector.ph:                                        ; preds = %vector.memcheck
  %n.vec = and i32 %6, -2
  br label %vector.body

vector.body:                                      ; preds = %vector.body, %vector.ph
  %index = phi i32 [ 0, %vector.ph ], [ %index.next, %vector.body ]
  %17 = or i32 %index, 1
  %18 = add i32 %17, %3
  %19 = load i32, ptr %loadgep_, align 4, !tbaa !4, !alias.scope !10, !noalias !13
  %broadcast.splatinsert = insertelement <2 x i32> poison, i32 %19, i64 0
  %20 = sitofp <2 x i32> %broadcast.splatinsert to <2 x float>
  %21 = fdiv contract <2 x float> <float 1.000000e+00, float poison>, %20
  %22 = shufflevector <2 x float> %21, <2 x float> poison, <2 x i32> zeroinitializer
  %23 = fpext <2 x float> %22 to <2 x double>
  %24 = sext i32 %18 to i64
  %25 = add nsw i64 %24, -1
  %26 = getelementptr double, ptr %.unpack, i64 %25
  store <2 x double> %23, ptr %26, align 8, !tbaa !4, !alias.scope !13
  %index.next = add nuw i32 %index, 2
  %27 = icmp eq i32 %index.next, %n.vec
  br i1 %27, label %middle.block, label %vector.body, !llvm.loop !15

middle.block:                                     ; preds = %vector.body
  %cmp.n = icmp eq i32 %6, %n.vec
  br i1 %cmp.n, label %omp_loop.header.omp_loop.exit_crit_edge, label %omp_loop.body.preheader

omp_loop.body.preheader:                          ; preds = %vector.memcheck, %vector.scevcheck, %omp_loop.body.lr.ph, %middle.block
  %omp_loop.iv33.ph = phi i32 [ 0, %vector.memcheck ], [ 0, %vector.scevcheck ], [ 0, %omp_loop.body.lr.ph ], [ %n.vec, %middle.block ]
  br label %omp_loop.body

omp_loop.header.omp_loop.exit_crit_edge.loopexit: ; preds = %omp_loop.body
  br label %omp_loop.header.omp_loop.exit_crit_edge

omp_loop.header.omp_loop.exit_crit_edge:          ; preds = %omp_loop.header.omp_loop.exit_crit_edge.loopexit, %middle.block
  %loadgep_2.repack14 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  %loadgep_2.repack18 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  %loadgep_2.repack22 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  %loadgep_2.repack26 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  %loadgep_2.repack26.repack30 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  store ptr %.unpack, ptr %loadgep_2, align 8, !tbaa !8
  store i64 8, ptr %loadgep_2.repack14, align 8, !tbaa !8
  store i32 20180515, ptr %loadgep_2.repack16, align 8, !tbaa !8
  store i8 1, ptr %loadgep_2.repack18, align 4, !tbaa !8
  store i8 28, ptr %loadgep_2.repack20, align 1, !tbaa !8
  store i8 2, ptr %loadgep_2.repack22, align 2, !tbaa !8
  store i8 0, ptr %loadgep_2.repack24, align 1, !tbaa !8
  store i64 1, ptr %loadgep_2.repack26, align 8, !tbaa !8
  store i64 %.unpack9.unpack.unpack11, ptr %loadgep_2.repack26.repack28, align 8, !tbaa !8
  store i64 8, ptr %loadgep_2.repack26.repack30, align 8, !tbaa !8
  br label %omp_loop.exit

omp_loop.exit:                                    ; preds = %omp_loop.header.omp_loop.exit_crit_edge, %omp.par.entry
  call void @__kmpc_for_static_fini(ptr nonnull @1, i32 %omp_global_thread_num4)
  call void @__kmpc_barrier(ptr nonnull @2, i32 %omp_global_thread_num4)
  ret void

omp_loop.body:                                    ; preds = %omp_loop.body.preheader, %omp_loop.body
  %omp_loop.iv33 = phi i32 [ %28, %omp_loop.body ], [ %omp_loop.iv33.ph, %omp_loop.body.preheader ]
  %28 = add nuw i32 %omp_loop.iv33, 1
  %29 = add i32 %28, %3
  %30 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %31 = sitofp i32 %30 to float
  %32 = fdiv contract float 1.000000e+00, %31
  %33 = fpext float %32 to double
  %34 = sext i32 %29 to i64
  %35 = add nsw i64 %34, -1
  %36 = getelementptr double, ptr %.unpack, i64 %35
  store double %33, ptr %36, align 8, !tbaa !4
  %exitcond.not = icmp eq i32 %omp_loop.iv33, %reass.sub
  br i1 %exitcond.not, label %omp_loop.header.omp_loop.exit_crit_edge.loopexit, label %omp_loop.body, !llvm.loop !18
}
*** IR Dump After WarnMissedTransformationsPass on _QQmain..omp_par ***
; Function Attrs: norecurse nounwind
define internal void @_QQmain..omp_par(ptr noalias nocapture readnone %tid.addr, ptr noalias nocapture readnone %zero.addr, ptr nocapture readonly %0) #2 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %p.lastiter = alloca i32, align 4
  %p.lowerbound = alloca i32, align 4
  %p.upperbound = alloca i32, align 4
  %p.stride = alloca i32, align 4
  %1 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %omp_loop.tripcount = tail call i32 @llvm.smax.i32(i32 %1, i32 0)
  store i32 0, ptr %p.lowerbound, align 4
  %2 = add nsw i32 %omp_loop.tripcount, -1
  store i32 %2, ptr %p.upperbound, align 4
  store i32 1, ptr %p.stride, align 4
  %omp_global_thread_num4 = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  call void @__kmpc_for_static_init_4u(ptr nonnull @1, i32 %omp_global_thread_num4, i32 34, ptr nonnull %p.lastiter, ptr nonnull %p.lowerbound, ptr nonnull %p.upperbound, ptr nonnull %p.stride, i32 1, i32 0)
  %3 = load i32, ptr %p.lowerbound, align 4
  %4 = load i32, ptr %p.upperbound, align 4
  %reass.sub = sub i32 %4, %3
  %omp_loop.cmp32.not = icmp eq i32 %reass.sub, -1
  br i1 %omp_loop.cmp32.not, label %omp_loop.exit, label %omp_loop.body.lr.ph

omp_loop.body.lr.ph:                              ; preds = %omp.par.entry
  %.unpack = load ptr, ptr @_QFEarr.0, align 8, !tbaa !8
  %.unpack9.unpack.unpack11.b = load i1, ptr @_QFEarr.8, align 1
  %.unpack9.unpack.unpack11 = select i1 %.unpack9.unpack.unpack11.b, i64 1048576, i64 0
  %loadgep_2.repack16 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  %loadgep_2.repack20 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  %loadgep_2.repack24 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  %loadgep_2.repack26.repack28 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  %5 = add i32 %4, 1
  %6 = sub i32 %5, %3
  %min.iters.check = icmp ult i32 %6, 4
  br i1 %min.iters.check, label %omp_loop.body.preheader, label %vector.scevcheck

vector.scevcheck:                                 ; preds = %omp_loop.body.lr.ph
  %7 = add i32 %3, 1
  %8 = add i32 %4, 1
  %9 = icmp slt i32 %8, %7
  br i1 %9, label %omp_loop.body.preheader, label %vector.memcheck

vector.memcheck:                                  ; preds = %vector.scevcheck
  %scevgep = getelementptr i8, ptr %loadgep_, i64 4
  %10 = add i32 %3, 1
  %11 = sext i32 %10 to i64
  %12 = shl nsw i64 %11, 3
  %13 = add nsw i64 %12, -8
  %scevgep34 = getelementptr i8, ptr %.unpack, i64 %13
  %14 = zext i32 %reass.sub to i64
  %15 = add nsw i64 %11, %14
  %16 = shl nsw i64 %15, 3
  %scevgep35 = getelementptr i8, ptr %.unpack, i64 %16
  %bound0 = icmp ult ptr %loadgep_, %scevgep35
  %bound1 = icmp ult ptr %scevgep34, %scevgep
  %found.conflict = and i1 %bound0, %bound1
  br i1 %found.conflict, label %omp_loop.body.preheader, label %vector.ph

vector.ph:                                        ; preds = %vector.memcheck
  %n.vec = and i32 %6, -2
  br label %vector.body

vector.body:                                      ; preds = %vector.body, %vector.ph
  %index = phi i32 [ 0, %vector.ph ], [ %index.next, %vector.body ]
  %17 = or i32 %index, 1
  %18 = add i32 %17, %3
  %19 = load i32, ptr %loadgep_, align 4, !tbaa !4, !alias.scope !10, !noalias !13
  %broadcast.splatinsert = insertelement <2 x i32> poison, i32 %19, i64 0
  %20 = sitofp <2 x i32> %broadcast.splatinsert to <2 x float>
  %21 = fdiv contract <2 x float> <float 1.000000e+00, float poison>, %20
  %22 = shufflevector <2 x float> %21, <2 x float> poison, <2 x i32> zeroinitializer
  %23 = fpext <2 x float> %22 to <2 x double>
  %24 = sext i32 %18 to i64
  %25 = add nsw i64 %24, -1
  %26 = getelementptr double, ptr %.unpack, i64 %25
  store <2 x double> %23, ptr %26, align 8, !tbaa !4, !alias.scope !13
  %index.next = add nuw i32 %index, 2
  %27 = icmp eq i32 %index.next, %n.vec
  br i1 %27, label %middle.block, label %vector.body, !llvm.loop !15

middle.block:                                     ; preds = %vector.body
  %cmp.n = icmp eq i32 %6, %n.vec
  br i1 %cmp.n, label %omp_loop.header.omp_loop.exit_crit_edge, label %omp_loop.body.preheader

omp_loop.body.preheader:                          ; preds = %vector.memcheck, %vector.scevcheck, %omp_loop.body.lr.ph, %middle.block
  %omp_loop.iv33.ph = phi i32 [ 0, %vector.memcheck ], [ 0, %vector.scevcheck ], [ 0, %omp_loop.body.lr.ph ], [ %n.vec, %middle.block ]
  br label %omp_loop.body

omp_loop.header.omp_loop.exit_crit_edge.loopexit: ; preds = %omp_loop.body
  br label %omp_loop.header.omp_loop.exit_crit_edge

omp_loop.header.omp_loop.exit_crit_edge:          ; preds = %omp_loop.header.omp_loop.exit_crit_edge.loopexit, %middle.block
  %loadgep_2.repack14 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  %loadgep_2.repack18 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  %loadgep_2.repack22 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  %loadgep_2.repack26 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  %loadgep_2.repack26.repack30 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  store ptr %.unpack, ptr %loadgep_2, align 8, !tbaa !8
  store i64 8, ptr %loadgep_2.repack14, align 8, !tbaa !8
  store i32 20180515, ptr %loadgep_2.repack16, align 8, !tbaa !8
  store i8 1, ptr %loadgep_2.repack18, align 4, !tbaa !8
  store i8 28, ptr %loadgep_2.repack20, align 1, !tbaa !8
  store i8 2, ptr %loadgep_2.repack22, align 2, !tbaa !8
  store i8 0, ptr %loadgep_2.repack24, align 1, !tbaa !8
  store i64 1, ptr %loadgep_2.repack26, align 8, !tbaa !8
  store i64 %.unpack9.unpack.unpack11, ptr %loadgep_2.repack26.repack28, align 8, !tbaa !8
  store i64 8, ptr %loadgep_2.repack26.repack30, align 8, !tbaa !8
  br label %omp_loop.exit

omp_loop.exit:                                    ; preds = %omp_loop.header.omp_loop.exit_crit_edge, %omp.par.entry
  call void @__kmpc_for_static_fini(ptr nonnull @1, i32 %omp_global_thread_num4)
  call void @__kmpc_barrier(ptr nonnull @2, i32 %omp_global_thread_num4)
  ret void

omp_loop.body:                                    ; preds = %omp_loop.body.preheader, %omp_loop.body
  %omp_loop.iv33 = phi i32 [ %28, %omp_loop.body ], [ %omp_loop.iv33.ph, %omp_loop.body.preheader ]
  %28 = add nuw i32 %omp_loop.iv33, 1
  %29 = add i32 %28, %3
  %30 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %31 = sitofp i32 %30 to float
  %32 = fdiv contract float 1.000000e+00, %31
  %33 = fpext float %32 to double
  %34 = sext i32 %29 to i64
  %35 = add nsw i64 %34, -1
  %36 = getelementptr double, ptr %.unpack, i64 %35
  store double %33, ptr %36, align 8, !tbaa !4
  %exitcond.not = icmp eq i32 %omp_loop.iv33, %reass.sub
  br i1 %exitcond.not, label %omp_loop.header.omp_loop.exit_crit_edge.loopexit, label %omp_loop.body, !llvm.loop !18
}
*** IR Dump After SROAPass on _QQmain..omp_par ***
; Function Attrs: norecurse nounwind
define internal void @_QQmain..omp_par(ptr noalias nocapture readnone %tid.addr, ptr noalias nocapture readnone %zero.addr, ptr nocapture readonly %0) #2 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %p.lastiter = alloca i32, align 4
  %p.lowerbound = alloca i32, align 4
  %p.upperbound = alloca i32, align 4
  %p.stride = alloca i32, align 4
  %1 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %omp_loop.tripcount = tail call i32 @llvm.smax.i32(i32 %1, i32 0)
  store i32 0, ptr %p.lowerbound, align 4
  %2 = add nsw i32 %omp_loop.tripcount, -1
  store i32 %2, ptr %p.upperbound, align 4
  store i32 1, ptr %p.stride, align 4
  %omp_global_thread_num4 = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  call void @__kmpc_for_static_init_4u(ptr nonnull @1, i32 %omp_global_thread_num4, i32 34, ptr nonnull %p.lastiter, ptr nonnull %p.lowerbound, ptr nonnull %p.upperbound, ptr nonnull %p.stride, i32 1, i32 0)
  %3 = load i32, ptr %p.lowerbound, align 4
  %4 = load i32, ptr %p.upperbound, align 4
  %reass.sub = sub i32 %4, %3
  %omp_loop.cmp32.not = icmp eq i32 %reass.sub, -1
  br i1 %omp_loop.cmp32.not, label %omp_loop.exit, label %omp_loop.body.lr.ph

omp_loop.body.lr.ph:                              ; preds = %omp.par.entry
  %.unpack = load ptr, ptr @_QFEarr.0, align 8, !tbaa !8
  %.unpack9.unpack.unpack11.b = load i1, ptr @_QFEarr.8, align 1
  %.unpack9.unpack.unpack11 = select i1 %.unpack9.unpack.unpack11.b, i64 1048576, i64 0
  %loadgep_2.repack16 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  %loadgep_2.repack20 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  %loadgep_2.repack24 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  %loadgep_2.repack26.repack28 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  %5 = add i32 %4, 1
  %6 = sub i32 %5, %3
  %min.iters.check = icmp ult i32 %6, 4
  br i1 %min.iters.check, label %omp_loop.body.preheader, label %vector.scevcheck

vector.scevcheck:                                 ; preds = %omp_loop.body.lr.ph
  %7 = add i32 %3, 1
  %8 = add i32 %4, 1
  %9 = icmp slt i32 %8, %7
  br i1 %9, label %omp_loop.body.preheader, label %vector.memcheck

vector.memcheck:                                  ; preds = %vector.scevcheck
  %scevgep = getelementptr i8, ptr %loadgep_, i64 4
  %10 = add i32 %3, 1
  %11 = sext i32 %10 to i64
  %12 = shl nsw i64 %11, 3
  %13 = add nsw i64 %12, -8
  %scevgep34 = getelementptr i8, ptr %.unpack, i64 %13
  %14 = zext i32 %reass.sub to i64
  %15 = add nsw i64 %11, %14
  %16 = shl nsw i64 %15, 3
  %scevgep35 = getelementptr i8, ptr %.unpack, i64 %16
  %bound0 = icmp ult ptr %loadgep_, %scevgep35
  %bound1 = icmp ult ptr %scevgep34, %scevgep
  %found.conflict = and i1 %bound0, %bound1
  br i1 %found.conflict, label %omp_loop.body.preheader, label %vector.ph

vector.ph:                                        ; preds = %vector.memcheck
  %n.vec = and i32 %6, -2
  br label %vector.body

vector.body:                                      ; preds = %vector.body, %vector.ph
  %index = phi i32 [ 0, %vector.ph ], [ %index.next, %vector.body ]
  %17 = or i32 %index, 1
  %18 = add i32 %17, %3
  %19 = load i32, ptr %loadgep_, align 4, !tbaa !4, !alias.scope !10, !noalias !13
  %broadcast.splatinsert = insertelement <2 x i32> poison, i32 %19, i64 0
  %20 = sitofp <2 x i32> %broadcast.splatinsert to <2 x float>
  %21 = fdiv contract <2 x float> <float 1.000000e+00, float poison>, %20
  %22 = shufflevector <2 x float> %21, <2 x float> poison, <2 x i32> zeroinitializer
  %23 = fpext <2 x float> %22 to <2 x double>
  %24 = sext i32 %18 to i64
  %25 = add nsw i64 %24, -1
  %26 = getelementptr double, ptr %.unpack, i64 %25
  store <2 x double> %23, ptr %26, align 8, !tbaa !4, !alias.scope !13
  %index.next = add nuw i32 %index, 2
  %27 = icmp eq i32 %index.next, %n.vec
  br i1 %27, label %middle.block, label %vector.body, !llvm.loop !15

middle.block:                                     ; preds = %vector.body
  %cmp.n = icmp eq i32 %6, %n.vec
  br i1 %cmp.n, label %omp_loop.header.omp_loop.exit_crit_edge, label %omp_loop.body.preheader

omp_loop.body.preheader:                          ; preds = %vector.memcheck, %vector.scevcheck, %omp_loop.body.lr.ph, %middle.block
  %omp_loop.iv33.ph = phi i32 [ 0, %vector.memcheck ], [ 0, %vector.scevcheck ], [ 0, %omp_loop.body.lr.ph ], [ %n.vec, %middle.block ]
  br label %omp_loop.body

omp_loop.header.omp_loop.exit_crit_edge.loopexit: ; preds = %omp_loop.body
  br label %omp_loop.header.omp_loop.exit_crit_edge

omp_loop.header.omp_loop.exit_crit_edge:          ; preds = %omp_loop.header.omp_loop.exit_crit_edge.loopexit, %middle.block
  %loadgep_2.repack14 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  %loadgep_2.repack18 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  %loadgep_2.repack22 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  %loadgep_2.repack26 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  %loadgep_2.repack26.repack30 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  store ptr %.unpack, ptr %loadgep_2, align 8, !tbaa !8
  store i64 8, ptr %loadgep_2.repack14, align 8, !tbaa !8
  store i32 20180515, ptr %loadgep_2.repack16, align 8, !tbaa !8
  store i8 1, ptr %loadgep_2.repack18, align 4, !tbaa !8
  store i8 28, ptr %loadgep_2.repack20, align 1, !tbaa !8
  store i8 2, ptr %loadgep_2.repack22, align 2, !tbaa !8
  store i8 0, ptr %loadgep_2.repack24, align 1, !tbaa !8
  store i64 1, ptr %loadgep_2.repack26, align 8, !tbaa !8
  store i64 %.unpack9.unpack.unpack11, ptr %loadgep_2.repack26.repack28, align 8, !tbaa !8
  store i64 8, ptr %loadgep_2.repack26.repack30, align 8, !tbaa !8
  br label %omp_loop.exit

omp_loop.exit:                                    ; preds = %omp_loop.header.omp_loop.exit_crit_edge, %omp.par.entry
  call void @__kmpc_for_static_fini(ptr nonnull @1, i32 %omp_global_thread_num4)
  call void @__kmpc_barrier(ptr nonnull @2, i32 %omp_global_thread_num4)
  ret void

omp_loop.body:                                    ; preds = %omp_loop.body.preheader, %omp_loop.body
  %omp_loop.iv33 = phi i32 [ %28, %omp_loop.body ], [ %omp_loop.iv33.ph, %omp_loop.body.preheader ]
  %28 = add nuw i32 %omp_loop.iv33, 1
  %29 = add i32 %28, %3
  %30 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %31 = sitofp i32 %30 to float
  %32 = fdiv contract float 1.000000e+00, %31
  %33 = fpext float %32 to double
  %34 = sext i32 %29 to i64
  %35 = add nsw i64 %34, -1
  %36 = getelementptr double, ptr %.unpack, i64 %35
  store double %33, ptr %36, align 8, !tbaa !4
  %exitcond.not = icmp eq i32 %omp_loop.iv33, %reass.sub
  br i1 %exitcond.not, label %omp_loop.header.omp_loop.exit_crit_edge.loopexit, label %omp_loop.body, !llvm.loop !18
}
*** IR Dump After InstCombinePass on _QQmain..omp_par ***
; Function Attrs: norecurse nounwind
define internal void @_QQmain..omp_par(ptr noalias nocapture readnone %tid.addr, ptr noalias nocapture readnone %zero.addr, ptr nocapture readonly %0) #2 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %p.lastiter = alloca i32, align 4
  %p.lowerbound = alloca i32, align 4
  %p.upperbound = alloca i32, align 4
  %p.stride = alloca i32, align 4
  %1 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %omp_loop.tripcount = tail call i32 @llvm.smax.i32(i32 %1, i32 0)
  store i32 0, ptr %p.lowerbound, align 4
  %2 = add nsw i32 %omp_loop.tripcount, -1
  store i32 %2, ptr %p.upperbound, align 4
  store i32 1, ptr %p.stride, align 4
  %omp_global_thread_num4 = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  call void @__kmpc_for_static_init_4u(ptr nonnull @1, i32 %omp_global_thread_num4, i32 34, ptr nonnull %p.lastiter, ptr nonnull %p.lowerbound, ptr nonnull %p.upperbound, ptr nonnull %p.stride, i32 1, i32 0)
  %3 = load i32, ptr %p.lowerbound, align 4
  %4 = load i32, ptr %p.upperbound, align 4
  %reass.sub = sub i32 %4, %3
  %omp_loop.cmp32.not = icmp eq i32 %reass.sub, -1
  br i1 %omp_loop.cmp32.not, label %omp_loop.exit, label %omp_loop.body.lr.ph

omp_loop.body.lr.ph:                              ; preds = %omp.par.entry
  %.unpack = load ptr, ptr @_QFEarr.0, align 8, !tbaa !8
  %.unpack9.unpack.unpack11.b = load i1, ptr @_QFEarr.8, align 1
  %.unpack9.unpack.unpack11 = select i1 %.unpack9.unpack.unpack11.b, i64 1048576, i64 0
  %loadgep_2.repack16 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  %loadgep_2.repack20 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  %loadgep_2.repack24 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  %loadgep_2.repack26.repack28 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  %5 = add i32 %4, 1
  %6 = sub i32 %5, %3
  %min.iters.check = icmp ult i32 %6, 4
  br i1 %min.iters.check, label %omp_loop.body.preheader, label %vector.scevcheck

vector.scevcheck:                                 ; preds = %omp_loop.body.lr.ph
  %7 = add i32 %3, 1
  %8 = add i32 %4, 1
  %9 = icmp slt i32 %8, %7
  br i1 %9, label %omp_loop.body.preheader, label %vector.memcheck

vector.memcheck:                                  ; preds = %vector.scevcheck
  %scevgep = getelementptr i8, ptr %loadgep_, i64 4
  %10 = add i32 %3, 1
  %11 = sext i32 %10 to i64
  %12 = shl nsw i64 %11, 3
  %13 = add nsw i64 %12, -8
  %scevgep34 = getelementptr i8, ptr %.unpack, i64 %13
  %14 = zext i32 %reass.sub to i64
  %15 = add nsw i64 %11, %14
  %16 = shl nsw i64 %15, 3
  %scevgep35 = getelementptr i8, ptr %.unpack, i64 %16
  %bound0 = icmp ult ptr %loadgep_, %scevgep35
  %bound1 = icmp ult ptr %scevgep34, %scevgep
  %found.conflict = and i1 %bound0, %bound1
  br i1 %found.conflict, label %omp_loop.body.preheader, label %vector.ph

vector.ph:                                        ; preds = %vector.memcheck
  %n.vec = and i32 %6, -2
  br label %vector.body

vector.body:                                      ; preds = %vector.body, %vector.ph
  %index = phi i32 [ 0, %vector.ph ], [ %index.next, %vector.body ]
  %17 = or i32 %index, 1
  %18 = add i32 %17, %3
  %19 = load i32, ptr %loadgep_, align 4, !tbaa !4, !alias.scope !10, !noalias !13
  %broadcast.splatinsert = insertelement <2 x i32> poison, i32 %19, i64 0
  %20 = sitofp <2 x i32> %broadcast.splatinsert to <2 x float>
  %21 = fdiv contract <2 x float> <float 1.000000e+00, float poison>, %20
  %22 = shufflevector <2 x float> %21, <2 x float> poison, <2 x i32> zeroinitializer
  %23 = fpext <2 x float> %22 to <2 x double>
  %24 = sext i32 %18 to i64
  %25 = add nsw i64 %24, -1
  %26 = getelementptr double, ptr %.unpack, i64 %25
  store <2 x double> %23, ptr %26, align 8, !tbaa !4, !alias.scope !13
  %index.next = add nuw i32 %index, 2
  %27 = icmp eq i32 %index.next, %n.vec
  br i1 %27, label %middle.block, label %vector.body, !llvm.loop !15

middle.block:                                     ; preds = %vector.body
  %cmp.n = icmp eq i32 %6, %n.vec
  br i1 %cmp.n, label %omp_loop.header.omp_loop.exit_crit_edge, label %omp_loop.body.preheader

omp_loop.body.preheader:                          ; preds = %vector.memcheck, %vector.scevcheck, %omp_loop.body.lr.ph, %middle.block
  %omp_loop.iv33.ph = phi i32 [ 0, %vector.memcheck ], [ 0, %vector.scevcheck ], [ 0, %omp_loop.body.lr.ph ], [ %n.vec, %middle.block ]
  br label %omp_loop.body

omp_loop.header.omp_loop.exit_crit_edge.loopexit: ; preds = %omp_loop.body
  br label %omp_loop.header.omp_loop.exit_crit_edge

omp_loop.header.omp_loop.exit_crit_edge:          ; preds = %omp_loop.header.omp_loop.exit_crit_edge.loopexit, %middle.block
  %loadgep_2.repack14 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  %loadgep_2.repack18 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  %loadgep_2.repack22 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  %loadgep_2.repack26 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  %loadgep_2.repack26.repack30 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  store ptr %.unpack, ptr %loadgep_2, align 8, !tbaa !8
  store i64 8, ptr %loadgep_2.repack14, align 8, !tbaa !8
  store i32 20180515, ptr %loadgep_2.repack16, align 8, !tbaa !8
  store i8 1, ptr %loadgep_2.repack18, align 4, !tbaa !8
  store i8 28, ptr %loadgep_2.repack20, align 1, !tbaa !8
  store i8 2, ptr %loadgep_2.repack22, align 2, !tbaa !8
  store i8 0, ptr %loadgep_2.repack24, align 1, !tbaa !8
  store i64 1, ptr %loadgep_2.repack26, align 8, !tbaa !8
  store i64 %.unpack9.unpack.unpack11, ptr %loadgep_2.repack26.repack28, align 8, !tbaa !8
  store i64 8, ptr %loadgep_2.repack26.repack30, align 8, !tbaa !8
  br label %omp_loop.exit

omp_loop.exit:                                    ; preds = %omp_loop.header.omp_loop.exit_crit_edge, %omp.par.entry
  call void @__kmpc_for_static_fini(ptr nonnull @1, i32 %omp_global_thread_num4)
  call void @__kmpc_barrier(ptr nonnull @2, i32 %omp_global_thread_num4)
  ret void

omp_loop.body:                                    ; preds = %omp_loop.body.preheader, %omp_loop.body
  %omp_loop.iv33 = phi i32 [ %28, %omp_loop.body ], [ %omp_loop.iv33.ph, %omp_loop.body.preheader ]
  %28 = add nuw i32 %omp_loop.iv33, 1
  %29 = add i32 %28, %3
  %30 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %31 = sitofp i32 %30 to float
  %32 = fdiv contract float 1.000000e+00, %31
  %33 = fpext float %32 to double
  %34 = sext i32 %29 to i64
  %35 = add nsw i64 %34, -1
  %36 = getelementptr double, ptr %.unpack, i64 %35
  store double %33, ptr %36, align 8, !tbaa !4
  %exitcond.not = icmp eq i32 %omp_loop.iv33, %reass.sub
  br i1 %exitcond.not, label %omp_loop.header.omp_loop.exit_crit_edge.loopexit, label %omp_loop.body, !llvm.loop !18
}
*** IR Dump After LoopSimplifyPass on _QQmain..omp_par ***
; Function Attrs: norecurse nounwind
define internal void @_QQmain..omp_par(ptr noalias nocapture readnone %tid.addr, ptr noalias nocapture readnone %zero.addr, ptr nocapture readonly %0) #2 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %p.lastiter = alloca i32, align 4
  %p.lowerbound = alloca i32, align 4
  %p.upperbound = alloca i32, align 4
  %p.stride = alloca i32, align 4
  %1 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %omp_loop.tripcount = tail call i32 @llvm.smax.i32(i32 %1, i32 0)
  store i32 0, ptr %p.lowerbound, align 4
  %2 = add nsw i32 %omp_loop.tripcount, -1
  store i32 %2, ptr %p.upperbound, align 4
  store i32 1, ptr %p.stride, align 4
  %omp_global_thread_num4 = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  call void @__kmpc_for_static_init_4u(ptr nonnull @1, i32 %omp_global_thread_num4, i32 34, ptr nonnull %p.lastiter, ptr nonnull %p.lowerbound, ptr nonnull %p.upperbound, ptr nonnull %p.stride, i32 1, i32 0)
  %3 = load i32, ptr %p.lowerbound, align 4
  %4 = load i32, ptr %p.upperbound, align 4
  %reass.sub = sub i32 %4, %3
  %omp_loop.cmp32.not = icmp eq i32 %reass.sub, -1
  br i1 %omp_loop.cmp32.not, label %omp_loop.exit, label %omp_loop.body.lr.ph

omp_loop.body.lr.ph:                              ; preds = %omp.par.entry
  %.unpack = load ptr, ptr @_QFEarr.0, align 8, !tbaa !8
  %.unpack9.unpack.unpack11.b = load i1, ptr @_QFEarr.8, align 1
  %.unpack9.unpack.unpack11 = select i1 %.unpack9.unpack.unpack11.b, i64 1048576, i64 0
  %loadgep_2.repack16 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  %loadgep_2.repack20 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  %loadgep_2.repack24 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  %loadgep_2.repack26.repack28 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  %5 = add i32 %4, 1
  %6 = sub i32 %5, %3
  %min.iters.check = icmp ult i32 %6, 4
  br i1 %min.iters.check, label %omp_loop.body.preheader, label %vector.scevcheck

vector.scevcheck:                                 ; preds = %omp_loop.body.lr.ph
  %7 = add i32 %3, 1
  %8 = add i32 %4, 1
  %9 = icmp slt i32 %8, %7
  br i1 %9, label %omp_loop.body.preheader, label %vector.memcheck

vector.memcheck:                                  ; preds = %vector.scevcheck
  %scevgep = getelementptr i8, ptr %loadgep_, i64 4
  %10 = add i32 %3, 1
  %11 = sext i32 %10 to i64
  %12 = shl nsw i64 %11, 3
  %13 = add nsw i64 %12, -8
  %scevgep34 = getelementptr i8, ptr %.unpack, i64 %13
  %14 = zext i32 %reass.sub to i64
  %15 = add nsw i64 %11, %14
  %16 = shl nsw i64 %15, 3
  %scevgep35 = getelementptr i8, ptr %.unpack, i64 %16
  %bound0 = icmp ult ptr %loadgep_, %scevgep35
  %bound1 = icmp ult ptr %scevgep34, %scevgep
  %found.conflict = and i1 %bound0, %bound1
  br i1 %found.conflict, label %omp_loop.body.preheader, label %vector.ph

vector.ph:                                        ; preds = %vector.memcheck
  %n.vec = and i32 %6, -2
  br label %vector.body

vector.body:                                      ; preds = %vector.body, %vector.ph
  %index = phi i32 [ 0, %vector.ph ], [ %index.next, %vector.body ]
  %17 = or i32 %index, 1
  %18 = add i32 %17, %3
  %19 = load i32, ptr %loadgep_, align 4, !tbaa !4, !alias.scope !10, !noalias !13
  %broadcast.splatinsert = insertelement <2 x i32> poison, i32 %19, i64 0
  %20 = sitofp <2 x i32> %broadcast.splatinsert to <2 x float>
  %21 = fdiv contract <2 x float> <float 1.000000e+00, float poison>, %20
  %22 = shufflevector <2 x float> %21, <2 x float> poison, <2 x i32> zeroinitializer
  %23 = fpext <2 x float> %22 to <2 x double>
  %24 = sext i32 %18 to i64
  %25 = add nsw i64 %24, -1
  %26 = getelementptr double, ptr %.unpack, i64 %25
  store <2 x double> %23, ptr %26, align 8, !tbaa !4, !alias.scope !13
  %index.next = add nuw i32 %index, 2
  %27 = icmp eq i32 %index.next, %n.vec
  br i1 %27, label %middle.block, label %vector.body, !llvm.loop !15

middle.block:                                     ; preds = %vector.body
  %cmp.n = icmp eq i32 %6, %n.vec
  br i1 %cmp.n, label %omp_loop.header.omp_loop.exit_crit_edge, label %omp_loop.body.preheader

omp_loop.body.preheader:                          ; preds = %vector.memcheck, %vector.scevcheck, %omp_loop.body.lr.ph, %middle.block
  %omp_loop.iv33.ph = phi i32 [ 0, %vector.memcheck ], [ 0, %vector.scevcheck ], [ 0, %omp_loop.body.lr.ph ], [ %n.vec, %middle.block ]
  br label %omp_loop.body

omp_loop.header.omp_loop.exit_crit_edge.loopexit: ; preds = %omp_loop.body
  br label %omp_loop.header.omp_loop.exit_crit_edge

omp_loop.header.omp_loop.exit_crit_edge:          ; preds = %omp_loop.header.omp_loop.exit_crit_edge.loopexit, %middle.block
  %loadgep_2.repack14 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  %loadgep_2.repack18 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  %loadgep_2.repack22 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  %loadgep_2.repack26 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  %loadgep_2.repack26.repack30 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  store ptr %.unpack, ptr %loadgep_2, align 8, !tbaa !8
  store i64 8, ptr %loadgep_2.repack14, align 8, !tbaa !8
  store i32 20180515, ptr %loadgep_2.repack16, align 8, !tbaa !8
  store i8 1, ptr %loadgep_2.repack18, align 4, !tbaa !8
  store i8 28, ptr %loadgep_2.repack20, align 1, !tbaa !8
  store i8 2, ptr %loadgep_2.repack22, align 2, !tbaa !8
  store i8 0, ptr %loadgep_2.repack24, align 1, !tbaa !8
  store i64 1, ptr %loadgep_2.repack26, align 8, !tbaa !8
  store i64 %.unpack9.unpack.unpack11, ptr %loadgep_2.repack26.repack28, align 8, !tbaa !8
  store i64 8, ptr %loadgep_2.repack26.repack30, align 8, !tbaa !8
  br label %omp_loop.exit

omp_loop.exit:                                    ; preds = %omp_loop.header.omp_loop.exit_crit_edge, %omp.par.entry
  call void @__kmpc_for_static_fini(ptr nonnull @1, i32 %omp_global_thread_num4)
  call void @__kmpc_barrier(ptr nonnull @2, i32 %omp_global_thread_num4)
  ret void

omp_loop.body:                                    ; preds = %omp_loop.body.preheader, %omp_loop.body
  %omp_loop.iv33 = phi i32 [ %28, %omp_loop.body ], [ %omp_loop.iv33.ph, %omp_loop.body.preheader ]
  %28 = add nuw i32 %omp_loop.iv33, 1
  %29 = add i32 %28, %3
  %30 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %31 = sitofp i32 %30 to float
  %32 = fdiv contract float 1.000000e+00, %31
  %33 = fpext float %32 to double
  %34 = sext i32 %29 to i64
  %35 = add nsw i64 %34, -1
  %36 = getelementptr double, ptr %.unpack, i64 %35
  store double %33, ptr %36, align 8, !tbaa !4
  %exitcond.not = icmp eq i32 %omp_loop.iv33, %reass.sub
  br i1 %exitcond.not, label %omp_loop.header.omp_loop.exit_crit_edge.loopexit, label %omp_loop.body, !llvm.loop !18
}
*** IR Dump After LCSSAPass on _QQmain..omp_par ***
; Function Attrs: norecurse nounwind
define internal void @_QQmain..omp_par(ptr noalias nocapture readnone %tid.addr, ptr noalias nocapture readnone %zero.addr, ptr nocapture readonly %0) #2 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %p.lastiter = alloca i32, align 4
  %p.lowerbound = alloca i32, align 4
  %p.upperbound = alloca i32, align 4
  %p.stride = alloca i32, align 4
  %1 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %omp_loop.tripcount = tail call i32 @llvm.smax.i32(i32 %1, i32 0)
  store i32 0, ptr %p.lowerbound, align 4
  %2 = add nsw i32 %omp_loop.tripcount, -1
  store i32 %2, ptr %p.upperbound, align 4
  store i32 1, ptr %p.stride, align 4
  %omp_global_thread_num4 = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  call void @__kmpc_for_static_init_4u(ptr nonnull @1, i32 %omp_global_thread_num4, i32 34, ptr nonnull %p.lastiter, ptr nonnull %p.lowerbound, ptr nonnull %p.upperbound, ptr nonnull %p.stride, i32 1, i32 0)
  %3 = load i32, ptr %p.lowerbound, align 4
  %4 = load i32, ptr %p.upperbound, align 4
  %reass.sub = sub i32 %4, %3
  %omp_loop.cmp32.not = icmp eq i32 %reass.sub, -1
  br i1 %omp_loop.cmp32.not, label %omp_loop.exit, label %omp_loop.body.lr.ph

omp_loop.body.lr.ph:                              ; preds = %omp.par.entry
  %.unpack = load ptr, ptr @_QFEarr.0, align 8, !tbaa !8
  %.unpack9.unpack.unpack11.b = load i1, ptr @_QFEarr.8, align 1
  %.unpack9.unpack.unpack11 = select i1 %.unpack9.unpack.unpack11.b, i64 1048576, i64 0
  %loadgep_2.repack16 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  %loadgep_2.repack20 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  %loadgep_2.repack24 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  %loadgep_2.repack26.repack28 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  %5 = add i32 %4, 1
  %6 = sub i32 %5, %3
  %min.iters.check = icmp ult i32 %6, 4
  br i1 %min.iters.check, label %omp_loop.body.preheader, label %vector.scevcheck

vector.scevcheck:                                 ; preds = %omp_loop.body.lr.ph
  %7 = add i32 %3, 1
  %8 = add i32 %4, 1
  %9 = icmp slt i32 %8, %7
  br i1 %9, label %omp_loop.body.preheader, label %vector.memcheck

vector.memcheck:                                  ; preds = %vector.scevcheck
  %scevgep = getelementptr i8, ptr %loadgep_, i64 4
  %10 = add i32 %3, 1
  %11 = sext i32 %10 to i64
  %12 = shl nsw i64 %11, 3
  %13 = add nsw i64 %12, -8
  %scevgep34 = getelementptr i8, ptr %.unpack, i64 %13
  %14 = zext i32 %reass.sub to i64
  %15 = add nsw i64 %11, %14
  %16 = shl nsw i64 %15, 3
  %scevgep35 = getelementptr i8, ptr %.unpack, i64 %16
  %bound0 = icmp ult ptr %loadgep_, %scevgep35
  %bound1 = icmp ult ptr %scevgep34, %scevgep
  %found.conflict = and i1 %bound0, %bound1
  br i1 %found.conflict, label %omp_loop.body.preheader, label %vector.ph

vector.ph:                                        ; preds = %vector.memcheck
  %n.vec = and i32 %6, -2
  br label %vector.body

vector.body:                                      ; preds = %vector.body, %vector.ph
  %index = phi i32 [ 0, %vector.ph ], [ %index.next, %vector.body ]
  %17 = or i32 %index, 1
  %18 = add i32 %17, %3
  %19 = load i32, ptr %loadgep_, align 4, !tbaa !4, !alias.scope !10, !noalias !13
  %broadcast.splatinsert = insertelement <2 x i32> poison, i32 %19, i64 0
  %20 = sitofp <2 x i32> %broadcast.splatinsert to <2 x float>
  %21 = fdiv contract <2 x float> <float 1.000000e+00, float poison>, %20
  %22 = shufflevector <2 x float> %21, <2 x float> poison, <2 x i32> zeroinitializer
  %23 = fpext <2 x float> %22 to <2 x double>
  %24 = sext i32 %18 to i64
  %25 = add nsw i64 %24, -1
  %26 = getelementptr double, ptr %.unpack, i64 %25
  store <2 x double> %23, ptr %26, align 8, !tbaa !4, !alias.scope !13
  %index.next = add nuw i32 %index, 2
  %27 = icmp eq i32 %index.next, %n.vec
  br i1 %27, label %middle.block, label %vector.body, !llvm.loop !15

middle.block:                                     ; preds = %vector.body
  %cmp.n = icmp eq i32 %6, %n.vec
  br i1 %cmp.n, label %omp_loop.header.omp_loop.exit_crit_edge, label %omp_loop.body.preheader

omp_loop.body.preheader:                          ; preds = %vector.memcheck, %vector.scevcheck, %omp_loop.body.lr.ph, %middle.block
  %omp_loop.iv33.ph = phi i32 [ 0, %vector.memcheck ], [ 0, %vector.scevcheck ], [ 0, %omp_loop.body.lr.ph ], [ %n.vec, %middle.block ]
  br label %omp_loop.body

omp_loop.header.omp_loop.exit_crit_edge.loopexit: ; preds = %omp_loop.body
  br label %omp_loop.header.omp_loop.exit_crit_edge

omp_loop.header.omp_loop.exit_crit_edge:          ; preds = %omp_loop.header.omp_loop.exit_crit_edge.loopexit, %middle.block
  %loadgep_2.repack14 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  %loadgep_2.repack18 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  %loadgep_2.repack22 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  %loadgep_2.repack26 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  %loadgep_2.repack26.repack30 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  store ptr %.unpack, ptr %loadgep_2, align 8, !tbaa !8
  store i64 8, ptr %loadgep_2.repack14, align 8, !tbaa !8
  store i32 20180515, ptr %loadgep_2.repack16, align 8, !tbaa !8
  store i8 1, ptr %loadgep_2.repack18, align 4, !tbaa !8
  store i8 28, ptr %loadgep_2.repack20, align 1, !tbaa !8
  store i8 2, ptr %loadgep_2.repack22, align 2, !tbaa !8
  store i8 0, ptr %loadgep_2.repack24, align 1, !tbaa !8
  store i64 1, ptr %loadgep_2.repack26, align 8, !tbaa !8
  store i64 %.unpack9.unpack.unpack11, ptr %loadgep_2.repack26.repack28, align 8, !tbaa !8
  store i64 8, ptr %loadgep_2.repack26.repack30, align 8, !tbaa !8
  br label %omp_loop.exit

omp_loop.exit:                                    ; preds = %omp_loop.header.omp_loop.exit_crit_edge, %omp.par.entry
  call void @__kmpc_for_static_fini(ptr nonnull @1, i32 %omp_global_thread_num4)
  call void @__kmpc_barrier(ptr nonnull @2, i32 %omp_global_thread_num4)
  ret void

omp_loop.body:                                    ; preds = %omp_loop.body.preheader, %omp_loop.body
  %omp_loop.iv33 = phi i32 [ %28, %omp_loop.body ], [ %omp_loop.iv33.ph, %omp_loop.body.preheader ]
  %28 = add nuw i32 %omp_loop.iv33, 1
  %29 = add i32 %28, %3
  %30 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %31 = sitofp i32 %30 to float
  %32 = fdiv contract float 1.000000e+00, %31
  %33 = fpext float %32 to double
  %34 = sext i32 %29 to i64
  %35 = add nsw i64 %34, -1
  %36 = getelementptr double, ptr %.unpack, i64 %35
  store double %33, ptr %36, align 8, !tbaa !4
  %exitcond.not = icmp eq i32 %omp_loop.iv33, %reass.sub
  br i1 %exitcond.not, label %omp_loop.header.omp_loop.exit_crit_edge.loopexit, label %omp_loop.body, !llvm.loop !18
}
*** IR Dump After LICMPass on vector.body ***

; Preheader:
vector.ph:                                        ; preds = %vector.memcheck
  %n.vec = and i32 %6, -2
  %17 = load i32, ptr %loadgep_, align 4, !tbaa !4, !alias.scope !10, !noalias !13
  %broadcast.splatinsert = insertelement <2 x i32> poison, i32 %17, i64 0
  %18 = sitofp <2 x i32> %broadcast.splatinsert to <2 x float>
  %19 = fdiv contract <2 x float> <float 1.000000e+00, float poison>, %18
  %20 = shufflevector <2 x float> %19, <2 x float> poison, <2 x i32> zeroinitializer
  %21 = fpext <2 x float> %20 to <2 x double>
  br label %vector.body

; Loop:
vector.body:                                      ; preds = %vector.body, %vector.ph
  %index = phi i32 [ 0, %vector.ph ], [ %index.next, %vector.body ]
  %22 = or i32 %index, 1
  %23 = add i32 %22, %3
  %24 = sext i32 %23 to i64
  %25 = add nsw i64 %24, -1
  %26 = getelementptr double, ptr %.unpack, i64 %25
  store <2 x double> %21, ptr %26, align 8, !tbaa !4, !alias.scope !13
  %index.next = add nuw i32 %index, 2
  %27 = icmp eq i32 %index.next, %n.vec
  br i1 %27, label %middle.block, label %vector.body, !llvm.loop !15

; Exit blocks
middle.block:                                     ; preds = %vector.body
  %cmp.n = icmp eq i32 %6, %n.vec
  br i1 %cmp.n, label %omp_loop.header.omp_loop.exit_crit_edge, label %omp_loop.body.preheader
*** IR Dump After LICMPass on omp_loop.body ***

; Preheader:
omp_loop.body.preheader:                          ; preds = %vector.memcheck, %vector.scevcheck, %omp_loop.body.lr.ph, %middle.block
  %omp_loop.iv33.ph = phi i32 [ 0, %vector.memcheck ], [ 0, %vector.scevcheck ], [ 0, %omp_loop.body.lr.ph ], [ %n.vec, %middle.block ]
  br label %omp_loop.body

; Loop:
omp_loop.body:                                    ; preds = %omp_loop.body.preheader, %omp_loop.body
  %omp_loop.iv33 = phi i32 [ %28, %omp_loop.body ], [ %omp_loop.iv33.ph, %omp_loop.body.preheader ]
  %28 = add nuw i32 %omp_loop.iv33, 1
  %29 = add i32 %28, %3
  %30 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %31 = sitofp i32 %30 to float
  %32 = fdiv contract float 1.000000e+00, %31
  %33 = fpext float %32 to double
  %34 = sext i32 %29 to i64
  %35 = add nsw i64 %34, -1
  %36 = getelementptr double, ptr %.unpack, i64 %35
  store double %33, ptr %36, align 8, !tbaa !4
  %exitcond.not = icmp eq i32 %omp_loop.iv33, %reass.sub
  br i1 %exitcond.not, label %omp_loop.header.omp_loop.exit_crit_edge.loopexit, label %omp_loop.body, !llvm.loop !18

; Exit blocks
omp_loop.header.omp_loop.exit_crit_edge.loopexit: ; preds = %omp_loop.body
  br label %omp_loop.header.omp_loop.exit_crit_edge
*** IR Dump After AlignmentFromAssumptionsPass on _QQmain..omp_par ***
; Function Attrs: norecurse nounwind
define internal void @_QQmain..omp_par(ptr noalias nocapture readnone %tid.addr, ptr noalias nocapture readnone %zero.addr, ptr nocapture readonly %0) #2 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %p.lastiter = alloca i32, align 4
  %p.lowerbound = alloca i32, align 4
  %p.upperbound = alloca i32, align 4
  %p.stride = alloca i32, align 4
  %1 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %omp_loop.tripcount = tail call i32 @llvm.smax.i32(i32 %1, i32 0)
  store i32 0, ptr %p.lowerbound, align 4
  %2 = add nsw i32 %omp_loop.tripcount, -1
  store i32 %2, ptr %p.upperbound, align 4
  store i32 1, ptr %p.stride, align 4
  %omp_global_thread_num4 = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  call void @__kmpc_for_static_init_4u(ptr nonnull @1, i32 %omp_global_thread_num4, i32 34, ptr nonnull %p.lastiter, ptr nonnull %p.lowerbound, ptr nonnull %p.upperbound, ptr nonnull %p.stride, i32 1, i32 0)
  %3 = load i32, ptr %p.lowerbound, align 4
  %4 = load i32, ptr %p.upperbound, align 4
  %reass.sub = sub i32 %4, %3
  %omp_loop.cmp32.not = icmp eq i32 %reass.sub, -1
  br i1 %omp_loop.cmp32.not, label %omp_loop.exit, label %omp_loop.body.lr.ph

omp_loop.body.lr.ph:                              ; preds = %omp.par.entry
  %.unpack = load ptr, ptr @_QFEarr.0, align 8, !tbaa !8
  %.unpack9.unpack.unpack11.b = load i1, ptr @_QFEarr.8, align 1
  %.unpack9.unpack.unpack11 = select i1 %.unpack9.unpack.unpack11.b, i64 1048576, i64 0
  %loadgep_2.repack16 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  %loadgep_2.repack20 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  %loadgep_2.repack24 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  %loadgep_2.repack26.repack28 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  %5 = add i32 %4, 1
  %6 = sub i32 %5, %3
  %min.iters.check = icmp ult i32 %6, 4
  br i1 %min.iters.check, label %omp_loop.body.preheader, label %vector.scevcheck

vector.scevcheck:                                 ; preds = %omp_loop.body.lr.ph
  %7 = add i32 %3, 1
  %8 = add i32 %4, 1
  %9 = icmp slt i32 %8, %7
  br i1 %9, label %omp_loop.body.preheader, label %vector.memcheck

vector.memcheck:                                  ; preds = %vector.scevcheck
  %scevgep = getelementptr i8, ptr %loadgep_, i64 4
  %10 = add i32 %3, 1
  %11 = sext i32 %10 to i64
  %12 = shl nsw i64 %11, 3
  %13 = add nsw i64 %12, -8
  %scevgep34 = getelementptr i8, ptr %.unpack, i64 %13
  %14 = zext i32 %reass.sub to i64
  %15 = add nsw i64 %11, %14
  %16 = shl nsw i64 %15, 3
  %scevgep35 = getelementptr i8, ptr %.unpack, i64 %16
  %bound0 = icmp ult ptr %loadgep_, %scevgep35
  %bound1 = icmp ult ptr %scevgep34, %scevgep
  %found.conflict = and i1 %bound0, %bound1
  br i1 %found.conflict, label %omp_loop.body.preheader, label %vector.ph

vector.ph:                                        ; preds = %vector.memcheck
  %n.vec = and i32 %6, -2
  %17 = load i32, ptr %loadgep_, align 4, !tbaa !4, !alias.scope !10, !noalias !13
  %broadcast.splatinsert = insertelement <2 x i32> poison, i32 %17, i64 0
  %18 = sitofp <2 x i32> %broadcast.splatinsert to <2 x float>
  %19 = fdiv contract <2 x float> <float 1.000000e+00, float poison>, %18
  %20 = shufflevector <2 x float> %19, <2 x float> poison, <2 x i32> zeroinitializer
  %21 = fpext <2 x float> %20 to <2 x double>
  br label %vector.body

vector.body:                                      ; preds = %vector.body, %vector.ph
  %index = phi i32 [ 0, %vector.ph ], [ %index.next, %vector.body ]
  %22 = or i32 %index, 1
  %23 = add i32 %22, %3
  %24 = sext i32 %23 to i64
  %25 = add nsw i64 %24, -1
  %26 = getelementptr double, ptr %.unpack, i64 %25
  store <2 x double> %21, ptr %26, align 8, !tbaa !4, !alias.scope !13
  %index.next = add nuw i32 %index, 2
  %27 = icmp eq i32 %index.next, %n.vec
  br i1 %27, label %middle.block, label %vector.body, !llvm.loop !15

middle.block:                                     ; preds = %vector.body
  %cmp.n = icmp eq i32 %6, %n.vec
  br i1 %cmp.n, label %omp_loop.header.omp_loop.exit_crit_edge, label %omp_loop.body.preheader

omp_loop.body.preheader:                          ; preds = %vector.memcheck, %vector.scevcheck, %omp_loop.body.lr.ph, %middle.block
  %omp_loop.iv33.ph = phi i32 [ 0, %vector.memcheck ], [ 0, %vector.scevcheck ], [ 0, %omp_loop.body.lr.ph ], [ %n.vec, %middle.block ]
  br label %omp_loop.body

omp_loop.header.omp_loop.exit_crit_edge.loopexit: ; preds = %omp_loop.body
  br label %omp_loop.header.omp_loop.exit_crit_edge

omp_loop.header.omp_loop.exit_crit_edge:          ; preds = %omp_loop.header.omp_loop.exit_crit_edge.loopexit, %middle.block
  %loadgep_2.repack14 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  %loadgep_2.repack18 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  %loadgep_2.repack22 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  %loadgep_2.repack26 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  %loadgep_2.repack26.repack30 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  store ptr %.unpack, ptr %loadgep_2, align 8, !tbaa !8
  store i64 8, ptr %loadgep_2.repack14, align 8, !tbaa !8
  store i32 20180515, ptr %loadgep_2.repack16, align 8, !tbaa !8
  store i8 1, ptr %loadgep_2.repack18, align 4, !tbaa !8
  store i8 28, ptr %loadgep_2.repack20, align 1, !tbaa !8
  store i8 2, ptr %loadgep_2.repack22, align 2, !tbaa !8
  store i8 0, ptr %loadgep_2.repack24, align 1, !tbaa !8
  store i64 1, ptr %loadgep_2.repack26, align 8, !tbaa !8
  store i64 %.unpack9.unpack.unpack11, ptr %loadgep_2.repack26.repack28, align 8, !tbaa !8
  store i64 8, ptr %loadgep_2.repack26.repack30, align 8, !tbaa !8
  br label %omp_loop.exit

omp_loop.exit:                                    ; preds = %omp_loop.header.omp_loop.exit_crit_edge, %omp.par.entry
  call void @__kmpc_for_static_fini(ptr nonnull @1, i32 %omp_global_thread_num4)
  call void @__kmpc_barrier(ptr nonnull @2, i32 %omp_global_thread_num4)
  ret void

omp_loop.body:                                    ; preds = %omp_loop.body.preheader, %omp_loop.body
  %omp_loop.iv33 = phi i32 [ %28, %omp_loop.body ], [ %omp_loop.iv33.ph, %omp_loop.body.preheader ]
  %28 = add nuw i32 %omp_loop.iv33, 1
  %29 = add i32 %28, %3
  %30 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %31 = sitofp i32 %30 to float
  %32 = fdiv contract float 1.000000e+00, %31
  %33 = fpext float %32 to double
  %34 = sext i32 %29 to i64
  %35 = add nsw i64 %34, -1
  %36 = getelementptr double, ptr %.unpack, i64 %35
  store double %33, ptr %36, align 8, !tbaa !4
  %exitcond.not = icmp eq i32 %omp_loop.iv33, %reass.sub
  br i1 %exitcond.not, label %omp_loop.header.omp_loop.exit_crit_edge.loopexit, label %omp_loop.body, !llvm.loop !18
}
*** IR Dump After LoopSinkPass on _QQmain..omp_par ***
; Function Attrs: norecurse nounwind
define internal void @_QQmain..omp_par(ptr noalias nocapture readnone %tid.addr, ptr noalias nocapture readnone %zero.addr, ptr nocapture readonly %0) #2 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %p.lastiter = alloca i32, align 4
  %p.lowerbound = alloca i32, align 4
  %p.upperbound = alloca i32, align 4
  %p.stride = alloca i32, align 4
  %1 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %omp_loop.tripcount = tail call i32 @llvm.smax.i32(i32 %1, i32 0)
  store i32 0, ptr %p.lowerbound, align 4
  %2 = add nsw i32 %omp_loop.tripcount, -1
  store i32 %2, ptr %p.upperbound, align 4
  store i32 1, ptr %p.stride, align 4
  %omp_global_thread_num4 = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  call void @__kmpc_for_static_init_4u(ptr nonnull @1, i32 %omp_global_thread_num4, i32 34, ptr nonnull %p.lastiter, ptr nonnull %p.lowerbound, ptr nonnull %p.upperbound, ptr nonnull %p.stride, i32 1, i32 0)
  %3 = load i32, ptr %p.lowerbound, align 4
  %4 = load i32, ptr %p.upperbound, align 4
  %reass.sub = sub i32 %4, %3
  %omp_loop.cmp32.not = icmp eq i32 %reass.sub, -1
  br i1 %omp_loop.cmp32.not, label %omp_loop.exit, label %omp_loop.body.lr.ph

omp_loop.body.lr.ph:                              ; preds = %omp.par.entry
  %.unpack = load ptr, ptr @_QFEarr.0, align 8, !tbaa !8
  %.unpack9.unpack.unpack11.b = load i1, ptr @_QFEarr.8, align 1
  %.unpack9.unpack.unpack11 = select i1 %.unpack9.unpack.unpack11.b, i64 1048576, i64 0
  %loadgep_2.repack16 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  %loadgep_2.repack20 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  %loadgep_2.repack24 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  %loadgep_2.repack26.repack28 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  %5 = add i32 %4, 1
  %6 = sub i32 %5, %3
  %min.iters.check = icmp ult i32 %6, 4
  br i1 %min.iters.check, label %omp_loop.body.preheader, label %vector.scevcheck

vector.scevcheck:                                 ; preds = %omp_loop.body.lr.ph
  %7 = add i32 %3, 1
  %8 = add i32 %4, 1
  %9 = icmp slt i32 %8, %7
  br i1 %9, label %omp_loop.body.preheader, label %vector.memcheck

vector.memcheck:                                  ; preds = %vector.scevcheck
  %scevgep = getelementptr i8, ptr %loadgep_, i64 4
  %10 = add i32 %3, 1
  %11 = sext i32 %10 to i64
  %12 = shl nsw i64 %11, 3
  %13 = add nsw i64 %12, -8
  %scevgep34 = getelementptr i8, ptr %.unpack, i64 %13
  %14 = zext i32 %reass.sub to i64
  %15 = add nsw i64 %11, %14
  %16 = shl nsw i64 %15, 3
  %scevgep35 = getelementptr i8, ptr %.unpack, i64 %16
  %bound0 = icmp ult ptr %loadgep_, %scevgep35
  %bound1 = icmp ult ptr %scevgep34, %scevgep
  %found.conflict = and i1 %bound0, %bound1
  br i1 %found.conflict, label %omp_loop.body.preheader, label %vector.ph

vector.ph:                                        ; preds = %vector.memcheck
  %n.vec = and i32 %6, -2
  %17 = load i32, ptr %loadgep_, align 4, !tbaa !4, !alias.scope !10, !noalias !13
  %broadcast.splatinsert = insertelement <2 x i32> poison, i32 %17, i64 0
  %18 = sitofp <2 x i32> %broadcast.splatinsert to <2 x float>
  %19 = fdiv contract <2 x float> <float 1.000000e+00, float poison>, %18
  %20 = shufflevector <2 x float> %19, <2 x float> poison, <2 x i32> zeroinitializer
  %21 = fpext <2 x float> %20 to <2 x double>
  br label %vector.body

vector.body:                                      ; preds = %vector.body, %vector.ph
  %index = phi i32 [ 0, %vector.ph ], [ %index.next, %vector.body ]
  %22 = or i32 %index, 1
  %23 = add i32 %22, %3
  %24 = sext i32 %23 to i64
  %25 = add nsw i64 %24, -1
  %26 = getelementptr double, ptr %.unpack, i64 %25
  store <2 x double> %21, ptr %26, align 8, !tbaa !4, !alias.scope !13
  %index.next = add nuw i32 %index, 2
  %27 = icmp eq i32 %index.next, %n.vec
  br i1 %27, label %middle.block, label %vector.body, !llvm.loop !15

middle.block:                                     ; preds = %vector.body
  %cmp.n = icmp eq i32 %6, %n.vec
  br i1 %cmp.n, label %omp_loop.header.omp_loop.exit_crit_edge, label %omp_loop.body.preheader

omp_loop.body.preheader:                          ; preds = %vector.memcheck, %vector.scevcheck, %omp_loop.body.lr.ph, %middle.block
  %omp_loop.iv33.ph = phi i32 [ 0, %vector.memcheck ], [ 0, %vector.scevcheck ], [ 0, %omp_loop.body.lr.ph ], [ %n.vec, %middle.block ]
  br label %omp_loop.body

omp_loop.header.omp_loop.exit_crit_edge.loopexit: ; preds = %omp_loop.body
  br label %omp_loop.header.omp_loop.exit_crit_edge

omp_loop.header.omp_loop.exit_crit_edge:          ; preds = %omp_loop.header.omp_loop.exit_crit_edge.loopexit, %middle.block
  %loadgep_2.repack14 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  %loadgep_2.repack18 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  %loadgep_2.repack22 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  %loadgep_2.repack26 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  %loadgep_2.repack26.repack30 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  store ptr %.unpack, ptr %loadgep_2, align 8, !tbaa !8
  store i64 8, ptr %loadgep_2.repack14, align 8, !tbaa !8
  store i32 20180515, ptr %loadgep_2.repack16, align 8, !tbaa !8
  store i8 1, ptr %loadgep_2.repack18, align 4, !tbaa !8
  store i8 28, ptr %loadgep_2.repack20, align 1, !tbaa !8
  store i8 2, ptr %loadgep_2.repack22, align 2, !tbaa !8
  store i8 0, ptr %loadgep_2.repack24, align 1, !tbaa !8
  store i64 1, ptr %loadgep_2.repack26, align 8, !tbaa !8
  store i64 %.unpack9.unpack.unpack11, ptr %loadgep_2.repack26.repack28, align 8, !tbaa !8
  store i64 8, ptr %loadgep_2.repack26.repack30, align 8, !tbaa !8
  br label %omp_loop.exit

omp_loop.exit:                                    ; preds = %omp_loop.header.omp_loop.exit_crit_edge, %omp.par.entry
  call void @__kmpc_for_static_fini(ptr nonnull @1, i32 %omp_global_thread_num4)
  call void @__kmpc_barrier(ptr nonnull @2, i32 %omp_global_thread_num4)
  ret void

omp_loop.body:                                    ; preds = %omp_loop.body.preheader, %omp_loop.body
  %omp_loop.iv33 = phi i32 [ %28, %omp_loop.body ], [ %omp_loop.iv33.ph, %omp_loop.body.preheader ]
  %28 = add nuw i32 %omp_loop.iv33, 1
  %29 = add i32 %28, %3
  %30 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %31 = sitofp i32 %30 to float
  %32 = fdiv contract float 1.000000e+00, %31
  %33 = fpext float %32 to double
  %34 = sext i32 %29 to i64
  %35 = add nsw i64 %34, -1
  %36 = getelementptr double, ptr %.unpack, i64 %35
  store double %33, ptr %36, align 8, !tbaa !4
  %exitcond.not = icmp eq i32 %omp_loop.iv33, %reass.sub
  br i1 %exitcond.not, label %omp_loop.header.omp_loop.exit_crit_edge.loopexit, label %omp_loop.body, !llvm.loop !18
}
*** IR Dump After InstSimplifyPass on _QQmain..omp_par ***
; Function Attrs: norecurse nounwind
define internal void @_QQmain..omp_par(ptr noalias nocapture readnone %tid.addr, ptr noalias nocapture readnone %zero.addr, ptr nocapture readonly %0) #2 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %p.lastiter = alloca i32, align 4
  %p.lowerbound = alloca i32, align 4
  %p.upperbound = alloca i32, align 4
  %p.stride = alloca i32, align 4
  %1 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %omp_loop.tripcount = tail call i32 @llvm.smax.i32(i32 %1, i32 0)
  store i32 0, ptr %p.lowerbound, align 4
  %2 = add nsw i32 %omp_loop.tripcount, -1
  store i32 %2, ptr %p.upperbound, align 4
  store i32 1, ptr %p.stride, align 4
  %omp_global_thread_num4 = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  call void @__kmpc_for_static_init_4u(ptr nonnull @1, i32 %omp_global_thread_num4, i32 34, ptr nonnull %p.lastiter, ptr nonnull %p.lowerbound, ptr nonnull %p.upperbound, ptr nonnull %p.stride, i32 1, i32 0)
  %3 = load i32, ptr %p.lowerbound, align 4
  %4 = load i32, ptr %p.upperbound, align 4
  %reass.sub = sub i32 %4, %3
  %omp_loop.cmp32.not = icmp eq i32 %reass.sub, -1
  br i1 %omp_loop.cmp32.not, label %omp_loop.exit, label %omp_loop.body.lr.ph

omp_loop.body.lr.ph:                              ; preds = %omp.par.entry
  %.unpack = load ptr, ptr @_QFEarr.0, align 8, !tbaa !8
  %.unpack9.unpack.unpack11.b = load i1, ptr @_QFEarr.8, align 1
  %.unpack9.unpack.unpack11 = select i1 %.unpack9.unpack.unpack11.b, i64 1048576, i64 0
  %loadgep_2.repack16 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  %loadgep_2.repack20 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  %loadgep_2.repack24 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  %loadgep_2.repack26.repack28 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  %5 = add i32 %4, 1
  %6 = sub i32 %5, %3
  %min.iters.check = icmp ult i32 %6, 4
  br i1 %min.iters.check, label %omp_loop.body.preheader, label %vector.scevcheck

vector.scevcheck:                                 ; preds = %omp_loop.body.lr.ph
  %7 = add i32 %3, 1
  %8 = add i32 %4, 1
  %9 = icmp slt i32 %8, %7
  br i1 %9, label %omp_loop.body.preheader, label %vector.memcheck

vector.memcheck:                                  ; preds = %vector.scevcheck
  %scevgep = getelementptr i8, ptr %loadgep_, i64 4
  %10 = add i32 %3, 1
  %11 = sext i32 %10 to i64
  %12 = shl nsw i64 %11, 3
  %13 = add nsw i64 %12, -8
  %scevgep34 = getelementptr i8, ptr %.unpack, i64 %13
  %14 = zext i32 %reass.sub to i64
  %15 = add nsw i64 %11, %14
  %16 = shl nsw i64 %15, 3
  %scevgep35 = getelementptr i8, ptr %.unpack, i64 %16
  %bound0 = icmp ult ptr %loadgep_, %scevgep35
  %bound1 = icmp ult ptr %scevgep34, %scevgep
  %found.conflict = and i1 %bound0, %bound1
  br i1 %found.conflict, label %omp_loop.body.preheader, label %vector.ph

vector.ph:                                        ; preds = %vector.memcheck
  %n.vec = and i32 %6, -2
  %17 = load i32, ptr %loadgep_, align 4, !tbaa !4, !alias.scope !10, !noalias !13
  %broadcast.splatinsert = insertelement <2 x i32> poison, i32 %17, i64 0
  %18 = sitofp <2 x i32> %broadcast.splatinsert to <2 x float>
  %19 = fdiv contract <2 x float> <float 1.000000e+00, float poison>, %18
  %20 = shufflevector <2 x float> %19, <2 x float> poison, <2 x i32> zeroinitializer
  %21 = fpext <2 x float> %20 to <2 x double>
  br label %vector.body

vector.body:                                      ; preds = %vector.body, %vector.ph
  %index = phi i32 [ 0, %vector.ph ], [ %index.next, %vector.body ]
  %22 = or i32 %index, 1
  %23 = add i32 %22, %3
  %24 = sext i32 %23 to i64
  %25 = add nsw i64 %24, -1
  %26 = getelementptr double, ptr %.unpack, i64 %25
  store <2 x double> %21, ptr %26, align 8, !tbaa !4, !alias.scope !13
  %index.next = add nuw i32 %index, 2
  %27 = icmp eq i32 %index.next, %n.vec
  br i1 %27, label %middle.block, label %vector.body, !llvm.loop !15

middle.block:                                     ; preds = %vector.body
  %cmp.n = icmp eq i32 %6, %n.vec
  br i1 %cmp.n, label %omp_loop.header.omp_loop.exit_crit_edge, label %omp_loop.body.preheader

omp_loop.body.preheader:                          ; preds = %vector.memcheck, %vector.scevcheck, %omp_loop.body.lr.ph, %middle.block
  %omp_loop.iv33.ph = phi i32 [ 0, %vector.memcheck ], [ 0, %vector.scevcheck ], [ 0, %omp_loop.body.lr.ph ], [ %n.vec, %middle.block ]
  br label %omp_loop.body

omp_loop.header.omp_loop.exit_crit_edge.loopexit: ; preds = %omp_loop.body
  br label %omp_loop.header.omp_loop.exit_crit_edge

omp_loop.header.omp_loop.exit_crit_edge:          ; preds = %omp_loop.header.omp_loop.exit_crit_edge.loopexit, %middle.block
  %loadgep_2.repack14 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  %loadgep_2.repack18 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  %loadgep_2.repack22 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  %loadgep_2.repack26 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  %loadgep_2.repack26.repack30 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  store ptr %.unpack, ptr %loadgep_2, align 8, !tbaa !8
  store i64 8, ptr %loadgep_2.repack14, align 8, !tbaa !8
  store i32 20180515, ptr %loadgep_2.repack16, align 8, !tbaa !8
  store i8 1, ptr %loadgep_2.repack18, align 4, !tbaa !8
  store i8 28, ptr %loadgep_2.repack20, align 1, !tbaa !8
  store i8 2, ptr %loadgep_2.repack22, align 2, !tbaa !8
  store i8 0, ptr %loadgep_2.repack24, align 1, !tbaa !8
  store i64 1, ptr %loadgep_2.repack26, align 8, !tbaa !8
  store i64 %.unpack9.unpack.unpack11, ptr %loadgep_2.repack26.repack28, align 8, !tbaa !8
  store i64 8, ptr %loadgep_2.repack26.repack30, align 8, !tbaa !8
  br label %omp_loop.exit

omp_loop.exit:                                    ; preds = %omp_loop.header.omp_loop.exit_crit_edge, %omp.par.entry
  call void @__kmpc_for_static_fini(ptr nonnull @1, i32 %omp_global_thread_num4)
  call void @__kmpc_barrier(ptr nonnull @2, i32 %omp_global_thread_num4)
  ret void

omp_loop.body:                                    ; preds = %omp_loop.body.preheader, %omp_loop.body
  %omp_loop.iv33 = phi i32 [ %28, %omp_loop.body ], [ %omp_loop.iv33.ph, %omp_loop.body.preheader ]
  %28 = add nuw i32 %omp_loop.iv33, 1
  %29 = add i32 %28, %3
  %30 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %31 = sitofp i32 %30 to float
  %32 = fdiv contract float 1.000000e+00, %31
  %33 = fpext float %32 to double
  %34 = sext i32 %29 to i64
  %35 = add nsw i64 %34, -1
  %36 = getelementptr double, ptr %.unpack, i64 %35
  store double %33, ptr %36, align 8, !tbaa !4
  %exitcond.not = icmp eq i32 %omp_loop.iv33, %reass.sub
  br i1 %exitcond.not, label %omp_loop.header.omp_loop.exit_crit_edge.loopexit, label %omp_loop.body, !llvm.loop !18
}
*** IR Dump After DivRemPairsPass on _QQmain..omp_par ***
; Function Attrs: norecurse nounwind
define internal void @_QQmain..omp_par(ptr noalias nocapture readnone %tid.addr, ptr noalias nocapture readnone %zero.addr, ptr nocapture readonly %0) #2 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %p.lastiter = alloca i32, align 4
  %p.lowerbound = alloca i32, align 4
  %p.upperbound = alloca i32, align 4
  %p.stride = alloca i32, align 4
  %1 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %omp_loop.tripcount = tail call i32 @llvm.smax.i32(i32 %1, i32 0)
  store i32 0, ptr %p.lowerbound, align 4
  %2 = add nsw i32 %omp_loop.tripcount, -1
  store i32 %2, ptr %p.upperbound, align 4
  store i32 1, ptr %p.stride, align 4
  %omp_global_thread_num4 = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  call void @__kmpc_for_static_init_4u(ptr nonnull @1, i32 %omp_global_thread_num4, i32 34, ptr nonnull %p.lastiter, ptr nonnull %p.lowerbound, ptr nonnull %p.upperbound, ptr nonnull %p.stride, i32 1, i32 0)
  %3 = load i32, ptr %p.lowerbound, align 4
  %4 = load i32, ptr %p.upperbound, align 4
  %reass.sub = sub i32 %4, %3
  %omp_loop.cmp32.not = icmp eq i32 %reass.sub, -1
  br i1 %omp_loop.cmp32.not, label %omp_loop.exit, label %omp_loop.body.lr.ph

omp_loop.body.lr.ph:                              ; preds = %omp.par.entry
  %.unpack = load ptr, ptr @_QFEarr.0, align 8, !tbaa !8
  %.unpack9.unpack.unpack11.b = load i1, ptr @_QFEarr.8, align 1
  %.unpack9.unpack.unpack11 = select i1 %.unpack9.unpack.unpack11.b, i64 1048576, i64 0
  %loadgep_2.repack16 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  %loadgep_2.repack20 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  %loadgep_2.repack24 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  %loadgep_2.repack26.repack28 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  %5 = add i32 %4, 1
  %6 = sub i32 %5, %3
  %min.iters.check = icmp ult i32 %6, 4
  br i1 %min.iters.check, label %omp_loop.body.preheader, label %vector.scevcheck

vector.scevcheck:                                 ; preds = %omp_loop.body.lr.ph
  %7 = add i32 %3, 1
  %8 = add i32 %4, 1
  %9 = icmp slt i32 %8, %7
  br i1 %9, label %omp_loop.body.preheader, label %vector.memcheck

vector.memcheck:                                  ; preds = %vector.scevcheck
  %scevgep = getelementptr i8, ptr %loadgep_, i64 4
  %10 = add i32 %3, 1
  %11 = sext i32 %10 to i64
  %12 = shl nsw i64 %11, 3
  %13 = add nsw i64 %12, -8
  %scevgep34 = getelementptr i8, ptr %.unpack, i64 %13
  %14 = zext i32 %reass.sub to i64
  %15 = add nsw i64 %11, %14
  %16 = shl nsw i64 %15, 3
  %scevgep35 = getelementptr i8, ptr %.unpack, i64 %16
  %bound0 = icmp ult ptr %loadgep_, %scevgep35
  %bound1 = icmp ult ptr %scevgep34, %scevgep
  %found.conflict = and i1 %bound0, %bound1
  br i1 %found.conflict, label %omp_loop.body.preheader, label %vector.ph

vector.ph:                                        ; preds = %vector.memcheck
  %n.vec = and i32 %6, -2
  %17 = load i32, ptr %loadgep_, align 4, !tbaa !4, !alias.scope !10, !noalias !13
  %broadcast.splatinsert = insertelement <2 x i32> poison, i32 %17, i64 0
  %18 = sitofp <2 x i32> %broadcast.splatinsert to <2 x float>
  %19 = fdiv contract <2 x float> <float 1.000000e+00, float poison>, %18
  %20 = shufflevector <2 x float> %19, <2 x float> poison, <2 x i32> zeroinitializer
  %21 = fpext <2 x float> %20 to <2 x double>
  br label %vector.body

vector.body:                                      ; preds = %vector.body, %vector.ph
  %index = phi i32 [ 0, %vector.ph ], [ %index.next, %vector.body ]
  %22 = or i32 %index, 1
  %23 = add i32 %22, %3
  %24 = sext i32 %23 to i64
  %25 = add nsw i64 %24, -1
  %26 = getelementptr double, ptr %.unpack, i64 %25
  store <2 x double> %21, ptr %26, align 8, !tbaa !4, !alias.scope !13
  %index.next = add nuw i32 %index, 2
  %27 = icmp eq i32 %index.next, %n.vec
  br i1 %27, label %middle.block, label %vector.body, !llvm.loop !15

middle.block:                                     ; preds = %vector.body
  %cmp.n = icmp eq i32 %6, %n.vec
  br i1 %cmp.n, label %omp_loop.header.omp_loop.exit_crit_edge, label %omp_loop.body.preheader

omp_loop.body.preheader:                          ; preds = %vector.memcheck, %vector.scevcheck, %omp_loop.body.lr.ph, %middle.block
  %omp_loop.iv33.ph = phi i32 [ 0, %vector.memcheck ], [ 0, %vector.scevcheck ], [ 0, %omp_loop.body.lr.ph ], [ %n.vec, %middle.block ]
  br label %omp_loop.body

omp_loop.header.omp_loop.exit_crit_edge.loopexit: ; preds = %omp_loop.body
  br label %omp_loop.header.omp_loop.exit_crit_edge

omp_loop.header.omp_loop.exit_crit_edge:          ; preds = %omp_loop.header.omp_loop.exit_crit_edge.loopexit, %middle.block
  %loadgep_2.repack14 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  %loadgep_2.repack18 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  %loadgep_2.repack22 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  %loadgep_2.repack26 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  %loadgep_2.repack26.repack30 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  store ptr %.unpack, ptr %loadgep_2, align 8, !tbaa !8
  store i64 8, ptr %loadgep_2.repack14, align 8, !tbaa !8
  store i32 20180515, ptr %loadgep_2.repack16, align 8, !tbaa !8
  store i8 1, ptr %loadgep_2.repack18, align 4, !tbaa !8
  store i8 28, ptr %loadgep_2.repack20, align 1, !tbaa !8
  store i8 2, ptr %loadgep_2.repack22, align 2, !tbaa !8
  store i8 0, ptr %loadgep_2.repack24, align 1, !tbaa !8
  store i64 1, ptr %loadgep_2.repack26, align 8, !tbaa !8
  store i64 %.unpack9.unpack.unpack11, ptr %loadgep_2.repack26.repack28, align 8, !tbaa !8
  store i64 8, ptr %loadgep_2.repack26.repack30, align 8, !tbaa !8
  br label %omp_loop.exit

omp_loop.exit:                                    ; preds = %omp_loop.header.omp_loop.exit_crit_edge, %omp.par.entry
  call void @__kmpc_for_static_fini(ptr nonnull @1, i32 %omp_global_thread_num4)
  call void @__kmpc_barrier(ptr nonnull @2, i32 %omp_global_thread_num4)
  ret void

omp_loop.body:                                    ; preds = %omp_loop.body.preheader, %omp_loop.body
  %omp_loop.iv33 = phi i32 [ %28, %omp_loop.body ], [ %omp_loop.iv33.ph, %omp_loop.body.preheader ]
  %28 = add nuw i32 %omp_loop.iv33, 1
  %29 = add i32 %28, %3
  %30 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %31 = sitofp i32 %30 to float
  %32 = fdiv contract float 1.000000e+00, %31
  %33 = fpext float %32 to double
  %34 = sext i32 %29 to i64
  %35 = add nsw i64 %34, -1
  %36 = getelementptr double, ptr %.unpack, i64 %35
  store double %33, ptr %36, align 8, !tbaa !4
  %exitcond.not = icmp eq i32 %omp_loop.iv33, %reass.sub
  br i1 %exitcond.not, label %omp_loop.header.omp_loop.exit_crit_edge.loopexit, label %omp_loop.body, !llvm.loop !18
}
*** IR Dump After TailCallElimPass on _QQmain..omp_par ***
; Function Attrs: norecurse nounwind
define internal void @_QQmain..omp_par(ptr noalias nocapture readnone %tid.addr, ptr noalias nocapture readnone %zero.addr, ptr nocapture readonly %0) #2 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %p.lastiter = alloca i32, align 4
  %p.lowerbound = alloca i32, align 4
  %p.upperbound = alloca i32, align 4
  %p.stride = alloca i32, align 4
  %1 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %omp_loop.tripcount = tail call i32 @llvm.smax.i32(i32 %1, i32 0)
  store i32 0, ptr %p.lowerbound, align 4
  %2 = add nsw i32 %omp_loop.tripcount, -1
  store i32 %2, ptr %p.upperbound, align 4
  store i32 1, ptr %p.stride, align 4
  %omp_global_thread_num4 = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  call void @__kmpc_for_static_init_4u(ptr nonnull @1, i32 %omp_global_thread_num4, i32 34, ptr nonnull %p.lastiter, ptr nonnull %p.lowerbound, ptr nonnull %p.upperbound, ptr nonnull %p.stride, i32 1, i32 0)
  %3 = load i32, ptr %p.lowerbound, align 4
  %4 = load i32, ptr %p.upperbound, align 4
  %reass.sub = sub i32 %4, %3
  %omp_loop.cmp32.not = icmp eq i32 %reass.sub, -1
  br i1 %omp_loop.cmp32.not, label %omp_loop.exit, label %omp_loop.body.lr.ph

omp_loop.body.lr.ph:                              ; preds = %omp.par.entry
  %.unpack = load ptr, ptr @_QFEarr.0, align 8, !tbaa !8
  %.unpack9.unpack.unpack11.b = load i1, ptr @_QFEarr.8, align 1
  %.unpack9.unpack.unpack11 = select i1 %.unpack9.unpack.unpack11.b, i64 1048576, i64 0
  %loadgep_2.repack16 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  %loadgep_2.repack20 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  %loadgep_2.repack24 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  %loadgep_2.repack26.repack28 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  %5 = add i32 %4, 1
  %6 = sub i32 %5, %3
  %min.iters.check = icmp ult i32 %6, 4
  br i1 %min.iters.check, label %omp_loop.body.preheader, label %vector.scevcheck

vector.scevcheck:                                 ; preds = %omp_loop.body.lr.ph
  %7 = add i32 %3, 1
  %8 = add i32 %4, 1
  %9 = icmp slt i32 %8, %7
  br i1 %9, label %omp_loop.body.preheader, label %vector.memcheck

vector.memcheck:                                  ; preds = %vector.scevcheck
  %scevgep = getelementptr i8, ptr %loadgep_, i64 4
  %10 = add i32 %3, 1
  %11 = sext i32 %10 to i64
  %12 = shl nsw i64 %11, 3
  %13 = add nsw i64 %12, -8
  %scevgep34 = getelementptr i8, ptr %.unpack, i64 %13
  %14 = zext i32 %reass.sub to i64
  %15 = add nsw i64 %11, %14
  %16 = shl nsw i64 %15, 3
  %scevgep35 = getelementptr i8, ptr %.unpack, i64 %16
  %bound0 = icmp ult ptr %loadgep_, %scevgep35
  %bound1 = icmp ult ptr %scevgep34, %scevgep
  %found.conflict = and i1 %bound0, %bound1
  br i1 %found.conflict, label %omp_loop.body.preheader, label %vector.ph

vector.ph:                                        ; preds = %vector.memcheck
  %n.vec = and i32 %6, -2
  %17 = load i32, ptr %loadgep_, align 4, !tbaa !4, !alias.scope !10, !noalias !13
  %broadcast.splatinsert = insertelement <2 x i32> poison, i32 %17, i64 0
  %18 = sitofp <2 x i32> %broadcast.splatinsert to <2 x float>
  %19 = fdiv contract <2 x float> <float 1.000000e+00, float poison>, %18
  %20 = shufflevector <2 x float> %19, <2 x float> poison, <2 x i32> zeroinitializer
  %21 = fpext <2 x float> %20 to <2 x double>
  br label %vector.body

vector.body:                                      ; preds = %vector.body, %vector.ph
  %index = phi i32 [ 0, %vector.ph ], [ %index.next, %vector.body ]
  %22 = or i32 %index, 1
  %23 = add i32 %22, %3
  %24 = sext i32 %23 to i64
  %25 = add nsw i64 %24, -1
  %26 = getelementptr double, ptr %.unpack, i64 %25
  store <2 x double> %21, ptr %26, align 8, !tbaa !4, !alias.scope !13
  %index.next = add nuw i32 %index, 2
  %27 = icmp eq i32 %index.next, %n.vec
  br i1 %27, label %middle.block, label %vector.body, !llvm.loop !15

middle.block:                                     ; preds = %vector.body
  %cmp.n = icmp eq i32 %6, %n.vec
  br i1 %cmp.n, label %omp_loop.header.omp_loop.exit_crit_edge, label %omp_loop.body.preheader

omp_loop.body.preheader:                          ; preds = %vector.memcheck, %vector.scevcheck, %omp_loop.body.lr.ph, %middle.block
  %omp_loop.iv33.ph = phi i32 [ 0, %vector.memcheck ], [ 0, %vector.scevcheck ], [ 0, %omp_loop.body.lr.ph ], [ %n.vec, %middle.block ]
  br label %omp_loop.body

omp_loop.header.omp_loop.exit_crit_edge.loopexit: ; preds = %omp_loop.body
  br label %omp_loop.header.omp_loop.exit_crit_edge

omp_loop.header.omp_loop.exit_crit_edge:          ; preds = %omp_loop.header.omp_loop.exit_crit_edge.loopexit, %middle.block
  %loadgep_2.repack14 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  %loadgep_2.repack18 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  %loadgep_2.repack22 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  %loadgep_2.repack26 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  %loadgep_2.repack26.repack30 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  store ptr %.unpack, ptr %loadgep_2, align 8, !tbaa !8
  store i64 8, ptr %loadgep_2.repack14, align 8, !tbaa !8
  store i32 20180515, ptr %loadgep_2.repack16, align 8, !tbaa !8
  store i8 1, ptr %loadgep_2.repack18, align 4, !tbaa !8
  store i8 28, ptr %loadgep_2.repack20, align 1, !tbaa !8
  store i8 2, ptr %loadgep_2.repack22, align 2, !tbaa !8
  store i8 0, ptr %loadgep_2.repack24, align 1, !tbaa !8
  store i64 1, ptr %loadgep_2.repack26, align 8, !tbaa !8
  store i64 %.unpack9.unpack.unpack11, ptr %loadgep_2.repack26.repack28, align 8, !tbaa !8
  store i64 8, ptr %loadgep_2.repack26.repack30, align 8, !tbaa !8
  br label %omp_loop.exit

omp_loop.exit:                                    ; preds = %omp_loop.header.omp_loop.exit_crit_edge, %omp.par.entry
  call void @__kmpc_for_static_fini(ptr nonnull @1, i32 %omp_global_thread_num4)
  call void @__kmpc_barrier(ptr nonnull @2, i32 %omp_global_thread_num4)
  ret void

omp_loop.body:                                    ; preds = %omp_loop.body.preheader, %omp_loop.body
  %omp_loop.iv33 = phi i32 [ %28, %omp_loop.body ], [ %omp_loop.iv33.ph, %omp_loop.body.preheader ]
  %28 = add nuw i32 %omp_loop.iv33, 1
  %29 = add i32 %28, %3
  %30 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %31 = sitofp i32 %30 to float
  %32 = fdiv contract float 1.000000e+00, %31
  %33 = fpext float %32 to double
  %34 = sext i32 %29 to i64
  %35 = add nsw i64 %34, -1
  %36 = getelementptr double, ptr %.unpack, i64 %35
  store double %33, ptr %36, align 8, !tbaa !4
  %exitcond.not = icmp eq i32 %omp_loop.iv33, %reass.sub
  br i1 %exitcond.not, label %omp_loop.header.omp_loop.exit_crit_edge.loopexit, label %omp_loop.body, !llvm.loop !18
}
*** IR Dump After SimplifyCFGPass on _QQmain..omp_par ***
; Function Attrs: norecurse nounwind
define internal void @_QQmain..omp_par(ptr noalias nocapture readnone %tid.addr, ptr noalias nocapture readnone %zero.addr, ptr nocapture readonly %0) #2 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %p.lastiter = alloca i32, align 4
  %p.lowerbound = alloca i32, align 4
  %p.upperbound = alloca i32, align 4
  %p.stride = alloca i32, align 4
  %1 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %omp_loop.tripcount = tail call i32 @llvm.smax.i32(i32 %1, i32 0)
  store i32 0, ptr %p.lowerbound, align 4
  %2 = add nsw i32 %omp_loop.tripcount, -1
  store i32 %2, ptr %p.upperbound, align 4
  store i32 1, ptr %p.stride, align 4
  %omp_global_thread_num4 = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  call void @__kmpc_for_static_init_4u(ptr nonnull @1, i32 %omp_global_thread_num4, i32 34, ptr nonnull %p.lastiter, ptr nonnull %p.lowerbound, ptr nonnull %p.upperbound, ptr nonnull %p.stride, i32 1, i32 0)
  %3 = load i32, ptr %p.lowerbound, align 4
  %4 = load i32, ptr %p.upperbound, align 4
  %reass.sub = sub i32 %4, %3
  %omp_loop.cmp32.not = icmp eq i32 %reass.sub, -1
  br i1 %omp_loop.cmp32.not, label %omp_loop.exit, label %omp_loop.body.lr.ph

omp_loop.body.lr.ph:                              ; preds = %omp.par.entry
  %.unpack = load ptr, ptr @_QFEarr.0, align 8, !tbaa !8
  %.unpack9.unpack.unpack11.b = load i1, ptr @_QFEarr.8, align 1
  %.unpack9.unpack.unpack11 = select i1 %.unpack9.unpack.unpack11.b, i64 1048576, i64 0
  %loadgep_2.repack16 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  %loadgep_2.repack20 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  %loadgep_2.repack24 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  %loadgep_2.repack26.repack28 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  %5 = add i32 %4, 1
  %6 = sub i32 %5, %3
  %min.iters.check = icmp ult i32 %6, 4
  br i1 %min.iters.check, label %omp_loop.body.preheader, label %vector.scevcheck

vector.scevcheck:                                 ; preds = %omp_loop.body.lr.ph
  %7 = add i32 %3, 1
  %8 = add i32 %4, 1
  %9 = icmp slt i32 %8, %7
  br i1 %9, label %omp_loop.body.preheader, label %vector.memcheck

vector.memcheck:                                  ; preds = %vector.scevcheck
  %scevgep = getelementptr i8, ptr %loadgep_, i64 4
  %10 = add i32 %3, 1
  %11 = sext i32 %10 to i64
  %12 = shl nsw i64 %11, 3
  %13 = add nsw i64 %12, -8
  %scevgep34 = getelementptr i8, ptr %.unpack, i64 %13
  %14 = zext i32 %reass.sub to i64
  %15 = add nsw i64 %11, %14
  %16 = shl nsw i64 %15, 3
  %scevgep35 = getelementptr i8, ptr %.unpack, i64 %16
  %bound0 = icmp ult ptr %loadgep_, %scevgep35
  %bound1 = icmp ult ptr %scevgep34, %scevgep
  %found.conflict = and i1 %bound0, %bound1
  br i1 %found.conflict, label %omp_loop.body.preheader, label %vector.ph

vector.ph:                                        ; preds = %vector.memcheck
  %n.vec = and i32 %6, -2
  %17 = load i32, ptr %loadgep_, align 4, !tbaa !4, !alias.scope !10, !noalias !13
  %broadcast.splatinsert = insertelement <2 x i32> poison, i32 %17, i64 0
  %18 = sitofp <2 x i32> %broadcast.splatinsert to <2 x float>
  %19 = fdiv contract <2 x float> <float 1.000000e+00, float poison>, %18
  %20 = shufflevector <2 x float> %19, <2 x float> poison, <2 x i32> zeroinitializer
  %21 = fpext <2 x float> %20 to <2 x double>
  br label %vector.body

vector.body:                                      ; preds = %vector.body, %vector.ph
  %index = phi i32 [ 0, %vector.ph ], [ %index.next, %vector.body ]
  %22 = or i32 %index, 1
  %23 = add i32 %22, %3
  %24 = sext i32 %23 to i64
  %25 = add nsw i64 %24, -1
  %26 = getelementptr double, ptr %.unpack, i64 %25
  store <2 x double> %21, ptr %26, align 8, !tbaa !4, !alias.scope !13
  %index.next = add nuw i32 %index, 2
  %27 = icmp eq i32 %index.next, %n.vec
  br i1 %27, label %middle.block, label %vector.body, !llvm.loop !15

middle.block:                                     ; preds = %vector.body
  %cmp.n = icmp eq i32 %6, %n.vec
  br i1 %cmp.n, label %omp_loop.header.omp_loop.exit_crit_edge, label %omp_loop.body.preheader

omp_loop.body.preheader:                          ; preds = %vector.memcheck, %vector.scevcheck, %omp_loop.body.lr.ph, %middle.block
  %omp_loop.iv33.ph = phi i32 [ 0, %vector.memcheck ], [ 0, %vector.scevcheck ], [ 0, %omp_loop.body.lr.ph ], [ %n.vec, %middle.block ]
  br label %omp_loop.body

omp_loop.header.omp_loop.exit_crit_edge:          ; preds = %omp_loop.body, %middle.block
  %loadgep_2.repack14 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  %loadgep_2.repack18 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  %loadgep_2.repack22 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  %loadgep_2.repack26 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  %loadgep_2.repack26.repack30 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  store ptr %.unpack, ptr %loadgep_2, align 8, !tbaa !8
  store i64 8, ptr %loadgep_2.repack14, align 8, !tbaa !8
  store i32 20180515, ptr %loadgep_2.repack16, align 8, !tbaa !8
  store i8 1, ptr %loadgep_2.repack18, align 4, !tbaa !8
  store i8 28, ptr %loadgep_2.repack20, align 1, !tbaa !8
  store i8 2, ptr %loadgep_2.repack22, align 2, !tbaa !8
  store i8 0, ptr %loadgep_2.repack24, align 1, !tbaa !8
  store i64 1, ptr %loadgep_2.repack26, align 8, !tbaa !8
  store i64 %.unpack9.unpack.unpack11, ptr %loadgep_2.repack26.repack28, align 8, !tbaa !8
  store i64 8, ptr %loadgep_2.repack26.repack30, align 8, !tbaa !8
  br label %omp_loop.exit

omp_loop.exit:                                    ; preds = %omp_loop.header.omp_loop.exit_crit_edge, %omp.par.entry
  call void @__kmpc_for_static_fini(ptr nonnull @1, i32 %omp_global_thread_num4)
  call void @__kmpc_barrier(ptr nonnull @2, i32 %omp_global_thread_num4)
  ret void

omp_loop.body:                                    ; preds = %omp_loop.body.preheader, %omp_loop.body
  %omp_loop.iv33 = phi i32 [ %28, %omp_loop.body ], [ %omp_loop.iv33.ph, %omp_loop.body.preheader ]
  %28 = add nuw i32 %omp_loop.iv33, 1
  %29 = add i32 %28, %3
  %30 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %31 = sitofp i32 %30 to float
  %32 = fdiv contract float 1.000000e+00, %31
  %33 = fpext float %32 to double
  %34 = sext i32 %29 to i64
  %35 = add nsw i64 %34, -1
  %36 = getelementptr double, ptr %.unpack, i64 %35
  store double %33, ptr %36, align 8, !tbaa !4
  %exitcond.not = icmp eq i32 %omp_loop.iv33, %reass.sub
  br i1 %exitcond.not, label %omp_loop.header.omp_loop.exit_crit_edge, label %omp_loop.body, !llvm.loop !18
}
*** IR Dump After GlobalDCEPass on [module] ***
; ModuleID = 'FIRModule'
source_filename = "FIRModule"
target datalayout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128"
target triple = "x86_64-unknown-linux-gnu"

%struct.ident_t = type { i32, i32, i32, i32, ptr }

@_QFEarr.0 = internal unnamed_addr global ptr null
@_QFEarr.8 = internal unnamed_addr global i1 false
@_QQcl.68815510185ede6107d6524e77abf791 = internal constant [52 x i8] c"/g/g92/rydahl1/flangtests/src/array_descriptors.f90\00"
@_QQcl.28612C69372C612C6531332E36653229 = internal constant [16 x i8] c"(a,i7,a,e13.6e2)"
@_QQcl.54686520726573756C74206F6620286172722831292B61727228 = internal constant [26 x i8] c"The result of (arr(1)+arr("
@_QQcl.2920697320 = internal constant [5 x i8] c") is "
@_QQEnvironmentDefaults = local_unnamed_addr constant ptr null
@0 = private unnamed_addr constant [23 x i8] c";unknown;unknown;0;0;;\00", align 1
@1 = private unnamed_addr constant %struct.ident_t { i32 0, i32 2, i32 0, i32 22, ptr @0 }, align 8
@2 = private unnamed_addr constant %struct.ident_t { i32 0, i32 66, i32 0, i32 22, ptr @0 }, align 8

; Function Attrs: mustprogress nofree nounwind willreturn allockind("alloc,uninitialized") allocsize(0) memory(inaccessiblemem: readwrite)
declare noalias noundef ptr @malloc(i64 noundef) local_unnamed_addr #0

; Function Attrs: mustprogress nounwind willreturn allockind("free") memory(argmem: readwrite, inaccessiblemem: readwrite)
declare void @free(ptr allocptr nocapture noundef) local_unnamed_addr #1

define void @_QQmain() local_unnamed_addr {
entry:
  %structArg = alloca { ptr, ptr }, align 8
  %0 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %1 = alloca i32, align 4
  store i32 1048576, ptr %1, align 4, !tbaa !4
  %2 = tail call dereferenceable_or_null(8388608) ptr @malloc(i64 8388608)
  store ptr %2, ptr @_QFEarr.0, align 8, !tbaa !8
  store i1 true, ptr @_QFEarr.8, align 1
  %omp_global_thread_num = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %1, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %0, ptr %gep_5, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QQmain..omp_par, ptr nonnull %structArg)
  %3 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.68815510185ede6107d6524e77abf791, i32 19)
  %4 = call i1 @_FortranAioOutputAscii(ptr %3, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %5 = load i32, ptr %1, align 4, !tbaa !4
  %6 = call i1 @_FortranAioOutputInteger32(ptr %3, i32 %5)
  %7 = call i1 @_FortranAioOutputAscii(ptr %3, ptr nonnull @_QQcl.2920697320, i64 5)
  %.unpack = load ptr, ptr @_QFEarr.0, align 8, !tbaa !8
  %8 = load double, ptr %.unpack, align 8, !tbaa !4
  %9 = load i32, ptr %1, align 4, !tbaa !4
  %10 = sext i32 %9 to i64
  %11 = add nsw i64 %10, -1
  %12 = getelementptr double, ptr %.unpack, i64 %11
  %13 = load double, ptr %12, align 8, !tbaa !4
  %14 = fadd contract double %8, %13
  %15 = call i1 @_FortranAioOutputReal64(ptr %3, double %14)
  %16 = call i32 @_FortranAioEndIoStatement(ptr %3)
  %.unpack100 = load ptr, ptr @_QFEarr.0, align 8, !tbaa !8
  call void @free(ptr %.unpack100)
  store ptr null, ptr @_QFEarr.0, align 8, !tbaa !8
  store i1 false, ptr @_QFEarr.8, align 1
  ret void
}

; Function Attrs: norecurse nounwind
define internal void @_QQmain..omp_par(ptr noalias nocapture readnone %tid.addr, ptr noalias nocapture readnone %zero.addr, ptr nocapture readonly %0) #2 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %p.lastiter = alloca i32, align 4
  %p.lowerbound = alloca i32, align 4
  %p.upperbound = alloca i32, align 4
  %p.stride = alloca i32, align 4
  %1 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %omp_loop.tripcount = tail call i32 @llvm.smax.i32(i32 %1, i32 0)
  store i32 0, ptr %p.lowerbound, align 4
  %2 = add nsw i32 %omp_loop.tripcount, -1
  store i32 %2, ptr %p.upperbound, align 4
  store i32 1, ptr %p.stride, align 4
  %omp_global_thread_num4 = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  call void @__kmpc_for_static_init_4u(ptr nonnull @1, i32 %omp_global_thread_num4, i32 34, ptr nonnull %p.lastiter, ptr nonnull %p.lowerbound, ptr nonnull %p.upperbound, ptr nonnull %p.stride, i32 1, i32 0)
  %3 = load i32, ptr %p.lowerbound, align 4
  %4 = load i32, ptr %p.upperbound, align 4
  %reass.sub = sub i32 %4, %3
  %omp_loop.cmp32.not = icmp eq i32 %reass.sub, -1
  br i1 %omp_loop.cmp32.not, label %omp_loop.exit, label %omp_loop.body.lr.ph

omp_loop.body.lr.ph:                              ; preds = %omp.par.entry
  %.unpack = load ptr, ptr @_QFEarr.0, align 8, !tbaa !8
  %.unpack9.unpack.unpack11.b = load i1, ptr @_QFEarr.8, align 1
  %.unpack9.unpack.unpack11 = select i1 %.unpack9.unpack.unpack11.b, i64 1048576, i64 0
  %loadgep_2.repack16 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  %loadgep_2.repack20 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  %loadgep_2.repack24 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  %loadgep_2.repack26.repack28 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  %5 = add i32 %4, 1
  %6 = sub i32 %5, %3
  %min.iters.check = icmp ult i32 %6, 4
  br i1 %min.iters.check, label %omp_loop.body.preheader, label %vector.scevcheck

vector.scevcheck:                                 ; preds = %omp_loop.body.lr.ph
  %7 = add i32 %3, 1
  %8 = add i32 %4, 1
  %9 = icmp slt i32 %8, %7
  br i1 %9, label %omp_loop.body.preheader, label %vector.memcheck

vector.memcheck:                                  ; preds = %vector.scevcheck
  %scevgep = getelementptr i8, ptr %loadgep_, i64 4
  %10 = add i32 %3, 1
  %11 = sext i32 %10 to i64
  %12 = shl nsw i64 %11, 3
  %13 = add nsw i64 %12, -8
  %scevgep34 = getelementptr i8, ptr %.unpack, i64 %13
  %14 = zext i32 %reass.sub to i64
  %15 = add nsw i64 %11, %14
  %16 = shl nsw i64 %15, 3
  %scevgep35 = getelementptr i8, ptr %.unpack, i64 %16
  %bound0 = icmp ult ptr %loadgep_, %scevgep35
  %bound1 = icmp ult ptr %scevgep34, %scevgep
  %found.conflict = and i1 %bound0, %bound1
  br i1 %found.conflict, label %omp_loop.body.preheader, label %vector.ph

vector.ph:                                        ; preds = %vector.memcheck
  %n.vec = and i32 %6, -2
  %17 = load i32, ptr %loadgep_, align 4, !tbaa !4, !alias.scope !10, !noalias !13
  %broadcast.splatinsert = insertelement <2 x i32> poison, i32 %17, i64 0
  %18 = sitofp <2 x i32> %broadcast.splatinsert to <2 x float>
  %19 = fdiv contract <2 x float> <float 1.000000e+00, float poison>, %18
  %20 = shufflevector <2 x float> %19, <2 x float> poison, <2 x i32> zeroinitializer
  %21 = fpext <2 x float> %20 to <2 x double>
  br label %vector.body

vector.body:                                      ; preds = %vector.body, %vector.ph
  %index = phi i32 [ 0, %vector.ph ], [ %index.next, %vector.body ]
  %22 = or i32 %index, 1
  %23 = add i32 %22, %3
  %24 = sext i32 %23 to i64
  %25 = add nsw i64 %24, -1
  %26 = getelementptr double, ptr %.unpack, i64 %25
  store <2 x double> %21, ptr %26, align 8, !tbaa !4, !alias.scope !13
  %index.next = add nuw i32 %index, 2
  %27 = icmp eq i32 %index.next, %n.vec
  br i1 %27, label %middle.block, label %vector.body, !llvm.loop !15

middle.block:                                     ; preds = %vector.body
  %cmp.n = icmp eq i32 %6, %n.vec
  br i1 %cmp.n, label %omp_loop.header.omp_loop.exit_crit_edge, label %omp_loop.body.preheader

omp_loop.body.preheader:                          ; preds = %vector.memcheck, %vector.scevcheck, %omp_loop.body.lr.ph, %middle.block
  %omp_loop.iv33.ph = phi i32 [ 0, %vector.memcheck ], [ 0, %vector.scevcheck ], [ 0, %omp_loop.body.lr.ph ], [ %n.vec, %middle.block ]
  br label %omp_loop.body

omp_loop.header.omp_loop.exit_crit_edge:          ; preds = %omp_loop.body, %middle.block
  %loadgep_2.repack14 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  %loadgep_2.repack18 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  %loadgep_2.repack22 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  %loadgep_2.repack26 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  %loadgep_2.repack26.repack30 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  store ptr %.unpack, ptr %loadgep_2, align 8, !tbaa !8
  store i64 8, ptr %loadgep_2.repack14, align 8, !tbaa !8
  store i32 20180515, ptr %loadgep_2.repack16, align 8, !tbaa !8
  store i8 1, ptr %loadgep_2.repack18, align 4, !tbaa !8
  store i8 28, ptr %loadgep_2.repack20, align 1, !tbaa !8
  store i8 2, ptr %loadgep_2.repack22, align 2, !tbaa !8
  store i8 0, ptr %loadgep_2.repack24, align 1, !tbaa !8
  store i64 1, ptr %loadgep_2.repack26, align 8, !tbaa !8
  store i64 %.unpack9.unpack.unpack11, ptr %loadgep_2.repack26.repack28, align 8, !tbaa !8
  store i64 8, ptr %loadgep_2.repack26.repack30, align 8, !tbaa !8
  br label %omp_loop.exit

omp_loop.exit:                                    ; preds = %omp_loop.header.omp_loop.exit_crit_edge, %omp.par.entry
  call void @__kmpc_for_static_fini(ptr nonnull @1, i32 %omp_global_thread_num4)
  call void @__kmpc_barrier(ptr nonnull @2, i32 %omp_global_thread_num4)
  ret void

omp_loop.body:                                    ; preds = %omp_loop.body.preheader, %omp_loop.body
  %omp_loop.iv33 = phi i32 [ %28, %omp_loop.body ], [ %omp_loop.iv33.ph, %omp_loop.body.preheader ]
  %28 = add nuw i32 %omp_loop.iv33, 1
  %29 = add i32 %28, %3
  %30 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %31 = sitofp i32 %30 to float
  %32 = fdiv contract float 1.000000e+00, %31
  %33 = fpext float %32 to double
  %34 = sext i32 %29 to i64
  %35 = add nsw i64 %34, -1
  %36 = getelementptr double, ptr %.unpack, i64 %35
  store double %33, ptr %36, align 8, !tbaa !4
  %exitcond.not = icmp eq i32 %omp_loop.iv33, %reass.sub
  br i1 %exitcond.not, label %omp_loop.header.omp_loop.exit_crit_edge, label %omp_loop.body, !llvm.loop !18
}

declare ptr @_FortranAioBeginExternalFormattedOutput(ptr, i64, ptr, i32, ptr, i32) local_unnamed_addr

declare zeroext i1 @_FortranAioOutputAscii(ptr, ptr, i64) local_unnamed_addr

declare zeroext i1 @_FortranAioOutputInteger32(ptr, i32) local_unnamed_addr

declare zeroext i1 @_FortranAioOutputReal64(ptr, double) local_unnamed_addr

declare i32 @_FortranAioEndIoStatement(ptr) local_unnamed_addr

; Function Attrs: nounwind
declare i32 @__kmpc_global_thread_num(ptr) local_unnamed_addr #3

; Function Attrs: nounwind
declare void @__kmpc_for_static_init_4u(ptr, i32, i32, ptr, ptr, ptr, ptr, i32, i32) local_unnamed_addr #3

; Function Attrs: nounwind
declare void @__kmpc_for_static_fini(ptr, i32) local_unnamed_addr #3

; Function Attrs: convergent nounwind
declare void @__kmpc_barrier(ptr, i32) local_unnamed_addr #4

; Function Attrs: nounwind
declare !callback !19 void @__kmpc_fork_call(ptr, i32, ptr, ...) local_unnamed_addr #3

; Function Attrs: nocallback nofree nosync nounwind speculatable willreturn memory(none)
declare i32 @llvm.smax.i32(i32, i32) #5

attributes #0 = { mustprogress nofree nounwind willreturn allockind("alloc,uninitialized") allocsize(0) memory(inaccessiblemem: readwrite) "alloc-family"="malloc" }
attributes #1 = { mustprogress nounwind willreturn allockind("free") memory(argmem: readwrite, inaccessiblemem: readwrite) "alloc-family"="malloc" }
attributes #2 = { norecurse nounwind }
attributes #3 = { nounwind }
attributes #4 = { convergent nounwind }
attributes #5 = { nocallback nofree nosync nounwind speculatable willreturn memory(none) }

!llvm.module.flags = !{!0, !1, !2, !3}

!0 = !{i32 2, !"Debug Info Version", i32 3}
!1 = !{i32 7, !"openmp", i32 11}
!2 = !{i32 8, !"PIC Level", i32 2}
!3 = !{i32 7, !"PIE Level", i32 2}
!4 = !{!5, !5, i64 0}
!5 = !{!"any data access", !6, i64 0}
!6 = !{!"any access", !7, i64 0}
!7 = !{!"Flang Type TBAA Root"}
!8 = !{!9, !9, i64 0}
!9 = !{!"descriptor member", !6, i64 0}
!10 = !{!11}
!11 = distinct !{!11, !12}
!12 = distinct !{!12, !"LVerDomain"}
!13 = !{!14}
!14 = distinct !{!14, !12}
!15 = distinct !{!15, !16, !17}
!16 = !{!"llvm.loop.isvectorized", i32 1}
!17 = !{!"llvm.loop.unroll.runtime.disable"}
!18 = distinct !{!18, !16}
!19 = !{!20}
!20 = !{i64 2, i64 -1, i64 -1, i1 true}
*** IR Dump After ConstantMergePass on [module] ***
; ModuleID = 'FIRModule'
source_filename = "FIRModule"
target datalayout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128"
target triple = "x86_64-unknown-linux-gnu"

%struct.ident_t = type { i32, i32, i32, i32, ptr }

@_QFEarr.0 = internal unnamed_addr global ptr null
@_QFEarr.8 = internal unnamed_addr global i1 false
@_QQcl.68815510185ede6107d6524e77abf791 = internal constant [52 x i8] c"/g/g92/rydahl1/flangtests/src/array_descriptors.f90\00"
@_QQcl.28612C69372C612C6531332E36653229 = internal constant [16 x i8] c"(a,i7,a,e13.6e2)"
@_QQcl.54686520726573756C74206F6620286172722831292B61727228 = internal constant [26 x i8] c"The result of (arr(1)+arr("
@_QQcl.2920697320 = internal constant [5 x i8] c") is "
@_QQEnvironmentDefaults = local_unnamed_addr constant ptr null
@0 = private unnamed_addr constant [23 x i8] c";unknown;unknown;0;0;;\00", align 1
@1 = private unnamed_addr constant %struct.ident_t { i32 0, i32 2, i32 0, i32 22, ptr @0 }, align 8
@2 = private unnamed_addr constant %struct.ident_t { i32 0, i32 66, i32 0, i32 22, ptr @0 }, align 8

; Function Attrs: mustprogress nofree nounwind willreturn allockind("alloc,uninitialized") allocsize(0) memory(inaccessiblemem: readwrite)
declare noalias noundef ptr @malloc(i64 noundef) local_unnamed_addr #0

; Function Attrs: mustprogress nounwind willreturn allockind("free") memory(argmem: readwrite, inaccessiblemem: readwrite)
declare void @free(ptr allocptr nocapture noundef) local_unnamed_addr #1

define void @_QQmain() local_unnamed_addr {
entry:
  %structArg = alloca { ptr, ptr }, align 8
  %0 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %1 = alloca i32, align 4
  store i32 1048576, ptr %1, align 4, !tbaa !4
  %2 = tail call dereferenceable_or_null(8388608) ptr @malloc(i64 8388608)
  store ptr %2, ptr @_QFEarr.0, align 8, !tbaa !8
  store i1 true, ptr @_QFEarr.8, align 1
  %omp_global_thread_num = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %1, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %0, ptr %gep_5, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QQmain..omp_par, ptr nonnull %structArg)
  %3 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.68815510185ede6107d6524e77abf791, i32 19)
  %4 = call i1 @_FortranAioOutputAscii(ptr %3, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %5 = load i32, ptr %1, align 4, !tbaa !4
  %6 = call i1 @_FortranAioOutputInteger32(ptr %3, i32 %5)
  %7 = call i1 @_FortranAioOutputAscii(ptr %3, ptr nonnull @_QQcl.2920697320, i64 5)
  %.unpack = load ptr, ptr @_QFEarr.0, align 8, !tbaa !8
  %8 = load double, ptr %.unpack, align 8, !tbaa !4
  %9 = load i32, ptr %1, align 4, !tbaa !4
  %10 = sext i32 %9 to i64
  %11 = add nsw i64 %10, -1
  %12 = getelementptr double, ptr %.unpack, i64 %11
  %13 = load double, ptr %12, align 8, !tbaa !4
  %14 = fadd contract double %8, %13
  %15 = call i1 @_FortranAioOutputReal64(ptr %3, double %14)
  %16 = call i32 @_FortranAioEndIoStatement(ptr %3)
  %.unpack100 = load ptr, ptr @_QFEarr.0, align 8, !tbaa !8
  call void @free(ptr %.unpack100)
  store ptr null, ptr @_QFEarr.0, align 8, !tbaa !8
  store i1 false, ptr @_QFEarr.8, align 1
  ret void
}

; Function Attrs: norecurse nounwind
define internal void @_QQmain..omp_par(ptr noalias nocapture readnone %tid.addr, ptr noalias nocapture readnone %zero.addr, ptr nocapture readonly %0) #2 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %p.lastiter = alloca i32, align 4
  %p.lowerbound = alloca i32, align 4
  %p.upperbound = alloca i32, align 4
  %p.stride = alloca i32, align 4
  %1 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %omp_loop.tripcount = tail call i32 @llvm.smax.i32(i32 %1, i32 0)
  store i32 0, ptr %p.lowerbound, align 4
  %2 = add nsw i32 %omp_loop.tripcount, -1
  store i32 %2, ptr %p.upperbound, align 4
  store i32 1, ptr %p.stride, align 4
  %omp_global_thread_num4 = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  call void @__kmpc_for_static_init_4u(ptr nonnull @1, i32 %omp_global_thread_num4, i32 34, ptr nonnull %p.lastiter, ptr nonnull %p.lowerbound, ptr nonnull %p.upperbound, ptr nonnull %p.stride, i32 1, i32 0)
  %3 = load i32, ptr %p.lowerbound, align 4
  %4 = load i32, ptr %p.upperbound, align 4
  %reass.sub = sub i32 %4, %3
  %omp_loop.cmp32.not = icmp eq i32 %reass.sub, -1
  br i1 %omp_loop.cmp32.not, label %omp_loop.exit, label %omp_loop.body.lr.ph

omp_loop.body.lr.ph:                              ; preds = %omp.par.entry
  %.unpack = load ptr, ptr @_QFEarr.0, align 8, !tbaa !8
  %.unpack9.unpack.unpack11.b = load i1, ptr @_QFEarr.8, align 1
  %.unpack9.unpack.unpack11 = select i1 %.unpack9.unpack.unpack11.b, i64 1048576, i64 0
  %loadgep_2.repack16 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  %loadgep_2.repack20 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  %loadgep_2.repack24 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  %loadgep_2.repack26.repack28 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  %5 = add i32 %4, 1
  %6 = sub i32 %5, %3
  %min.iters.check = icmp ult i32 %6, 4
  br i1 %min.iters.check, label %omp_loop.body.preheader, label %vector.scevcheck

vector.scevcheck:                                 ; preds = %omp_loop.body.lr.ph
  %7 = add i32 %3, 1
  %8 = add i32 %4, 1
  %9 = icmp slt i32 %8, %7
  br i1 %9, label %omp_loop.body.preheader, label %vector.memcheck

vector.memcheck:                                  ; preds = %vector.scevcheck
  %scevgep = getelementptr i8, ptr %loadgep_, i64 4
  %10 = add i32 %3, 1
  %11 = sext i32 %10 to i64
  %12 = shl nsw i64 %11, 3
  %13 = add nsw i64 %12, -8
  %scevgep34 = getelementptr i8, ptr %.unpack, i64 %13
  %14 = zext i32 %reass.sub to i64
  %15 = add nsw i64 %11, %14
  %16 = shl nsw i64 %15, 3
  %scevgep35 = getelementptr i8, ptr %.unpack, i64 %16
  %bound0 = icmp ult ptr %loadgep_, %scevgep35
  %bound1 = icmp ult ptr %scevgep34, %scevgep
  %found.conflict = and i1 %bound0, %bound1
  br i1 %found.conflict, label %omp_loop.body.preheader, label %vector.ph

vector.ph:                                        ; preds = %vector.memcheck
  %n.vec = and i32 %6, -2
  %17 = load i32, ptr %loadgep_, align 4, !tbaa !4, !alias.scope !10, !noalias !13
  %broadcast.splatinsert = insertelement <2 x i32> poison, i32 %17, i64 0
  %18 = sitofp <2 x i32> %broadcast.splatinsert to <2 x float>
  %19 = fdiv contract <2 x float> <float 1.000000e+00, float poison>, %18
  %20 = shufflevector <2 x float> %19, <2 x float> poison, <2 x i32> zeroinitializer
  %21 = fpext <2 x float> %20 to <2 x double>
  br label %vector.body

vector.body:                                      ; preds = %vector.body, %vector.ph
  %index = phi i32 [ 0, %vector.ph ], [ %index.next, %vector.body ]
  %22 = or i32 %index, 1
  %23 = add i32 %22, %3
  %24 = sext i32 %23 to i64
  %25 = add nsw i64 %24, -1
  %26 = getelementptr double, ptr %.unpack, i64 %25
  store <2 x double> %21, ptr %26, align 8, !tbaa !4, !alias.scope !13
  %index.next = add nuw i32 %index, 2
  %27 = icmp eq i32 %index.next, %n.vec
  br i1 %27, label %middle.block, label %vector.body, !llvm.loop !15

middle.block:                                     ; preds = %vector.body
  %cmp.n = icmp eq i32 %6, %n.vec
  br i1 %cmp.n, label %omp_loop.header.omp_loop.exit_crit_edge, label %omp_loop.body.preheader

omp_loop.body.preheader:                          ; preds = %vector.memcheck, %vector.scevcheck, %omp_loop.body.lr.ph, %middle.block
  %omp_loop.iv33.ph = phi i32 [ 0, %vector.memcheck ], [ 0, %vector.scevcheck ], [ 0, %omp_loop.body.lr.ph ], [ %n.vec, %middle.block ]
  br label %omp_loop.body

omp_loop.header.omp_loop.exit_crit_edge:          ; preds = %omp_loop.body, %middle.block
  %loadgep_2.repack14 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  %loadgep_2.repack18 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  %loadgep_2.repack22 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  %loadgep_2.repack26 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  %loadgep_2.repack26.repack30 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  store ptr %.unpack, ptr %loadgep_2, align 8, !tbaa !8
  store i64 8, ptr %loadgep_2.repack14, align 8, !tbaa !8
  store i32 20180515, ptr %loadgep_2.repack16, align 8, !tbaa !8
  store i8 1, ptr %loadgep_2.repack18, align 4, !tbaa !8
  store i8 28, ptr %loadgep_2.repack20, align 1, !tbaa !8
  store i8 2, ptr %loadgep_2.repack22, align 2, !tbaa !8
  store i8 0, ptr %loadgep_2.repack24, align 1, !tbaa !8
  store i64 1, ptr %loadgep_2.repack26, align 8, !tbaa !8
  store i64 %.unpack9.unpack.unpack11, ptr %loadgep_2.repack26.repack28, align 8, !tbaa !8
  store i64 8, ptr %loadgep_2.repack26.repack30, align 8, !tbaa !8
  br label %omp_loop.exit

omp_loop.exit:                                    ; preds = %omp_loop.header.omp_loop.exit_crit_edge, %omp.par.entry
  call void @__kmpc_for_static_fini(ptr nonnull @1, i32 %omp_global_thread_num4)
  call void @__kmpc_barrier(ptr nonnull @2, i32 %omp_global_thread_num4)
  ret void

omp_loop.body:                                    ; preds = %omp_loop.body.preheader, %omp_loop.body
  %omp_loop.iv33 = phi i32 [ %28, %omp_loop.body ], [ %omp_loop.iv33.ph, %omp_loop.body.preheader ]
  %28 = add nuw i32 %omp_loop.iv33, 1
  %29 = add i32 %28, %3
  %30 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %31 = sitofp i32 %30 to float
  %32 = fdiv contract float 1.000000e+00, %31
  %33 = fpext float %32 to double
  %34 = sext i32 %29 to i64
  %35 = add nsw i64 %34, -1
  %36 = getelementptr double, ptr %.unpack, i64 %35
  store double %33, ptr %36, align 8, !tbaa !4
  %exitcond.not = icmp eq i32 %omp_loop.iv33, %reass.sub
  br i1 %exitcond.not, label %omp_loop.header.omp_loop.exit_crit_edge, label %omp_loop.body, !llvm.loop !18
}

declare ptr @_FortranAioBeginExternalFormattedOutput(ptr, i64, ptr, i32, ptr, i32) local_unnamed_addr

declare zeroext i1 @_FortranAioOutputAscii(ptr, ptr, i64) local_unnamed_addr

declare zeroext i1 @_FortranAioOutputInteger32(ptr, i32) local_unnamed_addr

declare zeroext i1 @_FortranAioOutputReal64(ptr, double) local_unnamed_addr

declare i32 @_FortranAioEndIoStatement(ptr) local_unnamed_addr

; Function Attrs: nounwind
declare i32 @__kmpc_global_thread_num(ptr) local_unnamed_addr #3

; Function Attrs: nounwind
declare void @__kmpc_for_static_init_4u(ptr, i32, i32, ptr, ptr, ptr, ptr, i32, i32) local_unnamed_addr #3

; Function Attrs: nounwind
declare void @__kmpc_for_static_fini(ptr, i32) local_unnamed_addr #3

; Function Attrs: convergent nounwind
declare void @__kmpc_barrier(ptr, i32) local_unnamed_addr #4

; Function Attrs: nounwind
declare !callback !19 void @__kmpc_fork_call(ptr, i32, ptr, ...) local_unnamed_addr #3

; Function Attrs: nocallback nofree nosync nounwind speculatable willreturn memory(none)
declare i32 @llvm.smax.i32(i32, i32) #5

attributes #0 = { mustprogress nofree nounwind willreturn allockind("alloc,uninitialized") allocsize(0) memory(inaccessiblemem: readwrite) "alloc-family"="malloc" }
attributes #1 = { mustprogress nounwind willreturn allockind("free") memory(argmem: readwrite, inaccessiblemem: readwrite) "alloc-family"="malloc" }
attributes #2 = { norecurse nounwind }
attributes #3 = { nounwind }
attributes #4 = { convergent nounwind }
attributes #5 = { nocallback nofree nosync nounwind speculatable willreturn memory(none) }

!llvm.module.flags = !{!0, !1, !2, !3}

!0 = !{i32 2, !"Debug Info Version", i32 3}
!1 = !{i32 7, !"openmp", i32 11}
!2 = !{i32 8, !"PIC Level", i32 2}
!3 = !{i32 7, !"PIE Level", i32 2}
!4 = !{!5, !5, i64 0}
!5 = !{!"any data access", !6, i64 0}
!6 = !{!"any access", !7, i64 0}
!7 = !{!"Flang Type TBAA Root"}
!8 = !{!9, !9, i64 0}
!9 = !{!"descriptor member", !6, i64 0}
!10 = !{!11}
!11 = distinct !{!11, !12}
!12 = distinct !{!12, !"LVerDomain"}
!13 = !{!14}
!14 = distinct !{!14, !12}
!15 = distinct !{!15, !16, !17}
!16 = !{!"llvm.loop.isvectorized", i32 1}
!17 = !{!"llvm.loop.unroll.runtime.disable"}
!18 = distinct !{!18, !16}
!19 = !{!20}
!20 = !{i64 2, i64 -1, i64 -1, i1 true}
*** IR Dump After CGProfilePass on [module] ***
; ModuleID = 'FIRModule'
source_filename = "FIRModule"
target datalayout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128"
target triple = "x86_64-unknown-linux-gnu"

%struct.ident_t = type { i32, i32, i32, i32, ptr }

@_QFEarr.0 = internal unnamed_addr global ptr null
@_QFEarr.8 = internal unnamed_addr global i1 false
@_QQcl.68815510185ede6107d6524e77abf791 = internal constant [52 x i8] c"/g/g92/rydahl1/flangtests/src/array_descriptors.f90\00"
@_QQcl.28612C69372C612C6531332E36653229 = internal constant [16 x i8] c"(a,i7,a,e13.6e2)"
@_QQcl.54686520726573756C74206F6620286172722831292B61727228 = internal constant [26 x i8] c"The result of (arr(1)+arr("
@_QQcl.2920697320 = internal constant [5 x i8] c") is "
@_QQEnvironmentDefaults = local_unnamed_addr constant ptr null
@0 = private unnamed_addr constant [23 x i8] c";unknown;unknown;0;0;;\00", align 1
@1 = private unnamed_addr constant %struct.ident_t { i32 0, i32 2, i32 0, i32 22, ptr @0 }, align 8
@2 = private unnamed_addr constant %struct.ident_t { i32 0, i32 66, i32 0, i32 22, ptr @0 }, align 8

; Function Attrs: mustprogress nofree nounwind willreturn allockind("alloc,uninitialized") allocsize(0) memory(inaccessiblemem: readwrite)
declare noalias noundef ptr @malloc(i64 noundef) local_unnamed_addr #0

; Function Attrs: mustprogress nounwind willreturn allockind("free") memory(argmem: readwrite, inaccessiblemem: readwrite)
declare void @free(ptr allocptr nocapture noundef) local_unnamed_addr #1

define void @_QQmain() local_unnamed_addr {
entry:
  %structArg = alloca { ptr, ptr }, align 8
  %0 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %1 = alloca i32, align 4
  store i32 1048576, ptr %1, align 4, !tbaa !4
  %2 = tail call dereferenceable_or_null(8388608) ptr @malloc(i64 8388608)
  store ptr %2, ptr @_QFEarr.0, align 8, !tbaa !8
  store i1 true, ptr @_QFEarr.8, align 1
  %omp_global_thread_num = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %1, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %0, ptr %gep_5, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QQmain..omp_par, ptr nonnull %structArg)
  %3 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.68815510185ede6107d6524e77abf791, i32 19)
  %4 = call i1 @_FortranAioOutputAscii(ptr %3, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %5 = load i32, ptr %1, align 4, !tbaa !4
  %6 = call i1 @_FortranAioOutputInteger32(ptr %3, i32 %5)
  %7 = call i1 @_FortranAioOutputAscii(ptr %3, ptr nonnull @_QQcl.2920697320, i64 5)
  %.unpack = load ptr, ptr @_QFEarr.0, align 8, !tbaa !8
  %8 = load double, ptr %.unpack, align 8, !tbaa !4
  %9 = load i32, ptr %1, align 4, !tbaa !4
  %10 = sext i32 %9 to i64
  %11 = add nsw i64 %10, -1
  %12 = getelementptr double, ptr %.unpack, i64 %11
  %13 = load double, ptr %12, align 8, !tbaa !4
  %14 = fadd contract double %8, %13
  %15 = call i1 @_FortranAioOutputReal64(ptr %3, double %14)
  %16 = call i32 @_FortranAioEndIoStatement(ptr %3)
  %.unpack100 = load ptr, ptr @_QFEarr.0, align 8, !tbaa !8
  call void @free(ptr %.unpack100)
  store ptr null, ptr @_QFEarr.0, align 8, !tbaa !8
  store i1 false, ptr @_QFEarr.8, align 1
  ret void
}

; Function Attrs: norecurse nounwind
define internal void @_QQmain..omp_par(ptr noalias nocapture readnone %tid.addr, ptr noalias nocapture readnone %zero.addr, ptr nocapture readonly %0) #2 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %p.lastiter = alloca i32, align 4
  %p.lowerbound = alloca i32, align 4
  %p.upperbound = alloca i32, align 4
  %p.stride = alloca i32, align 4
  %1 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %omp_loop.tripcount = tail call i32 @llvm.smax.i32(i32 %1, i32 0)
  store i32 0, ptr %p.lowerbound, align 4
  %2 = add nsw i32 %omp_loop.tripcount, -1
  store i32 %2, ptr %p.upperbound, align 4
  store i32 1, ptr %p.stride, align 4
  %omp_global_thread_num4 = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  call void @__kmpc_for_static_init_4u(ptr nonnull @1, i32 %omp_global_thread_num4, i32 34, ptr nonnull %p.lastiter, ptr nonnull %p.lowerbound, ptr nonnull %p.upperbound, ptr nonnull %p.stride, i32 1, i32 0)
  %3 = load i32, ptr %p.lowerbound, align 4
  %4 = load i32, ptr %p.upperbound, align 4
  %reass.sub = sub i32 %4, %3
  %omp_loop.cmp32.not = icmp eq i32 %reass.sub, -1
  br i1 %omp_loop.cmp32.not, label %omp_loop.exit, label %omp_loop.body.lr.ph

omp_loop.body.lr.ph:                              ; preds = %omp.par.entry
  %.unpack = load ptr, ptr @_QFEarr.0, align 8, !tbaa !8
  %.unpack9.unpack.unpack11.b = load i1, ptr @_QFEarr.8, align 1
  %.unpack9.unpack.unpack11 = select i1 %.unpack9.unpack.unpack11.b, i64 1048576, i64 0
  %loadgep_2.repack16 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  %loadgep_2.repack20 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  %loadgep_2.repack24 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  %loadgep_2.repack26.repack28 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  %5 = add i32 %4, 1
  %6 = sub i32 %5, %3
  %min.iters.check = icmp ult i32 %6, 4
  br i1 %min.iters.check, label %omp_loop.body.preheader, label %vector.scevcheck

vector.scevcheck:                                 ; preds = %omp_loop.body.lr.ph
  %7 = add i32 %3, 1
  %8 = add i32 %4, 1
  %9 = icmp slt i32 %8, %7
  br i1 %9, label %omp_loop.body.preheader, label %vector.memcheck

vector.memcheck:                                  ; preds = %vector.scevcheck
  %scevgep = getelementptr i8, ptr %loadgep_, i64 4
  %10 = add i32 %3, 1
  %11 = sext i32 %10 to i64
  %12 = shl nsw i64 %11, 3
  %13 = add nsw i64 %12, -8
  %scevgep34 = getelementptr i8, ptr %.unpack, i64 %13
  %14 = zext i32 %reass.sub to i64
  %15 = add nsw i64 %11, %14
  %16 = shl nsw i64 %15, 3
  %scevgep35 = getelementptr i8, ptr %.unpack, i64 %16
  %bound0 = icmp ult ptr %loadgep_, %scevgep35
  %bound1 = icmp ult ptr %scevgep34, %scevgep
  %found.conflict = and i1 %bound0, %bound1
  br i1 %found.conflict, label %omp_loop.body.preheader, label %vector.ph

vector.ph:                                        ; preds = %vector.memcheck
  %n.vec = and i32 %6, -2
  %17 = load i32, ptr %loadgep_, align 4, !tbaa !4, !alias.scope !10, !noalias !13
  %broadcast.splatinsert = insertelement <2 x i32> poison, i32 %17, i64 0
  %18 = sitofp <2 x i32> %broadcast.splatinsert to <2 x float>
  %19 = fdiv contract <2 x float> <float 1.000000e+00, float poison>, %18
  %20 = shufflevector <2 x float> %19, <2 x float> poison, <2 x i32> zeroinitializer
  %21 = fpext <2 x float> %20 to <2 x double>
  br label %vector.body

vector.body:                                      ; preds = %vector.body, %vector.ph
  %index = phi i32 [ 0, %vector.ph ], [ %index.next, %vector.body ]
  %22 = or i32 %index, 1
  %23 = add i32 %22, %3
  %24 = sext i32 %23 to i64
  %25 = add nsw i64 %24, -1
  %26 = getelementptr double, ptr %.unpack, i64 %25
  store <2 x double> %21, ptr %26, align 8, !tbaa !4, !alias.scope !13
  %index.next = add nuw i32 %index, 2
  %27 = icmp eq i32 %index.next, %n.vec
  br i1 %27, label %middle.block, label %vector.body, !llvm.loop !15

middle.block:                                     ; preds = %vector.body
  %cmp.n = icmp eq i32 %6, %n.vec
  br i1 %cmp.n, label %omp_loop.header.omp_loop.exit_crit_edge, label %omp_loop.body.preheader

omp_loop.body.preheader:                          ; preds = %vector.memcheck, %vector.scevcheck, %omp_loop.body.lr.ph, %middle.block
  %omp_loop.iv33.ph = phi i32 [ 0, %vector.memcheck ], [ 0, %vector.scevcheck ], [ 0, %omp_loop.body.lr.ph ], [ %n.vec, %middle.block ]
  br label %omp_loop.body

omp_loop.header.omp_loop.exit_crit_edge:          ; preds = %omp_loop.body, %middle.block
  %loadgep_2.repack14 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  %loadgep_2.repack18 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  %loadgep_2.repack22 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  %loadgep_2.repack26 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  %loadgep_2.repack26.repack30 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  store ptr %.unpack, ptr %loadgep_2, align 8, !tbaa !8
  store i64 8, ptr %loadgep_2.repack14, align 8, !tbaa !8
  store i32 20180515, ptr %loadgep_2.repack16, align 8, !tbaa !8
  store i8 1, ptr %loadgep_2.repack18, align 4, !tbaa !8
  store i8 28, ptr %loadgep_2.repack20, align 1, !tbaa !8
  store i8 2, ptr %loadgep_2.repack22, align 2, !tbaa !8
  store i8 0, ptr %loadgep_2.repack24, align 1, !tbaa !8
  store i64 1, ptr %loadgep_2.repack26, align 8, !tbaa !8
  store i64 %.unpack9.unpack.unpack11, ptr %loadgep_2.repack26.repack28, align 8, !tbaa !8
  store i64 8, ptr %loadgep_2.repack26.repack30, align 8, !tbaa !8
  br label %omp_loop.exit

omp_loop.exit:                                    ; preds = %omp_loop.header.omp_loop.exit_crit_edge, %omp.par.entry
  call void @__kmpc_for_static_fini(ptr nonnull @1, i32 %omp_global_thread_num4)
  call void @__kmpc_barrier(ptr nonnull @2, i32 %omp_global_thread_num4)
  ret void

omp_loop.body:                                    ; preds = %omp_loop.body.preheader, %omp_loop.body
  %omp_loop.iv33 = phi i32 [ %28, %omp_loop.body ], [ %omp_loop.iv33.ph, %omp_loop.body.preheader ]
  %28 = add nuw i32 %omp_loop.iv33, 1
  %29 = add i32 %28, %3
  %30 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %31 = sitofp i32 %30 to float
  %32 = fdiv contract float 1.000000e+00, %31
  %33 = fpext float %32 to double
  %34 = sext i32 %29 to i64
  %35 = add nsw i64 %34, -1
  %36 = getelementptr double, ptr %.unpack, i64 %35
  store double %33, ptr %36, align 8, !tbaa !4
  %exitcond.not = icmp eq i32 %omp_loop.iv33, %reass.sub
  br i1 %exitcond.not, label %omp_loop.header.omp_loop.exit_crit_edge, label %omp_loop.body, !llvm.loop !18
}

declare ptr @_FortranAioBeginExternalFormattedOutput(ptr, i64, ptr, i32, ptr, i32) local_unnamed_addr

declare zeroext i1 @_FortranAioOutputAscii(ptr, ptr, i64) local_unnamed_addr

declare zeroext i1 @_FortranAioOutputInteger32(ptr, i32) local_unnamed_addr

declare zeroext i1 @_FortranAioOutputReal64(ptr, double) local_unnamed_addr

declare i32 @_FortranAioEndIoStatement(ptr) local_unnamed_addr

; Function Attrs: nounwind
declare i32 @__kmpc_global_thread_num(ptr) local_unnamed_addr #3

; Function Attrs: nounwind
declare void @__kmpc_for_static_init_4u(ptr, i32, i32, ptr, ptr, ptr, ptr, i32, i32) local_unnamed_addr #3

; Function Attrs: nounwind
declare void @__kmpc_for_static_fini(ptr, i32) local_unnamed_addr #3

; Function Attrs: convergent nounwind
declare void @__kmpc_barrier(ptr, i32) local_unnamed_addr #4

; Function Attrs: nounwind
declare !callback !19 void @__kmpc_fork_call(ptr, i32, ptr, ...) local_unnamed_addr #3

; Function Attrs: nocallback nofree nosync nounwind speculatable willreturn memory(none)
declare i32 @llvm.smax.i32(i32, i32) #5

attributes #0 = { mustprogress nofree nounwind willreturn allockind("alloc,uninitialized") allocsize(0) memory(inaccessiblemem: readwrite) "alloc-family"="malloc" }
attributes #1 = { mustprogress nounwind willreturn allockind("free") memory(argmem: readwrite, inaccessiblemem: readwrite) "alloc-family"="malloc" }
attributes #2 = { norecurse nounwind }
attributes #3 = { nounwind }
attributes #4 = { convergent nounwind }
attributes #5 = { nocallback nofree nosync nounwind speculatable willreturn memory(none) }

!llvm.module.flags = !{!0, !1, !2, !3}

!0 = !{i32 2, !"Debug Info Version", i32 3}
!1 = !{i32 7, !"openmp", i32 11}
!2 = !{i32 8, !"PIC Level", i32 2}
!3 = !{i32 7, !"PIE Level", i32 2}
!4 = !{!5, !5, i64 0}
!5 = !{!"any data access", !6, i64 0}
!6 = !{!"any access", !7, i64 0}
!7 = !{!"Flang Type TBAA Root"}
!8 = !{!9, !9, i64 0}
!9 = !{!"descriptor member", !6, i64 0}
!10 = !{!11}
!11 = distinct !{!11, !12}
!12 = distinct !{!12, !"LVerDomain"}
!13 = !{!14}
!14 = distinct !{!14, !12}
!15 = distinct !{!15, !16, !17}
!16 = !{!"llvm.loop.isvectorized", i32 1}
!17 = !{!"llvm.loop.unroll.runtime.disable"}
!18 = distinct !{!18, !16}
!19 = !{!20}
!20 = !{i64 2, i64 -1, i64 -1, i1 true}
*** IR Dump After RelLookupTableConverterPass on [module] ***
; ModuleID = 'FIRModule'
source_filename = "FIRModule"
target datalayout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128"
target triple = "x86_64-unknown-linux-gnu"

%struct.ident_t = type { i32, i32, i32, i32, ptr }

@_QFEarr.0 = internal unnamed_addr global ptr null
@_QFEarr.8 = internal unnamed_addr global i1 false
@_QQcl.68815510185ede6107d6524e77abf791 = internal constant [52 x i8] c"/g/g92/rydahl1/flangtests/src/array_descriptors.f90\00"
@_QQcl.28612C69372C612C6531332E36653229 = internal constant [16 x i8] c"(a,i7,a,e13.6e2)"
@_QQcl.54686520726573756C74206F6620286172722831292B61727228 = internal constant [26 x i8] c"The result of (arr(1)+arr("
@_QQcl.2920697320 = internal constant [5 x i8] c") is "
@_QQEnvironmentDefaults = local_unnamed_addr constant ptr null
@0 = private unnamed_addr constant [23 x i8] c";unknown;unknown;0;0;;\00", align 1
@1 = private unnamed_addr constant %struct.ident_t { i32 0, i32 2, i32 0, i32 22, ptr @0 }, align 8
@2 = private unnamed_addr constant %struct.ident_t { i32 0, i32 66, i32 0, i32 22, ptr @0 }, align 8

; Function Attrs: mustprogress nofree nounwind willreturn allockind("alloc,uninitialized") allocsize(0) memory(inaccessiblemem: readwrite)
declare noalias noundef ptr @malloc(i64 noundef) local_unnamed_addr #0

; Function Attrs: mustprogress nounwind willreturn allockind("free") memory(argmem: readwrite, inaccessiblemem: readwrite)
declare void @free(ptr allocptr nocapture noundef) local_unnamed_addr #1

define void @_QQmain() local_unnamed_addr {
entry:
  %structArg = alloca { ptr, ptr }, align 8
  %0 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %1 = alloca i32, align 4
  store i32 1048576, ptr %1, align 4, !tbaa !4
  %2 = tail call dereferenceable_or_null(8388608) ptr @malloc(i64 8388608)
  store ptr %2, ptr @_QFEarr.0, align 8, !tbaa !8
  store i1 true, ptr @_QFEarr.8, align 1
  %omp_global_thread_num = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %1, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %0, ptr %gep_5, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QQmain..omp_par, ptr nonnull %structArg)
  %3 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.68815510185ede6107d6524e77abf791, i32 19)
  %4 = call i1 @_FortranAioOutputAscii(ptr %3, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %5 = load i32, ptr %1, align 4, !tbaa !4
  %6 = call i1 @_FortranAioOutputInteger32(ptr %3, i32 %5)
  %7 = call i1 @_FortranAioOutputAscii(ptr %3, ptr nonnull @_QQcl.2920697320, i64 5)
  %.unpack = load ptr, ptr @_QFEarr.0, align 8, !tbaa !8
  %8 = load double, ptr %.unpack, align 8, !tbaa !4
  %9 = load i32, ptr %1, align 4, !tbaa !4
  %10 = sext i32 %9 to i64
  %11 = add nsw i64 %10, -1
  %12 = getelementptr double, ptr %.unpack, i64 %11
  %13 = load double, ptr %12, align 8, !tbaa !4
  %14 = fadd contract double %8, %13
  %15 = call i1 @_FortranAioOutputReal64(ptr %3, double %14)
  %16 = call i32 @_FortranAioEndIoStatement(ptr %3)
  %.unpack100 = load ptr, ptr @_QFEarr.0, align 8, !tbaa !8
  call void @free(ptr %.unpack100)
  store ptr null, ptr @_QFEarr.0, align 8, !tbaa !8
  store i1 false, ptr @_QFEarr.8, align 1
  ret void
}

; Function Attrs: norecurse nounwind
define internal void @_QQmain..omp_par(ptr noalias nocapture readnone %tid.addr, ptr noalias nocapture readnone %zero.addr, ptr nocapture readonly %0) #2 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %p.lastiter = alloca i32, align 4
  %p.lowerbound = alloca i32, align 4
  %p.upperbound = alloca i32, align 4
  %p.stride = alloca i32, align 4
  %1 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %omp_loop.tripcount = tail call i32 @llvm.smax.i32(i32 %1, i32 0)
  store i32 0, ptr %p.lowerbound, align 4
  %2 = add nsw i32 %omp_loop.tripcount, -1
  store i32 %2, ptr %p.upperbound, align 4
  store i32 1, ptr %p.stride, align 4
  %omp_global_thread_num4 = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  call void @__kmpc_for_static_init_4u(ptr nonnull @1, i32 %omp_global_thread_num4, i32 34, ptr nonnull %p.lastiter, ptr nonnull %p.lowerbound, ptr nonnull %p.upperbound, ptr nonnull %p.stride, i32 1, i32 0)
  %3 = load i32, ptr %p.lowerbound, align 4
  %4 = load i32, ptr %p.upperbound, align 4
  %reass.sub = sub i32 %4, %3
  %omp_loop.cmp32.not = icmp eq i32 %reass.sub, -1
  br i1 %omp_loop.cmp32.not, label %omp_loop.exit, label %omp_loop.body.lr.ph

omp_loop.body.lr.ph:                              ; preds = %omp.par.entry
  %.unpack = load ptr, ptr @_QFEarr.0, align 8, !tbaa !8
  %.unpack9.unpack.unpack11.b = load i1, ptr @_QFEarr.8, align 1
  %.unpack9.unpack.unpack11 = select i1 %.unpack9.unpack.unpack11.b, i64 1048576, i64 0
  %loadgep_2.repack16 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  %loadgep_2.repack20 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  %loadgep_2.repack24 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  %loadgep_2.repack26.repack28 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  %5 = add i32 %4, 1
  %6 = sub i32 %5, %3
  %min.iters.check = icmp ult i32 %6, 4
  br i1 %min.iters.check, label %omp_loop.body.preheader, label %vector.scevcheck

vector.scevcheck:                                 ; preds = %omp_loop.body.lr.ph
  %7 = add i32 %3, 1
  %8 = add i32 %4, 1
  %9 = icmp slt i32 %8, %7
  br i1 %9, label %omp_loop.body.preheader, label %vector.memcheck

vector.memcheck:                                  ; preds = %vector.scevcheck
  %scevgep = getelementptr i8, ptr %loadgep_, i64 4
  %10 = add i32 %3, 1
  %11 = sext i32 %10 to i64
  %12 = shl nsw i64 %11, 3
  %13 = add nsw i64 %12, -8
  %scevgep34 = getelementptr i8, ptr %.unpack, i64 %13
  %14 = zext i32 %reass.sub to i64
  %15 = add nsw i64 %11, %14
  %16 = shl nsw i64 %15, 3
  %scevgep35 = getelementptr i8, ptr %.unpack, i64 %16
  %bound0 = icmp ult ptr %loadgep_, %scevgep35
  %bound1 = icmp ult ptr %scevgep34, %scevgep
  %found.conflict = and i1 %bound0, %bound1
  br i1 %found.conflict, label %omp_loop.body.preheader, label %vector.ph

vector.ph:                                        ; preds = %vector.memcheck
  %n.vec = and i32 %6, -2
  %17 = load i32, ptr %loadgep_, align 4, !tbaa !4, !alias.scope !10, !noalias !13
  %broadcast.splatinsert = insertelement <2 x i32> poison, i32 %17, i64 0
  %18 = sitofp <2 x i32> %broadcast.splatinsert to <2 x float>
  %19 = fdiv contract <2 x float> <float 1.000000e+00, float poison>, %18
  %20 = shufflevector <2 x float> %19, <2 x float> poison, <2 x i32> zeroinitializer
  %21 = fpext <2 x float> %20 to <2 x double>
  br label %vector.body

vector.body:                                      ; preds = %vector.body, %vector.ph
  %index = phi i32 [ 0, %vector.ph ], [ %index.next, %vector.body ]
  %22 = or i32 %index, 1
  %23 = add i32 %22, %3
  %24 = sext i32 %23 to i64
  %25 = add nsw i64 %24, -1
  %26 = getelementptr double, ptr %.unpack, i64 %25
  store <2 x double> %21, ptr %26, align 8, !tbaa !4, !alias.scope !13
  %index.next = add nuw i32 %index, 2
  %27 = icmp eq i32 %index.next, %n.vec
  br i1 %27, label %middle.block, label %vector.body, !llvm.loop !15

middle.block:                                     ; preds = %vector.body
  %cmp.n = icmp eq i32 %6, %n.vec
  br i1 %cmp.n, label %omp_loop.header.omp_loop.exit_crit_edge, label %omp_loop.body.preheader

omp_loop.body.preheader:                          ; preds = %vector.memcheck, %vector.scevcheck, %omp_loop.body.lr.ph, %middle.block
  %omp_loop.iv33.ph = phi i32 [ 0, %vector.memcheck ], [ 0, %vector.scevcheck ], [ 0, %omp_loop.body.lr.ph ], [ %n.vec, %middle.block ]
  br label %omp_loop.body

omp_loop.header.omp_loop.exit_crit_edge:          ; preds = %omp_loop.body, %middle.block
  %loadgep_2.repack14 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  %loadgep_2.repack18 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  %loadgep_2.repack22 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  %loadgep_2.repack26 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  %loadgep_2.repack26.repack30 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  store ptr %.unpack, ptr %loadgep_2, align 8, !tbaa !8
  store i64 8, ptr %loadgep_2.repack14, align 8, !tbaa !8
  store i32 20180515, ptr %loadgep_2.repack16, align 8, !tbaa !8
  store i8 1, ptr %loadgep_2.repack18, align 4, !tbaa !8
  store i8 28, ptr %loadgep_2.repack20, align 1, !tbaa !8
  store i8 2, ptr %loadgep_2.repack22, align 2, !tbaa !8
  store i8 0, ptr %loadgep_2.repack24, align 1, !tbaa !8
  store i64 1, ptr %loadgep_2.repack26, align 8, !tbaa !8
  store i64 %.unpack9.unpack.unpack11, ptr %loadgep_2.repack26.repack28, align 8, !tbaa !8
  store i64 8, ptr %loadgep_2.repack26.repack30, align 8, !tbaa !8
  br label %omp_loop.exit

omp_loop.exit:                                    ; preds = %omp_loop.header.omp_loop.exit_crit_edge, %omp.par.entry
  call void @__kmpc_for_static_fini(ptr nonnull @1, i32 %omp_global_thread_num4)
  call void @__kmpc_barrier(ptr nonnull @2, i32 %omp_global_thread_num4)
  ret void

omp_loop.body:                                    ; preds = %omp_loop.body.preheader, %omp_loop.body
  %omp_loop.iv33 = phi i32 [ %28, %omp_loop.body ], [ %omp_loop.iv33.ph, %omp_loop.body.preheader ]
  %28 = add nuw i32 %omp_loop.iv33, 1
  %29 = add i32 %28, %3
  %30 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %31 = sitofp i32 %30 to float
  %32 = fdiv contract float 1.000000e+00, %31
  %33 = fpext float %32 to double
  %34 = sext i32 %29 to i64
  %35 = add nsw i64 %34, -1
  %36 = getelementptr double, ptr %.unpack, i64 %35
  store double %33, ptr %36, align 8, !tbaa !4
  %exitcond.not = icmp eq i32 %omp_loop.iv33, %reass.sub
  br i1 %exitcond.not, label %omp_loop.header.omp_loop.exit_crit_edge, label %omp_loop.body, !llvm.loop !18
}

declare ptr @_FortranAioBeginExternalFormattedOutput(ptr, i64, ptr, i32, ptr, i32) local_unnamed_addr

declare zeroext i1 @_FortranAioOutputAscii(ptr, ptr, i64) local_unnamed_addr

declare zeroext i1 @_FortranAioOutputInteger32(ptr, i32) local_unnamed_addr

declare zeroext i1 @_FortranAioOutputReal64(ptr, double) local_unnamed_addr

declare i32 @_FortranAioEndIoStatement(ptr) local_unnamed_addr

; Function Attrs: nounwind
declare i32 @__kmpc_global_thread_num(ptr) local_unnamed_addr #3

; Function Attrs: nounwind
declare void @__kmpc_for_static_init_4u(ptr, i32, i32, ptr, ptr, ptr, ptr, i32, i32) local_unnamed_addr #3

; Function Attrs: nounwind
declare void @__kmpc_for_static_fini(ptr, i32) local_unnamed_addr #3

; Function Attrs: convergent nounwind
declare void @__kmpc_barrier(ptr, i32) local_unnamed_addr #4

; Function Attrs: nounwind
declare !callback !19 void @__kmpc_fork_call(ptr, i32, ptr, ...) local_unnamed_addr #3

; Function Attrs: nocallback nofree nosync nounwind speculatable willreturn memory(none)
declare i32 @llvm.smax.i32(i32, i32) #5

attributes #0 = { mustprogress nofree nounwind willreturn allockind("alloc,uninitialized") allocsize(0) memory(inaccessiblemem: readwrite) "alloc-family"="malloc" }
attributes #1 = { mustprogress nounwind willreturn allockind("free") memory(argmem: readwrite, inaccessiblemem: readwrite) "alloc-family"="malloc" }
attributes #2 = { norecurse nounwind }
attributes #3 = { nounwind }
attributes #4 = { convergent nounwind }
attributes #5 = { nocallback nofree nosync nounwind speculatable willreturn memory(none) }

!llvm.module.flags = !{!0, !1, !2, !3}

!0 = !{i32 2, !"Debug Info Version", i32 3}
!1 = !{i32 7, !"openmp", i32 11}
!2 = !{i32 8, !"PIC Level", i32 2}
!3 = !{i32 7, !"PIE Level", i32 2}
!4 = !{!5, !5, i64 0}
!5 = !{!"any data access", !6, i64 0}
!6 = !{!"any access", !7, i64 0}
!7 = !{!"Flang Type TBAA Root"}
!8 = !{!9, !9, i64 0}
!9 = !{!"descriptor member", !6, i64 0}
!10 = !{!11}
!11 = distinct !{!11, !12}
!12 = distinct !{!12, !"LVerDomain"}
!13 = !{!14}
!14 = distinct !{!14, !12}
!15 = distinct !{!15, !16, !17}
!16 = !{!"llvm.loop.isvectorized", i32 1}
!17 = !{!"llvm.loop.unroll.runtime.disable"}
!18 = distinct !{!18, !16}
!19 = !{!20}
!20 = !{i64 2, i64 -1, i64 -1, i1 true}
*** IR Dump After AnnotationRemarksPass on _QQmain ***
define void @_QQmain() local_unnamed_addr {
entry:
  %structArg = alloca { ptr, ptr }, align 8
  %0 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %1 = alloca i32, align 4
  store i32 1048576, ptr %1, align 4, !tbaa !4
  %2 = tail call dereferenceable_or_null(8388608) ptr @malloc(i64 8388608)
  store ptr %2, ptr @_QFEarr.0, align 8, !tbaa !8
  store i1 true, ptr @_QFEarr.8, align 1
  %omp_global_thread_num = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %1, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %0, ptr %gep_5, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QQmain..omp_par, ptr nonnull %structArg)
  %3 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.68815510185ede6107d6524e77abf791, i32 19)
  %4 = call i1 @_FortranAioOutputAscii(ptr %3, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %5 = load i32, ptr %1, align 4, !tbaa !4
  %6 = call i1 @_FortranAioOutputInteger32(ptr %3, i32 %5)
  %7 = call i1 @_FortranAioOutputAscii(ptr %3, ptr nonnull @_QQcl.2920697320, i64 5)
  %.unpack = load ptr, ptr @_QFEarr.0, align 8, !tbaa !8
  %8 = load double, ptr %.unpack, align 8, !tbaa !4
  %9 = load i32, ptr %1, align 4, !tbaa !4
  %10 = sext i32 %9 to i64
  %11 = add nsw i64 %10, -1
  %12 = getelementptr double, ptr %.unpack, i64 %11
  %13 = load double, ptr %12, align 8, !tbaa !4
  %14 = fadd contract double %8, %13
  %15 = call i1 @_FortranAioOutputReal64(ptr %3, double %14)
  %16 = call i32 @_FortranAioEndIoStatement(ptr %3)
  %.unpack100 = load ptr, ptr @_QFEarr.0, align 8, !tbaa !8
  call void @free(ptr %.unpack100)
  store ptr null, ptr @_QFEarr.0, align 8, !tbaa !8
  store i1 false, ptr @_QFEarr.8, align 1
  ret void
}
*** IR Dump After AnnotationRemarksPass on _QQmain..omp_par ***
; Function Attrs: norecurse nounwind
define internal void @_QQmain..omp_par(ptr noalias nocapture readnone %tid.addr, ptr noalias nocapture readnone %zero.addr, ptr nocapture readonly %0) #2 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %p.lastiter = alloca i32, align 4
  %p.lowerbound = alloca i32, align 4
  %p.upperbound = alloca i32, align 4
  %p.stride = alloca i32, align 4
  %1 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %omp_loop.tripcount = tail call i32 @llvm.smax.i32(i32 %1, i32 0)
  store i32 0, ptr %p.lowerbound, align 4
  %2 = add nsw i32 %omp_loop.tripcount, -1
  store i32 %2, ptr %p.upperbound, align 4
  store i32 1, ptr %p.stride, align 4
  %omp_global_thread_num4 = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  call void @__kmpc_for_static_init_4u(ptr nonnull @1, i32 %omp_global_thread_num4, i32 34, ptr nonnull %p.lastiter, ptr nonnull %p.lowerbound, ptr nonnull %p.upperbound, ptr nonnull %p.stride, i32 1, i32 0)
  %3 = load i32, ptr %p.lowerbound, align 4
  %4 = load i32, ptr %p.upperbound, align 4
  %reass.sub = sub i32 %4, %3
  %omp_loop.cmp32.not = icmp eq i32 %reass.sub, -1
  br i1 %omp_loop.cmp32.not, label %omp_loop.exit, label %omp_loop.body.lr.ph

omp_loop.body.lr.ph:                              ; preds = %omp.par.entry
  %.unpack = load ptr, ptr @_QFEarr.0, align 8, !tbaa !8
  %.unpack9.unpack.unpack11.b = load i1, ptr @_QFEarr.8, align 1
  %.unpack9.unpack.unpack11 = select i1 %.unpack9.unpack.unpack11.b, i64 1048576, i64 0
  %loadgep_2.repack16 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  %loadgep_2.repack20 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  %loadgep_2.repack24 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  %loadgep_2.repack26.repack28 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  %5 = add i32 %4, 1
  %6 = sub i32 %5, %3
  %min.iters.check = icmp ult i32 %6, 4
  br i1 %min.iters.check, label %omp_loop.body.preheader, label %vector.scevcheck

vector.scevcheck:                                 ; preds = %omp_loop.body.lr.ph
  %7 = add i32 %3, 1
  %8 = add i32 %4, 1
  %9 = icmp slt i32 %8, %7
  br i1 %9, label %omp_loop.body.preheader, label %vector.memcheck

vector.memcheck:                                  ; preds = %vector.scevcheck
  %scevgep = getelementptr i8, ptr %loadgep_, i64 4
  %10 = add i32 %3, 1
  %11 = sext i32 %10 to i64
  %12 = shl nsw i64 %11, 3
  %13 = add nsw i64 %12, -8
  %scevgep34 = getelementptr i8, ptr %.unpack, i64 %13
  %14 = zext i32 %reass.sub to i64
  %15 = add nsw i64 %11, %14
  %16 = shl nsw i64 %15, 3
  %scevgep35 = getelementptr i8, ptr %.unpack, i64 %16
  %bound0 = icmp ult ptr %loadgep_, %scevgep35
  %bound1 = icmp ult ptr %scevgep34, %scevgep
  %found.conflict = and i1 %bound0, %bound1
  br i1 %found.conflict, label %omp_loop.body.preheader, label %vector.ph

vector.ph:                                        ; preds = %vector.memcheck
  %n.vec = and i32 %6, -2
  %17 = load i32, ptr %loadgep_, align 4, !tbaa !4, !alias.scope !10, !noalias !13
  %broadcast.splatinsert = insertelement <2 x i32> poison, i32 %17, i64 0
  %18 = sitofp <2 x i32> %broadcast.splatinsert to <2 x float>
  %19 = fdiv contract <2 x float> <float 1.000000e+00, float poison>, %18
  %20 = shufflevector <2 x float> %19, <2 x float> poison, <2 x i32> zeroinitializer
  %21 = fpext <2 x float> %20 to <2 x double>
  br label %vector.body

vector.body:                                      ; preds = %vector.body, %vector.ph
  %index = phi i32 [ 0, %vector.ph ], [ %index.next, %vector.body ]
  %22 = or i32 %index, 1
  %23 = add i32 %22, %3
  %24 = sext i32 %23 to i64
  %25 = add nsw i64 %24, -1
  %26 = getelementptr double, ptr %.unpack, i64 %25
  store <2 x double> %21, ptr %26, align 8, !tbaa !4, !alias.scope !13
  %index.next = add nuw i32 %index, 2
  %27 = icmp eq i32 %index.next, %n.vec
  br i1 %27, label %middle.block, label %vector.body, !llvm.loop !15

middle.block:                                     ; preds = %vector.body
  %cmp.n = icmp eq i32 %6, %n.vec
  br i1 %cmp.n, label %omp_loop.header.omp_loop.exit_crit_edge, label %omp_loop.body.preheader

omp_loop.body.preheader:                          ; preds = %vector.memcheck, %vector.scevcheck, %omp_loop.body.lr.ph, %middle.block
  %omp_loop.iv33.ph = phi i32 [ 0, %vector.memcheck ], [ 0, %vector.scevcheck ], [ 0, %omp_loop.body.lr.ph ], [ %n.vec, %middle.block ]
  br label %omp_loop.body

omp_loop.header.omp_loop.exit_crit_edge:          ; preds = %omp_loop.body, %middle.block
  %loadgep_2.repack14 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  %loadgep_2.repack18 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  %loadgep_2.repack22 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  %loadgep_2.repack26 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  %loadgep_2.repack26.repack30 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  store ptr %.unpack, ptr %loadgep_2, align 8, !tbaa !8
  store i64 8, ptr %loadgep_2.repack14, align 8, !tbaa !8
  store i32 20180515, ptr %loadgep_2.repack16, align 8, !tbaa !8
  store i8 1, ptr %loadgep_2.repack18, align 4, !tbaa !8
  store i8 28, ptr %loadgep_2.repack20, align 1, !tbaa !8
  store i8 2, ptr %loadgep_2.repack22, align 2, !tbaa !8
  store i8 0, ptr %loadgep_2.repack24, align 1, !tbaa !8
  store i64 1, ptr %loadgep_2.repack26, align 8, !tbaa !8
  store i64 %.unpack9.unpack.unpack11, ptr %loadgep_2.repack26.repack28, align 8, !tbaa !8
  store i64 8, ptr %loadgep_2.repack26.repack30, align 8, !tbaa !8
  br label %omp_loop.exit

omp_loop.exit:                                    ; preds = %omp_loop.header.omp_loop.exit_crit_edge, %omp.par.entry
  call void @__kmpc_for_static_fini(ptr nonnull @1, i32 %omp_global_thread_num4)
  call void @__kmpc_barrier(ptr nonnull @2, i32 %omp_global_thread_num4)
  ret void

omp_loop.body:                                    ; preds = %omp_loop.body.preheader, %omp_loop.body
  %omp_loop.iv33 = phi i32 [ %28, %omp_loop.body ], [ %omp_loop.iv33.ph, %omp_loop.body.preheader ]
  %28 = add nuw i32 %omp_loop.iv33, 1
  %29 = add i32 %28, %3
  %30 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %31 = sitofp i32 %30 to float
  %32 = fdiv contract float 1.000000e+00, %31
  %33 = fpext float %32 to double
  %34 = sext i32 %29 to i64
  %35 = add nsw i64 %34, -1
  %36 = getelementptr double, ptr %.unpack, i64 %35
  store double %33, ptr %36, align 8, !tbaa !4
  %exitcond.not = icmp eq i32 %omp_loop.iv33, %reass.sub
  br i1 %exitcond.not, label %omp_loop.header.omp_loop.exit_crit_edge, label %omp_loop.body, !llvm.loop !18
}
