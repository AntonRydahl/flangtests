*** IR Dump After Annotation2MetadataPass on [module] ***
; ModuleID = 'FIRModule'
source_filename = "FIRModule"
target datalayout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128"
target triple = "x86_64-unknown-linux-gnu"

%struct.ident_t = type { i32, i32, i32, i32, ptr }

@_QMomp_libEComp_allocator_handle_kind = external constant i32
@_QMomp_libEComp_alloctrait_key_kind = external constant i32
@_QMomp_libEComp_alloctrait_val_kind = external constant i32
@_QMomp_libEComp_allow_completion_event = external constant i32
@_QMomp_libEComp_atk_access = external constant i32
@_QMomp_libEComp_atk_alignment = external constant i32
@_QMomp_libEComp_atk_fallback = external constant i32
@_QMomp_libEComp_atk_fb_data = external constant i32
@_QMomp_libEComp_atk_partition = external constant i32
@_QMomp_libEComp_atk_pinned = external constant i32
@_QMomp_libEComp_atk_pool_size = external constant i32
@_QMomp_libEComp_atk_sync_hint = external constant i32
@_QMomp_libEComp_atv_abort_fb = external constant i32
@_QMomp_libEComp_atv_all = external constant i32
@_QMomp_libEComp_atv_allocator_fb = external constant i32
@_QMomp_libEComp_atv_blocked = external constant i32
@_QMomp_libEComp_atv_cgroup = external constant i32
@_QMomp_libEComp_atv_contended = external constant i32
@_QMomp_libEComp_atv_default = external constant i32
@_QMomp_libEComp_atv_default_mem_fb = external constant i32
@_QMomp_libEComp_atv_environment = external constant i32
@_QMomp_libEComp_atv_false = external constant i32
@_QMomp_libEComp_atv_interleaved = external constant i32
@_QMomp_libEComp_atv_nearest = external constant i32
@_QMomp_libEComp_atv_null_fb = external constant i32
@_QMomp_libEComp_atv_private = external constant i32
@_QMomp_libEComp_atv_pteam = external constant i32
@_QMomp_libEComp_atv_sequential = external constant i32
@_QMomp_libEComp_atv_thread = external constant i32
@_QMomp_libEComp_atv_true = external constant i32
@_QMomp_libEComp_atv_uncontended = external constant i32
@_QMomp_libEComp_cgroup_mem_alloc = external constant i32
@_QMomp_libEComp_const_mem_alloc = external constant i32
@_QMomp_libEComp_const_mem_space = external constant i32
@_QMomp_libEComp_default_mem_alloc = external constant i32
@_QMomp_libEComp_default_mem_space = external constant i32
@_QMomp_libEComp_depend_kind = external constant i32
@_QMomp_libEComp_event_handle_kind = external constant i32
@_QMomp_libEComp_high_bw_mem_alloc = external constant i32
@_QMomp_libEComp_high_bw_mem_space = external constant i32
@_QMomp_libEComp_integer_kind = external constant i32
@_QMomp_libEComp_large_cap_mem_alloc = external constant i32
@_QMomp_libEComp_large_cap_mem_space = external constant i32
@_QMomp_libEComp_lock_hint_contended = external constant i32
@_QMomp_libEComp_lock_hint_kind = external constant i32
@_QMomp_libEComp_lock_hint_none = external constant i32
@_QMomp_libEComp_lock_hint_nonspeculative = external constant i32
@_QMomp_libEComp_lock_hint_speculative = external constant i32
@_QMomp_libEComp_lock_hint_uncontended = external constant i32
@_QMomp_libEComp_lock_kind = external constant i32
@_QMomp_libEComp_logical_kind = external constant i32
@_QMomp_libEComp_low_lat_mem_alloc = external constant i32
@_QMomp_libEComp_low_lat_mem_space = external constant i32
@_QMomp_libEComp_memspace_handle_kind = external constant i32
@_QMomp_libEComp_nest_lock_kind = external constant i32
@_QMomp_libEComp_null_allocator = external constant i32
@_QMomp_libEComp_pause_hard = external constant i32
@_QMomp_libEComp_pause_resource_kind = external constant i32
@_QMomp_libEComp_pause_soft = external constant i32
@_QMomp_libEComp_proc_bind_close = external constant i32
@_QMomp_libEComp_proc_bind_false = external constant i32
@_QMomp_libEComp_proc_bind_kind = external constant i32
@_QMomp_libEComp_proc_bind_master = external constant i32
@_QMomp_libEComp_proc_bind_spread = external constant i32
@_QMomp_libEComp_proc_bind_true = external constant i32
@_QMomp_libEComp_pteam_mem_alloc = external constant i32
@_QMomp_libEComp_sched_auto = external constant i32
@_QMomp_libEComp_sched_dynamic = external constant i32
@_QMomp_libEComp_sched_guided = external constant i32
@_QMomp_libEComp_sched_kind = external constant i32
@_QMomp_libEComp_sched_static = external constant i32
@_QMomp_libEComp_sync_hint_contended = external constant i32
@_QMomp_libEComp_sync_hint_kind = external constant i32
@_QMomp_libEComp_sync_hint_none = external constant i32
@_QMomp_libEComp_sync_hint_nonspeculative = external constant i32
@_QMomp_libEComp_sync_hint_speculative = external constant i32
@_QMomp_libEComp_sync_hint_uncontended = external constant i32
@_QMomp_libEComp_task_fulfill_event = external constant i32
@_QMomp_libEComp_thread_mem_alloc = external constant i32
@_QMomp_libECopenmp_version = external constant i32
@_QQcl.28612C69372C612C6531332E36653229 = internal constant [16 x i8] c"(a,i7,a,e13.6e2)"
@_QQcl.e8a0ac9186c064ac8543d822e9060d96 = internal constant [59 x i8] c"/g/g92/rydahl1/flangtests/src/parallel_region_outlined.f90\00"
@_QQcl.54686520726573756C74206F6620286172722831292B61727228 = internal constant [26 x i8] c"The result of (arr(1)+arr("
@_QQcl.2920697320 = internal constant [5 x i8] c") is "
@_QQEnvironmentDefaults = constant ptr null
@0 = private unnamed_addr constant [23 x i8] c";unknown;unknown;0;0;;\00", align 1
@1 = private unnamed_addr constant %struct.ident_t { i32 0, i32 2, i32 0, i32 22, ptr @0 }, align 8

declare ptr @malloc(i64)

declare void @free(ptr)

define void @_QQmain() {
  %1 = alloca i32, i64 1, align 4
  %2 = alloca double, i64 1, align 8
  %3 = alloca double, i64 1, align 8
  %4 = alloca { ptr, ptr }, i64 1, align 8
  %5 = getelementptr { ptr, ptr }, ptr %4, i32 0, i32 0
  store ptr %1, ptr %5, align 8, !tbaa !4
  %6 = getelementptr { ptr, ptr }, ptr %4, i32 0, i32 1
  store ptr %3, ptr %6, align 8, !tbaa !4
  store i32 1048576, ptr %1, align 4, !tbaa !4
  call void @_QFPomp_subroutine(ptr %1, ptr %2, ptr %4)
  %7 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr @_QQcl.e8a0ac9186c064ac8543d822e9060d96, i32 10)
  %8 = call i1 @_FortranAioOutputAscii(ptr %7, ptr @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %9 = load i32, ptr %1, align 4, !tbaa !4
  %10 = call i1 @_FortranAioOutputInteger32(ptr %7, i32 %9)
  %11 = call i1 @_FortranAioOutputAscii(ptr %7, ptr @_QQcl.2920697320, i64 5)
  %12 = load double, ptr %2, align 8, !tbaa !4
  %13 = call i1 @_FortranAioOutputReal64(ptr %7, double %12)
  %14 = call i32 @_FortranAioEndIoStatement(ptr %7)
  ret void
}

define void @_QFPomp_subroutine(ptr %0, ptr %1, ptr nest %2) {
  %structArg = alloca { ptr, ptr, ptr, ptr, ptr }, align 8
  %4 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %5 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %6 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %7 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %8 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %9 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %10 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, i64 1, align 8
  store { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } { ptr null, i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), i32 20180515, i8 1, i8 28, i8 2, i8 0, [1 x [3 x i64]] [[3 x i64] [i64 1, i64 0, i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64)]] }, ptr %9, align 8, !tbaa !8
  %11 = load { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %9, align 8, !tbaa !8
  store { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %11, ptr %10, align 8, !tbaa !8
  %12 = alloca i32, i64 1, align 4
  %13 = alloca i32, i64 1, align 4
  %14 = alloca i32, i64 1, align 4
  %15 = alloca i32, i64 1, align 4
  %16 = alloca double, i64 1, align 8
  %17 = alloca i32, i64 1, align 4
  %18 = load i32, ptr %0, align 4, !tbaa !4
  %19 = sext i32 %18 to i64
  %20 = icmp sgt i64 %19, 0
  %21 = select i1 %20, i64 %19, i64 0
  %22 = mul i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), %21
  %23 = call ptr @malloc(i64 %22)
  %24 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } { ptr undef, i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), i32 20180515, i8 1, i8 28, i8 2, i8 0, [1 x [3 x i64]] [[3 x i64] [i64 1, i64 undef, i64 undef]] }, i64 %21, 7, 0, 1
  %25 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %24, i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), 7, 0, 2
  %26 = mul i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), %21
  %27 = mul i64 1, %21
  %28 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %25, ptr %23, 0
  store { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %28, ptr %8, align 8, !tbaa !8
  %29 = load { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %8, align 8, !tbaa !8
  store { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %29, ptr %10, align 8, !tbaa !8
  br label %entry

entry:                                            ; preds = %3
  %omp_global_thread_num = call i32 @__kmpc_global_thread_num(ptr @1)
  br label %omp_parallel

omp_parallel:                                     ; preds = %entry
  %gep_ = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i32 0, i32 0
  store ptr %0, ptr %gep_, align 8
  %gep_5 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i32 0, i32 1
  store ptr %10, ptr %gep_5, align 8
  %gep_6 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i32 0, i32 2
  store ptr %7, ptr %gep_6, align 8
  %gep_7 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i32 0, i32 3
  store ptr %6, ptr %gep_7, align 8
  %gep_8 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i32 0, i32 4
  store ptr %2, ptr %gep_8, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr @1, i32 1, ptr @_QFPomp_subroutine..omp_par, ptr %structArg)
  br label %omp.par.outlined.exit

omp.par.outlined.exit:                            ; preds = %omp_parallel
  br label %omp.par.exit.split

omp.par.exit.split:                               ; preds = %omp.par.outlined.exit
  %30 = load { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %10, align 8, !tbaa !8
  store { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %30, ptr %5, align 8, !tbaa !8
  %31 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i32 0, i32 7, i64 0, i32 0
  %32 = load i64, ptr %31, align 8, !tbaa !8
  %33 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i32 0, i32 7, i64 0, i32 1
  %34 = load i64, ptr %33, align 8, !tbaa !8
  %35 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i32 0, i32 7, i64 0, i32 2
  %36 = load i64, ptr %35, align 8, !tbaa !8
  %37 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i32 0, i32 0
  %38 = load ptr, ptr %37, align 8, !tbaa !8
  %39 = sub i64 1, %32
  %40 = getelementptr double, ptr %38, i64 %39
  %41 = load double, ptr %40, align 8, !tbaa !4
  %42 = load i32, ptr %0, align 4, !tbaa !4
  %43 = sext i32 %42 to i64
  %44 = sub i64 %43, %32
  %45 = getelementptr double, ptr %38, i64 %44
  %46 = load double, ptr %45, align 8, !tbaa !4
  %47 = fadd contract double %41, %46
  store double %47, ptr %1, align 8, !tbaa !4
  %48 = load { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %10, align 8, !tbaa !8
  store { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %48, ptr %4, align 8, !tbaa !8
  %49 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %4, i32 0, i32 0
  %50 = load ptr, ptr %49, align 8, !tbaa !8
  call void @free(ptr %50)
  %51 = load { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %9, align 8, !tbaa !8
  store { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %51, ptr %10, align 8, !tbaa !8
  ret void
}

; Function Attrs: norecurse nounwind
define internal void @_QFPomp_subroutine..omp_par(ptr noalias %tid.addr, ptr noalias %zero.addr, ptr %0) #0 {
omp.par.entry:
  %gep_ = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i32 0, i32 0
  %loadgep_ = load ptr, ptr %gep_, align 8
  %gep_1 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i32 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %gep_3 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i32 0, i32 2
  %loadgep_4 = load ptr, ptr %gep_3, align 8
  %gep_5 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i32 0, i32 3
  %loadgep_6 = load ptr, ptr %gep_5, align 8
  %gep_7 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i32 0, i32 4
  %loadgep_8 = load ptr, ptr %gep_7, align 8
  %tid.addr.local = alloca i32, align 4
  %1 = load i32, ptr %tid.addr, align 4
  store i32 %1, ptr %tid.addr.local, align 4
  %tid = load i32, ptr %tid.addr.local, align 4
  br label %omp.par.region

omp.par.region:                                   ; preds = %omp.par.entry
  br label %omp.par.region1

omp.par.region1:                                  ; preds = %omp.par.region
  %2 = alloca i32, i64 1, align 4
  %3 = alloca i32, i64 1, align 4
  %4 = alloca i32, i64 1, align 4
  %5 = alloca i32, i64 1, align 4
  %6 = alloca i32, i64 1, align 4
  %7 = call i32 @omp_get_thread_num()
  store i32 %7, ptr %2, align 4, !tbaa !4
  %8 = call i32 @omp_get_num_threads()
  store i32 %8, ptr %3, align 4, !tbaa !4
  %9 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %10 = load i32, ptr %3, align 4, !tbaa !4
  %11 = sdiv i32 %9, %10
  store i32 %11, ptr %6, align 4, !tbaa !4
  %12 = load i32, ptr %2, align 4, !tbaa !4
  %13 = load i32, ptr %6, align 4, !tbaa !4
  %14 = mul i32 %12, %13
  %15 = add i32 %14, 1
  store i32 %15, ptr %4, align 4, !tbaa !4
  %16 = load i32, ptr %2, align 4, !tbaa !4
  %17 = load i32, ptr %3, align 4, !tbaa !4
  %18 = sub i32 %17, 1
  %19 = icmp eq i32 %16, %18
  br i1 %19, label %omp.par.region2, label %omp.par.region3

omp.par.region3:                                  ; preds = %omp.par.region1
  %20 = load i32, ptr %4, align 4, !tbaa !4
  %21 = load i32, ptr %6, align 4, !tbaa !4
  %22 = add i32 %20, %21
  store i32 %22, ptr %5, align 4, !tbaa !4
  br label %omp.par.region4

omp.par.region4:                                  ; preds = %omp.par.region2, %omp.par.region3
  %23 = load { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, align 8, !tbaa !8
  store { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %23, ptr %loadgep_4, align 8, !tbaa !8
  %24 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i32 0, i32 7, i64 0, i32 0
  %25 = load i64, ptr %24, align 8, !tbaa !8
  %26 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i32 0, i32 7, i64 0, i32 1
  %27 = load i64, ptr %26, align 8, !tbaa !8
  %28 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i32 0, i32 7, i64 0, i32 2
  %29 = load i64, ptr %28, align 8, !tbaa !8
  %30 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i32 0, i32 0
  %31 = load ptr, ptr %30, align 8, !tbaa !8
  %32 = icmp eq i64 %27, 0
  %33 = select i1 %32, i64 1, i64 %25
  %34 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } { ptr undef, i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), i32 20180515, i8 1, i8 28, i8 0, i8 0, [1 x [3 x i64]] undef }, i64 %33, 7, 0, 0
  %35 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %34, i64 %27, 7, 0, 1
  %36 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %35, i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), 7, 0, 2
  %37 = mul i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), %27
  %38 = mul i64 1, %27
  %39 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %36, ptr %31, 0
  store { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %39, ptr %loadgep_6, align 8, !tbaa !8
  call void @_QFPloop(ptr %4, ptr %5, ptr %loadgep_6, ptr %loadgep_8)
  br label %omp.region.cont

omp.region.cont:                                  ; preds = %omp.par.region4
  br label %omp.par.pre_finalize

omp.par.pre_finalize:                             ; preds = %omp.region.cont
  br label %omp.par.outlined.exit.exitStub

omp.par.region2:                                  ; preds = %omp.par.region1
  %40 = load i32, ptr %loadgep_, align 4, !tbaa !4
  store i32 %40, ptr %5, align 4, !tbaa !4
  br label %omp.par.region4

omp.par.outlined.exit.exitStub:                   ; preds = %omp.par.pre_finalize
  ret void
}

define void @_QFPloop(ptr %0, ptr %1, ptr %2, ptr nest %3) {
  %5 = getelementptr { ptr, ptr }, ptr %3, i32 0, i32 0
  %6 = load ptr, ptr %5, align 8, !tbaa !4
  %7 = getelementptr { ptr, ptr }, ptr %3, i32 0, i32 1
  %8 = load ptr, ptr %7, align 8, !tbaa !4
  %9 = alloca i32, i64 1, align 4
  %10 = load i32, ptr %0, align 4, !tbaa !4
  %11 = sext i32 %10 to i64
  %12 = load i32, ptr %1, align 4, !tbaa !4
  %13 = sext i32 %12 to i64
  %14 = trunc i64 %11 to i32
  %15 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %2, i32 0, i32 7, i64 0, i32 0
  %16 = load i64, ptr %15, align 8, !tbaa !8
  %17 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %2, i32 0, i32 7, i64 0, i32 1
  %18 = load i64, ptr %17, align 8, !tbaa !8
  %19 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %2, i32 0, i32 7, i64 0, i32 2
  %20 = load i64, ptr %19, align 8, !tbaa !8
  %21 = icmp eq i64 %20, 8
  br i1 %21, label %22, label %48

22:                                               ; preds = %4
  %23 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %2, i32 0, i32 0
  %24 = load ptr, ptr %23, align 8, !tbaa !8
  %25 = sub i64 %13, %11
  %26 = add i64 %25, 1
  br label %27

27:                                               ; preds = %31, %22
  %28 = phi i32 [ %46, %31 ], [ %14, %22 ]
  %29 = phi i64 [ %47, %31 ], [ %26, %22 ]
  %30 = icmp sgt i64 %29, 0
  br i1 %30, label %31, label %84

31:                                               ; preds = %27
  store i32 %28, ptr %9, align 4, !tbaa !4
  %32 = load i32, ptr %6, align 4, !tbaa !4
  %33 = sitofp i32 %32 to float
  %34 = fdiv contract float 1.000000e+00, %33
  %35 = fpext float %34 to double
  %36 = load i32, ptr %9, align 4, !tbaa !4
  %37 = sext i32 %36 to i64
  %38 = sub i64 %37, 1
  %39 = getelementptr double, ptr %24, i64 %38
  store double %35, ptr %39, align 8, !tbaa !4
  %40 = load i32, ptr %9, align 4, !tbaa !4
  %41 = sext i32 %40 to i64
  %42 = sub i64 %41, 1
  %43 = getelementptr double, ptr %24, i64 %42
  %44 = load double, ptr %43, align 8, !tbaa !4
  store double %44, ptr %8, align 8, !tbaa !4
  %45 = load i32, ptr %9, align 4, !tbaa !4
  %46 = add i32 %45, 1
  %47 = sub i64 %29, 1
  br label %27

48:                                               ; preds = %4
  %49 = sub i64 %13, %11
  %50 = add i64 %49, 1
  br label %51

51:                                               ; preds = %55, %48
  %52 = phi i32 [ %82, %55 ], [ %14, %48 ]
  %53 = phi i64 [ %83, %55 ], [ %50, %48 ]
  %54 = icmp sgt i64 %53, 0
  br i1 %54, label %55, label %84

55:                                               ; preds = %51
  store i32 %52, ptr %9, align 4, !tbaa !4
  %56 = load i32, ptr %6, align 4, !tbaa !4
  %57 = sitofp i32 %56 to float
  %58 = fdiv contract float 1.000000e+00, %57
  %59 = fpext float %58 to double
  %60 = load i32, ptr %9, align 4, !tbaa !4
  %61 = sext i32 %60 to i64
  %62 = sub i64 %61, 1
  %63 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %2, i32 0, i32 0
  %64 = load ptr, ptr %63, align 8, !tbaa !8
  %65 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %2, i32 0, i32 7, i32 0, i32 2
  %66 = load i64, ptr %65, align 8, !tbaa !8
  %67 = mul i64 %62, %66
  %68 = add i64 %67, 0
  %69 = getelementptr i8, ptr %64, i64 %68
  store double %59, ptr %69, align 8, !tbaa !4
  %70 = load i32, ptr %9, align 4, !tbaa !4
  %71 = sext i32 %70 to i64
  %72 = sub i64 %71, 1
  %73 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %2, i32 0, i32 0
  %74 = load ptr, ptr %73, align 8, !tbaa !8
  %75 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %2, i32 0, i32 7, i32 0, i32 2
  %76 = load i64, ptr %75, align 8, !tbaa !8
  %77 = mul i64 %72, %76
  %78 = add i64 %77, 0
  %79 = getelementptr i8, ptr %74, i64 %78
  %80 = load double, ptr %79, align 8, !tbaa !4
  store double %80, ptr %8, align 8, !tbaa !4
  %81 = load i32, ptr %9, align 4, !tbaa !4
  %82 = add i32 %81, 1
  %83 = sub i64 %53, 1
  br label %51

84:                                               ; preds = %27, %51
  %85 = phi i32 [ %52, %51 ], [ %28, %27 ]
  store i32 %85, ptr %9, align 4, !tbaa !4
  ret void
}

declare ptr @_FortranAioBeginExternalFormattedOutput(ptr, i64, ptr, i32, ptr, i32)

declare zeroext i1 @_FortranAioOutputAscii(ptr, ptr, i64)

declare zeroext i1 @_FortranAioOutputInteger32(ptr, i32)

declare zeroext i1 @_FortranAioOutputReal64(ptr, double)

declare i32 @_FortranAioEndIoStatement(ptr)

declare i32 @omp_get_thread_num()

declare i32 @omp_get_num_threads()

; Function Attrs: nocallback nofree nosync nounwind willreturn
declare ptr @llvm.stacksave() #1

; Function Attrs: nocallback nofree nosync nounwind willreturn
declare void @llvm.stackrestore(ptr) #1

; Function Attrs: nounwind
declare i32 @__kmpc_global_thread_num(ptr) #2

; Function Attrs: nounwind
declare !callback !10 void @__kmpc_fork_call(ptr, i32, ptr, ...) #2

attributes #0 = { norecurse nounwind }
attributes #1 = { nocallback nofree nosync nounwind willreturn }
attributes #2 = { nounwind }

!llvm.module.flags = !{!0, !1, !2, !3}

!0 = !{i32 2, !"Debug Info Version", i32 3}
!1 = !{i32 7, !"openmp", i32 11}
!2 = !{i32 8, !"PIC Level", i32 2}
!3 = !{i32 7, !"PIE Level", i32 2}
!4 = !{!5, !5, i64 0}
!5 = !{!"any data access", !6, i64 0}
!6 = !{!"any access", !7, i64 0}
!7 = !{!"Flang Type TBAA Root"}
!8 = !{!9, !9, i64 0}
!9 = !{!"descriptor member", !6, i64 0}
!10 = !{!11}
!11 = !{i64 2, i64 -1, i64 -1, i1 true}
*** IR Dump After ForceFunctionAttrsPass on [module] ***
; ModuleID = 'FIRModule'
source_filename = "FIRModule"
target datalayout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128"
target triple = "x86_64-unknown-linux-gnu"

%struct.ident_t = type { i32, i32, i32, i32, ptr }

@_QMomp_libEComp_allocator_handle_kind = external constant i32
@_QMomp_libEComp_alloctrait_key_kind = external constant i32
@_QMomp_libEComp_alloctrait_val_kind = external constant i32
@_QMomp_libEComp_allow_completion_event = external constant i32
@_QMomp_libEComp_atk_access = external constant i32
@_QMomp_libEComp_atk_alignment = external constant i32
@_QMomp_libEComp_atk_fallback = external constant i32
@_QMomp_libEComp_atk_fb_data = external constant i32
@_QMomp_libEComp_atk_partition = external constant i32
@_QMomp_libEComp_atk_pinned = external constant i32
@_QMomp_libEComp_atk_pool_size = external constant i32
@_QMomp_libEComp_atk_sync_hint = external constant i32
@_QMomp_libEComp_atv_abort_fb = external constant i32
@_QMomp_libEComp_atv_all = external constant i32
@_QMomp_libEComp_atv_allocator_fb = external constant i32
@_QMomp_libEComp_atv_blocked = external constant i32
@_QMomp_libEComp_atv_cgroup = external constant i32
@_QMomp_libEComp_atv_contended = external constant i32
@_QMomp_libEComp_atv_default = external constant i32
@_QMomp_libEComp_atv_default_mem_fb = external constant i32
@_QMomp_libEComp_atv_environment = external constant i32
@_QMomp_libEComp_atv_false = external constant i32
@_QMomp_libEComp_atv_interleaved = external constant i32
@_QMomp_libEComp_atv_nearest = external constant i32
@_QMomp_libEComp_atv_null_fb = external constant i32
@_QMomp_libEComp_atv_private = external constant i32
@_QMomp_libEComp_atv_pteam = external constant i32
@_QMomp_libEComp_atv_sequential = external constant i32
@_QMomp_libEComp_atv_thread = external constant i32
@_QMomp_libEComp_atv_true = external constant i32
@_QMomp_libEComp_atv_uncontended = external constant i32
@_QMomp_libEComp_cgroup_mem_alloc = external constant i32
@_QMomp_libEComp_const_mem_alloc = external constant i32
@_QMomp_libEComp_const_mem_space = external constant i32
@_QMomp_libEComp_default_mem_alloc = external constant i32
@_QMomp_libEComp_default_mem_space = external constant i32
@_QMomp_libEComp_depend_kind = external constant i32
@_QMomp_libEComp_event_handle_kind = external constant i32
@_QMomp_libEComp_high_bw_mem_alloc = external constant i32
@_QMomp_libEComp_high_bw_mem_space = external constant i32
@_QMomp_libEComp_integer_kind = external constant i32
@_QMomp_libEComp_large_cap_mem_alloc = external constant i32
@_QMomp_libEComp_large_cap_mem_space = external constant i32
@_QMomp_libEComp_lock_hint_contended = external constant i32
@_QMomp_libEComp_lock_hint_kind = external constant i32
@_QMomp_libEComp_lock_hint_none = external constant i32
@_QMomp_libEComp_lock_hint_nonspeculative = external constant i32
@_QMomp_libEComp_lock_hint_speculative = external constant i32
@_QMomp_libEComp_lock_hint_uncontended = external constant i32
@_QMomp_libEComp_lock_kind = external constant i32
@_QMomp_libEComp_logical_kind = external constant i32
@_QMomp_libEComp_low_lat_mem_alloc = external constant i32
@_QMomp_libEComp_low_lat_mem_space = external constant i32
@_QMomp_libEComp_memspace_handle_kind = external constant i32
@_QMomp_libEComp_nest_lock_kind = external constant i32
@_QMomp_libEComp_null_allocator = external constant i32
@_QMomp_libEComp_pause_hard = external constant i32
@_QMomp_libEComp_pause_resource_kind = external constant i32
@_QMomp_libEComp_pause_soft = external constant i32
@_QMomp_libEComp_proc_bind_close = external constant i32
@_QMomp_libEComp_proc_bind_false = external constant i32
@_QMomp_libEComp_proc_bind_kind = external constant i32
@_QMomp_libEComp_proc_bind_master = external constant i32
@_QMomp_libEComp_proc_bind_spread = external constant i32
@_QMomp_libEComp_proc_bind_true = external constant i32
@_QMomp_libEComp_pteam_mem_alloc = external constant i32
@_QMomp_libEComp_sched_auto = external constant i32
@_QMomp_libEComp_sched_dynamic = external constant i32
@_QMomp_libEComp_sched_guided = external constant i32
@_QMomp_libEComp_sched_kind = external constant i32
@_QMomp_libEComp_sched_static = external constant i32
@_QMomp_libEComp_sync_hint_contended = external constant i32
@_QMomp_libEComp_sync_hint_kind = external constant i32
@_QMomp_libEComp_sync_hint_none = external constant i32
@_QMomp_libEComp_sync_hint_nonspeculative = external constant i32
@_QMomp_libEComp_sync_hint_speculative = external constant i32
@_QMomp_libEComp_sync_hint_uncontended = external constant i32
@_QMomp_libEComp_task_fulfill_event = external constant i32
@_QMomp_libEComp_thread_mem_alloc = external constant i32
@_QMomp_libECopenmp_version = external constant i32
@_QQcl.28612C69372C612C6531332E36653229 = internal constant [16 x i8] c"(a,i7,a,e13.6e2)"
@_QQcl.e8a0ac9186c064ac8543d822e9060d96 = internal constant [59 x i8] c"/g/g92/rydahl1/flangtests/src/parallel_region_outlined.f90\00"
@_QQcl.54686520726573756C74206F6620286172722831292B61727228 = internal constant [26 x i8] c"The result of (arr(1)+arr("
@_QQcl.2920697320 = internal constant [5 x i8] c") is "
@_QQEnvironmentDefaults = constant ptr null
@0 = private unnamed_addr constant [23 x i8] c";unknown;unknown;0;0;;\00", align 1
@1 = private unnamed_addr constant %struct.ident_t { i32 0, i32 2, i32 0, i32 22, ptr @0 }, align 8

declare ptr @malloc(i64)

declare void @free(ptr)

define void @_QQmain() {
  %1 = alloca i32, i64 1, align 4
  %2 = alloca double, i64 1, align 8
  %3 = alloca double, i64 1, align 8
  %4 = alloca { ptr, ptr }, i64 1, align 8
  %5 = getelementptr { ptr, ptr }, ptr %4, i32 0, i32 0
  store ptr %1, ptr %5, align 8, !tbaa !4
  %6 = getelementptr { ptr, ptr }, ptr %4, i32 0, i32 1
  store ptr %3, ptr %6, align 8, !tbaa !4
  store i32 1048576, ptr %1, align 4, !tbaa !4
  call void @_QFPomp_subroutine(ptr %1, ptr %2, ptr %4)
  %7 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr @_QQcl.e8a0ac9186c064ac8543d822e9060d96, i32 10)
  %8 = call i1 @_FortranAioOutputAscii(ptr %7, ptr @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %9 = load i32, ptr %1, align 4, !tbaa !4
  %10 = call i1 @_FortranAioOutputInteger32(ptr %7, i32 %9)
  %11 = call i1 @_FortranAioOutputAscii(ptr %7, ptr @_QQcl.2920697320, i64 5)
  %12 = load double, ptr %2, align 8, !tbaa !4
  %13 = call i1 @_FortranAioOutputReal64(ptr %7, double %12)
  %14 = call i32 @_FortranAioEndIoStatement(ptr %7)
  ret void
}

define void @_QFPomp_subroutine(ptr %0, ptr %1, ptr nest %2) {
  %structArg = alloca { ptr, ptr, ptr, ptr, ptr }, align 8
  %4 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %5 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %6 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %7 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %8 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %9 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %10 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, i64 1, align 8
  store { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } { ptr null, i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), i32 20180515, i8 1, i8 28, i8 2, i8 0, [1 x [3 x i64]] [[3 x i64] [i64 1, i64 0, i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64)]] }, ptr %9, align 8, !tbaa !8
  %11 = load { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %9, align 8, !tbaa !8
  store { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %11, ptr %10, align 8, !tbaa !8
  %12 = alloca i32, i64 1, align 4
  %13 = alloca i32, i64 1, align 4
  %14 = alloca i32, i64 1, align 4
  %15 = alloca i32, i64 1, align 4
  %16 = alloca double, i64 1, align 8
  %17 = alloca i32, i64 1, align 4
  %18 = load i32, ptr %0, align 4, !tbaa !4
  %19 = sext i32 %18 to i64
  %20 = icmp sgt i64 %19, 0
  %21 = select i1 %20, i64 %19, i64 0
  %22 = mul i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), %21
  %23 = call ptr @malloc(i64 %22)
  %24 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } { ptr undef, i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), i32 20180515, i8 1, i8 28, i8 2, i8 0, [1 x [3 x i64]] [[3 x i64] [i64 1, i64 undef, i64 undef]] }, i64 %21, 7, 0, 1
  %25 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %24, i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), 7, 0, 2
  %26 = mul i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), %21
  %27 = mul i64 1, %21
  %28 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %25, ptr %23, 0
  store { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %28, ptr %8, align 8, !tbaa !8
  %29 = load { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %8, align 8, !tbaa !8
  store { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %29, ptr %10, align 8, !tbaa !8
  br label %entry

entry:                                            ; preds = %3
  %omp_global_thread_num = call i32 @__kmpc_global_thread_num(ptr @1)
  br label %omp_parallel

omp_parallel:                                     ; preds = %entry
  %gep_ = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i32 0, i32 0
  store ptr %0, ptr %gep_, align 8
  %gep_5 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i32 0, i32 1
  store ptr %10, ptr %gep_5, align 8
  %gep_6 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i32 0, i32 2
  store ptr %7, ptr %gep_6, align 8
  %gep_7 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i32 0, i32 3
  store ptr %6, ptr %gep_7, align 8
  %gep_8 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i32 0, i32 4
  store ptr %2, ptr %gep_8, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr @1, i32 1, ptr @_QFPomp_subroutine..omp_par, ptr %structArg)
  br label %omp.par.outlined.exit

omp.par.outlined.exit:                            ; preds = %omp_parallel
  br label %omp.par.exit.split

omp.par.exit.split:                               ; preds = %omp.par.outlined.exit
  %30 = load { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %10, align 8, !tbaa !8
  store { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %30, ptr %5, align 8, !tbaa !8
  %31 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i32 0, i32 7, i64 0, i32 0
  %32 = load i64, ptr %31, align 8, !tbaa !8
  %33 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i32 0, i32 7, i64 0, i32 1
  %34 = load i64, ptr %33, align 8, !tbaa !8
  %35 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i32 0, i32 7, i64 0, i32 2
  %36 = load i64, ptr %35, align 8, !tbaa !8
  %37 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i32 0, i32 0
  %38 = load ptr, ptr %37, align 8, !tbaa !8
  %39 = sub i64 1, %32
  %40 = getelementptr double, ptr %38, i64 %39
  %41 = load double, ptr %40, align 8, !tbaa !4
  %42 = load i32, ptr %0, align 4, !tbaa !4
  %43 = sext i32 %42 to i64
  %44 = sub i64 %43, %32
  %45 = getelementptr double, ptr %38, i64 %44
  %46 = load double, ptr %45, align 8, !tbaa !4
  %47 = fadd contract double %41, %46
  store double %47, ptr %1, align 8, !tbaa !4
  %48 = load { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %10, align 8, !tbaa !8
  store { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %48, ptr %4, align 8, !tbaa !8
  %49 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %4, i32 0, i32 0
  %50 = load ptr, ptr %49, align 8, !tbaa !8
  call void @free(ptr %50)
  %51 = load { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %9, align 8, !tbaa !8
  store { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %51, ptr %10, align 8, !tbaa !8
  ret void
}

; Function Attrs: norecurse nounwind
define internal void @_QFPomp_subroutine..omp_par(ptr noalias %tid.addr, ptr noalias %zero.addr, ptr %0) #0 {
omp.par.entry:
  %gep_ = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i32 0, i32 0
  %loadgep_ = load ptr, ptr %gep_, align 8
  %gep_1 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i32 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %gep_3 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i32 0, i32 2
  %loadgep_4 = load ptr, ptr %gep_3, align 8
  %gep_5 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i32 0, i32 3
  %loadgep_6 = load ptr, ptr %gep_5, align 8
  %gep_7 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i32 0, i32 4
  %loadgep_8 = load ptr, ptr %gep_7, align 8
  %tid.addr.local = alloca i32, align 4
  %1 = load i32, ptr %tid.addr, align 4
  store i32 %1, ptr %tid.addr.local, align 4
  %tid = load i32, ptr %tid.addr.local, align 4
  br label %omp.par.region

omp.par.region:                                   ; preds = %omp.par.entry
  br label %omp.par.region1

omp.par.region1:                                  ; preds = %omp.par.region
  %2 = alloca i32, i64 1, align 4
  %3 = alloca i32, i64 1, align 4
  %4 = alloca i32, i64 1, align 4
  %5 = alloca i32, i64 1, align 4
  %6 = alloca i32, i64 1, align 4
  %7 = call i32 @omp_get_thread_num()
  store i32 %7, ptr %2, align 4, !tbaa !4
  %8 = call i32 @omp_get_num_threads()
  store i32 %8, ptr %3, align 4, !tbaa !4
  %9 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %10 = load i32, ptr %3, align 4, !tbaa !4
  %11 = sdiv i32 %9, %10
  store i32 %11, ptr %6, align 4, !tbaa !4
  %12 = load i32, ptr %2, align 4, !tbaa !4
  %13 = load i32, ptr %6, align 4, !tbaa !4
  %14 = mul i32 %12, %13
  %15 = add i32 %14, 1
  store i32 %15, ptr %4, align 4, !tbaa !4
  %16 = load i32, ptr %2, align 4, !tbaa !4
  %17 = load i32, ptr %3, align 4, !tbaa !4
  %18 = sub i32 %17, 1
  %19 = icmp eq i32 %16, %18
  br i1 %19, label %omp.par.region2, label %omp.par.region3

omp.par.region3:                                  ; preds = %omp.par.region1
  %20 = load i32, ptr %4, align 4, !tbaa !4
  %21 = load i32, ptr %6, align 4, !tbaa !4
  %22 = add i32 %20, %21
  store i32 %22, ptr %5, align 4, !tbaa !4
  br label %omp.par.region4

omp.par.region4:                                  ; preds = %omp.par.region2, %omp.par.region3
  %23 = load { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, align 8, !tbaa !8
  store { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %23, ptr %loadgep_4, align 8, !tbaa !8
  %24 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i32 0, i32 7, i64 0, i32 0
  %25 = load i64, ptr %24, align 8, !tbaa !8
  %26 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i32 0, i32 7, i64 0, i32 1
  %27 = load i64, ptr %26, align 8, !tbaa !8
  %28 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i32 0, i32 7, i64 0, i32 2
  %29 = load i64, ptr %28, align 8, !tbaa !8
  %30 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i32 0, i32 0
  %31 = load ptr, ptr %30, align 8, !tbaa !8
  %32 = icmp eq i64 %27, 0
  %33 = select i1 %32, i64 1, i64 %25
  %34 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } { ptr undef, i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), i32 20180515, i8 1, i8 28, i8 0, i8 0, [1 x [3 x i64]] undef }, i64 %33, 7, 0, 0
  %35 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %34, i64 %27, 7, 0, 1
  %36 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %35, i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), 7, 0, 2
  %37 = mul i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), %27
  %38 = mul i64 1, %27
  %39 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %36, ptr %31, 0
  store { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %39, ptr %loadgep_6, align 8, !tbaa !8
  call void @_QFPloop(ptr %4, ptr %5, ptr %loadgep_6, ptr %loadgep_8)
  br label %omp.region.cont

omp.region.cont:                                  ; preds = %omp.par.region4
  br label %omp.par.pre_finalize

omp.par.pre_finalize:                             ; preds = %omp.region.cont
  br label %omp.par.outlined.exit.exitStub

omp.par.region2:                                  ; preds = %omp.par.region1
  %40 = load i32, ptr %loadgep_, align 4, !tbaa !4
  store i32 %40, ptr %5, align 4, !tbaa !4
  br label %omp.par.region4

omp.par.outlined.exit.exitStub:                   ; preds = %omp.par.pre_finalize
  ret void
}

define void @_QFPloop(ptr %0, ptr %1, ptr %2, ptr nest %3) {
  %5 = getelementptr { ptr, ptr }, ptr %3, i32 0, i32 0
  %6 = load ptr, ptr %5, align 8, !tbaa !4
  %7 = getelementptr { ptr, ptr }, ptr %3, i32 0, i32 1
  %8 = load ptr, ptr %7, align 8, !tbaa !4
  %9 = alloca i32, i64 1, align 4
  %10 = load i32, ptr %0, align 4, !tbaa !4
  %11 = sext i32 %10 to i64
  %12 = load i32, ptr %1, align 4, !tbaa !4
  %13 = sext i32 %12 to i64
  %14 = trunc i64 %11 to i32
  %15 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %2, i32 0, i32 7, i64 0, i32 0
  %16 = load i64, ptr %15, align 8, !tbaa !8
  %17 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %2, i32 0, i32 7, i64 0, i32 1
  %18 = load i64, ptr %17, align 8, !tbaa !8
  %19 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %2, i32 0, i32 7, i64 0, i32 2
  %20 = load i64, ptr %19, align 8, !tbaa !8
  %21 = icmp eq i64 %20, 8
  br i1 %21, label %22, label %48

22:                                               ; preds = %4
  %23 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %2, i32 0, i32 0
  %24 = load ptr, ptr %23, align 8, !tbaa !8
  %25 = sub i64 %13, %11
  %26 = add i64 %25, 1
  br label %27

27:                                               ; preds = %31, %22
  %28 = phi i32 [ %46, %31 ], [ %14, %22 ]
  %29 = phi i64 [ %47, %31 ], [ %26, %22 ]
  %30 = icmp sgt i64 %29, 0
  br i1 %30, label %31, label %84

31:                                               ; preds = %27
  store i32 %28, ptr %9, align 4, !tbaa !4
  %32 = load i32, ptr %6, align 4, !tbaa !4
  %33 = sitofp i32 %32 to float
  %34 = fdiv contract float 1.000000e+00, %33
  %35 = fpext float %34 to double
  %36 = load i32, ptr %9, align 4, !tbaa !4
  %37 = sext i32 %36 to i64
  %38 = sub i64 %37, 1
  %39 = getelementptr double, ptr %24, i64 %38
  store double %35, ptr %39, align 8, !tbaa !4
  %40 = load i32, ptr %9, align 4, !tbaa !4
  %41 = sext i32 %40 to i64
  %42 = sub i64 %41, 1
  %43 = getelementptr double, ptr %24, i64 %42
  %44 = load double, ptr %43, align 8, !tbaa !4
  store double %44, ptr %8, align 8, !tbaa !4
  %45 = load i32, ptr %9, align 4, !tbaa !4
  %46 = add i32 %45, 1
  %47 = sub i64 %29, 1
  br label %27

48:                                               ; preds = %4
  %49 = sub i64 %13, %11
  %50 = add i64 %49, 1
  br label %51

51:                                               ; preds = %55, %48
  %52 = phi i32 [ %82, %55 ], [ %14, %48 ]
  %53 = phi i64 [ %83, %55 ], [ %50, %48 ]
  %54 = icmp sgt i64 %53, 0
  br i1 %54, label %55, label %84

55:                                               ; preds = %51
  store i32 %52, ptr %9, align 4, !tbaa !4
  %56 = load i32, ptr %6, align 4, !tbaa !4
  %57 = sitofp i32 %56 to float
  %58 = fdiv contract float 1.000000e+00, %57
  %59 = fpext float %58 to double
  %60 = load i32, ptr %9, align 4, !tbaa !4
  %61 = sext i32 %60 to i64
  %62 = sub i64 %61, 1
  %63 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %2, i32 0, i32 0
  %64 = load ptr, ptr %63, align 8, !tbaa !8
  %65 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %2, i32 0, i32 7, i32 0, i32 2
  %66 = load i64, ptr %65, align 8, !tbaa !8
  %67 = mul i64 %62, %66
  %68 = add i64 %67, 0
  %69 = getelementptr i8, ptr %64, i64 %68
  store double %59, ptr %69, align 8, !tbaa !4
  %70 = load i32, ptr %9, align 4, !tbaa !4
  %71 = sext i32 %70 to i64
  %72 = sub i64 %71, 1
  %73 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %2, i32 0, i32 0
  %74 = load ptr, ptr %73, align 8, !tbaa !8
  %75 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %2, i32 0, i32 7, i32 0, i32 2
  %76 = load i64, ptr %75, align 8, !tbaa !8
  %77 = mul i64 %72, %76
  %78 = add i64 %77, 0
  %79 = getelementptr i8, ptr %74, i64 %78
  %80 = load double, ptr %79, align 8, !tbaa !4
  store double %80, ptr %8, align 8, !tbaa !4
  %81 = load i32, ptr %9, align 4, !tbaa !4
  %82 = add i32 %81, 1
  %83 = sub i64 %53, 1
  br label %51

84:                                               ; preds = %27, %51
  %85 = phi i32 [ %52, %51 ], [ %28, %27 ]
  store i32 %85, ptr %9, align 4, !tbaa !4
  ret void
}

declare ptr @_FortranAioBeginExternalFormattedOutput(ptr, i64, ptr, i32, ptr, i32)

declare zeroext i1 @_FortranAioOutputAscii(ptr, ptr, i64)

declare zeroext i1 @_FortranAioOutputInteger32(ptr, i32)

declare zeroext i1 @_FortranAioOutputReal64(ptr, double)

declare i32 @_FortranAioEndIoStatement(ptr)

declare i32 @omp_get_thread_num()

declare i32 @omp_get_num_threads()

; Function Attrs: nocallback nofree nosync nounwind willreturn
declare ptr @llvm.stacksave() #1

; Function Attrs: nocallback nofree nosync nounwind willreturn
declare void @llvm.stackrestore(ptr) #1

; Function Attrs: nounwind
declare i32 @__kmpc_global_thread_num(ptr) #2

; Function Attrs: nounwind
declare !callback !10 void @__kmpc_fork_call(ptr, i32, ptr, ...) #2

attributes #0 = { norecurse nounwind }
attributes #1 = { nocallback nofree nosync nounwind willreturn }
attributes #2 = { nounwind }

!llvm.module.flags = !{!0, !1, !2, !3}

!0 = !{i32 2, !"Debug Info Version", i32 3}
!1 = !{i32 7, !"openmp", i32 11}
!2 = !{i32 8, !"PIC Level", i32 2}
!3 = !{i32 7, !"PIE Level", i32 2}
!4 = !{!5, !5, i64 0}
!5 = !{!"any data access", !6, i64 0}
!6 = !{!"any access", !7, i64 0}
!7 = !{!"Flang Type TBAA Root"}
!8 = !{!9, !9, i64 0}
!9 = !{!"descriptor member", !6, i64 0}
!10 = !{!11}
!11 = !{i64 2, i64 -1, i64 -1, i1 true}
*** IR Dump After InferFunctionAttrsPass on [module] ***
; ModuleID = 'FIRModule'
source_filename = "FIRModule"
target datalayout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128"
target triple = "x86_64-unknown-linux-gnu"

%struct.ident_t = type { i32, i32, i32, i32, ptr }

@_QMomp_libEComp_allocator_handle_kind = external constant i32
@_QMomp_libEComp_alloctrait_key_kind = external constant i32
@_QMomp_libEComp_alloctrait_val_kind = external constant i32
@_QMomp_libEComp_allow_completion_event = external constant i32
@_QMomp_libEComp_atk_access = external constant i32
@_QMomp_libEComp_atk_alignment = external constant i32
@_QMomp_libEComp_atk_fallback = external constant i32
@_QMomp_libEComp_atk_fb_data = external constant i32
@_QMomp_libEComp_atk_partition = external constant i32
@_QMomp_libEComp_atk_pinned = external constant i32
@_QMomp_libEComp_atk_pool_size = external constant i32
@_QMomp_libEComp_atk_sync_hint = external constant i32
@_QMomp_libEComp_atv_abort_fb = external constant i32
@_QMomp_libEComp_atv_all = external constant i32
@_QMomp_libEComp_atv_allocator_fb = external constant i32
@_QMomp_libEComp_atv_blocked = external constant i32
@_QMomp_libEComp_atv_cgroup = external constant i32
@_QMomp_libEComp_atv_contended = external constant i32
@_QMomp_libEComp_atv_default = external constant i32
@_QMomp_libEComp_atv_default_mem_fb = external constant i32
@_QMomp_libEComp_atv_environment = external constant i32
@_QMomp_libEComp_atv_false = external constant i32
@_QMomp_libEComp_atv_interleaved = external constant i32
@_QMomp_libEComp_atv_nearest = external constant i32
@_QMomp_libEComp_atv_null_fb = external constant i32
@_QMomp_libEComp_atv_private = external constant i32
@_QMomp_libEComp_atv_pteam = external constant i32
@_QMomp_libEComp_atv_sequential = external constant i32
@_QMomp_libEComp_atv_thread = external constant i32
@_QMomp_libEComp_atv_true = external constant i32
@_QMomp_libEComp_atv_uncontended = external constant i32
@_QMomp_libEComp_cgroup_mem_alloc = external constant i32
@_QMomp_libEComp_const_mem_alloc = external constant i32
@_QMomp_libEComp_const_mem_space = external constant i32
@_QMomp_libEComp_default_mem_alloc = external constant i32
@_QMomp_libEComp_default_mem_space = external constant i32
@_QMomp_libEComp_depend_kind = external constant i32
@_QMomp_libEComp_event_handle_kind = external constant i32
@_QMomp_libEComp_high_bw_mem_alloc = external constant i32
@_QMomp_libEComp_high_bw_mem_space = external constant i32
@_QMomp_libEComp_integer_kind = external constant i32
@_QMomp_libEComp_large_cap_mem_alloc = external constant i32
@_QMomp_libEComp_large_cap_mem_space = external constant i32
@_QMomp_libEComp_lock_hint_contended = external constant i32
@_QMomp_libEComp_lock_hint_kind = external constant i32
@_QMomp_libEComp_lock_hint_none = external constant i32
@_QMomp_libEComp_lock_hint_nonspeculative = external constant i32
@_QMomp_libEComp_lock_hint_speculative = external constant i32
@_QMomp_libEComp_lock_hint_uncontended = external constant i32
@_QMomp_libEComp_lock_kind = external constant i32
@_QMomp_libEComp_logical_kind = external constant i32
@_QMomp_libEComp_low_lat_mem_alloc = external constant i32
@_QMomp_libEComp_low_lat_mem_space = external constant i32
@_QMomp_libEComp_memspace_handle_kind = external constant i32
@_QMomp_libEComp_nest_lock_kind = external constant i32
@_QMomp_libEComp_null_allocator = external constant i32
@_QMomp_libEComp_pause_hard = external constant i32
@_QMomp_libEComp_pause_resource_kind = external constant i32
@_QMomp_libEComp_pause_soft = external constant i32
@_QMomp_libEComp_proc_bind_close = external constant i32
@_QMomp_libEComp_proc_bind_false = external constant i32
@_QMomp_libEComp_proc_bind_kind = external constant i32
@_QMomp_libEComp_proc_bind_master = external constant i32
@_QMomp_libEComp_proc_bind_spread = external constant i32
@_QMomp_libEComp_proc_bind_true = external constant i32
@_QMomp_libEComp_pteam_mem_alloc = external constant i32
@_QMomp_libEComp_sched_auto = external constant i32
@_QMomp_libEComp_sched_dynamic = external constant i32
@_QMomp_libEComp_sched_guided = external constant i32
@_QMomp_libEComp_sched_kind = external constant i32
@_QMomp_libEComp_sched_static = external constant i32
@_QMomp_libEComp_sync_hint_contended = external constant i32
@_QMomp_libEComp_sync_hint_kind = external constant i32
@_QMomp_libEComp_sync_hint_none = external constant i32
@_QMomp_libEComp_sync_hint_nonspeculative = external constant i32
@_QMomp_libEComp_sync_hint_speculative = external constant i32
@_QMomp_libEComp_sync_hint_uncontended = external constant i32
@_QMomp_libEComp_task_fulfill_event = external constant i32
@_QMomp_libEComp_thread_mem_alloc = external constant i32
@_QMomp_libECopenmp_version = external constant i32
@_QQcl.28612C69372C612C6531332E36653229 = internal constant [16 x i8] c"(a,i7,a,e13.6e2)"
@_QQcl.e8a0ac9186c064ac8543d822e9060d96 = internal constant [59 x i8] c"/g/g92/rydahl1/flangtests/src/parallel_region_outlined.f90\00"
@_QQcl.54686520726573756C74206F6620286172722831292B61727228 = internal constant [26 x i8] c"The result of (arr(1)+arr("
@_QQcl.2920697320 = internal constant [5 x i8] c") is "
@_QQEnvironmentDefaults = constant ptr null
@0 = private unnamed_addr constant [23 x i8] c";unknown;unknown;0;0;;\00", align 1
@1 = private unnamed_addr constant %struct.ident_t { i32 0, i32 2, i32 0, i32 22, ptr @0 }, align 8

; Function Attrs: mustprogress nofree nounwind willreturn allockind("alloc,uninitialized") allocsize(0) memory(inaccessiblemem: readwrite)
declare noalias noundef ptr @malloc(i64 noundef) #0

; Function Attrs: mustprogress nounwind willreturn allockind("free") memory(argmem: readwrite, inaccessiblemem: readwrite)
declare void @free(ptr allocptr nocapture noundef) #1

define void @_QQmain() {
  %1 = alloca i32, i64 1, align 4
  %2 = alloca double, i64 1, align 8
  %3 = alloca double, i64 1, align 8
  %4 = alloca { ptr, ptr }, i64 1, align 8
  %5 = getelementptr { ptr, ptr }, ptr %4, i32 0, i32 0
  store ptr %1, ptr %5, align 8, !tbaa !4
  %6 = getelementptr { ptr, ptr }, ptr %4, i32 0, i32 1
  store ptr %3, ptr %6, align 8, !tbaa !4
  store i32 1048576, ptr %1, align 4, !tbaa !4
  call void @_QFPomp_subroutine(ptr %1, ptr %2, ptr %4)
  %7 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr @_QQcl.e8a0ac9186c064ac8543d822e9060d96, i32 10)
  %8 = call i1 @_FortranAioOutputAscii(ptr %7, ptr @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %9 = load i32, ptr %1, align 4, !tbaa !4
  %10 = call i1 @_FortranAioOutputInteger32(ptr %7, i32 %9)
  %11 = call i1 @_FortranAioOutputAscii(ptr %7, ptr @_QQcl.2920697320, i64 5)
  %12 = load double, ptr %2, align 8, !tbaa !4
  %13 = call i1 @_FortranAioOutputReal64(ptr %7, double %12)
  %14 = call i32 @_FortranAioEndIoStatement(ptr %7)
  ret void
}

define void @_QFPomp_subroutine(ptr %0, ptr %1, ptr nest %2) {
  %structArg = alloca { ptr, ptr, ptr, ptr, ptr }, align 8
  %4 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %5 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %6 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %7 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %8 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %9 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %10 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, i64 1, align 8
  store { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } { ptr null, i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), i32 20180515, i8 1, i8 28, i8 2, i8 0, [1 x [3 x i64]] [[3 x i64] [i64 1, i64 0, i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64)]] }, ptr %9, align 8, !tbaa !8
  %11 = load { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %9, align 8, !tbaa !8
  store { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %11, ptr %10, align 8, !tbaa !8
  %12 = alloca i32, i64 1, align 4
  %13 = alloca i32, i64 1, align 4
  %14 = alloca i32, i64 1, align 4
  %15 = alloca i32, i64 1, align 4
  %16 = alloca double, i64 1, align 8
  %17 = alloca i32, i64 1, align 4
  %18 = load i32, ptr %0, align 4, !tbaa !4
  %19 = sext i32 %18 to i64
  %20 = icmp sgt i64 %19, 0
  %21 = select i1 %20, i64 %19, i64 0
  %22 = mul i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), %21
  %23 = call ptr @malloc(i64 %22)
  %24 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } { ptr undef, i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), i32 20180515, i8 1, i8 28, i8 2, i8 0, [1 x [3 x i64]] [[3 x i64] [i64 1, i64 undef, i64 undef]] }, i64 %21, 7, 0, 1
  %25 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %24, i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), 7, 0, 2
  %26 = mul i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), %21
  %27 = mul i64 1, %21
  %28 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %25, ptr %23, 0
  store { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %28, ptr %8, align 8, !tbaa !8
  %29 = load { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %8, align 8, !tbaa !8
  store { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %29, ptr %10, align 8, !tbaa !8
  br label %entry

entry:                                            ; preds = %3
  %omp_global_thread_num = call i32 @__kmpc_global_thread_num(ptr @1)
  br label %omp_parallel

omp_parallel:                                     ; preds = %entry
  %gep_ = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i32 0, i32 0
  store ptr %0, ptr %gep_, align 8
  %gep_5 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i32 0, i32 1
  store ptr %10, ptr %gep_5, align 8
  %gep_6 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i32 0, i32 2
  store ptr %7, ptr %gep_6, align 8
  %gep_7 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i32 0, i32 3
  store ptr %6, ptr %gep_7, align 8
  %gep_8 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i32 0, i32 4
  store ptr %2, ptr %gep_8, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr @1, i32 1, ptr @_QFPomp_subroutine..omp_par, ptr %structArg)
  br label %omp.par.outlined.exit

omp.par.outlined.exit:                            ; preds = %omp_parallel
  br label %omp.par.exit.split

omp.par.exit.split:                               ; preds = %omp.par.outlined.exit
  %30 = load { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %10, align 8, !tbaa !8
  store { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %30, ptr %5, align 8, !tbaa !8
  %31 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i32 0, i32 7, i64 0, i32 0
  %32 = load i64, ptr %31, align 8, !tbaa !8
  %33 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i32 0, i32 7, i64 0, i32 1
  %34 = load i64, ptr %33, align 8, !tbaa !8
  %35 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i32 0, i32 7, i64 0, i32 2
  %36 = load i64, ptr %35, align 8, !tbaa !8
  %37 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i32 0, i32 0
  %38 = load ptr, ptr %37, align 8, !tbaa !8
  %39 = sub i64 1, %32
  %40 = getelementptr double, ptr %38, i64 %39
  %41 = load double, ptr %40, align 8, !tbaa !4
  %42 = load i32, ptr %0, align 4, !tbaa !4
  %43 = sext i32 %42 to i64
  %44 = sub i64 %43, %32
  %45 = getelementptr double, ptr %38, i64 %44
  %46 = load double, ptr %45, align 8, !tbaa !4
  %47 = fadd contract double %41, %46
  store double %47, ptr %1, align 8, !tbaa !4
  %48 = load { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %10, align 8, !tbaa !8
  store { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %48, ptr %4, align 8, !tbaa !8
  %49 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %4, i32 0, i32 0
  %50 = load ptr, ptr %49, align 8, !tbaa !8
  call void @free(ptr %50)
  %51 = load { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %9, align 8, !tbaa !8
  store { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %51, ptr %10, align 8, !tbaa !8
  ret void
}

; Function Attrs: norecurse nounwind
define internal void @_QFPomp_subroutine..omp_par(ptr noalias %tid.addr, ptr noalias %zero.addr, ptr %0) #2 {
omp.par.entry:
  %gep_ = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i32 0, i32 0
  %loadgep_ = load ptr, ptr %gep_, align 8
  %gep_1 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i32 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %gep_3 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i32 0, i32 2
  %loadgep_4 = load ptr, ptr %gep_3, align 8
  %gep_5 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i32 0, i32 3
  %loadgep_6 = load ptr, ptr %gep_5, align 8
  %gep_7 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i32 0, i32 4
  %loadgep_8 = load ptr, ptr %gep_7, align 8
  %tid.addr.local = alloca i32, align 4
  %1 = load i32, ptr %tid.addr, align 4
  store i32 %1, ptr %tid.addr.local, align 4
  %tid = load i32, ptr %tid.addr.local, align 4
  br label %omp.par.region

omp.par.region:                                   ; preds = %omp.par.entry
  br label %omp.par.region1

omp.par.region1:                                  ; preds = %omp.par.region
  %2 = alloca i32, i64 1, align 4
  %3 = alloca i32, i64 1, align 4
  %4 = alloca i32, i64 1, align 4
  %5 = alloca i32, i64 1, align 4
  %6 = alloca i32, i64 1, align 4
  %7 = call i32 @omp_get_thread_num()
  store i32 %7, ptr %2, align 4, !tbaa !4
  %8 = call i32 @omp_get_num_threads()
  store i32 %8, ptr %3, align 4, !tbaa !4
  %9 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %10 = load i32, ptr %3, align 4, !tbaa !4
  %11 = sdiv i32 %9, %10
  store i32 %11, ptr %6, align 4, !tbaa !4
  %12 = load i32, ptr %2, align 4, !tbaa !4
  %13 = load i32, ptr %6, align 4, !tbaa !4
  %14 = mul i32 %12, %13
  %15 = add i32 %14, 1
  store i32 %15, ptr %4, align 4, !tbaa !4
  %16 = load i32, ptr %2, align 4, !tbaa !4
  %17 = load i32, ptr %3, align 4, !tbaa !4
  %18 = sub i32 %17, 1
  %19 = icmp eq i32 %16, %18
  br i1 %19, label %omp.par.region2, label %omp.par.region3

omp.par.region3:                                  ; preds = %omp.par.region1
  %20 = load i32, ptr %4, align 4, !tbaa !4
  %21 = load i32, ptr %6, align 4, !tbaa !4
  %22 = add i32 %20, %21
  store i32 %22, ptr %5, align 4, !tbaa !4
  br label %omp.par.region4

omp.par.region4:                                  ; preds = %omp.par.region2, %omp.par.region3
  %23 = load { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, align 8, !tbaa !8
  store { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %23, ptr %loadgep_4, align 8, !tbaa !8
  %24 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i32 0, i32 7, i64 0, i32 0
  %25 = load i64, ptr %24, align 8, !tbaa !8
  %26 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i32 0, i32 7, i64 0, i32 1
  %27 = load i64, ptr %26, align 8, !tbaa !8
  %28 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i32 0, i32 7, i64 0, i32 2
  %29 = load i64, ptr %28, align 8, !tbaa !8
  %30 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i32 0, i32 0
  %31 = load ptr, ptr %30, align 8, !tbaa !8
  %32 = icmp eq i64 %27, 0
  %33 = select i1 %32, i64 1, i64 %25
  %34 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } { ptr undef, i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), i32 20180515, i8 1, i8 28, i8 0, i8 0, [1 x [3 x i64]] undef }, i64 %33, 7, 0, 0
  %35 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %34, i64 %27, 7, 0, 1
  %36 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %35, i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), 7, 0, 2
  %37 = mul i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), %27
  %38 = mul i64 1, %27
  %39 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %36, ptr %31, 0
  store { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %39, ptr %loadgep_6, align 8, !tbaa !8
  call void @_QFPloop(ptr %4, ptr %5, ptr %loadgep_6, ptr %loadgep_8)
  br label %omp.region.cont

omp.region.cont:                                  ; preds = %omp.par.region4
  br label %omp.par.pre_finalize

omp.par.pre_finalize:                             ; preds = %omp.region.cont
  br label %omp.par.outlined.exit.exitStub

omp.par.region2:                                  ; preds = %omp.par.region1
  %40 = load i32, ptr %loadgep_, align 4, !tbaa !4
  store i32 %40, ptr %5, align 4, !tbaa !4
  br label %omp.par.region4

omp.par.outlined.exit.exitStub:                   ; preds = %omp.par.pre_finalize
  ret void
}

define void @_QFPloop(ptr %0, ptr %1, ptr %2, ptr nest %3) {
  %5 = getelementptr { ptr, ptr }, ptr %3, i32 0, i32 0
  %6 = load ptr, ptr %5, align 8, !tbaa !4
  %7 = getelementptr { ptr, ptr }, ptr %3, i32 0, i32 1
  %8 = load ptr, ptr %7, align 8, !tbaa !4
  %9 = alloca i32, i64 1, align 4
  %10 = load i32, ptr %0, align 4, !tbaa !4
  %11 = sext i32 %10 to i64
  %12 = load i32, ptr %1, align 4, !tbaa !4
  %13 = sext i32 %12 to i64
  %14 = trunc i64 %11 to i32
  %15 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %2, i32 0, i32 7, i64 0, i32 0
  %16 = load i64, ptr %15, align 8, !tbaa !8
  %17 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %2, i32 0, i32 7, i64 0, i32 1
  %18 = load i64, ptr %17, align 8, !tbaa !8
  %19 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %2, i32 0, i32 7, i64 0, i32 2
  %20 = load i64, ptr %19, align 8, !tbaa !8
  %21 = icmp eq i64 %20, 8
  br i1 %21, label %22, label %48

22:                                               ; preds = %4
  %23 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %2, i32 0, i32 0
  %24 = load ptr, ptr %23, align 8, !tbaa !8
  %25 = sub i64 %13, %11
  %26 = add i64 %25, 1
  br label %27

27:                                               ; preds = %31, %22
  %28 = phi i32 [ %46, %31 ], [ %14, %22 ]
  %29 = phi i64 [ %47, %31 ], [ %26, %22 ]
  %30 = icmp sgt i64 %29, 0
  br i1 %30, label %31, label %84

31:                                               ; preds = %27
  store i32 %28, ptr %9, align 4, !tbaa !4
  %32 = load i32, ptr %6, align 4, !tbaa !4
  %33 = sitofp i32 %32 to float
  %34 = fdiv contract float 1.000000e+00, %33
  %35 = fpext float %34 to double
  %36 = load i32, ptr %9, align 4, !tbaa !4
  %37 = sext i32 %36 to i64
  %38 = sub i64 %37, 1
  %39 = getelementptr double, ptr %24, i64 %38
  store double %35, ptr %39, align 8, !tbaa !4
  %40 = load i32, ptr %9, align 4, !tbaa !4
  %41 = sext i32 %40 to i64
  %42 = sub i64 %41, 1
  %43 = getelementptr double, ptr %24, i64 %42
  %44 = load double, ptr %43, align 8, !tbaa !4
  store double %44, ptr %8, align 8, !tbaa !4
  %45 = load i32, ptr %9, align 4, !tbaa !4
  %46 = add i32 %45, 1
  %47 = sub i64 %29, 1
  br label %27

48:                                               ; preds = %4
  %49 = sub i64 %13, %11
  %50 = add i64 %49, 1
  br label %51

51:                                               ; preds = %55, %48
  %52 = phi i32 [ %82, %55 ], [ %14, %48 ]
  %53 = phi i64 [ %83, %55 ], [ %50, %48 ]
  %54 = icmp sgt i64 %53, 0
  br i1 %54, label %55, label %84

55:                                               ; preds = %51
  store i32 %52, ptr %9, align 4, !tbaa !4
  %56 = load i32, ptr %6, align 4, !tbaa !4
  %57 = sitofp i32 %56 to float
  %58 = fdiv contract float 1.000000e+00, %57
  %59 = fpext float %58 to double
  %60 = load i32, ptr %9, align 4, !tbaa !4
  %61 = sext i32 %60 to i64
  %62 = sub i64 %61, 1
  %63 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %2, i32 0, i32 0
  %64 = load ptr, ptr %63, align 8, !tbaa !8
  %65 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %2, i32 0, i32 7, i32 0, i32 2
  %66 = load i64, ptr %65, align 8, !tbaa !8
  %67 = mul i64 %62, %66
  %68 = add i64 %67, 0
  %69 = getelementptr i8, ptr %64, i64 %68
  store double %59, ptr %69, align 8, !tbaa !4
  %70 = load i32, ptr %9, align 4, !tbaa !4
  %71 = sext i32 %70 to i64
  %72 = sub i64 %71, 1
  %73 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %2, i32 0, i32 0
  %74 = load ptr, ptr %73, align 8, !tbaa !8
  %75 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %2, i32 0, i32 7, i32 0, i32 2
  %76 = load i64, ptr %75, align 8, !tbaa !8
  %77 = mul i64 %72, %76
  %78 = add i64 %77, 0
  %79 = getelementptr i8, ptr %74, i64 %78
  %80 = load double, ptr %79, align 8, !tbaa !4
  store double %80, ptr %8, align 8, !tbaa !4
  %81 = load i32, ptr %9, align 4, !tbaa !4
  %82 = add i32 %81, 1
  %83 = sub i64 %53, 1
  br label %51

84:                                               ; preds = %27, %51
  %85 = phi i32 [ %52, %51 ], [ %28, %27 ]
  store i32 %85, ptr %9, align 4, !tbaa !4
  ret void
}

declare ptr @_FortranAioBeginExternalFormattedOutput(ptr, i64, ptr, i32, ptr, i32)

declare zeroext i1 @_FortranAioOutputAscii(ptr, ptr, i64)

declare zeroext i1 @_FortranAioOutputInteger32(ptr, i32)

declare zeroext i1 @_FortranAioOutputReal64(ptr, double)

declare i32 @_FortranAioEndIoStatement(ptr)

declare i32 @omp_get_thread_num()

declare i32 @omp_get_num_threads()

; Function Attrs: mustprogress nocallback nofree nosync nounwind willreturn
declare ptr @llvm.stacksave() #3

; Function Attrs: mustprogress nocallback nofree nosync nounwind willreturn
declare void @llvm.stackrestore(ptr) #3

; Function Attrs: nounwind
declare i32 @__kmpc_global_thread_num(ptr) #4

; Function Attrs: nounwind
declare !callback !10 void @__kmpc_fork_call(ptr, i32, ptr, ...) #4

attributes #0 = { mustprogress nofree nounwind willreturn allockind("alloc,uninitialized") allocsize(0) memory(inaccessiblemem: readwrite) "alloc-family"="malloc" }
attributes #1 = { mustprogress nounwind willreturn allockind("free") memory(argmem: readwrite, inaccessiblemem: readwrite) "alloc-family"="malloc" }
attributes #2 = { norecurse nounwind }
attributes #3 = { mustprogress nocallback nofree nosync nounwind willreturn }
attributes #4 = { nounwind }

!llvm.module.flags = !{!0, !1, !2, !3}

!0 = !{i32 2, !"Debug Info Version", i32 3}
!1 = !{i32 7, !"openmp", i32 11}
!2 = !{i32 8, !"PIC Level", i32 2}
!3 = !{i32 7, !"PIE Level", i32 2}
!4 = !{!5, !5, i64 0}
!5 = !{!"any data access", !6, i64 0}
!6 = !{!"any access", !7, i64 0}
!7 = !{!"Flang Type TBAA Root"}
!8 = !{!9, !9, i64 0}
!9 = !{!"descriptor member", !6, i64 0}
!10 = !{!11}
!11 = !{i64 2, i64 -1, i64 -1, i1 true}
*** IR Dump After CoroEarlyPass on [module] ***
; ModuleID = 'FIRModule'
source_filename = "FIRModule"
target datalayout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128"
target triple = "x86_64-unknown-linux-gnu"

%struct.ident_t = type { i32, i32, i32, i32, ptr }

@_QMomp_libEComp_allocator_handle_kind = external constant i32
@_QMomp_libEComp_alloctrait_key_kind = external constant i32
@_QMomp_libEComp_alloctrait_val_kind = external constant i32
@_QMomp_libEComp_allow_completion_event = external constant i32
@_QMomp_libEComp_atk_access = external constant i32
@_QMomp_libEComp_atk_alignment = external constant i32
@_QMomp_libEComp_atk_fallback = external constant i32
@_QMomp_libEComp_atk_fb_data = external constant i32
@_QMomp_libEComp_atk_partition = external constant i32
@_QMomp_libEComp_atk_pinned = external constant i32
@_QMomp_libEComp_atk_pool_size = external constant i32
@_QMomp_libEComp_atk_sync_hint = external constant i32
@_QMomp_libEComp_atv_abort_fb = external constant i32
@_QMomp_libEComp_atv_all = external constant i32
@_QMomp_libEComp_atv_allocator_fb = external constant i32
@_QMomp_libEComp_atv_blocked = external constant i32
@_QMomp_libEComp_atv_cgroup = external constant i32
@_QMomp_libEComp_atv_contended = external constant i32
@_QMomp_libEComp_atv_default = external constant i32
@_QMomp_libEComp_atv_default_mem_fb = external constant i32
@_QMomp_libEComp_atv_environment = external constant i32
@_QMomp_libEComp_atv_false = external constant i32
@_QMomp_libEComp_atv_interleaved = external constant i32
@_QMomp_libEComp_atv_nearest = external constant i32
@_QMomp_libEComp_atv_null_fb = external constant i32
@_QMomp_libEComp_atv_private = external constant i32
@_QMomp_libEComp_atv_pteam = external constant i32
@_QMomp_libEComp_atv_sequential = external constant i32
@_QMomp_libEComp_atv_thread = external constant i32
@_QMomp_libEComp_atv_true = external constant i32
@_QMomp_libEComp_atv_uncontended = external constant i32
@_QMomp_libEComp_cgroup_mem_alloc = external constant i32
@_QMomp_libEComp_const_mem_alloc = external constant i32
@_QMomp_libEComp_const_mem_space = external constant i32
@_QMomp_libEComp_default_mem_alloc = external constant i32
@_QMomp_libEComp_default_mem_space = external constant i32
@_QMomp_libEComp_depend_kind = external constant i32
@_QMomp_libEComp_event_handle_kind = external constant i32
@_QMomp_libEComp_high_bw_mem_alloc = external constant i32
@_QMomp_libEComp_high_bw_mem_space = external constant i32
@_QMomp_libEComp_integer_kind = external constant i32
@_QMomp_libEComp_large_cap_mem_alloc = external constant i32
@_QMomp_libEComp_large_cap_mem_space = external constant i32
@_QMomp_libEComp_lock_hint_contended = external constant i32
@_QMomp_libEComp_lock_hint_kind = external constant i32
@_QMomp_libEComp_lock_hint_none = external constant i32
@_QMomp_libEComp_lock_hint_nonspeculative = external constant i32
@_QMomp_libEComp_lock_hint_speculative = external constant i32
@_QMomp_libEComp_lock_hint_uncontended = external constant i32
@_QMomp_libEComp_lock_kind = external constant i32
@_QMomp_libEComp_logical_kind = external constant i32
@_QMomp_libEComp_low_lat_mem_alloc = external constant i32
@_QMomp_libEComp_low_lat_mem_space = external constant i32
@_QMomp_libEComp_memspace_handle_kind = external constant i32
@_QMomp_libEComp_nest_lock_kind = external constant i32
@_QMomp_libEComp_null_allocator = external constant i32
@_QMomp_libEComp_pause_hard = external constant i32
@_QMomp_libEComp_pause_resource_kind = external constant i32
@_QMomp_libEComp_pause_soft = external constant i32
@_QMomp_libEComp_proc_bind_close = external constant i32
@_QMomp_libEComp_proc_bind_false = external constant i32
@_QMomp_libEComp_proc_bind_kind = external constant i32
@_QMomp_libEComp_proc_bind_master = external constant i32
@_QMomp_libEComp_proc_bind_spread = external constant i32
@_QMomp_libEComp_proc_bind_true = external constant i32
@_QMomp_libEComp_pteam_mem_alloc = external constant i32
@_QMomp_libEComp_sched_auto = external constant i32
@_QMomp_libEComp_sched_dynamic = external constant i32
@_QMomp_libEComp_sched_guided = external constant i32
@_QMomp_libEComp_sched_kind = external constant i32
@_QMomp_libEComp_sched_static = external constant i32
@_QMomp_libEComp_sync_hint_contended = external constant i32
@_QMomp_libEComp_sync_hint_kind = external constant i32
@_QMomp_libEComp_sync_hint_none = external constant i32
@_QMomp_libEComp_sync_hint_nonspeculative = external constant i32
@_QMomp_libEComp_sync_hint_speculative = external constant i32
@_QMomp_libEComp_sync_hint_uncontended = external constant i32
@_QMomp_libEComp_task_fulfill_event = external constant i32
@_QMomp_libEComp_thread_mem_alloc = external constant i32
@_QMomp_libECopenmp_version = external constant i32
@_QQcl.28612C69372C612C6531332E36653229 = internal constant [16 x i8] c"(a,i7,a,e13.6e2)"
@_QQcl.e8a0ac9186c064ac8543d822e9060d96 = internal constant [59 x i8] c"/g/g92/rydahl1/flangtests/src/parallel_region_outlined.f90\00"
@_QQcl.54686520726573756C74206F6620286172722831292B61727228 = internal constant [26 x i8] c"The result of (arr(1)+arr("
@_QQcl.2920697320 = internal constant [5 x i8] c") is "
@_QQEnvironmentDefaults = constant ptr null
@0 = private unnamed_addr constant [23 x i8] c";unknown;unknown;0;0;;\00", align 1
@1 = private unnamed_addr constant %struct.ident_t { i32 0, i32 2, i32 0, i32 22, ptr @0 }, align 8

; Function Attrs: mustprogress nofree nounwind willreturn allockind("alloc,uninitialized") allocsize(0) memory(inaccessiblemem: readwrite)
declare noalias noundef ptr @malloc(i64 noundef) #0

; Function Attrs: mustprogress nounwind willreturn allockind("free") memory(argmem: readwrite, inaccessiblemem: readwrite)
declare void @free(ptr allocptr nocapture noundef) #1

define void @_QQmain() {
  %1 = alloca i32, i64 1, align 4
  %2 = alloca double, i64 1, align 8
  %3 = alloca double, i64 1, align 8
  %4 = alloca { ptr, ptr }, i64 1, align 8
  %5 = getelementptr { ptr, ptr }, ptr %4, i32 0, i32 0
  store ptr %1, ptr %5, align 8, !tbaa !4
  %6 = getelementptr { ptr, ptr }, ptr %4, i32 0, i32 1
  store ptr %3, ptr %6, align 8, !tbaa !4
  store i32 1048576, ptr %1, align 4, !tbaa !4
  call void @_QFPomp_subroutine(ptr %1, ptr %2, ptr %4)
  %7 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr @_QQcl.e8a0ac9186c064ac8543d822e9060d96, i32 10)
  %8 = call i1 @_FortranAioOutputAscii(ptr %7, ptr @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %9 = load i32, ptr %1, align 4, !tbaa !4
  %10 = call i1 @_FortranAioOutputInteger32(ptr %7, i32 %9)
  %11 = call i1 @_FortranAioOutputAscii(ptr %7, ptr @_QQcl.2920697320, i64 5)
  %12 = load double, ptr %2, align 8, !tbaa !4
  %13 = call i1 @_FortranAioOutputReal64(ptr %7, double %12)
  %14 = call i32 @_FortranAioEndIoStatement(ptr %7)
  ret void
}

define void @_QFPomp_subroutine(ptr %0, ptr %1, ptr nest %2) {
  %structArg = alloca { ptr, ptr, ptr, ptr, ptr }, align 8
  %4 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %5 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %6 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %7 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %8 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %9 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %10 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, i64 1, align 8
  store { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } { ptr null, i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), i32 20180515, i8 1, i8 28, i8 2, i8 0, [1 x [3 x i64]] [[3 x i64] [i64 1, i64 0, i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64)]] }, ptr %9, align 8, !tbaa !8
  %11 = load { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %9, align 8, !tbaa !8
  store { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %11, ptr %10, align 8, !tbaa !8
  %12 = alloca i32, i64 1, align 4
  %13 = alloca i32, i64 1, align 4
  %14 = alloca i32, i64 1, align 4
  %15 = alloca i32, i64 1, align 4
  %16 = alloca double, i64 1, align 8
  %17 = alloca i32, i64 1, align 4
  %18 = load i32, ptr %0, align 4, !tbaa !4
  %19 = sext i32 %18 to i64
  %20 = icmp sgt i64 %19, 0
  %21 = select i1 %20, i64 %19, i64 0
  %22 = mul i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), %21
  %23 = call ptr @malloc(i64 %22)
  %24 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } { ptr undef, i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), i32 20180515, i8 1, i8 28, i8 2, i8 0, [1 x [3 x i64]] [[3 x i64] [i64 1, i64 undef, i64 undef]] }, i64 %21, 7, 0, 1
  %25 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %24, i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), 7, 0, 2
  %26 = mul i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), %21
  %27 = mul i64 1, %21
  %28 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %25, ptr %23, 0
  store { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %28, ptr %8, align 8, !tbaa !8
  %29 = load { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %8, align 8, !tbaa !8
  store { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %29, ptr %10, align 8, !tbaa !8
  br label %entry

entry:                                            ; preds = %3
  %omp_global_thread_num = call i32 @__kmpc_global_thread_num(ptr @1)
  br label %omp_parallel

omp_parallel:                                     ; preds = %entry
  %gep_ = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i32 0, i32 0
  store ptr %0, ptr %gep_, align 8
  %gep_5 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i32 0, i32 1
  store ptr %10, ptr %gep_5, align 8
  %gep_6 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i32 0, i32 2
  store ptr %7, ptr %gep_6, align 8
  %gep_7 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i32 0, i32 3
  store ptr %6, ptr %gep_7, align 8
  %gep_8 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i32 0, i32 4
  store ptr %2, ptr %gep_8, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr @1, i32 1, ptr @_QFPomp_subroutine..omp_par, ptr %structArg)
  br label %omp.par.outlined.exit

omp.par.outlined.exit:                            ; preds = %omp_parallel
  br label %omp.par.exit.split

omp.par.exit.split:                               ; preds = %omp.par.outlined.exit
  %30 = load { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %10, align 8, !tbaa !8
  store { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %30, ptr %5, align 8, !tbaa !8
  %31 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i32 0, i32 7, i64 0, i32 0
  %32 = load i64, ptr %31, align 8, !tbaa !8
  %33 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i32 0, i32 7, i64 0, i32 1
  %34 = load i64, ptr %33, align 8, !tbaa !8
  %35 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i32 0, i32 7, i64 0, i32 2
  %36 = load i64, ptr %35, align 8, !tbaa !8
  %37 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i32 0, i32 0
  %38 = load ptr, ptr %37, align 8, !tbaa !8
  %39 = sub i64 1, %32
  %40 = getelementptr double, ptr %38, i64 %39
  %41 = load double, ptr %40, align 8, !tbaa !4
  %42 = load i32, ptr %0, align 4, !tbaa !4
  %43 = sext i32 %42 to i64
  %44 = sub i64 %43, %32
  %45 = getelementptr double, ptr %38, i64 %44
  %46 = load double, ptr %45, align 8, !tbaa !4
  %47 = fadd contract double %41, %46
  store double %47, ptr %1, align 8, !tbaa !4
  %48 = load { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %10, align 8, !tbaa !8
  store { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %48, ptr %4, align 8, !tbaa !8
  %49 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %4, i32 0, i32 0
  %50 = load ptr, ptr %49, align 8, !tbaa !8
  call void @free(ptr %50)
  %51 = load { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %9, align 8, !tbaa !8
  store { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %51, ptr %10, align 8, !tbaa !8
  ret void
}

; Function Attrs: norecurse nounwind
define internal void @_QFPomp_subroutine..omp_par(ptr noalias %tid.addr, ptr noalias %zero.addr, ptr %0) #2 {
omp.par.entry:
  %gep_ = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i32 0, i32 0
  %loadgep_ = load ptr, ptr %gep_, align 8
  %gep_1 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i32 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %gep_3 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i32 0, i32 2
  %loadgep_4 = load ptr, ptr %gep_3, align 8
  %gep_5 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i32 0, i32 3
  %loadgep_6 = load ptr, ptr %gep_5, align 8
  %gep_7 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i32 0, i32 4
  %loadgep_8 = load ptr, ptr %gep_7, align 8
  %tid.addr.local = alloca i32, align 4
  %1 = load i32, ptr %tid.addr, align 4
  store i32 %1, ptr %tid.addr.local, align 4
  %tid = load i32, ptr %tid.addr.local, align 4
  br label %omp.par.region

omp.par.region:                                   ; preds = %omp.par.entry
  br label %omp.par.region1

omp.par.region1:                                  ; preds = %omp.par.region
  %2 = alloca i32, i64 1, align 4
  %3 = alloca i32, i64 1, align 4
  %4 = alloca i32, i64 1, align 4
  %5 = alloca i32, i64 1, align 4
  %6 = alloca i32, i64 1, align 4
  %7 = call i32 @omp_get_thread_num()
  store i32 %7, ptr %2, align 4, !tbaa !4
  %8 = call i32 @omp_get_num_threads()
  store i32 %8, ptr %3, align 4, !tbaa !4
  %9 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %10 = load i32, ptr %3, align 4, !tbaa !4
  %11 = sdiv i32 %9, %10
  store i32 %11, ptr %6, align 4, !tbaa !4
  %12 = load i32, ptr %2, align 4, !tbaa !4
  %13 = load i32, ptr %6, align 4, !tbaa !4
  %14 = mul i32 %12, %13
  %15 = add i32 %14, 1
  store i32 %15, ptr %4, align 4, !tbaa !4
  %16 = load i32, ptr %2, align 4, !tbaa !4
  %17 = load i32, ptr %3, align 4, !tbaa !4
  %18 = sub i32 %17, 1
  %19 = icmp eq i32 %16, %18
  br i1 %19, label %omp.par.region2, label %omp.par.region3

omp.par.region3:                                  ; preds = %omp.par.region1
  %20 = load i32, ptr %4, align 4, !tbaa !4
  %21 = load i32, ptr %6, align 4, !tbaa !4
  %22 = add i32 %20, %21
  store i32 %22, ptr %5, align 4, !tbaa !4
  br label %omp.par.region4

omp.par.region4:                                  ; preds = %omp.par.region2, %omp.par.region3
  %23 = load { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, align 8, !tbaa !8
  store { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %23, ptr %loadgep_4, align 8, !tbaa !8
  %24 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i32 0, i32 7, i64 0, i32 0
  %25 = load i64, ptr %24, align 8, !tbaa !8
  %26 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i32 0, i32 7, i64 0, i32 1
  %27 = load i64, ptr %26, align 8, !tbaa !8
  %28 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i32 0, i32 7, i64 0, i32 2
  %29 = load i64, ptr %28, align 8, !tbaa !8
  %30 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i32 0, i32 0
  %31 = load ptr, ptr %30, align 8, !tbaa !8
  %32 = icmp eq i64 %27, 0
  %33 = select i1 %32, i64 1, i64 %25
  %34 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } { ptr undef, i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), i32 20180515, i8 1, i8 28, i8 0, i8 0, [1 x [3 x i64]] undef }, i64 %33, 7, 0, 0
  %35 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %34, i64 %27, 7, 0, 1
  %36 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %35, i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), 7, 0, 2
  %37 = mul i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), %27
  %38 = mul i64 1, %27
  %39 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %36, ptr %31, 0
  store { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %39, ptr %loadgep_6, align 8, !tbaa !8
  call void @_QFPloop(ptr %4, ptr %5, ptr %loadgep_6, ptr %loadgep_8)
  br label %omp.region.cont

omp.region.cont:                                  ; preds = %omp.par.region4
  br label %omp.par.pre_finalize

omp.par.pre_finalize:                             ; preds = %omp.region.cont
  br label %omp.par.outlined.exit.exitStub

omp.par.region2:                                  ; preds = %omp.par.region1
  %40 = load i32, ptr %loadgep_, align 4, !tbaa !4
  store i32 %40, ptr %5, align 4, !tbaa !4
  br label %omp.par.region4

omp.par.outlined.exit.exitStub:                   ; preds = %omp.par.pre_finalize
  ret void
}

define void @_QFPloop(ptr %0, ptr %1, ptr %2, ptr nest %3) {
  %5 = getelementptr { ptr, ptr }, ptr %3, i32 0, i32 0
  %6 = load ptr, ptr %5, align 8, !tbaa !4
  %7 = getelementptr { ptr, ptr }, ptr %3, i32 0, i32 1
  %8 = load ptr, ptr %7, align 8, !tbaa !4
  %9 = alloca i32, i64 1, align 4
  %10 = load i32, ptr %0, align 4, !tbaa !4
  %11 = sext i32 %10 to i64
  %12 = load i32, ptr %1, align 4, !tbaa !4
  %13 = sext i32 %12 to i64
  %14 = trunc i64 %11 to i32
  %15 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %2, i32 0, i32 7, i64 0, i32 0
  %16 = load i64, ptr %15, align 8, !tbaa !8
  %17 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %2, i32 0, i32 7, i64 0, i32 1
  %18 = load i64, ptr %17, align 8, !tbaa !8
  %19 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %2, i32 0, i32 7, i64 0, i32 2
  %20 = load i64, ptr %19, align 8, !tbaa !8
  %21 = icmp eq i64 %20, 8
  br i1 %21, label %22, label %48

22:                                               ; preds = %4
  %23 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %2, i32 0, i32 0
  %24 = load ptr, ptr %23, align 8, !tbaa !8
  %25 = sub i64 %13, %11
  %26 = add i64 %25, 1
  br label %27

27:                                               ; preds = %31, %22
  %28 = phi i32 [ %46, %31 ], [ %14, %22 ]
  %29 = phi i64 [ %47, %31 ], [ %26, %22 ]
  %30 = icmp sgt i64 %29, 0
  br i1 %30, label %31, label %84

31:                                               ; preds = %27
  store i32 %28, ptr %9, align 4, !tbaa !4
  %32 = load i32, ptr %6, align 4, !tbaa !4
  %33 = sitofp i32 %32 to float
  %34 = fdiv contract float 1.000000e+00, %33
  %35 = fpext float %34 to double
  %36 = load i32, ptr %9, align 4, !tbaa !4
  %37 = sext i32 %36 to i64
  %38 = sub i64 %37, 1
  %39 = getelementptr double, ptr %24, i64 %38
  store double %35, ptr %39, align 8, !tbaa !4
  %40 = load i32, ptr %9, align 4, !tbaa !4
  %41 = sext i32 %40 to i64
  %42 = sub i64 %41, 1
  %43 = getelementptr double, ptr %24, i64 %42
  %44 = load double, ptr %43, align 8, !tbaa !4
  store double %44, ptr %8, align 8, !tbaa !4
  %45 = load i32, ptr %9, align 4, !tbaa !4
  %46 = add i32 %45, 1
  %47 = sub i64 %29, 1
  br label %27

48:                                               ; preds = %4
  %49 = sub i64 %13, %11
  %50 = add i64 %49, 1
  br label %51

51:                                               ; preds = %55, %48
  %52 = phi i32 [ %82, %55 ], [ %14, %48 ]
  %53 = phi i64 [ %83, %55 ], [ %50, %48 ]
  %54 = icmp sgt i64 %53, 0
  br i1 %54, label %55, label %84

55:                                               ; preds = %51
  store i32 %52, ptr %9, align 4, !tbaa !4
  %56 = load i32, ptr %6, align 4, !tbaa !4
  %57 = sitofp i32 %56 to float
  %58 = fdiv contract float 1.000000e+00, %57
  %59 = fpext float %58 to double
  %60 = load i32, ptr %9, align 4, !tbaa !4
  %61 = sext i32 %60 to i64
  %62 = sub i64 %61, 1
  %63 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %2, i32 0, i32 0
  %64 = load ptr, ptr %63, align 8, !tbaa !8
  %65 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %2, i32 0, i32 7, i32 0, i32 2
  %66 = load i64, ptr %65, align 8, !tbaa !8
  %67 = mul i64 %62, %66
  %68 = add i64 %67, 0
  %69 = getelementptr i8, ptr %64, i64 %68
  store double %59, ptr %69, align 8, !tbaa !4
  %70 = load i32, ptr %9, align 4, !tbaa !4
  %71 = sext i32 %70 to i64
  %72 = sub i64 %71, 1
  %73 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %2, i32 0, i32 0
  %74 = load ptr, ptr %73, align 8, !tbaa !8
  %75 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %2, i32 0, i32 7, i32 0, i32 2
  %76 = load i64, ptr %75, align 8, !tbaa !8
  %77 = mul i64 %72, %76
  %78 = add i64 %77, 0
  %79 = getelementptr i8, ptr %74, i64 %78
  %80 = load double, ptr %79, align 8, !tbaa !4
  store double %80, ptr %8, align 8, !tbaa !4
  %81 = load i32, ptr %9, align 4, !tbaa !4
  %82 = add i32 %81, 1
  %83 = sub i64 %53, 1
  br label %51

84:                                               ; preds = %27, %51
  %85 = phi i32 [ %52, %51 ], [ %28, %27 ]
  store i32 %85, ptr %9, align 4, !tbaa !4
  ret void
}

declare ptr @_FortranAioBeginExternalFormattedOutput(ptr, i64, ptr, i32, ptr, i32)

declare zeroext i1 @_FortranAioOutputAscii(ptr, ptr, i64)

declare zeroext i1 @_FortranAioOutputInteger32(ptr, i32)

declare zeroext i1 @_FortranAioOutputReal64(ptr, double)

declare i32 @_FortranAioEndIoStatement(ptr)

declare i32 @omp_get_thread_num()

declare i32 @omp_get_num_threads()

; Function Attrs: mustprogress nocallback nofree nosync nounwind willreturn
declare ptr @llvm.stacksave() #3

; Function Attrs: mustprogress nocallback nofree nosync nounwind willreturn
declare void @llvm.stackrestore(ptr) #3

; Function Attrs: nounwind
declare i32 @__kmpc_global_thread_num(ptr) #4

; Function Attrs: nounwind
declare !callback !10 void @__kmpc_fork_call(ptr, i32, ptr, ...) #4

attributes #0 = { mustprogress nofree nounwind willreturn allockind("alloc,uninitialized") allocsize(0) memory(inaccessiblemem: readwrite) "alloc-family"="malloc" }
attributes #1 = { mustprogress nounwind willreturn allockind("free") memory(argmem: readwrite, inaccessiblemem: readwrite) "alloc-family"="malloc" }
attributes #2 = { norecurse nounwind }
attributes #3 = { mustprogress nocallback nofree nosync nounwind willreturn }
attributes #4 = { nounwind }

!llvm.module.flags = !{!0, !1, !2, !3}

!0 = !{i32 2, !"Debug Info Version", i32 3}
!1 = !{i32 7, !"openmp", i32 11}
!2 = !{i32 8, !"PIC Level", i32 2}
!3 = !{i32 7, !"PIE Level", i32 2}
!4 = !{!5, !5, i64 0}
!5 = !{!"any data access", !6, i64 0}
!6 = !{!"any access", !7, i64 0}
!7 = !{!"Flang Type TBAA Root"}
!8 = !{!9, !9, i64 0}
!9 = !{!"descriptor member", !6, i64 0}
!10 = !{!11}
!11 = !{i64 2, i64 -1, i64 -1, i1 true}
*** IR Dump After LowerExpectIntrinsicPass on _QQmain ***
define void @_QQmain() {
  %1 = alloca i32, i64 1, align 4
  %2 = alloca double, i64 1, align 8
  %3 = alloca double, i64 1, align 8
  %4 = alloca { ptr, ptr }, i64 1, align 8
  %5 = getelementptr { ptr, ptr }, ptr %4, i32 0, i32 0
  store ptr %1, ptr %5, align 8, !tbaa !4
  %6 = getelementptr { ptr, ptr }, ptr %4, i32 0, i32 1
  store ptr %3, ptr %6, align 8, !tbaa !4
  store i32 1048576, ptr %1, align 4, !tbaa !4
  call void @_QFPomp_subroutine(ptr %1, ptr %2, ptr %4)
  %7 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr @_QQcl.e8a0ac9186c064ac8543d822e9060d96, i32 10)
  %8 = call i1 @_FortranAioOutputAscii(ptr %7, ptr @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %9 = load i32, ptr %1, align 4, !tbaa !4
  %10 = call i1 @_FortranAioOutputInteger32(ptr %7, i32 %9)
  %11 = call i1 @_FortranAioOutputAscii(ptr %7, ptr @_QQcl.2920697320, i64 5)
  %12 = load double, ptr %2, align 8, !tbaa !4
  %13 = call i1 @_FortranAioOutputReal64(ptr %7, double %12)
  %14 = call i32 @_FortranAioEndIoStatement(ptr %7)
  ret void
}
*** IR Dump After SimplifyCFGPass on _QQmain ***
define void @_QQmain() {
  %1 = alloca i32, i64 1, align 4
  %2 = alloca double, i64 1, align 8
  %3 = alloca double, i64 1, align 8
  %4 = alloca { ptr, ptr }, i64 1, align 8
  %5 = getelementptr { ptr, ptr }, ptr %4, i32 0, i32 0
  store ptr %1, ptr %5, align 8, !tbaa !4
  %6 = getelementptr { ptr, ptr }, ptr %4, i32 0, i32 1
  store ptr %3, ptr %6, align 8, !tbaa !4
  store i32 1048576, ptr %1, align 4, !tbaa !4
  call void @_QFPomp_subroutine(ptr %1, ptr %2, ptr %4)
  %7 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr @_QQcl.e8a0ac9186c064ac8543d822e9060d96, i32 10)
  %8 = call i1 @_FortranAioOutputAscii(ptr %7, ptr @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %9 = load i32, ptr %1, align 4, !tbaa !4
  %10 = call i1 @_FortranAioOutputInteger32(ptr %7, i32 %9)
  %11 = call i1 @_FortranAioOutputAscii(ptr %7, ptr @_QQcl.2920697320, i64 5)
  %12 = load double, ptr %2, align 8, !tbaa !4
  %13 = call i1 @_FortranAioOutputReal64(ptr %7, double %12)
  %14 = call i32 @_FortranAioEndIoStatement(ptr %7)
  ret void
}
*** IR Dump After SROAPass on _QQmain ***
define void @_QQmain() {
  %1 = alloca i32, i64 1, align 4
  %2 = alloca double, i64 1, align 8
  %3 = alloca double, i64 1, align 8
  %4 = alloca { ptr, ptr }, i64 1, align 8
  %5 = getelementptr { ptr, ptr }, ptr %4, i32 0, i32 0
  store ptr %1, ptr %5, align 8, !tbaa !4
  %6 = getelementptr { ptr, ptr }, ptr %4, i32 0, i32 1
  store ptr %3, ptr %6, align 8, !tbaa !4
  store i32 1048576, ptr %1, align 4, !tbaa !4
  call void @_QFPomp_subroutine(ptr %1, ptr %2, ptr %4)
  %7 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr @_QQcl.e8a0ac9186c064ac8543d822e9060d96, i32 10)
  %8 = call i1 @_FortranAioOutputAscii(ptr %7, ptr @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %9 = load i32, ptr %1, align 4, !tbaa !4
  %10 = call i1 @_FortranAioOutputInteger32(ptr %7, i32 %9)
  %11 = call i1 @_FortranAioOutputAscii(ptr %7, ptr @_QQcl.2920697320, i64 5)
  %12 = load double, ptr %2, align 8, !tbaa !4
  %13 = call i1 @_FortranAioOutputReal64(ptr %7, double %12)
  %14 = call i32 @_FortranAioEndIoStatement(ptr %7)
  ret void
}
*** IR Dump After EarlyCSEPass on _QQmain ***
define void @_QQmain() {
  %1 = alloca i32, i64 1, align 4
  %2 = alloca double, i64 1, align 8
  %3 = alloca double, i64 1, align 8
  %4 = alloca { ptr, ptr }, i64 1, align 8
  store ptr %1, ptr %4, align 8, !tbaa !4
  %5 = getelementptr { ptr, ptr }, ptr %4, i32 0, i32 1
  store ptr %3, ptr %5, align 8, !tbaa !4
  store i32 1048576, ptr %1, align 4, !tbaa !4
  call void @_QFPomp_subroutine(ptr %1, ptr %2, ptr %4)
  %6 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr @_QQcl.e8a0ac9186c064ac8543d822e9060d96, i32 10)
  %7 = call i1 @_FortranAioOutputAscii(ptr %6, ptr @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %8 = load i32, ptr %1, align 4, !tbaa !4
  %9 = call i1 @_FortranAioOutputInteger32(ptr %6, i32 %8)
  %10 = call i1 @_FortranAioOutputAscii(ptr %6, ptr @_QQcl.2920697320, i64 5)
  %11 = load double, ptr %2, align 8, !tbaa !4
  %12 = call i1 @_FortranAioOutputReal64(ptr %6, double %11)
  %13 = call i32 @_FortranAioEndIoStatement(ptr %6)
  ret void
}
*** IR Dump After CallSiteSplittingPass on _QQmain ***
define void @_QQmain() {
  %1 = alloca i32, i64 1, align 4
  %2 = alloca double, i64 1, align 8
  %3 = alloca double, i64 1, align 8
  %4 = alloca { ptr, ptr }, i64 1, align 8
  store ptr %1, ptr %4, align 8, !tbaa !4
  %5 = getelementptr { ptr, ptr }, ptr %4, i32 0, i32 1
  store ptr %3, ptr %5, align 8, !tbaa !4
  store i32 1048576, ptr %1, align 4, !tbaa !4
  call void @_QFPomp_subroutine(ptr %1, ptr %2, ptr %4)
  %6 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr @_QQcl.e8a0ac9186c064ac8543d822e9060d96, i32 10)
  %7 = call i1 @_FortranAioOutputAscii(ptr %6, ptr @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %8 = load i32, ptr %1, align 4, !tbaa !4
  %9 = call i1 @_FortranAioOutputInteger32(ptr %6, i32 %8)
  %10 = call i1 @_FortranAioOutputAscii(ptr %6, ptr @_QQcl.2920697320, i64 5)
  %11 = load double, ptr %2, align 8, !tbaa !4
  %12 = call i1 @_FortranAioOutputReal64(ptr %6, double %11)
  %13 = call i32 @_FortranAioEndIoStatement(ptr %6)
  ret void
}
*** IR Dump After LowerExpectIntrinsicPass on _QFPomp_subroutine ***
define void @_QFPomp_subroutine(ptr %0, ptr %1, ptr nest %2) {
  %structArg = alloca { ptr, ptr, ptr, ptr, ptr }, align 8
  %4 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %5 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %6 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %7 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %8 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %9 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %10 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, i64 1, align 8
  store { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } { ptr null, i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), i32 20180515, i8 1, i8 28, i8 2, i8 0, [1 x [3 x i64]] [[3 x i64] [i64 1, i64 0, i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64)]] }, ptr %9, align 8, !tbaa !8
  %11 = load { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %9, align 8, !tbaa !8
  store { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %11, ptr %10, align 8, !tbaa !8
  %12 = alloca i32, i64 1, align 4
  %13 = alloca i32, i64 1, align 4
  %14 = alloca i32, i64 1, align 4
  %15 = alloca i32, i64 1, align 4
  %16 = alloca double, i64 1, align 8
  %17 = alloca i32, i64 1, align 4
  %18 = load i32, ptr %0, align 4, !tbaa !4
  %19 = sext i32 %18 to i64
  %20 = icmp sgt i64 %19, 0
  %21 = select i1 %20, i64 %19, i64 0
  %22 = mul i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), %21
  %23 = call ptr @malloc(i64 %22)
  %24 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } { ptr undef, i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), i32 20180515, i8 1, i8 28, i8 2, i8 0, [1 x [3 x i64]] [[3 x i64] [i64 1, i64 undef, i64 undef]] }, i64 %21, 7, 0, 1
  %25 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %24, i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), 7, 0, 2
  %26 = mul i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), %21
  %27 = mul i64 1, %21
  %28 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %25, ptr %23, 0
  store { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %28, ptr %8, align 8, !tbaa !8
  %29 = load { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %8, align 8, !tbaa !8
  store { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %29, ptr %10, align 8, !tbaa !8
  br label %entry

entry:                                            ; preds = %3
  %omp_global_thread_num = call i32 @__kmpc_global_thread_num(ptr @1)
  br label %omp_parallel

omp_parallel:                                     ; preds = %entry
  %gep_ = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i32 0, i32 0
  store ptr %0, ptr %gep_, align 8
  %gep_5 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i32 0, i32 1
  store ptr %10, ptr %gep_5, align 8
  %gep_6 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i32 0, i32 2
  store ptr %7, ptr %gep_6, align 8
  %gep_7 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i32 0, i32 3
  store ptr %6, ptr %gep_7, align 8
  %gep_8 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i32 0, i32 4
  store ptr %2, ptr %gep_8, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr @1, i32 1, ptr @_QFPomp_subroutine..omp_par, ptr %structArg)
  br label %omp.par.outlined.exit

omp.par.outlined.exit:                            ; preds = %omp_parallel
  br label %omp.par.exit.split

omp.par.exit.split:                               ; preds = %omp.par.outlined.exit
  %30 = load { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %10, align 8, !tbaa !8
  store { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %30, ptr %5, align 8, !tbaa !8
  %31 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i32 0, i32 7, i64 0, i32 0
  %32 = load i64, ptr %31, align 8, !tbaa !8
  %33 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i32 0, i32 7, i64 0, i32 1
  %34 = load i64, ptr %33, align 8, !tbaa !8
  %35 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i32 0, i32 7, i64 0, i32 2
  %36 = load i64, ptr %35, align 8, !tbaa !8
  %37 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i32 0, i32 0
  %38 = load ptr, ptr %37, align 8, !tbaa !8
  %39 = sub i64 1, %32
  %40 = getelementptr double, ptr %38, i64 %39
  %41 = load double, ptr %40, align 8, !tbaa !4
  %42 = load i32, ptr %0, align 4, !tbaa !4
  %43 = sext i32 %42 to i64
  %44 = sub i64 %43, %32
  %45 = getelementptr double, ptr %38, i64 %44
  %46 = load double, ptr %45, align 8, !tbaa !4
  %47 = fadd contract double %41, %46
  store double %47, ptr %1, align 8, !tbaa !4
  %48 = load { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %10, align 8, !tbaa !8
  store { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %48, ptr %4, align 8, !tbaa !8
  %49 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %4, i32 0, i32 0
  %50 = load ptr, ptr %49, align 8, !tbaa !8
  call void @free(ptr %50)
  %51 = load { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %9, align 8, !tbaa !8
  store { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %51, ptr %10, align 8, !tbaa !8
  ret void
}
*** IR Dump After SimplifyCFGPass on _QFPomp_subroutine ***
define void @_QFPomp_subroutine(ptr %0, ptr %1, ptr nest %2) {
entry:
  %structArg = alloca { ptr, ptr, ptr, ptr, ptr }, align 8
  %3 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %4 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %5 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %6 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %7 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %8 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %9 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, i64 1, align 8
  store { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } { ptr null, i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), i32 20180515, i8 1, i8 28, i8 2, i8 0, [1 x [3 x i64]] [[3 x i64] [i64 1, i64 0, i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64)]] }, ptr %8, align 8, !tbaa !8
  %10 = load { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %8, align 8, !tbaa !8
  store { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %10, ptr %9, align 8, !tbaa !8
  %11 = alloca i32, i64 1, align 4
  %12 = alloca i32, i64 1, align 4
  %13 = alloca i32, i64 1, align 4
  %14 = alloca i32, i64 1, align 4
  %15 = alloca double, i64 1, align 8
  %16 = alloca i32, i64 1, align 4
  %17 = load i32, ptr %0, align 4, !tbaa !4
  %18 = sext i32 %17 to i64
  %19 = icmp sgt i64 %18, 0
  %20 = select i1 %19, i64 %18, i64 0
  %21 = mul i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), %20
  %22 = call ptr @malloc(i64 %21)
  %23 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } { ptr undef, i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), i32 20180515, i8 1, i8 28, i8 2, i8 0, [1 x [3 x i64]] [[3 x i64] [i64 1, i64 undef, i64 undef]] }, i64 %20, 7, 0, 1
  %24 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %23, i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), 7, 0, 2
  %25 = mul i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), %20
  %26 = mul i64 1, %20
  %27 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %24, ptr %22, 0
  store { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %27, ptr %7, align 8, !tbaa !8
  %28 = load { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %7, align 8, !tbaa !8
  store { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %28, ptr %9, align 8, !tbaa !8
  %omp_global_thread_num = call i32 @__kmpc_global_thread_num(ptr @1)
  %gep_ = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i32 0, i32 0
  store ptr %0, ptr %gep_, align 8
  %gep_5 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i32 0, i32 1
  store ptr %9, ptr %gep_5, align 8
  %gep_6 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i32 0, i32 2
  store ptr %6, ptr %gep_6, align 8
  %gep_7 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i32 0, i32 3
  store ptr %5, ptr %gep_7, align 8
  %gep_8 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i32 0, i32 4
  store ptr %2, ptr %gep_8, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr @1, i32 1, ptr @_QFPomp_subroutine..omp_par, ptr %structArg)
  %29 = load { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %9, align 8, !tbaa !8
  store { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %29, ptr %4, align 8, !tbaa !8
  %30 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %4, i32 0, i32 7, i64 0, i32 0
  %31 = load i64, ptr %30, align 8, !tbaa !8
  %32 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %4, i32 0, i32 7, i64 0, i32 1
  %33 = load i64, ptr %32, align 8, !tbaa !8
  %34 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %4, i32 0, i32 7, i64 0, i32 2
  %35 = load i64, ptr %34, align 8, !tbaa !8
  %36 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %4, i32 0, i32 0
  %37 = load ptr, ptr %36, align 8, !tbaa !8
  %38 = sub i64 1, %31
  %39 = getelementptr double, ptr %37, i64 %38
  %40 = load double, ptr %39, align 8, !tbaa !4
  %41 = load i32, ptr %0, align 4, !tbaa !4
  %42 = sext i32 %41 to i64
  %43 = sub i64 %42, %31
  %44 = getelementptr double, ptr %37, i64 %43
  %45 = load double, ptr %44, align 8, !tbaa !4
  %46 = fadd contract double %40, %45
  store double %46, ptr %1, align 8, !tbaa !4
  %47 = load { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %9, align 8, !tbaa !8
  store { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %47, ptr %3, align 8, !tbaa !8
  %48 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i32 0, i32 0
  %49 = load ptr, ptr %48, align 8, !tbaa !8
  call void @free(ptr %49)
  %50 = load { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %8, align 8, !tbaa !8
  store { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %50, ptr %9, align 8, !tbaa !8
  ret void
}
*** IR Dump After SROAPass on _QFPomp_subroutine ***
define void @_QFPomp_subroutine(ptr %0, ptr %1, ptr nest %2) {
entry:
  %structArg = alloca { ptr, ptr, ptr, ptr, ptr }, align 8
  %3 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %4 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %5 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, i64 1, align 8
  %.fca.0.insert101 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } poison, ptr null, 0
  %.fca.1.insert104 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.0.insert101, i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), 1
  %.fca.2.insert107 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.1.insert104, i32 20180515, 2
  %.fca.3.insert110 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.2.insert107, i8 1, 3
  %.fca.4.insert113 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.3.insert110, i8 28, 4
  %.fca.5.insert116 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.4.insert113, i8 2, 5
  %.fca.6.insert119 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.5.insert116, i8 0, 6
  %.fca.7.0.0.insert122 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.6.insert119, i64 1, 7, 0, 0
  %.fca.7.0.1.insert125 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.7.0.0.insert122, i64 0, 7, 0, 1
  %.fca.7.0.2.insert128 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.7.0.1.insert125, i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), 7, 0, 2
  %.fca.0.extract = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.7.0.2.insert128, 0
  %.fca.0.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i32 0, i32 0
  store ptr %.fca.0.extract, ptr %.fca.0.gep, align 8, !tbaa !8
  %.fca.1.extract = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.7.0.2.insert128, 1
  %.fca.1.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i32 0, i32 1
  store i64 %.fca.1.extract, ptr %.fca.1.gep, align 8, !tbaa !8
  %.fca.2.extract = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.7.0.2.insert128, 2
  %.fca.2.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i32 0, i32 2
  store i32 %.fca.2.extract, ptr %.fca.2.gep, align 8, !tbaa !8
  %.fca.3.extract = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.7.0.2.insert128, 3
  %.fca.3.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i32 0, i32 3
  store i8 %.fca.3.extract, ptr %.fca.3.gep, align 4, !tbaa !8
  %.fca.4.extract = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.7.0.2.insert128, 4
  %.fca.4.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i32 0, i32 4
  store i8 %.fca.4.extract, ptr %.fca.4.gep, align 1, !tbaa !8
  %.fca.5.extract = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.7.0.2.insert128, 5
  %.fca.5.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i32 0, i32 5
  store i8 %.fca.5.extract, ptr %.fca.5.gep, align 2, !tbaa !8
  %.fca.6.extract = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.7.0.2.insert128, 6
  %.fca.6.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i32 0, i32 6
  store i8 %.fca.6.extract, ptr %.fca.6.gep, align 1, !tbaa !8
  %.fca.7.0.0.extract = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.7.0.2.insert128, 7, 0, 0
  %.fca.7.0.0.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i32 0, i32 7, i32 0, i32 0
  store i64 %.fca.7.0.0.extract, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  %.fca.7.0.1.extract = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.7.0.2.insert128, 7, 0, 1
  %.fca.7.0.1.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i32 0, i32 7, i32 0, i32 1
  store i64 %.fca.7.0.1.extract, ptr %.fca.7.0.1.gep, align 8, !tbaa !8
  %.fca.7.0.2.extract = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.7.0.2.insert128, 7, 0, 2
  %.fca.7.0.2.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i32 0, i32 7, i32 0, i32 2
  store i64 %.fca.7.0.2.extract, ptr %.fca.7.0.2.gep, align 8, !tbaa !8
  %6 = load i32, ptr %0, align 4, !tbaa !4
  %7 = sext i32 %6 to i64
  %8 = icmp sgt i64 %7, 0
  %9 = select i1 %8, i64 %7, i64 0
  %10 = mul i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), %9
  %11 = call ptr @malloc(i64 %10)
  %12 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } { ptr undef, i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), i32 20180515, i8 1, i8 28, i8 2, i8 0, [1 x [3 x i64]] [[3 x i64] [i64 1, i64 undef, i64 undef]] }, i64 %9, 7, 0, 1
  %13 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %12, i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), 7, 0, 2
  %14 = mul i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), %9
  %15 = mul i64 1, %9
  %16 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %13, ptr %11, 0
  %.fca.0.extract168 = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %16, 0
  %.fca.1.extract170 = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %16, 1
  %.fca.2.extract172 = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %16, 2
  %.fca.3.extract174 = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %16, 3
  %.fca.4.extract176 = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %16, 4
  %.fca.5.extract178 = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %16, 5
  %.fca.6.extract180 = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %16, 6
  %.fca.7.0.0.extract182 = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %16, 7, 0, 0
  %.fca.7.0.1.extract184 = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %16, 7, 0, 1
  %.fca.7.0.2.extract186 = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %16, 7, 0, 2
  %.fca.0.insert190 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } poison, ptr %.fca.0.extract168, 0
  %.fca.1.insert193 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.0.insert190, i64 %.fca.1.extract170, 1
  %.fca.2.insert196 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.1.insert193, i32 %.fca.2.extract172, 2
  %.fca.3.insert199 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.2.insert196, i8 %.fca.3.extract174, 3
  %.fca.4.insert202 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.3.insert199, i8 %.fca.4.extract176, 4
  %.fca.5.insert205 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.4.insert202, i8 %.fca.5.extract178, 5
  %.fca.6.insert208 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.5.insert205, i8 %.fca.6.extract180, 6
  %.fca.7.0.0.insert211 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.6.insert208, i64 %.fca.7.0.0.extract182, 7, 0, 0
  %.fca.7.0.1.insert214 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.7.0.0.insert211, i64 %.fca.7.0.1.extract184, 7, 0, 1
  %.fca.7.0.2.insert217 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.7.0.1.insert214, i64 %.fca.7.0.2.extract186, 7, 0, 2
  %.fca.0.extract9 = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.7.0.2.insert217, 0
  %.fca.0.gep10 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i32 0, i32 0
  store ptr %.fca.0.extract9, ptr %.fca.0.gep10, align 8, !tbaa !8
  %.fca.1.extract11 = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.7.0.2.insert217, 1
  %.fca.1.gep12 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i32 0, i32 1
  store i64 %.fca.1.extract11, ptr %.fca.1.gep12, align 8, !tbaa !8
  %.fca.2.extract13 = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.7.0.2.insert217, 2
  %.fca.2.gep14 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i32 0, i32 2
  store i32 %.fca.2.extract13, ptr %.fca.2.gep14, align 8, !tbaa !8
  %.fca.3.extract15 = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.7.0.2.insert217, 3
  %.fca.3.gep16 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i32 0, i32 3
  store i8 %.fca.3.extract15, ptr %.fca.3.gep16, align 4, !tbaa !8
  %.fca.4.extract17 = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.7.0.2.insert217, 4
  %.fca.4.gep18 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i32 0, i32 4
  store i8 %.fca.4.extract17, ptr %.fca.4.gep18, align 1, !tbaa !8
  %.fca.5.extract19 = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.7.0.2.insert217, 5
  %.fca.5.gep20 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i32 0, i32 5
  store i8 %.fca.5.extract19, ptr %.fca.5.gep20, align 2, !tbaa !8
  %.fca.6.extract21 = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.7.0.2.insert217, 6
  %.fca.6.gep22 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i32 0, i32 6
  store i8 %.fca.6.extract21, ptr %.fca.6.gep22, align 1, !tbaa !8
  %.fca.7.0.0.extract23 = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.7.0.2.insert217, 7, 0, 0
  %.fca.7.0.0.gep24 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i32 0, i32 7, i32 0, i32 0
  store i64 %.fca.7.0.0.extract23, ptr %.fca.7.0.0.gep24, align 8, !tbaa !8
  %.fca.7.0.1.extract25 = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.7.0.2.insert217, 7, 0, 1
  %.fca.7.0.1.gep26 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i32 0, i32 7, i32 0, i32 1
  store i64 %.fca.7.0.1.extract25, ptr %.fca.7.0.1.gep26, align 8, !tbaa !8
  %.fca.7.0.2.extract27 = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.7.0.2.insert217, 7, 0, 2
  %.fca.7.0.2.gep28 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i32 0, i32 7, i32 0, i32 2
  store i64 %.fca.7.0.2.extract27, ptr %.fca.7.0.2.gep28, align 8, !tbaa !8
  %omp_global_thread_num = call i32 @__kmpc_global_thread_num(ptr @1)
  %gep_ = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i32 0, i32 0
  store ptr %0, ptr %gep_, align 8
  %gep_5 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i32 0, i32 1
  store ptr %5, ptr %gep_5, align 8
  %gep_6 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i32 0, i32 2
  store ptr %4, ptr %gep_6, align 8
  %gep_7 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i32 0, i32 3
  store ptr %3, ptr %gep_7, align 8
  %gep_8 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i32 0, i32 4
  store ptr %2, ptr %gep_8, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr @1, i32 1, ptr @_QFPomp_subroutine..omp_par, ptr %structArg)
  %.fca.0.gep29 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i32 0, i32 0
  %.fca.0.load = load ptr, ptr %.fca.0.gep29, align 8, !tbaa !8
  %.fca.0.insert = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } poison, ptr %.fca.0.load, 0
  %.fca.1.gep30 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i32 0, i32 1
  %.fca.1.load = load i64, ptr %.fca.1.gep30, align 8, !tbaa !8
  %.fca.1.insert = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.0.insert, i64 %.fca.1.load, 1
  %.fca.2.gep31 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i32 0, i32 2
  %.fca.2.load = load i32, ptr %.fca.2.gep31, align 8, !tbaa !8
  %.fca.2.insert = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.1.insert, i32 %.fca.2.load, 2
  %.fca.3.gep32 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i32 0, i32 3
  %.fca.3.load = load i8, ptr %.fca.3.gep32, align 4, !tbaa !8
  %.fca.3.insert = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.2.insert, i8 %.fca.3.load, 3
  %.fca.4.gep33 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i32 0, i32 4
  %.fca.4.load = load i8, ptr %.fca.4.gep33, align 1, !tbaa !8
  %.fca.4.insert = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.3.insert, i8 %.fca.4.load, 4
  %.fca.5.gep34 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i32 0, i32 5
  %.fca.5.load = load i8, ptr %.fca.5.gep34, align 2, !tbaa !8
  %.fca.5.insert = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.4.insert, i8 %.fca.5.load, 5
  %.fca.6.gep35 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i32 0, i32 6
  %.fca.6.load = load i8, ptr %.fca.6.gep35, align 1, !tbaa !8
  %.fca.6.insert = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.5.insert, i8 %.fca.6.load, 6
  %.fca.7.0.0.gep36 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i32 0, i32 7, i32 0, i32 0
  %.fca.7.0.0.load = load i64, ptr %.fca.7.0.0.gep36, align 8, !tbaa !8
  %.fca.7.0.0.insert = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.6.insert, i64 %.fca.7.0.0.load, 7, 0, 0
  %.fca.7.0.1.gep37 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i32 0, i32 7, i32 0, i32 1
  %.fca.7.0.1.load = load i64, ptr %.fca.7.0.1.gep37, align 8, !tbaa !8
  %.fca.7.0.1.insert = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.7.0.0.insert, i64 %.fca.7.0.1.load, 7, 0, 1
  %.fca.7.0.2.gep38 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i32 0, i32 7, i32 0, i32 2
  %.fca.7.0.2.load = load i64, ptr %.fca.7.0.2.gep38, align 8, !tbaa !8
  %.fca.7.0.2.insert = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.7.0.1.insert, i64 %.fca.7.0.2.load, 7, 0, 2
  %.fca.7.0.2.insert.fca.0.extract = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.7.0.2.insert, 0
  %.fca.7.0.2.insert.fca.1.extract = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.7.0.2.insert, 1
  %.fca.7.0.2.insert.fca.2.extract = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.7.0.2.insert, 2
  %.fca.7.0.2.insert.fca.3.extract = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.7.0.2.insert, 3
  %.fca.7.0.2.insert.fca.4.extract = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.7.0.2.insert, 4
  %.fca.7.0.2.insert.fca.5.extract = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.7.0.2.insert, 5
  %.fca.7.0.2.insert.fca.6.extract = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.7.0.2.insert, 6
  %.fca.7.0.2.insert.fca.7.0.0.extract = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.7.0.2.insert, 7, 0, 0
  %.fca.7.0.2.insert.fca.7.0.1.extract = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.7.0.2.insert, 7, 0, 1
  %.fca.7.0.2.insert.fca.7.0.2.extract = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.7.0.2.insert, 7, 0, 2
  %17 = sub i64 1, %.fca.7.0.2.insert.fca.7.0.0.extract
  %18 = getelementptr double, ptr %.fca.7.0.2.insert.fca.0.extract, i64 %17
  %19 = load double, ptr %18, align 8, !tbaa !4
  %20 = load i32, ptr %0, align 4, !tbaa !4
  %21 = sext i32 %20 to i64
  %22 = sub i64 %21, %.fca.7.0.2.insert.fca.7.0.0.extract
  %23 = getelementptr double, ptr %.fca.7.0.2.insert.fca.0.extract, i64 %22
  %24 = load double, ptr %23, align 8, !tbaa !4
  %25 = fadd contract double %19, %24
  store double %25, ptr %1, align 8, !tbaa !4
  %.fca.0.gep39 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i32 0, i32 0
  %.fca.0.load40 = load ptr, ptr %.fca.0.gep39, align 8, !tbaa !8
  %.fca.0.insert41 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } poison, ptr %.fca.0.load40, 0
  %.fca.1.gep42 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i32 0, i32 1
  %.fca.1.load43 = load i64, ptr %.fca.1.gep42, align 8, !tbaa !8
  %.fca.1.insert44 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.0.insert41, i64 %.fca.1.load43, 1
  %.fca.2.gep45 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i32 0, i32 2
  %.fca.2.load46 = load i32, ptr %.fca.2.gep45, align 8, !tbaa !8
  %.fca.2.insert47 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.1.insert44, i32 %.fca.2.load46, 2
  %.fca.3.gep48 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i32 0, i32 3
  %.fca.3.load49 = load i8, ptr %.fca.3.gep48, align 4, !tbaa !8
  %.fca.3.insert50 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.2.insert47, i8 %.fca.3.load49, 3
  %.fca.4.gep51 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i32 0, i32 4
  %.fca.4.load52 = load i8, ptr %.fca.4.gep51, align 1, !tbaa !8
  %.fca.4.insert53 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.3.insert50, i8 %.fca.4.load52, 4
  %.fca.5.gep54 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i32 0, i32 5
  %.fca.5.load55 = load i8, ptr %.fca.5.gep54, align 2, !tbaa !8
  %.fca.5.insert56 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.4.insert53, i8 %.fca.5.load55, 5
  %.fca.6.gep57 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i32 0, i32 6
  %.fca.6.load58 = load i8, ptr %.fca.6.gep57, align 1, !tbaa !8
  %.fca.6.insert59 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.5.insert56, i8 %.fca.6.load58, 6
  %.fca.7.0.0.gep60 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i32 0, i32 7, i32 0, i32 0
  %.fca.7.0.0.load61 = load i64, ptr %.fca.7.0.0.gep60, align 8, !tbaa !8
  %.fca.7.0.0.insert62 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.6.insert59, i64 %.fca.7.0.0.load61, 7, 0, 0
  %.fca.7.0.1.gep63 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i32 0, i32 7, i32 0, i32 1
  %.fca.7.0.1.load64 = load i64, ptr %.fca.7.0.1.gep63, align 8, !tbaa !8
  %.fca.7.0.1.insert65 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.7.0.0.insert62, i64 %.fca.7.0.1.load64, 7, 0, 1
  %.fca.7.0.2.gep66 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i32 0, i32 7, i32 0, i32 2
  %.fca.7.0.2.load67 = load i64, ptr %.fca.7.0.2.gep66, align 8, !tbaa !8
  %.fca.7.0.2.insert68 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.7.0.1.insert65, i64 %.fca.7.0.2.load67, 7, 0, 2
  %.fca.7.0.2.insert68.fca.0.extract = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.7.0.2.insert68, 0
  %.fca.7.0.2.insert68.fca.1.extract = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.7.0.2.insert68, 1
  %.fca.7.0.2.insert68.fca.2.extract = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.7.0.2.insert68, 2
  %.fca.7.0.2.insert68.fca.3.extract = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.7.0.2.insert68, 3
  %.fca.7.0.2.insert68.fca.4.extract = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.7.0.2.insert68, 4
  %.fca.7.0.2.insert68.fca.5.extract = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.7.0.2.insert68, 5
  %.fca.7.0.2.insert68.fca.6.extract = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.7.0.2.insert68, 6
  %.fca.7.0.2.insert68.fca.7.0.0.extract = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.7.0.2.insert68, 7, 0, 0
  %.fca.7.0.2.insert68.fca.7.0.1.extract = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.7.0.2.insert68, 7, 0, 1
  %.fca.7.0.2.insert68.fca.7.0.2.extract = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.7.0.2.insert68, 7, 0, 2
  call void @free(ptr %.fca.7.0.2.insert68.fca.0.extract)
  %.fca.0.insert131 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } poison, ptr null, 0
  %.fca.1.insert134 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.0.insert131, i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), 1
  %.fca.2.insert137 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.1.insert134, i32 20180515, 2
  %.fca.3.insert140 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.2.insert137, i8 1, 3
  %.fca.4.insert143 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.3.insert140, i8 28, 4
  %.fca.5.insert146 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.4.insert143, i8 2, 5
  %.fca.6.insert149 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.5.insert146, i8 0, 6
  %.fca.7.0.0.insert152 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.6.insert149, i64 1, 7, 0, 0
  %.fca.7.0.1.insert155 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.7.0.0.insert152, i64 0, 7, 0, 1
  %.fca.7.0.2.insert158 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.7.0.1.insert155, i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), 7, 0, 2
  %.fca.0.extract69 = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.7.0.2.insert158, 0
  %.fca.0.gep70 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i32 0, i32 0
  store ptr %.fca.0.extract69, ptr %.fca.0.gep70, align 8, !tbaa !8
  %.fca.1.extract71 = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.7.0.2.insert158, 1
  %.fca.1.gep72 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i32 0, i32 1
  store i64 %.fca.1.extract71, ptr %.fca.1.gep72, align 8, !tbaa !8
  %.fca.2.extract73 = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.7.0.2.insert158, 2
  %.fca.2.gep74 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i32 0, i32 2
  store i32 %.fca.2.extract73, ptr %.fca.2.gep74, align 8, !tbaa !8
  %.fca.3.extract75 = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.7.0.2.insert158, 3
  %.fca.3.gep76 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i32 0, i32 3
  store i8 %.fca.3.extract75, ptr %.fca.3.gep76, align 4, !tbaa !8
  %.fca.4.extract77 = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.7.0.2.insert158, 4
  %.fca.4.gep78 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i32 0, i32 4
  store i8 %.fca.4.extract77, ptr %.fca.4.gep78, align 1, !tbaa !8
  %.fca.5.extract79 = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.7.0.2.insert158, 5
  %.fca.5.gep80 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i32 0, i32 5
  store i8 %.fca.5.extract79, ptr %.fca.5.gep80, align 2, !tbaa !8
  %.fca.6.extract81 = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.7.0.2.insert158, 6
  %.fca.6.gep82 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i32 0, i32 6
  store i8 %.fca.6.extract81, ptr %.fca.6.gep82, align 1, !tbaa !8
  %.fca.7.0.0.extract83 = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.7.0.2.insert158, 7, 0, 0
  %.fca.7.0.0.gep84 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i32 0, i32 7, i32 0, i32 0
  store i64 %.fca.7.0.0.extract83, ptr %.fca.7.0.0.gep84, align 8, !tbaa !8
  %.fca.7.0.1.extract85 = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.7.0.2.insert158, 7, 0, 1
  %.fca.7.0.1.gep86 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i32 0, i32 7, i32 0, i32 1
  store i64 %.fca.7.0.1.extract85, ptr %.fca.7.0.1.gep86, align 8, !tbaa !8
  %.fca.7.0.2.extract87 = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.7.0.2.insert158, 7, 0, 2
  %.fca.7.0.2.gep88 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i32 0, i32 7, i32 0, i32 2
  store i64 %.fca.7.0.2.extract87, ptr %.fca.7.0.2.gep88, align 8, !tbaa !8
  ret void
}
*** IR Dump After EarlyCSEPass on _QFPomp_subroutine ***
define void @_QFPomp_subroutine(ptr %0, ptr %1, ptr nest %2) {
entry:
  %structArg = alloca { ptr, ptr, ptr, ptr, ptr }, align 8
  %3 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %4 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %5 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, i64 1, align 8
  store ptr null, ptr %5, align 8, !tbaa !8
  %.fca.1.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i32 0, i32 1
  store i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), ptr %.fca.1.gep, align 8, !tbaa !8
  %.fca.2.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i32 0, i32 2
  store i32 20180515, ptr %.fca.2.gep, align 8, !tbaa !8
  %.fca.3.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i32 0, i32 3
  store i8 1, ptr %.fca.3.gep, align 4, !tbaa !8
  %.fca.4.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i32 0, i32 4
  store i8 28, ptr %.fca.4.gep, align 1, !tbaa !8
  %.fca.5.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i32 0, i32 5
  store i8 2, ptr %.fca.5.gep, align 2, !tbaa !8
  %.fca.6.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i32 0, i32 6
  store i8 0, ptr %.fca.6.gep, align 1, !tbaa !8
  %.fca.7.0.0.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i32 0, i32 7, i32 0, i32 0
  store i64 1, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  %.fca.7.0.1.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i32 0, i32 7, i32 0, i32 1
  store i64 0, ptr %.fca.7.0.1.gep, align 8, !tbaa !8
  %.fca.7.0.2.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i32 0, i32 7, i32 0, i32 2
  store i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), ptr %.fca.7.0.2.gep, align 8, !tbaa !8
  %6 = load i32, ptr %0, align 4, !tbaa !4
  %7 = sext i32 %6 to i64
  %8 = icmp sgt i64 %7, 0
  %9 = select i1 %8, i64 %7, i64 0
  %10 = mul i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), %9
  %11 = call ptr @malloc(i64 %10)
  %12 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } { ptr undef, i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), i32 20180515, i8 1, i8 28, i8 2, i8 0, [1 x [3 x i64]] [[3 x i64] [i64 1, i64 undef, i64 undef]] }, i64 %9, 7, 0, 1
  %13 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %12, i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), 7, 0, 2
  %14 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %13, ptr %11, 0
  %.fca.1.extract170 = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %14, 1
  %.fca.2.extract172 = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %14, 2
  %.fca.3.extract174 = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %14, 3
  %.fca.4.extract176 = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %14, 4
  %.fca.5.extract178 = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %14, 5
  %.fca.6.extract180 = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %14, 6
  %.fca.7.0.0.extract182 = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %14, 7, 0, 0
  %.fca.0.insert190 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } poison, ptr %11, 0
  %.fca.1.insert193 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.0.insert190, i64 %.fca.1.extract170, 1
  %.fca.2.insert196 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.1.insert193, i32 %.fca.2.extract172, 2
  %.fca.3.insert199 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.2.insert196, i8 %.fca.3.extract174, 3
  %.fca.4.insert202 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.3.insert199, i8 %.fca.4.extract176, 4
  %.fca.5.insert205 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.4.insert202, i8 %.fca.5.extract178, 5
  %.fca.6.insert208 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.5.insert205, i8 %.fca.6.extract180, 6
  %.fca.7.0.0.insert211 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.6.insert208, i64 %.fca.7.0.0.extract182, 7, 0, 0
  %.fca.7.0.1.insert214 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.7.0.0.insert211, i64 %9, 7, 0, 1
  %.fca.7.0.2.insert217 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.7.0.1.insert214, i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), 7, 0, 2
  store ptr %11, ptr %5, align 8, !tbaa !8
  store i64 %.fca.1.extract170, ptr %.fca.1.gep, align 8, !tbaa !8
  store i32 %.fca.2.extract172, ptr %.fca.2.gep, align 8, !tbaa !8
  store i8 %.fca.3.extract174, ptr %.fca.3.gep, align 4, !tbaa !8
  store i8 %.fca.4.extract176, ptr %.fca.4.gep, align 1, !tbaa !8
  store i8 %.fca.5.extract178, ptr %.fca.5.gep, align 2, !tbaa !8
  store i8 %.fca.6.extract180, ptr %.fca.6.gep, align 1, !tbaa !8
  store i64 %.fca.7.0.0.extract182, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  store i64 %9, ptr %.fca.7.0.1.gep, align 8, !tbaa !8
  store i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), ptr %.fca.7.0.2.gep, align 8, !tbaa !8
  %omp_global_thread_num = call i32 @__kmpc_global_thread_num(ptr @1)
  store ptr %0, ptr %structArg, align 8
  %gep_5 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i32 0, i32 1
  store ptr %5, ptr %gep_5, align 8
  %gep_6 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i32 0, i32 2
  store ptr %4, ptr %gep_6, align 8
  %gep_7 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i32 0, i32 3
  store ptr %3, ptr %gep_7, align 8
  %gep_8 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i32 0, i32 4
  store ptr %2, ptr %gep_8, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr @1, i32 1, ptr @_QFPomp_subroutine..omp_par, ptr %structArg)
  %.fca.0.load = load ptr, ptr %5, align 8, !tbaa !8
  %.fca.0.insert = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } poison, ptr %.fca.0.load, 0
  %.fca.1.load = load i64, ptr %.fca.1.gep, align 8, !tbaa !8
  %.fca.1.insert = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.0.insert, i64 %.fca.1.load, 1
  %.fca.2.load = load i32, ptr %.fca.2.gep, align 8, !tbaa !8
  %.fca.2.insert = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.1.insert, i32 %.fca.2.load, 2
  %.fca.3.load = load i8, ptr %.fca.3.gep, align 4, !tbaa !8
  %.fca.3.insert = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.2.insert, i8 %.fca.3.load, 3
  %.fca.4.load = load i8, ptr %.fca.4.gep, align 1, !tbaa !8
  %.fca.4.insert = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.3.insert, i8 %.fca.4.load, 4
  %.fca.5.load = load i8, ptr %.fca.5.gep, align 2, !tbaa !8
  %.fca.5.insert = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.4.insert, i8 %.fca.5.load, 5
  %.fca.6.load = load i8, ptr %.fca.6.gep, align 1, !tbaa !8
  %.fca.6.insert = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.5.insert, i8 %.fca.6.load, 6
  %.fca.7.0.0.load = load i64, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  %.fca.7.0.0.insert = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.6.insert, i64 %.fca.7.0.0.load, 7, 0, 0
  %.fca.7.0.1.load = load i64, ptr %.fca.7.0.1.gep, align 8, !tbaa !8
  %.fca.7.0.1.insert = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.7.0.0.insert, i64 %.fca.7.0.1.load, 7, 0, 1
  %.fca.7.0.2.load = load i64, ptr %.fca.7.0.2.gep, align 8, !tbaa !8
  %.fca.7.0.2.insert = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.7.0.1.insert, i64 %.fca.7.0.2.load, 7, 0, 2
  %15 = sub i64 1, %.fca.7.0.0.load
  %16 = getelementptr double, ptr %.fca.0.load, i64 %15
  %17 = load double, ptr %16, align 8, !tbaa !4
  %18 = load i32, ptr %0, align 4, !tbaa !4
  %19 = sext i32 %18 to i64
  %20 = sub i64 %19, %.fca.7.0.0.load
  %21 = getelementptr double, ptr %.fca.0.load, i64 %20
  %22 = load double, ptr %21, align 8, !tbaa !4
  %23 = fadd contract double %17, %22
  store double %23, ptr %1, align 8, !tbaa !4
  %.fca.0.load40 = load ptr, ptr %5, align 8, !tbaa !8
  %.fca.0.insert41 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } poison, ptr %.fca.0.load40, 0
  %.fca.1.load43 = load i64, ptr %.fca.1.gep, align 8, !tbaa !8
  %.fca.1.insert44 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.0.insert41, i64 %.fca.1.load43, 1
  %.fca.2.load46 = load i32, ptr %.fca.2.gep, align 8, !tbaa !8
  %.fca.2.insert47 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.1.insert44, i32 %.fca.2.load46, 2
  %.fca.3.load49 = load i8, ptr %.fca.3.gep, align 4, !tbaa !8
  %.fca.3.insert50 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.2.insert47, i8 %.fca.3.load49, 3
  %.fca.4.load52 = load i8, ptr %.fca.4.gep, align 1, !tbaa !8
  %.fca.4.insert53 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.3.insert50, i8 %.fca.4.load52, 4
  %.fca.5.load55 = load i8, ptr %.fca.5.gep, align 2, !tbaa !8
  %.fca.5.insert56 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.4.insert53, i8 %.fca.5.load55, 5
  %.fca.6.load58 = load i8, ptr %.fca.6.gep, align 1, !tbaa !8
  %.fca.6.insert59 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.5.insert56, i8 %.fca.6.load58, 6
  %.fca.7.0.0.load61 = load i64, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  %.fca.7.0.0.insert62 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.6.insert59, i64 %.fca.7.0.0.load61, 7, 0, 0
  %.fca.7.0.1.load64 = load i64, ptr %.fca.7.0.1.gep, align 8, !tbaa !8
  %.fca.7.0.1.insert65 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.7.0.0.insert62, i64 %.fca.7.0.1.load64, 7, 0, 1
  %.fca.7.0.2.load67 = load i64, ptr %.fca.7.0.2.gep, align 8, !tbaa !8
  %.fca.7.0.2.insert68 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.7.0.1.insert65, i64 %.fca.7.0.2.load67, 7, 0, 2
  call void @free(ptr %.fca.0.load40)
  store ptr null, ptr %5, align 8, !tbaa !8
  store i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), ptr %.fca.1.gep, align 8, !tbaa !8
  store i32 20180515, ptr %.fca.2.gep, align 8, !tbaa !8
  store i8 1, ptr %.fca.3.gep, align 4, !tbaa !8
  store i8 28, ptr %.fca.4.gep, align 1, !tbaa !8
  store i8 2, ptr %.fca.5.gep, align 2, !tbaa !8
  store i8 0, ptr %.fca.6.gep, align 1, !tbaa !8
  store i64 1, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  store i64 0, ptr %.fca.7.0.1.gep, align 8, !tbaa !8
  store i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), ptr %.fca.7.0.2.gep, align 8, !tbaa !8
  ret void
}
*** IR Dump After CallSiteSplittingPass on _QFPomp_subroutine ***
define void @_QFPomp_subroutine(ptr %0, ptr %1, ptr nest %2) {
entry:
  %structArg = alloca { ptr, ptr, ptr, ptr, ptr }, align 8
  %3 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %4 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %5 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, i64 1, align 8
  store ptr null, ptr %5, align 8, !tbaa !8
  %.fca.1.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i32 0, i32 1
  store i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), ptr %.fca.1.gep, align 8, !tbaa !8
  %.fca.2.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i32 0, i32 2
  store i32 20180515, ptr %.fca.2.gep, align 8, !tbaa !8
  %.fca.3.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i32 0, i32 3
  store i8 1, ptr %.fca.3.gep, align 4, !tbaa !8
  %.fca.4.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i32 0, i32 4
  store i8 28, ptr %.fca.4.gep, align 1, !tbaa !8
  %.fca.5.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i32 0, i32 5
  store i8 2, ptr %.fca.5.gep, align 2, !tbaa !8
  %.fca.6.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i32 0, i32 6
  store i8 0, ptr %.fca.6.gep, align 1, !tbaa !8
  %.fca.7.0.0.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i32 0, i32 7, i32 0, i32 0
  store i64 1, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  %.fca.7.0.1.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i32 0, i32 7, i32 0, i32 1
  store i64 0, ptr %.fca.7.0.1.gep, align 8, !tbaa !8
  %.fca.7.0.2.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i32 0, i32 7, i32 0, i32 2
  store i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), ptr %.fca.7.0.2.gep, align 8, !tbaa !8
  %6 = load i32, ptr %0, align 4, !tbaa !4
  %7 = sext i32 %6 to i64
  %8 = icmp sgt i64 %7, 0
  %9 = select i1 %8, i64 %7, i64 0
  %10 = mul i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), %9
  %11 = call ptr @malloc(i64 %10)
  %12 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } { ptr undef, i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), i32 20180515, i8 1, i8 28, i8 2, i8 0, [1 x [3 x i64]] [[3 x i64] [i64 1, i64 undef, i64 undef]] }, i64 %9, 7, 0, 1
  %13 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %12, i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), 7, 0, 2
  %14 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %13, ptr %11, 0
  %.fca.1.extract170 = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %14, 1
  %.fca.2.extract172 = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %14, 2
  %.fca.3.extract174 = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %14, 3
  %.fca.4.extract176 = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %14, 4
  %.fca.5.extract178 = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %14, 5
  %.fca.6.extract180 = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %14, 6
  %.fca.7.0.0.extract182 = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %14, 7, 0, 0
  %.fca.0.insert190 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } poison, ptr %11, 0
  %.fca.1.insert193 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.0.insert190, i64 %.fca.1.extract170, 1
  %.fca.2.insert196 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.1.insert193, i32 %.fca.2.extract172, 2
  %.fca.3.insert199 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.2.insert196, i8 %.fca.3.extract174, 3
  %.fca.4.insert202 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.3.insert199, i8 %.fca.4.extract176, 4
  %.fca.5.insert205 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.4.insert202, i8 %.fca.5.extract178, 5
  %.fca.6.insert208 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.5.insert205, i8 %.fca.6.extract180, 6
  %.fca.7.0.0.insert211 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.6.insert208, i64 %.fca.7.0.0.extract182, 7, 0, 0
  %.fca.7.0.1.insert214 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.7.0.0.insert211, i64 %9, 7, 0, 1
  %.fca.7.0.2.insert217 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.7.0.1.insert214, i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), 7, 0, 2
  store ptr %11, ptr %5, align 8, !tbaa !8
  store i64 %.fca.1.extract170, ptr %.fca.1.gep, align 8, !tbaa !8
  store i32 %.fca.2.extract172, ptr %.fca.2.gep, align 8, !tbaa !8
  store i8 %.fca.3.extract174, ptr %.fca.3.gep, align 4, !tbaa !8
  store i8 %.fca.4.extract176, ptr %.fca.4.gep, align 1, !tbaa !8
  store i8 %.fca.5.extract178, ptr %.fca.5.gep, align 2, !tbaa !8
  store i8 %.fca.6.extract180, ptr %.fca.6.gep, align 1, !tbaa !8
  store i64 %.fca.7.0.0.extract182, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  store i64 %9, ptr %.fca.7.0.1.gep, align 8, !tbaa !8
  store i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), ptr %.fca.7.0.2.gep, align 8, !tbaa !8
  %omp_global_thread_num = call i32 @__kmpc_global_thread_num(ptr @1)
  store ptr %0, ptr %structArg, align 8
  %gep_5 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i32 0, i32 1
  store ptr %5, ptr %gep_5, align 8
  %gep_6 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i32 0, i32 2
  store ptr %4, ptr %gep_6, align 8
  %gep_7 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i32 0, i32 3
  store ptr %3, ptr %gep_7, align 8
  %gep_8 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i32 0, i32 4
  store ptr %2, ptr %gep_8, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr @1, i32 1, ptr @_QFPomp_subroutine..omp_par, ptr %structArg)
  %.fca.0.load = load ptr, ptr %5, align 8, !tbaa !8
  %.fca.0.insert = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } poison, ptr %.fca.0.load, 0
  %.fca.1.load = load i64, ptr %.fca.1.gep, align 8, !tbaa !8
  %.fca.1.insert = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.0.insert, i64 %.fca.1.load, 1
  %.fca.2.load = load i32, ptr %.fca.2.gep, align 8, !tbaa !8
  %.fca.2.insert = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.1.insert, i32 %.fca.2.load, 2
  %.fca.3.load = load i8, ptr %.fca.3.gep, align 4, !tbaa !8
  %.fca.3.insert = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.2.insert, i8 %.fca.3.load, 3
  %.fca.4.load = load i8, ptr %.fca.4.gep, align 1, !tbaa !8
  %.fca.4.insert = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.3.insert, i8 %.fca.4.load, 4
  %.fca.5.load = load i8, ptr %.fca.5.gep, align 2, !tbaa !8
  %.fca.5.insert = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.4.insert, i8 %.fca.5.load, 5
  %.fca.6.load = load i8, ptr %.fca.6.gep, align 1, !tbaa !8
  %.fca.6.insert = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.5.insert, i8 %.fca.6.load, 6
  %.fca.7.0.0.load = load i64, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  %.fca.7.0.0.insert = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.6.insert, i64 %.fca.7.0.0.load, 7, 0, 0
  %.fca.7.0.1.load = load i64, ptr %.fca.7.0.1.gep, align 8, !tbaa !8
  %.fca.7.0.1.insert = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.7.0.0.insert, i64 %.fca.7.0.1.load, 7, 0, 1
  %.fca.7.0.2.load = load i64, ptr %.fca.7.0.2.gep, align 8, !tbaa !8
  %.fca.7.0.2.insert = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.7.0.1.insert, i64 %.fca.7.0.2.load, 7, 0, 2
  %15 = sub i64 1, %.fca.7.0.0.load
  %16 = getelementptr double, ptr %.fca.0.load, i64 %15
  %17 = load double, ptr %16, align 8, !tbaa !4
  %18 = load i32, ptr %0, align 4, !tbaa !4
  %19 = sext i32 %18 to i64
  %20 = sub i64 %19, %.fca.7.0.0.load
  %21 = getelementptr double, ptr %.fca.0.load, i64 %20
  %22 = load double, ptr %21, align 8, !tbaa !4
  %23 = fadd contract double %17, %22
  store double %23, ptr %1, align 8, !tbaa !4
  %.fca.0.load40 = load ptr, ptr %5, align 8, !tbaa !8
  %.fca.0.insert41 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } poison, ptr %.fca.0.load40, 0
  %.fca.1.load43 = load i64, ptr %.fca.1.gep, align 8, !tbaa !8
  %.fca.1.insert44 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.0.insert41, i64 %.fca.1.load43, 1
  %.fca.2.load46 = load i32, ptr %.fca.2.gep, align 8, !tbaa !8
  %.fca.2.insert47 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.1.insert44, i32 %.fca.2.load46, 2
  %.fca.3.load49 = load i8, ptr %.fca.3.gep, align 4, !tbaa !8
  %.fca.3.insert50 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.2.insert47, i8 %.fca.3.load49, 3
  %.fca.4.load52 = load i8, ptr %.fca.4.gep, align 1, !tbaa !8
  %.fca.4.insert53 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.3.insert50, i8 %.fca.4.load52, 4
  %.fca.5.load55 = load i8, ptr %.fca.5.gep, align 2, !tbaa !8
  %.fca.5.insert56 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.4.insert53, i8 %.fca.5.load55, 5
  %.fca.6.load58 = load i8, ptr %.fca.6.gep, align 1, !tbaa !8
  %.fca.6.insert59 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.5.insert56, i8 %.fca.6.load58, 6
  %.fca.7.0.0.load61 = load i64, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  %.fca.7.0.0.insert62 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.6.insert59, i64 %.fca.7.0.0.load61, 7, 0, 0
  %.fca.7.0.1.load64 = load i64, ptr %.fca.7.0.1.gep, align 8, !tbaa !8
  %.fca.7.0.1.insert65 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.7.0.0.insert62, i64 %.fca.7.0.1.load64, 7, 0, 1
  %.fca.7.0.2.load67 = load i64, ptr %.fca.7.0.2.gep, align 8, !tbaa !8
  %.fca.7.0.2.insert68 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.7.0.1.insert65, i64 %.fca.7.0.2.load67, 7, 0, 2
  call void @free(ptr %.fca.0.load40)
  store ptr null, ptr %5, align 8, !tbaa !8
  store i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), ptr %.fca.1.gep, align 8, !tbaa !8
  store i32 20180515, ptr %.fca.2.gep, align 8, !tbaa !8
  store i8 1, ptr %.fca.3.gep, align 4, !tbaa !8
  store i8 28, ptr %.fca.4.gep, align 1, !tbaa !8
  store i8 2, ptr %.fca.5.gep, align 2, !tbaa !8
  store i8 0, ptr %.fca.6.gep, align 1, !tbaa !8
  store i64 1, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  store i64 0, ptr %.fca.7.0.1.gep, align 8, !tbaa !8
  store i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), ptr %.fca.7.0.2.gep, align 8, !tbaa !8
  ret void
}
*** IR Dump After LowerExpectIntrinsicPass on _QFPomp_subroutine..omp_par ***
; Function Attrs: norecurse nounwind
define internal void @_QFPomp_subroutine..omp_par(ptr noalias %tid.addr, ptr noalias %zero.addr, ptr %0) #2 {
omp.par.entry:
  %gep_ = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i32 0, i32 0
  %loadgep_ = load ptr, ptr %gep_, align 8
  %gep_1 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i32 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %gep_3 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i32 0, i32 2
  %loadgep_4 = load ptr, ptr %gep_3, align 8
  %gep_5 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i32 0, i32 3
  %loadgep_6 = load ptr, ptr %gep_5, align 8
  %gep_7 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i32 0, i32 4
  %loadgep_8 = load ptr, ptr %gep_7, align 8
  %tid.addr.local = alloca i32, align 4
  %1 = load i32, ptr %tid.addr, align 4
  store i32 %1, ptr %tid.addr.local, align 4
  %tid = load i32, ptr %tid.addr.local, align 4
  br label %omp.par.region

omp.par.region:                                   ; preds = %omp.par.entry
  br label %omp.par.region1

omp.par.region1:                                  ; preds = %omp.par.region
  %2 = alloca i32, i64 1, align 4
  %3 = alloca i32, i64 1, align 4
  %4 = alloca i32, i64 1, align 4
  %5 = alloca i32, i64 1, align 4
  %6 = alloca i32, i64 1, align 4
  %7 = call i32 @omp_get_thread_num()
  store i32 %7, ptr %2, align 4, !tbaa !4
  %8 = call i32 @omp_get_num_threads()
  store i32 %8, ptr %3, align 4, !tbaa !4
  %9 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %10 = load i32, ptr %3, align 4, !tbaa !4
  %11 = sdiv i32 %9, %10
  store i32 %11, ptr %6, align 4, !tbaa !4
  %12 = load i32, ptr %2, align 4, !tbaa !4
  %13 = load i32, ptr %6, align 4, !tbaa !4
  %14 = mul i32 %12, %13
  %15 = add i32 %14, 1
  store i32 %15, ptr %4, align 4, !tbaa !4
  %16 = load i32, ptr %2, align 4, !tbaa !4
  %17 = load i32, ptr %3, align 4, !tbaa !4
  %18 = sub i32 %17, 1
  %19 = icmp eq i32 %16, %18
  br i1 %19, label %omp.par.region2, label %omp.par.region3

omp.par.region3:                                  ; preds = %omp.par.region1
  %20 = load i32, ptr %4, align 4, !tbaa !4
  %21 = load i32, ptr %6, align 4, !tbaa !4
  %22 = add i32 %20, %21
  store i32 %22, ptr %5, align 4, !tbaa !4
  br label %omp.par.region4

omp.par.region4:                                  ; preds = %omp.par.region2, %omp.par.region3
  %23 = load { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, align 8, !tbaa !8
  store { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %23, ptr %loadgep_4, align 8, !tbaa !8
  %24 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i32 0, i32 7, i64 0, i32 0
  %25 = load i64, ptr %24, align 8, !tbaa !8
  %26 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i32 0, i32 7, i64 0, i32 1
  %27 = load i64, ptr %26, align 8, !tbaa !8
  %28 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i32 0, i32 7, i64 0, i32 2
  %29 = load i64, ptr %28, align 8, !tbaa !8
  %30 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i32 0, i32 0
  %31 = load ptr, ptr %30, align 8, !tbaa !8
  %32 = icmp eq i64 %27, 0
  %33 = select i1 %32, i64 1, i64 %25
  %34 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } { ptr undef, i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), i32 20180515, i8 1, i8 28, i8 0, i8 0, [1 x [3 x i64]] undef }, i64 %33, 7, 0, 0
  %35 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %34, i64 %27, 7, 0, 1
  %36 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %35, i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), 7, 0, 2
  %37 = mul i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), %27
  %38 = mul i64 1, %27
  %39 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %36, ptr %31, 0
  store { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %39, ptr %loadgep_6, align 8, !tbaa !8
  call void @_QFPloop(ptr %4, ptr %5, ptr %loadgep_6, ptr %loadgep_8)
  br label %omp.region.cont

omp.region.cont:                                  ; preds = %omp.par.region4
  br label %omp.par.pre_finalize

omp.par.pre_finalize:                             ; preds = %omp.region.cont
  br label %omp.par.outlined.exit.exitStub

omp.par.region2:                                  ; preds = %omp.par.region1
  %40 = load i32, ptr %loadgep_, align 4, !tbaa !4
  store i32 %40, ptr %5, align 4, !tbaa !4
  br label %omp.par.region4

omp.par.outlined.exit.exitStub:                   ; preds = %omp.par.pre_finalize
  ret void
}
*** IR Dump After SimplifyCFGPass on _QFPomp_subroutine..omp_par ***
; Function Attrs: norecurse nounwind
define internal void @_QFPomp_subroutine..omp_par(ptr noalias %tid.addr, ptr noalias %zero.addr, ptr %0) #2 {
omp.par.entry:
  %gep_ = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i32 0, i32 0
  %loadgep_ = load ptr, ptr %gep_, align 8
  %gep_1 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i32 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %gep_3 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i32 0, i32 2
  %loadgep_4 = load ptr, ptr %gep_3, align 8
  %gep_5 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i32 0, i32 3
  %loadgep_6 = load ptr, ptr %gep_5, align 8
  %gep_7 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i32 0, i32 4
  %loadgep_8 = load ptr, ptr %gep_7, align 8
  %tid.addr.local = alloca i32, align 4
  %1 = load i32, ptr %tid.addr, align 4
  store i32 %1, ptr %tid.addr.local, align 4
  %tid = load i32, ptr %tid.addr.local, align 4
  %2 = alloca i32, i64 1, align 4
  %3 = alloca i32, i64 1, align 4
  %4 = alloca i32, i64 1, align 4
  %5 = alloca i32, i64 1, align 4
  %6 = alloca i32, i64 1, align 4
  %7 = call i32 @omp_get_thread_num()
  store i32 %7, ptr %2, align 4, !tbaa !4
  %8 = call i32 @omp_get_num_threads()
  store i32 %8, ptr %3, align 4, !tbaa !4
  %9 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %10 = load i32, ptr %3, align 4, !tbaa !4
  %11 = sdiv i32 %9, %10
  store i32 %11, ptr %6, align 4, !tbaa !4
  %12 = load i32, ptr %2, align 4, !tbaa !4
  %13 = load i32, ptr %6, align 4, !tbaa !4
  %14 = mul i32 %12, %13
  %15 = add i32 %14, 1
  store i32 %15, ptr %4, align 4, !tbaa !4
  %16 = load i32, ptr %2, align 4, !tbaa !4
  %17 = load i32, ptr %3, align 4, !tbaa !4
  %18 = sub i32 %17, 1
  %19 = icmp eq i32 %16, %18
  br i1 %19, label %omp.par.region2, label %omp.par.region3

omp.par.region3:                                  ; preds = %omp.par.entry
  %20 = load i32, ptr %4, align 4, !tbaa !4
  %21 = load i32, ptr %6, align 4, !tbaa !4
  %22 = add i32 %20, %21
  store i32 %22, ptr %5, align 4, !tbaa !4
  br label %omp.par.region4

omp.par.region4:                                  ; preds = %omp.par.region2, %omp.par.region3
  %23 = load { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, align 8, !tbaa !8
  store { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %23, ptr %loadgep_4, align 8, !tbaa !8
  %24 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i32 0, i32 7, i64 0, i32 0
  %25 = load i64, ptr %24, align 8, !tbaa !8
  %26 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i32 0, i32 7, i64 0, i32 1
  %27 = load i64, ptr %26, align 8, !tbaa !8
  %28 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i32 0, i32 7, i64 0, i32 2
  %29 = load i64, ptr %28, align 8, !tbaa !8
  %30 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i32 0, i32 0
  %31 = load ptr, ptr %30, align 8, !tbaa !8
  %32 = icmp eq i64 %27, 0
  %33 = select i1 %32, i64 1, i64 %25
  %34 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } { ptr undef, i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), i32 20180515, i8 1, i8 28, i8 0, i8 0, [1 x [3 x i64]] undef }, i64 %33, 7, 0, 0
  %35 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %34, i64 %27, 7, 0, 1
  %36 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %35, i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), 7, 0, 2
  %37 = mul i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), %27
  %38 = mul i64 1, %27
  %39 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %36, ptr %31, 0
  store { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %39, ptr %loadgep_6, align 8, !tbaa !8
  call void @_QFPloop(ptr %4, ptr %5, ptr %loadgep_6, ptr %loadgep_8)
  ret void

omp.par.region2:                                  ; preds = %omp.par.entry
  %40 = load i32, ptr %loadgep_, align 4, !tbaa !4
  store i32 %40, ptr %5, align 4, !tbaa !4
  br label %omp.par.region4
}
*** IR Dump After SROAPass on _QFPomp_subroutine..omp_par ***
; Function Attrs: norecurse nounwind
define internal void @_QFPomp_subroutine..omp_par(ptr noalias %tid.addr, ptr noalias %zero.addr, ptr %0) #2 {
omp.par.entry:
  %gep_ = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i32 0, i32 0
  %loadgep_ = load ptr, ptr %gep_, align 8
  %gep_1 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i32 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %gep_3 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i32 0, i32 2
  %loadgep_4 = load ptr, ptr %gep_3, align 8
  %gep_5 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i32 0, i32 3
  %loadgep_6 = load ptr, ptr %gep_5, align 8
  %gep_7 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i32 0, i32 4
  %loadgep_8 = load ptr, ptr %gep_7, align 8
  %1 = load i32, ptr %tid.addr, align 4
  %2 = alloca i32, i64 1, align 4
  %3 = alloca i32, i64 1, align 4
  %4 = call i32 @omp_get_thread_num()
  %5 = call i32 @omp_get_num_threads()
  %6 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %7 = sdiv i32 %6, %5
  %8 = mul i32 %4, %7
  %9 = add i32 %8, 1
  store i32 %9, ptr %2, align 4, !tbaa !4
  %10 = sub i32 %5, 1
  %11 = icmp eq i32 %4, %10
  br i1 %11, label %omp.par.region2, label %omp.par.region3

omp.par.region3:                                  ; preds = %omp.par.entry
  %12 = load i32, ptr %2, align 4, !tbaa !4
  %13 = add i32 %12, %7
  store i32 %13, ptr %3, align 4, !tbaa !4
  br label %omp.par.region4

omp.par.region4:                                  ; preds = %omp.par.region2, %omp.par.region3
  %14 = load { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, align 8, !tbaa !8
  store { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %14, ptr %loadgep_4, align 8, !tbaa !8
  %15 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i32 0, i32 7, i64 0, i32 0
  %16 = load i64, ptr %15, align 8, !tbaa !8
  %17 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i32 0, i32 7, i64 0, i32 1
  %18 = load i64, ptr %17, align 8, !tbaa !8
  %19 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i32 0, i32 7, i64 0, i32 2
  %20 = load i64, ptr %19, align 8, !tbaa !8
  %21 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i32 0, i32 0
  %22 = load ptr, ptr %21, align 8, !tbaa !8
  %23 = icmp eq i64 %18, 0
  %24 = select i1 %23, i64 1, i64 %16
  %25 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } { ptr undef, i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), i32 20180515, i8 1, i8 28, i8 0, i8 0, [1 x [3 x i64]] undef }, i64 %24, 7, 0, 0
  %26 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %25, i64 %18, 7, 0, 1
  %27 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %26, i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), 7, 0, 2
  %28 = mul i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), %18
  %29 = mul i64 1, %18
  %30 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %27, ptr %22, 0
  store { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %30, ptr %loadgep_6, align 8, !tbaa !8
  call void @_QFPloop(ptr %2, ptr %3, ptr %loadgep_6, ptr %loadgep_8)
  ret void

omp.par.region2:                                  ; preds = %omp.par.entry
  %31 = load i32, ptr %loadgep_, align 4, !tbaa !4
  store i32 %31, ptr %3, align 4, !tbaa !4
  br label %omp.par.region4
}
*** IR Dump After EarlyCSEPass on _QFPomp_subroutine..omp_par ***
; Function Attrs: norecurse nounwind
define internal void @_QFPomp_subroutine..omp_par(ptr noalias %tid.addr, ptr noalias %zero.addr, ptr %0) #2 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i32 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %gep_3 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i32 0, i32 2
  %loadgep_4 = load ptr, ptr %gep_3, align 8
  %gep_5 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i32 0, i32 3
  %loadgep_6 = load ptr, ptr %gep_5, align 8
  %gep_7 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i32 0, i32 4
  %loadgep_8 = load ptr, ptr %gep_7, align 8
  %1 = alloca i32, i64 1, align 4
  %2 = alloca i32, i64 1, align 4
  %3 = call i32 @omp_get_thread_num()
  %4 = call i32 @omp_get_num_threads()
  %5 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %6 = sdiv i32 %5, %4
  %7 = mul i32 %3, %6
  %8 = add i32 %7, 1
  store i32 %8, ptr %1, align 4, !tbaa !4
  %9 = sub i32 %4, 1
  %10 = icmp eq i32 %3, %9
  br i1 %10, label %omp.par.region2, label %omp.par.region3

omp.par.region3:                                  ; preds = %omp.par.entry
  %11 = add i32 %8, %6
  store i32 %11, ptr %2, align 4, !tbaa !4
  br label %omp.par.region4

omp.par.region4:                                  ; preds = %omp.par.region2, %omp.par.region3
  %12 = load { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, align 8, !tbaa !8
  store { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %12, ptr %loadgep_4, align 8, !tbaa !8
  %13 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i32 0, i32 7, i64 0, i32 0
  %14 = load i64, ptr %13, align 8, !tbaa !8
  %15 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i32 0, i32 7, i64 0, i32 1
  %16 = load i64, ptr %15, align 8, !tbaa !8
  %17 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i32 0, i32 7, i64 0, i32 2
  %18 = load ptr, ptr %loadgep_4, align 8, !tbaa !8
  %19 = icmp eq i64 %16, 0
  %20 = select i1 %19, i64 1, i64 %14
  %21 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } { ptr undef, i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), i32 20180515, i8 1, i8 28, i8 0, i8 0, [1 x [3 x i64]] undef }, i64 %20, 7, 0, 0
  %22 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %21, i64 %16, 7, 0, 1
  %23 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %22, i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), 7, 0, 2
  %24 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %23, ptr %18, 0
  store { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %24, ptr %loadgep_6, align 8, !tbaa !8
  call void @_QFPloop(ptr %1, ptr %2, ptr %loadgep_6, ptr %loadgep_8)
  ret void

omp.par.region2:                                  ; preds = %omp.par.entry
  %25 = load i32, ptr %loadgep_, align 4, !tbaa !4
  store i32 %25, ptr %2, align 4, !tbaa !4
  br label %omp.par.region4
}
*** IR Dump After CallSiteSplittingPass on _QFPomp_subroutine..omp_par ***
; Function Attrs: norecurse nounwind
define internal void @_QFPomp_subroutine..omp_par(ptr noalias %tid.addr, ptr noalias %zero.addr, ptr %0) #2 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i32 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %gep_3 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i32 0, i32 2
  %loadgep_4 = load ptr, ptr %gep_3, align 8
  %gep_5 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i32 0, i32 3
  %loadgep_6 = load ptr, ptr %gep_5, align 8
  %gep_7 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i32 0, i32 4
  %loadgep_8 = load ptr, ptr %gep_7, align 8
  %1 = alloca i32, i64 1, align 4
  %2 = alloca i32, i64 1, align 4
  %3 = call i32 @omp_get_thread_num()
  %4 = call i32 @omp_get_num_threads()
  %5 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %6 = sdiv i32 %5, %4
  %7 = mul i32 %3, %6
  %8 = add i32 %7, 1
  store i32 %8, ptr %1, align 4, !tbaa !4
  %9 = sub i32 %4, 1
  %10 = icmp eq i32 %3, %9
  br i1 %10, label %omp.par.region2, label %omp.par.region3

omp.par.region3:                                  ; preds = %omp.par.entry
  %11 = add i32 %8, %6
  store i32 %11, ptr %2, align 4, !tbaa !4
  br label %omp.par.region4

omp.par.region4:                                  ; preds = %omp.par.region2, %omp.par.region3
  %12 = load { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, align 8, !tbaa !8
  store { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %12, ptr %loadgep_4, align 8, !tbaa !8
  %13 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i32 0, i32 7, i64 0, i32 0
  %14 = load i64, ptr %13, align 8, !tbaa !8
  %15 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i32 0, i32 7, i64 0, i32 1
  %16 = load i64, ptr %15, align 8, !tbaa !8
  %17 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i32 0, i32 7, i64 0, i32 2
  %18 = load ptr, ptr %loadgep_4, align 8, !tbaa !8
  %19 = icmp eq i64 %16, 0
  %20 = select i1 %19, i64 1, i64 %14
  %21 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } { ptr undef, i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), i32 20180515, i8 1, i8 28, i8 0, i8 0, [1 x [3 x i64]] undef }, i64 %20, 7, 0, 0
  %22 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %21, i64 %16, 7, 0, 1
  %23 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %22, i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), 7, 0, 2
  %24 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %23, ptr %18, 0
  store { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %24, ptr %loadgep_6, align 8, !tbaa !8
  call void @_QFPloop(ptr %1, ptr %2, ptr %loadgep_6, ptr %loadgep_8)
  ret void

omp.par.region2:                                  ; preds = %omp.par.entry
  %25 = load i32, ptr %loadgep_, align 4, !tbaa !4
  store i32 %25, ptr %2, align 4, !tbaa !4
  br label %omp.par.region4
}
*** IR Dump After LowerExpectIntrinsicPass on _QFPloop ***
define void @_QFPloop(ptr %0, ptr %1, ptr %2, ptr nest %3) {
  %5 = getelementptr { ptr, ptr }, ptr %3, i32 0, i32 0
  %6 = load ptr, ptr %5, align 8, !tbaa !4
  %7 = getelementptr { ptr, ptr }, ptr %3, i32 0, i32 1
  %8 = load ptr, ptr %7, align 8, !tbaa !4
  %9 = alloca i32, i64 1, align 4
  %10 = load i32, ptr %0, align 4, !tbaa !4
  %11 = sext i32 %10 to i64
  %12 = load i32, ptr %1, align 4, !tbaa !4
  %13 = sext i32 %12 to i64
  %14 = trunc i64 %11 to i32
  %15 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %2, i32 0, i32 7, i64 0, i32 0
  %16 = load i64, ptr %15, align 8, !tbaa !8
  %17 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %2, i32 0, i32 7, i64 0, i32 1
  %18 = load i64, ptr %17, align 8, !tbaa !8
  %19 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %2, i32 0, i32 7, i64 0, i32 2
  %20 = load i64, ptr %19, align 8, !tbaa !8
  %21 = icmp eq i64 %20, 8
  br i1 %21, label %22, label %48

22:                                               ; preds = %4
  %23 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %2, i32 0, i32 0
  %24 = load ptr, ptr %23, align 8, !tbaa !8
  %25 = sub i64 %13, %11
  %26 = add i64 %25, 1
  br label %27

27:                                               ; preds = %31, %22
  %28 = phi i32 [ %46, %31 ], [ %14, %22 ]
  %29 = phi i64 [ %47, %31 ], [ %26, %22 ]
  %30 = icmp sgt i64 %29, 0
  br i1 %30, label %31, label %84

31:                                               ; preds = %27
  store i32 %28, ptr %9, align 4, !tbaa !4
  %32 = load i32, ptr %6, align 4, !tbaa !4
  %33 = sitofp i32 %32 to float
  %34 = fdiv contract float 1.000000e+00, %33
  %35 = fpext float %34 to double
  %36 = load i32, ptr %9, align 4, !tbaa !4
  %37 = sext i32 %36 to i64
  %38 = sub i64 %37, 1
  %39 = getelementptr double, ptr %24, i64 %38
  store double %35, ptr %39, align 8, !tbaa !4
  %40 = load i32, ptr %9, align 4, !tbaa !4
  %41 = sext i32 %40 to i64
  %42 = sub i64 %41, 1
  %43 = getelementptr double, ptr %24, i64 %42
  %44 = load double, ptr %43, align 8, !tbaa !4
  store double %44, ptr %8, align 8, !tbaa !4
  %45 = load i32, ptr %9, align 4, !tbaa !4
  %46 = add i32 %45, 1
  %47 = sub i64 %29, 1
  br label %27

48:                                               ; preds = %4
  %49 = sub i64 %13, %11
  %50 = add i64 %49, 1
  br label %51

51:                                               ; preds = %55, %48
  %52 = phi i32 [ %82, %55 ], [ %14, %48 ]
  %53 = phi i64 [ %83, %55 ], [ %50, %48 ]
  %54 = icmp sgt i64 %53, 0
  br i1 %54, label %55, label %84

55:                                               ; preds = %51
  store i32 %52, ptr %9, align 4, !tbaa !4
  %56 = load i32, ptr %6, align 4, !tbaa !4
  %57 = sitofp i32 %56 to float
  %58 = fdiv contract float 1.000000e+00, %57
  %59 = fpext float %58 to double
  %60 = load i32, ptr %9, align 4, !tbaa !4
  %61 = sext i32 %60 to i64
  %62 = sub i64 %61, 1
  %63 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %2, i32 0, i32 0
  %64 = load ptr, ptr %63, align 8, !tbaa !8
  %65 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %2, i32 0, i32 7, i32 0, i32 2
  %66 = load i64, ptr %65, align 8, !tbaa !8
  %67 = mul i64 %62, %66
  %68 = add i64 %67, 0
  %69 = getelementptr i8, ptr %64, i64 %68
  store double %59, ptr %69, align 8, !tbaa !4
  %70 = load i32, ptr %9, align 4, !tbaa !4
  %71 = sext i32 %70 to i64
  %72 = sub i64 %71, 1
  %73 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %2, i32 0, i32 0
  %74 = load ptr, ptr %73, align 8, !tbaa !8
  %75 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %2, i32 0, i32 7, i32 0, i32 2
  %76 = load i64, ptr %75, align 8, !tbaa !8
  %77 = mul i64 %72, %76
  %78 = add i64 %77, 0
  %79 = getelementptr i8, ptr %74, i64 %78
  %80 = load double, ptr %79, align 8, !tbaa !4
  store double %80, ptr %8, align 8, !tbaa !4
  %81 = load i32, ptr %9, align 4, !tbaa !4
  %82 = add i32 %81, 1
  %83 = sub i64 %53, 1
  br label %51

84:                                               ; preds = %27, %51
  %85 = phi i32 [ %52, %51 ], [ %28, %27 ]
  store i32 %85, ptr %9, align 4, !tbaa !4
  ret void
}
*** IR Dump After SimplifyCFGPass on _QFPloop ***
define void @_QFPloop(ptr %0, ptr %1, ptr %2, ptr nest %3) {
  %5 = getelementptr { ptr, ptr }, ptr %3, i32 0, i32 0
  %6 = load ptr, ptr %5, align 8, !tbaa !4
  %7 = getelementptr { ptr, ptr }, ptr %3, i32 0, i32 1
  %8 = load ptr, ptr %7, align 8, !tbaa !4
  %9 = alloca i32, i64 1, align 4
  %10 = load i32, ptr %0, align 4, !tbaa !4
  %11 = sext i32 %10 to i64
  %12 = load i32, ptr %1, align 4, !tbaa !4
  %13 = sext i32 %12 to i64
  %14 = trunc i64 %11 to i32
  %15 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %2, i32 0, i32 7, i64 0, i32 0
  %16 = load i64, ptr %15, align 8, !tbaa !8
  %17 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %2, i32 0, i32 7, i64 0, i32 1
  %18 = load i64, ptr %17, align 8, !tbaa !8
  %19 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %2, i32 0, i32 7, i64 0, i32 2
  %20 = load i64, ptr %19, align 8, !tbaa !8
  %21 = icmp eq i64 %20, 8
  br i1 %21, label %22, label %48

22:                                               ; preds = %4
  %23 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %2, i32 0, i32 0
  %24 = load ptr, ptr %23, align 8, !tbaa !8
  %25 = sub i64 %13, %11
  %26 = add i64 %25, 1
  br label %27

27:                                               ; preds = %31, %22
  %28 = phi i32 [ %46, %31 ], [ %14, %22 ]
  %29 = phi i64 [ %47, %31 ], [ %26, %22 ]
  %30 = icmp sgt i64 %29, 0
  br i1 %30, label %31, label %84

31:                                               ; preds = %27
  store i32 %28, ptr %9, align 4, !tbaa !4
  %32 = load i32, ptr %6, align 4, !tbaa !4
  %33 = sitofp i32 %32 to float
  %34 = fdiv contract float 1.000000e+00, %33
  %35 = fpext float %34 to double
  %36 = load i32, ptr %9, align 4, !tbaa !4
  %37 = sext i32 %36 to i64
  %38 = sub i64 %37, 1
  %39 = getelementptr double, ptr %24, i64 %38
  store double %35, ptr %39, align 8, !tbaa !4
  %40 = load i32, ptr %9, align 4, !tbaa !4
  %41 = sext i32 %40 to i64
  %42 = sub i64 %41, 1
  %43 = getelementptr double, ptr %24, i64 %42
  %44 = load double, ptr %43, align 8, !tbaa !4
  store double %44, ptr %8, align 8, !tbaa !4
  %45 = load i32, ptr %9, align 4, !tbaa !4
  %46 = add i32 %45, 1
  %47 = sub i64 %29, 1
  br label %27

48:                                               ; preds = %4
  %49 = sub i64 %13, %11
  %50 = add i64 %49, 1
  br label %51

51:                                               ; preds = %55, %48
  %52 = phi i32 [ %82, %55 ], [ %14, %48 ]
  %53 = phi i64 [ %83, %55 ], [ %50, %48 ]
  %54 = icmp sgt i64 %53, 0
  br i1 %54, label %55, label %84

55:                                               ; preds = %51
  store i32 %52, ptr %9, align 4, !tbaa !4
  %56 = load i32, ptr %6, align 4, !tbaa !4
  %57 = sitofp i32 %56 to float
  %58 = fdiv contract float 1.000000e+00, %57
  %59 = fpext float %58 to double
  %60 = load i32, ptr %9, align 4, !tbaa !4
  %61 = sext i32 %60 to i64
  %62 = sub i64 %61, 1
  %63 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %2, i32 0, i32 0
  %64 = load ptr, ptr %63, align 8, !tbaa !8
  %65 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %2, i32 0, i32 7, i32 0, i32 2
  %66 = load i64, ptr %65, align 8, !tbaa !8
  %67 = mul i64 %62, %66
  %68 = add i64 %67, 0
  %69 = getelementptr i8, ptr %64, i64 %68
  store double %59, ptr %69, align 8, !tbaa !4
  %70 = load i32, ptr %9, align 4, !tbaa !4
  %71 = sext i32 %70 to i64
  %72 = sub i64 %71, 1
  %73 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %2, i32 0, i32 0
  %74 = load ptr, ptr %73, align 8, !tbaa !8
  %75 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %2, i32 0, i32 7, i32 0, i32 2
  %76 = load i64, ptr %75, align 8, !tbaa !8
  %77 = mul i64 %72, %76
  %78 = add i64 %77, 0
  %79 = getelementptr i8, ptr %74, i64 %78
  %80 = load double, ptr %79, align 8, !tbaa !4
  store double %80, ptr %8, align 8, !tbaa !4
  %81 = load i32, ptr %9, align 4, !tbaa !4
  %82 = add i32 %81, 1
  %83 = sub i64 %53, 1
  br label %51

84:                                               ; preds = %27, %51
  %85 = phi i32 [ %52, %51 ], [ %28, %27 ]
  store i32 %85, ptr %9, align 4, !tbaa !4
  ret void
}
*** IR Dump After SROAPass on _QFPloop ***
define void @_QFPloop(ptr %0, ptr %1, ptr %2, ptr nest %3) {
  %5 = getelementptr { ptr, ptr }, ptr %3, i32 0, i32 0
  %6 = load ptr, ptr %5, align 8, !tbaa !4
  %7 = getelementptr { ptr, ptr }, ptr %3, i32 0, i32 1
  %8 = load ptr, ptr %7, align 8, !tbaa !4
  %9 = load i32, ptr %0, align 4, !tbaa !4
  %10 = sext i32 %9 to i64
  %11 = load i32, ptr %1, align 4, !tbaa !4
  %12 = sext i32 %11 to i64
  %13 = trunc i64 %10 to i32
  %14 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %2, i32 0, i32 7, i64 0, i32 0
  %15 = load i64, ptr %14, align 8, !tbaa !8
  %16 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %2, i32 0, i32 7, i64 0, i32 1
  %17 = load i64, ptr %16, align 8, !tbaa !8
  %18 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %2, i32 0, i32 7, i64 0, i32 2
  %19 = load i64, ptr %18, align 8, !tbaa !8
  %20 = icmp eq i64 %19, 8
  br i1 %20, label %21, label %44

21:                                               ; preds = %4
  %22 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %2, i32 0, i32 0
  %23 = load ptr, ptr %22, align 8, !tbaa !8
  %24 = sub i64 %12, %10
  %25 = add i64 %24, 1
  br label %26

26:                                               ; preds = %30, %21
  %27 = phi i32 [ %42, %30 ], [ %13, %21 ]
  %28 = phi i64 [ %43, %30 ], [ %25, %21 ]
  %29 = icmp sgt i64 %28, 0
  br i1 %29, label %30, label %77

30:                                               ; preds = %26
  %31 = load i32, ptr %6, align 4, !tbaa !4
  %32 = sitofp i32 %31 to float
  %33 = fdiv contract float 1.000000e+00, %32
  %34 = fpext float %33 to double
  %35 = sext i32 %27 to i64
  %36 = sub i64 %35, 1
  %37 = getelementptr double, ptr %23, i64 %36
  store double %34, ptr %37, align 8, !tbaa !4
  %38 = sext i32 %27 to i64
  %39 = sub i64 %38, 1
  %40 = getelementptr double, ptr %23, i64 %39
  %41 = load double, ptr %40, align 8, !tbaa !4
  store double %41, ptr %8, align 8, !tbaa !4
  %42 = add i32 %27, 1
  %43 = sub i64 %28, 1
  br label %26

44:                                               ; preds = %4
  %45 = sub i64 %12, %10
  %46 = add i64 %45, 1
  br label %47

47:                                               ; preds = %51, %44
  %48 = phi i32 [ %75, %51 ], [ %13, %44 ]
  %49 = phi i64 [ %76, %51 ], [ %46, %44 ]
  %50 = icmp sgt i64 %49, 0
  br i1 %50, label %51, label %77

51:                                               ; preds = %47
  %52 = load i32, ptr %6, align 4, !tbaa !4
  %53 = sitofp i32 %52 to float
  %54 = fdiv contract float 1.000000e+00, %53
  %55 = fpext float %54 to double
  %56 = sext i32 %48 to i64
  %57 = sub i64 %56, 1
  %58 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %2, i32 0, i32 0
  %59 = load ptr, ptr %58, align 8, !tbaa !8
  %60 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %2, i32 0, i32 7, i32 0, i32 2
  %61 = load i64, ptr %60, align 8, !tbaa !8
  %62 = mul i64 %57, %61
  %63 = add i64 %62, 0
  %64 = getelementptr i8, ptr %59, i64 %63
  store double %55, ptr %64, align 8, !tbaa !4
  %65 = sext i32 %48 to i64
  %66 = sub i64 %65, 1
  %67 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %2, i32 0, i32 0
  %68 = load ptr, ptr %67, align 8, !tbaa !8
  %69 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %2, i32 0, i32 7, i32 0, i32 2
  %70 = load i64, ptr %69, align 8, !tbaa !8
  %71 = mul i64 %66, %70
  %72 = add i64 %71, 0
  %73 = getelementptr i8, ptr %68, i64 %72
  %74 = load double, ptr %73, align 8, !tbaa !4
  store double %74, ptr %8, align 8, !tbaa !4
  %75 = add i32 %48, 1
  %76 = sub i64 %49, 1
  br label %47

77:                                               ; preds = %26, %47
  %78 = phi i32 [ %48, %47 ], [ %27, %26 ]
  ret void
}
*** IR Dump After EarlyCSEPass on _QFPloop ***
define void @_QFPloop(ptr %0, ptr %1, ptr %2, ptr nest %3) {
  %5 = load ptr, ptr %3, align 8, !tbaa !4
  %6 = getelementptr { ptr, ptr }, ptr %3, i32 0, i32 1
  %7 = load ptr, ptr %6, align 8, !tbaa !4
  %8 = load i32, ptr %0, align 4, !tbaa !4
  %9 = sext i32 %8 to i64
  %10 = load i32, ptr %1, align 4, !tbaa !4
  %11 = sext i32 %10 to i64
  %12 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %2, i32 0, i32 7, i64 0, i32 0
  %13 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %2, i32 0, i32 7, i64 0, i32 1
  %14 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %2, i32 0, i32 7, i64 0, i32 2
  %15 = load i64, ptr %14, align 8, !tbaa !8
  %16 = icmp eq i64 %15, 8
  br i1 %16, label %17, label %35

17:                                               ; preds = %4
  %18 = load ptr, ptr %2, align 8, !tbaa !8
  %19 = sub i64 %11, %9
  %20 = add i64 %19, 1
  br label %21

21:                                               ; preds = %25, %17
  %22 = phi i32 [ %33, %25 ], [ %8, %17 ]
  %23 = phi i64 [ %34, %25 ], [ %20, %17 ]
  %24 = icmp sgt i64 %23, 0
  br i1 %24, label %25, label %61

25:                                               ; preds = %21
  %26 = load i32, ptr %5, align 4, !tbaa !4
  %27 = sitofp i32 %26 to float
  %28 = fdiv contract float 1.000000e+00, %27
  %29 = fpext float %28 to double
  %30 = sext i32 %22 to i64
  %31 = sub i64 %30, 1
  %32 = getelementptr double, ptr %18, i64 %31
  store double %29, ptr %32, align 8, !tbaa !4
  store double %29, ptr %7, align 8, !tbaa !4
  %33 = add i32 %22, 1
  %34 = sub i64 %23, 1
  br label %21

35:                                               ; preds = %4
  %36 = sub i64 %11, %9
  %37 = add i64 %36, 1
  br label %38

38:                                               ; preds = %42, %35
  %39 = phi i32 [ %59, %42 ], [ %8, %35 ]
  %40 = phi i64 [ %60, %42 ], [ %37, %35 ]
  %41 = icmp sgt i64 %40, 0
  br i1 %41, label %42, label %61

42:                                               ; preds = %38
  %43 = load i32, ptr %5, align 4, !tbaa !4
  %44 = sitofp i32 %43 to float
  %45 = fdiv contract float 1.000000e+00, %44
  %46 = fpext float %45 to double
  %47 = sext i32 %39 to i64
  %48 = sub i64 %47, 1
  %49 = load ptr, ptr %2, align 8, !tbaa !8
  %50 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %2, i32 0, i32 7, i32 0, i32 2
  %51 = load i64, ptr %50, align 8, !tbaa !8
  %52 = mul i64 %48, %51
  %53 = getelementptr i8, ptr %49, i64 %52
  store double %46, ptr %53, align 8, !tbaa !4
  %54 = load ptr, ptr %2, align 8, !tbaa !8
  %55 = load i64, ptr %50, align 8, !tbaa !8
  %56 = mul i64 %48, %55
  %57 = getelementptr i8, ptr %54, i64 %56
  %58 = load double, ptr %57, align 8, !tbaa !4
  store double %58, ptr %7, align 8, !tbaa !4
  %59 = add i32 %39, 1
  %60 = sub i64 %40, 1
  br label %38

61:                                               ; preds = %21, %38
  ret void
}
*** IR Dump After CallSiteSplittingPass on _QFPloop ***
define void @_QFPloop(ptr %0, ptr %1, ptr %2, ptr nest %3) {
  %5 = load ptr, ptr %3, align 8, !tbaa !4
  %6 = getelementptr { ptr, ptr }, ptr %3, i32 0, i32 1
  %7 = load ptr, ptr %6, align 8, !tbaa !4
  %8 = load i32, ptr %0, align 4, !tbaa !4
  %9 = sext i32 %8 to i64
  %10 = load i32, ptr %1, align 4, !tbaa !4
  %11 = sext i32 %10 to i64
  %12 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %2, i32 0, i32 7, i64 0, i32 0
  %13 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %2, i32 0, i32 7, i64 0, i32 1
  %14 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %2, i32 0, i32 7, i64 0, i32 2
  %15 = load i64, ptr %14, align 8, !tbaa !8
  %16 = icmp eq i64 %15, 8
  br i1 %16, label %17, label %35

17:                                               ; preds = %4
  %18 = load ptr, ptr %2, align 8, !tbaa !8
  %19 = sub i64 %11, %9
  %20 = add i64 %19, 1
  br label %21

21:                                               ; preds = %25, %17
  %22 = phi i32 [ %33, %25 ], [ %8, %17 ]
  %23 = phi i64 [ %34, %25 ], [ %20, %17 ]
  %24 = icmp sgt i64 %23, 0
  br i1 %24, label %25, label %61

25:                                               ; preds = %21
  %26 = load i32, ptr %5, align 4, !tbaa !4
  %27 = sitofp i32 %26 to float
  %28 = fdiv contract float 1.000000e+00, %27
  %29 = fpext float %28 to double
  %30 = sext i32 %22 to i64
  %31 = sub i64 %30, 1
  %32 = getelementptr double, ptr %18, i64 %31
  store double %29, ptr %32, align 8, !tbaa !4
  store double %29, ptr %7, align 8, !tbaa !4
  %33 = add i32 %22, 1
  %34 = sub i64 %23, 1
  br label %21

35:                                               ; preds = %4
  %36 = sub i64 %11, %9
  %37 = add i64 %36, 1
  br label %38

38:                                               ; preds = %42, %35
  %39 = phi i32 [ %59, %42 ], [ %8, %35 ]
  %40 = phi i64 [ %60, %42 ], [ %37, %35 ]
  %41 = icmp sgt i64 %40, 0
  br i1 %41, label %42, label %61

42:                                               ; preds = %38
  %43 = load i32, ptr %5, align 4, !tbaa !4
  %44 = sitofp i32 %43 to float
  %45 = fdiv contract float 1.000000e+00, %44
  %46 = fpext float %45 to double
  %47 = sext i32 %39 to i64
  %48 = sub i64 %47, 1
  %49 = load ptr, ptr %2, align 8, !tbaa !8
  %50 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %2, i32 0, i32 7, i32 0, i32 2
  %51 = load i64, ptr %50, align 8, !tbaa !8
  %52 = mul i64 %48, %51
  %53 = getelementptr i8, ptr %49, i64 %52
  store double %46, ptr %53, align 8, !tbaa !4
  %54 = load ptr, ptr %2, align 8, !tbaa !8
  %55 = load i64, ptr %50, align 8, !tbaa !8
  %56 = mul i64 %48, %55
  %57 = getelementptr i8, ptr %54, i64 %56
  %58 = load double, ptr %57, align 8, !tbaa !4
  store double %58, ptr %7, align 8, !tbaa !4
  %59 = add i32 %39, 1
  %60 = sub i64 %40, 1
  br label %38

61:                                               ; preds = %21, %38
  ret void
}
*** IR Dump After OpenMPOptPass on [module] ***
; ModuleID = 'FIRModule'
source_filename = "FIRModule"
target datalayout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128"
target triple = "x86_64-unknown-linux-gnu"

%struct.ident_t = type { i32, i32, i32, i32, ptr }

@_QMomp_libEComp_allocator_handle_kind = external constant i32
@_QMomp_libEComp_alloctrait_key_kind = external constant i32
@_QMomp_libEComp_alloctrait_val_kind = external constant i32
@_QMomp_libEComp_allow_completion_event = external constant i32
@_QMomp_libEComp_atk_access = external constant i32
@_QMomp_libEComp_atk_alignment = external constant i32
@_QMomp_libEComp_atk_fallback = external constant i32
@_QMomp_libEComp_atk_fb_data = external constant i32
@_QMomp_libEComp_atk_partition = external constant i32
@_QMomp_libEComp_atk_pinned = external constant i32
@_QMomp_libEComp_atk_pool_size = external constant i32
@_QMomp_libEComp_atk_sync_hint = external constant i32
@_QMomp_libEComp_atv_abort_fb = external constant i32
@_QMomp_libEComp_atv_all = external constant i32
@_QMomp_libEComp_atv_allocator_fb = external constant i32
@_QMomp_libEComp_atv_blocked = external constant i32
@_QMomp_libEComp_atv_cgroup = external constant i32
@_QMomp_libEComp_atv_contended = external constant i32
@_QMomp_libEComp_atv_default = external constant i32
@_QMomp_libEComp_atv_default_mem_fb = external constant i32
@_QMomp_libEComp_atv_environment = external constant i32
@_QMomp_libEComp_atv_false = external constant i32
@_QMomp_libEComp_atv_interleaved = external constant i32
@_QMomp_libEComp_atv_nearest = external constant i32
@_QMomp_libEComp_atv_null_fb = external constant i32
@_QMomp_libEComp_atv_private = external constant i32
@_QMomp_libEComp_atv_pteam = external constant i32
@_QMomp_libEComp_atv_sequential = external constant i32
@_QMomp_libEComp_atv_thread = external constant i32
@_QMomp_libEComp_atv_true = external constant i32
@_QMomp_libEComp_atv_uncontended = external constant i32
@_QMomp_libEComp_cgroup_mem_alloc = external constant i32
@_QMomp_libEComp_const_mem_alloc = external constant i32
@_QMomp_libEComp_const_mem_space = external constant i32
@_QMomp_libEComp_default_mem_alloc = external constant i32
@_QMomp_libEComp_default_mem_space = external constant i32
@_QMomp_libEComp_depend_kind = external constant i32
@_QMomp_libEComp_event_handle_kind = external constant i32
@_QMomp_libEComp_high_bw_mem_alloc = external constant i32
@_QMomp_libEComp_high_bw_mem_space = external constant i32
@_QMomp_libEComp_integer_kind = external constant i32
@_QMomp_libEComp_large_cap_mem_alloc = external constant i32
@_QMomp_libEComp_large_cap_mem_space = external constant i32
@_QMomp_libEComp_lock_hint_contended = external constant i32
@_QMomp_libEComp_lock_hint_kind = external constant i32
@_QMomp_libEComp_lock_hint_none = external constant i32
@_QMomp_libEComp_lock_hint_nonspeculative = external constant i32
@_QMomp_libEComp_lock_hint_speculative = external constant i32
@_QMomp_libEComp_lock_hint_uncontended = external constant i32
@_QMomp_libEComp_lock_kind = external constant i32
@_QMomp_libEComp_logical_kind = external constant i32
@_QMomp_libEComp_low_lat_mem_alloc = external constant i32
@_QMomp_libEComp_low_lat_mem_space = external constant i32
@_QMomp_libEComp_memspace_handle_kind = external constant i32
@_QMomp_libEComp_nest_lock_kind = external constant i32
@_QMomp_libEComp_null_allocator = external constant i32
@_QMomp_libEComp_pause_hard = external constant i32
@_QMomp_libEComp_pause_resource_kind = external constant i32
@_QMomp_libEComp_pause_soft = external constant i32
@_QMomp_libEComp_proc_bind_close = external constant i32
@_QMomp_libEComp_proc_bind_false = external constant i32
@_QMomp_libEComp_proc_bind_kind = external constant i32
@_QMomp_libEComp_proc_bind_master = external constant i32
@_QMomp_libEComp_proc_bind_spread = external constant i32
@_QMomp_libEComp_proc_bind_true = external constant i32
@_QMomp_libEComp_pteam_mem_alloc = external constant i32
@_QMomp_libEComp_sched_auto = external constant i32
@_QMomp_libEComp_sched_dynamic = external constant i32
@_QMomp_libEComp_sched_guided = external constant i32
@_QMomp_libEComp_sched_kind = external constant i32
@_QMomp_libEComp_sched_static = external constant i32
@_QMomp_libEComp_sync_hint_contended = external constant i32
@_QMomp_libEComp_sync_hint_kind = external constant i32
@_QMomp_libEComp_sync_hint_none = external constant i32
@_QMomp_libEComp_sync_hint_nonspeculative = external constant i32
@_QMomp_libEComp_sync_hint_speculative = external constant i32
@_QMomp_libEComp_sync_hint_uncontended = external constant i32
@_QMomp_libEComp_task_fulfill_event = external constant i32
@_QMomp_libEComp_thread_mem_alloc = external constant i32
@_QMomp_libECopenmp_version = external constant i32
@_QQcl.28612C69372C612C6531332E36653229 = internal constant [16 x i8] c"(a,i7,a,e13.6e2)"
@_QQcl.e8a0ac9186c064ac8543d822e9060d96 = internal constant [59 x i8] c"/g/g92/rydahl1/flangtests/src/parallel_region_outlined.f90\00"
@_QQcl.54686520726573756C74206F6620286172722831292B61727228 = internal constant [26 x i8] c"The result of (arr(1)+arr("
@_QQcl.2920697320 = internal constant [5 x i8] c") is "
@_QQEnvironmentDefaults = constant ptr null
@0 = private unnamed_addr constant [23 x i8] c";unknown;unknown;0;0;;\00", align 1
@1 = private unnamed_addr constant %struct.ident_t { i32 0, i32 2, i32 0, i32 22, ptr @0 }, align 8

; Function Attrs: mustprogress nofree nounwind willreturn allockind("alloc,uninitialized") allocsize(0) memory(inaccessiblemem: readwrite)
declare noalias noundef ptr @malloc(i64 noundef) #0

; Function Attrs: mustprogress nounwind willreturn allockind("free") memory(argmem: readwrite, inaccessiblemem: readwrite)
declare void @free(ptr allocptr nocapture noundef) #1

define void @_QQmain() {
  %1 = alloca i32, i64 1, align 4
  %2 = alloca double, i64 1, align 8
  %3 = alloca double, i64 1, align 8
  %4 = alloca { ptr, ptr }, i64 1, align 8
  store ptr %1, ptr %4, align 8, !tbaa !4
  %5 = getelementptr { ptr, ptr }, ptr %4, i32 0, i32 1
  store ptr %3, ptr %5, align 8, !tbaa !4
  store i32 1048576, ptr %1, align 4, !tbaa !4
  call void @_QFPomp_subroutine(ptr %1, ptr %2, ptr %4)
  %6 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr @_QQcl.e8a0ac9186c064ac8543d822e9060d96, i32 10)
  %7 = call i1 @_FortranAioOutputAscii(ptr %6, ptr @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %8 = load i32, ptr %1, align 4, !tbaa !4
  %9 = call i1 @_FortranAioOutputInteger32(ptr %6, i32 %8)
  %10 = call i1 @_FortranAioOutputAscii(ptr %6, ptr @_QQcl.2920697320, i64 5)
  %11 = load double, ptr %2, align 8, !tbaa !4
  %12 = call i1 @_FortranAioOutputReal64(ptr %6, double %11)
  %13 = call i32 @_FortranAioEndIoStatement(ptr %6)
  ret void
}

define void @_QFPomp_subroutine(ptr %0, ptr %1, ptr nest %2) {
entry:
  %structArg = alloca { ptr, ptr, ptr, ptr, ptr }, align 8
  %3 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %4 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %5 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, i64 1, align 8
  store ptr null, ptr %5, align 8, !tbaa !8
  %.fca.1.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i32 0, i32 1
  store i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), ptr %.fca.1.gep, align 8, !tbaa !8
  %.fca.2.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i32 0, i32 2
  store i32 20180515, ptr %.fca.2.gep, align 8, !tbaa !8
  %.fca.3.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i32 0, i32 3
  store i8 1, ptr %.fca.3.gep, align 4, !tbaa !8
  %.fca.4.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i32 0, i32 4
  store i8 28, ptr %.fca.4.gep, align 1, !tbaa !8
  %.fca.5.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i32 0, i32 5
  store i8 2, ptr %.fca.5.gep, align 2, !tbaa !8
  %.fca.6.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i32 0, i32 6
  store i8 0, ptr %.fca.6.gep, align 1, !tbaa !8
  %.fca.7.0.0.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i32 0, i32 7, i32 0, i32 0
  store i64 1, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  %.fca.7.0.1.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i32 0, i32 7, i32 0, i32 1
  store i64 0, ptr %.fca.7.0.1.gep, align 8, !tbaa !8
  %.fca.7.0.2.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i32 0, i32 7, i32 0, i32 2
  store i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), ptr %.fca.7.0.2.gep, align 8, !tbaa !8
  %6 = load i32, ptr %0, align 4, !tbaa !4
  %7 = sext i32 %6 to i64
  %8 = icmp sgt i64 %7, 0
  %9 = select i1 %8, i64 %7, i64 0
  %10 = mul i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), %9
  %11 = call ptr @malloc(i64 %10)
  %12 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } { ptr undef, i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), i32 20180515, i8 1, i8 28, i8 2, i8 0, [1 x [3 x i64]] [[3 x i64] [i64 1, i64 undef, i64 undef]] }, i64 %9, 7, 0, 1
  %13 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %12, i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), 7, 0, 2
  %14 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %13, ptr %11, 0
  %.fca.1.extract170 = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %14, 1
  %.fca.2.extract172 = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %14, 2
  %.fca.3.extract174 = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %14, 3
  %.fca.4.extract176 = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %14, 4
  %.fca.5.extract178 = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %14, 5
  %.fca.6.extract180 = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %14, 6
  %.fca.7.0.0.extract182 = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %14, 7, 0, 0
  %.fca.0.insert190 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } poison, ptr %11, 0
  %.fca.1.insert193 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.0.insert190, i64 %.fca.1.extract170, 1
  %.fca.2.insert196 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.1.insert193, i32 %.fca.2.extract172, 2
  %.fca.3.insert199 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.2.insert196, i8 %.fca.3.extract174, 3
  %.fca.4.insert202 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.3.insert199, i8 %.fca.4.extract176, 4
  %.fca.5.insert205 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.4.insert202, i8 %.fca.5.extract178, 5
  %.fca.6.insert208 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.5.insert205, i8 %.fca.6.extract180, 6
  %.fca.7.0.0.insert211 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.6.insert208, i64 %.fca.7.0.0.extract182, 7, 0, 0
  %.fca.7.0.1.insert214 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.7.0.0.insert211, i64 %9, 7, 0, 1
  %.fca.7.0.2.insert217 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.7.0.1.insert214, i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), 7, 0, 2
  store ptr %11, ptr %5, align 8, !tbaa !8
  store i64 %.fca.1.extract170, ptr %.fca.1.gep, align 8, !tbaa !8
  store i32 %.fca.2.extract172, ptr %.fca.2.gep, align 8, !tbaa !8
  store i8 %.fca.3.extract174, ptr %.fca.3.gep, align 4, !tbaa !8
  store i8 %.fca.4.extract176, ptr %.fca.4.gep, align 1, !tbaa !8
  store i8 %.fca.5.extract178, ptr %.fca.5.gep, align 2, !tbaa !8
  store i8 %.fca.6.extract180, ptr %.fca.6.gep, align 1, !tbaa !8
  store i64 %.fca.7.0.0.extract182, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  store i64 %9, ptr %.fca.7.0.1.gep, align 8, !tbaa !8
  store i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), ptr %.fca.7.0.2.gep, align 8, !tbaa !8
  %omp_global_thread_num = call i32 @__kmpc_global_thread_num(ptr @1)
  store ptr %0, ptr %structArg, align 8
  %gep_5 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i32 0, i32 1
  store ptr %5, ptr %gep_5, align 8
  %gep_6 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i32 0, i32 2
  store ptr %4, ptr %gep_6, align 8
  %gep_7 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i32 0, i32 3
  store ptr %3, ptr %gep_7, align 8
  %gep_8 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i32 0, i32 4
  store ptr %2, ptr %gep_8, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr @1, i32 1, ptr @_QFPomp_subroutine..omp_par, ptr %structArg)
  %.fca.0.load = load ptr, ptr %5, align 8, !tbaa !8
  %.fca.0.insert = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } poison, ptr %.fca.0.load, 0
  %.fca.1.load = load i64, ptr %.fca.1.gep, align 8, !tbaa !8
  %.fca.1.insert = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.0.insert, i64 %.fca.1.load, 1
  %.fca.2.load = load i32, ptr %.fca.2.gep, align 8, !tbaa !8
  %.fca.2.insert = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.1.insert, i32 %.fca.2.load, 2
  %.fca.3.load = load i8, ptr %.fca.3.gep, align 4, !tbaa !8
  %.fca.3.insert = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.2.insert, i8 %.fca.3.load, 3
  %.fca.4.load = load i8, ptr %.fca.4.gep, align 1, !tbaa !8
  %.fca.4.insert = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.3.insert, i8 %.fca.4.load, 4
  %.fca.5.load = load i8, ptr %.fca.5.gep, align 2, !tbaa !8
  %.fca.5.insert = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.4.insert, i8 %.fca.5.load, 5
  %.fca.6.load = load i8, ptr %.fca.6.gep, align 1, !tbaa !8
  %.fca.6.insert = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.5.insert, i8 %.fca.6.load, 6
  %.fca.7.0.0.load = load i64, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  %.fca.7.0.0.insert = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.6.insert, i64 %.fca.7.0.0.load, 7, 0, 0
  %.fca.7.0.1.load = load i64, ptr %.fca.7.0.1.gep, align 8, !tbaa !8
  %.fca.7.0.1.insert = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.7.0.0.insert, i64 %.fca.7.0.1.load, 7, 0, 1
  %.fca.7.0.2.load = load i64, ptr %.fca.7.0.2.gep, align 8, !tbaa !8
  %.fca.7.0.2.insert = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.7.0.1.insert, i64 %.fca.7.0.2.load, 7, 0, 2
  %15 = sub i64 1, %.fca.7.0.0.load
  %16 = getelementptr double, ptr %.fca.0.load, i64 %15
  %17 = load double, ptr %16, align 8, !tbaa !4
  %18 = load i32, ptr %0, align 4, !tbaa !4
  %19 = sext i32 %18 to i64
  %20 = sub i64 %19, %.fca.7.0.0.load
  %21 = getelementptr double, ptr %.fca.0.load, i64 %20
  %22 = load double, ptr %21, align 8, !tbaa !4
  %23 = fadd contract double %17, %22
  store double %23, ptr %1, align 8, !tbaa !4
  %.fca.0.load40 = load ptr, ptr %5, align 8, !tbaa !8
  %.fca.0.insert41 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } poison, ptr %.fca.0.load40, 0
  %.fca.1.load43 = load i64, ptr %.fca.1.gep, align 8, !tbaa !8
  %.fca.1.insert44 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.0.insert41, i64 %.fca.1.load43, 1
  %.fca.2.load46 = load i32, ptr %.fca.2.gep, align 8, !tbaa !8
  %.fca.2.insert47 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.1.insert44, i32 %.fca.2.load46, 2
  %.fca.3.load49 = load i8, ptr %.fca.3.gep, align 4, !tbaa !8
  %.fca.3.insert50 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.2.insert47, i8 %.fca.3.load49, 3
  %.fca.4.load52 = load i8, ptr %.fca.4.gep, align 1, !tbaa !8
  %.fca.4.insert53 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.3.insert50, i8 %.fca.4.load52, 4
  %.fca.5.load55 = load i8, ptr %.fca.5.gep, align 2, !tbaa !8
  %.fca.5.insert56 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.4.insert53, i8 %.fca.5.load55, 5
  %.fca.6.load58 = load i8, ptr %.fca.6.gep, align 1, !tbaa !8
  %.fca.6.insert59 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.5.insert56, i8 %.fca.6.load58, 6
  %.fca.7.0.0.load61 = load i64, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  %.fca.7.0.0.insert62 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.6.insert59, i64 %.fca.7.0.0.load61, 7, 0, 0
  %.fca.7.0.1.load64 = load i64, ptr %.fca.7.0.1.gep, align 8, !tbaa !8
  %.fca.7.0.1.insert65 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.7.0.0.insert62, i64 %.fca.7.0.1.load64, 7, 0, 1
  %.fca.7.0.2.load67 = load i64, ptr %.fca.7.0.2.gep, align 8, !tbaa !8
  %.fca.7.0.2.insert68 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.7.0.1.insert65, i64 %.fca.7.0.2.load67, 7, 0, 2
  call void @free(ptr %.fca.0.load40)
  store ptr null, ptr %5, align 8, !tbaa !8
  store i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), ptr %.fca.1.gep, align 8, !tbaa !8
  store i32 20180515, ptr %.fca.2.gep, align 8, !tbaa !8
  store i8 1, ptr %.fca.3.gep, align 4, !tbaa !8
  store i8 28, ptr %.fca.4.gep, align 1, !tbaa !8
  store i8 2, ptr %.fca.5.gep, align 2, !tbaa !8
  store i8 0, ptr %.fca.6.gep, align 1, !tbaa !8
  store i64 1, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  store i64 0, ptr %.fca.7.0.1.gep, align 8, !tbaa !8
  store i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), ptr %.fca.7.0.2.gep, align 8, !tbaa !8
  ret void
}

; Function Attrs: norecurse nounwind
define internal void @_QFPomp_subroutine..omp_par(ptr noalias %tid.addr, ptr noalias %zero.addr, ptr %0) #2 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i32 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %gep_3 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i32 0, i32 2
  %loadgep_4 = load ptr, ptr %gep_3, align 8
  %gep_5 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i32 0, i32 3
  %loadgep_6 = load ptr, ptr %gep_5, align 8
  %gep_7 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i32 0, i32 4
  %loadgep_8 = load ptr, ptr %gep_7, align 8
  %1 = alloca i32, i64 1, align 4
  %2 = alloca i32, i64 1, align 4
  %3 = call i32 @omp_get_thread_num()
  %4 = call i32 @omp_get_num_threads()
  %5 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %6 = sdiv i32 %5, %4
  %7 = mul i32 %3, %6
  %8 = add i32 %7, 1
  store i32 %8, ptr %1, align 4, !tbaa !4
  %9 = sub i32 %4, 1
  %10 = icmp eq i32 %3, %9
  br i1 %10, label %omp.par.region2, label %omp.par.region3

omp.par.region3:                                  ; preds = %omp.par.entry
  %11 = add i32 %8, %6
  store i32 %11, ptr %2, align 4, !tbaa !4
  br label %omp.par.region4

omp.par.region4:                                  ; preds = %omp.par.region2, %omp.par.region3
  %12 = load { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, align 8, !tbaa !8
  store { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %12, ptr %loadgep_4, align 8, !tbaa !8
  %13 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i32 0, i32 7, i64 0, i32 0
  %14 = load i64, ptr %13, align 8, !tbaa !8
  %15 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i32 0, i32 7, i64 0, i32 1
  %16 = load i64, ptr %15, align 8, !tbaa !8
  %17 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i32 0, i32 7, i64 0, i32 2
  %18 = load ptr, ptr %loadgep_4, align 8, !tbaa !8
  %19 = icmp eq i64 %16, 0
  %20 = select i1 %19, i64 1, i64 %14
  %21 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } { ptr undef, i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), i32 20180515, i8 1, i8 28, i8 0, i8 0, [1 x [3 x i64]] undef }, i64 %20, 7, 0, 0
  %22 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %21, i64 %16, 7, 0, 1
  %23 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %22, i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), 7, 0, 2
  %24 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %23, ptr %18, 0
  store { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %24, ptr %loadgep_6, align 8, !tbaa !8
  call void @_QFPloop(ptr %1, ptr %2, ptr %loadgep_6, ptr %loadgep_8)
  ret void

omp.par.region2:                                  ; preds = %omp.par.entry
  %25 = load i32, ptr %loadgep_, align 4, !tbaa !4
  store i32 %25, ptr %2, align 4, !tbaa !4
  br label %omp.par.region4
}

define void @_QFPloop(ptr %0, ptr %1, ptr %2, ptr nest %3) {
  %5 = load ptr, ptr %3, align 8, !tbaa !4
  %6 = getelementptr { ptr, ptr }, ptr %3, i32 0, i32 1
  %7 = load ptr, ptr %6, align 8, !tbaa !4
  %8 = load i32, ptr %0, align 4, !tbaa !4
  %9 = sext i32 %8 to i64
  %10 = load i32, ptr %1, align 4, !tbaa !4
  %11 = sext i32 %10 to i64
  %12 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %2, i32 0, i32 7, i64 0, i32 0
  %13 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %2, i32 0, i32 7, i64 0, i32 1
  %14 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %2, i32 0, i32 7, i64 0, i32 2
  %15 = load i64, ptr %14, align 8, !tbaa !8
  %16 = icmp eq i64 %15, 8
  br i1 %16, label %17, label %35

17:                                               ; preds = %4
  %18 = load ptr, ptr %2, align 8, !tbaa !8
  %19 = sub i64 %11, %9
  %20 = add i64 %19, 1
  br label %21

21:                                               ; preds = %25, %17
  %22 = phi i32 [ %33, %25 ], [ %8, %17 ]
  %23 = phi i64 [ %34, %25 ], [ %20, %17 ]
  %24 = icmp sgt i64 %23, 0
  br i1 %24, label %25, label %61

25:                                               ; preds = %21
  %26 = load i32, ptr %5, align 4, !tbaa !4
  %27 = sitofp i32 %26 to float
  %28 = fdiv contract float 1.000000e+00, %27
  %29 = fpext float %28 to double
  %30 = sext i32 %22 to i64
  %31 = sub i64 %30, 1
  %32 = getelementptr double, ptr %18, i64 %31
  store double %29, ptr %32, align 8, !tbaa !4
  store double %29, ptr %7, align 8, !tbaa !4
  %33 = add i32 %22, 1
  %34 = sub i64 %23, 1
  br label %21

35:                                               ; preds = %4
  %36 = sub i64 %11, %9
  %37 = add i64 %36, 1
  br label %38

38:                                               ; preds = %42, %35
  %39 = phi i32 [ %59, %42 ], [ %8, %35 ]
  %40 = phi i64 [ %60, %42 ], [ %37, %35 ]
  %41 = icmp sgt i64 %40, 0
  br i1 %41, label %42, label %61

42:                                               ; preds = %38
  %43 = load i32, ptr %5, align 4, !tbaa !4
  %44 = sitofp i32 %43 to float
  %45 = fdiv contract float 1.000000e+00, %44
  %46 = fpext float %45 to double
  %47 = sext i32 %39 to i64
  %48 = sub i64 %47, 1
  %49 = load ptr, ptr %2, align 8, !tbaa !8
  %50 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %2, i32 0, i32 7, i32 0, i32 2
  %51 = load i64, ptr %50, align 8, !tbaa !8
  %52 = mul i64 %48, %51
  %53 = getelementptr i8, ptr %49, i64 %52
  store double %46, ptr %53, align 8, !tbaa !4
  %54 = load ptr, ptr %2, align 8, !tbaa !8
  %55 = load i64, ptr %50, align 8, !tbaa !8
  %56 = mul i64 %48, %55
  %57 = getelementptr i8, ptr %54, i64 %56
  %58 = load double, ptr %57, align 8, !tbaa !4
  store double %58, ptr %7, align 8, !tbaa !4
  %59 = add i32 %39, 1
  %60 = sub i64 %40, 1
  br label %38

61:                                               ; preds = %21, %38
  ret void
}

declare ptr @_FortranAioBeginExternalFormattedOutput(ptr, i64, ptr, i32, ptr, i32)

declare zeroext i1 @_FortranAioOutputAscii(ptr, ptr, i64)

declare zeroext i1 @_FortranAioOutputInteger32(ptr, i32)

declare zeroext i1 @_FortranAioOutputReal64(ptr, double)

declare i32 @_FortranAioEndIoStatement(ptr)

; Function Attrs: nounwind
declare i32 @omp_get_thread_num() #3

; Function Attrs: nounwind
declare i32 @omp_get_num_threads() #3

; Function Attrs: mustprogress nocallback nofree nosync nounwind willreturn
declare ptr @llvm.stacksave() #4

; Function Attrs: mustprogress nocallback nofree nosync nounwind willreturn
declare void @llvm.stackrestore(ptr) #4

; Function Attrs: nounwind
declare i32 @__kmpc_global_thread_num(ptr) #3

; Function Attrs: nounwind
declare !callback !10 void @__kmpc_fork_call(ptr, i32, ptr, ...) #3

attributes #0 = { mustprogress nofree nounwind willreturn allockind("alloc,uninitialized") allocsize(0) memory(inaccessiblemem: readwrite) "alloc-family"="malloc" }
attributes #1 = { mustprogress nounwind willreturn allockind("free") memory(argmem: readwrite, inaccessiblemem: readwrite) "alloc-family"="malloc" }
attributes #2 = { norecurse nounwind }
attributes #3 = { nounwind }
attributes #4 = { mustprogress nocallback nofree nosync nounwind willreturn }

!llvm.module.flags = !{!0, !1, !2, !3}

!0 = !{i32 2, !"Debug Info Version", i32 3}
!1 = !{i32 7, !"openmp", i32 11}
!2 = !{i32 8, !"PIC Level", i32 2}
!3 = !{i32 7, !"PIE Level", i32 2}
!4 = !{!5, !5, i64 0}
!5 = !{!"any data access", !6, i64 0}
!6 = !{!"any access", !7, i64 0}
!7 = !{!"Flang Type TBAA Root"}
!8 = !{!9, !9, i64 0}
!9 = !{!"descriptor member", !6, i64 0}
!10 = !{!11}
!11 = !{i64 2, i64 -1, i64 -1, i1 true}
*** IR Dump After IPSCCPPass on [module] ***
; ModuleID = 'FIRModule'
source_filename = "FIRModule"
target datalayout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128"
target triple = "x86_64-unknown-linux-gnu"

%struct.ident_t = type { i32, i32, i32, i32, ptr }

@_QMomp_libEComp_allocator_handle_kind = external constant i32
@_QMomp_libEComp_alloctrait_key_kind = external constant i32
@_QMomp_libEComp_alloctrait_val_kind = external constant i32
@_QMomp_libEComp_allow_completion_event = external constant i32
@_QMomp_libEComp_atk_access = external constant i32
@_QMomp_libEComp_atk_alignment = external constant i32
@_QMomp_libEComp_atk_fallback = external constant i32
@_QMomp_libEComp_atk_fb_data = external constant i32
@_QMomp_libEComp_atk_partition = external constant i32
@_QMomp_libEComp_atk_pinned = external constant i32
@_QMomp_libEComp_atk_pool_size = external constant i32
@_QMomp_libEComp_atk_sync_hint = external constant i32
@_QMomp_libEComp_atv_abort_fb = external constant i32
@_QMomp_libEComp_atv_all = external constant i32
@_QMomp_libEComp_atv_allocator_fb = external constant i32
@_QMomp_libEComp_atv_blocked = external constant i32
@_QMomp_libEComp_atv_cgroup = external constant i32
@_QMomp_libEComp_atv_contended = external constant i32
@_QMomp_libEComp_atv_default = external constant i32
@_QMomp_libEComp_atv_default_mem_fb = external constant i32
@_QMomp_libEComp_atv_environment = external constant i32
@_QMomp_libEComp_atv_false = external constant i32
@_QMomp_libEComp_atv_interleaved = external constant i32
@_QMomp_libEComp_atv_nearest = external constant i32
@_QMomp_libEComp_atv_null_fb = external constant i32
@_QMomp_libEComp_atv_private = external constant i32
@_QMomp_libEComp_atv_pteam = external constant i32
@_QMomp_libEComp_atv_sequential = external constant i32
@_QMomp_libEComp_atv_thread = external constant i32
@_QMomp_libEComp_atv_true = external constant i32
@_QMomp_libEComp_atv_uncontended = external constant i32
@_QMomp_libEComp_cgroup_mem_alloc = external constant i32
@_QMomp_libEComp_const_mem_alloc = external constant i32
@_QMomp_libEComp_const_mem_space = external constant i32
@_QMomp_libEComp_default_mem_alloc = external constant i32
@_QMomp_libEComp_default_mem_space = external constant i32
@_QMomp_libEComp_depend_kind = external constant i32
@_QMomp_libEComp_event_handle_kind = external constant i32
@_QMomp_libEComp_high_bw_mem_alloc = external constant i32
@_QMomp_libEComp_high_bw_mem_space = external constant i32
@_QMomp_libEComp_integer_kind = external constant i32
@_QMomp_libEComp_large_cap_mem_alloc = external constant i32
@_QMomp_libEComp_large_cap_mem_space = external constant i32
@_QMomp_libEComp_lock_hint_contended = external constant i32
@_QMomp_libEComp_lock_hint_kind = external constant i32
@_QMomp_libEComp_lock_hint_none = external constant i32
@_QMomp_libEComp_lock_hint_nonspeculative = external constant i32
@_QMomp_libEComp_lock_hint_speculative = external constant i32
@_QMomp_libEComp_lock_hint_uncontended = external constant i32
@_QMomp_libEComp_lock_kind = external constant i32
@_QMomp_libEComp_logical_kind = external constant i32
@_QMomp_libEComp_low_lat_mem_alloc = external constant i32
@_QMomp_libEComp_low_lat_mem_space = external constant i32
@_QMomp_libEComp_memspace_handle_kind = external constant i32
@_QMomp_libEComp_nest_lock_kind = external constant i32
@_QMomp_libEComp_null_allocator = external constant i32
@_QMomp_libEComp_pause_hard = external constant i32
@_QMomp_libEComp_pause_resource_kind = external constant i32
@_QMomp_libEComp_pause_soft = external constant i32
@_QMomp_libEComp_proc_bind_close = external constant i32
@_QMomp_libEComp_proc_bind_false = external constant i32
@_QMomp_libEComp_proc_bind_kind = external constant i32
@_QMomp_libEComp_proc_bind_master = external constant i32
@_QMomp_libEComp_proc_bind_spread = external constant i32
@_QMomp_libEComp_proc_bind_true = external constant i32
@_QMomp_libEComp_pteam_mem_alloc = external constant i32
@_QMomp_libEComp_sched_auto = external constant i32
@_QMomp_libEComp_sched_dynamic = external constant i32
@_QMomp_libEComp_sched_guided = external constant i32
@_QMomp_libEComp_sched_kind = external constant i32
@_QMomp_libEComp_sched_static = external constant i32
@_QMomp_libEComp_sync_hint_contended = external constant i32
@_QMomp_libEComp_sync_hint_kind = external constant i32
@_QMomp_libEComp_sync_hint_none = external constant i32
@_QMomp_libEComp_sync_hint_nonspeculative = external constant i32
@_QMomp_libEComp_sync_hint_speculative = external constant i32
@_QMomp_libEComp_sync_hint_uncontended = external constant i32
@_QMomp_libEComp_task_fulfill_event = external constant i32
@_QMomp_libEComp_thread_mem_alloc = external constant i32
@_QMomp_libECopenmp_version = external constant i32
@_QQcl.28612C69372C612C6531332E36653229 = internal constant [16 x i8] c"(a,i7,a,e13.6e2)"
@_QQcl.e8a0ac9186c064ac8543d822e9060d96 = internal constant [59 x i8] c"/g/g92/rydahl1/flangtests/src/parallel_region_outlined.f90\00"
@_QQcl.54686520726573756C74206F6620286172722831292B61727228 = internal constant [26 x i8] c"The result of (arr(1)+arr("
@_QQcl.2920697320 = internal constant [5 x i8] c") is "
@_QQEnvironmentDefaults = constant ptr null
@0 = private unnamed_addr constant [23 x i8] c";unknown;unknown;0;0;;\00", align 1
@1 = private unnamed_addr constant %struct.ident_t { i32 0, i32 2, i32 0, i32 22, ptr @0 }, align 8

; Function Attrs: mustprogress nofree nounwind willreturn allockind("alloc,uninitialized") allocsize(0) memory(inaccessiblemem: readwrite)
declare noalias noundef ptr @malloc(i64 noundef) #0

; Function Attrs: mustprogress nounwind willreturn allockind("free") memory(argmem: readwrite, inaccessiblemem: readwrite)
declare void @free(ptr allocptr nocapture noundef) #1

define void @_QQmain() {
  %1 = alloca i32, i64 1, align 4
  %2 = alloca double, i64 1, align 8
  %3 = alloca double, i64 1, align 8
  %4 = alloca { ptr, ptr }, i64 1, align 8
  store ptr %1, ptr %4, align 8, !tbaa !4
  %5 = getelementptr { ptr, ptr }, ptr %4, i32 0, i32 1
  store ptr %3, ptr %5, align 8, !tbaa !4
  store i32 1048576, ptr %1, align 4, !tbaa !4
  call void @_QFPomp_subroutine(ptr %1, ptr %2, ptr %4)
  %6 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr @_QQcl.e8a0ac9186c064ac8543d822e9060d96, i32 10)
  %7 = call i1 @_FortranAioOutputAscii(ptr %6, ptr @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %8 = load i32, ptr %1, align 4, !tbaa !4
  %9 = call i1 @_FortranAioOutputInteger32(ptr %6, i32 %8)
  %10 = call i1 @_FortranAioOutputAscii(ptr %6, ptr @_QQcl.2920697320, i64 5)
  %11 = load double, ptr %2, align 8, !tbaa !4
  %12 = call i1 @_FortranAioOutputReal64(ptr %6, double %11)
  %13 = call i32 @_FortranAioEndIoStatement(ptr %6)
  ret void
}

define void @_QFPomp_subroutine(ptr %0, ptr %1, ptr nest %2) {
entry:
  %structArg = alloca { ptr, ptr, ptr, ptr, ptr }, align 8
  %3 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %4 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %5 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, i64 1, align 8
  store ptr null, ptr %5, align 8, !tbaa !8
  %.fca.1.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i32 0, i32 1
  store i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), ptr %.fca.1.gep, align 8, !tbaa !8
  %.fca.2.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i32 0, i32 2
  store i32 20180515, ptr %.fca.2.gep, align 8, !tbaa !8
  %.fca.3.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i32 0, i32 3
  store i8 1, ptr %.fca.3.gep, align 4, !tbaa !8
  %.fca.4.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i32 0, i32 4
  store i8 28, ptr %.fca.4.gep, align 1, !tbaa !8
  %.fca.5.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i32 0, i32 5
  store i8 2, ptr %.fca.5.gep, align 2, !tbaa !8
  %.fca.6.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i32 0, i32 6
  store i8 0, ptr %.fca.6.gep, align 1, !tbaa !8
  %.fca.7.0.0.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i32 0, i32 7, i32 0, i32 0
  store i64 1, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  %.fca.7.0.1.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i32 0, i32 7, i32 0, i32 1
  store i64 0, ptr %.fca.7.0.1.gep, align 8, !tbaa !8
  %.fca.7.0.2.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i32 0, i32 7, i32 0, i32 2
  store i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), ptr %.fca.7.0.2.gep, align 8, !tbaa !8
  %6 = load i32, ptr %0, align 4, !tbaa !4
  %7 = sext i32 %6 to i64
  %8 = icmp sgt i64 %7, 0
  %9 = select i1 %8, i64 %7, i64 0
  %10 = mul i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), %9
  %11 = call ptr @malloc(i64 %10)
  %12 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } { ptr undef, i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), i32 20180515, i8 1, i8 28, i8 2, i8 0, [1 x [3 x i64]] [[3 x i64] [i64 1, i64 undef, i64 undef]] }, i64 %9, 7, 0, 1
  %13 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %12, i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), 7, 0, 2
  %14 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %13, ptr %11, 0
  %.fca.1.extract170 = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %14, 1
  %.fca.2.extract172 = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %14, 2
  %.fca.3.extract174 = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %14, 3
  %.fca.4.extract176 = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %14, 4
  %.fca.5.extract178 = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %14, 5
  %.fca.6.extract180 = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %14, 6
  %.fca.7.0.0.extract182 = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %14, 7, 0, 0
  %.fca.0.insert190 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } poison, ptr %11, 0
  %.fca.1.insert193 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.0.insert190, i64 %.fca.1.extract170, 1
  %.fca.2.insert196 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.1.insert193, i32 %.fca.2.extract172, 2
  %.fca.3.insert199 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.2.insert196, i8 %.fca.3.extract174, 3
  %.fca.4.insert202 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.3.insert199, i8 %.fca.4.extract176, 4
  %.fca.5.insert205 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.4.insert202, i8 %.fca.5.extract178, 5
  %.fca.6.insert208 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.5.insert205, i8 %.fca.6.extract180, 6
  %.fca.7.0.0.insert211 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.6.insert208, i64 %.fca.7.0.0.extract182, 7, 0, 0
  %.fca.7.0.1.insert214 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.7.0.0.insert211, i64 %9, 7, 0, 1
  %.fca.7.0.2.insert217 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.7.0.1.insert214, i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), 7, 0, 2
  store ptr %11, ptr %5, align 8, !tbaa !8
  store i64 %.fca.1.extract170, ptr %.fca.1.gep, align 8, !tbaa !8
  store i32 %.fca.2.extract172, ptr %.fca.2.gep, align 8, !tbaa !8
  store i8 %.fca.3.extract174, ptr %.fca.3.gep, align 4, !tbaa !8
  store i8 %.fca.4.extract176, ptr %.fca.4.gep, align 1, !tbaa !8
  store i8 %.fca.5.extract178, ptr %.fca.5.gep, align 2, !tbaa !8
  store i8 %.fca.6.extract180, ptr %.fca.6.gep, align 1, !tbaa !8
  store i64 %.fca.7.0.0.extract182, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  store i64 %9, ptr %.fca.7.0.1.gep, align 8, !tbaa !8
  store i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), ptr %.fca.7.0.2.gep, align 8, !tbaa !8
  %omp_global_thread_num = call i32 @__kmpc_global_thread_num(ptr @1)
  store ptr %0, ptr %structArg, align 8
  %gep_5 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i32 0, i32 1
  store ptr %5, ptr %gep_5, align 8
  %gep_6 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i32 0, i32 2
  store ptr %4, ptr %gep_6, align 8
  %gep_7 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i32 0, i32 3
  store ptr %3, ptr %gep_7, align 8
  %gep_8 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i32 0, i32 4
  store ptr %2, ptr %gep_8, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr @1, i32 1, ptr @_QFPomp_subroutine..omp_par, ptr %structArg)
  %.fca.0.load = load ptr, ptr %5, align 8, !tbaa !8
  %.fca.0.insert = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } poison, ptr %.fca.0.load, 0
  %.fca.1.load = load i64, ptr %.fca.1.gep, align 8, !tbaa !8
  %.fca.1.insert = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.0.insert, i64 %.fca.1.load, 1
  %.fca.2.load = load i32, ptr %.fca.2.gep, align 8, !tbaa !8
  %.fca.2.insert = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.1.insert, i32 %.fca.2.load, 2
  %.fca.3.load = load i8, ptr %.fca.3.gep, align 4, !tbaa !8
  %.fca.3.insert = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.2.insert, i8 %.fca.3.load, 3
  %.fca.4.load = load i8, ptr %.fca.4.gep, align 1, !tbaa !8
  %.fca.4.insert = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.3.insert, i8 %.fca.4.load, 4
  %.fca.5.load = load i8, ptr %.fca.5.gep, align 2, !tbaa !8
  %.fca.5.insert = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.4.insert, i8 %.fca.5.load, 5
  %.fca.6.load = load i8, ptr %.fca.6.gep, align 1, !tbaa !8
  %.fca.6.insert = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.5.insert, i8 %.fca.6.load, 6
  %.fca.7.0.0.load = load i64, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  %.fca.7.0.0.insert = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.6.insert, i64 %.fca.7.0.0.load, 7, 0, 0
  %.fca.7.0.1.load = load i64, ptr %.fca.7.0.1.gep, align 8, !tbaa !8
  %.fca.7.0.1.insert = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.7.0.0.insert, i64 %.fca.7.0.1.load, 7, 0, 1
  %.fca.7.0.2.load = load i64, ptr %.fca.7.0.2.gep, align 8, !tbaa !8
  %.fca.7.0.2.insert = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.7.0.1.insert, i64 %.fca.7.0.2.load, 7, 0, 2
  %15 = sub i64 1, %.fca.7.0.0.load
  %16 = getelementptr double, ptr %.fca.0.load, i64 %15
  %17 = load double, ptr %16, align 8, !tbaa !4
  %18 = load i32, ptr %0, align 4, !tbaa !4
  %19 = sext i32 %18 to i64
  %20 = sub i64 %19, %.fca.7.0.0.load
  %21 = getelementptr double, ptr %.fca.0.load, i64 %20
  %22 = load double, ptr %21, align 8, !tbaa !4
  %23 = fadd contract double %17, %22
  store double %23, ptr %1, align 8, !tbaa !4
  %.fca.0.load40 = load ptr, ptr %5, align 8, !tbaa !8
  %.fca.0.insert41 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } poison, ptr %.fca.0.load40, 0
  %.fca.1.load43 = load i64, ptr %.fca.1.gep, align 8, !tbaa !8
  %.fca.1.insert44 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.0.insert41, i64 %.fca.1.load43, 1
  %.fca.2.load46 = load i32, ptr %.fca.2.gep, align 8, !tbaa !8
  %.fca.2.insert47 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.1.insert44, i32 %.fca.2.load46, 2
  %.fca.3.load49 = load i8, ptr %.fca.3.gep, align 4, !tbaa !8
  %.fca.3.insert50 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.2.insert47, i8 %.fca.3.load49, 3
  %.fca.4.load52 = load i8, ptr %.fca.4.gep, align 1, !tbaa !8
  %.fca.4.insert53 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.3.insert50, i8 %.fca.4.load52, 4
  %.fca.5.load55 = load i8, ptr %.fca.5.gep, align 2, !tbaa !8
  %.fca.5.insert56 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.4.insert53, i8 %.fca.5.load55, 5
  %.fca.6.load58 = load i8, ptr %.fca.6.gep, align 1, !tbaa !8
  %.fca.6.insert59 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.5.insert56, i8 %.fca.6.load58, 6
  %.fca.7.0.0.load61 = load i64, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  %.fca.7.0.0.insert62 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.6.insert59, i64 %.fca.7.0.0.load61, 7, 0, 0
  %.fca.7.0.1.load64 = load i64, ptr %.fca.7.0.1.gep, align 8, !tbaa !8
  %.fca.7.0.1.insert65 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.7.0.0.insert62, i64 %.fca.7.0.1.load64, 7, 0, 1
  %.fca.7.0.2.load67 = load i64, ptr %.fca.7.0.2.gep, align 8, !tbaa !8
  %.fca.7.0.2.insert68 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.7.0.1.insert65, i64 %.fca.7.0.2.load67, 7, 0, 2
  call void @free(ptr %.fca.0.load40)
  store ptr null, ptr %5, align 8, !tbaa !8
  store i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), ptr %.fca.1.gep, align 8, !tbaa !8
  store i32 20180515, ptr %.fca.2.gep, align 8, !tbaa !8
  store i8 1, ptr %.fca.3.gep, align 4, !tbaa !8
  store i8 28, ptr %.fca.4.gep, align 1, !tbaa !8
  store i8 2, ptr %.fca.5.gep, align 2, !tbaa !8
  store i8 0, ptr %.fca.6.gep, align 1, !tbaa !8
  store i64 1, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  store i64 0, ptr %.fca.7.0.1.gep, align 8, !tbaa !8
  store i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), ptr %.fca.7.0.2.gep, align 8, !tbaa !8
  ret void
}

; Function Attrs: norecurse nounwind
define internal void @_QFPomp_subroutine..omp_par(ptr noalias %tid.addr, ptr noalias %zero.addr, ptr %0) #2 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i32 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %gep_3 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i32 0, i32 2
  %loadgep_4 = load ptr, ptr %gep_3, align 8
  %gep_5 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i32 0, i32 3
  %loadgep_6 = load ptr, ptr %gep_5, align 8
  %gep_7 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i32 0, i32 4
  %loadgep_8 = load ptr, ptr %gep_7, align 8
  %1 = alloca i32, i64 1, align 4
  %2 = alloca i32, i64 1, align 4
  %3 = call i32 @omp_get_thread_num()
  %4 = call i32 @omp_get_num_threads()
  %5 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %6 = sdiv i32 %5, %4
  %7 = mul i32 %3, %6
  %8 = add i32 %7, 1
  store i32 %8, ptr %1, align 4, !tbaa !4
  %9 = sub i32 %4, 1
  %10 = icmp eq i32 %3, %9
  br i1 %10, label %omp.par.region2, label %omp.par.region3

omp.par.region3:                                  ; preds = %omp.par.entry
  %11 = add i32 %8, %6
  store i32 %11, ptr %2, align 4, !tbaa !4
  br label %omp.par.region4

omp.par.region4:                                  ; preds = %omp.par.region2, %omp.par.region3
  %12 = load { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, align 8, !tbaa !8
  store { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %12, ptr %loadgep_4, align 8, !tbaa !8
  %13 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i32 0, i32 7, i64 0, i32 0
  %14 = load i64, ptr %13, align 8, !tbaa !8
  %15 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i32 0, i32 7, i64 0, i32 1
  %16 = load i64, ptr %15, align 8, !tbaa !8
  %17 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i32 0, i32 7, i64 0, i32 2
  %18 = load ptr, ptr %loadgep_4, align 8, !tbaa !8
  %19 = icmp eq i64 %16, 0
  %20 = select i1 %19, i64 1, i64 %14
  %21 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } { ptr undef, i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), i32 20180515, i8 1, i8 28, i8 0, i8 0, [1 x [3 x i64]] undef }, i64 %20, 7, 0, 0
  %22 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %21, i64 %16, 7, 0, 1
  %23 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %22, i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), 7, 0, 2
  %24 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %23, ptr %18, 0
  store { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %24, ptr %loadgep_6, align 8, !tbaa !8
  call void @_QFPloop(ptr %1, ptr %2, ptr %loadgep_6, ptr %loadgep_8)
  ret void

omp.par.region2:                                  ; preds = %omp.par.entry
  %25 = load i32, ptr %loadgep_, align 4, !tbaa !4
  store i32 %25, ptr %2, align 4, !tbaa !4
  br label %omp.par.region4
}

define void @_QFPloop(ptr %0, ptr %1, ptr %2, ptr nest %3) {
  %5 = load ptr, ptr %3, align 8, !tbaa !4
  %6 = getelementptr { ptr, ptr }, ptr %3, i32 0, i32 1
  %7 = load ptr, ptr %6, align 8, !tbaa !4
  %8 = load i32, ptr %0, align 4, !tbaa !4
  %9 = sext i32 %8 to i64
  %10 = load i32, ptr %1, align 4, !tbaa !4
  %11 = sext i32 %10 to i64
  %12 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %2, i32 0, i32 7, i64 0, i32 0
  %13 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %2, i32 0, i32 7, i64 0, i32 1
  %14 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %2, i32 0, i32 7, i64 0, i32 2
  %15 = load i64, ptr %14, align 8, !tbaa !8
  %16 = icmp eq i64 %15, 8
  br i1 %16, label %17, label %35

17:                                               ; preds = %4
  %18 = load ptr, ptr %2, align 8, !tbaa !8
  %19 = sub nsw i64 %11, %9
  %20 = add nsw i64 %19, 1
  br label %21

21:                                               ; preds = %25, %17
  %22 = phi i32 [ %33, %25 ], [ %8, %17 ]
  %23 = phi i64 [ %34, %25 ], [ %20, %17 ]
  %24 = icmp sgt i64 %23, 0
  br i1 %24, label %25, label %61

25:                                               ; preds = %21
  %26 = load i32, ptr %5, align 4, !tbaa !4
  %27 = sitofp i32 %26 to float
  %28 = fdiv contract float 1.000000e+00, %27
  %29 = fpext float %28 to double
  %30 = sext i32 %22 to i64
  %31 = sub nsw i64 %30, 1
  %32 = getelementptr double, ptr %18, i64 %31
  store double %29, ptr %32, align 8, !tbaa !4
  store double %29, ptr %7, align 8, !tbaa !4
  %33 = add i32 %22, 1
  %34 = sub nuw nsw i64 %23, 1
  br label %21

35:                                               ; preds = %4
  %36 = sub nsw i64 %11, %9
  %37 = add nsw i64 %36, 1
  br label %38

38:                                               ; preds = %42, %35
  %39 = phi i32 [ %59, %42 ], [ %8, %35 ]
  %40 = phi i64 [ %60, %42 ], [ %37, %35 ]
  %41 = icmp sgt i64 %40, 0
  br i1 %41, label %42, label %61

42:                                               ; preds = %38
  %43 = load i32, ptr %5, align 4, !tbaa !4
  %44 = sitofp i32 %43 to float
  %45 = fdiv contract float 1.000000e+00, %44
  %46 = fpext float %45 to double
  %47 = sext i32 %39 to i64
  %48 = sub nsw i64 %47, 1
  %49 = load ptr, ptr %2, align 8, !tbaa !8
  %50 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %2, i32 0, i32 7, i32 0, i32 2
  %51 = load i64, ptr %50, align 8, !tbaa !8
  %52 = mul i64 %48, %51
  %53 = getelementptr i8, ptr %49, i64 %52
  store double %46, ptr %53, align 8, !tbaa !4
  %54 = load ptr, ptr %2, align 8, !tbaa !8
  %55 = load i64, ptr %50, align 8, !tbaa !8
  %56 = mul i64 %48, %55
  %57 = getelementptr i8, ptr %54, i64 %56
  %58 = load double, ptr %57, align 8, !tbaa !4
  store double %58, ptr %7, align 8, !tbaa !4
  %59 = add i32 %39, 1
  %60 = sub nuw nsw i64 %40, 1
  br label %38

61:                                               ; preds = %21, %38
  ret void
}

declare ptr @_FortranAioBeginExternalFormattedOutput(ptr, i64, ptr, i32, ptr, i32)

declare zeroext i1 @_FortranAioOutputAscii(ptr, ptr, i64)

declare zeroext i1 @_FortranAioOutputInteger32(ptr, i32)

declare zeroext i1 @_FortranAioOutputReal64(ptr, double)

declare i32 @_FortranAioEndIoStatement(ptr)

; Function Attrs: nounwind
declare i32 @omp_get_thread_num() #3

; Function Attrs: nounwind
declare i32 @omp_get_num_threads() #3

; Function Attrs: mustprogress nocallback nofree nosync nounwind willreturn
declare ptr @llvm.stacksave() #4

; Function Attrs: mustprogress nocallback nofree nosync nounwind willreturn
declare void @llvm.stackrestore(ptr) #4

; Function Attrs: nounwind
declare i32 @__kmpc_global_thread_num(ptr) #3

; Function Attrs: nounwind
declare !callback !10 void @__kmpc_fork_call(ptr, i32, ptr, ...) #3

attributes #0 = { mustprogress nofree nounwind willreturn allockind("alloc,uninitialized") allocsize(0) memory(inaccessiblemem: readwrite) "alloc-family"="malloc" }
attributes #1 = { mustprogress nounwind willreturn allockind("free") memory(argmem: readwrite, inaccessiblemem: readwrite) "alloc-family"="malloc" }
attributes #2 = { norecurse nounwind }
attributes #3 = { nounwind }
attributes #4 = { mustprogress nocallback nofree nosync nounwind willreturn }

!llvm.module.flags = !{!0, !1, !2, !3}

!0 = !{i32 2, !"Debug Info Version", i32 3}
!1 = !{i32 7, !"openmp", i32 11}
!2 = !{i32 8, !"PIC Level", i32 2}
!3 = !{i32 7, !"PIE Level", i32 2}
!4 = !{!5, !5, i64 0}
!5 = !{!"any data access", !6, i64 0}
!6 = !{!"any access", !7, i64 0}
!7 = !{!"Flang Type TBAA Root"}
!8 = !{!9, !9, i64 0}
!9 = !{!"descriptor member", !6, i64 0}
!10 = !{!11}
!11 = !{i64 2, i64 -1, i64 -1, i1 true}
*** IR Dump After CalledValuePropagationPass on [module] ***
; ModuleID = 'FIRModule'
source_filename = "FIRModule"
target datalayout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128"
target triple = "x86_64-unknown-linux-gnu"

%struct.ident_t = type { i32, i32, i32, i32, ptr }

@_QMomp_libEComp_allocator_handle_kind = external constant i32
@_QMomp_libEComp_alloctrait_key_kind = external constant i32
@_QMomp_libEComp_alloctrait_val_kind = external constant i32
@_QMomp_libEComp_allow_completion_event = external constant i32
@_QMomp_libEComp_atk_access = external constant i32
@_QMomp_libEComp_atk_alignment = external constant i32
@_QMomp_libEComp_atk_fallback = external constant i32
@_QMomp_libEComp_atk_fb_data = external constant i32
@_QMomp_libEComp_atk_partition = external constant i32
@_QMomp_libEComp_atk_pinned = external constant i32
@_QMomp_libEComp_atk_pool_size = external constant i32
@_QMomp_libEComp_atk_sync_hint = external constant i32
@_QMomp_libEComp_atv_abort_fb = external constant i32
@_QMomp_libEComp_atv_all = external constant i32
@_QMomp_libEComp_atv_allocator_fb = external constant i32
@_QMomp_libEComp_atv_blocked = external constant i32
@_QMomp_libEComp_atv_cgroup = external constant i32
@_QMomp_libEComp_atv_contended = external constant i32
@_QMomp_libEComp_atv_default = external constant i32
@_QMomp_libEComp_atv_default_mem_fb = external constant i32
@_QMomp_libEComp_atv_environment = external constant i32
@_QMomp_libEComp_atv_false = external constant i32
@_QMomp_libEComp_atv_interleaved = external constant i32
@_QMomp_libEComp_atv_nearest = external constant i32
@_QMomp_libEComp_atv_null_fb = external constant i32
@_QMomp_libEComp_atv_private = external constant i32
@_QMomp_libEComp_atv_pteam = external constant i32
@_QMomp_libEComp_atv_sequential = external constant i32
@_QMomp_libEComp_atv_thread = external constant i32
@_QMomp_libEComp_atv_true = external constant i32
@_QMomp_libEComp_atv_uncontended = external constant i32
@_QMomp_libEComp_cgroup_mem_alloc = external constant i32
@_QMomp_libEComp_const_mem_alloc = external constant i32
@_QMomp_libEComp_const_mem_space = external constant i32
@_QMomp_libEComp_default_mem_alloc = external constant i32
@_QMomp_libEComp_default_mem_space = external constant i32
@_QMomp_libEComp_depend_kind = external constant i32
@_QMomp_libEComp_event_handle_kind = external constant i32
@_QMomp_libEComp_high_bw_mem_alloc = external constant i32
@_QMomp_libEComp_high_bw_mem_space = external constant i32
@_QMomp_libEComp_integer_kind = external constant i32
@_QMomp_libEComp_large_cap_mem_alloc = external constant i32
@_QMomp_libEComp_large_cap_mem_space = external constant i32
@_QMomp_libEComp_lock_hint_contended = external constant i32
@_QMomp_libEComp_lock_hint_kind = external constant i32
@_QMomp_libEComp_lock_hint_none = external constant i32
@_QMomp_libEComp_lock_hint_nonspeculative = external constant i32
@_QMomp_libEComp_lock_hint_speculative = external constant i32
@_QMomp_libEComp_lock_hint_uncontended = external constant i32
@_QMomp_libEComp_lock_kind = external constant i32
@_QMomp_libEComp_logical_kind = external constant i32
@_QMomp_libEComp_low_lat_mem_alloc = external constant i32
@_QMomp_libEComp_low_lat_mem_space = external constant i32
@_QMomp_libEComp_memspace_handle_kind = external constant i32
@_QMomp_libEComp_nest_lock_kind = external constant i32
@_QMomp_libEComp_null_allocator = external constant i32
@_QMomp_libEComp_pause_hard = external constant i32
@_QMomp_libEComp_pause_resource_kind = external constant i32
@_QMomp_libEComp_pause_soft = external constant i32
@_QMomp_libEComp_proc_bind_close = external constant i32
@_QMomp_libEComp_proc_bind_false = external constant i32
@_QMomp_libEComp_proc_bind_kind = external constant i32
@_QMomp_libEComp_proc_bind_master = external constant i32
@_QMomp_libEComp_proc_bind_spread = external constant i32
@_QMomp_libEComp_proc_bind_true = external constant i32
@_QMomp_libEComp_pteam_mem_alloc = external constant i32
@_QMomp_libEComp_sched_auto = external constant i32
@_QMomp_libEComp_sched_dynamic = external constant i32
@_QMomp_libEComp_sched_guided = external constant i32
@_QMomp_libEComp_sched_kind = external constant i32
@_QMomp_libEComp_sched_static = external constant i32
@_QMomp_libEComp_sync_hint_contended = external constant i32
@_QMomp_libEComp_sync_hint_kind = external constant i32
@_QMomp_libEComp_sync_hint_none = external constant i32
@_QMomp_libEComp_sync_hint_nonspeculative = external constant i32
@_QMomp_libEComp_sync_hint_speculative = external constant i32
@_QMomp_libEComp_sync_hint_uncontended = external constant i32
@_QMomp_libEComp_task_fulfill_event = external constant i32
@_QMomp_libEComp_thread_mem_alloc = external constant i32
@_QMomp_libECopenmp_version = external constant i32
@_QQcl.28612C69372C612C6531332E36653229 = internal constant [16 x i8] c"(a,i7,a,e13.6e2)"
@_QQcl.e8a0ac9186c064ac8543d822e9060d96 = internal constant [59 x i8] c"/g/g92/rydahl1/flangtests/src/parallel_region_outlined.f90\00"
@_QQcl.54686520726573756C74206F6620286172722831292B61727228 = internal constant [26 x i8] c"The result of (arr(1)+arr("
@_QQcl.2920697320 = internal constant [5 x i8] c") is "
@_QQEnvironmentDefaults = constant ptr null
@0 = private unnamed_addr constant [23 x i8] c";unknown;unknown;0;0;;\00", align 1
@1 = private unnamed_addr constant %struct.ident_t { i32 0, i32 2, i32 0, i32 22, ptr @0 }, align 8

; Function Attrs: mustprogress nofree nounwind willreturn allockind("alloc,uninitialized") allocsize(0) memory(inaccessiblemem: readwrite)
declare noalias noundef ptr @malloc(i64 noundef) #0

; Function Attrs: mustprogress nounwind willreturn allockind("free") memory(argmem: readwrite, inaccessiblemem: readwrite)
declare void @free(ptr allocptr nocapture noundef) #1

define void @_QQmain() {
  %1 = alloca i32, i64 1, align 4
  %2 = alloca double, i64 1, align 8
  %3 = alloca double, i64 1, align 8
  %4 = alloca { ptr, ptr }, i64 1, align 8
  store ptr %1, ptr %4, align 8, !tbaa !4
  %5 = getelementptr { ptr, ptr }, ptr %4, i32 0, i32 1
  store ptr %3, ptr %5, align 8, !tbaa !4
  store i32 1048576, ptr %1, align 4, !tbaa !4
  call void @_QFPomp_subroutine(ptr %1, ptr %2, ptr %4)
  %6 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr @_QQcl.e8a0ac9186c064ac8543d822e9060d96, i32 10)
  %7 = call i1 @_FortranAioOutputAscii(ptr %6, ptr @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %8 = load i32, ptr %1, align 4, !tbaa !4
  %9 = call i1 @_FortranAioOutputInteger32(ptr %6, i32 %8)
  %10 = call i1 @_FortranAioOutputAscii(ptr %6, ptr @_QQcl.2920697320, i64 5)
  %11 = load double, ptr %2, align 8, !tbaa !4
  %12 = call i1 @_FortranAioOutputReal64(ptr %6, double %11)
  %13 = call i32 @_FortranAioEndIoStatement(ptr %6)
  ret void
}

define void @_QFPomp_subroutine(ptr %0, ptr %1, ptr nest %2) {
entry:
  %structArg = alloca { ptr, ptr, ptr, ptr, ptr }, align 8
  %3 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %4 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %5 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, i64 1, align 8
  store ptr null, ptr %5, align 8, !tbaa !8
  %.fca.1.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i32 0, i32 1
  store i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), ptr %.fca.1.gep, align 8, !tbaa !8
  %.fca.2.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i32 0, i32 2
  store i32 20180515, ptr %.fca.2.gep, align 8, !tbaa !8
  %.fca.3.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i32 0, i32 3
  store i8 1, ptr %.fca.3.gep, align 4, !tbaa !8
  %.fca.4.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i32 0, i32 4
  store i8 28, ptr %.fca.4.gep, align 1, !tbaa !8
  %.fca.5.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i32 0, i32 5
  store i8 2, ptr %.fca.5.gep, align 2, !tbaa !8
  %.fca.6.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i32 0, i32 6
  store i8 0, ptr %.fca.6.gep, align 1, !tbaa !8
  %.fca.7.0.0.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i32 0, i32 7, i32 0, i32 0
  store i64 1, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  %.fca.7.0.1.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i32 0, i32 7, i32 0, i32 1
  store i64 0, ptr %.fca.7.0.1.gep, align 8, !tbaa !8
  %.fca.7.0.2.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i32 0, i32 7, i32 0, i32 2
  store i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), ptr %.fca.7.0.2.gep, align 8, !tbaa !8
  %6 = load i32, ptr %0, align 4, !tbaa !4
  %7 = sext i32 %6 to i64
  %8 = icmp sgt i64 %7, 0
  %9 = select i1 %8, i64 %7, i64 0
  %10 = mul i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), %9
  %11 = call ptr @malloc(i64 %10)
  %12 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } { ptr undef, i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), i32 20180515, i8 1, i8 28, i8 2, i8 0, [1 x [3 x i64]] [[3 x i64] [i64 1, i64 undef, i64 undef]] }, i64 %9, 7, 0, 1
  %13 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %12, i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), 7, 0, 2
  %14 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %13, ptr %11, 0
  %.fca.1.extract170 = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %14, 1
  %.fca.2.extract172 = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %14, 2
  %.fca.3.extract174 = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %14, 3
  %.fca.4.extract176 = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %14, 4
  %.fca.5.extract178 = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %14, 5
  %.fca.6.extract180 = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %14, 6
  %.fca.7.0.0.extract182 = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %14, 7, 0, 0
  %.fca.0.insert190 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } poison, ptr %11, 0
  %.fca.1.insert193 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.0.insert190, i64 %.fca.1.extract170, 1
  %.fca.2.insert196 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.1.insert193, i32 %.fca.2.extract172, 2
  %.fca.3.insert199 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.2.insert196, i8 %.fca.3.extract174, 3
  %.fca.4.insert202 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.3.insert199, i8 %.fca.4.extract176, 4
  %.fca.5.insert205 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.4.insert202, i8 %.fca.5.extract178, 5
  %.fca.6.insert208 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.5.insert205, i8 %.fca.6.extract180, 6
  %.fca.7.0.0.insert211 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.6.insert208, i64 %.fca.7.0.0.extract182, 7, 0, 0
  %.fca.7.0.1.insert214 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.7.0.0.insert211, i64 %9, 7, 0, 1
  %.fca.7.0.2.insert217 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.7.0.1.insert214, i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), 7, 0, 2
  store ptr %11, ptr %5, align 8, !tbaa !8
  store i64 %.fca.1.extract170, ptr %.fca.1.gep, align 8, !tbaa !8
  store i32 %.fca.2.extract172, ptr %.fca.2.gep, align 8, !tbaa !8
  store i8 %.fca.3.extract174, ptr %.fca.3.gep, align 4, !tbaa !8
  store i8 %.fca.4.extract176, ptr %.fca.4.gep, align 1, !tbaa !8
  store i8 %.fca.5.extract178, ptr %.fca.5.gep, align 2, !tbaa !8
  store i8 %.fca.6.extract180, ptr %.fca.6.gep, align 1, !tbaa !8
  store i64 %.fca.7.0.0.extract182, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  store i64 %9, ptr %.fca.7.0.1.gep, align 8, !tbaa !8
  store i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), ptr %.fca.7.0.2.gep, align 8, !tbaa !8
  %omp_global_thread_num = call i32 @__kmpc_global_thread_num(ptr @1)
  store ptr %0, ptr %structArg, align 8
  %gep_5 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i32 0, i32 1
  store ptr %5, ptr %gep_5, align 8
  %gep_6 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i32 0, i32 2
  store ptr %4, ptr %gep_6, align 8
  %gep_7 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i32 0, i32 3
  store ptr %3, ptr %gep_7, align 8
  %gep_8 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i32 0, i32 4
  store ptr %2, ptr %gep_8, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr @1, i32 1, ptr @_QFPomp_subroutine..omp_par, ptr %structArg)
  %.fca.0.load = load ptr, ptr %5, align 8, !tbaa !8
  %.fca.0.insert = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } poison, ptr %.fca.0.load, 0
  %.fca.1.load = load i64, ptr %.fca.1.gep, align 8, !tbaa !8
  %.fca.1.insert = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.0.insert, i64 %.fca.1.load, 1
  %.fca.2.load = load i32, ptr %.fca.2.gep, align 8, !tbaa !8
  %.fca.2.insert = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.1.insert, i32 %.fca.2.load, 2
  %.fca.3.load = load i8, ptr %.fca.3.gep, align 4, !tbaa !8
  %.fca.3.insert = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.2.insert, i8 %.fca.3.load, 3
  %.fca.4.load = load i8, ptr %.fca.4.gep, align 1, !tbaa !8
  %.fca.4.insert = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.3.insert, i8 %.fca.4.load, 4
  %.fca.5.load = load i8, ptr %.fca.5.gep, align 2, !tbaa !8
  %.fca.5.insert = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.4.insert, i8 %.fca.5.load, 5
  %.fca.6.load = load i8, ptr %.fca.6.gep, align 1, !tbaa !8
  %.fca.6.insert = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.5.insert, i8 %.fca.6.load, 6
  %.fca.7.0.0.load = load i64, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  %.fca.7.0.0.insert = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.6.insert, i64 %.fca.7.0.0.load, 7, 0, 0
  %.fca.7.0.1.load = load i64, ptr %.fca.7.0.1.gep, align 8, !tbaa !8
  %.fca.7.0.1.insert = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.7.0.0.insert, i64 %.fca.7.0.1.load, 7, 0, 1
  %.fca.7.0.2.load = load i64, ptr %.fca.7.0.2.gep, align 8, !tbaa !8
  %.fca.7.0.2.insert = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.7.0.1.insert, i64 %.fca.7.0.2.load, 7, 0, 2
  %15 = sub i64 1, %.fca.7.0.0.load
  %16 = getelementptr double, ptr %.fca.0.load, i64 %15
  %17 = load double, ptr %16, align 8, !tbaa !4
  %18 = load i32, ptr %0, align 4, !tbaa !4
  %19 = sext i32 %18 to i64
  %20 = sub i64 %19, %.fca.7.0.0.load
  %21 = getelementptr double, ptr %.fca.0.load, i64 %20
  %22 = load double, ptr %21, align 8, !tbaa !4
  %23 = fadd contract double %17, %22
  store double %23, ptr %1, align 8, !tbaa !4
  %.fca.0.load40 = load ptr, ptr %5, align 8, !tbaa !8
  %.fca.0.insert41 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } poison, ptr %.fca.0.load40, 0
  %.fca.1.load43 = load i64, ptr %.fca.1.gep, align 8, !tbaa !8
  %.fca.1.insert44 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.0.insert41, i64 %.fca.1.load43, 1
  %.fca.2.load46 = load i32, ptr %.fca.2.gep, align 8, !tbaa !8
  %.fca.2.insert47 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.1.insert44, i32 %.fca.2.load46, 2
  %.fca.3.load49 = load i8, ptr %.fca.3.gep, align 4, !tbaa !8
  %.fca.3.insert50 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.2.insert47, i8 %.fca.3.load49, 3
  %.fca.4.load52 = load i8, ptr %.fca.4.gep, align 1, !tbaa !8
  %.fca.4.insert53 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.3.insert50, i8 %.fca.4.load52, 4
  %.fca.5.load55 = load i8, ptr %.fca.5.gep, align 2, !tbaa !8
  %.fca.5.insert56 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.4.insert53, i8 %.fca.5.load55, 5
  %.fca.6.load58 = load i8, ptr %.fca.6.gep, align 1, !tbaa !8
  %.fca.6.insert59 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.5.insert56, i8 %.fca.6.load58, 6
  %.fca.7.0.0.load61 = load i64, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  %.fca.7.0.0.insert62 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.6.insert59, i64 %.fca.7.0.0.load61, 7, 0, 0
  %.fca.7.0.1.load64 = load i64, ptr %.fca.7.0.1.gep, align 8, !tbaa !8
  %.fca.7.0.1.insert65 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.7.0.0.insert62, i64 %.fca.7.0.1.load64, 7, 0, 1
  %.fca.7.0.2.load67 = load i64, ptr %.fca.7.0.2.gep, align 8, !tbaa !8
  %.fca.7.0.2.insert68 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.7.0.1.insert65, i64 %.fca.7.0.2.load67, 7, 0, 2
  call void @free(ptr %.fca.0.load40)
  store ptr null, ptr %5, align 8, !tbaa !8
  store i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), ptr %.fca.1.gep, align 8, !tbaa !8
  store i32 20180515, ptr %.fca.2.gep, align 8, !tbaa !8
  store i8 1, ptr %.fca.3.gep, align 4, !tbaa !8
  store i8 28, ptr %.fca.4.gep, align 1, !tbaa !8
  store i8 2, ptr %.fca.5.gep, align 2, !tbaa !8
  store i8 0, ptr %.fca.6.gep, align 1, !tbaa !8
  store i64 1, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  store i64 0, ptr %.fca.7.0.1.gep, align 8, !tbaa !8
  store i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), ptr %.fca.7.0.2.gep, align 8, !tbaa !8
  ret void
}

; Function Attrs: norecurse nounwind
define internal void @_QFPomp_subroutine..omp_par(ptr noalias %tid.addr, ptr noalias %zero.addr, ptr %0) #2 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i32 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %gep_3 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i32 0, i32 2
  %loadgep_4 = load ptr, ptr %gep_3, align 8
  %gep_5 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i32 0, i32 3
  %loadgep_6 = load ptr, ptr %gep_5, align 8
  %gep_7 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i32 0, i32 4
  %loadgep_8 = load ptr, ptr %gep_7, align 8
  %1 = alloca i32, i64 1, align 4
  %2 = alloca i32, i64 1, align 4
  %3 = call i32 @omp_get_thread_num()
  %4 = call i32 @omp_get_num_threads()
  %5 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %6 = sdiv i32 %5, %4
  %7 = mul i32 %3, %6
  %8 = add i32 %7, 1
  store i32 %8, ptr %1, align 4, !tbaa !4
  %9 = sub i32 %4, 1
  %10 = icmp eq i32 %3, %9
  br i1 %10, label %omp.par.region2, label %omp.par.region3

omp.par.region3:                                  ; preds = %omp.par.entry
  %11 = add i32 %8, %6
  store i32 %11, ptr %2, align 4, !tbaa !4
  br label %omp.par.region4

omp.par.region4:                                  ; preds = %omp.par.region2, %omp.par.region3
  %12 = load { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, align 8, !tbaa !8
  store { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %12, ptr %loadgep_4, align 8, !tbaa !8
  %13 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i32 0, i32 7, i64 0, i32 0
  %14 = load i64, ptr %13, align 8, !tbaa !8
  %15 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i32 0, i32 7, i64 0, i32 1
  %16 = load i64, ptr %15, align 8, !tbaa !8
  %17 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i32 0, i32 7, i64 0, i32 2
  %18 = load ptr, ptr %loadgep_4, align 8, !tbaa !8
  %19 = icmp eq i64 %16, 0
  %20 = select i1 %19, i64 1, i64 %14
  %21 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } { ptr undef, i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), i32 20180515, i8 1, i8 28, i8 0, i8 0, [1 x [3 x i64]] undef }, i64 %20, 7, 0, 0
  %22 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %21, i64 %16, 7, 0, 1
  %23 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %22, i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), 7, 0, 2
  %24 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %23, ptr %18, 0
  store { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %24, ptr %loadgep_6, align 8, !tbaa !8
  call void @_QFPloop(ptr %1, ptr %2, ptr %loadgep_6, ptr %loadgep_8)
  ret void

omp.par.region2:                                  ; preds = %omp.par.entry
  %25 = load i32, ptr %loadgep_, align 4, !tbaa !4
  store i32 %25, ptr %2, align 4, !tbaa !4
  br label %omp.par.region4
}

define void @_QFPloop(ptr %0, ptr %1, ptr %2, ptr nest %3) {
  %5 = load ptr, ptr %3, align 8, !tbaa !4
  %6 = getelementptr { ptr, ptr }, ptr %3, i32 0, i32 1
  %7 = load ptr, ptr %6, align 8, !tbaa !4
  %8 = load i32, ptr %0, align 4, !tbaa !4
  %9 = sext i32 %8 to i64
  %10 = load i32, ptr %1, align 4, !tbaa !4
  %11 = sext i32 %10 to i64
  %12 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %2, i32 0, i32 7, i64 0, i32 0
  %13 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %2, i32 0, i32 7, i64 0, i32 1
  %14 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %2, i32 0, i32 7, i64 0, i32 2
  %15 = load i64, ptr %14, align 8, !tbaa !8
  %16 = icmp eq i64 %15, 8
  br i1 %16, label %17, label %35

17:                                               ; preds = %4
  %18 = load ptr, ptr %2, align 8, !tbaa !8
  %19 = sub nsw i64 %11, %9
  %20 = add nsw i64 %19, 1
  br label %21

21:                                               ; preds = %25, %17
  %22 = phi i32 [ %33, %25 ], [ %8, %17 ]
  %23 = phi i64 [ %34, %25 ], [ %20, %17 ]
  %24 = icmp sgt i64 %23, 0
  br i1 %24, label %25, label %61

25:                                               ; preds = %21
  %26 = load i32, ptr %5, align 4, !tbaa !4
  %27 = sitofp i32 %26 to float
  %28 = fdiv contract float 1.000000e+00, %27
  %29 = fpext float %28 to double
  %30 = sext i32 %22 to i64
  %31 = sub nsw i64 %30, 1
  %32 = getelementptr double, ptr %18, i64 %31
  store double %29, ptr %32, align 8, !tbaa !4
  store double %29, ptr %7, align 8, !tbaa !4
  %33 = add i32 %22, 1
  %34 = sub nuw nsw i64 %23, 1
  br label %21

35:                                               ; preds = %4
  %36 = sub nsw i64 %11, %9
  %37 = add nsw i64 %36, 1
  br label %38

38:                                               ; preds = %42, %35
  %39 = phi i32 [ %59, %42 ], [ %8, %35 ]
  %40 = phi i64 [ %60, %42 ], [ %37, %35 ]
  %41 = icmp sgt i64 %40, 0
  br i1 %41, label %42, label %61

42:                                               ; preds = %38
  %43 = load i32, ptr %5, align 4, !tbaa !4
  %44 = sitofp i32 %43 to float
  %45 = fdiv contract float 1.000000e+00, %44
  %46 = fpext float %45 to double
  %47 = sext i32 %39 to i64
  %48 = sub nsw i64 %47, 1
  %49 = load ptr, ptr %2, align 8, !tbaa !8
  %50 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %2, i32 0, i32 7, i32 0, i32 2
  %51 = load i64, ptr %50, align 8, !tbaa !8
  %52 = mul i64 %48, %51
  %53 = getelementptr i8, ptr %49, i64 %52
  store double %46, ptr %53, align 8, !tbaa !4
  %54 = load ptr, ptr %2, align 8, !tbaa !8
  %55 = load i64, ptr %50, align 8, !tbaa !8
  %56 = mul i64 %48, %55
  %57 = getelementptr i8, ptr %54, i64 %56
  %58 = load double, ptr %57, align 8, !tbaa !4
  store double %58, ptr %7, align 8, !tbaa !4
  %59 = add i32 %39, 1
  %60 = sub nuw nsw i64 %40, 1
  br label %38

61:                                               ; preds = %21, %38
  ret void
}

declare ptr @_FortranAioBeginExternalFormattedOutput(ptr, i64, ptr, i32, ptr, i32)

declare zeroext i1 @_FortranAioOutputAscii(ptr, ptr, i64)

declare zeroext i1 @_FortranAioOutputInteger32(ptr, i32)

declare zeroext i1 @_FortranAioOutputReal64(ptr, double)

declare i32 @_FortranAioEndIoStatement(ptr)

; Function Attrs: nounwind
declare i32 @omp_get_thread_num() #3

; Function Attrs: nounwind
declare i32 @omp_get_num_threads() #3

; Function Attrs: mustprogress nocallback nofree nosync nounwind willreturn
declare ptr @llvm.stacksave() #4

; Function Attrs: mustprogress nocallback nofree nosync nounwind willreturn
declare void @llvm.stackrestore(ptr) #4

; Function Attrs: nounwind
declare i32 @__kmpc_global_thread_num(ptr) #3

; Function Attrs: nounwind
declare !callback !10 void @__kmpc_fork_call(ptr, i32, ptr, ...) #3

attributes #0 = { mustprogress nofree nounwind willreturn allockind("alloc,uninitialized") allocsize(0) memory(inaccessiblemem: readwrite) "alloc-family"="malloc" }
attributes #1 = { mustprogress nounwind willreturn allockind("free") memory(argmem: readwrite, inaccessiblemem: readwrite) "alloc-family"="malloc" }
attributes #2 = { norecurse nounwind }
attributes #3 = { nounwind }
attributes #4 = { mustprogress nocallback nofree nosync nounwind willreturn }

!llvm.module.flags = !{!0, !1, !2, !3}

!0 = !{i32 2, !"Debug Info Version", i32 3}
!1 = !{i32 7, !"openmp", i32 11}
!2 = !{i32 8, !"PIC Level", i32 2}
!3 = !{i32 7, !"PIE Level", i32 2}
!4 = !{!5, !5, i64 0}
!5 = !{!"any data access", !6, i64 0}
!6 = !{!"any access", !7, i64 0}
!7 = !{!"Flang Type TBAA Root"}
!8 = !{!9, !9, i64 0}
!9 = !{!"descriptor member", !6, i64 0}
!10 = !{!11}
!11 = !{i64 2, i64 -1, i64 -1, i1 true}
*** IR Dump After GlobalOptPass on [module] ***
; ModuleID = 'FIRModule'
source_filename = "FIRModule"
target datalayout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128"
target triple = "x86_64-unknown-linux-gnu"

%struct.ident_t = type { i32, i32, i32, i32, ptr }

@_QQcl.28612C69372C612C6531332E36653229 = internal constant [16 x i8] c"(a,i7,a,e13.6e2)"
@_QQcl.e8a0ac9186c064ac8543d822e9060d96 = internal constant [59 x i8] c"/g/g92/rydahl1/flangtests/src/parallel_region_outlined.f90\00"
@_QQcl.54686520726573756C74206F6620286172722831292B61727228 = internal constant [26 x i8] c"The result of (arr(1)+arr("
@_QQcl.2920697320 = internal constant [5 x i8] c") is "
@_QQEnvironmentDefaults = local_unnamed_addr constant ptr null
@0 = private unnamed_addr constant [23 x i8] c";unknown;unknown;0;0;;\00", align 1
@1 = private unnamed_addr constant %struct.ident_t { i32 0, i32 2, i32 0, i32 22, ptr @0 }, align 8

; Function Attrs: mustprogress nofree nounwind willreturn allockind("alloc,uninitialized") allocsize(0) memory(inaccessiblemem: readwrite)
declare noalias noundef ptr @malloc(i64 noundef) local_unnamed_addr #0

; Function Attrs: mustprogress nounwind willreturn allockind("free") memory(argmem: readwrite, inaccessiblemem: readwrite)
declare void @free(ptr allocptr nocapture noundef) local_unnamed_addr #1

define void @_QQmain() local_unnamed_addr {
  %1 = alloca i32, i64 1, align 4
  %2 = alloca double, i64 1, align 8
  %3 = alloca double, i64 1, align 8
  %4 = alloca { ptr, ptr }, i64 1, align 8
  store ptr %1, ptr %4, align 8, !tbaa !4
  %5 = getelementptr { ptr, ptr }, ptr %4, i32 0, i32 1
  store ptr %3, ptr %5, align 8, !tbaa !4
  store i32 1048576, ptr %1, align 4, !tbaa !4
  call void @_QFPomp_subroutine(ptr %1, ptr %2, ptr %4)
  %6 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr @_QQcl.e8a0ac9186c064ac8543d822e9060d96, i32 10)
  %7 = call i1 @_FortranAioOutputAscii(ptr %6, ptr @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %8 = load i32, ptr %1, align 4, !tbaa !4
  %9 = call i1 @_FortranAioOutputInteger32(ptr %6, i32 %8)
  %10 = call i1 @_FortranAioOutputAscii(ptr %6, ptr @_QQcl.2920697320, i64 5)
  %11 = load double, ptr %2, align 8, !tbaa !4
  %12 = call i1 @_FortranAioOutputReal64(ptr %6, double %11)
  %13 = call i32 @_FortranAioEndIoStatement(ptr %6)
  ret void
}

define void @_QFPomp_subroutine(ptr %0, ptr %1, ptr nest %2) local_unnamed_addr {
entry:
  %structArg = alloca { ptr, ptr, ptr, ptr, ptr }, align 8
  %3 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %4 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %5 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, i64 1, align 8
  store ptr null, ptr %5, align 8, !tbaa !8
  %.fca.1.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i32 0, i32 1
  store i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), ptr %.fca.1.gep, align 8, !tbaa !8
  %.fca.2.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i32 0, i32 2
  store i32 20180515, ptr %.fca.2.gep, align 8, !tbaa !8
  %.fca.3.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i32 0, i32 3
  store i8 1, ptr %.fca.3.gep, align 4, !tbaa !8
  %.fca.4.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i32 0, i32 4
  store i8 28, ptr %.fca.4.gep, align 1, !tbaa !8
  %.fca.5.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i32 0, i32 5
  store i8 2, ptr %.fca.5.gep, align 2, !tbaa !8
  %.fca.6.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i32 0, i32 6
  store i8 0, ptr %.fca.6.gep, align 1, !tbaa !8
  %.fca.7.0.0.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i32 0, i32 7, i32 0, i32 0
  store i64 1, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  %.fca.7.0.1.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i32 0, i32 7, i32 0, i32 1
  store i64 0, ptr %.fca.7.0.1.gep, align 8, !tbaa !8
  %.fca.7.0.2.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i32 0, i32 7, i32 0, i32 2
  store i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), ptr %.fca.7.0.2.gep, align 8, !tbaa !8
  %6 = load i32, ptr %0, align 4, !tbaa !4
  %7 = sext i32 %6 to i64
  %8 = icmp sgt i64 %7, 0
  %9 = select i1 %8, i64 %7, i64 0
  %10 = mul i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), %9
  %11 = call ptr @malloc(i64 %10)
  %12 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } { ptr undef, i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), i32 20180515, i8 1, i8 28, i8 2, i8 0, [1 x [3 x i64]] [[3 x i64] [i64 1, i64 undef, i64 undef]] }, i64 %9, 7, 0, 1
  %13 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %12, i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), 7, 0, 2
  %14 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %13, ptr %11, 0
  %.fca.1.extract170 = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %14, 1
  %.fca.2.extract172 = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %14, 2
  %.fca.3.extract174 = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %14, 3
  %.fca.4.extract176 = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %14, 4
  %.fca.5.extract178 = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %14, 5
  %.fca.6.extract180 = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %14, 6
  %.fca.7.0.0.extract182 = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %14, 7, 0, 0
  %.fca.0.insert190 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } poison, ptr %11, 0
  %.fca.1.insert193 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.0.insert190, i64 %.fca.1.extract170, 1
  %.fca.2.insert196 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.1.insert193, i32 %.fca.2.extract172, 2
  %.fca.3.insert199 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.2.insert196, i8 %.fca.3.extract174, 3
  %.fca.4.insert202 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.3.insert199, i8 %.fca.4.extract176, 4
  %.fca.5.insert205 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.4.insert202, i8 %.fca.5.extract178, 5
  %.fca.6.insert208 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.5.insert205, i8 %.fca.6.extract180, 6
  %.fca.7.0.0.insert211 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.6.insert208, i64 %.fca.7.0.0.extract182, 7, 0, 0
  %.fca.7.0.1.insert214 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.7.0.0.insert211, i64 %9, 7, 0, 1
  %.fca.7.0.2.insert217 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.7.0.1.insert214, i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), 7, 0, 2
  store ptr %11, ptr %5, align 8, !tbaa !8
  store i64 %.fca.1.extract170, ptr %.fca.1.gep, align 8, !tbaa !8
  store i32 %.fca.2.extract172, ptr %.fca.2.gep, align 8, !tbaa !8
  store i8 %.fca.3.extract174, ptr %.fca.3.gep, align 4, !tbaa !8
  store i8 %.fca.4.extract176, ptr %.fca.4.gep, align 1, !tbaa !8
  store i8 %.fca.5.extract178, ptr %.fca.5.gep, align 2, !tbaa !8
  store i8 %.fca.6.extract180, ptr %.fca.6.gep, align 1, !tbaa !8
  store i64 %.fca.7.0.0.extract182, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  store i64 %9, ptr %.fca.7.0.1.gep, align 8, !tbaa !8
  store i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), ptr %.fca.7.0.2.gep, align 8, !tbaa !8
  %omp_global_thread_num = call i32 @__kmpc_global_thread_num(ptr @1)
  store ptr %0, ptr %structArg, align 8
  %gep_5 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i32 0, i32 1
  store ptr %5, ptr %gep_5, align 8
  %gep_6 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i32 0, i32 2
  store ptr %4, ptr %gep_6, align 8
  %gep_7 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i32 0, i32 3
  store ptr %3, ptr %gep_7, align 8
  %gep_8 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i32 0, i32 4
  store ptr %2, ptr %gep_8, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr @1, i32 1, ptr @_QFPomp_subroutine..omp_par, ptr %structArg)
  %.fca.0.load = load ptr, ptr %5, align 8, !tbaa !8
  %.fca.0.insert = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } poison, ptr %.fca.0.load, 0
  %.fca.1.load = load i64, ptr %.fca.1.gep, align 8, !tbaa !8
  %.fca.1.insert = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.0.insert, i64 %.fca.1.load, 1
  %.fca.2.load = load i32, ptr %.fca.2.gep, align 8, !tbaa !8
  %.fca.2.insert = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.1.insert, i32 %.fca.2.load, 2
  %.fca.3.load = load i8, ptr %.fca.3.gep, align 4, !tbaa !8
  %.fca.3.insert = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.2.insert, i8 %.fca.3.load, 3
  %.fca.4.load = load i8, ptr %.fca.4.gep, align 1, !tbaa !8
  %.fca.4.insert = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.3.insert, i8 %.fca.4.load, 4
  %.fca.5.load = load i8, ptr %.fca.5.gep, align 2, !tbaa !8
  %.fca.5.insert = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.4.insert, i8 %.fca.5.load, 5
  %.fca.6.load = load i8, ptr %.fca.6.gep, align 1, !tbaa !8
  %.fca.6.insert = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.5.insert, i8 %.fca.6.load, 6
  %.fca.7.0.0.load = load i64, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  %.fca.7.0.0.insert = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.6.insert, i64 %.fca.7.0.0.load, 7, 0, 0
  %.fca.7.0.1.load = load i64, ptr %.fca.7.0.1.gep, align 8, !tbaa !8
  %.fca.7.0.1.insert = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.7.0.0.insert, i64 %.fca.7.0.1.load, 7, 0, 1
  %.fca.7.0.2.load = load i64, ptr %.fca.7.0.2.gep, align 8, !tbaa !8
  %.fca.7.0.2.insert = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.7.0.1.insert, i64 %.fca.7.0.2.load, 7, 0, 2
  %15 = sub i64 1, %.fca.7.0.0.load
  %16 = getelementptr double, ptr %.fca.0.load, i64 %15
  %17 = load double, ptr %16, align 8, !tbaa !4
  %18 = load i32, ptr %0, align 4, !tbaa !4
  %19 = sext i32 %18 to i64
  %20 = sub i64 %19, %.fca.7.0.0.load
  %21 = getelementptr double, ptr %.fca.0.load, i64 %20
  %22 = load double, ptr %21, align 8, !tbaa !4
  %23 = fadd contract double %17, %22
  store double %23, ptr %1, align 8, !tbaa !4
  %.fca.0.load40 = load ptr, ptr %5, align 8, !tbaa !8
  %.fca.0.insert41 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } poison, ptr %.fca.0.load40, 0
  %.fca.1.load43 = load i64, ptr %.fca.1.gep, align 8, !tbaa !8
  %.fca.1.insert44 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.0.insert41, i64 %.fca.1.load43, 1
  %.fca.2.load46 = load i32, ptr %.fca.2.gep, align 8, !tbaa !8
  %.fca.2.insert47 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.1.insert44, i32 %.fca.2.load46, 2
  %.fca.3.load49 = load i8, ptr %.fca.3.gep, align 4, !tbaa !8
  %.fca.3.insert50 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.2.insert47, i8 %.fca.3.load49, 3
  %.fca.4.load52 = load i8, ptr %.fca.4.gep, align 1, !tbaa !8
  %.fca.4.insert53 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.3.insert50, i8 %.fca.4.load52, 4
  %.fca.5.load55 = load i8, ptr %.fca.5.gep, align 2, !tbaa !8
  %.fca.5.insert56 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.4.insert53, i8 %.fca.5.load55, 5
  %.fca.6.load58 = load i8, ptr %.fca.6.gep, align 1, !tbaa !8
  %.fca.6.insert59 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.5.insert56, i8 %.fca.6.load58, 6
  %.fca.7.0.0.load61 = load i64, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  %.fca.7.0.0.insert62 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.6.insert59, i64 %.fca.7.0.0.load61, 7, 0, 0
  %.fca.7.0.1.load64 = load i64, ptr %.fca.7.0.1.gep, align 8, !tbaa !8
  %.fca.7.0.1.insert65 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.7.0.0.insert62, i64 %.fca.7.0.1.load64, 7, 0, 1
  %.fca.7.0.2.load67 = load i64, ptr %.fca.7.0.2.gep, align 8, !tbaa !8
  %.fca.7.0.2.insert68 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.7.0.1.insert65, i64 %.fca.7.0.2.load67, 7, 0, 2
  call void @free(ptr %.fca.0.load40)
  store ptr null, ptr %5, align 8, !tbaa !8
  store i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), ptr %.fca.1.gep, align 8, !tbaa !8
  store i32 20180515, ptr %.fca.2.gep, align 8, !tbaa !8
  store i8 1, ptr %.fca.3.gep, align 4, !tbaa !8
  store i8 28, ptr %.fca.4.gep, align 1, !tbaa !8
  store i8 2, ptr %.fca.5.gep, align 2, !tbaa !8
  store i8 0, ptr %.fca.6.gep, align 1, !tbaa !8
  store i64 1, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  store i64 0, ptr %.fca.7.0.1.gep, align 8, !tbaa !8
  store i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), ptr %.fca.7.0.2.gep, align 8, !tbaa !8
  ret void
}

; Function Attrs: norecurse nounwind
define internal void @_QFPomp_subroutine..omp_par(ptr noalias %tid.addr, ptr noalias %zero.addr, ptr %0) #2 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i32 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %gep_3 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i32 0, i32 2
  %loadgep_4 = load ptr, ptr %gep_3, align 8
  %gep_5 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i32 0, i32 3
  %loadgep_6 = load ptr, ptr %gep_5, align 8
  %gep_7 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i32 0, i32 4
  %loadgep_8 = load ptr, ptr %gep_7, align 8
  %1 = alloca i32, i64 1, align 4
  %2 = alloca i32, i64 1, align 4
  %3 = call i32 @omp_get_thread_num()
  %4 = call i32 @omp_get_num_threads()
  %5 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %6 = sdiv i32 %5, %4
  %7 = mul i32 %3, %6
  %8 = add i32 %7, 1
  store i32 %8, ptr %1, align 4, !tbaa !4
  %9 = sub i32 %4, 1
  %10 = icmp eq i32 %3, %9
  br i1 %10, label %omp.par.region2, label %omp.par.region3

omp.par.region3:                                  ; preds = %omp.par.entry
  %11 = add i32 %8, %6
  store i32 %11, ptr %2, align 4, !tbaa !4
  br label %omp.par.region4

omp.par.region4:                                  ; preds = %omp.par.region2, %omp.par.region3
  %12 = load { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, align 8, !tbaa !8
  store { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %12, ptr %loadgep_4, align 8, !tbaa !8
  %13 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i32 0, i32 7, i64 0, i32 0
  %14 = load i64, ptr %13, align 8, !tbaa !8
  %15 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i32 0, i32 7, i64 0, i32 1
  %16 = load i64, ptr %15, align 8, !tbaa !8
  %17 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i32 0, i32 7, i64 0, i32 2
  %18 = load ptr, ptr %loadgep_4, align 8, !tbaa !8
  %19 = icmp eq i64 %16, 0
  %20 = select i1 %19, i64 1, i64 %14
  %21 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } { ptr undef, i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), i32 20180515, i8 1, i8 28, i8 0, i8 0, [1 x [3 x i64]] undef }, i64 %20, 7, 0, 0
  %22 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %21, i64 %16, 7, 0, 1
  %23 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %22, i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), 7, 0, 2
  %24 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %23, ptr %18, 0
  store { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %24, ptr %loadgep_6, align 8, !tbaa !8
  call void @_QFPloop(ptr %1, ptr %2, ptr %loadgep_6, ptr %loadgep_8)
  ret void

omp.par.region2:                                  ; preds = %omp.par.entry
  %25 = load i32, ptr %loadgep_, align 4, !tbaa !4
  store i32 %25, ptr %2, align 4, !tbaa !4
  br label %omp.par.region4
}

define void @_QFPloop(ptr %0, ptr %1, ptr %2, ptr nest %3) local_unnamed_addr {
  %5 = load ptr, ptr %3, align 8, !tbaa !4
  %6 = getelementptr { ptr, ptr }, ptr %3, i32 0, i32 1
  %7 = load ptr, ptr %6, align 8, !tbaa !4
  %8 = load i32, ptr %0, align 4, !tbaa !4
  %9 = sext i32 %8 to i64
  %10 = load i32, ptr %1, align 4, !tbaa !4
  %11 = sext i32 %10 to i64
  %12 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %2, i32 0, i32 7, i64 0, i32 0
  %13 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %2, i32 0, i32 7, i64 0, i32 1
  %14 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %2, i32 0, i32 7, i64 0, i32 2
  %15 = load i64, ptr %14, align 8, !tbaa !8
  %16 = icmp eq i64 %15, 8
  br i1 %16, label %17, label %35

17:                                               ; preds = %4
  %18 = load ptr, ptr %2, align 8, !tbaa !8
  %19 = sub nsw i64 %11, %9
  %20 = add nsw i64 %19, 1
  br label %21

21:                                               ; preds = %25, %17
  %22 = phi i32 [ %33, %25 ], [ %8, %17 ]
  %23 = phi i64 [ %34, %25 ], [ %20, %17 ]
  %24 = icmp sgt i64 %23, 0
  br i1 %24, label %25, label %61

25:                                               ; preds = %21
  %26 = load i32, ptr %5, align 4, !tbaa !4
  %27 = sitofp i32 %26 to float
  %28 = fdiv contract float 1.000000e+00, %27
  %29 = fpext float %28 to double
  %30 = sext i32 %22 to i64
  %31 = sub nsw i64 %30, 1
  %32 = getelementptr double, ptr %18, i64 %31
  store double %29, ptr %32, align 8, !tbaa !4
  store double %29, ptr %7, align 8, !tbaa !4
  %33 = add i32 %22, 1
  %34 = sub nuw nsw i64 %23, 1
  br label %21

35:                                               ; preds = %4
  %36 = sub nsw i64 %11, %9
  %37 = add nsw i64 %36, 1
  br label %38

38:                                               ; preds = %42, %35
  %39 = phi i32 [ %59, %42 ], [ %8, %35 ]
  %40 = phi i64 [ %60, %42 ], [ %37, %35 ]
  %41 = icmp sgt i64 %40, 0
  br i1 %41, label %42, label %61

42:                                               ; preds = %38
  %43 = load i32, ptr %5, align 4, !tbaa !4
  %44 = sitofp i32 %43 to float
  %45 = fdiv contract float 1.000000e+00, %44
  %46 = fpext float %45 to double
  %47 = sext i32 %39 to i64
  %48 = sub nsw i64 %47, 1
  %49 = load ptr, ptr %2, align 8, !tbaa !8
  %50 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %2, i32 0, i32 7, i32 0, i32 2
  %51 = load i64, ptr %50, align 8, !tbaa !8
  %52 = mul i64 %48, %51
  %53 = getelementptr i8, ptr %49, i64 %52
  store double %46, ptr %53, align 8, !tbaa !4
  %54 = load ptr, ptr %2, align 8, !tbaa !8
  %55 = load i64, ptr %50, align 8, !tbaa !8
  %56 = mul i64 %48, %55
  %57 = getelementptr i8, ptr %54, i64 %56
  %58 = load double, ptr %57, align 8, !tbaa !4
  store double %58, ptr %7, align 8, !tbaa !4
  %59 = add i32 %39, 1
  %60 = sub nuw nsw i64 %40, 1
  br label %38

61:                                               ; preds = %21, %38
  ret void
}

declare ptr @_FortranAioBeginExternalFormattedOutput(ptr, i64, ptr, i32, ptr, i32) local_unnamed_addr

declare zeroext i1 @_FortranAioOutputAscii(ptr, ptr, i64) local_unnamed_addr

declare zeroext i1 @_FortranAioOutputInteger32(ptr, i32) local_unnamed_addr

declare zeroext i1 @_FortranAioOutputReal64(ptr, double) local_unnamed_addr

declare i32 @_FortranAioEndIoStatement(ptr) local_unnamed_addr

; Function Attrs: nounwind
declare i32 @omp_get_thread_num() local_unnamed_addr #3

; Function Attrs: nounwind
declare i32 @omp_get_num_threads() local_unnamed_addr #3

; Function Attrs: nounwind
declare i32 @__kmpc_global_thread_num(ptr) local_unnamed_addr #3

; Function Attrs: nounwind
declare !callback !10 void @__kmpc_fork_call(ptr, i32, ptr, ...) local_unnamed_addr #3

attributes #0 = { mustprogress nofree nounwind willreturn allockind("alloc,uninitialized") allocsize(0) memory(inaccessiblemem: readwrite) "alloc-family"="malloc" }
attributes #1 = { mustprogress nounwind willreturn allockind("free") memory(argmem: readwrite, inaccessiblemem: readwrite) "alloc-family"="malloc" }
attributes #2 = { norecurse nounwind }
attributes #3 = { nounwind }

!llvm.module.flags = !{!0, !1, !2, !3}

!0 = !{i32 2, !"Debug Info Version", i32 3}
!1 = !{i32 7, !"openmp", i32 11}
!2 = !{i32 8, !"PIC Level", i32 2}
!3 = !{i32 7, !"PIE Level", i32 2}
!4 = !{!5, !5, i64 0}
!5 = !{!"any data access", !6, i64 0}
!6 = !{!"any access", !7, i64 0}
!7 = !{!"Flang Type TBAA Root"}
!8 = !{!9, !9, i64 0}
!9 = !{!"descriptor member", !6, i64 0}
!10 = !{!11}
!11 = !{i64 2, i64 -1, i64 -1, i1 true}
*** IR Dump After PromotePass on _QQmain ***
define void @_QQmain() local_unnamed_addr {
  %1 = alloca i32, i64 1, align 4
  %2 = alloca double, i64 1, align 8
  %3 = alloca double, i64 1, align 8
  %4 = alloca { ptr, ptr }, i64 1, align 8
  store ptr %1, ptr %4, align 8, !tbaa !4
  %5 = getelementptr { ptr, ptr }, ptr %4, i32 0, i32 1
  store ptr %3, ptr %5, align 8, !tbaa !4
  store i32 1048576, ptr %1, align 4, !tbaa !4
  call void @_QFPomp_subroutine(ptr %1, ptr %2, ptr %4)
  %6 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr @_QQcl.e8a0ac9186c064ac8543d822e9060d96, i32 10)
  %7 = call i1 @_FortranAioOutputAscii(ptr %6, ptr @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %8 = load i32, ptr %1, align 4, !tbaa !4
  %9 = call i1 @_FortranAioOutputInteger32(ptr %6, i32 %8)
  %10 = call i1 @_FortranAioOutputAscii(ptr %6, ptr @_QQcl.2920697320, i64 5)
  %11 = load double, ptr %2, align 8, !tbaa !4
  %12 = call i1 @_FortranAioOutputReal64(ptr %6, double %11)
  %13 = call i32 @_FortranAioEndIoStatement(ptr %6)
  ret void
}
*** IR Dump After InstCombinePass on _QQmain ***
define void @_QQmain() local_unnamed_addr {
  %1 = alloca i32, align 4
  %2 = alloca double, align 8
  %3 = alloca double, align 8
  %4 = alloca { ptr, ptr }, align 8
  store ptr %1, ptr %4, align 8, !tbaa !4
  %5 = getelementptr inbounds { ptr, ptr }, ptr %4, i64 0, i32 1
  store ptr %3, ptr %5, align 8, !tbaa !4
  store i32 1048576, ptr %1, align 4, !tbaa !4
  call void @_QFPomp_subroutine(ptr nonnull %1, ptr nonnull %2, ptr nonnull %4)
  %6 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.e8a0ac9186c064ac8543d822e9060d96, i32 10)
  %7 = call i1 @_FortranAioOutputAscii(ptr %6, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %8 = load i32, ptr %1, align 4, !tbaa !4
  %9 = call i1 @_FortranAioOutputInteger32(ptr %6, i32 %8)
  %10 = call i1 @_FortranAioOutputAscii(ptr %6, ptr nonnull @_QQcl.2920697320, i64 5)
  %11 = load double, ptr %2, align 8, !tbaa !4
  %12 = call i1 @_FortranAioOutputReal64(ptr %6, double %11)
  %13 = call i32 @_FortranAioEndIoStatement(ptr %6)
  ret void
}
*** IR Dump After SimplifyCFGPass on _QQmain ***
define void @_QQmain() local_unnamed_addr {
  %1 = alloca i32, align 4
  %2 = alloca double, align 8
  %3 = alloca double, align 8
  %4 = alloca { ptr, ptr }, align 8
  store ptr %1, ptr %4, align 8, !tbaa !4
  %5 = getelementptr inbounds { ptr, ptr }, ptr %4, i64 0, i32 1
  store ptr %3, ptr %5, align 8, !tbaa !4
  store i32 1048576, ptr %1, align 4, !tbaa !4
  call void @_QFPomp_subroutine(ptr nonnull %1, ptr nonnull %2, ptr nonnull %4)
  %6 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.e8a0ac9186c064ac8543d822e9060d96, i32 10)
  %7 = call i1 @_FortranAioOutputAscii(ptr %6, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %8 = load i32, ptr %1, align 4, !tbaa !4
  %9 = call i1 @_FortranAioOutputInteger32(ptr %6, i32 %8)
  %10 = call i1 @_FortranAioOutputAscii(ptr %6, ptr nonnull @_QQcl.2920697320, i64 5)
  %11 = load double, ptr %2, align 8, !tbaa !4
  %12 = call i1 @_FortranAioOutputReal64(ptr %6, double %11)
  %13 = call i32 @_FortranAioEndIoStatement(ptr %6)
  ret void
}
*** IR Dump After PromotePass on _QFPomp_subroutine ***
define void @_QFPomp_subroutine(ptr %0, ptr %1, ptr nest %2) local_unnamed_addr {
entry:
  %structArg = alloca { ptr, ptr, ptr, ptr, ptr }, align 8
  %3 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %4 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %5 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, i64 1, align 8
  store ptr null, ptr %5, align 8, !tbaa !8
  %.fca.1.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i32 0, i32 1
  store i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), ptr %.fca.1.gep, align 8, !tbaa !8
  %.fca.2.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i32 0, i32 2
  store i32 20180515, ptr %.fca.2.gep, align 8, !tbaa !8
  %.fca.3.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i32 0, i32 3
  store i8 1, ptr %.fca.3.gep, align 4, !tbaa !8
  %.fca.4.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i32 0, i32 4
  store i8 28, ptr %.fca.4.gep, align 1, !tbaa !8
  %.fca.5.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i32 0, i32 5
  store i8 2, ptr %.fca.5.gep, align 2, !tbaa !8
  %.fca.6.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i32 0, i32 6
  store i8 0, ptr %.fca.6.gep, align 1, !tbaa !8
  %.fca.7.0.0.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i32 0, i32 7, i32 0, i32 0
  store i64 1, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  %.fca.7.0.1.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i32 0, i32 7, i32 0, i32 1
  store i64 0, ptr %.fca.7.0.1.gep, align 8, !tbaa !8
  %.fca.7.0.2.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i32 0, i32 7, i32 0, i32 2
  store i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), ptr %.fca.7.0.2.gep, align 8, !tbaa !8
  %6 = load i32, ptr %0, align 4, !tbaa !4
  %7 = sext i32 %6 to i64
  %8 = icmp sgt i64 %7, 0
  %9 = select i1 %8, i64 %7, i64 0
  %10 = mul i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), %9
  %11 = call ptr @malloc(i64 %10)
  %12 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } { ptr undef, i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), i32 20180515, i8 1, i8 28, i8 2, i8 0, [1 x [3 x i64]] [[3 x i64] [i64 1, i64 undef, i64 undef]] }, i64 %9, 7, 0, 1
  %13 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %12, i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), 7, 0, 2
  %14 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %13, ptr %11, 0
  %.fca.1.extract170 = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %14, 1
  %.fca.2.extract172 = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %14, 2
  %.fca.3.extract174 = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %14, 3
  %.fca.4.extract176 = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %14, 4
  %.fca.5.extract178 = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %14, 5
  %.fca.6.extract180 = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %14, 6
  %.fca.7.0.0.extract182 = extractvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %14, 7, 0, 0
  %.fca.0.insert190 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } poison, ptr %11, 0
  %.fca.1.insert193 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.0.insert190, i64 %.fca.1.extract170, 1
  %.fca.2.insert196 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.1.insert193, i32 %.fca.2.extract172, 2
  %.fca.3.insert199 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.2.insert196, i8 %.fca.3.extract174, 3
  %.fca.4.insert202 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.3.insert199, i8 %.fca.4.extract176, 4
  %.fca.5.insert205 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.4.insert202, i8 %.fca.5.extract178, 5
  %.fca.6.insert208 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.5.insert205, i8 %.fca.6.extract180, 6
  %.fca.7.0.0.insert211 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.6.insert208, i64 %.fca.7.0.0.extract182, 7, 0, 0
  %.fca.7.0.1.insert214 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.7.0.0.insert211, i64 %9, 7, 0, 1
  %.fca.7.0.2.insert217 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.7.0.1.insert214, i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), 7, 0, 2
  store ptr %11, ptr %5, align 8, !tbaa !8
  store i64 %.fca.1.extract170, ptr %.fca.1.gep, align 8, !tbaa !8
  store i32 %.fca.2.extract172, ptr %.fca.2.gep, align 8, !tbaa !8
  store i8 %.fca.3.extract174, ptr %.fca.3.gep, align 4, !tbaa !8
  store i8 %.fca.4.extract176, ptr %.fca.4.gep, align 1, !tbaa !8
  store i8 %.fca.5.extract178, ptr %.fca.5.gep, align 2, !tbaa !8
  store i8 %.fca.6.extract180, ptr %.fca.6.gep, align 1, !tbaa !8
  store i64 %.fca.7.0.0.extract182, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  store i64 %9, ptr %.fca.7.0.1.gep, align 8, !tbaa !8
  store i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), ptr %.fca.7.0.2.gep, align 8, !tbaa !8
  %omp_global_thread_num = call i32 @__kmpc_global_thread_num(ptr @1)
  store ptr %0, ptr %structArg, align 8
  %gep_5 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i32 0, i32 1
  store ptr %5, ptr %gep_5, align 8
  %gep_6 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i32 0, i32 2
  store ptr %4, ptr %gep_6, align 8
  %gep_7 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i32 0, i32 3
  store ptr %3, ptr %gep_7, align 8
  %gep_8 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i32 0, i32 4
  store ptr %2, ptr %gep_8, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr @1, i32 1, ptr @_QFPomp_subroutine..omp_par, ptr %structArg)
  %.fca.0.load = load ptr, ptr %5, align 8, !tbaa !8
  %.fca.0.insert = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } poison, ptr %.fca.0.load, 0
  %.fca.1.load = load i64, ptr %.fca.1.gep, align 8, !tbaa !8
  %.fca.1.insert = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.0.insert, i64 %.fca.1.load, 1
  %.fca.2.load = load i32, ptr %.fca.2.gep, align 8, !tbaa !8
  %.fca.2.insert = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.1.insert, i32 %.fca.2.load, 2
  %.fca.3.load = load i8, ptr %.fca.3.gep, align 4, !tbaa !8
  %.fca.3.insert = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.2.insert, i8 %.fca.3.load, 3
  %.fca.4.load = load i8, ptr %.fca.4.gep, align 1, !tbaa !8
  %.fca.4.insert = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.3.insert, i8 %.fca.4.load, 4
  %.fca.5.load = load i8, ptr %.fca.5.gep, align 2, !tbaa !8
  %.fca.5.insert = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.4.insert, i8 %.fca.5.load, 5
  %.fca.6.load = load i8, ptr %.fca.6.gep, align 1, !tbaa !8
  %.fca.6.insert = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.5.insert, i8 %.fca.6.load, 6
  %.fca.7.0.0.load = load i64, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  %.fca.7.0.0.insert = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.6.insert, i64 %.fca.7.0.0.load, 7, 0, 0
  %.fca.7.0.1.load = load i64, ptr %.fca.7.0.1.gep, align 8, !tbaa !8
  %.fca.7.0.1.insert = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.7.0.0.insert, i64 %.fca.7.0.1.load, 7, 0, 1
  %.fca.7.0.2.load = load i64, ptr %.fca.7.0.2.gep, align 8, !tbaa !8
  %.fca.7.0.2.insert = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.7.0.1.insert, i64 %.fca.7.0.2.load, 7, 0, 2
  %15 = sub i64 1, %.fca.7.0.0.load
  %16 = getelementptr double, ptr %.fca.0.load, i64 %15
  %17 = load double, ptr %16, align 8, !tbaa !4
  %18 = load i32, ptr %0, align 4, !tbaa !4
  %19 = sext i32 %18 to i64
  %20 = sub i64 %19, %.fca.7.0.0.load
  %21 = getelementptr double, ptr %.fca.0.load, i64 %20
  %22 = load double, ptr %21, align 8, !tbaa !4
  %23 = fadd contract double %17, %22
  store double %23, ptr %1, align 8, !tbaa !4
  %.fca.0.load40 = load ptr, ptr %5, align 8, !tbaa !8
  %.fca.0.insert41 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } poison, ptr %.fca.0.load40, 0
  %.fca.1.load43 = load i64, ptr %.fca.1.gep, align 8, !tbaa !8
  %.fca.1.insert44 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.0.insert41, i64 %.fca.1.load43, 1
  %.fca.2.load46 = load i32, ptr %.fca.2.gep, align 8, !tbaa !8
  %.fca.2.insert47 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.1.insert44, i32 %.fca.2.load46, 2
  %.fca.3.load49 = load i8, ptr %.fca.3.gep, align 4, !tbaa !8
  %.fca.3.insert50 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.2.insert47, i8 %.fca.3.load49, 3
  %.fca.4.load52 = load i8, ptr %.fca.4.gep, align 1, !tbaa !8
  %.fca.4.insert53 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.3.insert50, i8 %.fca.4.load52, 4
  %.fca.5.load55 = load i8, ptr %.fca.5.gep, align 2, !tbaa !8
  %.fca.5.insert56 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.4.insert53, i8 %.fca.5.load55, 5
  %.fca.6.load58 = load i8, ptr %.fca.6.gep, align 1, !tbaa !8
  %.fca.6.insert59 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.5.insert56, i8 %.fca.6.load58, 6
  %.fca.7.0.0.load61 = load i64, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  %.fca.7.0.0.insert62 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.6.insert59, i64 %.fca.7.0.0.load61, 7, 0, 0
  %.fca.7.0.1.load64 = load i64, ptr %.fca.7.0.1.gep, align 8, !tbaa !8
  %.fca.7.0.1.insert65 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.7.0.0.insert62, i64 %.fca.7.0.1.load64, 7, 0, 1
  %.fca.7.0.2.load67 = load i64, ptr %.fca.7.0.2.gep, align 8, !tbaa !8
  %.fca.7.0.2.insert68 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %.fca.7.0.1.insert65, i64 %.fca.7.0.2.load67, 7, 0, 2
  call void @free(ptr %.fca.0.load40)
  store ptr null, ptr %5, align 8, !tbaa !8
  store i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), ptr %.fca.1.gep, align 8, !tbaa !8
  store i32 20180515, ptr %.fca.2.gep, align 8, !tbaa !8
  store i8 1, ptr %.fca.3.gep, align 4, !tbaa !8
  store i8 28, ptr %.fca.4.gep, align 1, !tbaa !8
  store i8 2, ptr %.fca.5.gep, align 2, !tbaa !8
  store i8 0, ptr %.fca.6.gep, align 1, !tbaa !8
  store i64 1, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  store i64 0, ptr %.fca.7.0.1.gep, align 8, !tbaa !8
  store i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), ptr %.fca.7.0.2.gep, align 8, !tbaa !8
  ret void
}
*** IR Dump After InstCombinePass on _QFPomp_subroutine ***
define void @_QFPomp_subroutine(ptr %0, ptr %1, ptr nest %2) local_unnamed_addr {
entry:
  %structArg = alloca { ptr, ptr, ptr, ptr, ptr }, align 8
  %3 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %4 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %5 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  store ptr null, ptr %5, align 8, !tbaa !8
  %.fca.1.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 1
  store i64 8, ptr %.fca.1.gep, align 8, !tbaa !8
  %.fca.2.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 2
  store i32 20180515, ptr %.fca.2.gep, align 8, !tbaa !8
  %.fca.3.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 3
  store i8 1, ptr %.fca.3.gep, align 4, !tbaa !8
  %.fca.4.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 4
  store i8 28, ptr %.fca.4.gep, align 1, !tbaa !8
  %.fca.5.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 5
  store i8 2, ptr %.fca.5.gep, align 2, !tbaa !8
  %.fca.6.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 6
  store i8 0, ptr %.fca.6.gep, align 1, !tbaa !8
  %.fca.7.0.0.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 0
  store i64 1, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  %.fca.7.0.1.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 1
  store i64 0, ptr %.fca.7.0.1.gep, align 8, !tbaa !8
  %.fca.7.0.2.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 2
  store i64 8, ptr %.fca.7.0.2.gep, align 8, !tbaa !8
  %6 = load i32, ptr %0, align 4, !tbaa !4
  %7 = call i32 @llvm.smax.i32(i32 %6, i32 0)
  %8 = zext i32 %7 to i64
  %9 = shl nuw nsw i64 %8, 3
  %10 = call ptr @malloc(i64 %9)
  store ptr %10, ptr %5, align 8, !tbaa !8
  store i64 8, ptr %.fca.1.gep, align 8, !tbaa !8
  store i32 20180515, ptr %.fca.2.gep, align 8, !tbaa !8
  store i8 1, ptr %.fca.3.gep, align 4, !tbaa !8
  store i8 28, ptr %.fca.4.gep, align 1, !tbaa !8
  store i8 2, ptr %.fca.5.gep, align 2, !tbaa !8
  store i8 0, ptr %.fca.6.gep, align 1, !tbaa !8
  store i64 1, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  store i64 %8, ptr %.fca.7.0.1.gep, align 8, !tbaa !8
  store i64 8, ptr %.fca.7.0.2.gep, align 8, !tbaa !8
  %omp_global_thread_num = call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %0, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %5, ptr %gep_5, align 8
  %gep_6 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 2
  store ptr %4, ptr %gep_6, align 8
  %gep_7 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 3
  store ptr %3, ptr %gep_7, align 8
  %gep_8 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 4
  store ptr %2, ptr %gep_8, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QFPomp_subroutine..omp_par, ptr nonnull %structArg)
  %.fca.0.load = load ptr, ptr %5, align 8, !tbaa !8
  %.fca.7.0.0.load = load i64, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  %11 = sub i64 1, %.fca.7.0.0.load
  %12 = getelementptr double, ptr %.fca.0.load, i64 %11
  %13 = load double, ptr %12, align 8, !tbaa !4
  %14 = load i32, ptr %0, align 4, !tbaa !4
  %15 = sext i32 %14 to i64
  %16 = sub i64 %15, %.fca.7.0.0.load
  %17 = getelementptr double, ptr %.fca.0.load, i64 %16
  %18 = load double, ptr %17, align 8, !tbaa !4
  %19 = fadd contract double %13, %18
  store double %19, ptr %1, align 8, !tbaa !4
  %.fca.0.load40 = load ptr, ptr %5, align 8, !tbaa !8
  call void @free(ptr %.fca.0.load40)
  store ptr null, ptr %5, align 8, !tbaa !8
  store i64 8, ptr %.fca.1.gep, align 8, !tbaa !8
  store i32 20180515, ptr %.fca.2.gep, align 8, !tbaa !8
  store i8 1, ptr %.fca.3.gep, align 4, !tbaa !8
  store i8 28, ptr %.fca.4.gep, align 1, !tbaa !8
  store i8 2, ptr %.fca.5.gep, align 2, !tbaa !8
  store i8 0, ptr %.fca.6.gep, align 1, !tbaa !8
  store i64 1, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  store i64 0, ptr %.fca.7.0.1.gep, align 8, !tbaa !8
  store i64 8, ptr %.fca.7.0.2.gep, align 8, !tbaa !8
  ret void
}
*** IR Dump After SimplifyCFGPass on _QFPomp_subroutine ***
define void @_QFPomp_subroutine(ptr %0, ptr %1, ptr nest %2) local_unnamed_addr {
entry:
  %structArg = alloca { ptr, ptr, ptr, ptr, ptr }, align 8
  %3 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %4 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %5 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  store ptr null, ptr %5, align 8, !tbaa !8
  %.fca.1.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 1
  store i64 8, ptr %.fca.1.gep, align 8, !tbaa !8
  %.fca.2.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 2
  store i32 20180515, ptr %.fca.2.gep, align 8, !tbaa !8
  %.fca.3.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 3
  store i8 1, ptr %.fca.3.gep, align 4, !tbaa !8
  %.fca.4.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 4
  store i8 28, ptr %.fca.4.gep, align 1, !tbaa !8
  %.fca.5.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 5
  store i8 2, ptr %.fca.5.gep, align 2, !tbaa !8
  %.fca.6.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 6
  store i8 0, ptr %.fca.6.gep, align 1, !tbaa !8
  %.fca.7.0.0.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 0
  store i64 1, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  %.fca.7.0.1.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 1
  store i64 0, ptr %.fca.7.0.1.gep, align 8, !tbaa !8
  %.fca.7.0.2.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 2
  store i64 8, ptr %.fca.7.0.2.gep, align 8, !tbaa !8
  %6 = load i32, ptr %0, align 4, !tbaa !4
  %7 = call i32 @llvm.smax.i32(i32 %6, i32 0)
  %8 = zext i32 %7 to i64
  %9 = shl nuw nsw i64 %8, 3
  %10 = call ptr @malloc(i64 %9)
  store ptr %10, ptr %5, align 8, !tbaa !8
  store i64 8, ptr %.fca.1.gep, align 8, !tbaa !8
  store i32 20180515, ptr %.fca.2.gep, align 8, !tbaa !8
  store i8 1, ptr %.fca.3.gep, align 4, !tbaa !8
  store i8 28, ptr %.fca.4.gep, align 1, !tbaa !8
  store i8 2, ptr %.fca.5.gep, align 2, !tbaa !8
  store i8 0, ptr %.fca.6.gep, align 1, !tbaa !8
  store i64 1, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  store i64 %8, ptr %.fca.7.0.1.gep, align 8, !tbaa !8
  store i64 8, ptr %.fca.7.0.2.gep, align 8, !tbaa !8
  %omp_global_thread_num = call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %0, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %5, ptr %gep_5, align 8
  %gep_6 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 2
  store ptr %4, ptr %gep_6, align 8
  %gep_7 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 3
  store ptr %3, ptr %gep_7, align 8
  %gep_8 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 4
  store ptr %2, ptr %gep_8, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QFPomp_subroutine..omp_par, ptr nonnull %structArg)
  %.fca.0.load = load ptr, ptr %5, align 8, !tbaa !8
  %.fca.7.0.0.load = load i64, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  %11 = sub i64 1, %.fca.7.0.0.load
  %12 = getelementptr double, ptr %.fca.0.load, i64 %11
  %13 = load double, ptr %12, align 8, !tbaa !4
  %14 = load i32, ptr %0, align 4, !tbaa !4
  %15 = sext i32 %14 to i64
  %16 = sub i64 %15, %.fca.7.0.0.load
  %17 = getelementptr double, ptr %.fca.0.load, i64 %16
  %18 = load double, ptr %17, align 8, !tbaa !4
  %19 = fadd contract double %13, %18
  store double %19, ptr %1, align 8, !tbaa !4
  %.fca.0.load40 = load ptr, ptr %5, align 8, !tbaa !8
  call void @free(ptr %.fca.0.load40)
  store ptr null, ptr %5, align 8, !tbaa !8
  store i64 8, ptr %.fca.1.gep, align 8, !tbaa !8
  store i32 20180515, ptr %.fca.2.gep, align 8, !tbaa !8
  store i8 1, ptr %.fca.3.gep, align 4, !tbaa !8
  store i8 28, ptr %.fca.4.gep, align 1, !tbaa !8
  store i8 2, ptr %.fca.5.gep, align 2, !tbaa !8
  store i8 0, ptr %.fca.6.gep, align 1, !tbaa !8
  store i64 1, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  store i64 0, ptr %.fca.7.0.1.gep, align 8, !tbaa !8
  store i64 8, ptr %.fca.7.0.2.gep, align 8, !tbaa !8
  ret void
}
*** IR Dump After PromotePass on _QFPomp_subroutine..omp_par ***
; Function Attrs: norecurse nounwind
define internal void @_QFPomp_subroutine..omp_par(ptr noalias %tid.addr, ptr noalias %zero.addr, ptr %0) #2 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i32 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %gep_3 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i32 0, i32 2
  %loadgep_4 = load ptr, ptr %gep_3, align 8
  %gep_5 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i32 0, i32 3
  %loadgep_6 = load ptr, ptr %gep_5, align 8
  %gep_7 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i32 0, i32 4
  %loadgep_8 = load ptr, ptr %gep_7, align 8
  %1 = alloca i32, i64 1, align 4
  %2 = alloca i32, i64 1, align 4
  %3 = call i32 @omp_get_thread_num()
  %4 = call i32 @omp_get_num_threads()
  %5 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %6 = sdiv i32 %5, %4
  %7 = mul i32 %3, %6
  %8 = add i32 %7, 1
  store i32 %8, ptr %1, align 4, !tbaa !4
  %9 = sub i32 %4, 1
  %10 = icmp eq i32 %3, %9
  br i1 %10, label %omp.par.region2, label %omp.par.region3

omp.par.region3:                                  ; preds = %omp.par.entry
  %11 = add i32 %8, %6
  store i32 %11, ptr %2, align 4, !tbaa !4
  br label %omp.par.region4

omp.par.region4:                                  ; preds = %omp.par.region2, %omp.par.region3
  %12 = load { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, align 8, !tbaa !8
  store { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %12, ptr %loadgep_4, align 8, !tbaa !8
  %13 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i32 0, i32 7, i64 0, i32 0
  %14 = load i64, ptr %13, align 8, !tbaa !8
  %15 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i32 0, i32 7, i64 0, i32 1
  %16 = load i64, ptr %15, align 8, !tbaa !8
  %17 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i32 0, i32 7, i64 0, i32 2
  %18 = load ptr, ptr %loadgep_4, align 8, !tbaa !8
  %19 = icmp eq i64 %16, 0
  %20 = select i1 %19, i64 1, i64 %14
  %21 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } { ptr undef, i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), i32 20180515, i8 1, i8 28, i8 0, i8 0, [1 x [3 x i64]] undef }, i64 %20, 7, 0, 0
  %22 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %21, i64 %16, 7, 0, 1
  %23 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %22, i64 ptrtoint (ptr getelementptr (double, ptr null, i32 1) to i64), 7, 0, 2
  %24 = insertvalue { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %23, ptr %18, 0
  store { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] } %24, ptr %loadgep_6, align 8, !tbaa !8
  call void @_QFPloop(ptr %1, ptr %2, ptr %loadgep_6, ptr %loadgep_8)
  ret void

omp.par.region2:                                  ; preds = %omp.par.entry
  %25 = load i32, ptr %loadgep_, align 4, !tbaa !4
  store i32 %25, ptr %2, align 4, !tbaa !4
  br label %omp.par.region4
}
*** IR Dump After InstCombinePass on _QFPomp_subroutine..omp_par ***
; Function Attrs: norecurse nounwind
define internal void @_QFPomp_subroutine..omp_par(ptr noalias %tid.addr, ptr noalias %zero.addr, ptr %0) #2 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %gep_3 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 2
  %loadgep_4 = load ptr, ptr %gep_3, align 8
  %gep_5 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 3
  %loadgep_6 = load ptr, ptr %gep_5, align 8
  %gep_7 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 4
  %loadgep_8 = load ptr, ptr %gep_7, align 8
  %1 = alloca i32, align 4
  %2 = alloca i32, align 4
  %3 = call i32 @omp_get_thread_num()
  %4 = call i32 @omp_get_num_threads()
  %5 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %6 = sdiv i32 %5, %4
  %7 = mul i32 %3, %6
  %8 = add i32 %7, 1
  store i32 %8, ptr %1, align 4, !tbaa !4
  %9 = add i32 %4, -1
  %10 = icmp eq i32 %3, %9
  br i1 %10, label %omp.par.region2, label %omp.par.region3

omp.par.region3:                                  ; preds = %omp.par.entry
  %11 = add i32 %8, %6
  br label %omp.par.region4

omp.par.region4:                                  ; preds = %omp.par.region2, %omp.par.region3
  %storemerge = phi i32 [ %11, %omp.par.region3 ], [ %17, %omp.par.region2 ]
  store i32 %storemerge, ptr %2, align 4, !tbaa !4
  %.unpack = load ptr, ptr %loadgep_2, align 8, !tbaa !8
  %.elt14 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  %.unpack15 = load i64, ptr %.elt14, align 8, !tbaa !8
  %.elt16 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  %.unpack17 = load i32, ptr %.elt16, align 8, !tbaa !8
  %.elt18 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  %.unpack19 = load i8, ptr %.elt18, align 4, !tbaa !8
  %.elt20 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  %.unpack21 = load i8, ptr %.elt20, align 1, !tbaa !8
  %.elt22 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  %.unpack23 = load i8, ptr %.elt22, align 2, !tbaa !8
  %.elt24 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  %.unpack25 = load i8, ptr %.elt24, align 1, !tbaa !8
  %.elt26 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  %.unpack27.unpack.unpack = load i64, ptr %.elt26, align 8, !tbaa !8
  %.unpack27.unpack.elt29 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  %.unpack27.unpack.unpack30 = load i64, ptr %.unpack27.unpack.elt29, align 8, !tbaa !8
  %.unpack27.unpack.elt31 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  %.unpack27.unpack.unpack32 = load i64, ptr %.unpack27.unpack.elt31, align 8, !tbaa !8
  store ptr %.unpack, ptr %loadgep_4, align 8, !tbaa !8
  %loadgep_4.repack34 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 1
  store i64 %.unpack15, ptr %loadgep_4.repack34, align 8, !tbaa !8
  %loadgep_4.repack36 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 2
  store i32 %.unpack17, ptr %loadgep_4.repack36, align 8, !tbaa !8
  %loadgep_4.repack38 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 3
  store i8 %.unpack19, ptr %loadgep_4.repack38, align 4, !tbaa !8
  %loadgep_4.repack40 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 4
  store i8 %.unpack21, ptr %loadgep_4.repack40, align 1, !tbaa !8
  %loadgep_4.repack42 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 5
  store i8 %.unpack23, ptr %loadgep_4.repack42, align 2, !tbaa !8
  %loadgep_4.repack44 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 6
  store i8 %.unpack25, ptr %loadgep_4.repack44, align 1, !tbaa !8
  %loadgep_4.repack46 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7
  store i64 %.unpack27.unpack.unpack, ptr %loadgep_4.repack46, align 8, !tbaa !8
  %loadgep_4.repack46.repack48 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack27.unpack.unpack30, ptr %loadgep_4.repack46.repack48, align 8, !tbaa !8
  %loadgep_4.repack46.repack50 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 2
  store i64 %.unpack27.unpack.unpack32, ptr %loadgep_4.repack46.repack50, align 8, !tbaa !8
  %12 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 0
  %13 = load i64, ptr %12, align 8, !tbaa !8
  %14 = load ptr, ptr %loadgep_4, align 8, !tbaa !8
  %15 = icmp eq i64 %.unpack27.unpack.unpack30, 0
  %16 = select i1 %15, i64 1, i64 %13
  store ptr %14, ptr %loadgep_6, align 8, !tbaa !8
  %loadgep_6.repack52 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 1
  store i64 8, ptr %loadgep_6.repack52, align 8, !tbaa !8
  %loadgep_6.repack54 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 2
  store i32 20180515, ptr %loadgep_6.repack54, align 8, !tbaa !8
  %loadgep_6.repack56 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 3
  store i8 1, ptr %loadgep_6.repack56, align 4, !tbaa !8
  %loadgep_6.repack58 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 4
  store i8 28, ptr %loadgep_6.repack58, align 1, !tbaa !8
  %loadgep_6.repack60 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 5
  store i8 0, ptr %loadgep_6.repack60, align 2, !tbaa !8
  %loadgep_6.repack62 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 6
  store i8 0, ptr %loadgep_6.repack62, align 1, !tbaa !8
  %loadgep_6.repack64 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7
  store i64 %16, ptr %loadgep_6.repack64, align 8, !tbaa !8
  %loadgep_6.repack64.repack66 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack27.unpack.unpack30, ptr %loadgep_6.repack64.repack66, align 8, !tbaa !8
  %loadgep_6.repack64.repack68 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7, i64 0, i64 2
  store i64 8, ptr %loadgep_6.repack64.repack68, align 8, !tbaa !8
  call void @_QFPloop(ptr nonnull %1, ptr nonnull %2, ptr nonnull %loadgep_6, ptr %loadgep_8) #3
  ret void

omp.par.region2:                                  ; preds = %omp.par.entry
  %17 = load i32, ptr %loadgep_, align 4, !tbaa !4
  br label %omp.par.region4
}
*** IR Dump After SimplifyCFGPass on _QFPomp_subroutine..omp_par ***
; Function Attrs: norecurse nounwind
define internal void @_QFPomp_subroutine..omp_par(ptr noalias %tid.addr, ptr noalias %zero.addr, ptr %0) #2 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %gep_3 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 2
  %loadgep_4 = load ptr, ptr %gep_3, align 8
  %gep_5 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 3
  %loadgep_6 = load ptr, ptr %gep_5, align 8
  %gep_7 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 4
  %loadgep_8 = load ptr, ptr %gep_7, align 8
  %1 = alloca i32, align 4
  %2 = alloca i32, align 4
  %3 = call i32 @omp_get_thread_num()
  %4 = call i32 @omp_get_num_threads()
  %5 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %6 = sdiv i32 %5, %4
  %7 = mul i32 %3, %6
  %8 = add i32 %7, 1
  store i32 %8, ptr %1, align 4, !tbaa !4
  %9 = add i32 %4, -1
  %10 = icmp eq i32 %3, %9
  br i1 %10, label %omp.par.region2, label %omp.par.region3

omp.par.region3:                                  ; preds = %omp.par.entry
  %11 = add i32 %8, %6
  br label %omp.par.region4

omp.par.region4:                                  ; preds = %omp.par.region2, %omp.par.region3
  %storemerge = phi i32 [ %11, %omp.par.region3 ], [ %17, %omp.par.region2 ]
  store i32 %storemerge, ptr %2, align 4, !tbaa !4
  %.unpack = load ptr, ptr %loadgep_2, align 8, !tbaa !8
  %.elt14 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  %.unpack15 = load i64, ptr %.elt14, align 8, !tbaa !8
  %.elt16 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  %.unpack17 = load i32, ptr %.elt16, align 8, !tbaa !8
  %.elt18 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  %.unpack19 = load i8, ptr %.elt18, align 4, !tbaa !8
  %.elt20 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  %.unpack21 = load i8, ptr %.elt20, align 1, !tbaa !8
  %.elt22 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  %.unpack23 = load i8, ptr %.elt22, align 2, !tbaa !8
  %.elt24 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  %.unpack25 = load i8, ptr %.elt24, align 1, !tbaa !8
  %.elt26 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  %.unpack27.unpack.unpack = load i64, ptr %.elt26, align 8, !tbaa !8
  %.unpack27.unpack.elt29 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  %.unpack27.unpack.unpack30 = load i64, ptr %.unpack27.unpack.elt29, align 8, !tbaa !8
  %.unpack27.unpack.elt31 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  %.unpack27.unpack.unpack32 = load i64, ptr %.unpack27.unpack.elt31, align 8, !tbaa !8
  store ptr %.unpack, ptr %loadgep_4, align 8, !tbaa !8
  %loadgep_4.repack34 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 1
  store i64 %.unpack15, ptr %loadgep_4.repack34, align 8, !tbaa !8
  %loadgep_4.repack36 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 2
  store i32 %.unpack17, ptr %loadgep_4.repack36, align 8, !tbaa !8
  %loadgep_4.repack38 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 3
  store i8 %.unpack19, ptr %loadgep_4.repack38, align 4, !tbaa !8
  %loadgep_4.repack40 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 4
  store i8 %.unpack21, ptr %loadgep_4.repack40, align 1, !tbaa !8
  %loadgep_4.repack42 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 5
  store i8 %.unpack23, ptr %loadgep_4.repack42, align 2, !tbaa !8
  %loadgep_4.repack44 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 6
  store i8 %.unpack25, ptr %loadgep_4.repack44, align 1, !tbaa !8
  %loadgep_4.repack46 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7
  store i64 %.unpack27.unpack.unpack, ptr %loadgep_4.repack46, align 8, !tbaa !8
  %loadgep_4.repack46.repack48 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack27.unpack.unpack30, ptr %loadgep_4.repack46.repack48, align 8, !tbaa !8
  %loadgep_4.repack46.repack50 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 2
  store i64 %.unpack27.unpack.unpack32, ptr %loadgep_4.repack46.repack50, align 8, !tbaa !8
  %12 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 0
  %13 = load i64, ptr %12, align 8, !tbaa !8
  %14 = load ptr, ptr %loadgep_4, align 8, !tbaa !8
  %15 = icmp eq i64 %.unpack27.unpack.unpack30, 0
  %16 = select i1 %15, i64 1, i64 %13
  store ptr %14, ptr %loadgep_6, align 8, !tbaa !8
  %loadgep_6.repack52 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 1
  store i64 8, ptr %loadgep_6.repack52, align 8, !tbaa !8
  %loadgep_6.repack54 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 2
  store i32 20180515, ptr %loadgep_6.repack54, align 8, !tbaa !8
  %loadgep_6.repack56 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 3
  store i8 1, ptr %loadgep_6.repack56, align 4, !tbaa !8
  %loadgep_6.repack58 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 4
  store i8 28, ptr %loadgep_6.repack58, align 1, !tbaa !8
  %loadgep_6.repack60 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 5
  store i8 0, ptr %loadgep_6.repack60, align 2, !tbaa !8
  %loadgep_6.repack62 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 6
  store i8 0, ptr %loadgep_6.repack62, align 1, !tbaa !8
  %loadgep_6.repack64 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7
  store i64 %16, ptr %loadgep_6.repack64, align 8, !tbaa !8
  %loadgep_6.repack64.repack66 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack27.unpack.unpack30, ptr %loadgep_6.repack64.repack66, align 8, !tbaa !8
  %loadgep_6.repack64.repack68 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7, i64 0, i64 2
  store i64 8, ptr %loadgep_6.repack64.repack68, align 8, !tbaa !8
  call void @_QFPloop(ptr nonnull %1, ptr nonnull %2, ptr nonnull %loadgep_6, ptr %loadgep_8) #3
  ret void

omp.par.region2:                                  ; preds = %omp.par.entry
  %17 = load i32, ptr %loadgep_, align 4, !tbaa !4
  br label %omp.par.region4
}
*** IR Dump After PromotePass on _QFPloop ***
define void @_QFPloop(ptr %0, ptr %1, ptr %2, ptr nest %3) local_unnamed_addr {
  %5 = load ptr, ptr %3, align 8, !tbaa !4
  %6 = getelementptr { ptr, ptr }, ptr %3, i32 0, i32 1
  %7 = load ptr, ptr %6, align 8, !tbaa !4
  %8 = load i32, ptr %0, align 4, !tbaa !4
  %9 = sext i32 %8 to i64
  %10 = load i32, ptr %1, align 4, !tbaa !4
  %11 = sext i32 %10 to i64
  %12 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %2, i32 0, i32 7, i64 0, i32 0
  %13 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %2, i32 0, i32 7, i64 0, i32 1
  %14 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %2, i32 0, i32 7, i64 0, i32 2
  %15 = load i64, ptr %14, align 8, !tbaa !8
  %16 = icmp eq i64 %15, 8
  br i1 %16, label %17, label %35

17:                                               ; preds = %4
  %18 = load ptr, ptr %2, align 8, !tbaa !8
  %19 = sub nsw i64 %11, %9
  %20 = add nsw i64 %19, 1
  br label %21

21:                                               ; preds = %25, %17
  %22 = phi i32 [ %33, %25 ], [ %8, %17 ]
  %23 = phi i64 [ %34, %25 ], [ %20, %17 ]
  %24 = icmp sgt i64 %23, 0
  br i1 %24, label %25, label %61

25:                                               ; preds = %21
  %26 = load i32, ptr %5, align 4, !tbaa !4
  %27 = sitofp i32 %26 to float
  %28 = fdiv contract float 1.000000e+00, %27
  %29 = fpext float %28 to double
  %30 = sext i32 %22 to i64
  %31 = sub nsw i64 %30, 1
  %32 = getelementptr double, ptr %18, i64 %31
  store double %29, ptr %32, align 8, !tbaa !4
  store double %29, ptr %7, align 8, !tbaa !4
  %33 = add i32 %22, 1
  %34 = sub nuw nsw i64 %23, 1
  br label %21

35:                                               ; preds = %4
  %36 = sub nsw i64 %11, %9
  %37 = add nsw i64 %36, 1
  br label %38

38:                                               ; preds = %42, %35
  %39 = phi i32 [ %59, %42 ], [ %8, %35 ]
  %40 = phi i64 [ %60, %42 ], [ %37, %35 ]
  %41 = icmp sgt i64 %40, 0
  br i1 %41, label %42, label %61

42:                                               ; preds = %38
  %43 = load i32, ptr %5, align 4, !tbaa !4
  %44 = sitofp i32 %43 to float
  %45 = fdiv contract float 1.000000e+00, %44
  %46 = fpext float %45 to double
  %47 = sext i32 %39 to i64
  %48 = sub nsw i64 %47, 1
  %49 = load ptr, ptr %2, align 8, !tbaa !8
  %50 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %2, i32 0, i32 7, i32 0, i32 2
  %51 = load i64, ptr %50, align 8, !tbaa !8
  %52 = mul i64 %48, %51
  %53 = getelementptr i8, ptr %49, i64 %52
  store double %46, ptr %53, align 8, !tbaa !4
  %54 = load ptr, ptr %2, align 8, !tbaa !8
  %55 = load i64, ptr %50, align 8, !tbaa !8
  %56 = mul i64 %48, %55
  %57 = getelementptr i8, ptr %54, i64 %56
  %58 = load double, ptr %57, align 8, !tbaa !4
  store double %58, ptr %7, align 8, !tbaa !4
  %59 = add i32 %39, 1
  %60 = sub nuw nsw i64 %40, 1
  br label %38

61:                                               ; preds = %21, %38
  ret void
}
*** IR Dump After InstCombinePass on _QFPloop ***
define void @_QFPloop(ptr %0, ptr %1, ptr %2, ptr nest %3) local_unnamed_addr {
  %5 = load ptr, ptr %3, align 8, !tbaa !4
  %6 = getelementptr { ptr, ptr }, ptr %3, i64 0, i32 1
  %7 = load ptr, ptr %6, align 8, !tbaa !4
  %8 = load i32, ptr %0, align 4, !tbaa !4
  %9 = sext i32 %8 to i64
  %10 = load i32, ptr %1, align 4, !tbaa !4
  %11 = sext i32 %10 to i64
  %12 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %2, i64 0, i32 7, i64 0, i64 2
  %13 = load i64, ptr %12, align 8, !tbaa !8
  %14 = icmp eq i64 %13, 8
  br i1 %14, label %15, label %33

15:                                               ; preds = %4
  %16 = load ptr, ptr %2, align 8, !tbaa !8
  %17 = sub nsw i64 %11, %9
  %18 = add nsw i64 %17, 1
  br label %19

19:                                               ; preds = %23, %15
  %20 = phi i32 [ %31, %23 ], [ %8, %15 ]
  %21 = phi i64 [ %32, %23 ], [ %18, %15 ]
  %22 = icmp sgt i64 %21, 0
  br i1 %22, label %23, label %57

23:                                               ; preds = %19
  %24 = load i32, ptr %5, align 4, !tbaa !4
  %25 = sitofp i32 %24 to float
  %26 = fdiv contract float 1.000000e+00, %25
  %27 = fpext float %26 to double
  %28 = sext i32 %20 to i64
  %29 = add nsw i64 %28, -1
  %30 = getelementptr double, ptr %16, i64 %29
  store double %27, ptr %30, align 8, !tbaa !4
  store double %27, ptr %7, align 8, !tbaa !4
  %31 = add i32 %20, 1
  %32 = add nsw i64 %21, -1
  br label %19

33:                                               ; preds = %4
  %34 = sub nsw i64 %11, %9
  %35 = add nsw i64 %34, 1
  br label %36

36:                                               ; preds = %40, %33
  %37 = phi i32 [ %55, %40 ], [ %8, %33 ]
  %38 = phi i64 [ %56, %40 ], [ %35, %33 ]
  %39 = icmp sgt i64 %38, 0
  br i1 %39, label %40, label %57

40:                                               ; preds = %36
  %41 = load i32, ptr %5, align 4, !tbaa !4
  %42 = sitofp i32 %41 to float
  %43 = fdiv contract float 1.000000e+00, %42
  %44 = fpext float %43 to double
  %45 = sext i32 %37 to i64
  %46 = add nsw i64 %45, -1
  %47 = load ptr, ptr %2, align 8, !tbaa !8
  %48 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %2, i64 0, i32 7, i64 0, i64 2
  %49 = load i64, ptr %48, align 8, !tbaa !8
  %50 = mul i64 %46, %49
  %51 = getelementptr i8, ptr %47, i64 %50
  store double %44, ptr %51, align 8, !tbaa !4
  %52 = mul i64 %46, %49
  %53 = getelementptr i8, ptr %47, i64 %52
  %54 = load double, ptr %53, align 8, !tbaa !4
  store double %54, ptr %7, align 8, !tbaa !4
  %55 = add i32 %37, 1
  %56 = add nsw i64 %38, -1
  br label %36

57:                                               ; preds = %19, %36
  ret void
}
*** IR Dump After SimplifyCFGPass on _QFPloop ***
define void @_QFPloop(ptr %0, ptr %1, ptr %2, ptr nest %3) local_unnamed_addr {
  %5 = load ptr, ptr %3, align 8, !tbaa !4
  %6 = getelementptr { ptr, ptr }, ptr %3, i64 0, i32 1
  %7 = load ptr, ptr %6, align 8, !tbaa !4
  %8 = load i32, ptr %0, align 4, !tbaa !4
  %9 = sext i32 %8 to i64
  %10 = load i32, ptr %1, align 4, !tbaa !4
  %11 = sext i32 %10 to i64
  %12 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %2, i64 0, i32 7, i64 0, i64 2
  %13 = load i64, ptr %12, align 8, !tbaa !8
  %14 = icmp eq i64 %13, 8
  br i1 %14, label %15, label %33

15:                                               ; preds = %4
  %16 = load ptr, ptr %2, align 8, !tbaa !8
  %17 = sub nsw i64 %11, %9
  %18 = add nsw i64 %17, 1
  br label %19

19:                                               ; preds = %23, %15
  %20 = phi i32 [ %31, %23 ], [ %8, %15 ]
  %21 = phi i64 [ %32, %23 ], [ %18, %15 ]
  %22 = icmp sgt i64 %21, 0
  br i1 %22, label %23, label %57

23:                                               ; preds = %19
  %24 = load i32, ptr %5, align 4, !tbaa !4
  %25 = sitofp i32 %24 to float
  %26 = fdiv contract float 1.000000e+00, %25
  %27 = fpext float %26 to double
  %28 = sext i32 %20 to i64
  %29 = add nsw i64 %28, -1
  %30 = getelementptr double, ptr %16, i64 %29
  store double %27, ptr %30, align 8, !tbaa !4
  store double %27, ptr %7, align 8, !tbaa !4
  %31 = add i32 %20, 1
  %32 = add nsw i64 %21, -1
  br label %19

33:                                               ; preds = %4
  %34 = sub nsw i64 %11, %9
  %35 = add nsw i64 %34, 1
  br label %36

36:                                               ; preds = %40, %33
  %37 = phi i32 [ %55, %40 ], [ %8, %33 ]
  %38 = phi i64 [ %56, %40 ], [ %35, %33 ]
  %39 = icmp sgt i64 %38, 0
  br i1 %39, label %40, label %57

40:                                               ; preds = %36
  %41 = load i32, ptr %5, align 4, !tbaa !4
  %42 = sitofp i32 %41 to float
  %43 = fdiv contract float 1.000000e+00, %42
  %44 = fpext float %43 to double
  %45 = sext i32 %37 to i64
  %46 = add nsw i64 %45, -1
  %47 = load ptr, ptr %2, align 8, !tbaa !8
  %48 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %2, i64 0, i32 7, i64 0, i64 2
  %49 = load i64, ptr %48, align 8, !tbaa !8
  %50 = mul i64 %46, %49
  %51 = getelementptr i8, ptr %47, i64 %50
  store double %44, ptr %51, align 8, !tbaa !4
  %52 = mul i64 %46, %49
  %53 = getelementptr i8, ptr %47, i64 %52
  %54 = load double, ptr %53, align 8, !tbaa !4
  store double %54, ptr %7, align 8, !tbaa !4
  %55 = add i32 %37, 1
  %56 = add nsw i64 %38, -1
  br label %36

57:                                               ; preds = %19, %36
  ret void
}
*** IR Dump After RequireAnalysisPass<llvm::GlobalsAA, llvm::Module> on [module] ***
; ModuleID = 'FIRModule'
source_filename = "FIRModule"
target datalayout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128"
target triple = "x86_64-unknown-linux-gnu"

%struct.ident_t = type { i32, i32, i32, i32, ptr }

@_QQcl.28612C69372C612C6531332E36653229 = internal constant [16 x i8] c"(a,i7,a,e13.6e2)"
@_QQcl.e8a0ac9186c064ac8543d822e9060d96 = internal constant [59 x i8] c"/g/g92/rydahl1/flangtests/src/parallel_region_outlined.f90\00"
@_QQcl.54686520726573756C74206F6620286172722831292B61727228 = internal constant [26 x i8] c"The result of (arr(1)+arr("
@_QQcl.2920697320 = internal constant [5 x i8] c") is "
@_QQEnvironmentDefaults = local_unnamed_addr constant ptr null
@0 = private unnamed_addr constant [23 x i8] c";unknown;unknown;0;0;;\00", align 1
@1 = private unnamed_addr constant %struct.ident_t { i32 0, i32 2, i32 0, i32 22, ptr @0 }, align 8

; Function Attrs: mustprogress nofree nounwind willreturn allockind("alloc,uninitialized") allocsize(0) memory(inaccessiblemem: readwrite)
declare noalias noundef ptr @malloc(i64 noundef) local_unnamed_addr #0

; Function Attrs: mustprogress nounwind willreturn allockind("free") memory(argmem: readwrite, inaccessiblemem: readwrite)
declare void @free(ptr allocptr nocapture noundef) local_unnamed_addr #1

define void @_QQmain() local_unnamed_addr {
  %1 = alloca i32, align 4
  %2 = alloca double, align 8
  %3 = alloca double, align 8
  %4 = alloca { ptr, ptr }, align 8
  store ptr %1, ptr %4, align 8, !tbaa !4
  %5 = getelementptr inbounds { ptr, ptr }, ptr %4, i64 0, i32 1
  store ptr %3, ptr %5, align 8, !tbaa !4
  store i32 1048576, ptr %1, align 4, !tbaa !4
  call void @_QFPomp_subroutine(ptr nonnull %1, ptr nonnull %2, ptr nonnull %4)
  %6 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.e8a0ac9186c064ac8543d822e9060d96, i32 10)
  %7 = call i1 @_FortranAioOutputAscii(ptr %6, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %8 = load i32, ptr %1, align 4, !tbaa !4
  %9 = call i1 @_FortranAioOutputInteger32(ptr %6, i32 %8)
  %10 = call i1 @_FortranAioOutputAscii(ptr %6, ptr nonnull @_QQcl.2920697320, i64 5)
  %11 = load double, ptr %2, align 8, !tbaa !4
  %12 = call i1 @_FortranAioOutputReal64(ptr %6, double %11)
  %13 = call i32 @_FortranAioEndIoStatement(ptr %6)
  ret void
}

define void @_QFPomp_subroutine(ptr %0, ptr %1, ptr nest %2) local_unnamed_addr {
entry:
  %structArg = alloca { ptr, ptr, ptr, ptr, ptr }, align 8
  %3 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %4 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %5 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  store ptr null, ptr %5, align 8, !tbaa !8
  %.fca.1.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 1
  store i64 8, ptr %.fca.1.gep, align 8, !tbaa !8
  %.fca.2.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 2
  store i32 20180515, ptr %.fca.2.gep, align 8, !tbaa !8
  %.fca.3.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 3
  store i8 1, ptr %.fca.3.gep, align 4, !tbaa !8
  %.fca.4.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 4
  store i8 28, ptr %.fca.4.gep, align 1, !tbaa !8
  %.fca.5.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 5
  store i8 2, ptr %.fca.5.gep, align 2, !tbaa !8
  %.fca.6.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 6
  store i8 0, ptr %.fca.6.gep, align 1, !tbaa !8
  %.fca.7.0.0.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 0
  store i64 1, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  %.fca.7.0.1.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 1
  store i64 0, ptr %.fca.7.0.1.gep, align 8, !tbaa !8
  %.fca.7.0.2.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 2
  store i64 8, ptr %.fca.7.0.2.gep, align 8, !tbaa !8
  %6 = load i32, ptr %0, align 4, !tbaa !4
  %7 = call i32 @llvm.smax.i32(i32 %6, i32 0)
  %8 = zext i32 %7 to i64
  %9 = shl nuw nsw i64 %8, 3
  %10 = call ptr @malloc(i64 %9)
  store ptr %10, ptr %5, align 8, !tbaa !8
  store i64 8, ptr %.fca.1.gep, align 8, !tbaa !8
  store i32 20180515, ptr %.fca.2.gep, align 8, !tbaa !8
  store i8 1, ptr %.fca.3.gep, align 4, !tbaa !8
  store i8 28, ptr %.fca.4.gep, align 1, !tbaa !8
  store i8 2, ptr %.fca.5.gep, align 2, !tbaa !8
  store i8 0, ptr %.fca.6.gep, align 1, !tbaa !8
  store i64 1, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  store i64 %8, ptr %.fca.7.0.1.gep, align 8, !tbaa !8
  store i64 8, ptr %.fca.7.0.2.gep, align 8, !tbaa !8
  %omp_global_thread_num = call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %0, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %5, ptr %gep_5, align 8
  %gep_6 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 2
  store ptr %4, ptr %gep_6, align 8
  %gep_7 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 3
  store ptr %3, ptr %gep_7, align 8
  %gep_8 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 4
  store ptr %2, ptr %gep_8, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QFPomp_subroutine..omp_par, ptr nonnull %structArg)
  %.fca.0.load = load ptr, ptr %5, align 8, !tbaa !8
  %.fca.7.0.0.load = load i64, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  %11 = sub i64 1, %.fca.7.0.0.load
  %12 = getelementptr double, ptr %.fca.0.load, i64 %11
  %13 = load double, ptr %12, align 8, !tbaa !4
  %14 = load i32, ptr %0, align 4, !tbaa !4
  %15 = sext i32 %14 to i64
  %16 = sub i64 %15, %.fca.7.0.0.load
  %17 = getelementptr double, ptr %.fca.0.load, i64 %16
  %18 = load double, ptr %17, align 8, !tbaa !4
  %19 = fadd contract double %13, %18
  store double %19, ptr %1, align 8, !tbaa !4
  %.fca.0.load40 = load ptr, ptr %5, align 8, !tbaa !8
  call void @free(ptr %.fca.0.load40)
  store ptr null, ptr %5, align 8, !tbaa !8
  store i64 8, ptr %.fca.1.gep, align 8, !tbaa !8
  store i32 20180515, ptr %.fca.2.gep, align 8, !tbaa !8
  store i8 1, ptr %.fca.3.gep, align 4, !tbaa !8
  store i8 28, ptr %.fca.4.gep, align 1, !tbaa !8
  store i8 2, ptr %.fca.5.gep, align 2, !tbaa !8
  store i8 0, ptr %.fca.6.gep, align 1, !tbaa !8
  store i64 1, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  store i64 0, ptr %.fca.7.0.1.gep, align 8, !tbaa !8
  store i64 8, ptr %.fca.7.0.2.gep, align 8, !tbaa !8
  ret void
}

; Function Attrs: norecurse nounwind
define internal void @_QFPomp_subroutine..omp_par(ptr noalias %tid.addr, ptr noalias %zero.addr, ptr %0) #2 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %gep_3 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 2
  %loadgep_4 = load ptr, ptr %gep_3, align 8
  %gep_5 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 3
  %loadgep_6 = load ptr, ptr %gep_5, align 8
  %gep_7 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 4
  %loadgep_8 = load ptr, ptr %gep_7, align 8
  %1 = alloca i32, align 4
  %2 = alloca i32, align 4
  %3 = call i32 @omp_get_thread_num()
  %4 = call i32 @omp_get_num_threads()
  %5 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %6 = sdiv i32 %5, %4
  %7 = mul i32 %3, %6
  %8 = add i32 %7, 1
  store i32 %8, ptr %1, align 4, !tbaa !4
  %9 = add i32 %4, -1
  %10 = icmp eq i32 %3, %9
  br i1 %10, label %omp.par.region2, label %omp.par.region3

omp.par.region3:                                  ; preds = %omp.par.entry
  %11 = add i32 %8, %6
  br label %omp.par.region4

omp.par.region4:                                  ; preds = %omp.par.region2, %omp.par.region3
  %storemerge = phi i32 [ %11, %omp.par.region3 ], [ %17, %omp.par.region2 ]
  store i32 %storemerge, ptr %2, align 4, !tbaa !4
  %.unpack = load ptr, ptr %loadgep_2, align 8, !tbaa !8
  %.elt14 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  %.unpack15 = load i64, ptr %.elt14, align 8, !tbaa !8
  %.elt16 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  %.unpack17 = load i32, ptr %.elt16, align 8, !tbaa !8
  %.elt18 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  %.unpack19 = load i8, ptr %.elt18, align 4, !tbaa !8
  %.elt20 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  %.unpack21 = load i8, ptr %.elt20, align 1, !tbaa !8
  %.elt22 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  %.unpack23 = load i8, ptr %.elt22, align 2, !tbaa !8
  %.elt24 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  %.unpack25 = load i8, ptr %.elt24, align 1, !tbaa !8
  %.elt26 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  %.unpack27.unpack.unpack = load i64, ptr %.elt26, align 8, !tbaa !8
  %.unpack27.unpack.elt29 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  %.unpack27.unpack.unpack30 = load i64, ptr %.unpack27.unpack.elt29, align 8, !tbaa !8
  %.unpack27.unpack.elt31 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  %.unpack27.unpack.unpack32 = load i64, ptr %.unpack27.unpack.elt31, align 8, !tbaa !8
  store ptr %.unpack, ptr %loadgep_4, align 8, !tbaa !8
  %loadgep_4.repack34 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 1
  store i64 %.unpack15, ptr %loadgep_4.repack34, align 8, !tbaa !8
  %loadgep_4.repack36 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 2
  store i32 %.unpack17, ptr %loadgep_4.repack36, align 8, !tbaa !8
  %loadgep_4.repack38 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 3
  store i8 %.unpack19, ptr %loadgep_4.repack38, align 4, !tbaa !8
  %loadgep_4.repack40 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 4
  store i8 %.unpack21, ptr %loadgep_4.repack40, align 1, !tbaa !8
  %loadgep_4.repack42 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 5
  store i8 %.unpack23, ptr %loadgep_4.repack42, align 2, !tbaa !8
  %loadgep_4.repack44 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 6
  store i8 %.unpack25, ptr %loadgep_4.repack44, align 1, !tbaa !8
  %loadgep_4.repack46 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7
  store i64 %.unpack27.unpack.unpack, ptr %loadgep_4.repack46, align 8, !tbaa !8
  %loadgep_4.repack46.repack48 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack27.unpack.unpack30, ptr %loadgep_4.repack46.repack48, align 8, !tbaa !8
  %loadgep_4.repack46.repack50 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 2
  store i64 %.unpack27.unpack.unpack32, ptr %loadgep_4.repack46.repack50, align 8, !tbaa !8
  %12 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 0
  %13 = load i64, ptr %12, align 8, !tbaa !8
  %14 = load ptr, ptr %loadgep_4, align 8, !tbaa !8
  %15 = icmp eq i64 %.unpack27.unpack.unpack30, 0
  %16 = select i1 %15, i64 1, i64 %13
  store ptr %14, ptr %loadgep_6, align 8, !tbaa !8
  %loadgep_6.repack52 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 1
  store i64 8, ptr %loadgep_6.repack52, align 8, !tbaa !8
  %loadgep_6.repack54 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 2
  store i32 20180515, ptr %loadgep_6.repack54, align 8, !tbaa !8
  %loadgep_6.repack56 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 3
  store i8 1, ptr %loadgep_6.repack56, align 4, !tbaa !8
  %loadgep_6.repack58 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 4
  store i8 28, ptr %loadgep_6.repack58, align 1, !tbaa !8
  %loadgep_6.repack60 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 5
  store i8 0, ptr %loadgep_6.repack60, align 2, !tbaa !8
  %loadgep_6.repack62 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 6
  store i8 0, ptr %loadgep_6.repack62, align 1, !tbaa !8
  %loadgep_6.repack64 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7
  store i64 %16, ptr %loadgep_6.repack64, align 8, !tbaa !8
  %loadgep_6.repack64.repack66 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack27.unpack.unpack30, ptr %loadgep_6.repack64.repack66, align 8, !tbaa !8
  %loadgep_6.repack64.repack68 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7, i64 0, i64 2
  store i64 8, ptr %loadgep_6.repack64.repack68, align 8, !tbaa !8
  call void @_QFPloop(ptr nonnull %1, ptr nonnull %2, ptr nonnull %loadgep_6, ptr %loadgep_8) #3
  ret void

omp.par.region2:                                  ; preds = %omp.par.entry
  %17 = load i32, ptr %loadgep_, align 4, !tbaa !4
  br label %omp.par.region4
}

define void @_QFPloop(ptr %0, ptr %1, ptr %2, ptr nest %3) local_unnamed_addr {
  %5 = load ptr, ptr %3, align 8, !tbaa !4
  %6 = getelementptr { ptr, ptr }, ptr %3, i64 0, i32 1
  %7 = load ptr, ptr %6, align 8, !tbaa !4
  %8 = load i32, ptr %0, align 4, !tbaa !4
  %9 = sext i32 %8 to i64
  %10 = load i32, ptr %1, align 4, !tbaa !4
  %11 = sext i32 %10 to i64
  %12 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %2, i64 0, i32 7, i64 0, i64 2
  %13 = load i64, ptr %12, align 8, !tbaa !8
  %14 = icmp eq i64 %13, 8
  br i1 %14, label %15, label %33

15:                                               ; preds = %4
  %16 = load ptr, ptr %2, align 8, !tbaa !8
  %17 = sub nsw i64 %11, %9
  %18 = add nsw i64 %17, 1
  br label %19

19:                                               ; preds = %23, %15
  %20 = phi i32 [ %31, %23 ], [ %8, %15 ]
  %21 = phi i64 [ %32, %23 ], [ %18, %15 ]
  %22 = icmp sgt i64 %21, 0
  br i1 %22, label %23, label %57

23:                                               ; preds = %19
  %24 = load i32, ptr %5, align 4, !tbaa !4
  %25 = sitofp i32 %24 to float
  %26 = fdiv contract float 1.000000e+00, %25
  %27 = fpext float %26 to double
  %28 = sext i32 %20 to i64
  %29 = add nsw i64 %28, -1
  %30 = getelementptr double, ptr %16, i64 %29
  store double %27, ptr %30, align 8, !tbaa !4
  store double %27, ptr %7, align 8, !tbaa !4
  %31 = add i32 %20, 1
  %32 = add nsw i64 %21, -1
  br label %19

33:                                               ; preds = %4
  %34 = sub nsw i64 %11, %9
  %35 = add nsw i64 %34, 1
  br label %36

36:                                               ; preds = %40, %33
  %37 = phi i32 [ %55, %40 ], [ %8, %33 ]
  %38 = phi i64 [ %56, %40 ], [ %35, %33 ]
  %39 = icmp sgt i64 %38, 0
  br i1 %39, label %40, label %57

40:                                               ; preds = %36
  %41 = load i32, ptr %5, align 4, !tbaa !4
  %42 = sitofp i32 %41 to float
  %43 = fdiv contract float 1.000000e+00, %42
  %44 = fpext float %43 to double
  %45 = sext i32 %37 to i64
  %46 = add nsw i64 %45, -1
  %47 = load ptr, ptr %2, align 8, !tbaa !8
  %48 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %2, i64 0, i32 7, i64 0, i64 2
  %49 = load i64, ptr %48, align 8, !tbaa !8
  %50 = mul i64 %46, %49
  %51 = getelementptr i8, ptr %47, i64 %50
  store double %44, ptr %51, align 8, !tbaa !4
  %52 = mul i64 %46, %49
  %53 = getelementptr i8, ptr %47, i64 %52
  %54 = load double, ptr %53, align 8, !tbaa !4
  store double %54, ptr %7, align 8, !tbaa !4
  %55 = add i32 %37, 1
  %56 = add nsw i64 %38, -1
  br label %36

57:                                               ; preds = %19, %36
  ret void
}

declare ptr @_FortranAioBeginExternalFormattedOutput(ptr, i64, ptr, i32, ptr, i32) local_unnamed_addr

declare zeroext i1 @_FortranAioOutputAscii(ptr, ptr, i64) local_unnamed_addr

declare zeroext i1 @_FortranAioOutputInteger32(ptr, i32) local_unnamed_addr

declare zeroext i1 @_FortranAioOutputReal64(ptr, double) local_unnamed_addr

declare i32 @_FortranAioEndIoStatement(ptr) local_unnamed_addr

; Function Attrs: nounwind
declare i32 @omp_get_thread_num() local_unnamed_addr #3

; Function Attrs: nounwind
declare i32 @omp_get_num_threads() local_unnamed_addr #3

; Function Attrs: nounwind
declare i32 @__kmpc_global_thread_num(ptr) local_unnamed_addr #3

; Function Attrs: nounwind
declare !callback !10 void @__kmpc_fork_call(ptr, i32, ptr, ...) local_unnamed_addr #3

; Function Attrs: nocallback nofree nosync nounwind speculatable willreturn memory(none)
declare i64 @llvm.smax.i64(i64, i64) #4

; Function Attrs: nocallback nofree nosync nounwind speculatable willreturn memory(none)
declare i32 @llvm.smax.i32(i32, i32) #4

attributes #0 = { mustprogress nofree nounwind willreturn allockind("alloc,uninitialized") allocsize(0) memory(inaccessiblemem: readwrite) "alloc-family"="malloc" }
attributes #1 = { mustprogress nounwind willreturn allockind("free") memory(argmem: readwrite, inaccessiblemem: readwrite) "alloc-family"="malloc" }
attributes #2 = { norecurse nounwind }
attributes #3 = { nounwind }
attributes #4 = { nocallback nofree nosync nounwind speculatable willreturn memory(none) }

!llvm.module.flags = !{!0, !1, !2, !3}

!0 = !{i32 2, !"Debug Info Version", i32 3}
!1 = !{i32 7, !"openmp", i32 11}
!2 = !{i32 8, !"PIC Level", i32 2}
!3 = !{i32 7, !"PIE Level", i32 2}
!4 = !{!5, !5, i64 0}
!5 = !{!"any data access", !6, i64 0}
!6 = !{!"any access", !7, i64 0}
!7 = !{!"Flang Type TBAA Root"}
!8 = !{!9, !9, i64 0}
!9 = !{!"descriptor member", !6, i64 0}
!10 = !{!11}
!11 = !{i64 2, i64 -1, i64 -1, i1 true}
*** IR Dump After InvalidateAnalysisPass<llvm::AAManager> on _QQmain ***
define void @_QQmain() local_unnamed_addr {
  %1 = alloca i32, align 4
  %2 = alloca double, align 8
  %3 = alloca double, align 8
  %4 = alloca { ptr, ptr }, align 8
  store ptr %1, ptr %4, align 8, !tbaa !4
  %5 = getelementptr inbounds { ptr, ptr }, ptr %4, i64 0, i32 1
  store ptr %3, ptr %5, align 8, !tbaa !4
  store i32 1048576, ptr %1, align 4, !tbaa !4
  call void @_QFPomp_subroutine(ptr nonnull %1, ptr nonnull %2, ptr nonnull %4)
  %6 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.e8a0ac9186c064ac8543d822e9060d96, i32 10)
  %7 = call i1 @_FortranAioOutputAscii(ptr %6, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %8 = load i32, ptr %1, align 4, !tbaa !4
  %9 = call i1 @_FortranAioOutputInteger32(ptr %6, i32 %8)
  %10 = call i1 @_FortranAioOutputAscii(ptr %6, ptr nonnull @_QQcl.2920697320, i64 5)
  %11 = load double, ptr %2, align 8, !tbaa !4
  %12 = call i1 @_FortranAioOutputReal64(ptr %6, double %11)
  %13 = call i32 @_FortranAioEndIoStatement(ptr %6)
  ret void
}
*** IR Dump After InvalidateAnalysisPass<llvm::AAManager> on _QFPomp_subroutine ***
define void @_QFPomp_subroutine(ptr %0, ptr %1, ptr nest %2) local_unnamed_addr {
entry:
  %structArg = alloca { ptr, ptr, ptr, ptr, ptr }, align 8
  %3 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %4 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %5 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  store ptr null, ptr %5, align 8, !tbaa !8
  %.fca.1.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 1
  store i64 8, ptr %.fca.1.gep, align 8, !tbaa !8
  %.fca.2.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 2
  store i32 20180515, ptr %.fca.2.gep, align 8, !tbaa !8
  %.fca.3.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 3
  store i8 1, ptr %.fca.3.gep, align 4, !tbaa !8
  %.fca.4.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 4
  store i8 28, ptr %.fca.4.gep, align 1, !tbaa !8
  %.fca.5.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 5
  store i8 2, ptr %.fca.5.gep, align 2, !tbaa !8
  %.fca.6.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 6
  store i8 0, ptr %.fca.6.gep, align 1, !tbaa !8
  %.fca.7.0.0.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 0
  store i64 1, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  %.fca.7.0.1.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 1
  store i64 0, ptr %.fca.7.0.1.gep, align 8, !tbaa !8
  %.fca.7.0.2.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 2
  store i64 8, ptr %.fca.7.0.2.gep, align 8, !tbaa !8
  %6 = load i32, ptr %0, align 4, !tbaa !4
  %7 = call i32 @llvm.smax.i32(i32 %6, i32 0)
  %8 = zext i32 %7 to i64
  %9 = shl nuw nsw i64 %8, 3
  %10 = call ptr @malloc(i64 %9)
  store ptr %10, ptr %5, align 8, !tbaa !8
  store i64 8, ptr %.fca.1.gep, align 8, !tbaa !8
  store i32 20180515, ptr %.fca.2.gep, align 8, !tbaa !8
  store i8 1, ptr %.fca.3.gep, align 4, !tbaa !8
  store i8 28, ptr %.fca.4.gep, align 1, !tbaa !8
  store i8 2, ptr %.fca.5.gep, align 2, !tbaa !8
  store i8 0, ptr %.fca.6.gep, align 1, !tbaa !8
  store i64 1, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  store i64 %8, ptr %.fca.7.0.1.gep, align 8, !tbaa !8
  store i64 8, ptr %.fca.7.0.2.gep, align 8, !tbaa !8
  %omp_global_thread_num = call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %0, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %5, ptr %gep_5, align 8
  %gep_6 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 2
  store ptr %4, ptr %gep_6, align 8
  %gep_7 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 3
  store ptr %3, ptr %gep_7, align 8
  %gep_8 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 4
  store ptr %2, ptr %gep_8, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QFPomp_subroutine..omp_par, ptr nonnull %structArg)
  %.fca.0.load = load ptr, ptr %5, align 8, !tbaa !8
  %.fca.7.0.0.load = load i64, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  %11 = sub i64 1, %.fca.7.0.0.load
  %12 = getelementptr double, ptr %.fca.0.load, i64 %11
  %13 = load double, ptr %12, align 8, !tbaa !4
  %14 = load i32, ptr %0, align 4, !tbaa !4
  %15 = sext i32 %14 to i64
  %16 = sub i64 %15, %.fca.7.0.0.load
  %17 = getelementptr double, ptr %.fca.0.load, i64 %16
  %18 = load double, ptr %17, align 8, !tbaa !4
  %19 = fadd contract double %13, %18
  store double %19, ptr %1, align 8, !tbaa !4
  %.fca.0.load40 = load ptr, ptr %5, align 8, !tbaa !8
  call void @free(ptr %.fca.0.load40)
  store ptr null, ptr %5, align 8, !tbaa !8
  store i64 8, ptr %.fca.1.gep, align 8, !tbaa !8
  store i32 20180515, ptr %.fca.2.gep, align 8, !tbaa !8
  store i8 1, ptr %.fca.3.gep, align 4, !tbaa !8
  store i8 28, ptr %.fca.4.gep, align 1, !tbaa !8
  store i8 2, ptr %.fca.5.gep, align 2, !tbaa !8
  store i8 0, ptr %.fca.6.gep, align 1, !tbaa !8
  store i64 1, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  store i64 0, ptr %.fca.7.0.1.gep, align 8, !tbaa !8
  store i64 8, ptr %.fca.7.0.2.gep, align 8, !tbaa !8
  ret void
}
*** IR Dump After InvalidateAnalysisPass<llvm::AAManager> on _QFPomp_subroutine..omp_par ***
; Function Attrs: norecurse nounwind
define internal void @_QFPomp_subroutine..omp_par(ptr noalias %tid.addr, ptr noalias %zero.addr, ptr %0) #2 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %gep_3 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 2
  %loadgep_4 = load ptr, ptr %gep_3, align 8
  %gep_5 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 3
  %loadgep_6 = load ptr, ptr %gep_5, align 8
  %gep_7 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 4
  %loadgep_8 = load ptr, ptr %gep_7, align 8
  %1 = alloca i32, align 4
  %2 = alloca i32, align 4
  %3 = call i32 @omp_get_thread_num()
  %4 = call i32 @omp_get_num_threads()
  %5 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %6 = sdiv i32 %5, %4
  %7 = mul i32 %3, %6
  %8 = add i32 %7, 1
  store i32 %8, ptr %1, align 4, !tbaa !4
  %9 = add i32 %4, -1
  %10 = icmp eq i32 %3, %9
  br i1 %10, label %omp.par.region2, label %omp.par.region3

omp.par.region3:                                  ; preds = %omp.par.entry
  %11 = add i32 %8, %6
  br label %omp.par.region4

omp.par.region4:                                  ; preds = %omp.par.region2, %omp.par.region3
  %storemerge = phi i32 [ %11, %omp.par.region3 ], [ %17, %omp.par.region2 ]
  store i32 %storemerge, ptr %2, align 4, !tbaa !4
  %.unpack = load ptr, ptr %loadgep_2, align 8, !tbaa !8
  %.elt14 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  %.unpack15 = load i64, ptr %.elt14, align 8, !tbaa !8
  %.elt16 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  %.unpack17 = load i32, ptr %.elt16, align 8, !tbaa !8
  %.elt18 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  %.unpack19 = load i8, ptr %.elt18, align 4, !tbaa !8
  %.elt20 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  %.unpack21 = load i8, ptr %.elt20, align 1, !tbaa !8
  %.elt22 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  %.unpack23 = load i8, ptr %.elt22, align 2, !tbaa !8
  %.elt24 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  %.unpack25 = load i8, ptr %.elt24, align 1, !tbaa !8
  %.elt26 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  %.unpack27.unpack.unpack = load i64, ptr %.elt26, align 8, !tbaa !8
  %.unpack27.unpack.elt29 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  %.unpack27.unpack.unpack30 = load i64, ptr %.unpack27.unpack.elt29, align 8, !tbaa !8
  %.unpack27.unpack.elt31 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  %.unpack27.unpack.unpack32 = load i64, ptr %.unpack27.unpack.elt31, align 8, !tbaa !8
  store ptr %.unpack, ptr %loadgep_4, align 8, !tbaa !8
  %loadgep_4.repack34 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 1
  store i64 %.unpack15, ptr %loadgep_4.repack34, align 8, !tbaa !8
  %loadgep_4.repack36 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 2
  store i32 %.unpack17, ptr %loadgep_4.repack36, align 8, !tbaa !8
  %loadgep_4.repack38 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 3
  store i8 %.unpack19, ptr %loadgep_4.repack38, align 4, !tbaa !8
  %loadgep_4.repack40 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 4
  store i8 %.unpack21, ptr %loadgep_4.repack40, align 1, !tbaa !8
  %loadgep_4.repack42 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 5
  store i8 %.unpack23, ptr %loadgep_4.repack42, align 2, !tbaa !8
  %loadgep_4.repack44 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 6
  store i8 %.unpack25, ptr %loadgep_4.repack44, align 1, !tbaa !8
  %loadgep_4.repack46 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7
  store i64 %.unpack27.unpack.unpack, ptr %loadgep_4.repack46, align 8, !tbaa !8
  %loadgep_4.repack46.repack48 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack27.unpack.unpack30, ptr %loadgep_4.repack46.repack48, align 8, !tbaa !8
  %loadgep_4.repack46.repack50 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 2
  store i64 %.unpack27.unpack.unpack32, ptr %loadgep_4.repack46.repack50, align 8, !tbaa !8
  %12 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 0
  %13 = load i64, ptr %12, align 8, !tbaa !8
  %14 = load ptr, ptr %loadgep_4, align 8, !tbaa !8
  %15 = icmp eq i64 %.unpack27.unpack.unpack30, 0
  %16 = select i1 %15, i64 1, i64 %13
  store ptr %14, ptr %loadgep_6, align 8, !tbaa !8
  %loadgep_6.repack52 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 1
  store i64 8, ptr %loadgep_6.repack52, align 8, !tbaa !8
  %loadgep_6.repack54 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 2
  store i32 20180515, ptr %loadgep_6.repack54, align 8, !tbaa !8
  %loadgep_6.repack56 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 3
  store i8 1, ptr %loadgep_6.repack56, align 4, !tbaa !8
  %loadgep_6.repack58 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 4
  store i8 28, ptr %loadgep_6.repack58, align 1, !tbaa !8
  %loadgep_6.repack60 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 5
  store i8 0, ptr %loadgep_6.repack60, align 2, !tbaa !8
  %loadgep_6.repack62 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 6
  store i8 0, ptr %loadgep_6.repack62, align 1, !tbaa !8
  %loadgep_6.repack64 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7
  store i64 %16, ptr %loadgep_6.repack64, align 8, !tbaa !8
  %loadgep_6.repack64.repack66 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack27.unpack.unpack30, ptr %loadgep_6.repack64.repack66, align 8, !tbaa !8
  %loadgep_6.repack64.repack68 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7, i64 0, i64 2
  store i64 8, ptr %loadgep_6.repack64.repack68, align 8, !tbaa !8
  call void @_QFPloop(ptr nonnull %1, ptr nonnull %2, ptr nonnull %loadgep_6, ptr %loadgep_8) #3
  ret void

omp.par.region2:                                  ; preds = %omp.par.entry
  %17 = load i32, ptr %loadgep_, align 4, !tbaa !4
  br label %omp.par.region4
}
*** IR Dump After InvalidateAnalysisPass<llvm::AAManager> on _QFPloop ***
define void @_QFPloop(ptr %0, ptr %1, ptr %2, ptr nest %3) local_unnamed_addr {
  %5 = load ptr, ptr %3, align 8, !tbaa !4
  %6 = getelementptr { ptr, ptr }, ptr %3, i64 0, i32 1
  %7 = load ptr, ptr %6, align 8, !tbaa !4
  %8 = load i32, ptr %0, align 4, !tbaa !4
  %9 = sext i32 %8 to i64
  %10 = load i32, ptr %1, align 4, !tbaa !4
  %11 = sext i32 %10 to i64
  %12 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %2, i64 0, i32 7, i64 0, i64 2
  %13 = load i64, ptr %12, align 8, !tbaa !8
  %14 = icmp eq i64 %13, 8
  br i1 %14, label %15, label %33

15:                                               ; preds = %4
  %16 = load ptr, ptr %2, align 8, !tbaa !8
  %17 = sub nsw i64 %11, %9
  %18 = add nsw i64 %17, 1
  br label %19

19:                                               ; preds = %23, %15
  %20 = phi i32 [ %31, %23 ], [ %8, %15 ]
  %21 = phi i64 [ %32, %23 ], [ %18, %15 ]
  %22 = icmp sgt i64 %21, 0
  br i1 %22, label %23, label %57

23:                                               ; preds = %19
  %24 = load i32, ptr %5, align 4, !tbaa !4
  %25 = sitofp i32 %24 to float
  %26 = fdiv contract float 1.000000e+00, %25
  %27 = fpext float %26 to double
  %28 = sext i32 %20 to i64
  %29 = add nsw i64 %28, -1
  %30 = getelementptr double, ptr %16, i64 %29
  store double %27, ptr %30, align 8, !tbaa !4
  store double %27, ptr %7, align 8, !tbaa !4
  %31 = add i32 %20, 1
  %32 = add nsw i64 %21, -1
  br label %19

33:                                               ; preds = %4
  %34 = sub nsw i64 %11, %9
  %35 = add nsw i64 %34, 1
  br label %36

36:                                               ; preds = %40, %33
  %37 = phi i32 [ %55, %40 ], [ %8, %33 ]
  %38 = phi i64 [ %56, %40 ], [ %35, %33 ]
  %39 = icmp sgt i64 %38, 0
  br i1 %39, label %40, label %57

40:                                               ; preds = %36
  %41 = load i32, ptr %5, align 4, !tbaa !4
  %42 = sitofp i32 %41 to float
  %43 = fdiv contract float 1.000000e+00, %42
  %44 = fpext float %43 to double
  %45 = sext i32 %37 to i64
  %46 = add nsw i64 %45, -1
  %47 = load ptr, ptr %2, align 8, !tbaa !8
  %48 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %2, i64 0, i32 7, i64 0, i64 2
  %49 = load i64, ptr %48, align 8, !tbaa !8
  %50 = mul i64 %46, %49
  %51 = getelementptr i8, ptr %47, i64 %50
  store double %44, ptr %51, align 8, !tbaa !4
  %52 = mul i64 %46, %49
  %53 = getelementptr i8, ptr %47, i64 %52
  %54 = load double, ptr %53, align 8, !tbaa !4
  store double %54, ptr %7, align 8, !tbaa !4
  %55 = add i32 %37, 1
  %56 = add nsw i64 %38, -1
  br label %36

57:                                               ; preds = %19, %36
  ret void
}
*** IR Dump After RequireAnalysisPass<llvm::ProfileSummaryAnalysis, llvm::Module> on [module] ***
; ModuleID = 'FIRModule'
source_filename = "FIRModule"
target datalayout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128"
target triple = "x86_64-unknown-linux-gnu"

%struct.ident_t = type { i32, i32, i32, i32, ptr }

@_QQcl.28612C69372C612C6531332E36653229 = internal constant [16 x i8] c"(a,i7,a,e13.6e2)"
@_QQcl.e8a0ac9186c064ac8543d822e9060d96 = internal constant [59 x i8] c"/g/g92/rydahl1/flangtests/src/parallel_region_outlined.f90\00"
@_QQcl.54686520726573756C74206F6620286172722831292B61727228 = internal constant [26 x i8] c"The result of (arr(1)+arr("
@_QQcl.2920697320 = internal constant [5 x i8] c") is "
@_QQEnvironmentDefaults = local_unnamed_addr constant ptr null
@0 = private unnamed_addr constant [23 x i8] c";unknown;unknown;0;0;;\00", align 1
@1 = private unnamed_addr constant %struct.ident_t { i32 0, i32 2, i32 0, i32 22, ptr @0 }, align 8

; Function Attrs: mustprogress nofree nounwind willreturn allockind("alloc,uninitialized") allocsize(0) memory(inaccessiblemem: readwrite)
declare noalias noundef ptr @malloc(i64 noundef) local_unnamed_addr #0

; Function Attrs: mustprogress nounwind willreturn allockind("free") memory(argmem: readwrite, inaccessiblemem: readwrite)
declare void @free(ptr allocptr nocapture noundef) local_unnamed_addr #1

define void @_QQmain() local_unnamed_addr {
  %1 = alloca i32, align 4
  %2 = alloca double, align 8
  %3 = alloca double, align 8
  %4 = alloca { ptr, ptr }, align 8
  store ptr %1, ptr %4, align 8, !tbaa !4
  %5 = getelementptr inbounds { ptr, ptr }, ptr %4, i64 0, i32 1
  store ptr %3, ptr %5, align 8, !tbaa !4
  store i32 1048576, ptr %1, align 4, !tbaa !4
  call void @_QFPomp_subroutine(ptr nonnull %1, ptr nonnull %2, ptr nonnull %4)
  %6 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.e8a0ac9186c064ac8543d822e9060d96, i32 10)
  %7 = call i1 @_FortranAioOutputAscii(ptr %6, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %8 = load i32, ptr %1, align 4, !tbaa !4
  %9 = call i1 @_FortranAioOutputInteger32(ptr %6, i32 %8)
  %10 = call i1 @_FortranAioOutputAscii(ptr %6, ptr nonnull @_QQcl.2920697320, i64 5)
  %11 = load double, ptr %2, align 8, !tbaa !4
  %12 = call i1 @_FortranAioOutputReal64(ptr %6, double %11)
  %13 = call i32 @_FortranAioEndIoStatement(ptr %6)
  ret void
}

define void @_QFPomp_subroutine(ptr %0, ptr %1, ptr nest %2) local_unnamed_addr {
entry:
  %structArg = alloca { ptr, ptr, ptr, ptr, ptr }, align 8
  %3 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %4 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %5 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  store ptr null, ptr %5, align 8, !tbaa !8
  %.fca.1.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 1
  store i64 8, ptr %.fca.1.gep, align 8, !tbaa !8
  %.fca.2.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 2
  store i32 20180515, ptr %.fca.2.gep, align 8, !tbaa !8
  %.fca.3.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 3
  store i8 1, ptr %.fca.3.gep, align 4, !tbaa !8
  %.fca.4.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 4
  store i8 28, ptr %.fca.4.gep, align 1, !tbaa !8
  %.fca.5.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 5
  store i8 2, ptr %.fca.5.gep, align 2, !tbaa !8
  %.fca.6.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 6
  store i8 0, ptr %.fca.6.gep, align 1, !tbaa !8
  %.fca.7.0.0.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 0
  store i64 1, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  %.fca.7.0.1.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 1
  store i64 0, ptr %.fca.7.0.1.gep, align 8, !tbaa !8
  %.fca.7.0.2.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 2
  store i64 8, ptr %.fca.7.0.2.gep, align 8, !tbaa !8
  %6 = load i32, ptr %0, align 4, !tbaa !4
  %7 = call i32 @llvm.smax.i32(i32 %6, i32 0)
  %8 = zext i32 %7 to i64
  %9 = shl nuw nsw i64 %8, 3
  %10 = call ptr @malloc(i64 %9)
  store ptr %10, ptr %5, align 8, !tbaa !8
  store i64 8, ptr %.fca.1.gep, align 8, !tbaa !8
  store i32 20180515, ptr %.fca.2.gep, align 8, !tbaa !8
  store i8 1, ptr %.fca.3.gep, align 4, !tbaa !8
  store i8 28, ptr %.fca.4.gep, align 1, !tbaa !8
  store i8 2, ptr %.fca.5.gep, align 2, !tbaa !8
  store i8 0, ptr %.fca.6.gep, align 1, !tbaa !8
  store i64 1, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  store i64 %8, ptr %.fca.7.0.1.gep, align 8, !tbaa !8
  store i64 8, ptr %.fca.7.0.2.gep, align 8, !tbaa !8
  %omp_global_thread_num = call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %0, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %5, ptr %gep_5, align 8
  %gep_6 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 2
  store ptr %4, ptr %gep_6, align 8
  %gep_7 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 3
  store ptr %3, ptr %gep_7, align 8
  %gep_8 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 4
  store ptr %2, ptr %gep_8, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QFPomp_subroutine..omp_par, ptr nonnull %structArg)
  %.fca.0.load = load ptr, ptr %5, align 8, !tbaa !8
  %.fca.7.0.0.load = load i64, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  %11 = sub i64 1, %.fca.7.0.0.load
  %12 = getelementptr double, ptr %.fca.0.load, i64 %11
  %13 = load double, ptr %12, align 8, !tbaa !4
  %14 = load i32, ptr %0, align 4, !tbaa !4
  %15 = sext i32 %14 to i64
  %16 = sub i64 %15, %.fca.7.0.0.load
  %17 = getelementptr double, ptr %.fca.0.load, i64 %16
  %18 = load double, ptr %17, align 8, !tbaa !4
  %19 = fadd contract double %13, %18
  store double %19, ptr %1, align 8, !tbaa !4
  %.fca.0.load40 = load ptr, ptr %5, align 8, !tbaa !8
  call void @free(ptr %.fca.0.load40)
  store ptr null, ptr %5, align 8, !tbaa !8
  store i64 8, ptr %.fca.1.gep, align 8, !tbaa !8
  store i32 20180515, ptr %.fca.2.gep, align 8, !tbaa !8
  store i8 1, ptr %.fca.3.gep, align 4, !tbaa !8
  store i8 28, ptr %.fca.4.gep, align 1, !tbaa !8
  store i8 2, ptr %.fca.5.gep, align 2, !tbaa !8
  store i8 0, ptr %.fca.6.gep, align 1, !tbaa !8
  store i64 1, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  store i64 0, ptr %.fca.7.0.1.gep, align 8, !tbaa !8
  store i64 8, ptr %.fca.7.0.2.gep, align 8, !tbaa !8
  ret void
}

; Function Attrs: norecurse nounwind
define internal void @_QFPomp_subroutine..omp_par(ptr noalias %tid.addr, ptr noalias %zero.addr, ptr %0) #2 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %gep_3 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 2
  %loadgep_4 = load ptr, ptr %gep_3, align 8
  %gep_5 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 3
  %loadgep_6 = load ptr, ptr %gep_5, align 8
  %gep_7 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 4
  %loadgep_8 = load ptr, ptr %gep_7, align 8
  %1 = alloca i32, align 4
  %2 = alloca i32, align 4
  %3 = call i32 @omp_get_thread_num()
  %4 = call i32 @omp_get_num_threads()
  %5 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %6 = sdiv i32 %5, %4
  %7 = mul i32 %3, %6
  %8 = add i32 %7, 1
  store i32 %8, ptr %1, align 4, !tbaa !4
  %9 = add i32 %4, -1
  %10 = icmp eq i32 %3, %9
  br i1 %10, label %omp.par.region2, label %omp.par.region3

omp.par.region3:                                  ; preds = %omp.par.entry
  %11 = add i32 %8, %6
  br label %omp.par.region4

omp.par.region4:                                  ; preds = %omp.par.region2, %omp.par.region3
  %storemerge = phi i32 [ %11, %omp.par.region3 ], [ %17, %omp.par.region2 ]
  store i32 %storemerge, ptr %2, align 4, !tbaa !4
  %.unpack = load ptr, ptr %loadgep_2, align 8, !tbaa !8
  %.elt14 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  %.unpack15 = load i64, ptr %.elt14, align 8, !tbaa !8
  %.elt16 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  %.unpack17 = load i32, ptr %.elt16, align 8, !tbaa !8
  %.elt18 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  %.unpack19 = load i8, ptr %.elt18, align 4, !tbaa !8
  %.elt20 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  %.unpack21 = load i8, ptr %.elt20, align 1, !tbaa !8
  %.elt22 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  %.unpack23 = load i8, ptr %.elt22, align 2, !tbaa !8
  %.elt24 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  %.unpack25 = load i8, ptr %.elt24, align 1, !tbaa !8
  %.elt26 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  %.unpack27.unpack.unpack = load i64, ptr %.elt26, align 8, !tbaa !8
  %.unpack27.unpack.elt29 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  %.unpack27.unpack.unpack30 = load i64, ptr %.unpack27.unpack.elt29, align 8, !tbaa !8
  %.unpack27.unpack.elt31 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  %.unpack27.unpack.unpack32 = load i64, ptr %.unpack27.unpack.elt31, align 8, !tbaa !8
  store ptr %.unpack, ptr %loadgep_4, align 8, !tbaa !8
  %loadgep_4.repack34 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 1
  store i64 %.unpack15, ptr %loadgep_4.repack34, align 8, !tbaa !8
  %loadgep_4.repack36 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 2
  store i32 %.unpack17, ptr %loadgep_4.repack36, align 8, !tbaa !8
  %loadgep_4.repack38 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 3
  store i8 %.unpack19, ptr %loadgep_4.repack38, align 4, !tbaa !8
  %loadgep_4.repack40 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 4
  store i8 %.unpack21, ptr %loadgep_4.repack40, align 1, !tbaa !8
  %loadgep_4.repack42 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 5
  store i8 %.unpack23, ptr %loadgep_4.repack42, align 2, !tbaa !8
  %loadgep_4.repack44 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 6
  store i8 %.unpack25, ptr %loadgep_4.repack44, align 1, !tbaa !8
  %loadgep_4.repack46 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7
  store i64 %.unpack27.unpack.unpack, ptr %loadgep_4.repack46, align 8, !tbaa !8
  %loadgep_4.repack46.repack48 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack27.unpack.unpack30, ptr %loadgep_4.repack46.repack48, align 8, !tbaa !8
  %loadgep_4.repack46.repack50 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 2
  store i64 %.unpack27.unpack.unpack32, ptr %loadgep_4.repack46.repack50, align 8, !tbaa !8
  %12 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 0
  %13 = load i64, ptr %12, align 8, !tbaa !8
  %14 = load ptr, ptr %loadgep_4, align 8, !tbaa !8
  %15 = icmp eq i64 %.unpack27.unpack.unpack30, 0
  %16 = select i1 %15, i64 1, i64 %13
  store ptr %14, ptr %loadgep_6, align 8, !tbaa !8
  %loadgep_6.repack52 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 1
  store i64 8, ptr %loadgep_6.repack52, align 8, !tbaa !8
  %loadgep_6.repack54 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 2
  store i32 20180515, ptr %loadgep_6.repack54, align 8, !tbaa !8
  %loadgep_6.repack56 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 3
  store i8 1, ptr %loadgep_6.repack56, align 4, !tbaa !8
  %loadgep_6.repack58 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 4
  store i8 28, ptr %loadgep_6.repack58, align 1, !tbaa !8
  %loadgep_6.repack60 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 5
  store i8 0, ptr %loadgep_6.repack60, align 2, !tbaa !8
  %loadgep_6.repack62 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 6
  store i8 0, ptr %loadgep_6.repack62, align 1, !tbaa !8
  %loadgep_6.repack64 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7
  store i64 %16, ptr %loadgep_6.repack64, align 8, !tbaa !8
  %loadgep_6.repack64.repack66 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack27.unpack.unpack30, ptr %loadgep_6.repack64.repack66, align 8, !tbaa !8
  %loadgep_6.repack64.repack68 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7, i64 0, i64 2
  store i64 8, ptr %loadgep_6.repack64.repack68, align 8, !tbaa !8
  call void @_QFPloop(ptr nonnull %1, ptr nonnull %2, ptr nonnull %loadgep_6, ptr %loadgep_8) #3
  ret void

omp.par.region2:                                  ; preds = %omp.par.entry
  %17 = load i32, ptr %loadgep_, align 4, !tbaa !4
  br label %omp.par.region4
}

define void @_QFPloop(ptr %0, ptr %1, ptr %2, ptr nest %3) local_unnamed_addr {
  %5 = load ptr, ptr %3, align 8, !tbaa !4
  %6 = getelementptr { ptr, ptr }, ptr %3, i64 0, i32 1
  %7 = load ptr, ptr %6, align 8, !tbaa !4
  %8 = load i32, ptr %0, align 4, !tbaa !4
  %9 = sext i32 %8 to i64
  %10 = load i32, ptr %1, align 4, !tbaa !4
  %11 = sext i32 %10 to i64
  %12 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %2, i64 0, i32 7, i64 0, i64 2
  %13 = load i64, ptr %12, align 8, !tbaa !8
  %14 = icmp eq i64 %13, 8
  br i1 %14, label %15, label %33

15:                                               ; preds = %4
  %16 = load ptr, ptr %2, align 8, !tbaa !8
  %17 = sub nsw i64 %11, %9
  %18 = add nsw i64 %17, 1
  br label %19

19:                                               ; preds = %23, %15
  %20 = phi i32 [ %31, %23 ], [ %8, %15 ]
  %21 = phi i64 [ %32, %23 ], [ %18, %15 ]
  %22 = icmp sgt i64 %21, 0
  br i1 %22, label %23, label %57

23:                                               ; preds = %19
  %24 = load i32, ptr %5, align 4, !tbaa !4
  %25 = sitofp i32 %24 to float
  %26 = fdiv contract float 1.000000e+00, %25
  %27 = fpext float %26 to double
  %28 = sext i32 %20 to i64
  %29 = add nsw i64 %28, -1
  %30 = getelementptr double, ptr %16, i64 %29
  store double %27, ptr %30, align 8, !tbaa !4
  store double %27, ptr %7, align 8, !tbaa !4
  %31 = add i32 %20, 1
  %32 = add nsw i64 %21, -1
  br label %19

33:                                               ; preds = %4
  %34 = sub nsw i64 %11, %9
  %35 = add nsw i64 %34, 1
  br label %36

36:                                               ; preds = %40, %33
  %37 = phi i32 [ %55, %40 ], [ %8, %33 ]
  %38 = phi i64 [ %56, %40 ], [ %35, %33 ]
  %39 = icmp sgt i64 %38, 0
  br i1 %39, label %40, label %57

40:                                               ; preds = %36
  %41 = load i32, ptr %5, align 4, !tbaa !4
  %42 = sitofp i32 %41 to float
  %43 = fdiv contract float 1.000000e+00, %42
  %44 = fpext float %43 to double
  %45 = sext i32 %37 to i64
  %46 = add nsw i64 %45, -1
  %47 = load ptr, ptr %2, align 8, !tbaa !8
  %48 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %2, i64 0, i32 7, i64 0, i64 2
  %49 = load i64, ptr %48, align 8, !tbaa !8
  %50 = mul i64 %46, %49
  %51 = getelementptr i8, ptr %47, i64 %50
  store double %44, ptr %51, align 8, !tbaa !4
  %52 = mul i64 %46, %49
  %53 = getelementptr i8, ptr %47, i64 %52
  %54 = load double, ptr %53, align 8, !tbaa !4
  store double %54, ptr %7, align 8, !tbaa !4
  %55 = add i32 %37, 1
  %56 = add nsw i64 %38, -1
  br label %36

57:                                               ; preds = %19, %36
  ret void
}

declare ptr @_FortranAioBeginExternalFormattedOutput(ptr, i64, ptr, i32, ptr, i32) local_unnamed_addr

declare zeroext i1 @_FortranAioOutputAscii(ptr, ptr, i64) local_unnamed_addr

declare zeroext i1 @_FortranAioOutputInteger32(ptr, i32) local_unnamed_addr

declare zeroext i1 @_FortranAioOutputReal64(ptr, double) local_unnamed_addr

declare i32 @_FortranAioEndIoStatement(ptr) local_unnamed_addr

; Function Attrs: nounwind
declare i32 @omp_get_thread_num() local_unnamed_addr #3

; Function Attrs: nounwind
declare i32 @omp_get_num_threads() local_unnamed_addr #3

; Function Attrs: nounwind
declare i32 @__kmpc_global_thread_num(ptr) local_unnamed_addr #3

; Function Attrs: nounwind
declare !callback !10 void @__kmpc_fork_call(ptr, i32, ptr, ...) local_unnamed_addr #3

; Function Attrs: nocallback nofree nosync nounwind speculatable willreturn memory(none)
declare i64 @llvm.smax.i64(i64, i64) #4

; Function Attrs: nocallback nofree nosync nounwind speculatable willreturn memory(none)
declare i32 @llvm.smax.i32(i32, i32) #4

attributes #0 = { mustprogress nofree nounwind willreturn allockind("alloc,uninitialized") allocsize(0) memory(inaccessiblemem: readwrite) "alloc-family"="malloc" }
attributes #1 = { mustprogress nounwind willreturn allockind("free") memory(argmem: readwrite, inaccessiblemem: readwrite) "alloc-family"="malloc" }
attributes #2 = { norecurse nounwind }
attributes #3 = { nounwind }
attributes #4 = { nocallback nofree nosync nounwind speculatable willreturn memory(none) }

!llvm.module.flags = !{!0, !1, !2, !3}

!0 = !{i32 2, !"Debug Info Version", i32 3}
!1 = !{i32 7, !"openmp", i32 11}
!2 = !{i32 8, !"PIC Level", i32 2}
!3 = !{i32 7, !"PIE Level", i32 2}
!4 = !{!5, !5, i64 0}
!5 = !{!"any data access", !6, i64 0}
!6 = !{!"any access", !7, i64 0}
!7 = !{!"Flang Type TBAA Root"}
!8 = !{!9, !9, i64 0}
!9 = !{!"descriptor member", !6, i64 0}
!10 = !{!11}
!11 = !{i64 2, i64 -1, i64 -1, i1 true}
*** IR Dump After InlinerPass on (_QFPloop) ***
define void @_QFPloop(ptr %0, ptr %1, ptr %2, ptr nest %3) local_unnamed_addr {
  %5 = load ptr, ptr %3, align 8, !tbaa !4
  %6 = getelementptr { ptr, ptr }, ptr %3, i64 0, i32 1
  %7 = load ptr, ptr %6, align 8, !tbaa !4
  %8 = load i32, ptr %0, align 4, !tbaa !4
  %9 = sext i32 %8 to i64
  %10 = load i32, ptr %1, align 4, !tbaa !4
  %11 = sext i32 %10 to i64
  %12 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %2, i64 0, i32 7, i64 0, i64 2
  %13 = load i64, ptr %12, align 8, !tbaa !8
  %14 = icmp eq i64 %13, 8
  br i1 %14, label %15, label %33

15:                                               ; preds = %4
  %16 = load ptr, ptr %2, align 8, !tbaa !8
  %17 = sub nsw i64 %11, %9
  %18 = add nsw i64 %17, 1
  br label %19

19:                                               ; preds = %23, %15
  %20 = phi i32 [ %31, %23 ], [ %8, %15 ]
  %21 = phi i64 [ %32, %23 ], [ %18, %15 ]
  %22 = icmp sgt i64 %21, 0
  br i1 %22, label %23, label %57

23:                                               ; preds = %19
  %24 = load i32, ptr %5, align 4, !tbaa !4
  %25 = sitofp i32 %24 to float
  %26 = fdiv contract float 1.000000e+00, %25
  %27 = fpext float %26 to double
  %28 = sext i32 %20 to i64
  %29 = add nsw i64 %28, -1
  %30 = getelementptr double, ptr %16, i64 %29
  store double %27, ptr %30, align 8, !tbaa !4
  store double %27, ptr %7, align 8, !tbaa !4
  %31 = add i32 %20, 1
  %32 = add nsw i64 %21, -1
  br label %19

33:                                               ; preds = %4
  %34 = sub nsw i64 %11, %9
  %35 = add nsw i64 %34, 1
  br label %36

36:                                               ; preds = %40, %33
  %37 = phi i32 [ %55, %40 ], [ %8, %33 ]
  %38 = phi i64 [ %56, %40 ], [ %35, %33 ]
  %39 = icmp sgt i64 %38, 0
  br i1 %39, label %40, label %57

40:                                               ; preds = %36
  %41 = load i32, ptr %5, align 4, !tbaa !4
  %42 = sitofp i32 %41 to float
  %43 = fdiv contract float 1.000000e+00, %42
  %44 = fpext float %43 to double
  %45 = sext i32 %37 to i64
  %46 = add nsw i64 %45, -1
  %47 = load ptr, ptr %2, align 8, !tbaa !8
  %48 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %2, i64 0, i32 7, i64 0, i64 2
  %49 = load i64, ptr %48, align 8, !tbaa !8
  %50 = mul i64 %46, %49
  %51 = getelementptr i8, ptr %47, i64 %50
  store double %44, ptr %51, align 8, !tbaa !4
  %52 = mul i64 %46, %49
  %53 = getelementptr i8, ptr %47, i64 %52
  %54 = load double, ptr %53, align 8, !tbaa !4
  store double %54, ptr %7, align 8, !tbaa !4
  %55 = add i32 %37, 1
  %56 = add nsw i64 %38, -1
  br label %36

57:                                               ; preds = %19, %36
  ret void
}
*** IR Dump After InlinerPass on (_QFPloop) ***
define void @_QFPloop(ptr %0, ptr %1, ptr %2, ptr nest %3) local_unnamed_addr {
  %5 = load ptr, ptr %3, align 8, !tbaa !4
  %6 = getelementptr { ptr, ptr }, ptr %3, i64 0, i32 1
  %7 = load ptr, ptr %6, align 8, !tbaa !4
  %8 = load i32, ptr %0, align 4, !tbaa !4
  %9 = sext i32 %8 to i64
  %10 = load i32, ptr %1, align 4, !tbaa !4
  %11 = sext i32 %10 to i64
  %12 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %2, i64 0, i32 7, i64 0, i64 2
  %13 = load i64, ptr %12, align 8, !tbaa !8
  %14 = icmp eq i64 %13, 8
  br i1 %14, label %15, label %33

15:                                               ; preds = %4
  %16 = load ptr, ptr %2, align 8, !tbaa !8
  %17 = sub nsw i64 %11, %9
  %18 = add nsw i64 %17, 1
  br label %19

19:                                               ; preds = %23, %15
  %20 = phi i32 [ %31, %23 ], [ %8, %15 ]
  %21 = phi i64 [ %32, %23 ], [ %18, %15 ]
  %22 = icmp sgt i64 %21, 0
  br i1 %22, label %23, label %57

23:                                               ; preds = %19
  %24 = load i32, ptr %5, align 4, !tbaa !4
  %25 = sitofp i32 %24 to float
  %26 = fdiv contract float 1.000000e+00, %25
  %27 = fpext float %26 to double
  %28 = sext i32 %20 to i64
  %29 = add nsw i64 %28, -1
  %30 = getelementptr double, ptr %16, i64 %29
  store double %27, ptr %30, align 8, !tbaa !4
  store double %27, ptr %7, align 8, !tbaa !4
  %31 = add i32 %20, 1
  %32 = add nsw i64 %21, -1
  br label %19

33:                                               ; preds = %4
  %34 = sub nsw i64 %11, %9
  %35 = add nsw i64 %34, 1
  br label %36

36:                                               ; preds = %40, %33
  %37 = phi i32 [ %55, %40 ], [ %8, %33 ]
  %38 = phi i64 [ %56, %40 ], [ %35, %33 ]
  %39 = icmp sgt i64 %38, 0
  br i1 %39, label %40, label %57

40:                                               ; preds = %36
  %41 = load i32, ptr %5, align 4, !tbaa !4
  %42 = sitofp i32 %41 to float
  %43 = fdiv contract float 1.000000e+00, %42
  %44 = fpext float %43 to double
  %45 = sext i32 %37 to i64
  %46 = add nsw i64 %45, -1
  %47 = load ptr, ptr %2, align 8, !tbaa !8
  %48 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %2, i64 0, i32 7, i64 0, i64 2
  %49 = load i64, ptr %48, align 8, !tbaa !8
  %50 = mul i64 %46, %49
  %51 = getelementptr i8, ptr %47, i64 %50
  store double %44, ptr %51, align 8, !tbaa !4
  %52 = mul i64 %46, %49
  %53 = getelementptr i8, ptr %47, i64 %52
  %54 = load double, ptr %53, align 8, !tbaa !4
  store double %54, ptr %7, align 8, !tbaa !4
  %55 = add i32 %37, 1
  %56 = add nsw i64 %38, -1
  br label %36

57:                                               ; preds = %19, %36
  ret void
}
*** IR Dump After PostOrderFunctionAttrsPass on (_QFPloop) ***
define void @_QFPloop(ptr %0, ptr %1, ptr %2, ptr nest %3) local_unnamed_addr {
  %5 = load ptr, ptr %3, align 8, !tbaa !4
  %6 = getelementptr { ptr, ptr }, ptr %3, i64 0, i32 1
  %7 = load ptr, ptr %6, align 8, !tbaa !4
  %8 = load i32, ptr %0, align 4, !tbaa !4
  %9 = sext i32 %8 to i64
  %10 = load i32, ptr %1, align 4, !tbaa !4
  %11 = sext i32 %10 to i64
  %12 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %2, i64 0, i32 7, i64 0, i64 2
  %13 = load i64, ptr %12, align 8, !tbaa !8
  %14 = icmp eq i64 %13, 8
  br i1 %14, label %15, label %33

15:                                               ; preds = %4
  %16 = load ptr, ptr %2, align 8, !tbaa !8
  %17 = sub nsw i64 %11, %9
  %18 = add nsw i64 %17, 1
  br label %19

19:                                               ; preds = %23, %15
  %20 = phi i32 [ %31, %23 ], [ %8, %15 ]
  %21 = phi i64 [ %32, %23 ], [ %18, %15 ]
  %22 = icmp sgt i64 %21, 0
  br i1 %22, label %23, label %57

23:                                               ; preds = %19
  %24 = load i32, ptr %5, align 4, !tbaa !4
  %25 = sitofp i32 %24 to float
  %26 = fdiv contract float 1.000000e+00, %25
  %27 = fpext float %26 to double
  %28 = sext i32 %20 to i64
  %29 = add nsw i64 %28, -1
  %30 = getelementptr double, ptr %16, i64 %29
  store double %27, ptr %30, align 8, !tbaa !4
  store double %27, ptr %7, align 8, !tbaa !4
  %31 = add i32 %20, 1
  %32 = add nsw i64 %21, -1
  br label %19

33:                                               ; preds = %4
  %34 = sub nsw i64 %11, %9
  %35 = add nsw i64 %34, 1
  br label %36

36:                                               ; preds = %40, %33
  %37 = phi i32 [ %55, %40 ], [ %8, %33 ]
  %38 = phi i64 [ %56, %40 ], [ %35, %33 ]
  %39 = icmp sgt i64 %38, 0
  br i1 %39, label %40, label %57

40:                                               ; preds = %36
  %41 = load i32, ptr %5, align 4, !tbaa !4
  %42 = sitofp i32 %41 to float
  %43 = fdiv contract float 1.000000e+00, %42
  %44 = fpext float %43 to double
  %45 = sext i32 %37 to i64
  %46 = add nsw i64 %45, -1
  %47 = load ptr, ptr %2, align 8, !tbaa !8
  %48 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %2, i64 0, i32 7, i64 0, i64 2
  %49 = load i64, ptr %48, align 8, !tbaa !8
  %50 = mul i64 %46, %49
  %51 = getelementptr i8, ptr %47, i64 %50
  store double %44, ptr %51, align 8, !tbaa !4
  %52 = mul i64 %46, %49
  %53 = getelementptr i8, ptr %47, i64 %52
  %54 = load double, ptr %53, align 8, !tbaa !4
  store double %54, ptr %7, align 8, !tbaa !4
  %55 = add i32 %37, 1
  %56 = add nsw i64 %38, -1
  br label %36

57:                                               ; preds = %19, %36
  ret void
}
*** IR Dump After ArgumentPromotionPass on (_QFPloop) ***
define void @_QFPloop(ptr %0, ptr %1, ptr %2, ptr nest %3) local_unnamed_addr {
  %5 = load ptr, ptr %3, align 8, !tbaa !4
  %6 = getelementptr { ptr, ptr }, ptr %3, i64 0, i32 1
  %7 = load ptr, ptr %6, align 8, !tbaa !4
  %8 = load i32, ptr %0, align 4, !tbaa !4
  %9 = sext i32 %8 to i64
  %10 = load i32, ptr %1, align 4, !tbaa !4
  %11 = sext i32 %10 to i64
  %12 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %2, i64 0, i32 7, i64 0, i64 2
  %13 = load i64, ptr %12, align 8, !tbaa !8
  %14 = icmp eq i64 %13, 8
  br i1 %14, label %15, label %33

15:                                               ; preds = %4
  %16 = load ptr, ptr %2, align 8, !tbaa !8
  %17 = sub nsw i64 %11, %9
  %18 = add nsw i64 %17, 1
  br label %19

19:                                               ; preds = %23, %15
  %20 = phi i32 [ %31, %23 ], [ %8, %15 ]
  %21 = phi i64 [ %32, %23 ], [ %18, %15 ]
  %22 = icmp sgt i64 %21, 0
  br i1 %22, label %23, label %57

23:                                               ; preds = %19
  %24 = load i32, ptr %5, align 4, !tbaa !4
  %25 = sitofp i32 %24 to float
  %26 = fdiv contract float 1.000000e+00, %25
  %27 = fpext float %26 to double
  %28 = sext i32 %20 to i64
  %29 = add nsw i64 %28, -1
  %30 = getelementptr double, ptr %16, i64 %29
  store double %27, ptr %30, align 8, !tbaa !4
  store double %27, ptr %7, align 8, !tbaa !4
  %31 = add i32 %20, 1
  %32 = add nsw i64 %21, -1
  br label %19

33:                                               ; preds = %4
  %34 = sub nsw i64 %11, %9
  %35 = add nsw i64 %34, 1
  br label %36

36:                                               ; preds = %40, %33
  %37 = phi i32 [ %55, %40 ], [ %8, %33 ]
  %38 = phi i64 [ %56, %40 ], [ %35, %33 ]
  %39 = icmp sgt i64 %38, 0
  br i1 %39, label %40, label %57

40:                                               ; preds = %36
  %41 = load i32, ptr %5, align 4, !tbaa !4
  %42 = sitofp i32 %41 to float
  %43 = fdiv contract float 1.000000e+00, %42
  %44 = fpext float %43 to double
  %45 = sext i32 %37 to i64
  %46 = add nsw i64 %45, -1
  %47 = load ptr, ptr %2, align 8, !tbaa !8
  %48 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %2, i64 0, i32 7, i64 0, i64 2
  %49 = load i64, ptr %48, align 8, !tbaa !8
  %50 = mul i64 %46, %49
  %51 = getelementptr i8, ptr %47, i64 %50
  store double %44, ptr %51, align 8, !tbaa !4
  %52 = mul i64 %46, %49
  %53 = getelementptr i8, ptr %47, i64 %52
  %54 = load double, ptr %53, align 8, !tbaa !4
  store double %54, ptr %7, align 8, !tbaa !4
  %55 = add i32 %37, 1
  %56 = add nsw i64 %38, -1
  br label %36

57:                                               ; preds = %19, %36
  ret void
}
*** IR Dump After OpenMPOptCGSCCPass on (_QFPloop) ***
define void @_QFPloop(ptr %0, ptr %1, ptr %2, ptr nest %3) local_unnamed_addr {
  %5 = load ptr, ptr %3, align 8, !tbaa !4
  %6 = getelementptr { ptr, ptr }, ptr %3, i64 0, i32 1
  %7 = load ptr, ptr %6, align 8, !tbaa !4
  %8 = load i32, ptr %0, align 4, !tbaa !4
  %9 = sext i32 %8 to i64
  %10 = load i32, ptr %1, align 4, !tbaa !4
  %11 = sext i32 %10 to i64
  %12 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %2, i64 0, i32 7, i64 0, i64 2
  %13 = load i64, ptr %12, align 8, !tbaa !8
  %14 = icmp eq i64 %13, 8
  br i1 %14, label %15, label %33

15:                                               ; preds = %4
  %16 = load ptr, ptr %2, align 8, !tbaa !8
  %17 = sub nsw i64 %11, %9
  %18 = add nsw i64 %17, 1
  br label %19

19:                                               ; preds = %23, %15
  %20 = phi i32 [ %31, %23 ], [ %8, %15 ]
  %21 = phi i64 [ %32, %23 ], [ %18, %15 ]
  %22 = icmp sgt i64 %21, 0
  br i1 %22, label %23, label %57

23:                                               ; preds = %19
  %24 = load i32, ptr %5, align 4, !tbaa !4
  %25 = sitofp i32 %24 to float
  %26 = fdiv contract float 1.000000e+00, %25
  %27 = fpext float %26 to double
  %28 = sext i32 %20 to i64
  %29 = add nsw i64 %28, -1
  %30 = getelementptr double, ptr %16, i64 %29
  store double %27, ptr %30, align 8, !tbaa !4
  store double %27, ptr %7, align 8, !tbaa !4
  %31 = add i32 %20, 1
  %32 = add nsw i64 %21, -1
  br label %19

33:                                               ; preds = %4
  %34 = sub nsw i64 %11, %9
  %35 = add nsw i64 %34, 1
  br label %36

36:                                               ; preds = %40, %33
  %37 = phi i32 [ %55, %40 ], [ %8, %33 ]
  %38 = phi i64 [ %56, %40 ], [ %35, %33 ]
  %39 = icmp sgt i64 %38, 0
  br i1 %39, label %40, label %57

40:                                               ; preds = %36
  %41 = load i32, ptr %5, align 4, !tbaa !4
  %42 = sitofp i32 %41 to float
  %43 = fdiv contract float 1.000000e+00, %42
  %44 = fpext float %43 to double
  %45 = sext i32 %37 to i64
  %46 = add nsw i64 %45, -1
  %47 = load ptr, ptr %2, align 8, !tbaa !8
  %48 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %2, i64 0, i32 7, i64 0, i64 2
  %49 = load i64, ptr %48, align 8, !tbaa !8
  %50 = mul i64 %46, %49
  %51 = getelementptr i8, ptr %47, i64 %50
  store double %44, ptr %51, align 8, !tbaa !4
  %52 = mul i64 %46, %49
  %53 = getelementptr i8, ptr %47, i64 %52
  %54 = load double, ptr %53, align 8, !tbaa !4
  store double %54, ptr %7, align 8, !tbaa !4
  %55 = add i32 %37, 1
  %56 = add nsw i64 %38, -1
  br label %36

57:                                               ; preds = %19, %36
  ret void
}
*** IR Dump After SROAPass on _QFPloop ***
define void @_QFPloop(ptr %0, ptr %1, ptr %2, ptr nest %3) local_unnamed_addr {
  %5 = load ptr, ptr %3, align 8, !tbaa !4
  %6 = getelementptr { ptr, ptr }, ptr %3, i64 0, i32 1
  %7 = load ptr, ptr %6, align 8, !tbaa !4
  %8 = load i32, ptr %0, align 4, !tbaa !4
  %9 = sext i32 %8 to i64
  %10 = load i32, ptr %1, align 4, !tbaa !4
  %11 = sext i32 %10 to i64
  %12 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %2, i64 0, i32 7, i64 0, i64 2
  %13 = load i64, ptr %12, align 8, !tbaa !8
  %14 = icmp eq i64 %13, 8
  br i1 %14, label %15, label %33

15:                                               ; preds = %4
  %16 = load ptr, ptr %2, align 8, !tbaa !8
  %17 = sub nsw i64 %11, %9
  %18 = add nsw i64 %17, 1
  br label %19

19:                                               ; preds = %23, %15
  %20 = phi i32 [ %31, %23 ], [ %8, %15 ]
  %21 = phi i64 [ %32, %23 ], [ %18, %15 ]
  %22 = icmp sgt i64 %21, 0
  br i1 %22, label %23, label %57

23:                                               ; preds = %19
  %24 = load i32, ptr %5, align 4, !tbaa !4
  %25 = sitofp i32 %24 to float
  %26 = fdiv contract float 1.000000e+00, %25
  %27 = fpext float %26 to double
  %28 = sext i32 %20 to i64
  %29 = add nsw i64 %28, -1
  %30 = getelementptr double, ptr %16, i64 %29
  store double %27, ptr %30, align 8, !tbaa !4
  store double %27, ptr %7, align 8, !tbaa !4
  %31 = add i32 %20, 1
  %32 = add nsw i64 %21, -1
  br label %19

33:                                               ; preds = %4
  %34 = sub nsw i64 %11, %9
  %35 = add nsw i64 %34, 1
  br label %36

36:                                               ; preds = %40, %33
  %37 = phi i32 [ %55, %40 ], [ %8, %33 ]
  %38 = phi i64 [ %56, %40 ], [ %35, %33 ]
  %39 = icmp sgt i64 %38, 0
  br i1 %39, label %40, label %57

40:                                               ; preds = %36
  %41 = load i32, ptr %5, align 4, !tbaa !4
  %42 = sitofp i32 %41 to float
  %43 = fdiv contract float 1.000000e+00, %42
  %44 = fpext float %43 to double
  %45 = sext i32 %37 to i64
  %46 = add nsw i64 %45, -1
  %47 = load ptr, ptr %2, align 8, !tbaa !8
  %48 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %2, i64 0, i32 7, i64 0, i64 2
  %49 = load i64, ptr %48, align 8, !tbaa !8
  %50 = mul i64 %46, %49
  %51 = getelementptr i8, ptr %47, i64 %50
  store double %44, ptr %51, align 8, !tbaa !4
  %52 = mul i64 %46, %49
  %53 = getelementptr i8, ptr %47, i64 %52
  %54 = load double, ptr %53, align 8, !tbaa !4
  store double %54, ptr %7, align 8, !tbaa !4
  %55 = add i32 %37, 1
  %56 = add nsw i64 %38, -1
  br label %36

57:                                               ; preds = %19, %36
  ret void
}
*** IR Dump After EarlyCSEPass on _QFPloop ***
define void @_QFPloop(ptr %0, ptr %1, ptr %2, ptr nest %3) local_unnamed_addr {
  %5 = load ptr, ptr %3, align 8, !tbaa !4
  %6 = getelementptr { ptr, ptr }, ptr %3, i64 0, i32 1
  %7 = load ptr, ptr %6, align 8, !tbaa !4
  %8 = load i32, ptr %0, align 4, !tbaa !4
  %9 = sext i32 %8 to i64
  %10 = load i32, ptr %1, align 4, !tbaa !4
  %11 = sext i32 %10 to i64
  %12 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %2, i64 0, i32 7, i64 0, i64 2
  %13 = load i64, ptr %12, align 8, !tbaa !8
  %14 = icmp eq i64 %13, 8
  br i1 %14, label %15, label %33

15:                                               ; preds = %4
  %16 = load ptr, ptr %2, align 8, !tbaa !8
  %17 = sub nsw i64 %11, %9
  %18 = add nsw i64 %17, 1
  br label %19

19:                                               ; preds = %23, %15
  %20 = phi i32 [ %31, %23 ], [ %8, %15 ]
  %21 = phi i64 [ %32, %23 ], [ %18, %15 ]
  %22 = icmp sgt i64 %21, 0
  br i1 %22, label %23, label %52

23:                                               ; preds = %19
  %24 = load i32, ptr %5, align 4, !tbaa !4
  %25 = sitofp i32 %24 to float
  %26 = fdiv contract float 1.000000e+00, %25
  %27 = fpext float %26 to double
  %28 = sext i32 %20 to i64
  %29 = add nsw i64 %28, -1
  %30 = getelementptr double, ptr %16, i64 %29
  store double %27, ptr %30, align 8, !tbaa !4
  store double %27, ptr %7, align 8, !tbaa !4
  %31 = add i32 %20, 1
  %32 = add nsw i64 %21, -1
  br label %19

33:                                               ; preds = %4
  %34 = sub nsw i64 %11, %9
  %35 = add nsw i64 %34, 1
  br label %36

36:                                               ; preds = %40, %33
  %37 = phi i32 [ %50, %40 ], [ %8, %33 ]
  %38 = phi i64 [ %51, %40 ], [ %35, %33 ]
  %39 = icmp sgt i64 %38, 0
  br i1 %39, label %40, label %52

40:                                               ; preds = %36
  %41 = load i32, ptr %5, align 4, !tbaa !4
  %42 = sitofp i32 %41 to float
  %43 = fdiv contract float 1.000000e+00, %42
  %44 = fpext float %43 to double
  %45 = sext i32 %37 to i64
  %46 = add nsw i64 %45, -1
  %47 = load ptr, ptr %2, align 8, !tbaa !8
  %48 = mul i64 %46, %13
  %49 = getelementptr i8, ptr %47, i64 %48
  store double %44, ptr %49, align 8, !tbaa !4
  store double %44, ptr %7, align 8, !tbaa !4
  %50 = add i32 %37, 1
  %51 = add nsw i64 %38, -1
  br label %36

52:                                               ; preds = %19, %36
  ret void
}
*** IR Dump After SpeculativeExecutionPass on _QFPloop ***
define void @_QFPloop(ptr %0, ptr %1, ptr %2, ptr nest %3) local_unnamed_addr {
  %5 = load ptr, ptr %3, align 8, !tbaa !4
  %6 = getelementptr { ptr, ptr }, ptr %3, i64 0, i32 1
  %7 = load ptr, ptr %6, align 8, !tbaa !4
  %8 = load i32, ptr %0, align 4, !tbaa !4
  %9 = sext i32 %8 to i64
  %10 = load i32, ptr %1, align 4, !tbaa !4
  %11 = sext i32 %10 to i64
  %12 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %2, i64 0, i32 7, i64 0, i64 2
  %13 = load i64, ptr %12, align 8, !tbaa !8
  %14 = icmp eq i64 %13, 8
  br i1 %14, label %15, label %33

15:                                               ; preds = %4
  %16 = load ptr, ptr %2, align 8, !tbaa !8
  %17 = sub nsw i64 %11, %9
  %18 = add nsw i64 %17, 1
  br label %19

19:                                               ; preds = %23, %15
  %20 = phi i32 [ %31, %23 ], [ %8, %15 ]
  %21 = phi i64 [ %32, %23 ], [ %18, %15 ]
  %22 = icmp sgt i64 %21, 0
  br i1 %22, label %23, label %52

23:                                               ; preds = %19
  %24 = load i32, ptr %5, align 4, !tbaa !4
  %25 = sitofp i32 %24 to float
  %26 = fdiv contract float 1.000000e+00, %25
  %27 = fpext float %26 to double
  %28 = sext i32 %20 to i64
  %29 = add nsw i64 %28, -1
  %30 = getelementptr double, ptr %16, i64 %29
  store double %27, ptr %30, align 8, !tbaa !4
  store double %27, ptr %7, align 8, !tbaa !4
  %31 = add i32 %20, 1
  %32 = add nsw i64 %21, -1
  br label %19

33:                                               ; preds = %4
  %34 = sub nsw i64 %11, %9
  %35 = add nsw i64 %34, 1
  br label %36

36:                                               ; preds = %40, %33
  %37 = phi i32 [ %50, %40 ], [ %8, %33 ]
  %38 = phi i64 [ %51, %40 ], [ %35, %33 ]
  %39 = icmp sgt i64 %38, 0
  br i1 %39, label %40, label %52

40:                                               ; preds = %36
  %41 = load i32, ptr %5, align 4, !tbaa !4
  %42 = sitofp i32 %41 to float
  %43 = fdiv contract float 1.000000e+00, %42
  %44 = fpext float %43 to double
  %45 = sext i32 %37 to i64
  %46 = add nsw i64 %45, -1
  %47 = load ptr, ptr %2, align 8, !tbaa !8
  %48 = mul i64 %46, %13
  %49 = getelementptr i8, ptr %47, i64 %48
  store double %44, ptr %49, align 8, !tbaa !4
  store double %44, ptr %7, align 8, !tbaa !4
  %50 = add i32 %37, 1
  %51 = add nsw i64 %38, -1
  br label %36

52:                                               ; preds = %19, %36
  ret void
}
*** IR Dump After JumpThreadingPass on _QFPloop ***
define void @_QFPloop(ptr %0, ptr %1, ptr %2, ptr nest %3) local_unnamed_addr {
  %5 = load ptr, ptr %3, align 8, !tbaa !4
  %6 = getelementptr { ptr, ptr }, ptr %3, i64 0, i32 1
  %7 = load ptr, ptr %6, align 8, !tbaa !4
  %8 = load i32, ptr %0, align 4, !tbaa !4
  %9 = sext i32 %8 to i64
  %10 = load i32, ptr %1, align 4, !tbaa !4
  %11 = sext i32 %10 to i64
  %12 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %2, i64 0, i32 7, i64 0, i64 2
  %13 = load i64, ptr %12, align 8, !tbaa !8
  %14 = icmp eq i64 %13, 8
  br i1 %14, label %15, label %33

15:                                               ; preds = %4
  %16 = load ptr, ptr %2, align 8, !tbaa !8
  %17 = sub nsw i64 %11, %9
  %18 = add nsw i64 %17, 1
  br label %19

19:                                               ; preds = %23, %15
  %20 = phi i32 [ %31, %23 ], [ %8, %15 ]
  %21 = phi i64 [ %32, %23 ], [ %18, %15 ]
  %22 = icmp sgt i64 %21, 0
  br i1 %22, label %23, label %52

23:                                               ; preds = %19
  %24 = load i32, ptr %5, align 4, !tbaa !4
  %25 = sitofp i32 %24 to float
  %26 = fdiv contract float 1.000000e+00, %25
  %27 = fpext float %26 to double
  %28 = sext i32 %20 to i64
  %29 = add nsw i64 %28, -1
  %30 = getelementptr double, ptr %16, i64 %29
  store double %27, ptr %30, align 8, !tbaa !4
  store double %27, ptr %7, align 8, !tbaa !4
  %31 = add i32 %20, 1
  %32 = add nsw i64 %21, -1
  br label %19

33:                                               ; preds = %4
  %34 = sub nsw i64 %11, %9
  %35 = add nsw i64 %34, 1
  br label %36

36:                                               ; preds = %40, %33
  %37 = phi i32 [ %50, %40 ], [ %8, %33 ]
  %38 = phi i64 [ %51, %40 ], [ %35, %33 ]
  %39 = icmp sgt i64 %38, 0
  br i1 %39, label %40, label %52

40:                                               ; preds = %36
  %41 = load i32, ptr %5, align 4, !tbaa !4
  %42 = sitofp i32 %41 to float
  %43 = fdiv contract float 1.000000e+00, %42
  %44 = fpext float %43 to double
  %45 = sext i32 %37 to i64
  %46 = add nsw i64 %45, -1
  %47 = load ptr, ptr %2, align 8, !tbaa !8
  %48 = mul i64 %46, %13
  %49 = getelementptr i8, ptr %47, i64 %48
  store double %44, ptr %49, align 8, !tbaa !4
  store double %44, ptr %7, align 8, !tbaa !4
  %50 = add i32 %37, 1
  %51 = add nsw i64 %38, -1
  br label %36

52:                                               ; preds = %19, %36
  ret void
}
*** IR Dump After CorrelatedValuePropagationPass on _QFPloop ***
define void @_QFPloop(ptr %0, ptr %1, ptr %2, ptr nest %3) local_unnamed_addr {
  %5 = load ptr, ptr %3, align 8, !tbaa !4
  %6 = getelementptr { ptr, ptr }, ptr %3, i64 0, i32 1
  %7 = load ptr, ptr %6, align 8, !tbaa !4
  %8 = load i32, ptr %0, align 4, !tbaa !4
  %9 = sext i32 %8 to i64
  %10 = load i32, ptr %1, align 4, !tbaa !4
  %11 = sext i32 %10 to i64
  %12 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %2, i64 0, i32 7, i64 0, i64 2
  %13 = load i64, ptr %12, align 8, !tbaa !8
  %14 = icmp eq i64 %13, 8
  br i1 %14, label %15, label %33

15:                                               ; preds = %4
  %16 = load ptr, ptr %2, align 8, !tbaa !8
  %17 = sub nsw i64 %11, %9
  %18 = add nsw i64 %17, 1
  br label %19

19:                                               ; preds = %23, %15
  %20 = phi i32 [ %31, %23 ], [ %8, %15 ]
  %21 = phi i64 [ %32, %23 ], [ %18, %15 ]
  %22 = icmp sgt i64 %21, 0
  br i1 %22, label %23, label %52

23:                                               ; preds = %19
  %24 = load i32, ptr %5, align 4, !tbaa !4
  %25 = sitofp i32 %24 to float
  %26 = fdiv contract float 1.000000e+00, %25
  %27 = fpext float %26 to double
  %28 = sext i32 %20 to i64
  %29 = add nsw i64 %28, -1
  %30 = getelementptr double, ptr %16, i64 %29
  store double %27, ptr %30, align 8, !tbaa !4
  store double %27, ptr %7, align 8, !tbaa !4
  %31 = add i32 %20, 1
  %32 = add nsw i64 %21, -1
  br label %19

33:                                               ; preds = %4
  %34 = sub nsw i64 %11, %9
  %35 = add nsw i64 %34, 1
  br label %36

36:                                               ; preds = %40, %33
  %37 = phi i32 [ %50, %40 ], [ %8, %33 ]
  %38 = phi i64 [ %51, %40 ], [ %35, %33 ]
  %39 = icmp sgt i64 %38, 0
  br i1 %39, label %40, label %52

40:                                               ; preds = %36
  %41 = load i32, ptr %5, align 4, !tbaa !4
  %42 = sitofp i32 %41 to float
  %43 = fdiv contract float 1.000000e+00, %42
  %44 = fpext float %43 to double
  %45 = sext i32 %37 to i64
  %46 = add nsw i64 %45, -1
  %47 = load ptr, ptr %2, align 8, !tbaa !8
  %48 = mul i64 %46, %13
  %49 = getelementptr i8, ptr %47, i64 %48
  store double %44, ptr %49, align 8, !tbaa !4
  store double %44, ptr %7, align 8, !tbaa !4
  %50 = add i32 %37, 1
  %51 = add nsw i64 %38, -1
  br label %36

52:                                               ; preds = %19, %36
  ret void
}
*** IR Dump After SimplifyCFGPass on _QFPloop ***
define void @_QFPloop(ptr %0, ptr %1, ptr %2, ptr nest %3) local_unnamed_addr {
  %5 = load ptr, ptr %3, align 8, !tbaa !4
  %6 = getelementptr { ptr, ptr }, ptr %3, i64 0, i32 1
  %7 = load ptr, ptr %6, align 8, !tbaa !4
  %8 = load i32, ptr %0, align 4, !tbaa !4
  %9 = sext i32 %8 to i64
  %10 = load i32, ptr %1, align 4, !tbaa !4
  %11 = sext i32 %10 to i64
  %12 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %2, i64 0, i32 7, i64 0, i64 2
  %13 = load i64, ptr %12, align 8, !tbaa !8
  %14 = icmp eq i64 %13, 8
  br i1 %14, label %15, label %33

15:                                               ; preds = %4
  %16 = load ptr, ptr %2, align 8, !tbaa !8
  %17 = sub nsw i64 %11, %9
  %18 = add nsw i64 %17, 1
  br label %19

19:                                               ; preds = %23, %15
  %20 = phi i32 [ %31, %23 ], [ %8, %15 ]
  %21 = phi i64 [ %32, %23 ], [ %18, %15 ]
  %22 = icmp sgt i64 %21, 0
  br i1 %22, label %23, label %52

23:                                               ; preds = %19
  %24 = load i32, ptr %5, align 4, !tbaa !4
  %25 = sitofp i32 %24 to float
  %26 = fdiv contract float 1.000000e+00, %25
  %27 = fpext float %26 to double
  %28 = sext i32 %20 to i64
  %29 = add nsw i64 %28, -1
  %30 = getelementptr double, ptr %16, i64 %29
  store double %27, ptr %30, align 8, !tbaa !4
  store double %27, ptr %7, align 8, !tbaa !4
  %31 = add i32 %20, 1
  %32 = add nsw i64 %21, -1
  br label %19

33:                                               ; preds = %4
  %34 = sub nsw i64 %11, %9
  %35 = add nsw i64 %34, 1
  br label %36

36:                                               ; preds = %40, %33
  %37 = phi i32 [ %50, %40 ], [ %8, %33 ]
  %38 = phi i64 [ %51, %40 ], [ %35, %33 ]
  %39 = icmp sgt i64 %38, 0
  br i1 %39, label %40, label %52

40:                                               ; preds = %36
  %41 = load i32, ptr %5, align 4, !tbaa !4
  %42 = sitofp i32 %41 to float
  %43 = fdiv contract float 1.000000e+00, %42
  %44 = fpext float %43 to double
  %45 = sext i32 %37 to i64
  %46 = add nsw i64 %45, -1
  %47 = load ptr, ptr %2, align 8, !tbaa !8
  %48 = mul i64 %46, %13
  %49 = getelementptr i8, ptr %47, i64 %48
  store double %44, ptr %49, align 8, !tbaa !4
  store double %44, ptr %7, align 8, !tbaa !4
  %50 = add i32 %37, 1
  %51 = add nsw i64 %38, -1
  br label %36

52:                                               ; preds = %19, %36
  ret void
}
*** IR Dump After InstCombinePass on _QFPloop ***
define void @_QFPloop(ptr %0, ptr %1, ptr %2, ptr nest %3) local_unnamed_addr {
  %5 = load ptr, ptr %3, align 8, !tbaa !4
  %6 = getelementptr { ptr, ptr }, ptr %3, i64 0, i32 1
  %7 = load ptr, ptr %6, align 8, !tbaa !4
  %8 = load i32, ptr %0, align 4, !tbaa !4
  %9 = sext i32 %8 to i64
  %10 = load i32, ptr %1, align 4, !tbaa !4
  %11 = sext i32 %10 to i64
  %12 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %2, i64 0, i32 7, i64 0, i64 2
  %13 = load i64, ptr %12, align 8, !tbaa !8
  %14 = icmp eq i64 %13, 8
  br i1 %14, label %15, label %33

15:                                               ; preds = %4
  %16 = load ptr, ptr %2, align 8, !tbaa !8
  %17 = sub nsw i64 %11, %9
  %18 = add nsw i64 %17, 1
  br label %19

19:                                               ; preds = %23, %15
  %20 = phi i32 [ %31, %23 ], [ %8, %15 ]
  %21 = phi i64 [ %32, %23 ], [ %18, %15 ]
  %22 = icmp sgt i64 %21, 0
  br i1 %22, label %23, label %52

23:                                               ; preds = %19
  %24 = load i32, ptr %5, align 4, !tbaa !4
  %25 = sitofp i32 %24 to float
  %26 = fdiv contract float 1.000000e+00, %25
  %27 = fpext float %26 to double
  %28 = sext i32 %20 to i64
  %29 = add nsw i64 %28, -1
  %30 = getelementptr double, ptr %16, i64 %29
  store double %27, ptr %30, align 8, !tbaa !4
  store double %27, ptr %7, align 8, !tbaa !4
  %31 = add i32 %20, 1
  %32 = add nsw i64 %21, -1
  br label %19

33:                                               ; preds = %4
  %34 = sub nsw i64 %11, %9
  %35 = add nsw i64 %34, 1
  br label %36

36:                                               ; preds = %40, %33
  %37 = phi i32 [ %50, %40 ], [ %8, %33 ]
  %38 = phi i64 [ %51, %40 ], [ %35, %33 ]
  %39 = icmp sgt i64 %38, 0
  br i1 %39, label %40, label %52

40:                                               ; preds = %36
  %41 = load i32, ptr %5, align 4, !tbaa !4
  %42 = sitofp i32 %41 to float
  %43 = fdiv contract float 1.000000e+00, %42
  %44 = fpext float %43 to double
  %45 = sext i32 %37 to i64
  %46 = add nsw i64 %45, -1
  %47 = load ptr, ptr %2, align 8, !tbaa !8
  %48 = mul i64 %46, %13
  %49 = getelementptr i8, ptr %47, i64 %48
  store double %44, ptr %49, align 8, !tbaa !4
  store double %44, ptr %7, align 8, !tbaa !4
  %50 = add i32 %37, 1
  %51 = add nsw i64 %38, -1
  br label %36

52:                                               ; preds = %19, %36
  ret void
}
*** IR Dump After AggressiveInstCombinePass on _QFPloop ***
define void @_QFPloop(ptr %0, ptr %1, ptr %2, ptr nest %3) local_unnamed_addr {
  %5 = load ptr, ptr %3, align 8, !tbaa !4
  %6 = getelementptr { ptr, ptr }, ptr %3, i64 0, i32 1
  %7 = load ptr, ptr %6, align 8, !tbaa !4
  %8 = load i32, ptr %0, align 4, !tbaa !4
  %9 = sext i32 %8 to i64
  %10 = load i32, ptr %1, align 4, !tbaa !4
  %11 = sext i32 %10 to i64
  %12 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %2, i64 0, i32 7, i64 0, i64 2
  %13 = load i64, ptr %12, align 8, !tbaa !8
  %14 = icmp eq i64 %13, 8
  br i1 %14, label %15, label %33

15:                                               ; preds = %4
  %16 = load ptr, ptr %2, align 8, !tbaa !8
  %17 = sub nsw i64 %11, %9
  %18 = add nsw i64 %17, 1
  br label %19

19:                                               ; preds = %23, %15
  %20 = phi i32 [ %31, %23 ], [ %8, %15 ]
  %21 = phi i64 [ %32, %23 ], [ %18, %15 ]
  %22 = icmp sgt i64 %21, 0
  br i1 %22, label %23, label %52

23:                                               ; preds = %19
  %24 = load i32, ptr %5, align 4, !tbaa !4
  %25 = sitofp i32 %24 to float
  %26 = fdiv contract float 1.000000e+00, %25
  %27 = fpext float %26 to double
  %28 = sext i32 %20 to i64
  %29 = add nsw i64 %28, -1
  %30 = getelementptr double, ptr %16, i64 %29
  store double %27, ptr %30, align 8, !tbaa !4
  store double %27, ptr %7, align 8, !tbaa !4
  %31 = add i32 %20, 1
  %32 = add nsw i64 %21, -1
  br label %19

33:                                               ; preds = %4
  %34 = sub nsw i64 %11, %9
  %35 = add nsw i64 %34, 1
  br label %36

36:                                               ; preds = %40, %33
  %37 = phi i32 [ %50, %40 ], [ %8, %33 ]
  %38 = phi i64 [ %51, %40 ], [ %35, %33 ]
  %39 = icmp sgt i64 %38, 0
  br i1 %39, label %40, label %52

40:                                               ; preds = %36
  %41 = load i32, ptr %5, align 4, !tbaa !4
  %42 = sitofp i32 %41 to float
  %43 = fdiv contract float 1.000000e+00, %42
  %44 = fpext float %43 to double
  %45 = sext i32 %37 to i64
  %46 = add nsw i64 %45, -1
  %47 = load ptr, ptr %2, align 8, !tbaa !8
  %48 = mul i64 %46, %13
  %49 = getelementptr i8, ptr %47, i64 %48
  store double %44, ptr %49, align 8, !tbaa !4
  store double %44, ptr %7, align 8, !tbaa !4
  %50 = add i32 %37, 1
  %51 = add nsw i64 %38, -1
  br label %36

52:                                               ; preds = %19, %36
  ret void
}
*** IR Dump After ConstraintEliminationPass on _QFPloop ***
define void @_QFPloop(ptr %0, ptr %1, ptr %2, ptr nest %3) local_unnamed_addr {
  %5 = load ptr, ptr %3, align 8, !tbaa !4
  %6 = getelementptr { ptr, ptr }, ptr %3, i64 0, i32 1
  %7 = load ptr, ptr %6, align 8, !tbaa !4
  %8 = load i32, ptr %0, align 4, !tbaa !4
  %9 = sext i32 %8 to i64
  %10 = load i32, ptr %1, align 4, !tbaa !4
  %11 = sext i32 %10 to i64
  %12 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %2, i64 0, i32 7, i64 0, i64 2
  %13 = load i64, ptr %12, align 8, !tbaa !8
  %14 = icmp eq i64 %13, 8
  br i1 %14, label %15, label %33

15:                                               ; preds = %4
  %16 = load ptr, ptr %2, align 8, !tbaa !8
  %17 = sub nsw i64 %11, %9
  %18 = add nsw i64 %17, 1
  br label %19

19:                                               ; preds = %23, %15
  %20 = phi i32 [ %31, %23 ], [ %8, %15 ]
  %21 = phi i64 [ %32, %23 ], [ %18, %15 ]
  %22 = icmp sgt i64 %21, 0
  br i1 %22, label %23, label %52

23:                                               ; preds = %19
  %24 = load i32, ptr %5, align 4, !tbaa !4
  %25 = sitofp i32 %24 to float
  %26 = fdiv contract float 1.000000e+00, %25
  %27 = fpext float %26 to double
  %28 = sext i32 %20 to i64
  %29 = add nsw i64 %28, -1
  %30 = getelementptr double, ptr %16, i64 %29
  store double %27, ptr %30, align 8, !tbaa !4
  store double %27, ptr %7, align 8, !tbaa !4
  %31 = add i32 %20, 1
  %32 = add nsw i64 %21, -1
  br label %19

33:                                               ; preds = %4
  %34 = sub nsw i64 %11, %9
  %35 = add nsw i64 %34, 1
  br label %36

36:                                               ; preds = %40, %33
  %37 = phi i32 [ %50, %40 ], [ %8, %33 ]
  %38 = phi i64 [ %51, %40 ], [ %35, %33 ]
  %39 = icmp sgt i64 %38, 0
  br i1 %39, label %40, label %52

40:                                               ; preds = %36
  %41 = load i32, ptr %5, align 4, !tbaa !4
  %42 = sitofp i32 %41 to float
  %43 = fdiv contract float 1.000000e+00, %42
  %44 = fpext float %43 to double
  %45 = sext i32 %37 to i64
  %46 = add nsw i64 %45, -1
  %47 = load ptr, ptr %2, align 8, !tbaa !8
  %48 = mul i64 %46, %13
  %49 = getelementptr i8, ptr %47, i64 %48
  store double %44, ptr %49, align 8, !tbaa !4
  store double %44, ptr %7, align 8, !tbaa !4
  %50 = add i32 %37, 1
  %51 = add nsw i64 %38, -1
  br label %36

52:                                               ; preds = %19, %36
  ret void
}
*** IR Dump After LibCallsShrinkWrapPass on _QFPloop ***
define void @_QFPloop(ptr %0, ptr %1, ptr %2, ptr nest %3) local_unnamed_addr {
  %5 = load ptr, ptr %3, align 8, !tbaa !4
  %6 = getelementptr { ptr, ptr }, ptr %3, i64 0, i32 1
  %7 = load ptr, ptr %6, align 8, !tbaa !4
  %8 = load i32, ptr %0, align 4, !tbaa !4
  %9 = sext i32 %8 to i64
  %10 = load i32, ptr %1, align 4, !tbaa !4
  %11 = sext i32 %10 to i64
  %12 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %2, i64 0, i32 7, i64 0, i64 2
  %13 = load i64, ptr %12, align 8, !tbaa !8
  %14 = icmp eq i64 %13, 8
  br i1 %14, label %15, label %33

15:                                               ; preds = %4
  %16 = load ptr, ptr %2, align 8, !tbaa !8
  %17 = sub nsw i64 %11, %9
  %18 = add nsw i64 %17, 1
  br label %19

19:                                               ; preds = %23, %15
  %20 = phi i32 [ %31, %23 ], [ %8, %15 ]
  %21 = phi i64 [ %32, %23 ], [ %18, %15 ]
  %22 = icmp sgt i64 %21, 0
  br i1 %22, label %23, label %52

23:                                               ; preds = %19
  %24 = load i32, ptr %5, align 4, !tbaa !4
  %25 = sitofp i32 %24 to float
  %26 = fdiv contract float 1.000000e+00, %25
  %27 = fpext float %26 to double
  %28 = sext i32 %20 to i64
  %29 = add nsw i64 %28, -1
  %30 = getelementptr double, ptr %16, i64 %29
  store double %27, ptr %30, align 8, !tbaa !4
  store double %27, ptr %7, align 8, !tbaa !4
  %31 = add i32 %20, 1
  %32 = add nsw i64 %21, -1
  br label %19

33:                                               ; preds = %4
  %34 = sub nsw i64 %11, %9
  %35 = add nsw i64 %34, 1
  br label %36

36:                                               ; preds = %40, %33
  %37 = phi i32 [ %50, %40 ], [ %8, %33 ]
  %38 = phi i64 [ %51, %40 ], [ %35, %33 ]
  %39 = icmp sgt i64 %38, 0
  br i1 %39, label %40, label %52

40:                                               ; preds = %36
  %41 = load i32, ptr %5, align 4, !tbaa !4
  %42 = sitofp i32 %41 to float
  %43 = fdiv contract float 1.000000e+00, %42
  %44 = fpext float %43 to double
  %45 = sext i32 %37 to i64
  %46 = add nsw i64 %45, -1
  %47 = load ptr, ptr %2, align 8, !tbaa !8
  %48 = mul i64 %46, %13
  %49 = getelementptr i8, ptr %47, i64 %48
  store double %44, ptr %49, align 8, !tbaa !4
  store double %44, ptr %7, align 8, !tbaa !4
  %50 = add i32 %37, 1
  %51 = add nsw i64 %38, -1
  br label %36

52:                                               ; preds = %19, %36
  ret void
}
*** IR Dump After TailCallElimPass on _QFPloop ***
define void @_QFPloop(ptr %0, ptr %1, ptr %2, ptr nest %3) local_unnamed_addr {
  %5 = load ptr, ptr %3, align 8, !tbaa !4
  %6 = getelementptr { ptr, ptr }, ptr %3, i64 0, i32 1
  %7 = load ptr, ptr %6, align 8, !tbaa !4
  %8 = load i32, ptr %0, align 4, !tbaa !4
  %9 = sext i32 %8 to i64
  %10 = load i32, ptr %1, align 4, !tbaa !4
  %11 = sext i32 %10 to i64
  %12 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %2, i64 0, i32 7, i64 0, i64 2
  %13 = load i64, ptr %12, align 8, !tbaa !8
  %14 = icmp eq i64 %13, 8
  br i1 %14, label %15, label %33

15:                                               ; preds = %4
  %16 = load ptr, ptr %2, align 8, !tbaa !8
  %17 = sub nsw i64 %11, %9
  %18 = add nsw i64 %17, 1
  br label %19

19:                                               ; preds = %23, %15
  %20 = phi i32 [ %31, %23 ], [ %8, %15 ]
  %21 = phi i64 [ %32, %23 ], [ %18, %15 ]
  %22 = icmp sgt i64 %21, 0
  br i1 %22, label %23, label %52

23:                                               ; preds = %19
  %24 = load i32, ptr %5, align 4, !tbaa !4
  %25 = sitofp i32 %24 to float
  %26 = fdiv contract float 1.000000e+00, %25
  %27 = fpext float %26 to double
  %28 = sext i32 %20 to i64
  %29 = add nsw i64 %28, -1
  %30 = getelementptr double, ptr %16, i64 %29
  store double %27, ptr %30, align 8, !tbaa !4
  store double %27, ptr %7, align 8, !tbaa !4
  %31 = add i32 %20, 1
  %32 = add nsw i64 %21, -1
  br label %19

33:                                               ; preds = %4
  %34 = sub nsw i64 %11, %9
  %35 = add nsw i64 %34, 1
  br label %36

36:                                               ; preds = %40, %33
  %37 = phi i32 [ %50, %40 ], [ %8, %33 ]
  %38 = phi i64 [ %51, %40 ], [ %35, %33 ]
  %39 = icmp sgt i64 %38, 0
  br i1 %39, label %40, label %52

40:                                               ; preds = %36
  %41 = load i32, ptr %5, align 4, !tbaa !4
  %42 = sitofp i32 %41 to float
  %43 = fdiv contract float 1.000000e+00, %42
  %44 = fpext float %43 to double
  %45 = sext i32 %37 to i64
  %46 = add nsw i64 %45, -1
  %47 = load ptr, ptr %2, align 8, !tbaa !8
  %48 = mul i64 %46, %13
  %49 = getelementptr i8, ptr %47, i64 %48
  store double %44, ptr %49, align 8, !tbaa !4
  store double %44, ptr %7, align 8, !tbaa !4
  %50 = add i32 %37, 1
  %51 = add nsw i64 %38, -1
  br label %36

52:                                               ; preds = %19, %36
  ret void
}
*** IR Dump After SimplifyCFGPass on _QFPloop ***
define void @_QFPloop(ptr %0, ptr %1, ptr %2, ptr nest %3) local_unnamed_addr {
  %5 = load ptr, ptr %3, align 8, !tbaa !4
  %6 = getelementptr { ptr, ptr }, ptr %3, i64 0, i32 1
  %7 = load ptr, ptr %6, align 8, !tbaa !4
  %8 = load i32, ptr %0, align 4, !tbaa !4
  %9 = sext i32 %8 to i64
  %10 = load i32, ptr %1, align 4, !tbaa !4
  %11 = sext i32 %10 to i64
  %12 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %2, i64 0, i32 7, i64 0, i64 2
  %13 = load i64, ptr %12, align 8, !tbaa !8
  %14 = icmp eq i64 %13, 8
  br i1 %14, label %15, label %33

15:                                               ; preds = %4
  %16 = load ptr, ptr %2, align 8, !tbaa !8
  %17 = sub nsw i64 %11, %9
  %18 = add nsw i64 %17, 1
  br label %19

19:                                               ; preds = %23, %15
  %20 = phi i32 [ %31, %23 ], [ %8, %15 ]
  %21 = phi i64 [ %32, %23 ], [ %18, %15 ]
  %22 = icmp sgt i64 %21, 0
  br i1 %22, label %23, label %52

23:                                               ; preds = %19
  %24 = load i32, ptr %5, align 4, !tbaa !4
  %25 = sitofp i32 %24 to float
  %26 = fdiv contract float 1.000000e+00, %25
  %27 = fpext float %26 to double
  %28 = sext i32 %20 to i64
  %29 = add nsw i64 %28, -1
  %30 = getelementptr double, ptr %16, i64 %29
  store double %27, ptr %30, align 8, !tbaa !4
  store double %27, ptr %7, align 8, !tbaa !4
  %31 = add i32 %20, 1
  %32 = add nsw i64 %21, -1
  br label %19

33:                                               ; preds = %4
  %34 = sub nsw i64 %11, %9
  %35 = add nsw i64 %34, 1
  br label %36

36:                                               ; preds = %40, %33
  %37 = phi i32 [ %50, %40 ], [ %8, %33 ]
  %38 = phi i64 [ %51, %40 ], [ %35, %33 ]
  %39 = icmp sgt i64 %38, 0
  br i1 %39, label %40, label %52

40:                                               ; preds = %36
  %41 = load i32, ptr %5, align 4, !tbaa !4
  %42 = sitofp i32 %41 to float
  %43 = fdiv contract float 1.000000e+00, %42
  %44 = fpext float %43 to double
  %45 = sext i32 %37 to i64
  %46 = add nsw i64 %45, -1
  %47 = load ptr, ptr %2, align 8, !tbaa !8
  %48 = mul i64 %46, %13
  %49 = getelementptr i8, ptr %47, i64 %48
  store double %44, ptr %49, align 8, !tbaa !4
  store double %44, ptr %7, align 8, !tbaa !4
  %50 = add i32 %37, 1
  %51 = add nsw i64 %38, -1
  br label %36

52:                                               ; preds = %19, %36
  ret void
}
*** IR Dump After ReassociatePass on _QFPloop ***
define void @_QFPloop(ptr %0, ptr %1, ptr %2, ptr nest %3) local_unnamed_addr {
  %5 = load ptr, ptr %3, align 8, !tbaa !4
  %6 = getelementptr { ptr, ptr }, ptr %3, i64 0, i32 1
  %7 = load ptr, ptr %6, align 8, !tbaa !4
  %8 = load i32, ptr %0, align 4, !tbaa !4
  %9 = sext i32 %8 to i64
  %.neg = sub i64 0, %9
  %10 = load i32, ptr %1, align 4, !tbaa !4
  %11 = sext i32 %10 to i64
  %12 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %2, i64 0, i32 7, i64 0, i64 2
  %13 = load i64, ptr %12, align 8, !tbaa !8
  %14 = icmp eq i64 %13, 8
  br i1 %14, label %15, label %33

15:                                               ; preds = %4
  %16 = load ptr, ptr %2, align 8, !tbaa !8
  %17 = add i64 %.neg, 1
  %18 = add i64 %17, %11
  br label %19

19:                                               ; preds = %23, %15
  %20 = phi i32 [ %31, %23 ], [ %8, %15 ]
  %21 = phi i64 [ %32, %23 ], [ %18, %15 ]
  %22 = icmp sgt i64 %21, 0
  br i1 %22, label %23, label %52

23:                                               ; preds = %19
  %24 = load i32, ptr %5, align 4, !tbaa !4
  %25 = sitofp i32 %24 to float
  %26 = fdiv contract float 1.000000e+00, %25
  %27 = fpext float %26 to double
  %28 = sext i32 %20 to i64
  %29 = add nsw i64 %28, -1
  %30 = getelementptr double, ptr %16, i64 %29
  store double %27, ptr %30, align 8, !tbaa !4
  store double %27, ptr %7, align 8, !tbaa !4
  %31 = add i32 %20, 1
  %32 = add nsw i64 %21, -1
  br label %19

33:                                               ; preds = %4
  %34 = add i64 %.neg, 1
  %35 = add i64 %34, %11
  br label %36

36:                                               ; preds = %40, %33
  %37 = phi i32 [ %50, %40 ], [ %8, %33 ]
  %38 = phi i64 [ %51, %40 ], [ %35, %33 ]
  %39 = icmp sgt i64 %38, 0
  br i1 %39, label %40, label %52

40:                                               ; preds = %36
  %41 = load i32, ptr %5, align 4, !tbaa !4
  %42 = sitofp i32 %41 to float
  %43 = fdiv contract float 1.000000e+00, %42
  %44 = fpext float %43 to double
  %45 = sext i32 %37 to i64
  %46 = add nsw i64 %45, -1
  %47 = load ptr, ptr %2, align 8, !tbaa !8
  %48 = mul i64 %46, %13
  %49 = getelementptr i8, ptr %47, i64 %48
  store double %44, ptr %49, align 8, !tbaa !4
  store double %44, ptr %7, align 8, !tbaa !4
  %50 = add i32 %37, 1
  %51 = add nsw i64 %38, -1
  br label %36

52:                                               ; preds = %19, %36
  ret void
}
*** IR Dump After LoopSimplifyPass on _QFPloop ***
define void @_QFPloop(ptr %0, ptr %1, ptr %2, ptr nest %3) local_unnamed_addr {
  %5 = load ptr, ptr %3, align 8, !tbaa !4
  %6 = getelementptr { ptr, ptr }, ptr %3, i64 0, i32 1
  %7 = load ptr, ptr %6, align 8, !tbaa !4
  %8 = load i32, ptr %0, align 4, !tbaa !4
  %9 = sext i32 %8 to i64
  %.neg = sub i64 0, %9
  %10 = load i32, ptr %1, align 4, !tbaa !4
  %11 = sext i32 %10 to i64
  %12 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %2, i64 0, i32 7, i64 0, i64 2
  %13 = load i64, ptr %12, align 8, !tbaa !8
  %14 = icmp eq i64 %13, 8
  br i1 %14, label %15, label %33

15:                                               ; preds = %4
  %16 = load ptr, ptr %2, align 8, !tbaa !8
  %17 = add i64 %.neg, 1
  %18 = add i64 %17, %11
  br label %19

19:                                               ; preds = %23, %15
  %20 = phi i32 [ %31, %23 ], [ %8, %15 ]
  %21 = phi i64 [ %32, %23 ], [ %18, %15 ]
  %22 = icmp sgt i64 %21, 0
  br i1 %22, label %23, label %.loopexit

23:                                               ; preds = %19
  %24 = load i32, ptr %5, align 4, !tbaa !4
  %25 = sitofp i32 %24 to float
  %26 = fdiv contract float 1.000000e+00, %25
  %27 = fpext float %26 to double
  %28 = sext i32 %20 to i64
  %29 = add nsw i64 %28, -1
  %30 = getelementptr double, ptr %16, i64 %29
  store double %27, ptr %30, align 8, !tbaa !4
  store double %27, ptr %7, align 8, !tbaa !4
  %31 = add i32 %20, 1
  %32 = add nsw i64 %21, -1
  br label %19

33:                                               ; preds = %4
  %34 = add i64 %.neg, 1
  %35 = add i64 %34, %11
  br label %36

36:                                               ; preds = %40, %33
  %37 = phi i32 [ %50, %40 ], [ %8, %33 ]
  %38 = phi i64 [ %51, %40 ], [ %35, %33 ]
  %39 = icmp sgt i64 %38, 0
  br i1 %39, label %40, label %.loopexit7

40:                                               ; preds = %36
  %41 = load i32, ptr %5, align 4, !tbaa !4
  %42 = sitofp i32 %41 to float
  %43 = fdiv contract float 1.000000e+00, %42
  %44 = fpext float %43 to double
  %45 = sext i32 %37 to i64
  %46 = add nsw i64 %45, -1
  %47 = load ptr, ptr %2, align 8, !tbaa !8
  %48 = mul i64 %46, %13
  %49 = getelementptr i8, ptr %47, i64 %48
  store double %44, ptr %49, align 8, !tbaa !4
  store double %44, ptr %7, align 8, !tbaa !4
  %50 = add i32 %37, 1
  %51 = add nsw i64 %38, -1
  br label %36

.loopexit:                                        ; preds = %19
  br label %52

.loopexit7:                                       ; preds = %36
  br label %52

52:                                               ; preds = %.loopexit7, %.loopexit
  ret void
}
*** IR Dump After LCSSAPass on _QFPloop ***
define void @_QFPloop(ptr %0, ptr %1, ptr %2, ptr nest %3) local_unnamed_addr {
  %5 = load ptr, ptr %3, align 8, !tbaa !4
  %6 = getelementptr { ptr, ptr }, ptr %3, i64 0, i32 1
  %7 = load ptr, ptr %6, align 8, !tbaa !4
  %8 = load i32, ptr %0, align 4, !tbaa !4
  %9 = sext i32 %8 to i64
  %.neg = sub i64 0, %9
  %10 = load i32, ptr %1, align 4, !tbaa !4
  %11 = sext i32 %10 to i64
  %12 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %2, i64 0, i32 7, i64 0, i64 2
  %13 = load i64, ptr %12, align 8, !tbaa !8
  %14 = icmp eq i64 %13, 8
  br i1 %14, label %15, label %33

15:                                               ; preds = %4
  %16 = load ptr, ptr %2, align 8, !tbaa !8
  %17 = add i64 %.neg, 1
  %18 = add i64 %17, %11
  br label %19

19:                                               ; preds = %23, %15
  %20 = phi i32 [ %31, %23 ], [ %8, %15 ]
  %21 = phi i64 [ %32, %23 ], [ %18, %15 ]
  %22 = icmp sgt i64 %21, 0
  br i1 %22, label %23, label %.loopexit

23:                                               ; preds = %19
  %24 = load i32, ptr %5, align 4, !tbaa !4
  %25 = sitofp i32 %24 to float
  %26 = fdiv contract float 1.000000e+00, %25
  %27 = fpext float %26 to double
  %28 = sext i32 %20 to i64
  %29 = add nsw i64 %28, -1
  %30 = getelementptr double, ptr %16, i64 %29
  store double %27, ptr %30, align 8, !tbaa !4
  store double %27, ptr %7, align 8, !tbaa !4
  %31 = add i32 %20, 1
  %32 = add nsw i64 %21, -1
  br label %19

33:                                               ; preds = %4
  %34 = add i64 %.neg, 1
  %35 = add i64 %34, %11
  br label %36

36:                                               ; preds = %40, %33
  %37 = phi i32 [ %50, %40 ], [ %8, %33 ]
  %38 = phi i64 [ %51, %40 ], [ %35, %33 ]
  %39 = icmp sgt i64 %38, 0
  br i1 %39, label %40, label %.loopexit7

40:                                               ; preds = %36
  %41 = load i32, ptr %5, align 4, !tbaa !4
  %42 = sitofp i32 %41 to float
  %43 = fdiv contract float 1.000000e+00, %42
  %44 = fpext float %43 to double
  %45 = sext i32 %37 to i64
  %46 = add nsw i64 %45, -1
  %47 = load ptr, ptr %2, align 8, !tbaa !8
  %48 = mul i64 %46, %13
  %49 = getelementptr i8, ptr %47, i64 %48
  store double %44, ptr %49, align 8, !tbaa !4
  store double %44, ptr %7, align 8, !tbaa !4
  %50 = add i32 %37, 1
  %51 = add nsw i64 %38, -1
  br label %36

.loopexit:                                        ; preds = %19
  br label %52

.loopexit7:                                       ; preds = %36
  br label %52

52:                                               ; preds = %.loopexit7, %.loopexit
  ret void
}
*** IR Dump After LoopInstSimplifyPass on <unnamed loop> ***

; Preheader:
33:                                               ; preds = %4
  %34 = add i64 %.neg, 1
  %35 = add i64 %34, %11
  br label %36

; Loop:
36:                                               ; preds = %40, %33
  %37 = phi i32 [ %50, %40 ], [ %8, %33 ]
  %38 = phi i64 [ %51, %40 ], [ %35, %33 ]
  %39 = icmp sgt i64 %38, 0
  br i1 %39, label %40, label %.loopexit7

40:                                               ; preds = %36
  %41 = load i32, ptr %5, align 4, !tbaa !4
  %42 = sitofp i32 %41 to float
  %43 = fdiv contract float 1.000000e+00, %42
  %44 = fpext float %43 to double
  %45 = sext i32 %37 to i64
  %46 = add nsw i64 %45, -1
  %47 = load ptr, ptr %2, align 8, !tbaa !8
  %48 = mul i64 %46, %13
  %49 = getelementptr i8, ptr %47, i64 %48
  store double %44, ptr %49, align 8, !tbaa !4
  store double %44, ptr %7, align 8, !tbaa !4
  %50 = add i32 %37, 1
  %51 = add nsw i64 %38, -1
  br label %36

; Exit blocks
.loopexit7:                                       ; preds = %36
  br label %52
*** IR Dump After LoopSimplifyCFGPass on <unnamed loop> ***

; Preheader:
33:                                               ; preds = %4
  %34 = add i64 %.neg, 1
  %35 = add i64 %34, %11
  br label %36

; Loop:
36:                                               ; preds = %40, %33
  %37 = phi i32 [ %50, %40 ], [ %8, %33 ]
  %38 = phi i64 [ %51, %40 ], [ %35, %33 ]
  %39 = icmp sgt i64 %38, 0
  br i1 %39, label %40, label %.loopexit7

40:                                               ; preds = %36
  %41 = load i32, ptr %5, align 4, !tbaa !4
  %42 = sitofp i32 %41 to float
  %43 = fdiv contract float 1.000000e+00, %42
  %44 = fpext float %43 to double
  %45 = sext i32 %37 to i64
  %46 = add nsw i64 %45, -1
  %47 = load ptr, ptr %2, align 8, !tbaa !8
  %48 = mul i64 %46, %13
  %49 = getelementptr i8, ptr %47, i64 %48
  store double %44, ptr %49, align 8, !tbaa !4
  store double %44, ptr %7, align 8, !tbaa !4
  %50 = add i32 %37, 1
  %51 = add nsw i64 %38, -1
  br label %36

; Exit blocks
.loopexit7:                                       ; preds = %36
  br label %52
*** IR Dump After LICMPass on <unnamed loop> ***

; Preheader:
33:                                               ; preds = %4
  %34 = add i64 %.neg, 1
  %35 = add i64 %34, %11
  br label %36

; Loop:
36:                                               ; preds = %40, %33
  %37 = phi i32 [ %50, %40 ], [ %8, %33 ]
  %38 = phi i64 [ %51, %40 ], [ %35, %33 ]
  %39 = icmp sgt i64 %38, 0
  br i1 %39, label %40, label %.loopexit7

40:                                               ; preds = %36
  %41 = load i32, ptr %5, align 4, !tbaa !4
  %42 = sitofp i32 %41 to float
  %43 = fdiv contract float 1.000000e+00, %42
  %44 = fpext float %43 to double
  %45 = sext i32 %37 to i64
  %46 = add nsw i64 %45, -1
  %47 = load ptr, ptr %2, align 8, !tbaa !8
  %48 = mul i64 %46, %13
  %49 = getelementptr i8, ptr %47, i64 %48
  store double %44, ptr %49, align 8, !tbaa !4
  store double %44, ptr %7, align 8, !tbaa !4
  %50 = add i32 %37, 1
  %51 = add nsw i64 %38, -1
  br label %36

; Exit blocks
.loopexit7:                                       ; preds = %36
  br label %52
*** IR Dump After LoopRotatePass on <unnamed loop> ***

; Preheader:
.lr.ph:                                           ; preds = %33
  br label %37

; Loop:
37:                                               ; preds = %.lr.ph, %37
  %38 = phi i64 [ %35, %.lr.ph ], [ %50, %37 ]
  %39 = phi i32 [ %8, %.lr.ph ], [ %49, %37 ]
  %40 = load i32, ptr %5, align 4, !tbaa !4
  %41 = sitofp i32 %40 to float
  %42 = fdiv contract float 1.000000e+00, %41
  %43 = fpext float %42 to double
  %44 = sext i32 %39 to i64
  %45 = add nsw i64 %44, -1
  %46 = load ptr, ptr %2, align 8, !tbaa !8
  %47 = mul i64 %45, %13
  %48 = getelementptr i8, ptr %46, i64 %47
  store double %43, ptr %48, align 8, !tbaa !4
  store double %43, ptr %7, align 8, !tbaa !4
  %49 = add i32 %39, 1
  %50 = add nsw i64 %38, -1
  %51 = icmp sgt i64 %50, 0
  br i1 %51, label %37, label %..loopexit7_crit_edge

; Exit blocks
..loopexit7_crit_edge:                            ; preds = %37
  br label %.loopexit7
*** IR Dump After LICMPass on <unnamed loop> ***

; Preheader:
.lr.ph:                                           ; preds = %33
  %37 = load ptr, ptr %2, align 8, !tbaa !8
  br label %38

; Loop:
38:                                               ; preds = %.lr.ph, %38
  %39 = phi i64 [ %35, %.lr.ph ], [ %50, %38 ]
  %40 = phi i32 [ %8, %.lr.ph ], [ %49, %38 ]
  %41 = load i32, ptr %5, align 4, !tbaa !4
  %42 = sitofp i32 %41 to float
  %43 = fdiv contract float 1.000000e+00, %42
  %44 = fpext float %43 to double
  %45 = sext i32 %40 to i64
  %46 = add nsw i64 %45, -1
  %47 = mul i64 %46, %13
  %48 = getelementptr i8, ptr %37, i64 %47
  store double %44, ptr %48, align 8, !tbaa !4
  store double %44, ptr %7, align 8, !tbaa !4
  %49 = add i32 %40, 1
  %50 = add nsw i64 %39, -1
  %51 = icmp sgt i64 %50, 0
  br i1 %51, label %38, label %..loopexit7_crit_edge

; Exit blocks
..loopexit7_crit_edge:                            ; preds = %38
  br label %.loopexit7
*** IR Dump After SimpleLoopUnswitchPass on <unnamed loop> ***

; Preheader:
.lr.ph:                                           ; preds = %33
  %37 = load ptr, ptr %2, align 8, !tbaa !8
  br label %38

; Loop:
38:                                               ; preds = %.lr.ph, %38
  %39 = phi i64 [ %35, %.lr.ph ], [ %50, %38 ]
  %40 = phi i32 [ %8, %.lr.ph ], [ %49, %38 ]
  %41 = load i32, ptr %5, align 4, !tbaa !4
  %42 = sitofp i32 %41 to float
  %43 = fdiv contract float 1.000000e+00, %42
  %44 = fpext float %43 to double
  %45 = sext i32 %40 to i64
  %46 = add nsw i64 %45, -1
  %47 = mul i64 %46, %13
  %48 = getelementptr i8, ptr %37, i64 %47
  store double %44, ptr %48, align 8, !tbaa !4
  store double %44, ptr %7, align 8, !tbaa !4
  %49 = add i32 %40, 1
  %50 = add nsw i64 %39, -1
  %51 = icmp sgt i64 %50, 0
  br i1 %51, label %38, label %..loopexit7_crit_edge

; Exit blocks
..loopexit7_crit_edge:                            ; preds = %38
  br label %.loopexit7
*** IR Dump After LoopInstSimplifyPass on <unnamed loop> ***

; Preheader:
15:                                               ; preds = %4
  %16 = load ptr, ptr %2, align 8, !tbaa !8
  %17 = add i64 %.neg, 1
  %18 = add i64 %17, %11
  br label %19

; Loop:
19:                                               ; preds = %23, %15
  %20 = phi i32 [ %31, %23 ], [ %8, %15 ]
  %21 = phi i64 [ %32, %23 ], [ %18, %15 ]
  %22 = icmp sgt i64 %21, 0
  br i1 %22, label %23, label %.loopexit

23:                                               ; preds = %19
  %24 = load i32, ptr %5, align 4, !tbaa !4
  %25 = sitofp i32 %24 to float
  %26 = fdiv contract float 1.000000e+00, %25
  %27 = fpext float %26 to double
  %28 = sext i32 %20 to i64
  %29 = add nsw i64 %28, -1
  %30 = getelementptr double, ptr %16, i64 %29
  store double %27, ptr %30, align 8, !tbaa !4
  store double %27, ptr %7, align 8, !tbaa !4
  %31 = add i32 %20, 1
  %32 = add nsw i64 %21, -1
  br label %19

; Exit blocks
.loopexit:                                        ; preds = %19
  br label %52
*** IR Dump After LoopSimplifyCFGPass on <unnamed loop> ***

; Preheader:
15:                                               ; preds = %4
  %16 = load ptr, ptr %2, align 8, !tbaa !8
  %17 = add i64 %.neg, 1
  %18 = add i64 %17, %11
  br label %19

; Loop:
19:                                               ; preds = %23, %15
  %20 = phi i32 [ %31, %23 ], [ %8, %15 ]
  %21 = phi i64 [ %32, %23 ], [ %18, %15 ]
  %22 = icmp sgt i64 %21, 0
  br i1 %22, label %23, label %.loopexit

23:                                               ; preds = %19
  %24 = load i32, ptr %5, align 4, !tbaa !4
  %25 = sitofp i32 %24 to float
  %26 = fdiv contract float 1.000000e+00, %25
  %27 = fpext float %26 to double
  %28 = sext i32 %20 to i64
  %29 = add nsw i64 %28, -1
  %30 = getelementptr double, ptr %16, i64 %29
  store double %27, ptr %30, align 8, !tbaa !4
  store double %27, ptr %7, align 8, !tbaa !4
  %31 = add i32 %20, 1
  %32 = add nsw i64 %21, -1
  br label %19

; Exit blocks
.loopexit:                                        ; preds = %19
  br label %52
*** IR Dump After LICMPass on <unnamed loop> ***

; Preheader:
15:                                               ; preds = %4
  %16 = load ptr, ptr %2, align 8, !tbaa !8
  %17 = add i64 %.neg, 1
  %18 = add i64 %17, %11
  br label %19

; Loop:
19:                                               ; preds = %23, %15
  %20 = phi i32 [ %31, %23 ], [ %8, %15 ]
  %21 = phi i64 [ %32, %23 ], [ %18, %15 ]
  %22 = icmp sgt i64 %21, 0
  br i1 %22, label %23, label %.loopexit

23:                                               ; preds = %19
  %24 = load i32, ptr %5, align 4, !tbaa !4
  %25 = sitofp i32 %24 to float
  %26 = fdiv contract float 1.000000e+00, %25
  %27 = fpext float %26 to double
  %28 = sext i32 %20 to i64
  %29 = add nsw i64 %28, -1
  %30 = getelementptr double, ptr %16, i64 %29
  store double %27, ptr %30, align 8, !tbaa !4
  store double %27, ptr %7, align 8, !tbaa !4
  %31 = add i32 %20, 1
  %32 = add nsw i64 %21, -1
  br label %19

; Exit blocks
.loopexit:                                        ; preds = %19
  br label %52
*** IR Dump After LoopRotatePass on <unnamed loop> ***

; Preheader:
.lr.ph8:                                          ; preds = %15
  br label %20

; Loop:
20:                                               ; preds = %.lr.ph8, %20
  %21 = phi i64 [ %18, %.lr.ph8 ], [ %31, %20 ]
  %22 = phi i32 [ %8, %.lr.ph8 ], [ %30, %20 ]
  %23 = load i32, ptr %5, align 4, !tbaa !4
  %24 = sitofp i32 %23 to float
  %25 = fdiv contract float 1.000000e+00, %24
  %26 = fpext float %25 to double
  %27 = sext i32 %22 to i64
  %28 = add nsw i64 %27, -1
  %29 = getelementptr double, ptr %16, i64 %28
  store double %26, ptr %29, align 8, !tbaa !4
  store double %26, ptr %7, align 8, !tbaa !4
  %30 = add i32 %22, 1
  %31 = add nsw i64 %21, -1
  %32 = icmp sgt i64 %31, 0
  br i1 %32, label %20, label %..loopexit_crit_edge

; Exit blocks
..loopexit_crit_edge:                             ; preds = %20
  br label %.loopexit
*** IR Dump After LICMPass on <unnamed loop> ***

; Preheader:
.lr.ph8:                                          ; preds = %15
  br label %20

; Loop:
20:                                               ; preds = %.lr.ph8, %20
  %21 = phi i64 [ %18, %.lr.ph8 ], [ %31, %20 ]
  %22 = phi i32 [ %8, %.lr.ph8 ], [ %30, %20 ]
  %23 = load i32, ptr %5, align 4, !tbaa !4
  %24 = sitofp i32 %23 to float
  %25 = fdiv contract float 1.000000e+00, %24
  %26 = fpext float %25 to double
  %27 = sext i32 %22 to i64
  %28 = add nsw i64 %27, -1
  %29 = getelementptr double, ptr %16, i64 %28
  store double %26, ptr %29, align 8, !tbaa !4
  store double %26, ptr %7, align 8, !tbaa !4
  %30 = add i32 %22, 1
  %31 = add nsw i64 %21, -1
  %32 = icmp sgt i64 %31, 0
  br i1 %32, label %20, label %..loopexit_crit_edge

; Exit blocks
..loopexit_crit_edge:                             ; preds = %20
  br label %.loopexit
*** IR Dump After SimpleLoopUnswitchPass on <unnamed loop> ***

; Preheader:
.lr.ph8:                                          ; preds = %15
  br label %20

; Loop:
20:                                               ; preds = %.lr.ph8, %20
  %21 = phi i64 [ %18, %.lr.ph8 ], [ %31, %20 ]
  %22 = phi i32 [ %8, %.lr.ph8 ], [ %30, %20 ]
  %23 = load i32, ptr %5, align 4, !tbaa !4
  %24 = sitofp i32 %23 to float
  %25 = fdiv contract float 1.000000e+00, %24
  %26 = fpext float %25 to double
  %27 = sext i32 %22 to i64
  %28 = add nsw i64 %27, -1
  %29 = getelementptr double, ptr %16, i64 %28
  store double %26, ptr %29, align 8, !tbaa !4
  store double %26, ptr %7, align 8, !tbaa !4
  %30 = add i32 %22, 1
  %31 = add nsw i64 %21, -1
  %32 = icmp sgt i64 %31, 0
  br i1 %32, label %20, label %..loopexit_crit_edge

; Exit blocks
..loopexit_crit_edge:                             ; preds = %20
  br label %.loopexit
*** IR Dump After SimplifyCFGPass on _QFPloop ***
define void @_QFPloop(ptr %0, ptr %1, ptr %2, ptr nest %3) local_unnamed_addr {
  %5 = load ptr, ptr %3, align 8, !tbaa !4
  %6 = getelementptr { ptr, ptr }, ptr %3, i64 0, i32 1
  %7 = load ptr, ptr %6, align 8, !tbaa !4
  %8 = load i32, ptr %0, align 4, !tbaa !4
  %9 = sext i32 %8 to i64
  %.neg = sub i64 0, %9
  %10 = load i32, ptr %1, align 4, !tbaa !4
  %11 = sext i32 %10 to i64
  %12 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %2, i64 0, i32 7, i64 0, i64 2
  %13 = load i64, ptr %12, align 8, !tbaa !8
  %14 = icmp eq i64 %13, 8
  br i1 %14, label %15, label %32

15:                                               ; preds = %4
  %16 = load ptr, ptr %2, align 8, !tbaa !8
  %17 = add i64 %.neg, 1
  %18 = add i64 %17, %11
  %19 = icmp sgt i64 %18, 0
  br i1 %19, label %.lr.ph8, label %.loopexit

.lr.ph8:                                          ; preds = %15, %.lr.ph8
  %20 = phi i64 [ %30, %.lr.ph8 ], [ %18, %15 ]
  %21 = phi i32 [ %29, %.lr.ph8 ], [ %8, %15 ]
  %22 = load i32, ptr %5, align 4, !tbaa !4
  %23 = sitofp i32 %22 to float
  %24 = fdiv contract float 1.000000e+00, %23
  %25 = fpext float %24 to double
  %26 = sext i32 %21 to i64
  %27 = add nsw i64 %26, -1
  %28 = getelementptr double, ptr %16, i64 %27
  store double %25, ptr %28, align 8, !tbaa !4
  store double %25, ptr %7, align 8, !tbaa !4
  %29 = add i32 %21, 1
  %30 = add nsw i64 %20, -1
  %31 = icmp sgt i64 %30, 0
  br i1 %31, label %.lr.ph8, label %.loopexit

32:                                               ; preds = %4
  %33 = add i64 %.neg, 1
  %34 = add i64 %33, %11
  %35 = icmp sgt i64 %34, 0
  br i1 %35, label %.lr.ph, label %.loopexit

.lr.ph:                                           ; preds = %32
  %36 = load ptr, ptr %2, align 8, !tbaa !8
  br label %37

37:                                               ; preds = %.lr.ph, %37
  %38 = phi i64 [ %34, %.lr.ph ], [ %49, %37 ]
  %39 = phi i32 [ %8, %.lr.ph ], [ %48, %37 ]
  %40 = load i32, ptr %5, align 4, !tbaa !4
  %41 = sitofp i32 %40 to float
  %42 = fdiv contract float 1.000000e+00, %41
  %43 = fpext float %42 to double
  %44 = sext i32 %39 to i64
  %45 = add nsw i64 %44, -1
  %46 = mul i64 %45, %13
  %47 = getelementptr i8, ptr %36, i64 %46
  store double %43, ptr %47, align 8, !tbaa !4
  store double %43, ptr %7, align 8, !tbaa !4
  %48 = add i32 %39, 1
  %49 = add nsw i64 %38, -1
  %50 = icmp sgt i64 %49, 0
  br i1 %50, label %37, label %.loopexit

.loopexit:                                        ; preds = %32, %37, %15, %.lr.ph8
  ret void
}
*** IR Dump After InstCombinePass on _QFPloop ***
define void @_QFPloop(ptr %0, ptr %1, ptr %2, ptr nest %3) local_unnamed_addr {
  %5 = load ptr, ptr %3, align 8, !tbaa !4
  %6 = getelementptr { ptr, ptr }, ptr %3, i64 0, i32 1
  %7 = load ptr, ptr %6, align 8, !tbaa !4
  %8 = load i32, ptr %0, align 4, !tbaa !4
  %9 = sext i32 %8 to i64
  %10 = load i32, ptr %1, align 4, !tbaa !4
  %11 = sext i32 %10 to i64
  %12 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %2, i64 0, i32 7, i64 0, i64 2
  %13 = load i64, ptr %12, align 8, !tbaa !8
  %14 = icmp eq i64 %13, 8
  br i1 %14, label %15, label %31

15:                                               ; preds = %4
  %16 = load ptr, ptr %2, align 8, !tbaa !8
  %reass.sub9 = sub nsw i64 %11, %9
  %17 = add nsw i64 %reass.sub9, 1
  %18 = icmp sgt i64 %reass.sub9, -1
  br i1 %18, label %.lr.ph8, label %.loopexit

.lr.ph8:                                          ; preds = %15, %.lr.ph8
  %19 = phi i64 [ %29, %.lr.ph8 ], [ %17, %15 ]
  %20 = phi i32 [ %28, %.lr.ph8 ], [ %8, %15 ]
  %21 = load i32, ptr %5, align 4, !tbaa !4
  %22 = sitofp i32 %21 to float
  %23 = fdiv contract float 1.000000e+00, %22
  %24 = fpext float %23 to double
  %25 = sext i32 %20 to i64
  %26 = add nsw i64 %25, -1
  %27 = getelementptr double, ptr %16, i64 %26
  store double %24, ptr %27, align 8, !tbaa !4
  store double %24, ptr %7, align 8, !tbaa !4
  %28 = add i32 %20, 1
  %29 = add nsw i64 %19, -1
  %30 = icmp sgt i64 %19, 1
  br i1 %30, label %.lr.ph8, label %.loopexit

31:                                               ; preds = %4
  %reass.sub = sub nsw i64 %11, %9
  %32 = icmp sgt i64 %reass.sub, -1
  br i1 %32, label %.lr.ph, label %.loopexit

.lr.ph:                                           ; preds = %31
  %33 = add nsw i64 %reass.sub, 1
  %34 = load ptr, ptr %2, align 8, !tbaa !8
  br label %35

35:                                               ; preds = %.lr.ph, %35
  %36 = phi i64 [ %33, %.lr.ph ], [ %47, %35 ]
  %37 = phi i32 [ %8, %.lr.ph ], [ %46, %35 ]
  %38 = load i32, ptr %5, align 4, !tbaa !4
  %39 = sitofp i32 %38 to float
  %40 = fdiv contract float 1.000000e+00, %39
  %41 = fpext float %40 to double
  %42 = sext i32 %37 to i64
  %43 = add nsw i64 %42, -1
  %44 = mul i64 %43, %13
  %45 = getelementptr i8, ptr %34, i64 %44
  store double %41, ptr %45, align 8, !tbaa !4
  store double %41, ptr %7, align 8, !tbaa !4
  %46 = add i32 %37, 1
  %47 = add nsw i64 %36, -1
  %48 = icmp sgt i64 %36, 1
  br i1 %48, label %35, label %.loopexit

.loopexit:                                        ; preds = %31, %35, %15, %.lr.ph8
  ret void
}
*** IR Dump After LoopSimplifyPass on _QFPloop ***
define void @_QFPloop(ptr %0, ptr %1, ptr %2, ptr nest %3) local_unnamed_addr {
  %5 = load ptr, ptr %3, align 8, !tbaa !4
  %6 = getelementptr { ptr, ptr }, ptr %3, i64 0, i32 1
  %7 = load ptr, ptr %6, align 8, !tbaa !4
  %8 = load i32, ptr %0, align 4, !tbaa !4
  %9 = sext i32 %8 to i64
  %10 = load i32, ptr %1, align 4, !tbaa !4
  %11 = sext i32 %10 to i64
  %12 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %2, i64 0, i32 7, i64 0, i64 2
  %13 = load i64, ptr %12, align 8, !tbaa !8
  %14 = icmp eq i64 %13, 8
  br i1 %14, label %15, label %31

15:                                               ; preds = %4
  %16 = load ptr, ptr %2, align 8, !tbaa !8
  %reass.sub9 = sub nsw i64 %11, %9
  %17 = add nsw i64 %reass.sub9, 1
  %18 = icmp sgt i64 %reass.sub9, -1
  br i1 %18, label %.lr.ph8.preheader, label %.loopexit

.lr.ph8.preheader:                                ; preds = %15
  br label %.lr.ph8

.lr.ph8:                                          ; preds = %.lr.ph8.preheader, %.lr.ph8
  %19 = phi i64 [ %29, %.lr.ph8 ], [ %17, %.lr.ph8.preheader ]
  %20 = phi i32 [ %28, %.lr.ph8 ], [ %8, %.lr.ph8.preheader ]
  %21 = load i32, ptr %5, align 4, !tbaa !4
  %22 = sitofp i32 %21 to float
  %23 = fdiv contract float 1.000000e+00, %22
  %24 = fpext float %23 to double
  %25 = sext i32 %20 to i64
  %26 = add nsw i64 %25, -1
  %27 = getelementptr double, ptr %16, i64 %26
  store double %24, ptr %27, align 8, !tbaa !4
  store double %24, ptr %7, align 8, !tbaa !4
  %28 = add i32 %20, 1
  %29 = add nsw i64 %19, -1
  %30 = icmp sgt i64 %19, 1
  br i1 %30, label %.lr.ph8, label %.loopexit.loopexit

31:                                               ; preds = %4
  %reass.sub = sub nsw i64 %11, %9
  %32 = icmp sgt i64 %reass.sub, -1
  br i1 %32, label %.lr.ph, label %.loopexit

.lr.ph:                                           ; preds = %31
  %33 = add nsw i64 %reass.sub, 1
  %34 = load ptr, ptr %2, align 8, !tbaa !8
  br label %35

35:                                               ; preds = %.lr.ph, %35
  %36 = phi i64 [ %33, %.lr.ph ], [ %47, %35 ]
  %37 = phi i32 [ %8, %.lr.ph ], [ %46, %35 ]
  %38 = load i32, ptr %5, align 4, !tbaa !4
  %39 = sitofp i32 %38 to float
  %40 = fdiv contract float 1.000000e+00, %39
  %41 = fpext float %40 to double
  %42 = sext i32 %37 to i64
  %43 = add nsw i64 %42, -1
  %44 = mul i64 %43, %13
  %45 = getelementptr i8, ptr %34, i64 %44
  store double %41, ptr %45, align 8, !tbaa !4
  store double %41, ptr %7, align 8, !tbaa !4
  %46 = add i32 %37, 1
  %47 = add nsw i64 %36, -1
  %48 = icmp sgt i64 %36, 1
  br i1 %48, label %35, label %.loopexit.loopexit10

.loopexit.loopexit:                               ; preds = %.lr.ph8
  br label %.loopexit

.loopexit.loopexit10:                             ; preds = %35
  br label %.loopexit

.loopexit:                                        ; preds = %.loopexit.loopexit10, %.loopexit.loopexit, %31, %15
  ret void
}
*** IR Dump After LCSSAPass on _QFPloop ***
define void @_QFPloop(ptr %0, ptr %1, ptr %2, ptr nest %3) local_unnamed_addr {
  %5 = load ptr, ptr %3, align 8, !tbaa !4
  %6 = getelementptr { ptr, ptr }, ptr %3, i64 0, i32 1
  %7 = load ptr, ptr %6, align 8, !tbaa !4
  %8 = load i32, ptr %0, align 4, !tbaa !4
  %9 = sext i32 %8 to i64
  %10 = load i32, ptr %1, align 4, !tbaa !4
  %11 = sext i32 %10 to i64
  %12 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %2, i64 0, i32 7, i64 0, i64 2
  %13 = load i64, ptr %12, align 8, !tbaa !8
  %14 = icmp eq i64 %13, 8
  br i1 %14, label %15, label %31

15:                                               ; preds = %4
  %16 = load ptr, ptr %2, align 8, !tbaa !8
  %reass.sub9 = sub nsw i64 %11, %9
  %17 = add nsw i64 %reass.sub9, 1
  %18 = icmp sgt i64 %reass.sub9, -1
  br i1 %18, label %.lr.ph8.preheader, label %.loopexit

.lr.ph8.preheader:                                ; preds = %15
  br label %.lr.ph8

.lr.ph8:                                          ; preds = %.lr.ph8.preheader, %.lr.ph8
  %19 = phi i64 [ %29, %.lr.ph8 ], [ %17, %.lr.ph8.preheader ]
  %20 = phi i32 [ %28, %.lr.ph8 ], [ %8, %.lr.ph8.preheader ]
  %21 = load i32, ptr %5, align 4, !tbaa !4
  %22 = sitofp i32 %21 to float
  %23 = fdiv contract float 1.000000e+00, %22
  %24 = fpext float %23 to double
  %25 = sext i32 %20 to i64
  %26 = add nsw i64 %25, -1
  %27 = getelementptr double, ptr %16, i64 %26
  store double %24, ptr %27, align 8, !tbaa !4
  store double %24, ptr %7, align 8, !tbaa !4
  %28 = add i32 %20, 1
  %29 = add nsw i64 %19, -1
  %30 = icmp sgt i64 %19, 1
  br i1 %30, label %.lr.ph8, label %.loopexit.loopexit

31:                                               ; preds = %4
  %reass.sub = sub nsw i64 %11, %9
  %32 = icmp sgt i64 %reass.sub, -1
  br i1 %32, label %.lr.ph, label %.loopexit

.lr.ph:                                           ; preds = %31
  %33 = add nsw i64 %reass.sub, 1
  %34 = load ptr, ptr %2, align 8, !tbaa !8
  br label %35

35:                                               ; preds = %.lr.ph, %35
  %36 = phi i64 [ %33, %.lr.ph ], [ %47, %35 ]
  %37 = phi i32 [ %8, %.lr.ph ], [ %46, %35 ]
  %38 = load i32, ptr %5, align 4, !tbaa !4
  %39 = sitofp i32 %38 to float
  %40 = fdiv contract float 1.000000e+00, %39
  %41 = fpext float %40 to double
  %42 = sext i32 %37 to i64
  %43 = add nsw i64 %42, -1
  %44 = mul i64 %43, %13
  %45 = getelementptr i8, ptr %34, i64 %44
  store double %41, ptr %45, align 8, !tbaa !4
  store double %41, ptr %7, align 8, !tbaa !4
  %46 = add i32 %37, 1
  %47 = add nsw i64 %36, -1
  %48 = icmp sgt i64 %36, 1
  br i1 %48, label %35, label %.loopexit.loopexit10

.loopexit.loopexit:                               ; preds = %.lr.ph8
  br label %.loopexit

.loopexit.loopexit10:                             ; preds = %35
  br label %.loopexit

.loopexit:                                        ; preds = %.loopexit.loopexit10, %.loopexit.loopexit, %31, %15
  ret void
}
*** IR Dump After LoopIdiomRecognizePass on <unnamed loop> ***

; Preheader:
.lr.ph:                                           ; preds = %31
  %33 = add nsw i64 %reass.sub, 1
  %34 = load ptr, ptr %2, align 8, !tbaa !8
  br label %35

; Loop:
35:                                               ; preds = %.lr.ph, %35
  %36 = phi i64 [ %33, %.lr.ph ], [ %47, %35 ]
  %37 = phi i32 [ %8, %.lr.ph ], [ %46, %35 ]
  %38 = load i32, ptr %5, align 4, !tbaa !4
  %39 = sitofp i32 %38 to float
  %40 = fdiv contract float 1.000000e+00, %39
  %41 = fpext float %40 to double
  %42 = sext i32 %37 to i64
  %43 = add nsw i64 %42, -1
  %44 = mul i64 %43, %13
  %45 = getelementptr i8, ptr %34, i64 %44
  store double %41, ptr %45, align 8, !tbaa !4
  store double %41, ptr %7, align 8, !tbaa !4
  %46 = add i32 %37, 1
  %47 = add nsw i64 %36, -1
  %48 = icmp sgt i64 %36, 1
  br i1 %48, label %35, label %.loopexit.loopexit10

; Exit blocks
.loopexit.loopexit10:                             ; preds = %35
  br label %.loopexit
*** IR Dump After IndVarSimplifyPass on <unnamed loop> ***

; Preheader:
.lr.ph:                                           ; preds = %31
  %33 = add nsw i64 %reass.sub, 1
  %34 = load ptr, ptr %2, align 8, !tbaa !8
  br label %35

; Loop:
35:                                               ; preds = %.lr.ph, %35
  %36 = phi i64 [ %33, %.lr.ph ], [ %47, %35 ]
  %37 = phi i32 [ %8, %.lr.ph ], [ %46, %35 ]
  %38 = load i32, ptr %5, align 4, !tbaa !4
  %39 = sitofp i32 %38 to float
  %40 = fdiv contract float 1.000000e+00, %39
  %41 = fpext float %40 to double
  %42 = sext i32 %37 to i64
  %43 = add nsw i64 %42, -1
  %44 = mul i64 %43, %13
  %45 = getelementptr i8, ptr %34, i64 %44
  store double %41, ptr %45, align 8, !tbaa !4
  store double %41, ptr %7, align 8, !tbaa !4
  %46 = add i32 %37, 1
  %47 = add nsw i64 %36, -1
  %48 = icmp sgt i64 %36, 1
  br i1 %48, label %35, label %.loopexit.loopexit10

; Exit blocks
.loopexit.loopexit10:                             ; preds = %35
  br label %.loopexit
*** IR Dump After LoopDeletionPass on <unnamed loop> ***

; Preheader:
.lr.ph:                                           ; preds = %31
  %33 = add nsw i64 %reass.sub, 1
  %34 = load ptr, ptr %2, align 8, !tbaa !8
  br label %35

; Loop:
35:                                               ; preds = %.lr.ph, %35
  %36 = phi i64 [ %33, %.lr.ph ], [ %47, %35 ]
  %37 = phi i32 [ %8, %.lr.ph ], [ %46, %35 ]
  %38 = load i32, ptr %5, align 4, !tbaa !4
  %39 = sitofp i32 %38 to float
  %40 = fdiv contract float 1.000000e+00, %39
  %41 = fpext float %40 to double
  %42 = sext i32 %37 to i64
  %43 = add nsw i64 %42, -1
  %44 = mul i64 %43, %13
  %45 = getelementptr i8, ptr %34, i64 %44
  store double %41, ptr %45, align 8, !tbaa !4
  store double %41, ptr %7, align 8, !tbaa !4
  %46 = add i32 %37, 1
  %47 = add nsw i64 %36, -1
  %48 = icmp sgt i64 %36, 1
  br i1 %48, label %35, label %.loopexit.loopexit10

; Exit blocks
.loopexit.loopexit10:                             ; preds = %35
  br label %.loopexit
*** IR Dump After LoopFullUnrollPass on <unnamed loop> ***

; Preheader:
.lr.ph:                                           ; preds = %31
  %33 = add nsw i64 %reass.sub, 1
  %34 = load ptr, ptr %2, align 8, !tbaa !8
  br label %35

; Loop:
35:                                               ; preds = %.lr.ph, %35
  %36 = phi i64 [ %33, %.lr.ph ], [ %47, %35 ]
  %37 = phi i32 [ %8, %.lr.ph ], [ %46, %35 ]
  %38 = load i32, ptr %5, align 4, !tbaa !4
  %39 = sitofp i32 %38 to float
  %40 = fdiv contract float 1.000000e+00, %39
  %41 = fpext float %40 to double
  %42 = sext i32 %37 to i64
  %43 = add nsw i64 %42, -1
  %44 = mul i64 %43, %13
  %45 = getelementptr i8, ptr %34, i64 %44
  store double %41, ptr %45, align 8, !tbaa !4
  store double %41, ptr %7, align 8, !tbaa !4
  %46 = add i32 %37, 1
  %47 = add nsw i64 %36, -1
  %48 = icmp sgt i64 %36, 1
  br i1 %48, label %35, label %.loopexit.loopexit10

; Exit blocks
.loopexit.loopexit10:                             ; preds = %35
  br label %.loopexit
*** IR Dump After LoopIdiomRecognizePass on .lr.ph8 ***

; Preheader:
.lr.ph8.preheader:                                ; preds = %15
  br label %.lr.ph8

; Loop:
.lr.ph8:                                          ; preds = %.lr.ph8.preheader, %.lr.ph8
  %19 = phi i64 [ %29, %.lr.ph8 ], [ %17, %.lr.ph8.preheader ]
  %20 = phi i32 [ %28, %.lr.ph8 ], [ %8, %.lr.ph8.preheader ]
  %21 = load i32, ptr %5, align 4, !tbaa !4
  %22 = sitofp i32 %21 to float
  %23 = fdiv contract float 1.000000e+00, %22
  %24 = fpext float %23 to double
  %25 = sext i32 %20 to i64
  %26 = add nsw i64 %25, -1
  %27 = getelementptr double, ptr %16, i64 %26
  store double %24, ptr %27, align 8, !tbaa !4
  store double %24, ptr %7, align 8, !tbaa !4
  %28 = add i32 %20, 1
  %29 = add nsw i64 %19, -1
  %30 = icmp sgt i64 %19, 1
  br i1 %30, label %.lr.ph8, label %.loopexit.loopexit

; Exit blocks
.loopexit.loopexit:                               ; preds = %.lr.ph8
  br label %.loopexit
*** IR Dump After IndVarSimplifyPass on .lr.ph8 ***

; Preheader:
.lr.ph8.preheader:                                ; preds = %15
  br label %.lr.ph8

; Loop:
.lr.ph8:                                          ; preds = %.lr.ph8.preheader, %.lr.ph8
  %19 = phi i64 [ %29, %.lr.ph8 ], [ %17, %.lr.ph8.preheader ]
  %20 = phi i32 [ %28, %.lr.ph8 ], [ %8, %.lr.ph8.preheader ]
  %21 = load i32, ptr %5, align 4, !tbaa !4
  %22 = sitofp i32 %21 to float
  %23 = fdiv contract float 1.000000e+00, %22
  %24 = fpext float %23 to double
  %25 = sext i32 %20 to i64
  %26 = add nsw i64 %25, -1
  %27 = getelementptr double, ptr %16, i64 %26
  store double %24, ptr %27, align 8, !tbaa !4
  store double %24, ptr %7, align 8, !tbaa !4
  %28 = add i32 %20, 1
  %29 = add nsw i64 %19, -1
  %30 = icmp sgt i64 %19, 1
  br i1 %30, label %.lr.ph8, label %.loopexit.loopexit

; Exit blocks
.loopexit.loopexit:                               ; preds = %.lr.ph8
  br label %.loopexit
*** IR Dump After LoopDeletionPass on .lr.ph8 ***

; Preheader:
.lr.ph8.preheader:                                ; preds = %15
  br label %.lr.ph8

; Loop:
.lr.ph8:                                          ; preds = %.lr.ph8.preheader, %.lr.ph8
  %19 = phi i64 [ %29, %.lr.ph8 ], [ %17, %.lr.ph8.preheader ]
  %20 = phi i32 [ %28, %.lr.ph8 ], [ %8, %.lr.ph8.preheader ]
  %21 = load i32, ptr %5, align 4, !tbaa !4
  %22 = sitofp i32 %21 to float
  %23 = fdiv contract float 1.000000e+00, %22
  %24 = fpext float %23 to double
  %25 = sext i32 %20 to i64
  %26 = add nsw i64 %25, -1
  %27 = getelementptr double, ptr %16, i64 %26
  store double %24, ptr %27, align 8, !tbaa !4
  store double %24, ptr %7, align 8, !tbaa !4
  %28 = add i32 %20, 1
  %29 = add nsw i64 %19, -1
  %30 = icmp sgt i64 %19, 1
  br i1 %30, label %.lr.ph8, label %.loopexit.loopexit

; Exit blocks
.loopexit.loopexit:                               ; preds = %.lr.ph8
  br label %.loopexit
*** IR Dump After LoopFullUnrollPass on .lr.ph8 ***

; Preheader:
.lr.ph8.preheader:                                ; preds = %15
  br label %.lr.ph8

; Loop:
.lr.ph8:                                          ; preds = %.lr.ph8.preheader, %.lr.ph8
  %19 = phi i64 [ %29, %.lr.ph8 ], [ %17, %.lr.ph8.preheader ]
  %20 = phi i32 [ %28, %.lr.ph8 ], [ %8, %.lr.ph8.preheader ]
  %21 = load i32, ptr %5, align 4, !tbaa !4
  %22 = sitofp i32 %21 to float
  %23 = fdiv contract float 1.000000e+00, %22
  %24 = fpext float %23 to double
  %25 = sext i32 %20 to i64
  %26 = add nsw i64 %25, -1
  %27 = getelementptr double, ptr %16, i64 %26
  store double %24, ptr %27, align 8, !tbaa !4
  store double %24, ptr %7, align 8, !tbaa !4
  %28 = add i32 %20, 1
  %29 = add nsw i64 %19, -1
  %30 = icmp sgt i64 %19, 1
  br i1 %30, label %.lr.ph8, label %.loopexit.loopexit

; Exit blocks
.loopexit.loopexit:                               ; preds = %.lr.ph8
  br label %.loopexit
*** IR Dump After SROAPass on _QFPloop ***
define void @_QFPloop(ptr %0, ptr %1, ptr %2, ptr nest %3) local_unnamed_addr {
  %5 = load ptr, ptr %3, align 8, !tbaa !4
  %6 = getelementptr { ptr, ptr }, ptr %3, i64 0, i32 1
  %7 = load ptr, ptr %6, align 8, !tbaa !4
  %8 = load i32, ptr %0, align 4, !tbaa !4
  %9 = sext i32 %8 to i64
  %10 = load i32, ptr %1, align 4, !tbaa !4
  %11 = sext i32 %10 to i64
  %12 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %2, i64 0, i32 7, i64 0, i64 2
  %13 = load i64, ptr %12, align 8, !tbaa !8
  %14 = icmp eq i64 %13, 8
  br i1 %14, label %15, label %31

15:                                               ; preds = %4
  %16 = load ptr, ptr %2, align 8, !tbaa !8
  %reass.sub9 = sub nsw i64 %11, %9
  %17 = add nsw i64 %reass.sub9, 1
  %18 = icmp sgt i64 %reass.sub9, -1
  br i1 %18, label %.lr.ph8.preheader, label %.loopexit

.lr.ph8.preheader:                                ; preds = %15
  br label %.lr.ph8

.lr.ph8:                                          ; preds = %.lr.ph8.preheader, %.lr.ph8
  %19 = phi i64 [ %29, %.lr.ph8 ], [ %17, %.lr.ph8.preheader ]
  %20 = phi i32 [ %28, %.lr.ph8 ], [ %8, %.lr.ph8.preheader ]
  %21 = load i32, ptr %5, align 4, !tbaa !4
  %22 = sitofp i32 %21 to float
  %23 = fdiv contract float 1.000000e+00, %22
  %24 = fpext float %23 to double
  %25 = sext i32 %20 to i64
  %26 = add nsw i64 %25, -1
  %27 = getelementptr double, ptr %16, i64 %26
  store double %24, ptr %27, align 8, !tbaa !4
  store double %24, ptr %7, align 8, !tbaa !4
  %28 = add i32 %20, 1
  %29 = add nsw i64 %19, -1
  %30 = icmp sgt i64 %19, 1
  br i1 %30, label %.lr.ph8, label %.loopexit.loopexit

31:                                               ; preds = %4
  %reass.sub = sub nsw i64 %11, %9
  %32 = icmp sgt i64 %reass.sub, -1
  br i1 %32, label %.lr.ph, label %.loopexit

.lr.ph:                                           ; preds = %31
  %33 = add nsw i64 %reass.sub, 1
  %34 = load ptr, ptr %2, align 8, !tbaa !8
  br label %35

35:                                               ; preds = %.lr.ph, %35
  %36 = phi i64 [ %33, %.lr.ph ], [ %47, %35 ]
  %37 = phi i32 [ %8, %.lr.ph ], [ %46, %35 ]
  %38 = load i32, ptr %5, align 4, !tbaa !4
  %39 = sitofp i32 %38 to float
  %40 = fdiv contract float 1.000000e+00, %39
  %41 = fpext float %40 to double
  %42 = sext i32 %37 to i64
  %43 = add nsw i64 %42, -1
  %44 = mul i64 %43, %13
  %45 = getelementptr i8, ptr %34, i64 %44
  store double %41, ptr %45, align 8, !tbaa !4
  store double %41, ptr %7, align 8, !tbaa !4
  %46 = add i32 %37, 1
  %47 = add nsw i64 %36, -1
  %48 = icmp sgt i64 %36, 1
  br i1 %48, label %35, label %.loopexit.loopexit10

.loopexit.loopexit:                               ; preds = %.lr.ph8
  br label %.loopexit

.loopexit.loopexit10:                             ; preds = %35
  br label %.loopexit

.loopexit:                                        ; preds = %.loopexit.loopexit10, %.loopexit.loopexit, %31, %15
  ret void
}
*** IR Dump After VectorCombinePass on _QFPloop ***
define void @_QFPloop(ptr %0, ptr %1, ptr %2, ptr nest %3) local_unnamed_addr {
  %5 = load ptr, ptr %3, align 8, !tbaa !4
  %6 = getelementptr { ptr, ptr }, ptr %3, i64 0, i32 1
  %7 = load ptr, ptr %6, align 8, !tbaa !4
  %8 = load i32, ptr %0, align 4, !tbaa !4
  %9 = sext i32 %8 to i64
  %10 = load i32, ptr %1, align 4, !tbaa !4
  %11 = sext i32 %10 to i64
  %12 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %2, i64 0, i32 7, i64 0, i64 2
  %13 = load i64, ptr %12, align 8, !tbaa !8
  %14 = icmp eq i64 %13, 8
  br i1 %14, label %15, label %31

15:                                               ; preds = %4
  %16 = load ptr, ptr %2, align 8, !tbaa !8
  %reass.sub9 = sub nsw i64 %11, %9
  %17 = add nsw i64 %reass.sub9, 1
  %18 = icmp sgt i64 %reass.sub9, -1
  br i1 %18, label %.lr.ph8.preheader, label %.loopexit

.lr.ph8.preheader:                                ; preds = %15
  br label %.lr.ph8

.lr.ph8:                                          ; preds = %.lr.ph8.preheader, %.lr.ph8
  %19 = phi i64 [ %29, %.lr.ph8 ], [ %17, %.lr.ph8.preheader ]
  %20 = phi i32 [ %28, %.lr.ph8 ], [ %8, %.lr.ph8.preheader ]
  %21 = load i32, ptr %5, align 4, !tbaa !4
  %22 = sitofp i32 %21 to float
  %23 = fdiv contract float 1.000000e+00, %22
  %24 = fpext float %23 to double
  %25 = sext i32 %20 to i64
  %26 = add nsw i64 %25, -1
  %27 = getelementptr double, ptr %16, i64 %26
  store double %24, ptr %27, align 8, !tbaa !4
  store double %24, ptr %7, align 8, !tbaa !4
  %28 = add i32 %20, 1
  %29 = add nsw i64 %19, -1
  %30 = icmp sgt i64 %19, 1
  br i1 %30, label %.lr.ph8, label %.loopexit.loopexit

31:                                               ; preds = %4
  %reass.sub = sub nsw i64 %11, %9
  %32 = icmp sgt i64 %reass.sub, -1
  br i1 %32, label %.lr.ph, label %.loopexit

.lr.ph:                                           ; preds = %31
  %33 = add nsw i64 %reass.sub, 1
  %34 = load ptr, ptr %2, align 8, !tbaa !8
  br label %35

35:                                               ; preds = %.lr.ph, %35
  %36 = phi i64 [ %33, %.lr.ph ], [ %47, %35 ]
  %37 = phi i32 [ %8, %.lr.ph ], [ %46, %35 ]
  %38 = load i32, ptr %5, align 4, !tbaa !4
  %39 = sitofp i32 %38 to float
  %40 = fdiv contract float 1.000000e+00, %39
  %41 = fpext float %40 to double
  %42 = sext i32 %37 to i64
  %43 = add nsw i64 %42, -1
  %44 = mul i64 %43, %13
  %45 = getelementptr i8, ptr %34, i64 %44
  store double %41, ptr %45, align 8, !tbaa !4
  store double %41, ptr %7, align 8, !tbaa !4
  %46 = add i32 %37, 1
  %47 = add nsw i64 %36, -1
  %48 = icmp sgt i64 %36, 1
  br i1 %48, label %35, label %.loopexit.loopexit10

.loopexit.loopexit:                               ; preds = %.lr.ph8
  br label %.loopexit

.loopexit.loopexit10:                             ; preds = %35
  br label %.loopexit

.loopexit:                                        ; preds = %.loopexit.loopexit10, %.loopexit.loopexit, %31, %15
  ret void
}
*** IR Dump After MergedLoadStoreMotionPass on _QFPloop ***
define void @_QFPloop(ptr %0, ptr %1, ptr %2, ptr nest %3) local_unnamed_addr {
  %5 = load ptr, ptr %3, align 8, !tbaa !4
  %6 = getelementptr { ptr, ptr }, ptr %3, i64 0, i32 1
  %7 = load ptr, ptr %6, align 8, !tbaa !4
  %8 = load i32, ptr %0, align 4, !tbaa !4
  %9 = sext i32 %8 to i64
  %10 = load i32, ptr %1, align 4, !tbaa !4
  %11 = sext i32 %10 to i64
  %12 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %2, i64 0, i32 7, i64 0, i64 2
  %13 = load i64, ptr %12, align 8, !tbaa !8
  %14 = icmp eq i64 %13, 8
  br i1 %14, label %15, label %31

15:                                               ; preds = %4
  %16 = load ptr, ptr %2, align 8, !tbaa !8
  %reass.sub9 = sub nsw i64 %11, %9
  %17 = add nsw i64 %reass.sub9, 1
  %18 = icmp sgt i64 %reass.sub9, -1
  br i1 %18, label %.lr.ph8.preheader, label %.loopexit

.lr.ph8.preheader:                                ; preds = %15
  br label %.lr.ph8

.lr.ph8:                                          ; preds = %.lr.ph8.preheader, %.lr.ph8
  %19 = phi i64 [ %29, %.lr.ph8 ], [ %17, %.lr.ph8.preheader ]
  %20 = phi i32 [ %28, %.lr.ph8 ], [ %8, %.lr.ph8.preheader ]
  %21 = load i32, ptr %5, align 4, !tbaa !4
  %22 = sitofp i32 %21 to float
  %23 = fdiv contract float 1.000000e+00, %22
  %24 = fpext float %23 to double
  %25 = sext i32 %20 to i64
  %26 = add nsw i64 %25, -1
  %27 = getelementptr double, ptr %16, i64 %26
  store double %24, ptr %27, align 8, !tbaa !4
  store double %24, ptr %7, align 8, !tbaa !4
  %28 = add i32 %20, 1
  %29 = add nsw i64 %19, -1
  %30 = icmp sgt i64 %19, 1
  br i1 %30, label %.lr.ph8, label %.loopexit.loopexit

31:                                               ; preds = %4
  %reass.sub = sub nsw i64 %11, %9
  %32 = icmp sgt i64 %reass.sub, -1
  br i1 %32, label %.lr.ph, label %.loopexit

.lr.ph:                                           ; preds = %31
  %33 = add nsw i64 %reass.sub, 1
  %34 = load ptr, ptr %2, align 8, !tbaa !8
  br label %35

35:                                               ; preds = %.lr.ph, %35
  %36 = phi i64 [ %33, %.lr.ph ], [ %47, %35 ]
  %37 = phi i32 [ %8, %.lr.ph ], [ %46, %35 ]
  %38 = load i32, ptr %5, align 4, !tbaa !4
  %39 = sitofp i32 %38 to float
  %40 = fdiv contract float 1.000000e+00, %39
  %41 = fpext float %40 to double
  %42 = sext i32 %37 to i64
  %43 = add nsw i64 %42, -1
  %44 = mul i64 %43, %13
  %45 = getelementptr i8, ptr %34, i64 %44
  store double %41, ptr %45, align 8, !tbaa !4
  store double %41, ptr %7, align 8, !tbaa !4
  %46 = add i32 %37, 1
  %47 = add nsw i64 %36, -1
  %48 = icmp sgt i64 %36, 1
  br i1 %48, label %35, label %.loopexit.loopexit10

.loopexit.loopexit:                               ; preds = %.lr.ph8
  br label %.loopexit

.loopexit.loopexit10:                             ; preds = %35
  br label %.loopexit

.loopexit:                                        ; preds = %.loopexit.loopexit10, %.loopexit.loopexit, %31, %15
  ret void
}
*** IR Dump After GVNPass on _QFPloop ***
define void @_QFPloop(ptr %0, ptr %1, ptr %2, ptr nest %3) local_unnamed_addr {
  %5 = load ptr, ptr %3, align 8, !tbaa !4
  %6 = getelementptr { ptr, ptr }, ptr %3, i64 0, i32 1
  %7 = load ptr, ptr %6, align 8, !tbaa !4
  %8 = load i32, ptr %0, align 4, !tbaa !4
  %9 = sext i32 %8 to i64
  %10 = load i32, ptr %1, align 4, !tbaa !4
  %11 = sext i32 %10 to i64
  %12 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %2, i64 0, i32 7, i64 0, i64 2
  %13 = load i64, ptr %12, align 8, !tbaa !8
  %14 = icmp eq i64 %13, 8
  br i1 %14, label %15, label %31

15:                                               ; preds = %4
  %16 = load ptr, ptr %2, align 8, !tbaa !8
  %reass.sub9 = sub nsw i64 %11, %9
  %17 = add nsw i64 %reass.sub9, 1
  %18 = icmp sgt i64 %reass.sub9, -1
  br i1 %18, label %.lr.ph8.preheader, label %.loopexit

.lr.ph8.preheader:                                ; preds = %15
  br label %.lr.ph8

.lr.ph8:                                          ; preds = %.lr.ph8.preheader, %.lr.ph8
  %19 = phi i64 [ %29, %.lr.ph8 ], [ %17, %.lr.ph8.preheader ]
  %20 = phi i32 [ %28, %.lr.ph8 ], [ %8, %.lr.ph8.preheader ]
  %21 = load i32, ptr %5, align 4, !tbaa !4
  %22 = sitofp i32 %21 to float
  %23 = fdiv contract float 1.000000e+00, %22
  %24 = fpext float %23 to double
  %25 = sext i32 %20 to i64
  %26 = add nsw i64 %25, -1
  %27 = getelementptr double, ptr %16, i64 %26
  store double %24, ptr %27, align 8, !tbaa !4
  store double %24, ptr %7, align 8, !tbaa !4
  %28 = add i32 %20, 1
  %29 = add nsw i64 %19, -1
  %30 = icmp sgt i64 %19, 1
  br i1 %30, label %.lr.ph8, label %.loopexit.loopexit

31:                                               ; preds = %4
  %reass.sub = sub nsw i64 %11, %9
  %32 = icmp sgt i64 %reass.sub, -1
  br i1 %32, label %.lr.ph, label %.loopexit

.lr.ph:                                           ; preds = %31
  %33 = add nsw i64 %reass.sub, 1
  %34 = load ptr, ptr %2, align 8, !tbaa !8
  br label %35

35:                                               ; preds = %.lr.ph, %35
  %36 = phi i64 [ %33, %.lr.ph ], [ %47, %35 ]
  %37 = phi i32 [ %8, %.lr.ph ], [ %46, %35 ]
  %38 = load i32, ptr %5, align 4, !tbaa !4
  %39 = sitofp i32 %38 to float
  %40 = fdiv contract float 1.000000e+00, %39
  %41 = fpext float %40 to double
  %42 = sext i32 %37 to i64
  %43 = add nsw i64 %42, -1
  %44 = mul i64 %43, %13
  %45 = getelementptr i8, ptr %34, i64 %44
  store double %41, ptr %45, align 8, !tbaa !4
  store double %41, ptr %7, align 8, !tbaa !4
  %46 = add i32 %37, 1
  %47 = add nsw i64 %36, -1
  %48 = icmp sgt i64 %36, 1
  br i1 %48, label %35, label %.loopexit.loopexit10

.loopexit.loopexit:                               ; preds = %.lr.ph8
  br label %.loopexit

.loopexit.loopexit10:                             ; preds = %35
  br label %.loopexit

.loopexit:                                        ; preds = %.loopexit.loopexit10, %.loopexit.loopexit, %31, %15
  ret void
}
*** IR Dump After SCCPPass on _QFPloop ***
define void @_QFPloop(ptr %0, ptr %1, ptr %2, ptr nest %3) local_unnamed_addr {
  %5 = load ptr, ptr %3, align 8, !tbaa !4
  %6 = getelementptr { ptr, ptr }, ptr %3, i64 0, i32 1
  %7 = load ptr, ptr %6, align 8, !tbaa !4
  %8 = load i32, ptr %0, align 4, !tbaa !4
  %9 = sext i32 %8 to i64
  %10 = load i32, ptr %1, align 4, !tbaa !4
  %11 = sext i32 %10 to i64
  %12 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %2, i64 0, i32 7, i64 0, i64 2
  %13 = load i64, ptr %12, align 8, !tbaa !8
  %14 = icmp eq i64 %13, 8
  br i1 %14, label %15, label %31

15:                                               ; preds = %4
  %16 = load ptr, ptr %2, align 8, !tbaa !8
  %reass.sub9 = sub nsw i64 %11, %9
  %17 = add nsw i64 %reass.sub9, 1
  %18 = icmp sgt i64 %reass.sub9, -1
  br i1 %18, label %.lr.ph8.preheader, label %.loopexit

.lr.ph8.preheader:                                ; preds = %15
  br label %.lr.ph8

.lr.ph8:                                          ; preds = %.lr.ph8.preheader, %.lr.ph8
  %19 = phi i64 [ %29, %.lr.ph8 ], [ %17, %.lr.ph8.preheader ]
  %20 = phi i32 [ %28, %.lr.ph8 ], [ %8, %.lr.ph8.preheader ]
  %21 = load i32, ptr %5, align 4, !tbaa !4
  %22 = sitofp i32 %21 to float
  %23 = fdiv contract float 1.000000e+00, %22
  %24 = fpext float %23 to double
  %25 = sext i32 %20 to i64
  %26 = add nsw i64 %25, -1
  %27 = getelementptr double, ptr %16, i64 %26
  store double %24, ptr %27, align 8, !tbaa !4
  store double %24, ptr %7, align 8, !tbaa !4
  %28 = add i32 %20, 1
  %29 = add nsw i64 %19, -1
  %30 = icmp sgt i64 %19, 1
  br i1 %30, label %.lr.ph8, label %.loopexit.loopexit

31:                                               ; preds = %4
  %reass.sub = sub nsw i64 %11, %9
  %32 = icmp sgt i64 %reass.sub, -1
  br i1 %32, label %.lr.ph, label %.loopexit

.lr.ph:                                           ; preds = %31
  %33 = add nsw i64 %reass.sub, 1
  %34 = load ptr, ptr %2, align 8, !tbaa !8
  br label %35

35:                                               ; preds = %.lr.ph, %35
  %36 = phi i64 [ %33, %.lr.ph ], [ %47, %35 ]
  %37 = phi i32 [ %8, %.lr.ph ], [ %46, %35 ]
  %38 = load i32, ptr %5, align 4, !tbaa !4
  %39 = sitofp i32 %38 to float
  %40 = fdiv contract float 1.000000e+00, %39
  %41 = fpext float %40 to double
  %42 = sext i32 %37 to i64
  %43 = add nsw i64 %42, -1
  %44 = mul i64 %43, %13
  %45 = getelementptr i8, ptr %34, i64 %44
  store double %41, ptr %45, align 8, !tbaa !4
  store double %41, ptr %7, align 8, !tbaa !4
  %46 = add i32 %37, 1
  %47 = add nsw i64 %36, -1
  %48 = icmp sgt i64 %36, 1
  br i1 %48, label %35, label %.loopexit.loopexit10

.loopexit.loopexit:                               ; preds = %.lr.ph8
  br label %.loopexit

.loopexit.loopexit10:                             ; preds = %35
  br label %.loopexit

.loopexit:                                        ; preds = %.loopexit.loopexit10, %.loopexit.loopexit, %31, %15
  ret void
}
*** IR Dump After BDCEPass on _QFPloop ***
define void @_QFPloop(ptr %0, ptr %1, ptr %2, ptr nest %3) local_unnamed_addr {
  %5 = load ptr, ptr %3, align 8, !tbaa !4
  %6 = getelementptr { ptr, ptr }, ptr %3, i64 0, i32 1
  %7 = load ptr, ptr %6, align 8, !tbaa !4
  %8 = load i32, ptr %0, align 4, !tbaa !4
  %9 = sext i32 %8 to i64
  %10 = load i32, ptr %1, align 4, !tbaa !4
  %11 = sext i32 %10 to i64
  %12 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %2, i64 0, i32 7, i64 0, i64 2
  %13 = load i64, ptr %12, align 8, !tbaa !8
  %14 = icmp eq i64 %13, 8
  br i1 %14, label %15, label %31

15:                                               ; preds = %4
  %16 = load ptr, ptr %2, align 8, !tbaa !8
  %reass.sub9 = sub nsw i64 %11, %9
  %17 = add nsw i64 %reass.sub9, 1
  %18 = icmp sgt i64 %reass.sub9, -1
  br i1 %18, label %.lr.ph8.preheader, label %.loopexit

.lr.ph8.preheader:                                ; preds = %15
  br label %.lr.ph8

.lr.ph8:                                          ; preds = %.lr.ph8.preheader, %.lr.ph8
  %19 = phi i64 [ %29, %.lr.ph8 ], [ %17, %.lr.ph8.preheader ]
  %20 = phi i32 [ %28, %.lr.ph8 ], [ %8, %.lr.ph8.preheader ]
  %21 = load i32, ptr %5, align 4, !tbaa !4
  %22 = sitofp i32 %21 to float
  %23 = fdiv contract float 1.000000e+00, %22
  %24 = fpext float %23 to double
  %25 = sext i32 %20 to i64
  %26 = add nsw i64 %25, -1
  %27 = getelementptr double, ptr %16, i64 %26
  store double %24, ptr %27, align 8, !tbaa !4
  store double %24, ptr %7, align 8, !tbaa !4
  %28 = add i32 %20, 1
  %29 = add nsw i64 %19, -1
  %30 = icmp sgt i64 %19, 1
  br i1 %30, label %.lr.ph8, label %.loopexit.loopexit

31:                                               ; preds = %4
  %reass.sub = sub nsw i64 %11, %9
  %32 = icmp sgt i64 %reass.sub, -1
  br i1 %32, label %.lr.ph, label %.loopexit

.lr.ph:                                           ; preds = %31
  %33 = add nsw i64 %reass.sub, 1
  %34 = load ptr, ptr %2, align 8, !tbaa !8
  br label %35

35:                                               ; preds = %.lr.ph, %35
  %36 = phi i64 [ %33, %.lr.ph ], [ %47, %35 ]
  %37 = phi i32 [ %8, %.lr.ph ], [ %46, %35 ]
  %38 = load i32, ptr %5, align 4, !tbaa !4
  %39 = sitofp i32 %38 to float
  %40 = fdiv contract float 1.000000e+00, %39
  %41 = fpext float %40 to double
  %42 = sext i32 %37 to i64
  %43 = add nsw i64 %42, -1
  %44 = mul i64 %43, %13
  %45 = getelementptr i8, ptr %34, i64 %44
  store double %41, ptr %45, align 8, !tbaa !4
  store double %41, ptr %7, align 8, !tbaa !4
  %46 = add i32 %37, 1
  %47 = add nsw i64 %36, -1
  %48 = icmp sgt i64 %36, 1
  br i1 %48, label %35, label %.loopexit.loopexit10

.loopexit.loopexit:                               ; preds = %.lr.ph8
  br label %.loopexit

.loopexit.loopexit10:                             ; preds = %35
  br label %.loopexit

.loopexit:                                        ; preds = %.loopexit.loopexit10, %.loopexit.loopexit, %31, %15
  ret void
}
*** IR Dump After InstCombinePass on _QFPloop ***
define void @_QFPloop(ptr %0, ptr %1, ptr %2, ptr nest %3) local_unnamed_addr {
  %5 = load ptr, ptr %3, align 8, !tbaa !4
  %6 = getelementptr { ptr, ptr }, ptr %3, i64 0, i32 1
  %7 = load ptr, ptr %6, align 8, !tbaa !4
  %8 = load i32, ptr %0, align 4, !tbaa !4
  %9 = sext i32 %8 to i64
  %10 = load i32, ptr %1, align 4, !tbaa !4
  %11 = sext i32 %10 to i64
  %12 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %2, i64 0, i32 7, i64 0, i64 2
  %13 = load i64, ptr %12, align 8, !tbaa !8
  %14 = icmp eq i64 %13, 8
  br i1 %14, label %15, label %31

15:                                               ; preds = %4
  %16 = load ptr, ptr %2, align 8, !tbaa !8
  %reass.sub9 = sub nsw i64 %11, %9
  %17 = icmp sgt i64 %reass.sub9, -1
  br i1 %17, label %.lr.ph8.preheader, label %.loopexit

.lr.ph8.preheader:                                ; preds = %15
  %18 = add nsw i64 %reass.sub9, 1
  br label %.lr.ph8

.lr.ph8:                                          ; preds = %.lr.ph8.preheader, %.lr.ph8
  %19 = phi i64 [ %29, %.lr.ph8 ], [ %18, %.lr.ph8.preheader ]
  %20 = phi i32 [ %28, %.lr.ph8 ], [ %8, %.lr.ph8.preheader ]
  %21 = load i32, ptr %5, align 4, !tbaa !4
  %22 = sitofp i32 %21 to float
  %23 = fdiv contract float 1.000000e+00, %22
  %24 = fpext float %23 to double
  %25 = sext i32 %20 to i64
  %26 = add nsw i64 %25, -1
  %27 = getelementptr double, ptr %16, i64 %26
  store double %24, ptr %27, align 8, !tbaa !4
  store double %24, ptr %7, align 8, !tbaa !4
  %28 = add i32 %20, 1
  %29 = add nsw i64 %19, -1
  %30 = icmp sgt i64 %19, 1
  br i1 %30, label %.lr.ph8, label %.loopexit.loopexit

31:                                               ; preds = %4
  %reass.sub = sub nsw i64 %11, %9
  %32 = icmp sgt i64 %reass.sub, -1
  br i1 %32, label %.lr.ph, label %.loopexit

.lr.ph:                                           ; preds = %31
  %33 = add nsw i64 %reass.sub, 1
  %34 = load ptr, ptr %2, align 8, !tbaa !8
  br label %35

35:                                               ; preds = %.lr.ph, %35
  %36 = phi i64 [ %33, %.lr.ph ], [ %47, %35 ]
  %37 = phi i32 [ %8, %.lr.ph ], [ %46, %35 ]
  %38 = load i32, ptr %5, align 4, !tbaa !4
  %39 = sitofp i32 %38 to float
  %40 = fdiv contract float 1.000000e+00, %39
  %41 = fpext float %40 to double
  %42 = sext i32 %37 to i64
  %43 = add nsw i64 %42, -1
  %44 = mul i64 %43, %13
  %45 = getelementptr i8, ptr %34, i64 %44
  store double %41, ptr %45, align 8, !tbaa !4
  store double %41, ptr %7, align 8, !tbaa !4
  %46 = add i32 %37, 1
  %47 = add nsw i64 %36, -1
  %48 = icmp sgt i64 %36, 1
  br i1 %48, label %35, label %.loopexit.loopexit10

.loopexit.loopexit:                               ; preds = %.lr.ph8
  br label %.loopexit

.loopexit.loopexit10:                             ; preds = %35
  br label %.loopexit

.loopexit:                                        ; preds = %.loopexit.loopexit10, %.loopexit.loopexit, %31, %15
  ret void
}
*** IR Dump After JumpThreadingPass on _QFPloop ***
define void @_QFPloop(ptr %0, ptr %1, ptr %2, ptr nest %3) local_unnamed_addr {
  %5 = load ptr, ptr %3, align 8, !tbaa !4
  %6 = getelementptr { ptr, ptr }, ptr %3, i64 0, i32 1
  %7 = load ptr, ptr %6, align 8, !tbaa !4
  %8 = load i32, ptr %0, align 4, !tbaa !4
  %9 = sext i32 %8 to i64
  %10 = load i32, ptr %1, align 4, !tbaa !4
  %11 = sext i32 %10 to i64
  %12 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %2, i64 0, i32 7, i64 0, i64 2
  %13 = load i64, ptr %12, align 8, !tbaa !8
  %14 = icmp eq i64 %13, 8
  br i1 %14, label %15, label %31

15:                                               ; preds = %4
  %16 = load ptr, ptr %2, align 8, !tbaa !8
  %reass.sub9 = sub nsw i64 %11, %9
  %17 = icmp sgt i64 %reass.sub9, -1
  br i1 %17, label %.lr.ph8.preheader, label %.loopexit

.lr.ph8.preheader:                                ; preds = %15
  %18 = add nsw i64 %reass.sub9, 1
  br label %.lr.ph8

.lr.ph8:                                          ; preds = %.lr.ph8.preheader, %.lr.ph8
  %19 = phi i64 [ %29, %.lr.ph8 ], [ %18, %.lr.ph8.preheader ]
  %20 = phi i32 [ %28, %.lr.ph8 ], [ %8, %.lr.ph8.preheader ]
  %21 = load i32, ptr %5, align 4, !tbaa !4
  %22 = sitofp i32 %21 to float
  %23 = fdiv contract float 1.000000e+00, %22
  %24 = fpext float %23 to double
  %25 = sext i32 %20 to i64
  %26 = add nsw i64 %25, -1
  %27 = getelementptr double, ptr %16, i64 %26
  store double %24, ptr %27, align 8, !tbaa !4
  store double %24, ptr %7, align 8, !tbaa !4
  %28 = add i32 %20, 1
  %29 = add nsw i64 %19, -1
  %30 = icmp sgt i64 %19, 1
  br i1 %30, label %.lr.ph8, label %.loopexit

31:                                               ; preds = %4
  %reass.sub = sub nsw i64 %11, %9
  %32 = icmp sgt i64 %reass.sub, -1
  br i1 %32, label %.lr.ph, label %.loopexit

.lr.ph:                                           ; preds = %31
  %33 = add nsw i64 %reass.sub, 1
  %34 = load ptr, ptr %2, align 8, !tbaa !8
  br label %35

35:                                               ; preds = %.lr.ph, %35
  %36 = phi i64 [ %33, %.lr.ph ], [ %47, %35 ]
  %37 = phi i32 [ %8, %.lr.ph ], [ %46, %35 ]
  %38 = load i32, ptr %5, align 4, !tbaa !4
  %39 = sitofp i32 %38 to float
  %40 = fdiv contract float 1.000000e+00, %39
  %41 = fpext float %40 to double
  %42 = sext i32 %37 to i64
  %43 = add nsw i64 %42, -1
  %44 = mul i64 %43, %13
  %45 = getelementptr i8, ptr %34, i64 %44
  store double %41, ptr %45, align 8, !tbaa !4
  store double %41, ptr %7, align 8, !tbaa !4
  %46 = add i32 %37, 1
  %47 = add nsw i64 %36, -1
  %48 = icmp sgt i64 %36, 1
  br i1 %48, label %35, label %.loopexit

.loopexit:                                        ; preds = %35, %.lr.ph8, %31, %15
  ret void
}
*** IR Dump After CorrelatedValuePropagationPass on _QFPloop ***
define void @_QFPloop(ptr %0, ptr %1, ptr %2, ptr nest %3) local_unnamed_addr {
  %5 = load ptr, ptr %3, align 8, !tbaa !4
  %6 = getelementptr { ptr, ptr }, ptr %3, i64 0, i32 1
  %7 = load ptr, ptr %6, align 8, !tbaa !4
  %8 = load i32, ptr %0, align 4, !tbaa !4
  %9 = sext i32 %8 to i64
  %10 = load i32, ptr %1, align 4, !tbaa !4
  %11 = sext i32 %10 to i64
  %12 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %2, i64 0, i32 7, i64 0, i64 2
  %13 = load i64, ptr %12, align 8, !tbaa !8
  %14 = icmp eq i64 %13, 8
  br i1 %14, label %15, label %31

15:                                               ; preds = %4
  %16 = load ptr, ptr %2, align 8, !tbaa !8
  %reass.sub9 = sub nsw i64 %11, %9
  %17 = icmp sgt i64 %reass.sub9, -1
  br i1 %17, label %.lr.ph8.preheader, label %.loopexit

.lr.ph8.preheader:                                ; preds = %15
  %18 = add nuw nsw i64 %reass.sub9, 1
  br label %.lr.ph8

.lr.ph8:                                          ; preds = %.lr.ph8.preheader, %.lr.ph8
  %19 = phi i64 [ %29, %.lr.ph8 ], [ %18, %.lr.ph8.preheader ]
  %20 = phi i32 [ %28, %.lr.ph8 ], [ %8, %.lr.ph8.preheader ]
  %21 = load i32, ptr %5, align 4, !tbaa !4
  %22 = sitofp i32 %21 to float
  %23 = fdiv contract float 1.000000e+00, %22
  %24 = fpext float %23 to double
  %25 = sext i32 %20 to i64
  %26 = add nsw i64 %25, -1
  %27 = getelementptr double, ptr %16, i64 %26
  store double %24, ptr %27, align 8, !tbaa !4
  store double %24, ptr %7, align 8, !tbaa !4
  %28 = add i32 %20, 1
  %29 = add nsw i64 %19, -1
  %30 = icmp ugt i64 %19, 1
  br i1 %30, label %.lr.ph8, label %.loopexit

31:                                               ; preds = %4
  %reass.sub = sub nsw i64 %11, %9
  %32 = icmp sgt i64 %reass.sub, -1
  br i1 %32, label %.lr.ph, label %.loopexit

.lr.ph:                                           ; preds = %31
  %33 = add nuw nsw i64 %reass.sub, 1
  %34 = load ptr, ptr %2, align 8, !tbaa !8
  br label %35

35:                                               ; preds = %.lr.ph, %35
  %36 = phi i64 [ %33, %.lr.ph ], [ %47, %35 ]
  %37 = phi i32 [ %8, %.lr.ph ], [ %46, %35 ]
  %38 = load i32, ptr %5, align 4, !tbaa !4
  %39 = sitofp i32 %38 to float
  %40 = fdiv contract float 1.000000e+00, %39
  %41 = fpext float %40 to double
  %42 = sext i32 %37 to i64
  %43 = add nsw i64 %42, -1
  %44 = mul i64 %43, %13
  %45 = getelementptr i8, ptr %34, i64 %44
  store double %41, ptr %45, align 8, !tbaa !4
  store double %41, ptr %7, align 8, !tbaa !4
  %46 = add i32 %37, 1
  %47 = add nsw i64 %36, -1
  %48 = icmp ugt i64 %36, 1
  br i1 %48, label %35, label %.loopexit

.loopexit:                                        ; preds = %35, %.lr.ph8, %31, %15
  ret void
}
*** IR Dump After ADCEPass on _QFPloop ***
define void @_QFPloop(ptr %0, ptr %1, ptr %2, ptr nest %3) local_unnamed_addr {
  %5 = load ptr, ptr %3, align 8, !tbaa !4
  %6 = getelementptr { ptr, ptr }, ptr %3, i64 0, i32 1
  %7 = load ptr, ptr %6, align 8, !tbaa !4
  %8 = load i32, ptr %0, align 4, !tbaa !4
  %9 = sext i32 %8 to i64
  %10 = load i32, ptr %1, align 4, !tbaa !4
  %11 = sext i32 %10 to i64
  %12 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %2, i64 0, i32 7, i64 0, i64 2
  %13 = load i64, ptr %12, align 8, !tbaa !8
  %14 = icmp eq i64 %13, 8
  br i1 %14, label %15, label %31

15:                                               ; preds = %4
  %16 = load ptr, ptr %2, align 8, !tbaa !8
  %reass.sub9 = sub nsw i64 %11, %9
  %17 = icmp sgt i64 %reass.sub9, -1
  br i1 %17, label %.lr.ph8.preheader, label %.loopexit

.lr.ph8.preheader:                                ; preds = %15
  %18 = add nuw nsw i64 %reass.sub9, 1
  br label %.lr.ph8

.lr.ph8:                                          ; preds = %.lr.ph8.preheader, %.lr.ph8
  %19 = phi i64 [ %29, %.lr.ph8 ], [ %18, %.lr.ph8.preheader ]
  %20 = phi i32 [ %28, %.lr.ph8 ], [ %8, %.lr.ph8.preheader ]
  %21 = load i32, ptr %5, align 4, !tbaa !4
  %22 = sitofp i32 %21 to float
  %23 = fdiv contract float 1.000000e+00, %22
  %24 = fpext float %23 to double
  %25 = sext i32 %20 to i64
  %26 = add nsw i64 %25, -1
  %27 = getelementptr double, ptr %16, i64 %26
  store double %24, ptr %27, align 8, !tbaa !4
  store double %24, ptr %7, align 8, !tbaa !4
  %28 = add i32 %20, 1
  %29 = add nsw i64 %19, -1
  %30 = icmp ugt i64 %19, 1
  br i1 %30, label %.lr.ph8, label %.loopexit

31:                                               ; preds = %4
  %reass.sub = sub nsw i64 %11, %9
  %32 = icmp sgt i64 %reass.sub, -1
  br i1 %32, label %.lr.ph, label %.loopexit

.lr.ph:                                           ; preds = %31
  %33 = add nuw nsw i64 %reass.sub, 1
  %34 = load ptr, ptr %2, align 8, !tbaa !8
  br label %35

35:                                               ; preds = %.lr.ph, %35
  %36 = phi i64 [ %33, %.lr.ph ], [ %47, %35 ]
  %37 = phi i32 [ %8, %.lr.ph ], [ %46, %35 ]
  %38 = load i32, ptr %5, align 4, !tbaa !4
  %39 = sitofp i32 %38 to float
  %40 = fdiv contract float 1.000000e+00, %39
  %41 = fpext float %40 to double
  %42 = sext i32 %37 to i64
  %43 = add nsw i64 %42, -1
  %44 = mul i64 %43, %13
  %45 = getelementptr i8, ptr %34, i64 %44
  store double %41, ptr %45, align 8, !tbaa !4
  store double %41, ptr %7, align 8, !tbaa !4
  %46 = add i32 %37, 1
  %47 = add nsw i64 %36, -1
  %48 = icmp ugt i64 %36, 1
  br i1 %48, label %35, label %.loopexit

.loopexit:                                        ; preds = %35, %.lr.ph8, %31, %15
  ret void
}
*** IR Dump After MemCpyOptPass on _QFPloop ***
define void @_QFPloop(ptr %0, ptr %1, ptr %2, ptr nest %3) local_unnamed_addr {
  %5 = load ptr, ptr %3, align 8, !tbaa !4
  %6 = getelementptr { ptr, ptr }, ptr %3, i64 0, i32 1
  %7 = load ptr, ptr %6, align 8, !tbaa !4
  %8 = load i32, ptr %0, align 4, !tbaa !4
  %9 = sext i32 %8 to i64
  %10 = load i32, ptr %1, align 4, !tbaa !4
  %11 = sext i32 %10 to i64
  %12 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %2, i64 0, i32 7, i64 0, i64 2
  %13 = load i64, ptr %12, align 8, !tbaa !8
  %14 = icmp eq i64 %13, 8
  br i1 %14, label %15, label %31

15:                                               ; preds = %4
  %16 = load ptr, ptr %2, align 8, !tbaa !8
  %reass.sub9 = sub nsw i64 %11, %9
  %17 = icmp sgt i64 %reass.sub9, -1
  br i1 %17, label %.lr.ph8.preheader, label %.loopexit

.lr.ph8.preheader:                                ; preds = %15
  %18 = add nuw nsw i64 %reass.sub9, 1
  br label %.lr.ph8

.lr.ph8:                                          ; preds = %.lr.ph8.preheader, %.lr.ph8
  %19 = phi i64 [ %29, %.lr.ph8 ], [ %18, %.lr.ph8.preheader ]
  %20 = phi i32 [ %28, %.lr.ph8 ], [ %8, %.lr.ph8.preheader ]
  %21 = load i32, ptr %5, align 4, !tbaa !4
  %22 = sitofp i32 %21 to float
  %23 = fdiv contract float 1.000000e+00, %22
  %24 = fpext float %23 to double
  %25 = sext i32 %20 to i64
  %26 = add nsw i64 %25, -1
  %27 = getelementptr double, ptr %16, i64 %26
  store double %24, ptr %27, align 8, !tbaa !4
  store double %24, ptr %7, align 8, !tbaa !4
  %28 = add i32 %20, 1
  %29 = add nsw i64 %19, -1
  %30 = icmp ugt i64 %19, 1
  br i1 %30, label %.lr.ph8, label %.loopexit

31:                                               ; preds = %4
  %reass.sub = sub nsw i64 %11, %9
  %32 = icmp sgt i64 %reass.sub, -1
  br i1 %32, label %.lr.ph, label %.loopexit

.lr.ph:                                           ; preds = %31
  %33 = add nuw nsw i64 %reass.sub, 1
  %34 = load ptr, ptr %2, align 8, !tbaa !8
  br label %35

35:                                               ; preds = %.lr.ph, %35
  %36 = phi i64 [ %33, %.lr.ph ], [ %47, %35 ]
  %37 = phi i32 [ %8, %.lr.ph ], [ %46, %35 ]
  %38 = load i32, ptr %5, align 4, !tbaa !4
  %39 = sitofp i32 %38 to float
  %40 = fdiv contract float 1.000000e+00, %39
  %41 = fpext float %40 to double
  %42 = sext i32 %37 to i64
  %43 = add nsw i64 %42, -1
  %44 = mul i64 %43, %13
  %45 = getelementptr i8, ptr %34, i64 %44
  store double %41, ptr %45, align 8, !tbaa !4
  store double %41, ptr %7, align 8, !tbaa !4
  %46 = add i32 %37, 1
  %47 = add nsw i64 %36, -1
  %48 = icmp ugt i64 %36, 1
  br i1 %48, label %35, label %.loopexit

.loopexit:                                        ; preds = %35, %.lr.ph8, %31, %15
  ret void
}
*** IR Dump After DSEPass on _QFPloop ***
define void @_QFPloop(ptr %0, ptr %1, ptr %2, ptr nest %3) local_unnamed_addr {
  %5 = load ptr, ptr %3, align 8, !tbaa !4
  %6 = getelementptr { ptr, ptr }, ptr %3, i64 0, i32 1
  %7 = load ptr, ptr %6, align 8, !tbaa !4
  %8 = load i32, ptr %0, align 4, !tbaa !4
  %9 = sext i32 %8 to i64
  %10 = load i32, ptr %1, align 4, !tbaa !4
  %11 = sext i32 %10 to i64
  %12 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %2, i64 0, i32 7, i64 0, i64 2
  %13 = load i64, ptr %12, align 8, !tbaa !8
  %14 = icmp eq i64 %13, 8
  br i1 %14, label %15, label %31

15:                                               ; preds = %4
  %16 = load ptr, ptr %2, align 8, !tbaa !8
  %reass.sub9 = sub nsw i64 %11, %9
  %17 = icmp sgt i64 %reass.sub9, -1
  br i1 %17, label %.lr.ph8.preheader, label %.loopexit

.lr.ph8.preheader:                                ; preds = %15
  %18 = add nuw nsw i64 %reass.sub9, 1
  br label %.lr.ph8

.lr.ph8:                                          ; preds = %.lr.ph8.preheader, %.lr.ph8
  %19 = phi i64 [ %29, %.lr.ph8 ], [ %18, %.lr.ph8.preheader ]
  %20 = phi i32 [ %28, %.lr.ph8 ], [ %8, %.lr.ph8.preheader ]
  %21 = load i32, ptr %5, align 4, !tbaa !4
  %22 = sitofp i32 %21 to float
  %23 = fdiv contract float 1.000000e+00, %22
  %24 = fpext float %23 to double
  %25 = sext i32 %20 to i64
  %26 = add nsw i64 %25, -1
  %27 = getelementptr double, ptr %16, i64 %26
  store double %24, ptr %27, align 8, !tbaa !4
  store double %24, ptr %7, align 8, !tbaa !4
  %28 = add i32 %20, 1
  %29 = add nsw i64 %19, -1
  %30 = icmp ugt i64 %19, 1
  br i1 %30, label %.lr.ph8, label %.loopexit

31:                                               ; preds = %4
  %reass.sub = sub nsw i64 %11, %9
  %32 = icmp sgt i64 %reass.sub, -1
  br i1 %32, label %.lr.ph, label %.loopexit

.lr.ph:                                           ; preds = %31
  %33 = add nuw nsw i64 %reass.sub, 1
  %34 = load ptr, ptr %2, align 8, !tbaa !8
  br label %35

35:                                               ; preds = %.lr.ph, %35
  %36 = phi i64 [ %33, %.lr.ph ], [ %47, %35 ]
  %37 = phi i32 [ %8, %.lr.ph ], [ %46, %35 ]
  %38 = load i32, ptr %5, align 4, !tbaa !4
  %39 = sitofp i32 %38 to float
  %40 = fdiv contract float 1.000000e+00, %39
  %41 = fpext float %40 to double
  %42 = sext i32 %37 to i64
  %43 = add nsw i64 %42, -1
  %44 = mul i64 %43, %13
  %45 = getelementptr i8, ptr %34, i64 %44
  store double %41, ptr %45, align 8, !tbaa !4
  store double %41, ptr %7, align 8, !tbaa !4
  %46 = add i32 %37, 1
  %47 = add nsw i64 %36, -1
  %48 = icmp ugt i64 %36, 1
  br i1 %48, label %35, label %.loopexit

.loopexit:                                        ; preds = %35, %.lr.ph8, %31, %15
  ret void
}
*** IR Dump After MoveAutoInitPass on _QFPloop ***
define void @_QFPloop(ptr %0, ptr %1, ptr %2, ptr nest %3) local_unnamed_addr {
  %5 = load ptr, ptr %3, align 8, !tbaa !4
  %6 = getelementptr { ptr, ptr }, ptr %3, i64 0, i32 1
  %7 = load ptr, ptr %6, align 8, !tbaa !4
  %8 = load i32, ptr %0, align 4, !tbaa !4
  %9 = sext i32 %8 to i64
  %10 = load i32, ptr %1, align 4, !tbaa !4
  %11 = sext i32 %10 to i64
  %12 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %2, i64 0, i32 7, i64 0, i64 2
  %13 = load i64, ptr %12, align 8, !tbaa !8
  %14 = icmp eq i64 %13, 8
  br i1 %14, label %15, label %31

15:                                               ; preds = %4
  %16 = load ptr, ptr %2, align 8, !tbaa !8
  %reass.sub9 = sub nsw i64 %11, %9
  %17 = icmp sgt i64 %reass.sub9, -1
  br i1 %17, label %.lr.ph8.preheader, label %.loopexit

.lr.ph8.preheader:                                ; preds = %15
  %18 = add nuw nsw i64 %reass.sub9, 1
  br label %.lr.ph8

.lr.ph8:                                          ; preds = %.lr.ph8.preheader, %.lr.ph8
  %19 = phi i64 [ %29, %.lr.ph8 ], [ %18, %.lr.ph8.preheader ]
  %20 = phi i32 [ %28, %.lr.ph8 ], [ %8, %.lr.ph8.preheader ]
  %21 = load i32, ptr %5, align 4, !tbaa !4
  %22 = sitofp i32 %21 to float
  %23 = fdiv contract float 1.000000e+00, %22
  %24 = fpext float %23 to double
  %25 = sext i32 %20 to i64
  %26 = add nsw i64 %25, -1
  %27 = getelementptr double, ptr %16, i64 %26
  store double %24, ptr %27, align 8, !tbaa !4
  store double %24, ptr %7, align 8, !tbaa !4
  %28 = add i32 %20, 1
  %29 = add nsw i64 %19, -1
  %30 = icmp ugt i64 %19, 1
  br i1 %30, label %.lr.ph8, label %.loopexit

31:                                               ; preds = %4
  %reass.sub = sub nsw i64 %11, %9
  %32 = icmp sgt i64 %reass.sub, -1
  br i1 %32, label %.lr.ph, label %.loopexit

.lr.ph:                                           ; preds = %31
  %33 = add nuw nsw i64 %reass.sub, 1
  %34 = load ptr, ptr %2, align 8, !tbaa !8
  br label %35

35:                                               ; preds = %.lr.ph, %35
  %36 = phi i64 [ %33, %.lr.ph ], [ %47, %35 ]
  %37 = phi i32 [ %8, %.lr.ph ], [ %46, %35 ]
  %38 = load i32, ptr %5, align 4, !tbaa !4
  %39 = sitofp i32 %38 to float
  %40 = fdiv contract float 1.000000e+00, %39
  %41 = fpext float %40 to double
  %42 = sext i32 %37 to i64
  %43 = add nsw i64 %42, -1
  %44 = mul i64 %43, %13
  %45 = getelementptr i8, ptr %34, i64 %44
  store double %41, ptr %45, align 8, !tbaa !4
  store double %41, ptr %7, align 8, !tbaa !4
  %46 = add i32 %37, 1
  %47 = add nsw i64 %36, -1
  %48 = icmp ugt i64 %36, 1
  br i1 %48, label %35, label %.loopexit

.loopexit:                                        ; preds = %35, %.lr.ph8, %31, %15
  ret void
}
*** IR Dump After LoopSimplifyPass on _QFPloop ***
define void @_QFPloop(ptr %0, ptr %1, ptr %2, ptr nest %3) local_unnamed_addr {
  %5 = load ptr, ptr %3, align 8, !tbaa !4
  %6 = getelementptr { ptr, ptr }, ptr %3, i64 0, i32 1
  %7 = load ptr, ptr %6, align 8, !tbaa !4
  %8 = load i32, ptr %0, align 4, !tbaa !4
  %9 = sext i32 %8 to i64
  %10 = load i32, ptr %1, align 4, !tbaa !4
  %11 = sext i32 %10 to i64
  %12 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %2, i64 0, i32 7, i64 0, i64 2
  %13 = load i64, ptr %12, align 8, !tbaa !8
  %14 = icmp eq i64 %13, 8
  br i1 %14, label %15, label %31

15:                                               ; preds = %4
  %16 = load ptr, ptr %2, align 8, !tbaa !8
  %reass.sub9 = sub nsw i64 %11, %9
  %17 = icmp sgt i64 %reass.sub9, -1
  br i1 %17, label %.lr.ph8.preheader, label %.loopexit

.lr.ph8.preheader:                                ; preds = %15
  %18 = add nuw nsw i64 %reass.sub9, 1
  br label %.lr.ph8

.lr.ph8:                                          ; preds = %.lr.ph8.preheader, %.lr.ph8
  %19 = phi i64 [ %29, %.lr.ph8 ], [ %18, %.lr.ph8.preheader ]
  %20 = phi i32 [ %28, %.lr.ph8 ], [ %8, %.lr.ph8.preheader ]
  %21 = load i32, ptr %5, align 4, !tbaa !4
  %22 = sitofp i32 %21 to float
  %23 = fdiv contract float 1.000000e+00, %22
  %24 = fpext float %23 to double
  %25 = sext i32 %20 to i64
  %26 = add nsw i64 %25, -1
  %27 = getelementptr double, ptr %16, i64 %26
  store double %24, ptr %27, align 8, !tbaa !4
  store double %24, ptr %7, align 8, !tbaa !4
  %28 = add i32 %20, 1
  %29 = add nsw i64 %19, -1
  %30 = icmp ugt i64 %19, 1
  br i1 %30, label %.lr.ph8, label %.loopexit.loopexit

31:                                               ; preds = %4
  %reass.sub = sub nsw i64 %11, %9
  %32 = icmp sgt i64 %reass.sub, -1
  br i1 %32, label %.lr.ph, label %.loopexit

.lr.ph:                                           ; preds = %31
  %33 = add nuw nsw i64 %reass.sub, 1
  %34 = load ptr, ptr %2, align 8, !tbaa !8
  br label %35

35:                                               ; preds = %.lr.ph, %35
  %36 = phi i64 [ %33, %.lr.ph ], [ %47, %35 ]
  %37 = phi i32 [ %8, %.lr.ph ], [ %46, %35 ]
  %38 = load i32, ptr %5, align 4, !tbaa !4
  %39 = sitofp i32 %38 to float
  %40 = fdiv contract float 1.000000e+00, %39
  %41 = fpext float %40 to double
  %42 = sext i32 %37 to i64
  %43 = add nsw i64 %42, -1
  %44 = mul i64 %43, %13
  %45 = getelementptr i8, ptr %34, i64 %44
  store double %41, ptr %45, align 8, !tbaa !4
  store double %41, ptr %7, align 8, !tbaa !4
  %46 = add i32 %37, 1
  %47 = add nsw i64 %36, -1
  %48 = icmp ugt i64 %36, 1
  br i1 %48, label %35, label %.loopexit.loopexit11

.loopexit.loopexit:                               ; preds = %.lr.ph8
  br label %.loopexit

.loopexit.loopexit11:                             ; preds = %35
  br label %.loopexit

.loopexit:                                        ; preds = %.loopexit.loopexit11, %.loopexit.loopexit, %31, %15
  ret void
}
*** IR Dump After LCSSAPass on _QFPloop ***
define void @_QFPloop(ptr %0, ptr %1, ptr %2, ptr nest %3) local_unnamed_addr {
  %5 = load ptr, ptr %3, align 8, !tbaa !4
  %6 = getelementptr { ptr, ptr }, ptr %3, i64 0, i32 1
  %7 = load ptr, ptr %6, align 8, !tbaa !4
  %8 = load i32, ptr %0, align 4, !tbaa !4
  %9 = sext i32 %8 to i64
  %10 = load i32, ptr %1, align 4, !tbaa !4
  %11 = sext i32 %10 to i64
  %12 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %2, i64 0, i32 7, i64 0, i64 2
  %13 = load i64, ptr %12, align 8, !tbaa !8
  %14 = icmp eq i64 %13, 8
  br i1 %14, label %15, label %31

15:                                               ; preds = %4
  %16 = load ptr, ptr %2, align 8, !tbaa !8
  %reass.sub9 = sub nsw i64 %11, %9
  %17 = icmp sgt i64 %reass.sub9, -1
  br i1 %17, label %.lr.ph8.preheader, label %.loopexit

.lr.ph8.preheader:                                ; preds = %15
  %18 = add nuw nsw i64 %reass.sub9, 1
  br label %.lr.ph8

.lr.ph8:                                          ; preds = %.lr.ph8.preheader, %.lr.ph8
  %19 = phi i64 [ %29, %.lr.ph8 ], [ %18, %.lr.ph8.preheader ]
  %20 = phi i32 [ %28, %.lr.ph8 ], [ %8, %.lr.ph8.preheader ]
  %21 = load i32, ptr %5, align 4, !tbaa !4
  %22 = sitofp i32 %21 to float
  %23 = fdiv contract float 1.000000e+00, %22
  %24 = fpext float %23 to double
  %25 = sext i32 %20 to i64
  %26 = add nsw i64 %25, -1
  %27 = getelementptr double, ptr %16, i64 %26
  store double %24, ptr %27, align 8, !tbaa !4
  store double %24, ptr %7, align 8, !tbaa !4
  %28 = add i32 %20, 1
  %29 = add nsw i64 %19, -1
  %30 = icmp ugt i64 %19, 1
  br i1 %30, label %.lr.ph8, label %.loopexit.loopexit

31:                                               ; preds = %4
  %reass.sub = sub nsw i64 %11, %9
  %32 = icmp sgt i64 %reass.sub, -1
  br i1 %32, label %.lr.ph, label %.loopexit

.lr.ph:                                           ; preds = %31
  %33 = add nuw nsw i64 %reass.sub, 1
  %34 = load ptr, ptr %2, align 8, !tbaa !8
  br label %35

35:                                               ; preds = %.lr.ph, %35
  %36 = phi i64 [ %33, %.lr.ph ], [ %47, %35 ]
  %37 = phi i32 [ %8, %.lr.ph ], [ %46, %35 ]
  %38 = load i32, ptr %5, align 4, !tbaa !4
  %39 = sitofp i32 %38 to float
  %40 = fdiv contract float 1.000000e+00, %39
  %41 = fpext float %40 to double
  %42 = sext i32 %37 to i64
  %43 = add nsw i64 %42, -1
  %44 = mul i64 %43, %13
  %45 = getelementptr i8, ptr %34, i64 %44
  store double %41, ptr %45, align 8, !tbaa !4
  store double %41, ptr %7, align 8, !tbaa !4
  %46 = add i32 %37, 1
  %47 = add nsw i64 %36, -1
  %48 = icmp ugt i64 %36, 1
  br i1 %48, label %35, label %.loopexit.loopexit11

.loopexit.loopexit:                               ; preds = %.lr.ph8
  br label %.loopexit

.loopexit.loopexit11:                             ; preds = %35
  br label %.loopexit

.loopexit:                                        ; preds = %.loopexit.loopexit11, %.loopexit.loopexit, %31, %15
  ret void
}
*** IR Dump After LICMPass on <unnamed loop> ***

; Preheader:
.lr.ph:                                           ; preds = %31
  %33 = add nuw nsw i64 %reass.sub, 1
  %34 = load ptr, ptr %2, align 8, !tbaa !8
  br label %35

; Loop:
35:                                               ; preds = %.lr.ph, %35
  %36 = phi i64 [ %33, %.lr.ph ], [ %47, %35 ]
  %37 = phi i32 [ %8, %.lr.ph ], [ %46, %35 ]
  %38 = load i32, ptr %5, align 4, !tbaa !4
  %39 = sitofp i32 %38 to float
  %40 = fdiv contract float 1.000000e+00, %39
  %41 = fpext float %40 to double
  %42 = sext i32 %37 to i64
  %43 = add nsw i64 %42, -1
  %44 = mul i64 %43, %13
  %45 = getelementptr i8, ptr %34, i64 %44
  store double %41, ptr %45, align 8, !tbaa !4
  store double %41, ptr %7, align 8, !tbaa !4
  %46 = add i32 %37, 1
  %47 = add nsw i64 %36, -1
  %48 = icmp ugt i64 %36, 1
  br i1 %48, label %35, label %.loopexit.loopexit11

; Exit blocks
.loopexit.loopexit11:                             ; preds = %35
  br label %.loopexit
*** IR Dump After LICMPass on .lr.ph8 ***

; Preheader:
.lr.ph8.preheader:                                ; preds = %15
  %18 = add nuw nsw i64 %reass.sub9, 1
  br label %.lr.ph8

; Loop:
.lr.ph8:                                          ; preds = %.lr.ph8.preheader, %.lr.ph8
  %19 = phi i64 [ %29, %.lr.ph8 ], [ %18, %.lr.ph8.preheader ]
  %20 = phi i32 [ %28, %.lr.ph8 ], [ %8, %.lr.ph8.preheader ]
  %21 = load i32, ptr %5, align 4, !tbaa !4
  %22 = sitofp i32 %21 to float
  %23 = fdiv contract float 1.000000e+00, %22
  %24 = fpext float %23 to double
  %25 = sext i32 %20 to i64
  %26 = add nsw i64 %25, -1
  %27 = getelementptr double, ptr %16, i64 %26
  store double %24, ptr %27, align 8, !tbaa !4
  store double %24, ptr %7, align 8, !tbaa !4
  %28 = add i32 %20, 1
  %29 = add nsw i64 %19, -1
  %30 = icmp ugt i64 %19, 1
  br i1 %30, label %.lr.ph8, label %.loopexit.loopexit

; Exit blocks
.loopexit.loopexit:                               ; preds = %.lr.ph8
  br label %.loopexit
*** IR Dump After CoroElidePass on _QFPloop ***
define void @_QFPloop(ptr %0, ptr %1, ptr %2, ptr nest %3) local_unnamed_addr {
  %5 = load ptr, ptr %3, align 8, !tbaa !4
  %6 = getelementptr { ptr, ptr }, ptr %3, i64 0, i32 1
  %7 = load ptr, ptr %6, align 8, !tbaa !4
  %8 = load i32, ptr %0, align 4, !tbaa !4
  %9 = sext i32 %8 to i64
  %10 = load i32, ptr %1, align 4, !tbaa !4
  %11 = sext i32 %10 to i64
  %12 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %2, i64 0, i32 7, i64 0, i64 2
  %13 = load i64, ptr %12, align 8, !tbaa !8
  %14 = icmp eq i64 %13, 8
  br i1 %14, label %15, label %31

15:                                               ; preds = %4
  %16 = load ptr, ptr %2, align 8, !tbaa !8
  %reass.sub9 = sub nsw i64 %11, %9
  %17 = icmp sgt i64 %reass.sub9, -1
  br i1 %17, label %.lr.ph8.preheader, label %.loopexit

.lr.ph8.preheader:                                ; preds = %15
  %18 = add nuw nsw i64 %reass.sub9, 1
  br label %.lr.ph8

.lr.ph8:                                          ; preds = %.lr.ph8.preheader, %.lr.ph8
  %19 = phi i64 [ %29, %.lr.ph8 ], [ %18, %.lr.ph8.preheader ]
  %20 = phi i32 [ %28, %.lr.ph8 ], [ %8, %.lr.ph8.preheader ]
  %21 = load i32, ptr %5, align 4, !tbaa !4
  %22 = sitofp i32 %21 to float
  %23 = fdiv contract float 1.000000e+00, %22
  %24 = fpext float %23 to double
  %25 = sext i32 %20 to i64
  %26 = add nsw i64 %25, -1
  %27 = getelementptr double, ptr %16, i64 %26
  store double %24, ptr %27, align 8, !tbaa !4
  store double %24, ptr %7, align 8, !tbaa !4
  %28 = add i32 %20, 1
  %29 = add nsw i64 %19, -1
  %30 = icmp ugt i64 %19, 1
  br i1 %30, label %.lr.ph8, label %.loopexit.loopexit

31:                                               ; preds = %4
  %reass.sub = sub nsw i64 %11, %9
  %32 = icmp sgt i64 %reass.sub, -1
  br i1 %32, label %.lr.ph, label %.loopexit

.lr.ph:                                           ; preds = %31
  %33 = add nuw nsw i64 %reass.sub, 1
  %34 = load ptr, ptr %2, align 8, !tbaa !8
  br label %35

35:                                               ; preds = %.lr.ph, %35
  %36 = phi i64 [ %33, %.lr.ph ], [ %47, %35 ]
  %37 = phi i32 [ %8, %.lr.ph ], [ %46, %35 ]
  %38 = load i32, ptr %5, align 4, !tbaa !4
  %39 = sitofp i32 %38 to float
  %40 = fdiv contract float 1.000000e+00, %39
  %41 = fpext float %40 to double
  %42 = sext i32 %37 to i64
  %43 = add nsw i64 %42, -1
  %44 = mul i64 %43, %13
  %45 = getelementptr i8, ptr %34, i64 %44
  store double %41, ptr %45, align 8, !tbaa !4
  store double %41, ptr %7, align 8, !tbaa !4
  %46 = add i32 %37, 1
  %47 = add nsw i64 %36, -1
  %48 = icmp ugt i64 %36, 1
  br i1 %48, label %35, label %.loopexit.loopexit11

.loopexit.loopexit:                               ; preds = %.lr.ph8
  br label %.loopexit

.loopexit.loopexit11:                             ; preds = %35
  br label %.loopexit

.loopexit:                                        ; preds = %.loopexit.loopexit11, %.loopexit.loopexit, %31, %15
  ret void
}
*** IR Dump After SimplifyCFGPass on _QFPloop ***
define void @_QFPloop(ptr %0, ptr %1, ptr %2, ptr nest %3) local_unnamed_addr {
  %5 = load ptr, ptr %3, align 8, !tbaa !4
  %6 = getelementptr { ptr, ptr }, ptr %3, i64 0, i32 1
  %7 = load ptr, ptr %6, align 8, !tbaa !4
  %8 = load i32, ptr %0, align 4, !tbaa !4
  %9 = sext i32 %8 to i64
  %10 = load i32, ptr %1, align 4, !tbaa !4
  %11 = sext i32 %10 to i64
  %12 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %2, i64 0, i32 7, i64 0, i64 2
  %13 = load i64, ptr %12, align 8, !tbaa !8
  %14 = icmp eq i64 %13, 8
  br i1 %14, label %15, label %31

15:                                               ; preds = %4
  %16 = load ptr, ptr %2, align 8, !tbaa !8
  %reass.sub9 = sub nsw i64 %11, %9
  %17 = icmp sgt i64 %reass.sub9, -1
  br i1 %17, label %.lr.ph8.preheader, label %.loopexit

.lr.ph8.preheader:                                ; preds = %15
  %18 = add nuw nsw i64 %reass.sub9, 1
  br label %.lr.ph8

.lr.ph8:                                          ; preds = %.lr.ph8.preheader, %.lr.ph8
  %19 = phi i64 [ %29, %.lr.ph8 ], [ %18, %.lr.ph8.preheader ]
  %20 = phi i32 [ %28, %.lr.ph8 ], [ %8, %.lr.ph8.preheader ]
  %21 = load i32, ptr %5, align 4, !tbaa !4
  %22 = sitofp i32 %21 to float
  %23 = fdiv contract float 1.000000e+00, %22
  %24 = fpext float %23 to double
  %25 = sext i32 %20 to i64
  %26 = add nsw i64 %25, -1
  %27 = getelementptr double, ptr %16, i64 %26
  store double %24, ptr %27, align 8, !tbaa !4
  store double %24, ptr %7, align 8, !tbaa !4
  %28 = add i32 %20, 1
  %29 = add nsw i64 %19, -1
  %30 = icmp ugt i64 %19, 1
  br i1 %30, label %.lr.ph8, label %.loopexit

31:                                               ; preds = %4
  %reass.sub = sub nsw i64 %11, %9
  %32 = icmp sgt i64 %reass.sub, -1
  br i1 %32, label %.lr.ph, label %.loopexit

.lr.ph:                                           ; preds = %31
  %33 = add nuw nsw i64 %reass.sub, 1
  %34 = load ptr, ptr %2, align 8, !tbaa !8
  br label %35

35:                                               ; preds = %.lr.ph, %35
  %36 = phi i64 [ %33, %.lr.ph ], [ %47, %35 ]
  %37 = phi i32 [ %8, %.lr.ph ], [ %46, %35 ]
  %38 = load i32, ptr %5, align 4, !tbaa !4
  %39 = sitofp i32 %38 to float
  %40 = fdiv contract float 1.000000e+00, %39
  %41 = fpext float %40 to double
  %42 = sext i32 %37 to i64
  %43 = add nsw i64 %42, -1
  %44 = mul i64 %43, %13
  %45 = getelementptr i8, ptr %34, i64 %44
  store double %41, ptr %45, align 8, !tbaa !4
  store double %41, ptr %7, align 8, !tbaa !4
  %46 = add i32 %37, 1
  %47 = add nsw i64 %36, -1
  %48 = icmp ugt i64 %36, 1
  br i1 %48, label %35, label %.loopexit

.loopexit:                                        ; preds = %35, %.lr.ph8, %31, %15
  ret void
}
*** IR Dump After InstCombinePass on _QFPloop ***
define void @_QFPloop(ptr %0, ptr %1, ptr %2, ptr nest %3) local_unnamed_addr {
  %5 = load ptr, ptr %3, align 8, !tbaa !4
  %6 = getelementptr { ptr, ptr }, ptr %3, i64 0, i32 1
  %7 = load ptr, ptr %6, align 8, !tbaa !4
  %8 = load i32, ptr %0, align 4, !tbaa !4
  %9 = sext i32 %8 to i64
  %10 = load i32, ptr %1, align 4, !tbaa !4
  %11 = sext i32 %10 to i64
  %12 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %2, i64 0, i32 7, i64 0, i64 2
  %13 = load i64, ptr %12, align 8, !tbaa !8
  %14 = icmp eq i64 %13, 8
  br i1 %14, label %15, label %31

15:                                               ; preds = %4
  %16 = load ptr, ptr %2, align 8, !tbaa !8
  %reass.sub9 = sub nsw i64 %11, %9
  %17 = icmp sgt i64 %reass.sub9, -1
  br i1 %17, label %.lr.ph8.preheader, label %.loopexit

.lr.ph8.preheader:                                ; preds = %15
  %18 = add nuw nsw i64 %reass.sub9, 1
  br label %.lr.ph8

.lr.ph8:                                          ; preds = %.lr.ph8.preheader, %.lr.ph8
  %19 = phi i64 [ %29, %.lr.ph8 ], [ %18, %.lr.ph8.preheader ]
  %20 = phi i32 [ %28, %.lr.ph8 ], [ %8, %.lr.ph8.preheader ]
  %21 = load i32, ptr %5, align 4, !tbaa !4
  %22 = sitofp i32 %21 to float
  %23 = fdiv contract float 1.000000e+00, %22
  %24 = fpext float %23 to double
  %25 = sext i32 %20 to i64
  %26 = add nsw i64 %25, -1
  %27 = getelementptr double, ptr %16, i64 %26
  store double %24, ptr %27, align 8, !tbaa !4
  store double %24, ptr %7, align 8, !tbaa !4
  %28 = add i32 %20, 1
  %29 = add nsw i64 %19, -1
  %30 = icmp ugt i64 %19, 1
  br i1 %30, label %.lr.ph8, label %.loopexit

31:                                               ; preds = %4
  %reass.sub = sub nsw i64 %11, %9
  %32 = icmp sgt i64 %reass.sub, -1
  br i1 %32, label %.lr.ph, label %.loopexit

.lr.ph:                                           ; preds = %31
  %33 = add nuw nsw i64 %reass.sub, 1
  %34 = load ptr, ptr %2, align 8, !tbaa !8
  br label %35

35:                                               ; preds = %.lr.ph, %35
  %36 = phi i64 [ %33, %.lr.ph ], [ %47, %35 ]
  %37 = phi i32 [ %8, %.lr.ph ], [ %46, %35 ]
  %38 = load i32, ptr %5, align 4, !tbaa !4
  %39 = sitofp i32 %38 to float
  %40 = fdiv contract float 1.000000e+00, %39
  %41 = fpext float %40 to double
  %42 = sext i32 %37 to i64
  %43 = add nsw i64 %42, -1
  %44 = mul i64 %43, %13
  %45 = getelementptr i8, ptr %34, i64 %44
  store double %41, ptr %45, align 8, !tbaa !4
  store double %41, ptr %7, align 8, !tbaa !4
  %46 = add i32 %37, 1
  %47 = add nsw i64 %36, -1
  %48 = icmp ugt i64 %36, 1
  br i1 %48, label %35, label %.loopexit

.loopexit:                                        ; preds = %35, %.lr.ph8, %31, %15
  ret void
}
*** IR Dump After PostOrderFunctionAttrsPass on (_QFPloop) ***
; Function Attrs: nofree norecurse nosync nounwind memory(readwrite, inaccessiblemem: none)
define void @_QFPloop(ptr nocapture readonly %0, ptr nocapture readonly %1, ptr nocapture readonly %2, ptr nest nocapture readonly %3) local_unnamed_addr #3 {
  %5 = load ptr, ptr %3, align 8, !tbaa !4
  %6 = getelementptr { ptr, ptr }, ptr %3, i64 0, i32 1
  %7 = load ptr, ptr %6, align 8, !tbaa !4
  %8 = load i32, ptr %0, align 4, !tbaa !4
  %9 = sext i32 %8 to i64
  %10 = load i32, ptr %1, align 4, !tbaa !4
  %11 = sext i32 %10 to i64
  %12 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %2, i64 0, i32 7, i64 0, i64 2
  %13 = load i64, ptr %12, align 8, !tbaa !8
  %14 = icmp eq i64 %13, 8
  br i1 %14, label %15, label %31

15:                                               ; preds = %4
  %16 = load ptr, ptr %2, align 8, !tbaa !8
  %reass.sub9 = sub nsw i64 %11, %9
  %17 = icmp sgt i64 %reass.sub9, -1
  br i1 %17, label %.lr.ph8.preheader, label %.loopexit

.lr.ph8.preheader:                                ; preds = %15
  %18 = add nuw nsw i64 %reass.sub9, 1
  br label %.lr.ph8

.lr.ph8:                                          ; preds = %.lr.ph8.preheader, %.lr.ph8
  %19 = phi i64 [ %29, %.lr.ph8 ], [ %18, %.lr.ph8.preheader ]
  %20 = phi i32 [ %28, %.lr.ph8 ], [ %8, %.lr.ph8.preheader ]
  %21 = load i32, ptr %5, align 4, !tbaa !4
  %22 = sitofp i32 %21 to float
  %23 = fdiv contract float 1.000000e+00, %22
  %24 = fpext float %23 to double
  %25 = sext i32 %20 to i64
  %26 = add nsw i64 %25, -1
  %27 = getelementptr double, ptr %16, i64 %26
  store double %24, ptr %27, align 8, !tbaa !4
  store double %24, ptr %7, align 8, !tbaa !4
  %28 = add i32 %20, 1
  %29 = add nsw i64 %19, -1
  %30 = icmp ugt i64 %19, 1
  br i1 %30, label %.lr.ph8, label %.loopexit

31:                                               ; preds = %4
  %reass.sub = sub nsw i64 %11, %9
  %32 = icmp sgt i64 %reass.sub, -1
  br i1 %32, label %.lr.ph, label %.loopexit

.lr.ph:                                           ; preds = %31
  %33 = add nuw nsw i64 %reass.sub, 1
  %34 = load ptr, ptr %2, align 8, !tbaa !8
  br label %35

35:                                               ; preds = %.lr.ph, %35
  %36 = phi i64 [ %33, %.lr.ph ], [ %47, %35 ]
  %37 = phi i32 [ %8, %.lr.ph ], [ %46, %35 ]
  %38 = load i32, ptr %5, align 4, !tbaa !4
  %39 = sitofp i32 %38 to float
  %40 = fdiv contract float 1.000000e+00, %39
  %41 = fpext float %40 to double
  %42 = sext i32 %37 to i64
  %43 = add nsw i64 %42, -1
  %44 = mul i64 %43, %13
  %45 = getelementptr i8, ptr %34, i64 %44
  store double %41, ptr %45, align 8, !tbaa !4
  store double %41, ptr %7, align 8, !tbaa !4
  %46 = add i32 %37, 1
  %47 = add nsw i64 %36, -1
  %48 = icmp ugt i64 %36, 1
  br i1 %48, label %35, label %.loopexit

.loopexit:                                        ; preds = %35, %.lr.ph8, %31, %15
  ret void
}
*** IR Dump After RequireAnalysisPass<llvm::ShouldNotRunFunctionPassesAnalysis, llvm::Function> on _QFPloop ***
; Function Attrs: nofree norecurse nosync nounwind memory(readwrite, inaccessiblemem: none)
define void @_QFPloop(ptr nocapture readonly %0, ptr nocapture readonly %1, ptr nocapture readonly %2, ptr nest nocapture readonly %3) local_unnamed_addr #3 {
  %5 = load ptr, ptr %3, align 8, !tbaa !4
  %6 = getelementptr { ptr, ptr }, ptr %3, i64 0, i32 1
  %7 = load ptr, ptr %6, align 8, !tbaa !4
  %8 = load i32, ptr %0, align 4, !tbaa !4
  %9 = sext i32 %8 to i64
  %10 = load i32, ptr %1, align 4, !tbaa !4
  %11 = sext i32 %10 to i64
  %12 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %2, i64 0, i32 7, i64 0, i64 2
  %13 = load i64, ptr %12, align 8, !tbaa !8
  %14 = icmp eq i64 %13, 8
  br i1 %14, label %15, label %31

15:                                               ; preds = %4
  %16 = load ptr, ptr %2, align 8, !tbaa !8
  %reass.sub9 = sub nsw i64 %11, %9
  %17 = icmp sgt i64 %reass.sub9, -1
  br i1 %17, label %.lr.ph8.preheader, label %.loopexit

.lr.ph8.preheader:                                ; preds = %15
  %18 = add nuw nsw i64 %reass.sub9, 1
  br label %.lr.ph8

.lr.ph8:                                          ; preds = %.lr.ph8.preheader, %.lr.ph8
  %19 = phi i64 [ %29, %.lr.ph8 ], [ %18, %.lr.ph8.preheader ]
  %20 = phi i32 [ %28, %.lr.ph8 ], [ %8, %.lr.ph8.preheader ]
  %21 = load i32, ptr %5, align 4, !tbaa !4
  %22 = sitofp i32 %21 to float
  %23 = fdiv contract float 1.000000e+00, %22
  %24 = fpext float %23 to double
  %25 = sext i32 %20 to i64
  %26 = add nsw i64 %25, -1
  %27 = getelementptr double, ptr %16, i64 %26
  store double %24, ptr %27, align 8, !tbaa !4
  store double %24, ptr %7, align 8, !tbaa !4
  %28 = add i32 %20, 1
  %29 = add nsw i64 %19, -1
  %30 = icmp ugt i64 %19, 1
  br i1 %30, label %.lr.ph8, label %.loopexit

31:                                               ; preds = %4
  %reass.sub = sub nsw i64 %11, %9
  %32 = icmp sgt i64 %reass.sub, -1
  br i1 %32, label %.lr.ph, label %.loopexit

.lr.ph:                                           ; preds = %31
  %33 = add nuw nsw i64 %reass.sub, 1
  %34 = load ptr, ptr %2, align 8, !tbaa !8
  br label %35

35:                                               ; preds = %.lr.ph, %35
  %36 = phi i64 [ %33, %.lr.ph ], [ %47, %35 ]
  %37 = phi i32 [ %8, %.lr.ph ], [ %46, %35 ]
  %38 = load i32, ptr %5, align 4, !tbaa !4
  %39 = sitofp i32 %38 to float
  %40 = fdiv contract float 1.000000e+00, %39
  %41 = fpext float %40 to double
  %42 = sext i32 %37 to i64
  %43 = add nsw i64 %42, -1
  %44 = mul i64 %43, %13
  %45 = getelementptr i8, ptr %34, i64 %44
  store double %41, ptr %45, align 8, !tbaa !4
  store double %41, ptr %7, align 8, !tbaa !4
  %46 = add i32 %37, 1
  %47 = add nsw i64 %36, -1
  %48 = icmp ugt i64 %36, 1
  br i1 %48, label %35, label %.loopexit

.loopexit:                                        ; preds = %35, %.lr.ph8, %31, %15
  ret void
}
*** IR Dump After CoroSplitPass on (_QFPloop) ***
; Function Attrs: nofree norecurse nosync nounwind memory(readwrite, inaccessiblemem: none)
define void @_QFPloop(ptr nocapture readonly %0, ptr nocapture readonly %1, ptr nocapture readonly %2, ptr nest nocapture readonly %3) local_unnamed_addr #3 {
  %5 = load ptr, ptr %3, align 8, !tbaa !4
  %6 = getelementptr { ptr, ptr }, ptr %3, i64 0, i32 1
  %7 = load ptr, ptr %6, align 8, !tbaa !4
  %8 = load i32, ptr %0, align 4, !tbaa !4
  %9 = sext i32 %8 to i64
  %10 = load i32, ptr %1, align 4, !tbaa !4
  %11 = sext i32 %10 to i64
  %12 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %2, i64 0, i32 7, i64 0, i64 2
  %13 = load i64, ptr %12, align 8, !tbaa !8
  %14 = icmp eq i64 %13, 8
  br i1 %14, label %15, label %31

15:                                               ; preds = %4
  %16 = load ptr, ptr %2, align 8, !tbaa !8
  %reass.sub9 = sub nsw i64 %11, %9
  %17 = icmp sgt i64 %reass.sub9, -1
  br i1 %17, label %.lr.ph8.preheader, label %.loopexit

.lr.ph8.preheader:                                ; preds = %15
  %18 = add nuw nsw i64 %reass.sub9, 1
  br label %.lr.ph8

.lr.ph8:                                          ; preds = %.lr.ph8.preheader, %.lr.ph8
  %19 = phi i64 [ %29, %.lr.ph8 ], [ %18, %.lr.ph8.preheader ]
  %20 = phi i32 [ %28, %.lr.ph8 ], [ %8, %.lr.ph8.preheader ]
  %21 = load i32, ptr %5, align 4, !tbaa !4
  %22 = sitofp i32 %21 to float
  %23 = fdiv contract float 1.000000e+00, %22
  %24 = fpext float %23 to double
  %25 = sext i32 %20 to i64
  %26 = add nsw i64 %25, -1
  %27 = getelementptr double, ptr %16, i64 %26
  store double %24, ptr %27, align 8, !tbaa !4
  store double %24, ptr %7, align 8, !tbaa !4
  %28 = add i32 %20, 1
  %29 = add nsw i64 %19, -1
  %30 = icmp ugt i64 %19, 1
  br i1 %30, label %.lr.ph8, label %.loopexit

31:                                               ; preds = %4
  %reass.sub = sub nsw i64 %11, %9
  %32 = icmp sgt i64 %reass.sub, -1
  br i1 %32, label %.lr.ph, label %.loopexit

.lr.ph:                                           ; preds = %31
  %33 = add nuw nsw i64 %reass.sub, 1
  %34 = load ptr, ptr %2, align 8, !tbaa !8
  br label %35

35:                                               ; preds = %.lr.ph, %35
  %36 = phi i64 [ %33, %.lr.ph ], [ %47, %35 ]
  %37 = phi i32 [ %8, %.lr.ph ], [ %46, %35 ]
  %38 = load i32, ptr %5, align 4, !tbaa !4
  %39 = sitofp i32 %38 to float
  %40 = fdiv contract float 1.000000e+00, %39
  %41 = fpext float %40 to double
  %42 = sext i32 %37 to i64
  %43 = add nsw i64 %42, -1
  %44 = mul i64 %43, %13
  %45 = getelementptr i8, ptr %34, i64 %44
  store double %41, ptr %45, align 8, !tbaa !4
  store double %41, ptr %7, align 8, !tbaa !4
  %46 = add i32 %37, 1
  %47 = add nsw i64 %36, -1
  %48 = icmp ugt i64 %36, 1
  br i1 %48, label %35, label %.loopexit

.loopexit:                                        ; preds = %35, %.lr.ph8, %31, %15
  ret void
}
*** IR Dump After InlinerPass on (_QFPomp_subroutine..omp_par) ***
; Function Attrs: norecurse nounwind
define internal void @_QFPomp_subroutine..omp_par(ptr noalias %tid.addr, ptr noalias %zero.addr, ptr %0) #2 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %gep_3 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 2
  %loadgep_4 = load ptr, ptr %gep_3, align 8
  %gep_5 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 3
  %loadgep_6 = load ptr, ptr %gep_5, align 8
  %gep_7 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 4
  %loadgep_8 = load ptr, ptr %gep_7, align 8
  %1 = alloca i32, align 4
  %2 = alloca i32, align 4
  %3 = call i32 @omp_get_thread_num()
  %4 = call i32 @omp_get_num_threads()
  %5 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %6 = sdiv i32 %5, %4
  %7 = mul i32 %3, %6
  %8 = add i32 %7, 1
  store i32 %8, ptr %1, align 4, !tbaa !4
  %9 = add i32 %4, -1
  %10 = icmp eq i32 %3, %9
  br i1 %10, label %omp.par.region2, label %omp.par.region3

omp.par.region3:                                  ; preds = %omp.par.entry
  %11 = add i32 %8, %6
  br label %omp.par.region4

omp.par.region4:                                  ; preds = %omp.par.region2, %omp.par.region3
  %storemerge = phi i32 [ %11, %omp.par.region3 ], [ %17, %omp.par.region2 ]
  store i32 %storemerge, ptr %2, align 4, !tbaa !4
  %.unpack = load ptr, ptr %loadgep_2, align 8, !tbaa !8
  %.elt14 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  %.unpack15 = load i64, ptr %.elt14, align 8, !tbaa !8
  %.elt16 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  %.unpack17 = load i32, ptr %.elt16, align 8, !tbaa !8
  %.elt18 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  %.unpack19 = load i8, ptr %.elt18, align 4, !tbaa !8
  %.elt20 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  %.unpack21 = load i8, ptr %.elt20, align 1, !tbaa !8
  %.elt22 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  %.unpack23 = load i8, ptr %.elt22, align 2, !tbaa !8
  %.elt24 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  %.unpack25 = load i8, ptr %.elt24, align 1, !tbaa !8
  %.elt26 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  %.unpack27.unpack.unpack = load i64, ptr %.elt26, align 8, !tbaa !8
  %.unpack27.unpack.elt29 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  %.unpack27.unpack.unpack30 = load i64, ptr %.unpack27.unpack.elt29, align 8, !tbaa !8
  %.unpack27.unpack.elt31 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  %.unpack27.unpack.unpack32 = load i64, ptr %.unpack27.unpack.elt31, align 8, !tbaa !8
  store ptr %.unpack, ptr %loadgep_4, align 8, !tbaa !8
  %loadgep_4.repack34 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 1
  store i64 %.unpack15, ptr %loadgep_4.repack34, align 8, !tbaa !8
  %loadgep_4.repack36 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 2
  store i32 %.unpack17, ptr %loadgep_4.repack36, align 8, !tbaa !8
  %loadgep_4.repack38 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 3
  store i8 %.unpack19, ptr %loadgep_4.repack38, align 4, !tbaa !8
  %loadgep_4.repack40 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 4
  store i8 %.unpack21, ptr %loadgep_4.repack40, align 1, !tbaa !8
  %loadgep_4.repack42 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 5
  store i8 %.unpack23, ptr %loadgep_4.repack42, align 2, !tbaa !8
  %loadgep_4.repack44 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 6
  store i8 %.unpack25, ptr %loadgep_4.repack44, align 1, !tbaa !8
  %loadgep_4.repack46 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7
  store i64 %.unpack27.unpack.unpack, ptr %loadgep_4.repack46, align 8, !tbaa !8
  %loadgep_4.repack46.repack48 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack27.unpack.unpack30, ptr %loadgep_4.repack46.repack48, align 8, !tbaa !8
  %loadgep_4.repack46.repack50 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 2
  store i64 %.unpack27.unpack.unpack32, ptr %loadgep_4.repack46.repack50, align 8, !tbaa !8
  %12 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 0
  %13 = load i64, ptr %12, align 8, !tbaa !8
  %14 = load ptr, ptr %loadgep_4, align 8, !tbaa !8
  %15 = icmp eq i64 %.unpack27.unpack.unpack30, 0
  %16 = select i1 %15, i64 1, i64 %13
  store ptr %14, ptr %loadgep_6, align 8, !tbaa !8
  %loadgep_6.repack52 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 1
  store i64 8, ptr %loadgep_6.repack52, align 8, !tbaa !8
  %loadgep_6.repack54 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 2
  store i32 20180515, ptr %loadgep_6.repack54, align 8, !tbaa !8
  %loadgep_6.repack56 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 3
  store i8 1, ptr %loadgep_6.repack56, align 4, !tbaa !8
  %loadgep_6.repack58 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 4
  store i8 28, ptr %loadgep_6.repack58, align 1, !tbaa !8
  %loadgep_6.repack60 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 5
  store i8 0, ptr %loadgep_6.repack60, align 2, !tbaa !8
  %loadgep_6.repack62 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 6
  store i8 0, ptr %loadgep_6.repack62, align 1, !tbaa !8
  %loadgep_6.repack64 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7
  store i64 %16, ptr %loadgep_6.repack64, align 8, !tbaa !8
  %loadgep_6.repack64.repack66 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack27.unpack.unpack30, ptr %loadgep_6.repack64.repack66, align 8, !tbaa !8
  %loadgep_6.repack64.repack68 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7, i64 0, i64 2
  store i64 8, ptr %loadgep_6.repack64.repack68, align 8, !tbaa !8
  call void @_QFPloop(ptr nonnull %1, ptr nonnull %2, ptr nonnull %loadgep_6, ptr %loadgep_8) #4
  ret void

omp.par.region2:                                  ; preds = %omp.par.entry
  %17 = load i32, ptr %loadgep_, align 4, !tbaa !4
  br label %omp.par.region4
}
*** IR Dump After InlinerPass on (_QFPomp_subroutine..omp_par) ***
; Function Attrs: norecurse nounwind
define internal void @_QFPomp_subroutine..omp_par(ptr noalias %tid.addr, ptr noalias %zero.addr, ptr %0) #2 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %gep_3 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 2
  %loadgep_4 = load ptr, ptr %gep_3, align 8
  %gep_5 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 3
  %loadgep_6 = load ptr, ptr %gep_5, align 8
  %gep_7 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 4
  %loadgep_8 = load ptr, ptr %gep_7, align 8
  %1 = alloca i32, align 4
  %2 = alloca i32, align 4
  %3 = call i32 @omp_get_thread_num()
  %4 = call i32 @omp_get_num_threads()
  %5 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %6 = sdiv i32 %5, %4
  %7 = mul i32 %3, %6
  %8 = add i32 %7, 1
  store i32 %8, ptr %1, align 4, !tbaa !4
  %9 = add i32 %4, -1
  %10 = icmp eq i32 %3, %9
  br i1 %10, label %omp.par.region2, label %omp.par.region3

omp.par.region3:                                  ; preds = %omp.par.entry
  %11 = add i32 %8, %6
  br label %omp.par.region4

omp.par.region4:                                  ; preds = %omp.par.region2, %omp.par.region3
  %storemerge = phi i32 [ %11, %omp.par.region3 ], [ %61, %omp.par.region2 ]
  store i32 %storemerge, ptr %2, align 4, !tbaa !4
  %.unpack = load ptr, ptr %loadgep_2, align 8, !tbaa !8
  %.elt14 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  %.unpack15 = load i64, ptr %.elt14, align 8, !tbaa !8
  %.elt16 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  %.unpack17 = load i32, ptr %.elt16, align 8, !tbaa !8
  %.elt18 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  %.unpack19 = load i8, ptr %.elt18, align 4, !tbaa !8
  %.elt20 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  %.unpack21 = load i8, ptr %.elt20, align 1, !tbaa !8
  %.elt22 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  %.unpack23 = load i8, ptr %.elt22, align 2, !tbaa !8
  %.elt24 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  %.unpack25 = load i8, ptr %.elt24, align 1, !tbaa !8
  %.elt26 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  %.unpack27.unpack.unpack = load i64, ptr %.elt26, align 8, !tbaa !8
  %.unpack27.unpack.elt29 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  %.unpack27.unpack.unpack30 = load i64, ptr %.unpack27.unpack.elt29, align 8, !tbaa !8
  %.unpack27.unpack.elt31 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  %.unpack27.unpack.unpack32 = load i64, ptr %.unpack27.unpack.elt31, align 8, !tbaa !8
  store ptr %.unpack, ptr %loadgep_4, align 8, !tbaa !8
  %loadgep_4.repack34 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 1
  store i64 %.unpack15, ptr %loadgep_4.repack34, align 8, !tbaa !8
  %loadgep_4.repack36 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 2
  store i32 %.unpack17, ptr %loadgep_4.repack36, align 8, !tbaa !8
  %loadgep_4.repack38 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 3
  store i8 %.unpack19, ptr %loadgep_4.repack38, align 4, !tbaa !8
  %loadgep_4.repack40 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 4
  store i8 %.unpack21, ptr %loadgep_4.repack40, align 1, !tbaa !8
  %loadgep_4.repack42 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 5
  store i8 %.unpack23, ptr %loadgep_4.repack42, align 2, !tbaa !8
  %loadgep_4.repack44 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 6
  store i8 %.unpack25, ptr %loadgep_4.repack44, align 1, !tbaa !8
  %loadgep_4.repack46 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7
  store i64 %.unpack27.unpack.unpack, ptr %loadgep_4.repack46, align 8, !tbaa !8
  %loadgep_4.repack46.repack48 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack27.unpack.unpack30, ptr %loadgep_4.repack46.repack48, align 8, !tbaa !8
  %loadgep_4.repack46.repack50 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 2
  store i64 %.unpack27.unpack.unpack32, ptr %loadgep_4.repack46.repack50, align 8, !tbaa !8
  %12 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 0
  %13 = load i64, ptr %12, align 8, !tbaa !8
  %14 = load ptr, ptr %loadgep_4, align 8, !tbaa !8
  %15 = icmp eq i64 %.unpack27.unpack.unpack30, 0
  %16 = select i1 %15, i64 1, i64 %13
  store ptr %14, ptr %loadgep_6, align 8, !tbaa !8
  %loadgep_6.repack52 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 1
  store i64 8, ptr %loadgep_6.repack52, align 8, !tbaa !8
  %loadgep_6.repack54 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 2
  store i32 20180515, ptr %loadgep_6.repack54, align 8, !tbaa !8
  %loadgep_6.repack56 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 3
  store i8 1, ptr %loadgep_6.repack56, align 4, !tbaa !8
  %loadgep_6.repack58 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 4
  store i8 28, ptr %loadgep_6.repack58, align 1, !tbaa !8
  %loadgep_6.repack60 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 5
  store i8 0, ptr %loadgep_6.repack60, align 2, !tbaa !8
  %loadgep_6.repack62 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 6
  store i8 0, ptr %loadgep_6.repack62, align 1, !tbaa !8
  %loadgep_6.repack64 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7
  store i64 %16, ptr %loadgep_6.repack64, align 8, !tbaa !8
  %loadgep_6.repack64.repack66 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack27.unpack.unpack30, ptr %loadgep_6.repack64.repack66, align 8, !tbaa !8
  %loadgep_6.repack64.repack68 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7, i64 0, i64 2
  store i64 8, ptr %loadgep_6.repack64.repack68, align 8, !tbaa !8
  %17 = load ptr, ptr %loadgep_8, align 8, !tbaa !4
  %18 = getelementptr { ptr, ptr }, ptr %loadgep_8, i64 0, i32 1
  %19 = load ptr, ptr %18, align 8, !tbaa !4
  %20 = load i32, ptr %1, align 4, !tbaa !4
  %21 = sext i32 %20 to i64
  %22 = load i32, ptr %2, align 4, !tbaa !4
  %23 = sext i32 %22 to i64
  %24 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7, i64 0, i64 2
  %25 = load i64, ptr %24, align 8, !tbaa !8
  %26 = icmp eq i64 %25, 8
  br i1 %26, label %27, label %43

27:                                               ; preds = %omp.par.region4
  %28 = load ptr, ptr %loadgep_6, align 8, !tbaa !8
  %reass.sub9.i = sub nsw i64 %23, %21
  %29 = icmp sgt i64 %reass.sub9.i, -1
  br i1 %29, label %.lr.ph8.preheader.i, label %_QFPloop.exit

.lr.ph8.preheader.i:                              ; preds = %27
  %30 = add nuw nsw i64 %reass.sub9.i, 1
  br label %.lr.ph8.i

.lr.ph8.i:                                        ; preds = %.lr.ph8.i, %.lr.ph8.preheader.i
  %31 = phi i64 [ %41, %.lr.ph8.i ], [ %30, %.lr.ph8.preheader.i ]
  %32 = phi i32 [ %40, %.lr.ph8.i ], [ %20, %.lr.ph8.preheader.i ]
  %33 = load i32, ptr %17, align 4, !tbaa !4
  %34 = sitofp i32 %33 to float
  %35 = fdiv contract float 1.000000e+00, %34
  %36 = fpext float %35 to double
  %37 = sext i32 %32 to i64
  %38 = add nsw i64 %37, -1
  %39 = getelementptr double, ptr %28, i64 %38
  store double %36, ptr %39, align 8, !tbaa !4
  store double %36, ptr %19, align 8, !tbaa !4
  %40 = add i32 %32, 1
  %41 = add nsw i64 %31, -1
  %42 = icmp ugt i64 %31, 1
  br i1 %42, label %.lr.ph8.i, label %_QFPloop.exit

43:                                               ; preds = %omp.par.region4
  %reass.sub.i = sub nsw i64 %23, %21
  %44 = icmp sgt i64 %reass.sub.i, -1
  br i1 %44, label %.lr.ph.i, label %_QFPloop.exit

.lr.ph.i:                                         ; preds = %43
  %45 = add nuw nsw i64 %reass.sub.i, 1
  %46 = load ptr, ptr %loadgep_6, align 8, !tbaa !8
  br label %47

47:                                               ; preds = %47, %.lr.ph.i
  %48 = phi i64 [ %45, %.lr.ph.i ], [ %59, %47 ]
  %49 = phi i32 [ %20, %.lr.ph.i ], [ %58, %47 ]
  %50 = load i32, ptr %17, align 4, !tbaa !4
  %51 = sitofp i32 %50 to float
  %52 = fdiv contract float 1.000000e+00, %51
  %53 = fpext float %52 to double
  %54 = sext i32 %49 to i64
  %55 = add nsw i64 %54, -1
  %56 = mul i64 %55, %25
  %57 = getelementptr i8, ptr %46, i64 %56
  store double %53, ptr %57, align 8, !tbaa !4
  store double %53, ptr %19, align 8, !tbaa !4
  %58 = add i32 %49, 1
  %59 = add nsw i64 %48, -1
  %60 = icmp ugt i64 %48, 1
  br i1 %60, label %47, label %_QFPloop.exit

_QFPloop.exit:                                    ; preds = %27, %.lr.ph8.i, %43, %47
  ret void

omp.par.region2:                                  ; preds = %omp.par.entry
  %61 = load i32, ptr %loadgep_, align 4, !tbaa !4
  br label %omp.par.region4
}
*** IR Dump After PostOrderFunctionAttrsPass on (_QFPomp_subroutine..omp_par) ***
; Function Attrs: norecurse nounwind
define internal void @_QFPomp_subroutine..omp_par(ptr noalias %tid.addr, ptr noalias %zero.addr, ptr %0) #2 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %gep_3 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 2
  %loadgep_4 = load ptr, ptr %gep_3, align 8
  %gep_5 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 3
  %loadgep_6 = load ptr, ptr %gep_5, align 8
  %gep_7 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 4
  %loadgep_8 = load ptr, ptr %gep_7, align 8
  %1 = alloca i32, align 4
  %2 = alloca i32, align 4
  %3 = call i32 @omp_get_thread_num()
  %4 = call i32 @omp_get_num_threads()
  %5 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %6 = sdiv i32 %5, %4
  %7 = mul i32 %3, %6
  %8 = add i32 %7, 1
  store i32 %8, ptr %1, align 4, !tbaa !4
  %9 = add i32 %4, -1
  %10 = icmp eq i32 %3, %9
  br i1 %10, label %omp.par.region2, label %omp.par.region3

omp.par.region3:                                  ; preds = %omp.par.entry
  %11 = add i32 %8, %6
  br label %omp.par.region4

omp.par.region4:                                  ; preds = %omp.par.region2, %omp.par.region3
  %storemerge = phi i32 [ %11, %omp.par.region3 ], [ %61, %omp.par.region2 ]
  store i32 %storemerge, ptr %2, align 4, !tbaa !4
  %.unpack = load ptr, ptr %loadgep_2, align 8, !tbaa !8
  %.elt14 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  %.unpack15 = load i64, ptr %.elt14, align 8, !tbaa !8
  %.elt16 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  %.unpack17 = load i32, ptr %.elt16, align 8, !tbaa !8
  %.elt18 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  %.unpack19 = load i8, ptr %.elt18, align 4, !tbaa !8
  %.elt20 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  %.unpack21 = load i8, ptr %.elt20, align 1, !tbaa !8
  %.elt22 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  %.unpack23 = load i8, ptr %.elt22, align 2, !tbaa !8
  %.elt24 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  %.unpack25 = load i8, ptr %.elt24, align 1, !tbaa !8
  %.elt26 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  %.unpack27.unpack.unpack = load i64, ptr %.elt26, align 8, !tbaa !8
  %.unpack27.unpack.elt29 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  %.unpack27.unpack.unpack30 = load i64, ptr %.unpack27.unpack.elt29, align 8, !tbaa !8
  %.unpack27.unpack.elt31 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  %.unpack27.unpack.unpack32 = load i64, ptr %.unpack27.unpack.elt31, align 8, !tbaa !8
  store ptr %.unpack, ptr %loadgep_4, align 8, !tbaa !8
  %loadgep_4.repack34 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 1
  store i64 %.unpack15, ptr %loadgep_4.repack34, align 8, !tbaa !8
  %loadgep_4.repack36 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 2
  store i32 %.unpack17, ptr %loadgep_4.repack36, align 8, !tbaa !8
  %loadgep_4.repack38 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 3
  store i8 %.unpack19, ptr %loadgep_4.repack38, align 4, !tbaa !8
  %loadgep_4.repack40 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 4
  store i8 %.unpack21, ptr %loadgep_4.repack40, align 1, !tbaa !8
  %loadgep_4.repack42 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 5
  store i8 %.unpack23, ptr %loadgep_4.repack42, align 2, !tbaa !8
  %loadgep_4.repack44 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 6
  store i8 %.unpack25, ptr %loadgep_4.repack44, align 1, !tbaa !8
  %loadgep_4.repack46 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7
  store i64 %.unpack27.unpack.unpack, ptr %loadgep_4.repack46, align 8, !tbaa !8
  %loadgep_4.repack46.repack48 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack27.unpack.unpack30, ptr %loadgep_4.repack46.repack48, align 8, !tbaa !8
  %loadgep_4.repack46.repack50 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 2
  store i64 %.unpack27.unpack.unpack32, ptr %loadgep_4.repack46.repack50, align 8, !tbaa !8
  %12 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 0
  %13 = load i64, ptr %12, align 8, !tbaa !8
  %14 = load ptr, ptr %loadgep_4, align 8, !tbaa !8
  %15 = icmp eq i64 %.unpack27.unpack.unpack30, 0
  %16 = select i1 %15, i64 1, i64 %13
  store ptr %14, ptr %loadgep_6, align 8, !tbaa !8
  %loadgep_6.repack52 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 1
  store i64 8, ptr %loadgep_6.repack52, align 8, !tbaa !8
  %loadgep_6.repack54 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 2
  store i32 20180515, ptr %loadgep_6.repack54, align 8, !tbaa !8
  %loadgep_6.repack56 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 3
  store i8 1, ptr %loadgep_6.repack56, align 4, !tbaa !8
  %loadgep_6.repack58 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 4
  store i8 28, ptr %loadgep_6.repack58, align 1, !tbaa !8
  %loadgep_6.repack60 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 5
  store i8 0, ptr %loadgep_6.repack60, align 2, !tbaa !8
  %loadgep_6.repack62 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 6
  store i8 0, ptr %loadgep_6.repack62, align 1, !tbaa !8
  %loadgep_6.repack64 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7
  store i64 %16, ptr %loadgep_6.repack64, align 8, !tbaa !8
  %loadgep_6.repack64.repack66 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack27.unpack.unpack30, ptr %loadgep_6.repack64.repack66, align 8, !tbaa !8
  %loadgep_6.repack64.repack68 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7, i64 0, i64 2
  store i64 8, ptr %loadgep_6.repack64.repack68, align 8, !tbaa !8
  %17 = load ptr, ptr %loadgep_8, align 8, !tbaa !4
  %18 = getelementptr { ptr, ptr }, ptr %loadgep_8, i64 0, i32 1
  %19 = load ptr, ptr %18, align 8, !tbaa !4
  %20 = load i32, ptr %1, align 4, !tbaa !4
  %21 = sext i32 %20 to i64
  %22 = load i32, ptr %2, align 4, !tbaa !4
  %23 = sext i32 %22 to i64
  %24 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7, i64 0, i64 2
  %25 = load i64, ptr %24, align 8, !tbaa !8
  %26 = icmp eq i64 %25, 8
  br i1 %26, label %27, label %43

27:                                               ; preds = %omp.par.region4
  %28 = load ptr, ptr %loadgep_6, align 8, !tbaa !8
  %reass.sub9.i = sub nsw i64 %23, %21
  %29 = icmp sgt i64 %reass.sub9.i, -1
  br i1 %29, label %.lr.ph8.preheader.i, label %_QFPloop.exit

.lr.ph8.preheader.i:                              ; preds = %27
  %30 = add nuw nsw i64 %reass.sub9.i, 1
  br label %.lr.ph8.i

.lr.ph8.i:                                        ; preds = %.lr.ph8.i, %.lr.ph8.preheader.i
  %31 = phi i64 [ %41, %.lr.ph8.i ], [ %30, %.lr.ph8.preheader.i ]
  %32 = phi i32 [ %40, %.lr.ph8.i ], [ %20, %.lr.ph8.preheader.i ]
  %33 = load i32, ptr %17, align 4, !tbaa !4
  %34 = sitofp i32 %33 to float
  %35 = fdiv contract float 1.000000e+00, %34
  %36 = fpext float %35 to double
  %37 = sext i32 %32 to i64
  %38 = add nsw i64 %37, -1
  %39 = getelementptr double, ptr %28, i64 %38
  store double %36, ptr %39, align 8, !tbaa !4
  store double %36, ptr %19, align 8, !tbaa !4
  %40 = add i32 %32, 1
  %41 = add nsw i64 %31, -1
  %42 = icmp ugt i64 %31, 1
  br i1 %42, label %.lr.ph8.i, label %_QFPloop.exit

43:                                               ; preds = %omp.par.region4
  %reass.sub.i = sub nsw i64 %23, %21
  %44 = icmp sgt i64 %reass.sub.i, -1
  br i1 %44, label %.lr.ph.i, label %_QFPloop.exit

.lr.ph.i:                                         ; preds = %43
  %45 = add nuw nsw i64 %reass.sub.i, 1
  %46 = load ptr, ptr %loadgep_6, align 8, !tbaa !8
  br label %47

47:                                               ; preds = %47, %.lr.ph.i
  %48 = phi i64 [ %45, %.lr.ph.i ], [ %59, %47 ]
  %49 = phi i32 [ %20, %.lr.ph.i ], [ %58, %47 ]
  %50 = load i32, ptr %17, align 4, !tbaa !4
  %51 = sitofp i32 %50 to float
  %52 = fdiv contract float 1.000000e+00, %51
  %53 = fpext float %52 to double
  %54 = sext i32 %49 to i64
  %55 = add nsw i64 %54, -1
  %56 = mul i64 %55, %25
  %57 = getelementptr i8, ptr %46, i64 %56
  store double %53, ptr %57, align 8, !tbaa !4
  store double %53, ptr %19, align 8, !tbaa !4
  %58 = add i32 %49, 1
  %59 = add nsw i64 %48, -1
  %60 = icmp ugt i64 %48, 1
  br i1 %60, label %47, label %_QFPloop.exit

_QFPloop.exit:                                    ; preds = %27, %.lr.ph8.i, %43, %47
  ret void

omp.par.region2:                                  ; preds = %omp.par.entry
  %61 = load i32, ptr %loadgep_, align 4, !tbaa !4
  br label %omp.par.region4
}
*** IR Dump After ArgumentPromotionPass on (_QFPomp_subroutine..omp_par) ***
; Function Attrs: norecurse nounwind
define internal void @_QFPomp_subroutine..omp_par(ptr noalias %tid.addr, ptr noalias %zero.addr, ptr %0) #2 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %gep_3 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 2
  %loadgep_4 = load ptr, ptr %gep_3, align 8
  %gep_5 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 3
  %loadgep_6 = load ptr, ptr %gep_5, align 8
  %gep_7 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 4
  %loadgep_8 = load ptr, ptr %gep_7, align 8
  %1 = alloca i32, align 4
  %2 = alloca i32, align 4
  %3 = call i32 @omp_get_thread_num()
  %4 = call i32 @omp_get_num_threads()
  %5 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %6 = sdiv i32 %5, %4
  %7 = mul i32 %3, %6
  %8 = add i32 %7, 1
  store i32 %8, ptr %1, align 4, !tbaa !4
  %9 = add i32 %4, -1
  %10 = icmp eq i32 %3, %9
  br i1 %10, label %omp.par.region2, label %omp.par.region3

omp.par.region3:                                  ; preds = %omp.par.entry
  %11 = add i32 %8, %6
  br label %omp.par.region4

omp.par.region4:                                  ; preds = %omp.par.region2, %omp.par.region3
  %storemerge = phi i32 [ %11, %omp.par.region3 ], [ %61, %omp.par.region2 ]
  store i32 %storemerge, ptr %2, align 4, !tbaa !4
  %.unpack = load ptr, ptr %loadgep_2, align 8, !tbaa !8
  %.elt14 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  %.unpack15 = load i64, ptr %.elt14, align 8, !tbaa !8
  %.elt16 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  %.unpack17 = load i32, ptr %.elt16, align 8, !tbaa !8
  %.elt18 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  %.unpack19 = load i8, ptr %.elt18, align 4, !tbaa !8
  %.elt20 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  %.unpack21 = load i8, ptr %.elt20, align 1, !tbaa !8
  %.elt22 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  %.unpack23 = load i8, ptr %.elt22, align 2, !tbaa !8
  %.elt24 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  %.unpack25 = load i8, ptr %.elt24, align 1, !tbaa !8
  %.elt26 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  %.unpack27.unpack.unpack = load i64, ptr %.elt26, align 8, !tbaa !8
  %.unpack27.unpack.elt29 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  %.unpack27.unpack.unpack30 = load i64, ptr %.unpack27.unpack.elt29, align 8, !tbaa !8
  %.unpack27.unpack.elt31 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  %.unpack27.unpack.unpack32 = load i64, ptr %.unpack27.unpack.elt31, align 8, !tbaa !8
  store ptr %.unpack, ptr %loadgep_4, align 8, !tbaa !8
  %loadgep_4.repack34 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 1
  store i64 %.unpack15, ptr %loadgep_4.repack34, align 8, !tbaa !8
  %loadgep_4.repack36 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 2
  store i32 %.unpack17, ptr %loadgep_4.repack36, align 8, !tbaa !8
  %loadgep_4.repack38 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 3
  store i8 %.unpack19, ptr %loadgep_4.repack38, align 4, !tbaa !8
  %loadgep_4.repack40 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 4
  store i8 %.unpack21, ptr %loadgep_4.repack40, align 1, !tbaa !8
  %loadgep_4.repack42 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 5
  store i8 %.unpack23, ptr %loadgep_4.repack42, align 2, !tbaa !8
  %loadgep_4.repack44 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 6
  store i8 %.unpack25, ptr %loadgep_4.repack44, align 1, !tbaa !8
  %loadgep_4.repack46 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7
  store i64 %.unpack27.unpack.unpack, ptr %loadgep_4.repack46, align 8, !tbaa !8
  %loadgep_4.repack46.repack48 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack27.unpack.unpack30, ptr %loadgep_4.repack46.repack48, align 8, !tbaa !8
  %loadgep_4.repack46.repack50 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 2
  store i64 %.unpack27.unpack.unpack32, ptr %loadgep_4.repack46.repack50, align 8, !tbaa !8
  %12 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 0
  %13 = load i64, ptr %12, align 8, !tbaa !8
  %14 = load ptr, ptr %loadgep_4, align 8, !tbaa !8
  %15 = icmp eq i64 %.unpack27.unpack.unpack30, 0
  %16 = select i1 %15, i64 1, i64 %13
  store ptr %14, ptr %loadgep_6, align 8, !tbaa !8
  %loadgep_6.repack52 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 1
  store i64 8, ptr %loadgep_6.repack52, align 8, !tbaa !8
  %loadgep_6.repack54 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 2
  store i32 20180515, ptr %loadgep_6.repack54, align 8, !tbaa !8
  %loadgep_6.repack56 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 3
  store i8 1, ptr %loadgep_6.repack56, align 4, !tbaa !8
  %loadgep_6.repack58 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 4
  store i8 28, ptr %loadgep_6.repack58, align 1, !tbaa !8
  %loadgep_6.repack60 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 5
  store i8 0, ptr %loadgep_6.repack60, align 2, !tbaa !8
  %loadgep_6.repack62 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 6
  store i8 0, ptr %loadgep_6.repack62, align 1, !tbaa !8
  %loadgep_6.repack64 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7
  store i64 %16, ptr %loadgep_6.repack64, align 8, !tbaa !8
  %loadgep_6.repack64.repack66 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack27.unpack.unpack30, ptr %loadgep_6.repack64.repack66, align 8, !tbaa !8
  %loadgep_6.repack64.repack68 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7, i64 0, i64 2
  store i64 8, ptr %loadgep_6.repack64.repack68, align 8, !tbaa !8
  %17 = load ptr, ptr %loadgep_8, align 8, !tbaa !4
  %18 = getelementptr { ptr, ptr }, ptr %loadgep_8, i64 0, i32 1
  %19 = load ptr, ptr %18, align 8, !tbaa !4
  %20 = load i32, ptr %1, align 4, !tbaa !4
  %21 = sext i32 %20 to i64
  %22 = load i32, ptr %2, align 4, !tbaa !4
  %23 = sext i32 %22 to i64
  %24 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7, i64 0, i64 2
  %25 = load i64, ptr %24, align 8, !tbaa !8
  %26 = icmp eq i64 %25, 8
  br i1 %26, label %27, label %43

27:                                               ; preds = %omp.par.region4
  %28 = load ptr, ptr %loadgep_6, align 8, !tbaa !8
  %reass.sub9.i = sub nsw i64 %23, %21
  %29 = icmp sgt i64 %reass.sub9.i, -1
  br i1 %29, label %.lr.ph8.preheader.i, label %_QFPloop.exit

.lr.ph8.preheader.i:                              ; preds = %27
  %30 = add nuw nsw i64 %reass.sub9.i, 1
  br label %.lr.ph8.i

.lr.ph8.i:                                        ; preds = %.lr.ph8.i, %.lr.ph8.preheader.i
  %31 = phi i64 [ %41, %.lr.ph8.i ], [ %30, %.lr.ph8.preheader.i ]
  %32 = phi i32 [ %40, %.lr.ph8.i ], [ %20, %.lr.ph8.preheader.i ]
  %33 = load i32, ptr %17, align 4, !tbaa !4
  %34 = sitofp i32 %33 to float
  %35 = fdiv contract float 1.000000e+00, %34
  %36 = fpext float %35 to double
  %37 = sext i32 %32 to i64
  %38 = add nsw i64 %37, -1
  %39 = getelementptr double, ptr %28, i64 %38
  store double %36, ptr %39, align 8, !tbaa !4
  store double %36, ptr %19, align 8, !tbaa !4
  %40 = add i32 %32, 1
  %41 = add nsw i64 %31, -1
  %42 = icmp ugt i64 %31, 1
  br i1 %42, label %.lr.ph8.i, label %_QFPloop.exit

43:                                               ; preds = %omp.par.region4
  %reass.sub.i = sub nsw i64 %23, %21
  %44 = icmp sgt i64 %reass.sub.i, -1
  br i1 %44, label %.lr.ph.i, label %_QFPloop.exit

.lr.ph.i:                                         ; preds = %43
  %45 = add nuw nsw i64 %reass.sub.i, 1
  %46 = load ptr, ptr %loadgep_6, align 8, !tbaa !8
  br label %47

47:                                               ; preds = %47, %.lr.ph.i
  %48 = phi i64 [ %45, %.lr.ph.i ], [ %59, %47 ]
  %49 = phi i32 [ %20, %.lr.ph.i ], [ %58, %47 ]
  %50 = load i32, ptr %17, align 4, !tbaa !4
  %51 = sitofp i32 %50 to float
  %52 = fdiv contract float 1.000000e+00, %51
  %53 = fpext float %52 to double
  %54 = sext i32 %49 to i64
  %55 = add nsw i64 %54, -1
  %56 = mul i64 %55, %25
  %57 = getelementptr i8, ptr %46, i64 %56
  store double %53, ptr %57, align 8, !tbaa !4
  store double %53, ptr %19, align 8, !tbaa !4
  %58 = add i32 %49, 1
  %59 = add nsw i64 %48, -1
  %60 = icmp ugt i64 %48, 1
  br i1 %60, label %47, label %_QFPloop.exit

_QFPloop.exit:                                    ; preds = %27, %.lr.ph8.i, %43, %47
  ret void

omp.par.region2:                                  ; preds = %omp.par.entry
  %61 = load i32, ptr %loadgep_, align 4, !tbaa !4
  br label %omp.par.region4
}
*** IR Dump After OpenMPOptCGSCCPass on (_QFPomp_subroutine..omp_par) ***
; Function Attrs: norecurse nounwind
define internal void @_QFPomp_subroutine..omp_par(ptr noalias %tid.addr, ptr noalias %zero.addr, ptr %0) #2 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %gep_3 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 2
  %loadgep_4 = load ptr, ptr %gep_3, align 8
  %gep_5 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 3
  %loadgep_6 = load ptr, ptr %gep_5, align 8
  %gep_7 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 4
  %loadgep_8 = load ptr, ptr %gep_7, align 8
  %1 = alloca i32, align 4
  %2 = alloca i32, align 4
  %3 = call i32 @omp_get_thread_num()
  %4 = call i32 @omp_get_num_threads()
  %5 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %6 = sdiv i32 %5, %4
  %7 = mul i32 %3, %6
  %8 = add i32 %7, 1
  store i32 %8, ptr %1, align 4, !tbaa !4
  %9 = add i32 %4, -1
  %10 = icmp eq i32 %3, %9
  br i1 %10, label %omp.par.region2, label %omp.par.region3

omp.par.region3:                                  ; preds = %omp.par.entry
  %11 = add i32 %8, %6
  br label %omp.par.region4

omp.par.region4:                                  ; preds = %omp.par.region2, %omp.par.region3
  %storemerge = phi i32 [ %11, %omp.par.region3 ], [ %61, %omp.par.region2 ]
  store i32 %storemerge, ptr %2, align 4, !tbaa !4
  %.unpack = load ptr, ptr %loadgep_2, align 8, !tbaa !8
  %.elt14 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  %.unpack15 = load i64, ptr %.elt14, align 8, !tbaa !8
  %.elt16 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  %.unpack17 = load i32, ptr %.elt16, align 8, !tbaa !8
  %.elt18 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  %.unpack19 = load i8, ptr %.elt18, align 4, !tbaa !8
  %.elt20 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  %.unpack21 = load i8, ptr %.elt20, align 1, !tbaa !8
  %.elt22 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  %.unpack23 = load i8, ptr %.elt22, align 2, !tbaa !8
  %.elt24 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  %.unpack25 = load i8, ptr %.elt24, align 1, !tbaa !8
  %.elt26 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  %.unpack27.unpack.unpack = load i64, ptr %.elt26, align 8, !tbaa !8
  %.unpack27.unpack.elt29 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  %.unpack27.unpack.unpack30 = load i64, ptr %.unpack27.unpack.elt29, align 8, !tbaa !8
  %.unpack27.unpack.elt31 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  %.unpack27.unpack.unpack32 = load i64, ptr %.unpack27.unpack.elt31, align 8, !tbaa !8
  store ptr %.unpack, ptr %loadgep_4, align 8, !tbaa !8
  %loadgep_4.repack34 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 1
  store i64 %.unpack15, ptr %loadgep_4.repack34, align 8, !tbaa !8
  %loadgep_4.repack36 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 2
  store i32 %.unpack17, ptr %loadgep_4.repack36, align 8, !tbaa !8
  %loadgep_4.repack38 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 3
  store i8 %.unpack19, ptr %loadgep_4.repack38, align 4, !tbaa !8
  %loadgep_4.repack40 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 4
  store i8 %.unpack21, ptr %loadgep_4.repack40, align 1, !tbaa !8
  %loadgep_4.repack42 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 5
  store i8 %.unpack23, ptr %loadgep_4.repack42, align 2, !tbaa !8
  %loadgep_4.repack44 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 6
  store i8 %.unpack25, ptr %loadgep_4.repack44, align 1, !tbaa !8
  %loadgep_4.repack46 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7
  store i64 %.unpack27.unpack.unpack, ptr %loadgep_4.repack46, align 8, !tbaa !8
  %loadgep_4.repack46.repack48 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack27.unpack.unpack30, ptr %loadgep_4.repack46.repack48, align 8, !tbaa !8
  %loadgep_4.repack46.repack50 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 2
  store i64 %.unpack27.unpack.unpack32, ptr %loadgep_4.repack46.repack50, align 8, !tbaa !8
  %12 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 0
  %13 = load i64, ptr %12, align 8, !tbaa !8
  %14 = load ptr, ptr %loadgep_4, align 8, !tbaa !8
  %15 = icmp eq i64 %.unpack27.unpack.unpack30, 0
  %16 = select i1 %15, i64 1, i64 %13
  store ptr %14, ptr %loadgep_6, align 8, !tbaa !8
  %loadgep_6.repack52 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 1
  store i64 8, ptr %loadgep_6.repack52, align 8, !tbaa !8
  %loadgep_6.repack54 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 2
  store i32 20180515, ptr %loadgep_6.repack54, align 8, !tbaa !8
  %loadgep_6.repack56 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 3
  store i8 1, ptr %loadgep_6.repack56, align 4, !tbaa !8
  %loadgep_6.repack58 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 4
  store i8 28, ptr %loadgep_6.repack58, align 1, !tbaa !8
  %loadgep_6.repack60 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 5
  store i8 0, ptr %loadgep_6.repack60, align 2, !tbaa !8
  %loadgep_6.repack62 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 6
  store i8 0, ptr %loadgep_6.repack62, align 1, !tbaa !8
  %loadgep_6.repack64 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7
  store i64 %16, ptr %loadgep_6.repack64, align 8, !tbaa !8
  %loadgep_6.repack64.repack66 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack27.unpack.unpack30, ptr %loadgep_6.repack64.repack66, align 8, !tbaa !8
  %loadgep_6.repack64.repack68 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7, i64 0, i64 2
  store i64 8, ptr %loadgep_6.repack64.repack68, align 8, !tbaa !8
  %17 = load ptr, ptr %loadgep_8, align 8, !tbaa !4
  %18 = getelementptr { ptr, ptr }, ptr %loadgep_8, i64 0, i32 1
  %19 = load ptr, ptr %18, align 8, !tbaa !4
  %20 = load i32, ptr %1, align 4, !tbaa !4
  %21 = sext i32 %20 to i64
  %22 = load i32, ptr %2, align 4, !tbaa !4
  %23 = sext i32 %22 to i64
  %24 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7, i64 0, i64 2
  %25 = load i64, ptr %24, align 8, !tbaa !8
  %26 = icmp eq i64 %25, 8
  br i1 %26, label %27, label %43

27:                                               ; preds = %omp.par.region4
  %28 = load ptr, ptr %loadgep_6, align 8, !tbaa !8
  %reass.sub9.i = sub nsw i64 %23, %21
  %29 = icmp sgt i64 %reass.sub9.i, -1
  br i1 %29, label %.lr.ph8.preheader.i, label %_QFPloop.exit

.lr.ph8.preheader.i:                              ; preds = %27
  %30 = add nuw nsw i64 %reass.sub9.i, 1
  br label %.lr.ph8.i

.lr.ph8.i:                                        ; preds = %.lr.ph8.i, %.lr.ph8.preheader.i
  %31 = phi i64 [ %41, %.lr.ph8.i ], [ %30, %.lr.ph8.preheader.i ]
  %32 = phi i32 [ %40, %.lr.ph8.i ], [ %20, %.lr.ph8.preheader.i ]
  %33 = load i32, ptr %17, align 4, !tbaa !4
  %34 = sitofp i32 %33 to float
  %35 = fdiv contract float 1.000000e+00, %34
  %36 = fpext float %35 to double
  %37 = sext i32 %32 to i64
  %38 = add nsw i64 %37, -1
  %39 = getelementptr double, ptr %28, i64 %38
  store double %36, ptr %39, align 8, !tbaa !4
  store double %36, ptr %19, align 8, !tbaa !4
  %40 = add i32 %32, 1
  %41 = add nsw i64 %31, -1
  %42 = icmp ugt i64 %31, 1
  br i1 %42, label %.lr.ph8.i, label %_QFPloop.exit

43:                                               ; preds = %omp.par.region4
  %reass.sub.i = sub nsw i64 %23, %21
  %44 = icmp sgt i64 %reass.sub.i, -1
  br i1 %44, label %.lr.ph.i, label %_QFPloop.exit

.lr.ph.i:                                         ; preds = %43
  %45 = add nuw nsw i64 %reass.sub.i, 1
  %46 = load ptr, ptr %loadgep_6, align 8, !tbaa !8
  br label %47

47:                                               ; preds = %47, %.lr.ph.i
  %48 = phi i64 [ %45, %.lr.ph.i ], [ %59, %47 ]
  %49 = phi i32 [ %20, %.lr.ph.i ], [ %58, %47 ]
  %50 = load i32, ptr %17, align 4, !tbaa !4
  %51 = sitofp i32 %50 to float
  %52 = fdiv contract float 1.000000e+00, %51
  %53 = fpext float %52 to double
  %54 = sext i32 %49 to i64
  %55 = add nsw i64 %54, -1
  %56 = mul i64 %55, %25
  %57 = getelementptr i8, ptr %46, i64 %56
  store double %53, ptr %57, align 8, !tbaa !4
  store double %53, ptr %19, align 8, !tbaa !4
  %58 = add i32 %49, 1
  %59 = add nsw i64 %48, -1
  %60 = icmp ugt i64 %48, 1
  br i1 %60, label %47, label %_QFPloop.exit

_QFPloop.exit:                                    ; preds = %27, %.lr.ph8.i, %43, %47
  ret void

omp.par.region2:                                  ; preds = %omp.par.entry
  %61 = load i32, ptr %loadgep_, align 4, !tbaa !4
  br label %omp.par.region4
}
*** IR Dump After SROAPass on _QFPomp_subroutine..omp_par ***
; Function Attrs: norecurse nounwind
define internal void @_QFPomp_subroutine..omp_par(ptr noalias %tid.addr, ptr noalias %zero.addr, ptr %0) #2 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %gep_3 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 2
  %loadgep_4 = load ptr, ptr %gep_3, align 8
  %gep_5 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 3
  %loadgep_6 = load ptr, ptr %gep_5, align 8
  %gep_7 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 4
  %loadgep_8 = load ptr, ptr %gep_7, align 8
  %1 = call i32 @omp_get_thread_num()
  %2 = call i32 @omp_get_num_threads()
  %3 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %4 = sdiv i32 %3, %2
  %5 = mul i32 %1, %4
  %6 = add i32 %5, 1
  %7 = add i32 %2, -1
  %8 = icmp eq i32 %1, %7
  br i1 %8, label %omp.par.region2, label %omp.par.region3

omp.par.region3:                                  ; preds = %omp.par.entry
  %9 = add i32 %6, %4
  br label %omp.par.region4

omp.par.region4:                                  ; preds = %omp.par.region2, %omp.par.region3
  %storemerge = phi i32 [ %9, %omp.par.region3 ], [ %57, %omp.par.region2 ]
  %.unpack = load ptr, ptr %loadgep_2, align 8, !tbaa !8
  %.elt14 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  %.unpack15 = load i64, ptr %.elt14, align 8, !tbaa !8
  %.elt16 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  %.unpack17 = load i32, ptr %.elt16, align 8, !tbaa !8
  %.elt18 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  %.unpack19 = load i8, ptr %.elt18, align 4, !tbaa !8
  %.elt20 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  %.unpack21 = load i8, ptr %.elt20, align 1, !tbaa !8
  %.elt22 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  %.unpack23 = load i8, ptr %.elt22, align 2, !tbaa !8
  %.elt24 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  %.unpack25 = load i8, ptr %.elt24, align 1, !tbaa !8
  %.elt26 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  %.unpack27.unpack.unpack = load i64, ptr %.elt26, align 8, !tbaa !8
  %.unpack27.unpack.elt29 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  %.unpack27.unpack.unpack30 = load i64, ptr %.unpack27.unpack.elt29, align 8, !tbaa !8
  %.unpack27.unpack.elt31 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  %.unpack27.unpack.unpack32 = load i64, ptr %.unpack27.unpack.elt31, align 8, !tbaa !8
  store ptr %.unpack, ptr %loadgep_4, align 8, !tbaa !8
  %loadgep_4.repack34 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 1
  store i64 %.unpack15, ptr %loadgep_4.repack34, align 8, !tbaa !8
  %loadgep_4.repack36 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 2
  store i32 %.unpack17, ptr %loadgep_4.repack36, align 8, !tbaa !8
  %loadgep_4.repack38 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 3
  store i8 %.unpack19, ptr %loadgep_4.repack38, align 4, !tbaa !8
  %loadgep_4.repack40 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 4
  store i8 %.unpack21, ptr %loadgep_4.repack40, align 1, !tbaa !8
  %loadgep_4.repack42 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 5
  store i8 %.unpack23, ptr %loadgep_4.repack42, align 2, !tbaa !8
  %loadgep_4.repack44 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 6
  store i8 %.unpack25, ptr %loadgep_4.repack44, align 1, !tbaa !8
  %loadgep_4.repack46 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7
  store i64 %.unpack27.unpack.unpack, ptr %loadgep_4.repack46, align 8, !tbaa !8
  %loadgep_4.repack46.repack48 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack27.unpack.unpack30, ptr %loadgep_4.repack46.repack48, align 8, !tbaa !8
  %loadgep_4.repack46.repack50 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 2
  store i64 %.unpack27.unpack.unpack32, ptr %loadgep_4.repack46.repack50, align 8, !tbaa !8
  %10 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 0
  %11 = load i64, ptr %10, align 8, !tbaa !8
  %12 = load ptr, ptr %loadgep_4, align 8, !tbaa !8
  %13 = icmp eq i64 %.unpack27.unpack.unpack30, 0
  %14 = select i1 %13, i64 1, i64 %11
  store ptr %12, ptr %loadgep_6, align 8, !tbaa !8
  %loadgep_6.repack52 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 1
  store i64 8, ptr %loadgep_6.repack52, align 8, !tbaa !8
  %loadgep_6.repack54 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 2
  store i32 20180515, ptr %loadgep_6.repack54, align 8, !tbaa !8
  %loadgep_6.repack56 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 3
  store i8 1, ptr %loadgep_6.repack56, align 4, !tbaa !8
  %loadgep_6.repack58 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 4
  store i8 28, ptr %loadgep_6.repack58, align 1, !tbaa !8
  %loadgep_6.repack60 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 5
  store i8 0, ptr %loadgep_6.repack60, align 2, !tbaa !8
  %loadgep_6.repack62 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 6
  store i8 0, ptr %loadgep_6.repack62, align 1, !tbaa !8
  %loadgep_6.repack64 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7
  store i64 %14, ptr %loadgep_6.repack64, align 8, !tbaa !8
  %loadgep_6.repack64.repack66 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack27.unpack.unpack30, ptr %loadgep_6.repack64.repack66, align 8, !tbaa !8
  %loadgep_6.repack64.repack68 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7, i64 0, i64 2
  store i64 8, ptr %loadgep_6.repack64.repack68, align 8, !tbaa !8
  %15 = load ptr, ptr %loadgep_8, align 8, !tbaa !4
  %16 = getelementptr { ptr, ptr }, ptr %loadgep_8, i64 0, i32 1
  %17 = load ptr, ptr %16, align 8, !tbaa !4
  %18 = sext i32 %6 to i64
  %19 = sext i32 %storemerge to i64
  %20 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7, i64 0, i64 2
  %21 = load i64, ptr %20, align 8, !tbaa !8
  %22 = icmp eq i64 %21, 8
  br i1 %22, label %23, label %39

23:                                               ; preds = %omp.par.region4
  %24 = load ptr, ptr %loadgep_6, align 8, !tbaa !8
  %reass.sub9.i = sub nsw i64 %19, %18
  %25 = icmp sgt i64 %reass.sub9.i, -1
  br i1 %25, label %.lr.ph8.preheader.i, label %_QFPloop.exit

.lr.ph8.preheader.i:                              ; preds = %23
  %26 = add nuw nsw i64 %reass.sub9.i, 1
  br label %.lr.ph8.i

.lr.ph8.i:                                        ; preds = %.lr.ph8.i, %.lr.ph8.preheader.i
  %27 = phi i64 [ %37, %.lr.ph8.i ], [ %26, %.lr.ph8.preheader.i ]
  %28 = phi i32 [ %36, %.lr.ph8.i ], [ %6, %.lr.ph8.preheader.i ]
  %29 = load i32, ptr %15, align 4, !tbaa !4
  %30 = sitofp i32 %29 to float
  %31 = fdiv contract float 1.000000e+00, %30
  %32 = fpext float %31 to double
  %33 = sext i32 %28 to i64
  %34 = add nsw i64 %33, -1
  %35 = getelementptr double, ptr %24, i64 %34
  store double %32, ptr %35, align 8, !tbaa !4
  store double %32, ptr %17, align 8, !tbaa !4
  %36 = add i32 %28, 1
  %37 = add nsw i64 %27, -1
  %38 = icmp ugt i64 %27, 1
  br i1 %38, label %.lr.ph8.i, label %_QFPloop.exit

39:                                               ; preds = %omp.par.region4
  %reass.sub.i = sub nsw i64 %19, %18
  %40 = icmp sgt i64 %reass.sub.i, -1
  br i1 %40, label %.lr.ph.i, label %_QFPloop.exit

.lr.ph.i:                                         ; preds = %39
  %41 = add nuw nsw i64 %reass.sub.i, 1
  %42 = load ptr, ptr %loadgep_6, align 8, !tbaa !8
  br label %43

43:                                               ; preds = %43, %.lr.ph.i
  %44 = phi i64 [ %41, %.lr.ph.i ], [ %55, %43 ]
  %45 = phi i32 [ %6, %.lr.ph.i ], [ %54, %43 ]
  %46 = load i32, ptr %15, align 4, !tbaa !4
  %47 = sitofp i32 %46 to float
  %48 = fdiv contract float 1.000000e+00, %47
  %49 = fpext float %48 to double
  %50 = sext i32 %45 to i64
  %51 = add nsw i64 %50, -1
  %52 = mul i64 %51, %21
  %53 = getelementptr i8, ptr %42, i64 %52
  store double %49, ptr %53, align 8, !tbaa !4
  store double %49, ptr %17, align 8, !tbaa !4
  %54 = add i32 %45, 1
  %55 = add nsw i64 %44, -1
  %56 = icmp ugt i64 %44, 1
  br i1 %56, label %43, label %_QFPloop.exit

_QFPloop.exit:                                    ; preds = %23, %.lr.ph8.i, %39, %43
  ret void

omp.par.region2:                                  ; preds = %omp.par.entry
  %57 = load i32, ptr %loadgep_, align 4, !tbaa !4
  br label %omp.par.region4
}
*** IR Dump After EarlyCSEPass on _QFPomp_subroutine..omp_par ***
; Function Attrs: norecurse nounwind
define internal void @_QFPomp_subroutine..omp_par(ptr noalias %tid.addr, ptr noalias %zero.addr, ptr %0) #2 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %gep_3 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 2
  %loadgep_4 = load ptr, ptr %gep_3, align 8
  %gep_5 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 3
  %loadgep_6 = load ptr, ptr %gep_5, align 8
  %gep_7 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 4
  %loadgep_8 = load ptr, ptr %gep_7, align 8
  %1 = call i32 @omp_get_thread_num()
  %2 = call i32 @omp_get_num_threads()
  %3 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %4 = sdiv i32 %3, %2
  %5 = mul i32 %1, %4
  %6 = add i32 %5, 1
  %7 = add i32 %2, -1
  %8 = icmp eq i32 %1, %7
  br i1 %8, label %omp.par.region2, label %omp.par.region3

omp.par.region3:                                  ; preds = %omp.par.entry
  %9 = add i32 %6, %4
  br label %omp.par.region4

omp.par.region4:                                  ; preds = %omp.par.region2, %omp.par.region3
  %storemerge = phi i32 [ %9, %omp.par.region3 ], [ %3, %omp.par.region2 ]
  %.unpack = load ptr, ptr %loadgep_2, align 8, !tbaa !8
  %.elt14 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  %.unpack15 = load i64, ptr %.elt14, align 8, !tbaa !8
  %.elt16 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  %.unpack17 = load i32, ptr %.elt16, align 8, !tbaa !8
  %.elt18 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  %.unpack19 = load i8, ptr %.elt18, align 4, !tbaa !8
  %.elt20 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  %.unpack21 = load i8, ptr %.elt20, align 1, !tbaa !8
  %.elt22 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  %.unpack23 = load i8, ptr %.elt22, align 2, !tbaa !8
  %.elt24 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  %.unpack25 = load i8, ptr %.elt24, align 1, !tbaa !8
  %.elt26 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  %.unpack27.unpack.unpack = load i64, ptr %.elt26, align 8, !tbaa !8
  %.unpack27.unpack.elt29 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  %.unpack27.unpack.unpack30 = load i64, ptr %.unpack27.unpack.elt29, align 8, !tbaa !8
  %.unpack27.unpack.elt31 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  %.unpack27.unpack.unpack32 = load i64, ptr %.unpack27.unpack.elt31, align 8, !tbaa !8
  store ptr %.unpack, ptr %loadgep_4, align 8, !tbaa !8
  %loadgep_4.repack34 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 1
  store i64 %.unpack15, ptr %loadgep_4.repack34, align 8, !tbaa !8
  %loadgep_4.repack36 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 2
  store i32 %.unpack17, ptr %loadgep_4.repack36, align 8, !tbaa !8
  %loadgep_4.repack38 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 3
  store i8 %.unpack19, ptr %loadgep_4.repack38, align 4, !tbaa !8
  %loadgep_4.repack40 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 4
  store i8 %.unpack21, ptr %loadgep_4.repack40, align 1, !tbaa !8
  %loadgep_4.repack42 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 5
  store i8 %.unpack23, ptr %loadgep_4.repack42, align 2, !tbaa !8
  %loadgep_4.repack44 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 6
  store i8 %.unpack25, ptr %loadgep_4.repack44, align 1, !tbaa !8
  %loadgep_4.repack46 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7
  store i64 %.unpack27.unpack.unpack, ptr %loadgep_4.repack46, align 8, !tbaa !8
  %loadgep_4.repack46.repack48 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack27.unpack.unpack30, ptr %loadgep_4.repack46.repack48, align 8, !tbaa !8
  %loadgep_4.repack46.repack50 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 2
  store i64 %.unpack27.unpack.unpack32, ptr %loadgep_4.repack46.repack50, align 8, !tbaa !8
  %10 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 0
  %11 = load i64, ptr %10, align 8, !tbaa !8
  %12 = icmp eq i64 %.unpack27.unpack.unpack30, 0
  %13 = select i1 %12, i64 1, i64 %11
  store ptr %.unpack, ptr %loadgep_6, align 8, !tbaa !8
  %loadgep_6.repack52 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 1
  store i64 8, ptr %loadgep_6.repack52, align 8, !tbaa !8
  %loadgep_6.repack54 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 2
  store i32 20180515, ptr %loadgep_6.repack54, align 8, !tbaa !8
  %loadgep_6.repack56 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 3
  store i8 1, ptr %loadgep_6.repack56, align 4, !tbaa !8
  %loadgep_6.repack58 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 4
  store i8 28, ptr %loadgep_6.repack58, align 1, !tbaa !8
  %loadgep_6.repack60 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 5
  store i8 0, ptr %loadgep_6.repack60, align 2, !tbaa !8
  %loadgep_6.repack62 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 6
  store i8 0, ptr %loadgep_6.repack62, align 1, !tbaa !8
  %loadgep_6.repack64 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7
  store i64 %13, ptr %loadgep_6.repack64, align 8, !tbaa !8
  %loadgep_6.repack64.repack66 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack27.unpack.unpack30, ptr %loadgep_6.repack64.repack66, align 8, !tbaa !8
  %loadgep_6.repack64.repack68 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7, i64 0, i64 2
  store i64 8, ptr %loadgep_6.repack64.repack68, align 8, !tbaa !8
  %14 = load ptr, ptr %loadgep_8, align 8, !tbaa !4
  %15 = getelementptr { ptr, ptr }, ptr %loadgep_8, i64 0, i32 1
  %16 = load ptr, ptr %15, align 8, !tbaa !4
  %17 = sext i32 %6 to i64
  %18 = sext i32 %storemerge to i64
  br i1 true, label %19, label %34

19:                                               ; preds = %omp.par.region4
  %reass.sub9.i = sub nsw i64 %18, %17
  %20 = icmp sgt i64 %reass.sub9.i, -1
  br i1 %20, label %.lr.ph8.preheader.i, label %_QFPloop.exit

.lr.ph8.preheader.i:                              ; preds = %19
  %21 = add nuw nsw i64 %reass.sub9.i, 1
  br label %.lr.ph8.i

.lr.ph8.i:                                        ; preds = %.lr.ph8.i, %.lr.ph8.preheader.i
  %22 = phi i64 [ %32, %.lr.ph8.i ], [ %21, %.lr.ph8.preheader.i ]
  %23 = phi i32 [ %31, %.lr.ph8.i ], [ %6, %.lr.ph8.preheader.i ]
  %24 = load i32, ptr %14, align 4, !tbaa !4
  %25 = sitofp i32 %24 to float
  %26 = fdiv contract float 1.000000e+00, %25
  %27 = fpext float %26 to double
  %28 = sext i32 %23 to i64
  %29 = add nsw i64 %28, -1
  %30 = getelementptr double, ptr %.unpack, i64 %29
  store double %27, ptr %30, align 8, !tbaa !4
  store double %27, ptr %16, align 8, !tbaa !4
  %31 = add i32 %23, 1
  %32 = add nsw i64 %22, -1
  %33 = icmp ugt i64 %22, 1
  br i1 %33, label %.lr.ph8.i, label %_QFPloop.exit

34:                                               ; preds = %omp.par.region4
  %reass.sub.i = sub nsw i64 %18, %17
  %35 = icmp sgt i64 %reass.sub.i, -1
  br i1 %35, label %.lr.ph.i, label %_QFPloop.exit

.lr.ph.i:                                         ; preds = %34
  %36 = add nuw nsw i64 %reass.sub.i, 1
  br label %37

37:                                               ; preds = %37, %.lr.ph.i
  %38 = phi i64 [ %36, %.lr.ph.i ], [ %49, %37 ]
  %39 = phi i32 [ %6, %.lr.ph.i ], [ %48, %37 ]
  %40 = load i32, ptr %14, align 4, !tbaa !4
  %41 = sitofp i32 %40 to float
  %42 = fdiv contract float 1.000000e+00, %41
  %43 = fpext float %42 to double
  %44 = sext i32 %39 to i64
  %45 = add nsw i64 %44, -1
  %46 = mul i64 %45, 8
  %47 = getelementptr i8, ptr %.unpack, i64 %46
  store double %43, ptr %47, align 8, !tbaa !4
  store double %43, ptr %16, align 8, !tbaa !4
  %48 = add i32 %39, 1
  %49 = add nsw i64 %38, -1
  %50 = icmp ugt i64 %38, 1
  br i1 %50, label %37, label %_QFPloop.exit

_QFPloop.exit:                                    ; preds = %19, %.lr.ph8.i, %34, %37
  ret void

omp.par.region2:                                  ; preds = %omp.par.entry
  br label %omp.par.region4
}
*** IR Dump After SpeculativeExecutionPass on _QFPomp_subroutine..omp_par ***
; Function Attrs: norecurse nounwind
define internal void @_QFPomp_subroutine..omp_par(ptr noalias %tid.addr, ptr noalias %zero.addr, ptr %0) #2 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %gep_3 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 2
  %loadgep_4 = load ptr, ptr %gep_3, align 8
  %gep_5 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 3
  %loadgep_6 = load ptr, ptr %gep_5, align 8
  %gep_7 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 4
  %loadgep_8 = load ptr, ptr %gep_7, align 8
  %1 = call i32 @omp_get_thread_num()
  %2 = call i32 @omp_get_num_threads()
  %3 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %4 = sdiv i32 %3, %2
  %5 = mul i32 %1, %4
  %6 = add i32 %5, 1
  %7 = add i32 %2, -1
  %8 = icmp eq i32 %1, %7
  br i1 %8, label %omp.par.region2, label %omp.par.region3

omp.par.region3:                                  ; preds = %omp.par.entry
  %9 = add i32 %6, %4
  br label %omp.par.region4

omp.par.region4:                                  ; preds = %omp.par.region2, %omp.par.region3
  %storemerge = phi i32 [ %9, %omp.par.region3 ], [ %3, %omp.par.region2 ]
  %.unpack = load ptr, ptr %loadgep_2, align 8, !tbaa !8
  %.elt14 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  %.unpack15 = load i64, ptr %.elt14, align 8, !tbaa !8
  %.elt16 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  %.unpack17 = load i32, ptr %.elt16, align 8, !tbaa !8
  %.elt18 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  %.unpack19 = load i8, ptr %.elt18, align 4, !tbaa !8
  %.elt20 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  %.unpack21 = load i8, ptr %.elt20, align 1, !tbaa !8
  %.elt22 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  %.unpack23 = load i8, ptr %.elt22, align 2, !tbaa !8
  %.elt24 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  %.unpack25 = load i8, ptr %.elt24, align 1, !tbaa !8
  %.elt26 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  %.unpack27.unpack.unpack = load i64, ptr %.elt26, align 8, !tbaa !8
  %.unpack27.unpack.elt29 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  %.unpack27.unpack.unpack30 = load i64, ptr %.unpack27.unpack.elt29, align 8, !tbaa !8
  %.unpack27.unpack.elt31 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  %.unpack27.unpack.unpack32 = load i64, ptr %.unpack27.unpack.elt31, align 8, !tbaa !8
  store ptr %.unpack, ptr %loadgep_4, align 8, !tbaa !8
  %loadgep_4.repack34 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 1
  store i64 %.unpack15, ptr %loadgep_4.repack34, align 8, !tbaa !8
  %loadgep_4.repack36 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 2
  store i32 %.unpack17, ptr %loadgep_4.repack36, align 8, !tbaa !8
  %loadgep_4.repack38 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 3
  store i8 %.unpack19, ptr %loadgep_4.repack38, align 4, !tbaa !8
  %loadgep_4.repack40 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 4
  store i8 %.unpack21, ptr %loadgep_4.repack40, align 1, !tbaa !8
  %loadgep_4.repack42 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 5
  store i8 %.unpack23, ptr %loadgep_4.repack42, align 2, !tbaa !8
  %loadgep_4.repack44 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 6
  store i8 %.unpack25, ptr %loadgep_4.repack44, align 1, !tbaa !8
  %loadgep_4.repack46 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7
  store i64 %.unpack27.unpack.unpack, ptr %loadgep_4.repack46, align 8, !tbaa !8
  %loadgep_4.repack46.repack48 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack27.unpack.unpack30, ptr %loadgep_4.repack46.repack48, align 8, !tbaa !8
  %loadgep_4.repack46.repack50 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 2
  store i64 %.unpack27.unpack.unpack32, ptr %loadgep_4.repack46.repack50, align 8, !tbaa !8
  %10 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 0
  %11 = load i64, ptr %10, align 8, !tbaa !8
  %12 = icmp eq i64 %.unpack27.unpack.unpack30, 0
  %13 = select i1 %12, i64 1, i64 %11
  store ptr %.unpack, ptr %loadgep_6, align 8, !tbaa !8
  %loadgep_6.repack52 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 1
  store i64 8, ptr %loadgep_6.repack52, align 8, !tbaa !8
  %loadgep_6.repack54 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 2
  store i32 20180515, ptr %loadgep_6.repack54, align 8, !tbaa !8
  %loadgep_6.repack56 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 3
  store i8 1, ptr %loadgep_6.repack56, align 4, !tbaa !8
  %loadgep_6.repack58 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 4
  store i8 28, ptr %loadgep_6.repack58, align 1, !tbaa !8
  %loadgep_6.repack60 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 5
  store i8 0, ptr %loadgep_6.repack60, align 2, !tbaa !8
  %loadgep_6.repack62 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 6
  store i8 0, ptr %loadgep_6.repack62, align 1, !tbaa !8
  %loadgep_6.repack64 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7
  store i64 %13, ptr %loadgep_6.repack64, align 8, !tbaa !8
  %loadgep_6.repack64.repack66 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack27.unpack.unpack30, ptr %loadgep_6.repack64.repack66, align 8, !tbaa !8
  %loadgep_6.repack64.repack68 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7, i64 0, i64 2
  store i64 8, ptr %loadgep_6.repack64.repack68, align 8, !tbaa !8
  %14 = load ptr, ptr %loadgep_8, align 8, !tbaa !4
  %15 = getelementptr { ptr, ptr }, ptr %loadgep_8, i64 0, i32 1
  %16 = load ptr, ptr %15, align 8, !tbaa !4
  %17 = sext i32 %6 to i64
  %18 = sext i32 %storemerge to i64
  br i1 true, label %19, label %34

19:                                               ; preds = %omp.par.region4
  %reass.sub9.i = sub nsw i64 %18, %17
  %20 = icmp sgt i64 %reass.sub9.i, -1
  br i1 %20, label %.lr.ph8.preheader.i, label %_QFPloop.exit

.lr.ph8.preheader.i:                              ; preds = %19
  %21 = add nuw nsw i64 %reass.sub9.i, 1
  br label %.lr.ph8.i

.lr.ph8.i:                                        ; preds = %.lr.ph8.i, %.lr.ph8.preheader.i
  %22 = phi i64 [ %32, %.lr.ph8.i ], [ %21, %.lr.ph8.preheader.i ]
  %23 = phi i32 [ %31, %.lr.ph8.i ], [ %6, %.lr.ph8.preheader.i ]
  %24 = load i32, ptr %14, align 4, !tbaa !4
  %25 = sitofp i32 %24 to float
  %26 = fdiv contract float 1.000000e+00, %25
  %27 = fpext float %26 to double
  %28 = sext i32 %23 to i64
  %29 = add nsw i64 %28, -1
  %30 = getelementptr double, ptr %.unpack, i64 %29
  store double %27, ptr %30, align 8, !tbaa !4
  store double %27, ptr %16, align 8, !tbaa !4
  %31 = add i32 %23, 1
  %32 = add nsw i64 %22, -1
  %33 = icmp ugt i64 %22, 1
  br i1 %33, label %.lr.ph8.i, label %_QFPloop.exit

34:                                               ; preds = %omp.par.region4
  %reass.sub.i = sub nsw i64 %18, %17
  %35 = icmp sgt i64 %reass.sub.i, -1
  br i1 %35, label %.lr.ph.i, label %_QFPloop.exit

.lr.ph.i:                                         ; preds = %34
  %36 = add nuw nsw i64 %reass.sub.i, 1
  br label %37

37:                                               ; preds = %37, %.lr.ph.i
  %38 = phi i64 [ %36, %.lr.ph.i ], [ %49, %37 ]
  %39 = phi i32 [ %6, %.lr.ph.i ], [ %48, %37 ]
  %40 = load i32, ptr %14, align 4, !tbaa !4
  %41 = sitofp i32 %40 to float
  %42 = fdiv contract float 1.000000e+00, %41
  %43 = fpext float %42 to double
  %44 = sext i32 %39 to i64
  %45 = add nsw i64 %44, -1
  %46 = mul i64 %45, 8
  %47 = getelementptr i8, ptr %.unpack, i64 %46
  store double %43, ptr %47, align 8, !tbaa !4
  store double %43, ptr %16, align 8, !tbaa !4
  %48 = add i32 %39, 1
  %49 = add nsw i64 %38, -1
  %50 = icmp ugt i64 %38, 1
  br i1 %50, label %37, label %_QFPloop.exit

_QFPloop.exit:                                    ; preds = %19, %.lr.ph8.i, %34, %37
  ret void

omp.par.region2:                                  ; preds = %omp.par.entry
  br label %omp.par.region4
}
*** IR Dump After JumpThreadingPass on _QFPomp_subroutine..omp_par ***
; Function Attrs: norecurse nounwind
define internal void @_QFPomp_subroutine..omp_par(ptr noalias %tid.addr, ptr noalias %zero.addr, ptr %0) #2 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %gep_3 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 2
  %loadgep_4 = load ptr, ptr %gep_3, align 8
  %gep_5 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 3
  %loadgep_6 = load ptr, ptr %gep_5, align 8
  %gep_7 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 4
  %loadgep_8 = load ptr, ptr %gep_7, align 8
  %1 = call i32 @omp_get_thread_num()
  %2 = call i32 @omp_get_num_threads()
  %3 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %4 = sdiv i32 %3, %2
  %5 = mul i32 %1, %4
  %6 = add i32 %5, 1
  %7 = add i32 %2, -1
  %8 = icmp eq i32 %1, %7
  br i1 %8, label %omp.par.region2, label %omp.par.region3

omp.par.region3:                                  ; preds = %omp.par.entry
  %9 = add i32 %6, %4
  br label %omp.par.region2

omp.par.region2:                                  ; preds = %omp.par.entry, %omp.par.region3
  %storemerge = phi i32 [ %9, %omp.par.region3 ], [ %3, %omp.par.entry ]
  %.unpack = load ptr, ptr %loadgep_2, align 8, !tbaa !8
  %.elt14 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  %.unpack15 = load i64, ptr %.elt14, align 8, !tbaa !8
  %.elt16 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  %.unpack17 = load i32, ptr %.elt16, align 8, !tbaa !8
  %.elt18 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  %.unpack19 = load i8, ptr %.elt18, align 4, !tbaa !8
  %.elt20 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  %.unpack21 = load i8, ptr %.elt20, align 1, !tbaa !8
  %.elt22 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  %.unpack23 = load i8, ptr %.elt22, align 2, !tbaa !8
  %.elt24 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  %.unpack25 = load i8, ptr %.elt24, align 1, !tbaa !8
  %.elt26 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  %.unpack27.unpack.unpack = load i64, ptr %.elt26, align 8, !tbaa !8
  %.unpack27.unpack.elt29 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  %.unpack27.unpack.unpack30 = load i64, ptr %.unpack27.unpack.elt29, align 8, !tbaa !8
  %.unpack27.unpack.elt31 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  %.unpack27.unpack.unpack32 = load i64, ptr %.unpack27.unpack.elt31, align 8, !tbaa !8
  store ptr %.unpack, ptr %loadgep_4, align 8, !tbaa !8
  %loadgep_4.repack34 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 1
  store i64 %.unpack15, ptr %loadgep_4.repack34, align 8, !tbaa !8
  %loadgep_4.repack36 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 2
  store i32 %.unpack17, ptr %loadgep_4.repack36, align 8, !tbaa !8
  %loadgep_4.repack38 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 3
  store i8 %.unpack19, ptr %loadgep_4.repack38, align 4, !tbaa !8
  %loadgep_4.repack40 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 4
  store i8 %.unpack21, ptr %loadgep_4.repack40, align 1, !tbaa !8
  %loadgep_4.repack42 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 5
  store i8 %.unpack23, ptr %loadgep_4.repack42, align 2, !tbaa !8
  %loadgep_4.repack44 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 6
  store i8 %.unpack25, ptr %loadgep_4.repack44, align 1, !tbaa !8
  %loadgep_4.repack46 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7
  store i64 %.unpack27.unpack.unpack, ptr %loadgep_4.repack46, align 8, !tbaa !8
  %loadgep_4.repack46.repack48 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack27.unpack.unpack30, ptr %loadgep_4.repack46.repack48, align 8, !tbaa !8
  %loadgep_4.repack46.repack50 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 2
  store i64 %.unpack27.unpack.unpack32, ptr %loadgep_4.repack46.repack50, align 8, !tbaa !8
  %10 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 0
  %11 = load i64, ptr %10, align 8, !tbaa !8
  %12 = icmp eq i64 %.unpack27.unpack.unpack30, 0
  %13 = select i1 %12, i64 1, i64 %11
  store ptr %.unpack, ptr %loadgep_6, align 8, !tbaa !8
  %loadgep_6.repack52 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 1
  store i64 8, ptr %loadgep_6.repack52, align 8, !tbaa !8
  %loadgep_6.repack54 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 2
  store i32 20180515, ptr %loadgep_6.repack54, align 8, !tbaa !8
  %loadgep_6.repack56 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 3
  store i8 1, ptr %loadgep_6.repack56, align 4, !tbaa !8
  %loadgep_6.repack58 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 4
  store i8 28, ptr %loadgep_6.repack58, align 1, !tbaa !8
  %loadgep_6.repack60 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 5
  store i8 0, ptr %loadgep_6.repack60, align 2, !tbaa !8
  %loadgep_6.repack62 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 6
  store i8 0, ptr %loadgep_6.repack62, align 1, !tbaa !8
  %loadgep_6.repack64 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7
  store i64 %13, ptr %loadgep_6.repack64, align 8, !tbaa !8
  %loadgep_6.repack64.repack66 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack27.unpack.unpack30, ptr %loadgep_6.repack64.repack66, align 8, !tbaa !8
  %loadgep_6.repack64.repack68 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7, i64 0, i64 2
  store i64 8, ptr %loadgep_6.repack64.repack68, align 8, !tbaa !8
  %14 = load ptr, ptr %loadgep_8, align 8, !tbaa !4
  %15 = getelementptr { ptr, ptr }, ptr %loadgep_8, i64 0, i32 1
  %16 = load ptr, ptr %15, align 8, !tbaa !4
  %17 = sext i32 %6 to i64
  %18 = sext i32 %storemerge to i64
  %reass.sub9.i = sub nsw i64 %18, %17
  %19 = icmp sgt i64 %reass.sub9.i, -1
  br i1 %19, label %.lr.ph8.preheader.i, label %_QFPloop.exit

.lr.ph8.preheader.i:                              ; preds = %omp.par.region2
  %20 = add nuw nsw i64 %reass.sub9.i, 1
  br label %.lr.ph8.i

.lr.ph8.i:                                        ; preds = %.lr.ph8.i, %.lr.ph8.preheader.i
  %21 = phi i64 [ %31, %.lr.ph8.i ], [ %20, %.lr.ph8.preheader.i ]
  %22 = phi i32 [ %30, %.lr.ph8.i ], [ %6, %.lr.ph8.preheader.i ]
  %23 = load i32, ptr %14, align 4, !tbaa !4
  %24 = sitofp i32 %23 to float
  %25 = fdiv contract float 1.000000e+00, %24
  %26 = fpext float %25 to double
  %27 = sext i32 %22 to i64
  %28 = add nsw i64 %27, -1
  %29 = getelementptr double, ptr %.unpack, i64 %28
  store double %26, ptr %29, align 8, !tbaa !4
  store double %26, ptr %16, align 8, !tbaa !4
  %30 = add i32 %22, 1
  %31 = add nsw i64 %21, -1
  %32 = icmp ugt i64 %21, 1
  br i1 %32, label %.lr.ph8.i, label %_QFPloop.exit

33:                                               ; preds = %33
  %34 = load i32, ptr %14, align 4, !tbaa !4
  %35 = sitofp i32 %34 to float
  %36 = fdiv contract float 1.000000e+00, %35
  %37 = fpext float %36 to double
  %38 = sext i32 %42 to i64
  %39 = add nsw i64 %38, -1
  %40 = mul i64 %39, 8
  %41 = getelementptr i8, ptr %.unpack, i64 %40
  store double %37, ptr %41, align 8, !tbaa !4
  store double %37, ptr %16, align 8, !tbaa !4
  %42 = add i32 %42, 1
  %43 = add nsw i64 %43, -1
  %44 = icmp ugt i64 %43, 1
  br label %33

_QFPloop.exit:                                    ; preds = %omp.par.region2, %.lr.ph8.i
  ret void
}
*** IR Dump After CorrelatedValuePropagationPass on _QFPomp_subroutine..omp_par ***
; Function Attrs: norecurse nounwind
define internal void @_QFPomp_subroutine..omp_par(ptr noalias %tid.addr, ptr noalias %zero.addr, ptr %0) #2 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %gep_3 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 2
  %loadgep_4 = load ptr, ptr %gep_3, align 8
  %gep_5 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 3
  %loadgep_6 = load ptr, ptr %gep_5, align 8
  %gep_7 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 4
  %loadgep_8 = load ptr, ptr %gep_7, align 8
  %1 = call i32 @omp_get_thread_num()
  %2 = call i32 @omp_get_num_threads()
  %3 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %4 = sdiv i32 %3, %2
  %5 = mul i32 %1, %4
  %6 = add i32 %5, 1
  %7 = add i32 %2, -1
  %8 = icmp eq i32 %1, %7
  br i1 %8, label %omp.par.region2, label %omp.par.region3

omp.par.region3:                                  ; preds = %omp.par.entry
  %9 = add i32 %6, %4
  br label %omp.par.region2

omp.par.region2:                                  ; preds = %omp.par.entry, %omp.par.region3
  %storemerge = phi i32 [ %9, %omp.par.region3 ], [ %3, %omp.par.entry ]
  %.unpack = load ptr, ptr %loadgep_2, align 8, !tbaa !8
  %.elt14 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  %.unpack15 = load i64, ptr %.elt14, align 8, !tbaa !8
  %.elt16 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  %.unpack17 = load i32, ptr %.elt16, align 8, !tbaa !8
  %.elt18 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  %.unpack19 = load i8, ptr %.elt18, align 4, !tbaa !8
  %.elt20 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  %.unpack21 = load i8, ptr %.elt20, align 1, !tbaa !8
  %.elt22 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  %.unpack23 = load i8, ptr %.elt22, align 2, !tbaa !8
  %.elt24 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  %.unpack25 = load i8, ptr %.elt24, align 1, !tbaa !8
  %.elt26 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  %.unpack27.unpack.unpack = load i64, ptr %.elt26, align 8, !tbaa !8
  %.unpack27.unpack.elt29 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  %.unpack27.unpack.unpack30 = load i64, ptr %.unpack27.unpack.elt29, align 8, !tbaa !8
  %.unpack27.unpack.elt31 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  %.unpack27.unpack.unpack32 = load i64, ptr %.unpack27.unpack.elt31, align 8, !tbaa !8
  store ptr %.unpack, ptr %loadgep_4, align 8, !tbaa !8
  %loadgep_4.repack34 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 1
  store i64 %.unpack15, ptr %loadgep_4.repack34, align 8, !tbaa !8
  %loadgep_4.repack36 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 2
  store i32 %.unpack17, ptr %loadgep_4.repack36, align 8, !tbaa !8
  %loadgep_4.repack38 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 3
  store i8 %.unpack19, ptr %loadgep_4.repack38, align 4, !tbaa !8
  %loadgep_4.repack40 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 4
  store i8 %.unpack21, ptr %loadgep_4.repack40, align 1, !tbaa !8
  %loadgep_4.repack42 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 5
  store i8 %.unpack23, ptr %loadgep_4.repack42, align 2, !tbaa !8
  %loadgep_4.repack44 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 6
  store i8 %.unpack25, ptr %loadgep_4.repack44, align 1, !tbaa !8
  %loadgep_4.repack46 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7
  store i64 %.unpack27.unpack.unpack, ptr %loadgep_4.repack46, align 8, !tbaa !8
  %loadgep_4.repack46.repack48 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack27.unpack.unpack30, ptr %loadgep_4.repack46.repack48, align 8, !tbaa !8
  %loadgep_4.repack46.repack50 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 2
  store i64 %.unpack27.unpack.unpack32, ptr %loadgep_4.repack46.repack50, align 8, !tbaa !8
  %10 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 0
  %11 = load i64, ptr %10, align 8, !tbaa !8
  %12 = icmp eq i64 %.unpack27.unpack.unpack30, 0
  %13 = select i1 %12, i64 1, i64 %11
  store ptr %.unpack, ptr %loadgep_6, align 8, !tbaa !8
  %loadgep_6.repack52 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 1
  store i64 8, ptr %loadgep_6.repack52, align 8, !tbaa !8
  %loadgep_6.repack54 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 2
  store i32 20180515, ptr %loadgep_6.repack54, align 8, !tbaa !8
  %loadgep_6.repack56 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 3
  store i8 1, ptr %loadgep_6.repack56, align 4, !tbaa !8
  %loadgep_6.repack58 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 4
  store i8 28, ptr %loadgep_6.repack58, align 1, !tbaa !8
  %loadgep_6.repack60 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 5
  store i8 0, ptr %loadgep_6.repack60, align 2, !tbaa !8
  %loadgep_6.repack62 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 6
  store i8 0, ptr %loadgep_6.repack62, align 1, !tbaa !8
  %loadgep_6.repack64 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7
  store i64 %13, ptr %loadgep_6.repack64, align 8, !tbaa !8
  %loadgep_6.repack64.repack66 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack27.unpack.unpack30, ptr %loadgep_6.repack64.repack66, align 8, !tbaa !8
  %loadgep_6.repack64.repack68 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7, i64 0, i64 2
  store i64 8, ptr %loadgep_6.repack64.repack68, align 8, !tbaa !8
  %14 = load ptr, ptr %loadgep_8, align 8, !tbaa !4
  %15 = getelementptr { ptr, ptr }, ptr %loadgep_8, i64 0, i32 1
  %16 = load ptr, ptr %15, align 8, !tbaa !4
  %17 = sext i32 %6 to i64
  %18 = sext i32 %storemerge to i64
  %reass.sub9.i = sub nsw i64 %18, %17
  %19 = icmp sgt i64 %reass.sub9.i, -1
  br i1 %19, label %.lr.ph8.preheader.i, label %_QFPloop.exit

.lr.ph8.preheader.i:                              ; preds = %omp.par.region2
  %20 = add nuw nsw i64 %reass.sub9.i, 1
  br label %.lr.ph8.i

.lr.ph8.i:                                        ; preds = %.lr.ph8.i, %.lr.ph8.preheader.i
  %21 = phi i64 [ %31, %.lr.ph8.i ], [ %20, %.lr.ph8.preheader.i ]
  %22 = phi i32 [ %30, %.lr.ph8.i ], [ %6, %.lr.ph8.preheader.i ]
  %23 = load i32, ptr %14, align 4, !tbaa !4
  %24 = sitofp i32 %23 to float
  %25 = fdiv contract float 1.000000e+00, %24
  %26 = fpext float %25 to double
  %27 = sext i32 %22 to i64
  %28 = add nsw i64 %27, -1
  %29 = getelementptr double, ptr %.unpack, i64 %28
  store double %26, ptr %29, align 8, !tbaa !4
  store double %26, ptr %16, align 8, !tbaa !4
  %30 = add i32 %22, 1
  %31 = add nsw i64 %21, -1
  %32 = icmp ugt i64 %21, 1
  br i1 %32, label %.lr.ph8.i, label %_QFPloop.exit

33:                                               ; preds = %33
  %34 = load i32, ptr %14, align 4, !tbaa !4
  %35 = sitofp i32 %34 to float
  %36 = fdiv contract float 1.000000e+00, %35
  %37 = fpext float %36 to double
  %38 = sext i32 %42 to i64
  %39 = add nsw i64 %38, -1
  %40 = mul i64 %39, 8
  %41 = getelementptr i8, ptr %.unpack, i64 %40
  store double %37, ptr %41, align 8, !tbaa !4
  store double %37, ptr %16, align 8, !tbaa !4
  %42 = add i32 %42, 1
  %43 = add nsw i64 %43, -1
  %44 = icmp ugt i64 %43, 1
  br label %33

_QFPloop.exit:                                    ; preds = %omp.par.region2, %.lr.ph8.i
  ret void
}
*** IR Dump After SimplifyCFGPass on _QFPomp_subroutine..omp_par ***
; Function Attrs: norecurse nounwind
define internal void @_QFPomp_subroutine..omp_par(ptr noalias %tid.addr, ptr noalias %zero.addr, ptr %0) #2 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %gep_3 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 2
  %loadgep_4 = load ptr, ptr %gep_3, align 8
  %gep_5 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 3
  %loadgep_6 = load ptr, ptr %gep_5, align 8
  %gep_7 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 4
  %loadgep_8 = load ptr, ptr %gep_7, align 8
  %1 = call i32 @omp_get_thread_num()
  %2 = call i32 @omp_get_num_threads()
  %3 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %4 = sdiv i32 %3, %2
  %5 = mul i32 %1, %4
  %6 = add i32 %5, 1
  %7 = add i32 %2, -1
  %8 = icmp eq i32 %1, %7
  %9 = add i32 %6, %4
  %spec.select = select i1 %8, i32 %3, i32 %9
  %.unpack = load ptr, ptr %loadgep_2, align 8, !tbaa !8
  %.elt14 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  %.unpack15 = load i64, ptr %.elt14, align 8, !tbaa !8
  %.elt16 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  %.unpack17 = load i32, ptr %.elt16, align 8, !tbaa !8
  %.elt18 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  %.unpack19 = load i8, ptr %.elt18, align 4, !tbaa !8
  %.elt20 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  %.unpack21 = load i8, ptr %.elt20, align 1, !tbaa !8
  %.elt22 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  %.unpack23 = load i8, ptr %.elt22, align 2, !tbaa !8
  %.elt24 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  %.unpack25 = load i8, ptr %.elt24, align 1, !tbaa !8
  %.elt26 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  %.unpack27.unpack.unpack = load i64, ptr %.elt26, align 8, !tbaa !8
  %.unpack27.unpack.elt29 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  %.unpack27.unpack.unpack30 = load i64, ptr %.unpack27.unpack.elt29, align 8, !tbaa !8
  %.unpack27.unpack.elt31 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  %.unpack27.unpack.unpack32 = load i64, ptr %.unpack27.unpack.elt31, align 8, !tbaa !8
  store ptr %.unpack, ptr %loadgep_4, align 8, !tbaa !8
  %loadgep_4.repack34 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 1
  store i64 %.unpack15, ptr %loadgep_4.repack34, align 8, !tbaa !8
  %loadgep_4.repack36 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 2
  store i32 %.unpack17, ptr %loadgep_4.repack36, align 8, !tbaa !8
  %loadgep_4.repack38 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 3
  store i8 %.unpack19, ptr %loadgep_4.repack38, align 4, !tbaa !8
  %loadgep_4.repack40 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 4
  store i8 %.unpack21, ptr %loadgep_4.repack40, align 1, !tbaa !8
  %loadgep_4.repack42 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 5
  store i8 %.unpack23, ptr %loadgep_4.repack42, align 2, !tbaa !8
  %loadgep_4.repack44 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 6
  store i8 %.unpack25, ptr %loadgep_4.repack44, align 1, !tbaa !8
  %loadgep_4.repack46 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7
  store i64 %.unpack27.unpack.unpack, ptr %loadgep_4.repack46, align 8, !tbaa !8
  %loadgep_4.repack46.repack48 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack27.unpack.unpack30, ptr %loadgep_4.repack46.repack48, align 8, !tbaa !8
  %loadgep_4.repack46.repack50 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 2
  store i64 %.unpack27.unpack.unpack32, ptr %loadgep_4.repack46.repack50, align 8, !tbaa !8
  %10 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 0
  %11 = load i64, ptr %10, align 8, !tbaa !8
  %12 = icmp eq i64 %.unpack27.unpack.unpack30, 0
  %13 = select i1 %12, i64 1, i64 %11
  store ptr %.unpack, ptr %loadgep_6, align 8, !tbaa !8
  %loadgep_6.repack52 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 1
  store i64 8, ptr %loadgep_6.repack52, align 8, !tbaa !8
  %loadgep_6.repack54 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 2
  store i32 20180515, ptr %loadgep_6.repack54, align 8, !tbaa !8
  %loadgep_6.repack56 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 3
  store i8 1, ptr %loadgep_6.repack56, align 4, !tbaa !8
  %loadgep_6.repack58 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 4
  store i8 28, ptr %loadgep_6.repack58, align 1, !tbaa !8
  %loadgep_6.repack60 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 5
  store i8 0, ptr %loadgep_6.repack60, align 2, !tbaa !8
  %loadgep_6.repack62 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 6
  store i8 0, ptr %loadgep_6.repack62, align 1, !tbaa !8
  %loadgep_6.repack64 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7
  store i64 %13, ptr %loadgep_6.repack64, align 8, !tbaa !8
  %loadgep_6.repack64.repack66 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack27.unpack.unpack30, ptr %loadgep_6.repack64.repack66, align 8, !tbaa !8
  %loadgep_6.repack64.repack68 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7, i64 0, i64 2
  store i64 8, ptr %loadgep_6.repack64.repack68, align 8, !tbaa !8
  %14 = load ptr, ptr %loadgep_8, align 8, !tbaa !4
  %15 = getelementptr { ptr, ptr }, ptr %loadgep_8, i64 0, i32 1
  %16 = load ptr, ptr %15, align 8, !tbaa !4
  %17 = sext i32 %6 to i64
  %18 = sext i32 %spec.select to i64
  %reass.sub9.i = sub nsw i64 %18, %17
  %19 = icmp sgt i64 %reass.sub9.i, -1
  br i1 %19, label %.lr.ph8.preheader.i, label %_QFPloop.exit

.lr.ph8.preheader.i:                              ; preds = %omp.par.entry
  %20 = add nuw nsw i64 %reass.sub9.i, 1
  br label %.lr.ph8.i

.lr.ph8.i:                                        ; preds = %.lr.ph8.i, %.lr.ph8.preheader.i
  %21 = phi i64 [ %31, %.lr.ph8.i ], [ %20, %.lr.ph8.preheader.i ]
  %22 = phi i32 [ %30, %.lr.ph8.i ], [ %6, %.lr.ph8.preheader.i ]
  %23 = load i32, ptr %14, align 4, !tbaa !4
  %24 = sitofp i32 %23 to float
  %25 = fdiv contract float 1.000000e+00, %24
  %26 = fpext float %25 to double
  %27 = sext i32 %22 to i64
  %28 = add nsw i64 %27, -1
  %29 = getelementptr double, ptr %.unpack, i64 %28
  store double %26, ptr %29, align 8, !tbaa !4
  store double %26, ptr %16, align 8, !tbaa !4
  %30 = add i32 %22, 1
  %31 = add nsw i64 %21, -1
  %32 = icmp ugt i64 %21, 1
  br i1 %32, label %.lr.ph8.i, label %_QFPloop.exit

_QFPloop.exit:                                    ; preds = %omp.par.entry, %.lr.ph8.i
  ret void
}
*** IR Dump After InstCombinePass on _QFPomp_subroutine..omp_par ***
; Function Attrs: norecurse nounwind
define internal void @_QFPomp_subroutine..omp_par(ptr noalias %tid.addr, ptr noalias %zero.addr, ptr %0) #2 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %gep_3 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 2
  %loadgep_4 = load ptr, ptr %gep_3, align 8
  %gep_5 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 3
  %loadgep_6 = load ptr, ptr %gep_5, align 8
  %gep_7 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 4
  %loadgep_8 = load ptr, ptr %gep_7, align 8
  %1 = call i32 @omp_get_thread_num()
  %2 = call i32 @omp_get_num_threads()
  %3 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %4 = sdiv i32 %3, %2
  %5 = mul i32 %1, %4
  %6 = add i32 %5, 1
  %7 = add i32 %2, -1
  %8 = icmp eq i32 %1, %7
  %9 = add i32 %6, %4
  %spec.select = select i1 %8, i32 %3, i32 %9
  %.unpack = load ptr, ptr %loadgep_2, align 8, !tbaa !8
  %.elt14 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  %.unpack15 = load i64, ptr %.elt14, align 8, !tbaa !8
  %.elt16 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  %.unpack17 = load i32, ptr %.elt16, align 8, !tbaa !8
  %.elt18 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  %.unpack19 = load i8, ptr %.elt18, align 4, !tbaa !8
  %.elt20 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  %.unpack21 = load i8, ptr %.elt20, align 1, !tbaa !8
  %.elt22 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  %.unpack23 = load i8, ptr %.elt22, align 2, !tbaa !8
  %.elt24 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  %.unpack25 = load i8, ptr %.elt24, align 1, !tbaa !8
  %.elt26 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  %.unpack27.unpack.unpack = load i64, ptr %.elt26, align 8, !tbaa !8
  %.unpack27.unpack.elt29 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  %.unpack27.unpack.unpack30 = load i64, ptr %.unpack27.unpack.elt29, align 8, !tbaa !8
  %.unpack27.unpack.elt31 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  %.unpack27.unpack.unpack32 = load i64, ptr %.unpack27.unpack.elt31, align 8, !tbaa !8
  store ptr %.unpack, ptr %loadgep_4, align 8, !tbaa !8
  %loadgep_4.repack34 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 1
  store i64 %.unpack15, ptr %loadgep_4.repack34, align 8, !tbaa !8
  %loadgep_4.repack36 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 2
  store i32 %.unpack17, ptr %loadgep_4.repack36, align 8, !tbaa !8
  %loadgep_4.repack38 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 3
  store i8 %.unpack19, ptr %loadgep_4.repack38, align 4, !tbaa !8
  %loadgep_4.repack40 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 4
  store i8 %.unpack21, ptr %loadgep_4.repack40, align 1, !tbaa !8
  %loadgep_4.repack42 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 5
  store i8 %.unpack23, ptr %loadgep_4.repack42, align 2, !tbaa !8
  %loadgep_4.repack44 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 6
  store i8 %.unpack25, ptr %loadgep_4.repack44, align 1, !tbaa !8
  %loadgep_4.repack46 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7
  store i64 %.unpack27.unpack.unpack, ptr %loadgep_4.repack46, align 8, !tbaa !8
  %loadgep_4.repack46.repack48 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack27.unpack.unpack30, ptr %loadgep_4.repack46.repack48, align 8, !tbaa !8
  %loadgep_4.repack46.repack50 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 2
  store i64 %.unpack27.unpack.unpack32, ptr %loadgep_4.repack46.repack50, align 8, !tbaa !8
  %10 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 0
  %11 = load i64, ptr %10, align 8, !tbaa !8
  %12 = icmp eq i64 %.unpack27.unpack.unpack30, 0
  %13 = select i1 %12, i64 1, i64 %11
  store ptr %.unpack, ptr %loadgep_6, align 8, !tbaa !8
  %loadgep_6.repack52 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 1
  store i64 8, ptr %loadgep_6.repack52, align 8, !tbaa !8
  %loadgep_6.repack54 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 2
  store i32 20180515, ptr %loadgep_6.repack54, align 8, !tbaa !8
  %loadgep_6.repack56 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 3
  store i8 1, ptr %loadgep_6.repack56, align 4, !tbaa !8
  %loadgep_6.repack58 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 4
  store i8 28, ptr %loadgep_6.repack58, align 1, !tbaa !8
  %loadgep_6.repack60 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 5
  store i8 0, ptr %loadgep_6.repack60, align 2, !tbaa !8
  %loadgep_6.repack62 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 6
  store i8 0, ptr %loadgep_6.repack62, align 1, !tbaa !8
  %loadgep_6.repack64 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7
  store i64 %13, ptr %loadgep_6.repack64, align 8, !tbaa !8
  %loadgep_6.repack64.repack66 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack27.unpack.unpack30, ptr %loadgep_6.repack64.repack66, align 8, !tbaa !8
  %loadgep_6.repack64.repack68 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7, i64 0, i64 2
  store i64 8, ptr %loadgep_6.repack64.repack68, align 8, !tbaa !8
  %14 = load ptr, ptr %loadgep_8, align 8, !tbaa !4
  %15 = getelementptr { ptr, ptr }, ptr %loadgep_8, i64 0, i32 1
  %16 = load ptr, ptr %15, align 8, !tbaa !4
  %17 = sext i32 %6 to i64
  %18 = sext i32 %spec.select to i64
  %reass.sub9.i = sub nsw i64 %18, %17
  %19 = icmp sgt i64 %reass.sub9.i, -1
  br i1 %19, label %.lr.ph8.preheader.i, label %_QFPloop.exit

.lr.ph8.preheader.i:                              ; preds = %omp.par.entry
  %20 = add nuw nsw i64 %reass.sub9.i, 1
  br label %.lr.ph8.i

.lr.ph8.i:                                        ; preds = %.lr.ph8.i, %.lr.ph8.preheader.i
  %21 = phi i64 [ %31, %.lr.ph8.i ], [ %20, %.lr.ph8.preheader.i ]
  %22 = phi i32 [ %30, %.lr.ph8.i ], [ %6, %.lr.ph8.preheader.i ]
  %23 = load i32, ptr %14, align 4, !tbaa !4
  %24 = sitofp i32 %23 to float
  %25 = fdiv contract float 1.000000e+00, %24
  %26 = fpext float %25 to double
  %27 = sext i32 %22 to i64
  %28 = add nsw i64 %27, -1
  %29 = getelementptr double, ptr %.unpack, i64 %28
  store double %26, ptr %29, align 8, !tbaa !4
  store double %26, ptr %16, align 8, !tbaa !4
  %30 = add i32 %22, 1
  %31 = add nsw i64 %21, -1
  %32 = icmp ugt i64 %21, 1
  br i1 %32, label %.lr.ph8.i, label %_QFPloop.exit

_QFPloop.exit:                                    ; preds = %omp.par.entry, %.lr.ph8.i
  ret void
}
*** IR Dump After AggressiveInstCombinePass on _QFPomp_subroutine..omp_par ***
; Function Attrs: norecurse nounwind
define internal void @_QFPomp_subroutine..omp_par(ptr noalias %tid.addr, ptr noalias %zero.addr, ptr %0) #2 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %gep_3 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 2
  %loadgep_4 = load ptr, ptr %gep_3, align 8
  %gep_5 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 3
  %loadgep_6 = load ptr, ptr %gep_5, align 8
  %gep_7 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 4
  %loadgep_8 = load ptr, ptr %gep_7, align 8
  %1 = call i32 @omp_get_thread_num()
  %2 = call i32 @omp_get_num_threads()
  %3 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %4 = sdiv i32 %3, %2
  %5 = mul i32 %1, %4
  %6 = add i32 %5, 1
  %7 = add i32 %2, -1
  %8 = icmp eq i32 %1, %7
  %9 = add i32 %6, %4
  %spec.select = select i1 %8, i32 %3, i32 %9
  %.unpack = load ptr, ptr %loadgep_2, align 8, !tbaa !8
  %.elt14 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  %.unpack15 = load i64, ptr %.elt14, align 8, !tbaa !8
  %.elt16 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  %.unpack17 = load i32, ptr %.elt16, align 8, !tbaa !8
  %.elt18 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  %.unpack19 = load i8, ptr %.elt18, align 4, !tbaa !8
  %.elt20 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  %.unpack21 = load i8, ptr %.elt20, align 1, !tbaa !8
  %.elt22 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  %.unpack23 = load i8, ptr %.elt22, align 2, !tbaa !8
  %.elt24 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  %.unpack25 = load i8, ptr %.elt24, align 1, !tbaa !8
  %.elt26 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  %.unpack27.unpack.unpack = load i64, ptr %.elt26, align 8, !tbaa !8
  %.unpack27.unpack.elt29 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  %.unpack27.unpack.unpack30 = load i64, ptr %.unpack27.unpack.elt29, align 8, !tbaa !8
  %.unpack27.unpack.elt31 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  %.unpack27.unpack.unpack32 = load i64, ptr %.unpack27.unpack.elt31, align 8, !tbaa !8
  store ptr %.unpack, ptr %loadgep_4, align 8, !tbaa !8
  %loadgep_4.repack34 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 1
  store i64 %.unpack15, ptr %loadgep_4.repack34, align 8, !tbaa !8
  %loadgep_4.repack36 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 2
  store i32 %.unpack17, ptr %loadgep_4.repack36, align 8, !tbaa !8
  %loadgep_4.repack38 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 3
  store i8 %.unpack19, ptr %loadgep_4.repack38, align 4, !tbaa !8
  %loadgep_4.repack40 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 4
  store i8 %.unpack21, ptr %loadgep_4.repack40, align 1, !tbaa !8
  %loadgep_4.repack42 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 5
  store i8 %.unpack23, ptr %loadgep_4.repack42, align 2, !tbaa !8
  %loadgep_4.repack44 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 6
  store i8 %.unpack25, ptr %loadgep_4.repack44, align 1, !tbaa !8
  %loadgep_4.repack46 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7
  store i64 %.unpack27.unpack.unpack, ptr %loadgep_4.repack46, align 8, !tbaa !8
  %loadgep_4.repack46.repack48 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack27.unpack.unpack30, ptr %loadgep_4.repack46.repack48, align 8, !tbaa !8
  %loadgep_4.repack46.repack50 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 2
  store i64 %.unpack27.unpack.unpack32, ptr %loadgep_4.repack46.repack50, align 8, !tbaa !8
  %10 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 0
  %11 = load i64, ptr %10, align 8, !tbaa !8
  %12 = icmp eq i64 %.unpack27.unpack.unpack30, 0
  %13 = select i1 %12, i64 1, i64 %11
  store ptr %.unpack, ptr %loadgep_6, align 8, !tbaa !8
  %loadgep_6.repack52 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 1
  store i64 8, ptr %loadgep_6.repack52, align 8, !tbaa !8
  %loadgep_6.repack54 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 2
  store i32 20180515, ptr %loadgep_6.repack54, align 8, !tbaa !8
  %loadgep_6.repack56 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 3
  store i8 1, ptr %loadgep_6.repack56, align 4, !tbaa !8
  %loadgep_6.repack58 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 4
  store i8 28, ptr %loadgep_6.repack58, align 1, !tbaa !8
  %loadgep_6.repack60 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 5
  store i8 0, ptr %loadgep_6.repack60, align 2, !tbaa !8
  %loadgep_6.repack62 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 6
  store i8 0, ptr %loadgep_6.repack62, align 1, !tbaa !8
  %loadgep_6.repack64 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7
  store i64 %13, ptr %loadgep_6.repack64, align 8, !tbaa !8
  %loadgep_6.repack64.repack66 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack27.unpack.unpack30, ptr %loadgep_6.repack64.repack66, align 8, !tbaa !8
  %loadgep_6.repack64.repack68 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7, i64 0, i64 2
  store i64 8, ptr %loadgep_6.repack64.repack68, align 8, !tbaa !8
  %14 = load ptr, ptr %loadgep_8, align 8, !tbaa !4
  %15 = getelementptr { ptr, ptr }, ptr %loadgep_8, i64 0, i32 1
  %16 = load ptr, ptr %15, align 8, !tbaa !4
  %17 = sext i32 %6 to i64
  %18 = sext i32 %spec.select to i64
  %reass.sub9.i = sub nsw i64 %18, %17
  %19 = icmp sgt i64 %reass.sub9.i, -1
  br i1 %19, label %.lr.ph8.preheader.i, label %_QFPloop.exit

.lr.ph8.preheader.i:                              ; preds = %omp.par.entry
  %20 = add nuw nsw i64 %reass.sub9.i, 1
  br label %.lr.ph8.i

.lr.ph8.i:                                        ; preds = %.lr.ph8.i, %.lr.ph8.preheader.i
  %21 = phi i64 [ %31, %.lr.ph8.i ], [ %20, %.lr.ph8.preheader.i ]
  %22 = phi i32 [ %30, %.lr.ph8.i ], [ %6, %.lr.ph8.preheader.i ]
  %23 = load i32, ptr %14, align 4, !tbaa !4
  %24 = sitofp i32 %23 to float
  %25 = fdiv contract float 1.000000e+00, %24
  %26 = fpext float %25 to double
  %27 = sext i32 %22 to i64
  %28 = add nsw i64 %27, -1
  %29 = getelementptr double, ptr %.unpack, i64 %28
  store double %26, ptr %29, align 8, !tbaa !4
  store double %26, ptr %16, align 8, !tbaa !4
  %30 = add i32 %22, 1
  %31 = add nsw i64 %21, -1
  %32 = icmp ugt i64 %21, 1
  br i1 %32, label %.lr.ph8.i, label %_QFPloop.exit

_QFPloop.exit:                                    ; preds = %omp.par.entry, %.lr.ph8.i
  ret void
}
*** IR Dump After ConstraintEliminationPass on _QFPomp_subroutine..omp_par ***
; Function Attrs: norecurse nounwind
define internal void @_QFPomp_subroutine..omp_par(ptr noalias %tid.addr, ptr noalias %zero.addr, ptr %0) #2 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %gep_3 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 2
  %loadgep_4 = load ptr, ptr %gep_3, align 8
  %gep_5 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 3
  %loadgep_6 = load ptr, ptr %gep_5, align 8
  %gep_7 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 4
  %loadgep_8 = load ptr, ptr %gep_7, align 8
  %1 = call i32 @omp_get_thread_num()
  %2 = call i32 @omp_get_num_threads()
  %3 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %4 = sdiv i32 %3, %2
  %5 = mul i32 %1, %4
  %6 = add i32 %5, 1
  %7 = add i32 %2, -1
  %8 = icmp eq i32 %1, %7
  %9 = add i32 %6, %4
  %spec.select = select i1 %8, i32 %3, i32 %9
  %.unpack = load ptr, ptr %loadgep_2, align 8, !tbaa !8
  %.elt14 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  %.unpack15 = load i64, ptr %.elt14, align 8, !tbaa !8
  %.elt16 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  %.unpack17 = load i32, ptr %.elt16, align 8, !tbaa !8
  %.elt18 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  %.unpack19 = load i8, ptr %.elt18, align 4, !tbaa !8
  %.elt20 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  %.unpack21 = load i8, ptr %.elt20, align 1, !tbaa !8
  %.elt22 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  %.unpack23 = load i8, ptr %.elt22, align 2, !tbaa !8
  %.elt24 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  %.unpack25 = load i8, ptr %.elt24, align 1, !tbaa !8
  %.elt26 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  %.unpack27.unpack.unpack = load i64, ptr %.elt26, align 8, !tbaa !8
  %.unpack27.unpack.elt29 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  %.unpack27.unpack.unpack30 = load i64, ptr %.unpack27.unpack.elt29, align 8, !tbaa !8
  %.unpack27.unpack.elt31 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  %.unpack27.unpack.unpack32 = load i64, ptr %.unpack27.unpack.elt31, align 8, !tbaa !8
  store ptr %.unpack, ptr %loadgep_4, align 8, !tbaa !8
  %loadgep_4.repack34 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 1
  store i64 %.unpack15, ptr %loadgep_4.repack34, align 8, !tbaa !8
  %loadgep_4.repack36 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 2
  store i32 %.unpack17, ptr %loadgep_4.repack36, align 8, !tbaa !8
  %loadgep_4.repack38 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 3
  store i8 %.unpack19, ptr %loadgep_4.repack38, align 4, !tbaa !8
  %loadgep_4.repack40 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 4
  store i8 %.unpack21, ptr %loadgep_4.repack40, align 1, !tbaa !8
  %loadgep_4.repack42 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 5
  store i8 %.unpack23, ptr %loadgep_4.repack42, align 2, !tbaa !8
  %loadgep_4.repack44 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 6
  store i8 %.unpack25, ptr %loadgep_4.repack44, align 1, !tbaa !8
  %loadgep_4.repack46 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7
  store i64 %.unpack27.unpack.unpack, ptr %loadgep_4.repack46, align 8, !tbaa !8
  %loadgep_4.repack46.repack48 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack27.unpack.unpack30, ptr %loadgep_4.repack46.repack48, align 8, !tbaa !8
  %loadgep_4.repack46.repack50 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 2
  store i64 %.unpack27.unpack.unpack32, ptr %loadgep_4.repack46.repack50, align 8, !tbaa !8
  %10 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 0
  %11 = load i64, ptr %10, align 8, !tbaa !8
  %12 = icmp eq i64 %.unpack27.unpack.unpack30, 0
  %13 = select i1 %12, i64 1, i64 %11
  store ptr %.unpack, ptr %loadgep_6, align 8, !tbaa !8
  %loadgep_6.repack52 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 1
  store i64 8, ptr %loadgep_6.repack52, align 8, !tbaa !8
  %loadgep_6.repack54 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 2
  store i32 20180515, ptr %loadgep_6.repack54, align 8, !tbaa !8
  %loadgep_6.repack56 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 3
  store i8 1, ptr %loadgep_6.repack56, align 4, !tbaa !8
  %loadgep_6.repack58 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 4
  store i8 28, ptr %loadgep_6.repack58, align 1, !tbaa !8
  %loadgep_6.repack60 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 5
  store i8 0, ptr %loadgep_6.repack60, align 2, !tbaa !8
  %loadgep_6.repack62 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 6
  store i8 0, ptr %loadgep_6.repack62, align 1, !tbaa !8
  %loadgep_6.repack64 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7
  store i64 %13, ptr %loadgep_6.repack64, align 8, !tbaa !8
  %loadgep_6.repack64.repack66 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack27.unpack.unpack30, ptr %loadgep_6.repack64.repack66, align 8, !tbaa !8
  %loadgep_6.repack64.repack68 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7, i64 0, i64 2
  store i64 8, ptr %loadgep_6.repack64.repack68, align 8, !tbaa !8
  %14 = load ptr, ptr %loadgep_8, align 8, !tbaa !4
  %15 = getelementptr { ptr, ptr }, ptr %loadgep_8, i64 0, i32 1
  %16 = load ptr, ptr %15, align 8, !tbaa !4
  %17 = sext i32 %6 to i64
  %18 = sext i32 %spec.select to i64
  %reass.sub9.i = sub nsw i64 %18, %17
  %19 = icmp sgt i64 %reass.sub9.i, -1
  br i1 %19, label %.lr.ph8.preheader.i, label %_QFPloop.exit

.lr.ph8.preheader.i:                              ; preds = %omp.par.entry
  %20 = add nuw nsw i64 %reass.sub9.i, 1
  br label %.lr.ph8.i

.lr.ph8.i:                                        ; preds = %.lr.ph8.i, %.lr.ph8.preheader.i
  %21 = phi i64 [ %31, %.lr.ph8.i ], [ %20, %.lr.ph8.preheader.i ]
  %22 = phi i32 [ %30, %.lr.ph8.i ], [ %6, %.lr.ph8.preheader.i ]
  %23 = load i32, ptr %14, align 4, !tbaa !4
  %24 = sitofp i32 %23 to float
  %25 = fdiv contract float 1.000000e+00, %24
  %26 = fpext float %25 to double
  %27 = sext i32 %22 to i64
  %28 = add nsw i64 %27, -1
  %29 = getelementptr double, ptr %.unpack, i64 %28
  store double %26, ptr %29, align 8, !tbaa !4
  store double %26, ptr %16, align 8, !tbaa !4
  %30 = add i32 %22, 1
  %31 = add nsw i64 %21, -1
  %32 = icmp ugt i64 %21, 1
  br i1 %32, label %.lr.ph8.i, label %_QFPloop.exit

_QFPloop.exit:                                    ; preds = %omp.par.entry, %.lr.ph8.i
  ret void
}
*** IR Dump After LibCallsShrinkWrapPass on _QFPomp_subroutine..omp_par ***
; Function Attrs: norecurse nounwind
define internal void @_QFPomp_subroutine..omp_par(ptr noalias %tid.addr, ptr noalias %zero.addr, ptr %0) #2 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %gep_3 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 2
  %loadgep_4 = load ptr, ptr %gep_3, align 8
  %gep_5 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 3
  %loadgep_6 = load ptr, ptr %gep_5, align 8
  %gep_7 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 4
  %loadgep_8 = load ptr, ptr %gep_7, align 8
  %1 = call i32 @omp_get_thread_num()
  %2 = call i32 @omp_get_num_threads()
  %3 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %4 = sdiv i32 %3, %2
  %5 = mul i32 %1, %4
  %6 = add i32 %5, 1
  %7 = add i32 %2, -1
  %8 = icmp eq i32 %1, %7
  %9 = add i32 %6, %4
  %spec.select = select i1 %8, i32 %3, i32 %9
  %.unpack = load ptr, ptr %loadgep_2, align 8, !tbaa !8
  %.elt14 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  %.unpack15 = load i64, ptr %.elt14, align 8, !tbaa !8
  %.elt16 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  %.unpack17 = load i32, ptr %.elt16, align 8, !tbaa !8
  %.elt18 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  %.unpack19 = load i8, ptr %.elt18, align 4, !tbaa !8
  %.elt20 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  %.unpack21 = load i8, ptr %.elt20, align 1, !tbaa !8
  %.elt22 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  %.unpack23 = load i8, ptr %.elt22, align 2, !tbaa !8
  %.elt24 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  %.unpack25 = load i8, ptr %.elt24, align 1, !tbaa !8
  %.elt26 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  %.unpack27.unpack.unpack = load i64, ptr %.elt26, align 8, !tbaa !8
  %.unpack27.unpack.elt29 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  %.unpack27.unpack.unpack30 = load i64, ptr %.unpack27.unpack.elt29, align 8, !tbaa !8
  %.unpack27.unpack.elt31 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  %.unpack27.unpack.unpack32 = load i64, ptr %.unpack27.unpack.elt31, align 8, !tbaa !8
  store ptr %.unpack, ptr %loadgep_4, align 8, !tbaa !8
  %loadgep_4.repack34 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 1
  store i64 %.unpack15, ptr %loadgep_4.repack34, align 8, !tbaa !8
  %loadgep_4.repack36 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 2
  store i32 %.unpack17, ptr %loadgep_4.repack36, align 8, !tbaa !8
  %loadgep_4.repack38 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 3
  store i8 %.unpack19, ptr %loadgep_4.repack38, align 4, !tbaa !8
  %loadgep_4.repack40 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 4
  store i8 %.unpack21, ptr %loadgep_4.repack40, align 1, !tbaa !8
  %loadgep_4.repack42 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 5
  store i8 %.unpack23, ptr %loadgep_4.repack42, align 2, !tbaa !8
  %loadgep_4.repack44 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 6
  store i8 %.unpack25, ptr %loadgep_4.repack44, align 1, !tbaa !8
  %loadgep_4.repack46 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7
  store i64 %.unpack27.unpack.unpack, ptr %loadgep_4.repack46, align 8, !tbaa !8
  %loadgep_4.repack46.repack48 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack27.unpack.unpack30, ptr %loadgep_4.repack46.repack48, align 8, !tbaa !8
  %loadgep_4.repack46.repack50 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 2
  store i64 %.unpack27.unpack.unpack32, ptr %loadgep_4.repack46.repack50, align 8, !tbaa !8
  %10 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 0
  %11 = load i64, ptr %10, align 8, !tbaa !8
  %12 = icmp eq i64 %.unpack27.unpack.unpack30, 0
  %13 = select i1 %12, i64 1, i64 %11
  store ptr %.unpack, ptr %loadgep_6, align 8, !tbaa !8
  %loadgep_6.repack52 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 1
  store i64 8, ptr %loadgep_6.repack52, align 8, !tbaa !8
  %loadgep_6.repack54 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 2
  store i32 20180515, ptr %loadgep_6.repack54, align 8, !tbaa !8
  %loadgep_6.repack56 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 3
  store i8 1, ptr %loadgep_6.repack56, align 4, !tbaa !8
  %loadgep_6.repack58 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 4
  store i8 28, ptr %loadgep_6.repack58, align 1, !tbaa !8
  %loadgep_6.repack60 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 5
  store i8 0, ptr %loadgep_6.repack60, align 2, !tbaa !8
  %loadgep_6.repack62 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 6
  store i8 0, ptr %loadgep_6.repack62, align 1, !tbaa !8
  %loadgep_6.repack64 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7
  store i64 %13, ptr %loadgep_6.repack64, align 8, !tbaa !8
  %loadgep_6.repack64.repack66 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack27.unpack.unpack30, ptr %loadgep_6.repack64.repack66, align 8, !tbaa !8
  %loadgep_6.repack64.repack68 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7, i64 0, i64 2
  store i64 8, ptr %loadgep_6.repack64.repack68, align 8, !tbaa !8
  %14 = load ptr, ptr %loadgep_8, align 8, !tbaa !4
  %15 = getelementptr { ptr, ptr }, ptr %loadgep_8, i64 0, i32 1
  %16 = load ptr, ptr %15, align 8, !tbaa !4
  %17 = sext i32 %6 to i64
  %18 = sext i32 %spec.select to i64
  %reass.sub9.i = sub nsw i64 %18, %17
  %19 = icmp sgt i64 %reass.sub9.i, -1
  br i1 %19, label %.lr.ph8.preheader.i, label %_QFPloop.exit

.lr.ph8.preheader.i:                              ; preds = %omp.par.entry
  %20 = add nuw nsw i64 %reass.sub9.i, 1
  br label %.lr.ph8.i

.lr.ph8.i:                                        ; preds = %.lr.ph8.i, %.lr.ph8.preheader.i
  %21 = phi i64 [ %31, %.lr.ph8.i ], [ %20, %.lr.ph8.preheader.i ]
  %22 = phi i32 [ %30, %.lr.ph8.i ], [ %6, %.lr.ph8.preheader.i ]
  %23 = load i32, ptr %14, align 4, !tbaa !4
  %24 = sitofp i32 %23 to float
  %25 = fdiv contract float 1.000000e+00, %24
  %26 = fpext float %25 to double
  %27 = sext i32 %22 to i64
  %28 = add nsw i64 %27, -1
  %29 = getelementptr double, ptr %.unpack, i64 %28
  store double %26, ptr %29, align 8, !tbaa !4
  store double %26, ptr %16, align 8, !tbaa !4
  %30 = add i32 %22, 1
  %31 = add nsw i64 %21, -1
  %32 = icmp ugt i64 %21, 1
  br i1 %32, label %.lr.ph8.i, label %_QFPloop.exit

_QFPloop.exit:                                    ; preds = %omp.par.entry, %.lr.ph8.i
  ret void
}
*** IR Dump After TailCallElimPass on _QFPomp_subroutine..omp_par ***
; Function Attrs: norecurse nounwind
define internal void @_QFPomp_subroutine..omp_par(ptr noalias %tid.addr, ptr noalias %zero.addr, ptr %0) #2 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %gep_3 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 2
  %loadgep_4 = load ptr, ptr %gep_3, align 8
  %gep_5 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 3
  %loadgep_6 = load ptr, ptr %gep_5, align 8
  %gep_7 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 4
  %loadgep_8 = load ptr, ptr %gep_7, align 8
  %1 = tail call i32 @omp_get_thread_num()
  %2 = tail call i32 @omp_get_num_threads()
  %3 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %4 = sdiv i32 %3, %2
  %5 = mul i32 %1, %4
  %6 = add i32 %5, 1
  %7 = add i32 %2, -1
  %8 = icmp eq i32 %1, %7
  %9 = add i32 %6, %4
  %spec.select = select i1 %8, i32 %3, i32 %9
  %.unpack = load ptr, ptr %loadgep_2, align 8, !tbaa !8
  %.elt14 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  %.unpack15 = load i64, ptr %.elt14, align 8, !tbaa !8
  %.elt16 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  %.unpack17 = load i32, ptr %.elt16, align 8, !tbaa !8
  %.elt18 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  %.unpack19 = load i8, ptr %.elt18, align 4, !tbaa !8
  %.elt20 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  %.unpack21 = load i8, ptr %.elt20, align 1, !tbaa !8
  %.elt22 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  %.unpack23 = load i8, ptr %.elt22, align 2, !tbaa !8
  %.elt24 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  %.unpack25 = load i8, ptr %.elt24, align 1, !tbaa !8
  %.elt26 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  %.unpack27.unpack.unpack = load i64, ptr %.elt26, align 8, !tbaa !8
  %.unpack27.unpack.elt29 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  %.unpack27.unpack.unpack30 = load i64, ptr %.unpack27.unpack.elt29, align 8, !tbaa !8
  %.unpack27.unpack.elt31 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  %.unpack27.unpack.unpack32 = load i64, ptr %.unpack27.unpack.elt31, align 8, !tbaa !8
  store ptr %.unpack, ptr %loadgep_4, align 8, !tbaa !8
  %loadgep_4.repack34 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 1
  store i64 %.unpack15, ptr %loadgep_4.repack34, align 8, !tbaa !8
  %loadgep_4.repack36 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 2
  store i32 %.unpack17, ptr %loadgep_4.repack36, align 8, !tbaa !8
  %loadgep_4.repack38 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 3
  store i8 %.unpack19, ptr %loadgep_4.repack38, align 4, !tbaa !8
  %loadgep_4.repack40 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 4
  store i8 %.unpack21, ptr %loadgep_4.repack40, align 1, !tbaa !8
  %loadgep_4.repack42 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 5
  store i8 %.unpack23, ptr %loadgep_4.repack42, align 2, !tbaa !8
  %loadgep_4.repack44 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 6
  store i8 %.unpack25, ptr %loadgep_4.repack44, align 1, !tbaa !8
  %loadgep_4.repack46 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7
  store i64 %.unpack27.unpack.unpack, ptr %loadgep_4.repack46, align 8, !tbaa !8
  %loadgep_4.repack46.repack48 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack27.unpack.unpack30, ptr %loadgep_4.repack46.repack48, align 8, !tbaa !8
  %loadgep_4.repack46.repack50 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 2
  store i64 %.unpack27.unpack.unpack32, ptr %loadgep_4.repack46.repack50, align 8, !tbaa !8
  %10 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 0
  %11 = load i64, ptr %10, align 8, !tbaa !8
  %12 = icmp eq i64 %.unpack27.unpack.unpack30, 0
  %13 = select i1 %12, i64 1, i64 %11
  store ptr %.unpack, ptr %loadgep_6, align 8, !tbaa !8
  %loadgep_6.repack52 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 1
  store i64 8, ptr %loadgep_6.repack52, align 8, !tbaa !8
  %loadgep_6.repack54 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 2
  store i32 20180515, ptr %loadgep_6.repack54, align 8, !tbaa !8
  %loadgep_6.repack56 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 3
  store i8 1, ptr %loadgep_6.repack56, align 4, !tbaa !8
  %loadgep_6.repack58 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 4
  store i8 28, ptr %loadgep_6.repack58, align 1, !tbaa !8
  %loadgep_6.repack60 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 5
  store i8 0, ptr %loadgep_6.repack60, align 2, !tbaa !8
  %loadgep_6.repack62 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 6
  store i8 0, ptr %loadgep_6.repack62, align 1, !tbaa !8
  %loadgep_6.repack64 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7
  store i64 %13, ptr %loadgep_6.repack64, align 8, !tbaa !8
  %loadgep_6.repack64.repack66 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack27.unpack.unpack30, ptr %loadgep_6.repack64.repack66, align 8, !tbaa !8
  %loadgep_6.repack64.repack68 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7, i64 0, i64 2
  store i64 8, ptr %loadgep_6.repack64.repack68, align 8, !tbaa !8
  %14 = load ptr, ptr %loadgep_8, align 8, !tbaa !4
  %15 = getelementptr { ptr, ptr }, ptr %loadgep_8, i64 0, i32 1
  %16 = load ptr, ptr %15, align 8, !tbaa !4
  %17 = sext i32 %6 to i64
  %18 = sext i32 %spec.select to i64
  %reass.sub9.i = sub nsw i64 %18, %17
  %19 = icmp sgt i64 %reass.sub9.i, -1
  br i1 %19, label %.lr.ph8.preheader.i, label %_QFPloop.exit

.lr.ph8.preheader.i:                              ; preds = %omp.par.entry
  %20 = add nuw nsw i64 %reass.sub9.i, 1
  br label %.lr.ph8.i

.lr.ph8.i:                                        ; preds = %.lr.ph8.i, %.lr.ph8.preheader.i
  %21 = phi i64 [ %31, %.lr.ph8.i ], [ %20, %.lr.ph8.preheader.i ]
  %22 = phi i32 [ %30, %.lr.ph8.i ], [ %6, %.lr.ph8.preheader.i ]
  %23 = load i32, ptr %14, align 4, !tbaa !4
  %24 = sitofp i32 %23 to float
  %25 = fdiv contract float 1.000000e+00, %24
  %26 = fpext float %25 to double
  %27 = sext i32 %22 to i64
  %28 = add nsw i64 %27, -1
  %29 = getelementptr double, ptr %.unpack, i64 %28
  store double %26, ptr %29, align 8, !tbaa !4
  store double %26, ptr %16, align 8, !tbaa !4
  %30 = add i32 %22, 1
  %31 = add nsw i64 %21, -1
  %32 = icmp ugt i64 %21, 1
  br i1 %32, label %.lr.ph8.i, label %_QFPloop.exit

_QFPloop.exit:                                    ; preds = %omp.par.entry, %.lr.ph8.i
  ret void
}
*** IR Dump After SimplifyCFGPass on _QFPomp_subroutine..omp_par ***
; Function Attrs: norecurse nounwind
define internal void @_QFPomp_subroutine..omp_par(ptr noalias %tid.addr, ptr noalias %zero.addr, ptr %0) #2 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %gep_3 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 2
  %loadgep_4 = load ptr, ptr %gep_3, align 8
  %gep_5 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 3
  %loadgep_6 = load ptr, ptr %gep_5, align 8
  %gep_7 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 4
  %loadgep_8 = load ptr, ptr %gep_7, align 8
  %1 = tail call i32 @omp_get_thread_num()
  %2 = tail call i32 @omp_get_num_threads()
  %3 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %4 = sdiv i32 %3, %2
  %5 = mul i32 %1, %4
  %6 = add i32 %5, 1
  %7 = add i32 %2, -1
  %8 = icmp eq i32 %1, %7
  %9 = add i32 %6, %4
  %spec.select = select i1 %8, i32 %3, i32 %9
  %.unpack = load ptr, ptr %loadgep_2, align 8, !tbaa !8
  %.elt14 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  %.unpack15 = load i64, ptr %.elt14, align 8, !tbaa !8
  %.elt16 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  %.unpack17 = load i32, ptr %.elt16, align 8, !tbaa !8
  %.elt18 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  %.unpack19 = load i8, ptr %.elt18, align 4, !tbaa !8
  %.elt20 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  %.unpack21 = load i8, ptr %.elt20, align 1, !tbaa !8
  %.elt22 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  %.unpack23 = load i8, ptr %.elt22, align 2, !tbaa !8
  %.elt24 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  %.unpack25 = load i8, ptr %.elt24, align 1, !tbaa !8
  %.elt26 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  %.unpack27.unpack.unpack = load i64, ptr %.elt26, align 8, !tbaa !8
  %.unpack27.unpack.elt29 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  %.unpack27.unpack.unpack30 = load i64, ptr %.unpack27.unpack.elt29, align 8, !tbaa !8
  %.unpack27.unpack.elt31 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  %.unpack27.unpack.unpack32 = load i64, ptr %.unpack27.unpack.elt31, align 8, !tbaa !8
  store ptr %.unpack, ptr %loadgep_4, align 8, !tbaa !8
  %loadgep_4.repack34 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 1
  store i64 %.unpack15, ptr %loadgep_4.repack34, align 8, !tbaa !8
  %loadgep_4.repack36 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 2
  store i32 %.unpack17, ptr %loadgep_4.repack36, align 8, !tbaa !8
  %loadgep_4.repack38 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 3
  store i8 %.unpack19, ptr %loadgep_4.repack38, align 4, !tbaa !8
  %loadgep_4.repack40 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 4
  store i8 %.unpack21, ptr %loadgep_4.repack40, align 1, !tbaa !8
  %loadgep_4.repack42 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 5
  store i8 %.unpack23, ptr %loadgep_4.repack42, align 2, !tbaa !8
  %loadgep_4.repack44 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 6
  store i8 %.unpack25, ptr %loadgep_4.repack44, align 1, !tbaa !8
  %loadgep_4.repack46 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7
  store i64 %.unpack27.unpack.unpack, ptr %loadgep_4.repack46, align 8, !tbaa !8
  %loadgep_4.repack46.repack48 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack27.unpack.unpack30, ptr %loadgep_4.repack46.repack48, align 8, !tbaa !8
  %loadgep_4.repack46.repack50 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 2
  store i64 %.unpack27.unpack.unpack32, ptr %loadgep_4.repack46.repack50, align 8, !tbaa !8
  %10 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 0
  %11 = load i64, ptr %10, align 8, !tbaa !8
  %12 = icmp eq i64 %.unpack27.unpack.unpack30, 0
  %13 = select i1 %12, i64 1, i64 %11
  store ptr %.unpack, ptr %loadgep_6, align 8, !tbaa !8
  %loadgep_6.repack52 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 1
  store i64 8, ptr %loadgep_6.repack52, align 8, !tbaa !8
  %loadgep_6.repack54 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 2
  store i32 20180515, ptr %loadgep_6.repack54, align 8, !tbaa !8
  %loadgep_6.repack56 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 3
  store i8 1, ptr %loadgep_6.repack56, align 4, !tbaa !8
  %loadgep_6.repack58 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 4
  store i8 28, ptr %loadgep_6.repack58, align 1, !tbaa !8
  %loadgep_6.repack60 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 5
  store i8 0, ptr %loadgep_6.repack60, align 2, !tbaa !8
  %loadgep_6.repack62 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 6
  store i8 0, ptr %loadgep_6.repack62, align 1, !tbaa !8
  %loadgep_6.repack64 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7
  store i64 %13, ptr %loadgep_6.repack64, align 8, !tbaa !8
  %loadgep_6.repack64.repack66 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack27.unpack.unpack30, ptr %loadgep_6.repack64.repack66, align 8, !tbaa !8
  %loadgep_6.repack64.repack68 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7, i64 0, i64 2
  store i64 8, ptr %loadgep_6.repack64.repack68, align 8, !tbaa !8
  %14 = load ptr, ptr %loadgep_8, align 8, !tbaa !4
  %15 = getelementptr { ptr, ptr }, ptr %loadgep_8, i64 0, i32 1
  %16 = load ptr, ptr %15, align 8, !tbaa !4
  %17 = sext i32 %6 to i64
  %18 = sext i32 %spec.select to i64
  %reass.sub9.i = sub nsw i64 %18, %17
  %19 = icmp sgt i64 %reass.sub9.i, -1
  br i1 %19, label %.lr.ph8.preheader.i, label %_QFPloop.exit

.lr.ph8.preheader.i:                              ; preds = %omp.par.entry
  %20 = add nuw nsw i64 %reass.sub9.i, 1
  br label %.lr.ph8.i

.lr.ph8.i:                                        ; preds = %.lr.ph8.i, %.lr.ph8.preheader.i
  %21 = phi i64 [ %31, %.lr.ph8.i ], [ %20, %.lr.ph8.preheader.i ]
  %22 = phi i32 [ %30, %.lr.ph8.i ], [ %6, %.lr.ph8.preheader.i ]
  %23 = load i32, ptr %14, align 4, !tbaa !4
  %24 = sitofp i32 %23 to float
  %25 = fdiv contract float 1.000000e+00, %24
  %26 = fpext float %25 to double
  %27 = sext i32 %22 to i64
  %28 = add nsw i64 %27, -1
  %29 = getelementptr double, ptr %.unpack, i64 %28
  store double %26, ptr %29, align 8, !tbaa !4
  store double %26, ptr %16, align 8, !tbaa !4
  %30 = add i32 %22, 1
  %31 = add nsw i64 %21, -1
  %32 = icmp ugt i64 %21, 1
  br i1 %32, label %.lr.ph8.i, label %_QFPloop.exit

_QFPloop.exit:                                    ; preds = %omp.par.entry, %.lr.ph8.i
  ret void
}
*** IR Dump After ReassociatePass on _QFPomp_subroutine..omp_par ***
; Function Attrs: norecurse nounwind
define internal void @_QFPomp_subroutine..omp_par(ptr noalias %tid.addr, ptr noalias %zero.addr, ptr %0) #2 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %gep_3 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 2
  %loadgep_4 = load ptr, ptr %gep_3, align 8
  %gep_5 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 3
  %loadgep_6 = load ptr, ptr %gep_5, align 8
  %gep_7 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 4
  %loadgep_8 = load ptr, ptr %gep_7, align 8
  %1 = tail call i32 @omp_get_thread_num()
  %2 = tail call i32 @omp_get_num_threads()
  %3 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %4 = sdiv i32 %3, %2
  %5 = mul i32 %4, %1
  %6 = add i32 %5, 1
  %7 = add i32 %2, -1
  %8 = icmp eq i32 %1, %7
  %9 = add i32 %6, %4
  %spec.select = select i1 %8, i32 %3, i32 %9
  %.unpack = load ptr, ptr %loadgep_2, align 8, !tbaa !8
  %.elt14 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  %.unpack15 = load i64, ptr %.elt14, align 8, !tbaa !8
  %.elt16 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  %.unpack17 = load i32, ptr %.elt16, align 8, !tbaa !8
  %.elt18 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  %.unpack19 = load i8, ptr %.elt18, align 4, !tbaa !8
  %.elt20 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  %.unpack21 = load i8, ptr %.elt20, align 1, !tbaa !8
  %.elt22 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  %.unpack23 = load i8, ptr %.elt22, align 2, !tbaa !8
  %.elt24 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  %.unpack25 = load i8, ptr %.elt24, align 1, !tbaa !8
  %.elt26 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  %.unpack27.unpack.unpack = load i64, ptr %.elt26, align 8, !tbaa !8
  %.unpack27.unpack.elt29 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  %.unpack27.unpack.unpack30 = load i64, ptr %.unpack27.unpack.elt29, align 8, !tbaa !8
  %.unpack27.unpack.elt31 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  %.unpack27.unpack.unpack32 = load i64, ptr %.unpack27.unpack.elt31, align 8, !tbaa !8
  store ptr %.unpack, ptr %loadgep_4, align 8, !tbaa !8
  %loadgep_4.repack34 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 1
  store i64 %.unpack15, ptr %loadgep_4.repack34, align 8, !tbaa !8
  %loadgep_4.repack36 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 2
  store i32 %.unpack17, ptr %loadgep_4.repack36, align 8, !tbaa !8
  %loadgep_4.repack38 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 3
  store i8 %.unpack19, ptr %loadgep_4.repack38, align 4, !tbaa !8
  %loadgep_4.repack40 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 4
  store i8 %.unpack21, ptr %loadgep_4.repack40, align 1, !tbaa !8
  %loadgep_4.repack42 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 5
  store i8 %.unpack23, ptr %loadgep_4.repack42, align 2, !tbaa !8
  %loadgep_4.repack44 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 6
  store i8 %.unpack25, ptr %loadgep_4.repack44, align 1, !tbaa !8
  %loadgep_4.repack46 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7
  store i64 %.unpack27.unpack.unpack, ptr %loadgep_4.repack46, align 8, !tbaa !8
  %loadgep_4.repack46.repack48 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack27.unpack.unpack30, ptr %loadgep_4.repack46.repack48, align 8, !tbaa !8
  %loadgep_4.repack46.repack50 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 2
  store i64 %.unpack27.unpack.unpack32, ptr %loadgep_4.repack46.repack50, align 8, !tbaa !8
  %10 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 0
  %11 = load i64, ptr %10, align 8, !tbaa !8
  %12 = icmp eq i64 %.unpack27.unpack.unpack30, 0
  %13 = select i1 %12, i64 1, i64 %11
  store ptr %.unpack, ptr %loadgep_6, align 8, !tbaa !8
  %loadgep_6.repack52 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 1
  store i64 8, ptr %loadgep_6.repack52, align 8, !tbaa !8
  %loadgep_6.repack54 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 2
  store i32 20180515, ptr %loadgep_6.repack54, align 8, !tbaa !8
  %loadgep_6.repack56 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 3
  store i8 1, ptr %loadgep_6.repack56, align 4, !tbaa !8
  %loadgep_6.repack58 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 4
  store i8 28, ptr %loadgep_6.repack58, align 1, !tbaa !8
  %loadgep_6.repack60 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 5
  store i8 0, ptr %loadgep_6.repack60, align 2, !tbaa !8
  %loadgep_6.repack62 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 6
  store i8 0, ptr %loadgep_6.repack62, align 1, !tbaa !8
  %loadgep_6.repack64 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7
  store i64 %13, ptr %loadgep_6.repack64, align 8, !tbaa !8
  %loadgep_6.repack64.repack66 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack27.unpack.unpack30, ptr %loadgep_6.repack64.repack66, align 8, !tbaa !8
  %loadgep_6.repack64.repack68 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7, i64 0, i64 2
  store i64 8, ptr %loadgep_6.repack64.repack68, align 8, !tbaa !8
  %14 = load ptr, ptr %loadgep_8, align 8, !tbaa !4
  %15 = getelementptr { ptr, ptr }, ptr %loadgep_8, i64 0, i32 1
  %16 = load ptr, ptr %15, align 8, !tbaa !4
  %17 = sext i32 %6 to i64
  %18 = sext i32 %spec.select to i64
  %reass.sub9.i = sub nsw i64 %18, %17
  %19 = icmp sgt i64 %reass.sub9.i, -1
  br i1 %19, label %.lr.ph8.preheader.i, label %_QFPloop.exit

.lr.ph8.preheader.i:                              ; preds = %omp.par.entry
  %20 = add nuw nsw i64 %reass.sub9.i, 1
  br label %.lr.ph8.i

.lr.ph8.i:                                        ; preds = %.lr.ph8.i, %.lr.ph8.preheader.i
  %21 = phi i64 [ %31, %.lr.ph8.i ], [ %20, %.lr.ph8.preheader.i ]
  %22 = phi i32 [ %30, %.lr.ph8.i ], [ %6, %.lr.ph8.preheader.i ]
  %23 = load i32, ptr %14, align 4, !tbaa !4
  %24 = sitofp i32 %23 to float
  %25 = fdiv contract float 1.000000e+00, %24
  %26 = fpext float %25 to double
  %27 = sext i32 %22 to i64
  %28 = add nsw i64 %27, -1
  %29 = getelementptr double, ptr %.unpack, i64 %28
  store double %26, ptr %29, align 8, !tbaa !4
  store double %26, ptr %16, align 8, !tbaa !4
  %30 = add i32 %22, 1
  %31 = add nsw i64 %21, -1
  %32 = icmp ugt i64 %21, 1
  br i1 %32, label %.lr.ph8.i, label %_QFPloop.exit

_QFPloop.exit:                                    ; preds = %omp.par.entry, %.lr.ph8.i
  ret void
}
*** IR Dump After LoopSimplifyPass on _QFPomp_subroutine..omp_par ***
; Function Attrs: norecurse nounwind
define internal void @_QFPomp_subroutine..omp_par(ptr noalias %tid.addr, ptr noalias %zero.addr, ptr %0) #2 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %gep_3 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 2
  %loadgep_4 = load ptr, ptr %gep_3, align 8
  %gep_5 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 3
  %loadgep_6 = load ptr, ptr %gep_5, align 8
  %gep_7 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 4
  %loadgep_8 = load ptr, ptr %gep_7, align 8
  %1 = tail call i32 @omp_get_thread_num()
  %2 = tail call i32 @omp_get_num_threads()
  %3 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %4 = sdiv i32 %3, %2
  %5 = mul i32 %4, %1
  %6 = add i32 %5, 1
  %7 = add i32 %2, -1
  %8 = icmp eq i32 %1, %7
  %9 = add i32 %6, %4
  %spec.select = select i1 %8, i32 %3, i32 %9
  %.unpack = load ptr, ptr %loadgep_2, align 8, !tbaa !8
  %.elt14 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  %.unpack15 = load i64, ptr %.elt14, align 8, !tbaa !8
  %.elt16 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  %.unpack17 = load i32, ptr %.elt16, align 8, !tbaa !8
  %.elt18 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  %.unpack19 = load i8, ptr %.elt18, align 4, !tbaa !8
  %.elt20 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  %.unpack21 = load i8, ptr %.elt20, align 1, !tbaa !8
  %.elt22 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  %.unpack23 = load i8, ptr %.elt22, align 2, !tbaa !8
  %.elt24 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  %.unpack25 = load i8, ptr %.elt24, align 1, !tbaa !8
  %.elt26 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  %.unpack27.unpack.unpack = load i64, ptr %.elt26, align 8, !tbaa !8
  %.unpack27.unpack.elt29 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  %.unpack27.unpack.unpack30 = load i64, ptr %.unpack27.unpack.elt29, align 8, !tbaa !8
  %.unpack27.unpack.elt31 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  %.unpack27.unpack.unpack32 = load i64, ptr %.unpack27.unpack.elt31, align 8, !tbaa !8
  store ptr %.unpack, ptr %loadgep_4, align 8, !tbaa !8
  %loadgep_4.repack34 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 1
  store i64 %.unpack15, ptr %loadgep_4.repack34, align 8, !tbaa !8
  %loadgep_4.repack36 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 2
  store i32 %.unpack17, ptr %loadgep_4.repack36, align 8, !tbaa !8
  %loadgep_4.repack38 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 3
  store i8 %.unpack19, ptr %loadgep_4.repack38, align 4, !tbaa !8
  %loadgep_4.repack40 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 4
  store i8 %.unpack21, ptr %loadgep_4.repack40, align 1, !tbaa !8
  %loadgep_4.repack42 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 5
  store i8 %.unpack23, ptr %loadgep_4.repack42, align 2, !tbaa !8
  %loadgep_4.repack44 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 6
  store i8 %.unpack25, ptr %loadgep_4.repack44, align 1, !tbaa !8
  %loadgep_4.repack46 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7
  store i64 %.unpack27.unpack.unpack, ptr %loadgep_4.repack46, align 8, !tbaa !8
  %loadgep_4.repack46.repack48 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack27.unpack.unpack30, ptr %loadgep_4.repack46.repack48, align 8, !tbaa !8
  %loadgep_4.repack46.repack50 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 2
  store i64 %.unpack27.unpack.unpack32, ptr %loadgep_4.repack46.repack50, align 8, !tbaa !8
  %10 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 0
  %11 = load i64, ptr %10, align 8, !tbaa !8
  %12 = icmp eq i64 %.unpack27.unpack.unpack30, 0
  %13 = select i1 %12, i64 1, i64 %11
  store ptr %.unpack, ptr %loadgep_6, align 8, !tbaa !8
  %loadgep_6.repack52 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 1
  store i64 8, ptr %loadgep_6.repack52, align 8, !tbaa !8
  %loadgep_6.repack54 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 2
  store i32 20180515, ptr %loadgep_6.repack54, align 8, !tbaa !8
  %loadgep_6.repack56 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 3
  store i8 1, ptr %loadgep_6.repack56, align 4, !tbaa !8
  %loadgep_6.repack58 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 4
  store i8 28, ptr %loadgep_6.repack58, align 1, !tbaa !8
  %loadgep_6.repack60 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 5
  store i8 0, ptr %loadgep_6.repack60, align 2, !tbaa !8
  %loadgep_6.repack62 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 6
  store i8 0, ptr %loadgep_6.repack62, align 1, !tbaa !8
  %loadgep_6.repack64 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7
  store i64 %13, ptr %loadgep_6.repack64, align 8, !tbaa !8
  %loadgep_6.repack64.repack66 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack27.unpack.unpack30, ptr %loadgep_6.repack64.repack66, align 8, !tbaa !8
  %loadgep_6.repack64.repack68 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7, i64 0, i64 2
  store i64 8, ptr %loadgep_6.repack64.repack68, align 8, !tbaa !8
  %14 = load ptr, ptr %loadgep_8, align 8, !tbaa !4
  %15 = getelementptr { ptr, ptr }, ptr %loadgep_8, i64 0, i32 1
  %16 = load ptr, ptr %15, align 8, !tbaa !4
  %17 = sext i32 %6 to i64
  %18 = sext i32 %spec.select to i64
  %reass.sub9.i = sub nsw i64 %18, %17
  %19 = icmp sgt i64 %reass.sub9.i, -1
  br i1 %19, label %.lr.ph8.preheader.i, label %_QFPloop.exit

.lr.ph8.preheader.i:                              ; preds = %omp.par.entry
  %20 = add nuw nsw i64 %reass.sub9.i, 1
  br label %.lr.ph8.i

.lr.ph8.i:                                        ; preds = %.lr.ph8.i, %.lr.ph8.preheader.i
  %21 = phi i64 [ %31, %.lr.ph8.i ], [ %20, %.lr.ph8.preheader.i ]
  %22 = phi i32 [ %30, %.lr.ph8.i ], [ %6, %.lr.ph8.preheader.i ]
  %23 = load i32, ptr %14, align 4, !tbaa !4
  %24 = sitofp i32 %23 to float
  %25 = fdiv contract float 1.000000e+00, %24
  %26 = fpext float %25 to double
  %27 = sext i32 %22 to i64
  %28 = add nsw i64 %27, -1
  %29 = getelementptr double, ptr %.unpack, i64 %28
  store double %26, ptr %29, align 8, !tbaa !4
  store double %26, ptr %16, align 8, !tbaa !4
  %30 = add i32 %22, 1
  %31 = add nsw i64 %21, -1
  %32 = icmp ugt i64 %21, 1
  br i1 %32, label %.lr.ph8.i, label %_QFPloop.exit.loopexit

_QFPloop.exit.loopexit:                           ; preds = %.lr.ph8.i
  br label %_QFPloop.exit

_QFPloop.exit:                                    ; preds = %_QFPloop.exit.loopexit, %omp.par.entry
  ret void
}
*** IR Dump After LCSSAPass on _QFPomp_subroutine..omp_par ***
; Function Attrs: norecurse nounwind
define internal void @_QFPomp_subroutine..omp_par(ptr noalias %tid.addr, ptr noalias %zero.addr, ptr %0) #2 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %gep_3 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 2
  %loadgep_4 = load ptr, ptr %gep_3, align 8
  %gep_5 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 3
  %loadgep_6 = load ptr, ptr %gep_5, align 8
  %gep_7 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 4
  %loadgep_8 = load ptr, ptr %gep_7, align 8
  %1 = tail call i32 @omp_get_thread_num()
  %2 = tail call i32 @omp_get_num_threads()
  %3 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %4 = sdiv i32 %3, %2
  %5 = mul i32 %4, %1
  %6 = add i32 %5, 1
  %7 = add i32 %2, -1
  %8 = icmp eq i32 %1, %7
  %9 = add i32 %6, %4
  %spec.select = select i1 %8, i32 %3, i32 %9
  %.unpack = load ptr, ptr %loadgep_2, align 8, !tbaa !8
  %.elt14 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  %.unpack15 = load i64, ptr %.elt14, align 8, !tbaa !8
  %.elt16 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  %.unpack17 = load i32, ptr %.elt16, align 8, !tbaa !8
  %.elt18 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  %.unpack19 = load i8, ptr %.elt18, align 4, !tbaa !8
  %.elt20 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  %.unpack21 = load i8, ptr %.elt20, align 1, !tbaa !8
  %.elt22 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  %.unpack23 = load i8, ptr %.elt22, align 2, !tbaa !8
  %.elt24 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  %.unpack25 = load i8, ptr %.elt24, align 1, !tbaa !8
  %.elt26 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  %.unpack27.unpack.unpack = load i64, ptr %.elt26, align 8, !tbaa !8
  %.unpack27.unpack.elt29 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  %.unpack27.unpack.unpack30 = load i64, ptr %.unpack27.unpack.elt29, align 8, !tbaa !8
  %.unpack27.unpack.elt31 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  %.unpack27.unpack.unpack32 = load i64, ptr %.unpack27.unpack.elt31, align 8, !tbaa !8
  store ptr %.unpack, ptr %loadgep_4, align 8, !tbaa !8
  %loadgep_4.repack34 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 1
  store i64 %.unpack15, ptr %loadgep_4.repack34, align 8, !tbaa !8
  %loadgep_4.repack36 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 2
  store i32 %.unpack17, ptr %loadgep_4.repack36, align 8, !tbaa !8
  %loadgep_4.repack38 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 3
  store i8 %.unpack19, ptr %loadgep_4.repack38, align 4, !tbaa !8
  %loadgep_4.repack40 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 4
  store i8 %.unpack21, ptr %loadgep_4.repack40, align 1, !tbaa !8
  %loadgep_4.repack42 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 5
  store i8 %.unpack23, ptr %loadgep_4.repack42, align 2, !tbaa !8
  %loadgep_4.repack44 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 6
  store i8 %.unpack25, ptr %loadgep_4.repack44, align 1, !tbaa !8
  %loadgep_4.repack46 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7
  store i64 %.unpack27.unpack.unpack, ptr %loadgep_4.repack46, align 8, !tbaa !8
  %loadgep_4.repack46.repack48 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack27.unpack.unpack30, ptr %loadgep_4.repack46.repack48, align 8, !tbaa !8
  %loadgep_4.repack46.repack50 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 2
  store i64 %.unpack27.unpack.unpack32, ptr %loadgep_4.repack46.repack50, align 8, !tbaa !8
  %10 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 0
  %11 = load i64, ptr %10, align 8, !tbaa !8
  %12 = icmp eq i64 %.unpack27.unpack.unpack30, 0
  %13 = select i1 %12, i64 1, i64 %11
  store ptr %.unpack, ptr %loadgep_6, align 8, !tbaa !8
  %loadgep_6.repack52 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 1
  store i64 8, ptr %loadgep_6.repack52, align 8, !tbaa !8
  %loadgep_6.repack54 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 2
  store i32 20180515, ptr %loadgep_6.repack54, align 8, !tbaa !8
  %loadgep_6.repack56 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 3
  store i8 1, ptr %loadgep_6.repack56, align 4, !tbaa !8
  %loadgep_6.repack58 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 4
  store i8 28, ptr %loadgep_6.repack58, align 1, !tbaa !8
  %loadgep_6.repack60 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 5
  store i8 0, ptr %loadgep_6.repack60, align 2, !tbaa !8
  %loadgep_6.repack62 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 6
  store i8 0, ptr %loadgep_6.repack62, align 1, !tbaa !8
  %loadgep_6.repack64 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7
  store i64 %13, ptr %loadgep_6.repack64, align 8, !tbaa !8
  %loadgep_6.repack64.repack66 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack27.unpack.unpack30, ptr %loadgep_6.repack64.repack66, align 8, !tbaa !8
  %loadgep_6.repack64.repack68 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7, i64 0, i64 2
  store i64 8, ptr %loadgep_6.repack64.repack68, align 8, !tbaa !8
  %14 = load ptr, ptr %loadgep_8, align 8, !tbaa !4
  %15 = getelementptr { ptr, ptr }, ptr %loadgep_8, i64 0, i32 1
  %16 = load ptr, ptr %15, align 8, !tbaa !4
  %17 = sext i32 %6 to i64
  %18 = sext i32 %spec.select to i64
  %reass.sub9.i = sub nsw i64 %18, %17
  %19 = icmp sgt i64 %reass.sub9.i, -1
  br i1 %19, label %.lr.ph8.preheader.i, label %_QFPloop.exit

.lr.ph8.preheader.i:                              ; preds = %omp.par.entry
  %20 = add nuw nsw i64 %reass.sub9.i, 1
  br label %.lr.ph8.i

.lr.ph8.i:                                        ; preds = %.lr.ph8.i, %.lr.ph8.preheader.i
  %21 = phi i64 [ %31, %.lr.ph8.i ], [ %20, %.lr.ph8.preheader.i ]
  %22 = phi i32 [ %30, %.lr.ph8.i ], [ %6, %.lr.ph8.preheader.i ]
  %23 = load i32, ptr %14, align 4, !tbaa !4
  %24 = sitofp i32 %23 to float
  %25 = fdiv contract float 1.000000e+00, %24
  %26 = fpext float %25 to double
  %27 = sext i32 %22 to i64
  %28 = add nsw i64 %27, -1
  %29 = getelementptr double, ptr %.unpack, i64 %28
  store double %26, ptr %29, align 8, !tbaa !4
  store double %26, ptr %16, align 8, !tbaa !4
  %30 = add i32 %22, 1
  %31 = add nsw i64 %21, -1
  %32 = icmp ugt i64 %21, 1
  br i1 %32, label %.lr.ph8.i, label %_QFPloop.exit.loopexit

_QFPloop.exit.loopexit:                           ; preds = %.lr.ph8.i
  br label %_QFPloop.exit

_QFPloop.exit:                                    ; preds = %_QFPloop.exit.loopexit, %omp.par.entry
  ret void
}
*** IR Dump After LoopInstSimplifyPass on .lr.ph8.i ***

; Preheader:
.lr.ph8.preheader.i:                              ; preds = %omp.par.entry
  %20 = add nuw nsw i64 %reass.sub9.i, 1
  br label %.lr.ph8.i

; Loop:
.lr.ph8.i:                                        ; preds = %.lr.ph8.i, %.lr.ph8.preheader.i
  %21 = phi i64 [ %31, %.lr.ph8.i ], [ %20, %.lr.ph8.preheader.i ]
  %22 = phi i32 [ %30, %.lr.ph8.i ], [ %6, %.lr.ph8.preheader.i ]
  %23 = load i32, ptr %14, align 4, !tbaa !4
  %24 = sitofp i32 %23 to float
  %25 = fdiv contract float 1.000000e+00, %24
  %26 = fpext float %25 to double
  %27 = sext i32 %22 to i64
  %28 = add nsw i64 %27, -1
  %29 = getelementptr double, ptr %.unpack, i64 %28
  store double %26, ptr %29, align 8, !tbaa !4
  store double %26, ptr %16, align 8, !tbaa !4
  %30 = add i32 %22, 1
  %31 = add nsw i64 %21, -1
  %32 = icmp ugt i64 %21, 1
  br i1 %32, label %.lr.ph8.i, label %_QFPloop.exit.loopexit

; Exit blocks
_QFPloop.exit.loopexit:                           ; preds = %.lr.ph8.i
  br label %_QFPloop.exit
*** IR Dump After LoopSimplifyCFGPass on .lr.ph8.i ***

; Preheader:
.lr.ph8.preheader.i:                              ; preds = %omp.par.entry
  %20 = add nuw nsw i64 %reass.sub9.i, 1
  br label %.lr.ph8.i

; Loop:
.lr.ph8.i:                                        ; preds = %.lr.ph8.i, %.lr.ph8.preheader.i
  %21 = phi i64 [ %31, %.lr.ph8.i ], [ %20, %.lr.ph8.preheader.i ]
  %22 = phi i32 [ %30, %.lr.ph8.i ], [ %6, %.lr.ph8.preheader.i ]
  %23 = load i32, ptr %14, align 4, !tbaa !4
  %24 = sitofp i32 %23 to float
  %25 = fdiv contract float 1.000000e+00, %24
  %26 = fpext float %25 to double
  %27 = sext i32 %22 to i64
  %28 = add nsw i64 %27, -1
  %29 = getelementptr double, ptr %.unpack, i64 %28
  store double %26, ptr %29, align 8, !tbaa !4
  store double %26, ptr %16, align 8, !tbaa !4
  %30 = add i32 %22, 1
  %31 = add nsw i64 %21, -1
  %32 = icmp ugt i64 %21, 1
  br i1 %32, label %.lr.ph8.i, label %_QFPloop.exit.loopexit

; Exit blocks
_QFPloop.exit.loopexit:                           ; preds = %.lr.ph8.i
  br label %_QFPloop.exit
*** IR Dump After LICMPass on .lr.ph8.i ***

; Preheader:
.lr.ph8.preheader.i:                              ; preds = %omp.par.entry
  %20 = add nuw nsw i64 %reass.sub9.i, 1
  br label %.lr.ph8.i

; Loop:
.lr.ph8.i:                                        ; preds = %.lr.ph8.i, %.lr.ph8.preheader.i
  %21 = phi i64 [ %31, %.lr.ph8.i ], [ %20, %.lr.ph8.preheader.i ]
  %22 = phi i32 [ %30, %.lr.ph8.i ], [ %6, %.lr.ph8.preheader.i ]
  %23 = load i32, ptr %14, align 4, !tbaa !4
  %24 = sitofp i32 %23 to float
  %25 = fdiv contract float 1.000000e+00, %24
  %26 = fpext float %25 to double
  %27 = sext i32 %22 to i64
  %28 = add nsw i64 %27, -1
  %29 = getelementptr double, ptr %.unpack, i64 %28
  store double %26, ptr %29, align 8, !tbaa !4
  store double %26, ptr %16, align 8, !tbaa !4
  %30 = add i32 %22, 1
  %31 = add nsw i64 %21, -1
  %32 = icmp ugt i64 %21, 1
  br i1 %32, label %.lr.ph8.i, label %_QFPloop.exit.loopexit

; Exit blocks
_QFPloop.exit.loopexit:                           ; preds = %.lr.ph8.i
  br label %_QFPloop.exit
*** IR Dump After LoopRotatePass on .lr.ph8.i ***

; Preheader:
.lr.ph8.preheader.i:                              ; preds = %omp.par.entry
  %20 = add nuw nsw i64 %reass.sub9.i, 1
  br label %.lr.ph8.i

; Loop:
.lr.ph8.i:                                        ; preds = %.lr.ph8.i, %.lr.ph8.preheader.i
  %21 = phi i64 [ %31, %.lr.ph8.i ], [ %20, %.lr.ph8.preheader.i ]
  %22 = phi i32 [ %30, %.lr.ph8.i ], [ %6, %.lr.ph8.preheader.i ]
  %23 = load i32, ptr %14, align 4, !tbaa !4
  %24 = sitofp i32 %23 to float
  %25 = fdiv contract float 1.000000e+00, %24
  %26 = fpext float %25 to double
  %27 = sext i32 %22 to i64
  %28 = add nsw i64 %27, -1
  %29 = getelementptr double, ptr %.unpack, i64 %28
  store double %26, ptr %29, align 8, !tbaa !4
  store double %26, ptr %16, align 8, !tbaa !4
  %30 = add i32 %22, 1
  %31 = add nsw i64 %21, -1
  %32 = icmp ugt i64 %21, 1
  br i1 %32, label %.lr.ph8.i, label %_QFPloop.exit.loopexit

; Exit blocks
_QFPloop.exit.loopexit:                           ; preds = %.lr.ph8.i
  br label %_QFPloop.exit
*** IR Dump After LICMPass on .lr.ph8.i ***

; Preheader:
.lr.ph8.preheader.i:                              ; preds = %omp.par.entry
  %20 = add nuw nsw i64 %reass.sub9.i, 1
  br label %.lr.ph8.i

; Loop:
.lr.ph8.i:                                        ; preds = %.lr.ph8.i, %.lr.ph8.preheader.i
  %21 = phi i64 [ %31, %.lr.ph8.i ], [ %20, %.lr.ph8.preheader.i ]
  %22 = phi i32 [ %30, %.lr.ph8.i ], [ %6, %.lr.ph8.preheader.i ]
  %23 = load i32, ptr %14, align 4, !tbaa !4
  %24 = sitofp i32 %23 to float
  %25 = fdiv contract float 1.000000e+00, %24
  %26 = fpext float %25 to double
  %27 = sext i32 %22 to i64
  %28 = add nsw i64 %27, -1
  %29 = getelementptr double, ptr %.unpack, i64 %28
  store double %26, ptr %29, align 8, !tbaa !4
  store double %26, ptr %16, align 8, !tbaa !4
  %30 = add i32 %22, 1
  %31 = add nsw i64 %21, -1
  %32 = icmp ugt i64 %21, 1
  br i1 %32, label %.lr.ph8.i, label %_QFPloop.exit.loopexit

; Exit blocks
_QFPloop.exit.loopexit:                           ; preds = %.lr.ph8.i
  br label %_QFPloop.exit
*** IR Dump After SimpleLoopUnswitchPass on .lr.ph8.i ***

; Preheader:
.lr.ph8.preheader.i:                              ; preds = %omp.par.entry
  %20 = add nuw nsw i64 %reass.sub9.i, 1
  br label %.lr.ph8.i

; Loop:
.lr.ph8.i:                                        ; preds = %.lr.ph8.i, %.lr.ph8.preheader.i
  %21 = phi i64 [ %31, %.lr.ph8.i ], [ %20, %.lr.ph8.preheader.i ]
  %22 = phi i32 [ %30, %.lr.ph8.i ], [ %6, %.lr.ph8.preheader.i ]
  %23 = load i32, ptr %14, align 4, !tbaa !4
  %24 = sitofp i32 %23 to float
  %25 = fdiv contract float 1.000000e+00, %24
  %26 = fpext float %25 to double
  %27 = sext i32 %22 to i64
  %28 = add nsw i64 %27, -1
  %29 = getelementptr double, ptr %.unpack, i64 %28
  store double %26, ptr %29, align 8, !tbaa !4
  store double %26, ptr %16, align 8, !tbaa !4
  %30 = add i32 %22, 1
  %31 = add nsw i64 %21, -1
  %32 = icmp ugt i64 %21, 1
  br i1 %32, label %.lr.ph8.i, label %_QFPloop.exit.loopexit

; Exit blocks
_QFPloop.exit.loopexit:                           ; preds = %.lr.ph8.i
  br label %_QFPloop.exit
*** IR Dump After SimplifyCFGPass on _QFPomp_subroutine..omp_par ***
; Function Attrs: norecurse nounwind
define internal void @_QFPomp_subroutine..omp_par(ptr noalias %tid.addr, ptr noalias %zero.addr, ptr %0) #2 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %gep_3 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 2
  %loadgep_4 = load ptr, ptr %gep_3, align 8
  %gep_5 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 3
  %loadgep_6 = load ptr, ptr %gep_5, align 8
  %gep_7 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 4
  %loadgep_8 = load ptr, ptr %gep_7, align 8
  %1 = tail call i32 @omp_get_thread_num()
  %2 = tail call i32 @omp_get_num_threads()
  %3 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %4 = sdiv i32 %3, %2
  %5 = mul i32 %4, %1
  %6 = add i32 %5, 1
  %7 = add i32 %2, -1
  %8 = icmp eq i32 %1, %7
  %9 = add i32 %6, %4
  %spec.select = select i1 %8, i32 %3, i32 %9
  %.unpack = load ptr, ptr %loadgep_2, align 8, !tbaa !8
  %.elt14 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  %.unpack15 = load i64, ptr %.elt14, align 8, !tbaa !8
  %.elt16 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  %.unpack17 = load i32, ptr %.elt16, align 8, !tbaa !8
  %.elt18 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  %.unpack19 = load i8, ptr %.elt18, align 4, !tbaa !8
  %.elt20 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  %.unpack21 = load i8, ptr %.elt20, align 1, !tbaa !8
  %.elt22 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  %.unpack23 = load i8, ptr %.elt22, align 2, !tbaa !8
  %.elt24 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  %.unpack25 = load i8, ptr %.elt24, align 1, !tbaa !8
  %.elt26 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  %.unpack27.unpack.unpack = load i64, ptr %.elt26, align 8, !tbaa !8
  %.unpack27.unpack.elt29 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  %.unpack27.unpack.unpack30 = load i64, ptr %.unpack27.unpack.elt29, align 8, !tbaa !8
  %.unpack27.unpack.elt31 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  %.unpack27.unpack.unpack32 = load i64, ptr %.unpack27.unpack.elt31, align 8, !tbaa !8
  store ptr %.unpack, ptr %loadgep_4, align 8, !tbaa !8
  %loadgep_4.repack34 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 1
  store i64 %.unpack15, ptr %loadgep_4.repack34, align 8, !tbaa !8
  %loadgep_4.repack36 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 2
  store i32 %.unpack17, ptr %loadgep_4.repack36, align 8, !tbaa !8
  %loadgep_4.repack38 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 3
  store i8 %.unpack19, ptr %loadgep_4.repack38, align 4, !tbaa !8
  %loadgep_4.repack40 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 4
  store i8 %.unpack21, ptr %loadgep_4.repack40, align 1, !tbaa !8
  %loadgep_4.repack42 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 5
  store i8 %.unpack23, ptr %loadgep_4.repack42, align 2, !tbaa !8
  %loadgep_4.repack44 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 6
  store i8 %.unpack25, ptr %loadgep_4.repack44, align 1, !tbaa !8
  %loadgep_4.repack46 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7
  store i64 %.unpack27.unpack.unpack, ptr %loadgep_4.repack46, align 8, !tbaa !8
  %loadgep_4.repack46.repack48 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack27.unpack.unpack30, ptr %loadgep_4.repack46.repack48, align 8, !tbaa !8
  %loadgep_4.repack46.repack50 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 2
  store i64 %.unpack27.unpack.unpack32, ptr %loadgep_4.repack46.repack50, align 8, !tbaa !8
  %10 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 0
  %11 = load i64, ptr %10, align 8, !tbaa !8
  %12 = icmp eq i64 %.unpack27.unpack.unpack30, 0
  %13 = select i1 %12, i64 1, i64 %11
  store ptr %.unpack, ptr %loadgep_6, align 8, !tbaa !8
  %loadgep_6.repack52 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 1
  store i64 8, ptr %loadgep_6.repack52, align 8, !tbaa !8
  %loadgep_6.repack54 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 2
  store i32 20180515, ptr %loadgep_6.repack54, align 8, !tbaa !8
  %loadgep_6.repack56 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 3
  store i8 1, ptr %loadgep_6.repack56, align 4, !tbaa !8
  %loadgep_6.repack58 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 4
  store i8 28, ptr %loadgep_6.repack58, align 1, !tbaa !8
  %loadgep_6.repack60 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 5
  store i8 0, ptr %loadgep_6.repack60, align 2, !tbaa !8
  %loadgep_6.repack62 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 6
  store i8 0, ptr %loadgep_6.repack62, align 1, !tbaa !8
  %loadgep_6.repack64 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7
  store i64 %13, ptr %loadgep_6.repack64, align 8, !tbaa !8
  %loadgep_6.repack64.repack66 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack27.unpack.unpack30, ptr %loadgep_6.repack64.repack66, align 8, !tbaa !8
  %loadgep_6.repack64.repack68 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7, i64 0, i64 2
  store i64 8, ptr %loadgep_6.repack64.repack68, align 8, !tbaa !8
  %14 = load ptr, ptr %loadgep_8, align 8, !tbaa !4
  %15 = getelementptr { ptr, ptr }, ptr %loadgep_8, i64 0, i32 1
  %16 = load ptr, ptr %15, align 8, !tbaa !4
  %17 = sext i32 %6 to i64
  %18 = sext i32 %spec.select to i64
  %reass.sub9.i = sub nsw i64 %18, %17
  %19 = icmp sgt i64 %reass.sub9.i, -1
  br i1 %19, label %.lr.ph8.preheader.i, label %_QFPloop.exit

.lr.ph8.preheader.i:                              ; preds = %omp.par.entry
  %20 = add nuw nsw i64 %reass.sub9.i, 1
  br label %.lr.ph8.i

.lr.ph8.i:                                        ; preds = %.lr.ph8.i, %.lr.ph8.preheader.i
  %21 = phi i64 [ %31, %.lr.ph8.i ], [ %20, %.lr.ph8.preheader.i ]
  %22 = phi i32 [ %30, %.lr.ph8.i ], [ %6, %.lr.ph8.preheader.i ]
  %23 = load i32, ptr %14, align 4, !tbaa !4
  %24 = sitofp i32 %23 to float
  %25 = fdiv contract float 1.000000e+00, %24
  %26 = fpext float %25 to double
  %27 = sext i32 %22 to i64
  %28 = add nsw i64 %27, -1
  %29 = getelementptr double, ptr %.unpack, i64 %28
  store double %26, ptr %29, align 8, !tbaa !4
  store double %26, ptr %16, align 8, !tbaa !4
  %30 = add i32 %22, 1
  %31 = add nsw i64 %21, -1
  %32 = icmp ugt i64 %21, 1
  br i1 %32, label %.lr.ph8.i, label %_QFPloop.exit

_QFPloop.exit:                                    ; preds = %.lr.ph8.i, %omp.par.entry
  ret void
}
*** IR Dump After InstCombinePass on _QFPomp_subroutine..omp_par ***
; Function Attrs: norecurse nounwind
define internal void @_QFPomp_subroutine..omp_par(ptr noalias %tid.addr, ptr noalias %zero.addr, ptr %0) #2 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %gep_3 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 2
  %loadgep_4 = load ptr, ptr %gep_3, align 8
  %gep_5 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 3
  %loadgep_6 = load ptr, ptr %gep_5, align 8
  %gep_7 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 4
  %loadgep_8 = load ptr, ptr %gep_7, align 8
  %1 = tail call i32 @omp_get_thread_num()
  %2 = tail call i32 @omp_get_num_threads()
  %3 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %4 = sdiv i32 %3, %2
  %5 = mul i32 %4, %1
  %6 = add i32 %5, 1
  %7 = add i32 %2, -1
  %8 = icmp eq i32 %1, %7
  %9 = add i32 %6, %4
  %spec.select = select i1 %8, i32 %3, i32 %9
  %.unpack = load ptr, ptr %loadgep_2, align 8, !tbaa !8
  %.elt14 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  %.unpack15 = load i64, ptr %.elt14, align 8, !tbaa !8
  %.elt16 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  %.unpack17 = load i32, ptr %.elt16, align 8, !tbaa !8
  %.elt18 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  %.unpack19 = load i8, ptr %.elt18, align 4, !tbaa !8
  %.elt20 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  %.unpack21 = load i8, ptr %.elt20, align 1, !tbaa !8
  %.elt22 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  %.unpack23 = load i8, ptr %.elt22, align 2, !tbaa !8
  %.elt24 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  %.unpack25 = load i8, ptr %.elt24, align 1, !tbaa !8
  %.elt26 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  %.unpack27.unpack.unpack = load i64, ptr %.elt26, align 8, !tbaa !8
  %.unpack27.unpack.elt29 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  %.unpack27.unpack.unpack30 = load i64, ptr %.unpack27.unpack.elt29, align 8, !tbaa !8
  %.unpack27.unpack.elt31 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  %.unpack27.unpack.unpack32 = load i64, ptr %.unpack27.unpack.elt31, align 8, !tbaa !8
  store ptr %.unpack, ptr %loadgep_4, align 8, !tbaa !8
  %loadgep_4.repack34 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 1
  store i64 %.unpack15, ptr %loadgep_4.repack34, align 8, !tbaa !8
  %loadgep_4.repack36 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 2
  store i32 %.unpack17, ptr %loadgep_4.repack36, align 8, !tbaa !8
  %loadgep_4.repack38 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 3
  store i8 %.unpack19, ptr %loadgep_4.repack38, align 4, !tbaa !8
  %loadgep_4.repack40 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 4
  store i8 %.unpack21, ptr %loadgep_4.repack40, align 1, !tbaa !8
  %loadgep_4.repack42 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 5
  store i8 %.unpack23, ptr %loadgep_4.repack42, align 2, !tbaa !8
  %loadgep_4.repack44 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 6
  store i8 %.unpack25, ptr %loadgep_4.repack44, align 1, !tbaa !8
  %loadgep_4.repack46 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7
  store i64 %.unpack27.unpack.unpack, ptr %loadgep_4.repack46, align 8, !tbaa !8
  %loadgep_4.repack46.repack48 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack27.unpack.unpack30, ptr %loadgep_4.repack46.repack48, align 8, !tbaa !8
  %loadgep_4.repack46.repack50 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 2
  store i64 %.unpack27.unpack.unpack32, ptr %loadgep_4.repack46.repack50, align 8, !tbaa !8
  %10 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 0
  %11 = load i64, ptr %10, align 8, !tbaa !8
  %12 = icmp eq i64 %.unpack27.unpack.unpack30, 0
  %13 = select i1 %12, i64 1, i64 %11
  store ptr %.unpack, ptr %loadgep_6, align 8, !tbaa !8
  %loadgep_6.repack52 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 1
  store i64 8, ptr %loadgep_6.repack52, align 8, !tbaa !8
  %loadgep_6.repack54 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 2
  store i32 20180515, ptr %loadgep_6.repack54, align 8, !tbaa !8
  %loadgep_6.repack56 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 3
  store i8 1, ptr %loadgep_6.repack56, align 4, !tbaa !8
  %loadgep_6.repack58 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 4
  store i8 28, ptr %loadgep_6.repack58, align 1, !tbaa !8
  %loadgep_6.repack60 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 5
  store i8 0, ptr %loadgep_6.repack60, align 2, !tbaa !8
  %loadgep_6.repack62 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 6
  store i8 0, ptr %loadgep_6.repack62, align 1, !tbaa !8
  %loadgep_6.repack64 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7
  store i64 %13, ptr %loadgep_6.repack64, align 8, !tbaa !8
  %loadgep_6.repack64.repack66 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack27.unpack.unpack30, ptr %loadgep_6.repack64.repack66, align 8, !tbaa !8
  %loadgep_6.repack64.repack68 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7, i64 0, i64 2
  store i64 8, ptr %loadgep_6.repack64.repack68, align 8, !tbaa !8
  %14 = load ptr, ptr %loadgep_8, align 8, !tbaa !4
  %15 = getelementptr { ptr, ptr }, ptr %loadgep_8, i64 0, i32 1
  %16 = load ptr, ptr %15, align 8, !tbaa !4
  %17 = sext i32 %6 to i64
  %18 = sext i32 %spec.select to i64
  %reass.sub9.i = sub nsw i64 %18, %17
  %19 = icmp sgt i64 %reass.sub9.i, -1
  br i1 %19, label %.lr.ph8.preheader.i, label %_QFPloop.exit

.lr.ph8.preheader.i:                              ; preds = %omp.par.entry
  %20 = add nuw nsw i64 %reass.sub9.i, 1
  br label %.lr.ph8.i

.lr.ph8.i:                                        ; preds = %.lr.ph8.i, %.lr.ph8.preheader.i
  %21 = phi i64 [ %31, %.lr.ph8.i ], [ %20, %.lr.ph8.preheader.i ]
  %22 = phi i32 [ %30, %.lr.ph8.i ], [ %6, %.lr.ph8.preheader.i ]
  %23 = load i32, ptr %14, align 4, !tbaa !4
  %24 = sitofp i32 %23 to float
  %25 = fdiv contract float 1.000000e+00, %24
  %26 = fpext float %25 to double
  %27 = sext i32 %22 to i64
  %28 = add nsw i64 %27, -1
  %29 = getelementptr double, ptr %.unpack, i64 %28
  store double %26, ptr %29, align 8, !tbaa !4
  store double %26, ptr %16, align 8, !tbaa !4
  %30 = add i32 %22, 1
  %31 = add nsw i64 %21, -1
  %32 = icmp ugt i64 %21, 1
  br i1 %32, label %.lr.ph8.i, label %_QFPloop.exit

_QFPloop.exit:                                    ; preds = %.lr.ph8.i, %omp.par.entry
  ret void
}
*** IR Dump After LoopSimplifyPass on _QFPomp_subroutine..omp_par ***
; Function Attrs: norecurse nounwind
define internal void @_QFPomp_subroutine..omp_par(ptr noalias %tid.addr, ptr noalias %zero.addr, ptr %0) #2 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %gep_3 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 2
  %loadgep_4 = load ptr, ptr %gep_3, align 8
  %gep_5 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 3
  %loadgep_6 = load ptr, ptr %gep_5, align 8
  %gep_7 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 4
  %loadgep_8 = load ptr, ptr %gep_7, align 8
  %1 = tail call i32 @omp_get_thread_num()
  %2 = tail call i32 @omp_get_num_threads()
  %3 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %4 = sdiv i32 %3, %2
  %5 = mul i32 %4, %1
  %6 = add i32 %5, 1
  %7 = add i32 %2, -1
  %8 = icmp eq i32 %1, %7
  %9 = add i32 %6, %4
  %spec.select = select i1 %8, i32 %3, i32 %9
  %.unpack = load ptr, ptr %loadgep_2, align 8, !tbaa !8
  %.elt14 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  %.unpack15 = load i64, ptr %.elt14, align 8, !tbaa !8
  %.elt16 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  %.unpack17 = load i32, ptr %.elt16, align 8, !tbaa !8
  %.elt18 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  %.unpack19 = load i8, ptr %.elt18, align 4, !tbaa !8
  %.elt20 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  %.unpack21 = load i8, ptr %.elt20, align 1, !tbaa !8
  %.elt22 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  %.unpack23 = load i8, ptr %.elt22, align 2, !tbaa !8
  %.elt24 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  %.unpack25 = load i8, ptr %.elt24, align 1, !tbaa !8
  %.elt26 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  %.unpack27.unpack.unpack = load i64, ptr %.elt26, align 8, !tbaa !8
  %.unpack27.unpack.elt29 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  %.unpack27.unpack.unpack30 = load i64, ptr %.unpack27.unpack.elt29, align 8, !tbaa !8
  %.unpack27.unpack.elt31 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  %.unpack27.unpack.unpack32 = load i64, ptr %.unpack27.unpack.elt31, align 8, !tbaa !8
  store ptr %.unpack, ptr %loadgep_4, align 8, !tbaa !8
  %loadgep_4.repack34 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 1
  store i64 %.unpack15, ptr %loadgep_4.repack34, align 8, !tbaa !8
  %loadgep_4.repack36 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 2
  store i32 %.unpack17, ptr %loadgep_4.repack36, align 8, !tbaa !8
  %loadgep_4.repack38 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 3
  store i8 %.unpack19, ptr %loadgep_4.repack38, align 4, !tbaa !8
  %loadgep_4.repack40 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 4
  store i8 %.unpack21, ptr %loadgep_4.repack40, align 1, !tbaa !8
  %loadgep_4.repack42 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 5
  store i8 %.unpack23, ptr %loadgep_4.repack42, align 2, !tbaa !8
  %loadgep_4.repack44 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 6
  store i8 %.unpack25, ptr %loadgep_4.repack44, align 1, !tbaa !8
  %loadgep_4.repack46 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7
  store i64 %.unpack27.unpack.unpack, ptr %loadgep_4.repack46, align 8, !tbaa !8
  %loadgep_4.repack46.repack48 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack27.unpack.unpack30, ptr %loadgep_4.repack46.repack48, align 8, !tbaa !8
  %loadgep_4.repack46.repack50 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 2
  store i64 %.unpack27.unpack.unpack32, ptr %loadgep_4.repack46.repack50, align 8, !tbaa !8
  %10 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 0
  %11 = load i64, ptr %10, align 8, !tbaa !8
  %12 = icmp eq i64 %.unpack27.unpack.unpack30, 0
  %13 = select i1 %12, i64 1, i64 %11
  store ptr %.unpack, ptr %loadgep_6, align 8, !tbaa !8
  %loadgep_6.repack52 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 1
  store i64 8, ptr %loadgep_6.repack52, align 8, !tbaa !8
  %loadgep_6.repack54 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 2
  store i32 20180515, ptr %loadgep_6.repack54, align 8, !tbaa !8
  %loadgep_6.repack56 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 3
  store i8 1, ptr %loadgep_6.repack56, align 4, !tbaa !8
  %loadgep_6.repack58 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 4
  store i8 28, ptr %loadgep_6.repack58, align 1, !tbaa !8
  %loadgep_6.repack60 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 5
  store i8 0, ptr %loadgep_6.repack60, align 2, !tbaa !8
  %loadgep_6.repack62 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 6
  store i8 0, ptr %loadgep_6.repack62, align 1, !tbaa !8
  %loadgep_6.repack64 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7
  store i64 %13, ptr %loadgep_6.repack64, align 8, !tbaa !8
  %loadgep_6.repack64.repack66 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack27.unpack.unpack30, ptr %loadgep_6.repack64.repack66, align 8, !tbaa !8
  %loadgep_6.repack64.repack68 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7, i64 0, i64 2
  store i64 8, ptr %loadgep_6.repack64.repack68, align 8, !tbaa !8
  %14 = load ptr, ptr %loadgep_8, align 8, !tbaa !4
  %15 = getelementptr { ptr, ptr }, ptr %loadgep_8, i64 0, i32 1
  %16 = load ptr, ptr %15, align 8, !tbaa !4
  %17 = sext i32 %6 to i64
  %18 = sext i32 %spec.select to i64
  %reass.sub9.i = sub nsw i64 %18, %17
  %19 = icmp sgt i64 %reass.sub9.i, -1
  br i1 %19, label %.lr.ph8.preheader.i, label %_QFPloop.exit

.lr.ph8.preheader.i:                              ; preds = %omp.par.entry
  %20 = add nuw nsw i64 %reass.sub9.i, 1
  br label %.lr.ph8.i

.lr.ph8.i:                                        ; preds = %.lr.ph8.i, %.lr.ph8.preheader.i
  %21 = phi i64 [ %31, %.lr.ph8.i ], [ %20, %.lr.ph8.preheader.i ]
  %22 = phi i32 [ %30, %.lr.ph8.i ], [ %6, %.lr.ph8.preheader.i ]
  %23 = load i32, ptr %14, align 4, !tbaa !4
  %24 = sitofp i32 %23 to float
  %25 = fdiv contract float 1.000000e+00, %24
  %26 = fpext float %25 to double
  %27 = sext i32 %22 to i64
  %28 = add nsw i64 %27, -1
  %29 = getelementptr double, ptr %.unpack, i64 %28
  store double %26, ptr %29, align 8, !tbaa !4
  store double %26, ptr %16, align 8, !tbaa !4
  %30 = add i32 %22, 1
  %31 = add nsw i64 %21, -1
  %32 = icmp ugt i64 %21, 1
  br i1 %32, label %.lr.ph8.i, label %_QFPloop.exit.loopexit

_QFPloop.exit.loopexit:                           ; preds = %.lr.ph8.i
  br label %_QFPloop.exit

_QFPloop.exit:                                    ; preds = %_QFPloop.exit.loopexit, %omp.par.entry
  ret void
}
*** IR Dump After LCSSAPass on _QFPomp_subroutine..omp_par ***
; Function Attrs: norecurse nounwind
define internal void @_QFPomp_subroutine..omp_par(ptr noalias %tid.addr, ptr noalias %zero.addr, ptr %0) #2 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %gep_3 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 2
  %loadgep_4 = load ptr, ptr %gep_3, align 8
  %gep_5 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 3
  %loadgep_6 = load ptr, ptr %gep_5, align 8
  %gep_7 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 4
  %loadgep_8 = load ptr, ptr %gep_7, align 8
  %1 = tail call i32 @omp_get_thread_num()
  %2 = tail call i32 @omp_get_num_threads()
  %3 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %4 = sdiv i32 %3, %2
  %5 = mul i32 %4, %1
  %6 = add i32 %5, 1
  %7 = add i32 %2, -1
  %8 = icmp eq i32 %1, %7
  %9 = add i32 %6, %4
  %spec.select = select i1 %8, i32 %3, i32 %9
  %.unpack = load ptr, ptr %loadgep_2, align 8, !tbaa !8
  %.elt14 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  %.unpack15 = load i64, ptr %.elt14, align 8, !tbaa !8
  %.elt16 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  %.unpack17 = load i32, ptr %.elt16, align 8, !tbaa !8
  %.elt18 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  %.unpack19 = load i8, ptr %.elt18, align 4, !tbaa !8
  %.elt20 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  %.unpack21 = load i8, ptr %.elt20, align 1, !tbaa !8
  %.elt22 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  %.unpack23 = load i8, ptr %.elt22, align 2, !tbaa !8
  %.elt24 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  %.unpack25 = load i8, ptr %.elt24, align 1, !tbaa !8
  %.elt26 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  %.unpack27.unpack.unpack = load i64, ptr %.elt26, align 8, !tbaa !8
  %.unpack27.unpack.elt29 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  %.unpack27.unpack.unpack30 = load i64, ptr %.unpack27.unpack.elt29, align 8, !tbaa !8
  %.unpack27.unpack.elt31 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  %.unpack27.unpack.unpack32 = load i64, ptr %.unpack27.unpack.elt31, align 8, !tbaa !8
  store ptr %.unpack, ptr %loadgep_4, align 8, !tbaa !8
  %loadgep_4.repack34 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 1
  store i64 %.unpack15, ptr %loadgep_4.repack34, align 8, !tbaa !8
  %loadgep_4.repack36 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 2
  store i32 %.unpack17, ptr %loadgep_4.repack36, align 8, !tbaa !8
  %loadgep_4.repack38 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 3
  store i8 %.unpack19, ptr %loadgep_4.repack38, align 4, !tbaa !8
  %loadgep_4.repack40 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 4
  store i8 %.unpack21, ptr %loadgep_4.repack40, align 1, !tbaa !8
  %loadgep_4.repack42 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 5
  store i8 %.unpack23, ptr %loadgep_4.repack42, align 2, !tbaa !8
  %loadgep_4.repack44 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 6
  store i8 %.unpack25, ptr %loadgep_4.repack44, align 1, !tbaa !8
  %loadgep_4.repack46 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7
  store i64 %.unpack27.unpack.unpack, ptr %loadgep_4.repack46, align 8, !tbaa !8
  %loadgep_4.repack46.repack48 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack27.unpack.unpack30, ptr %loadgep_4.repack46.repack48, align 8, !tbaa !8
  %loadgep_4.repack46.repack50 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 2
  store i64 %.unpack27.unpack.unpack32, ptr %loadgep_4.repack46.repack50, align 8, !tbaa !8
  %10 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 0
  %11 = load i64, ptr %10, align 8, !tbaa !8
  %12 = icmp eq i64 %.unpack27.unpack.unpack30, 0
  %13 = select i1 %12, i64 1, i64 %11
  store ptr %.unpack, ptr %loadgep_6, align 8, !tbaa !8
  %loadgep_6.repack52 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 1
  store i64 8, ptr %loadgep_6.repack52, align 8, !tbaa !8
  %loadgep_6.repack54 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 2
  store i32 20180515, ptr %loadgep_6.repack54, align 8, !tbaa !8
  %loadgep_6.repack56 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 3
  store i8 1, ptr %loadgep_6.repack56, align 4, !tbaa !8
  %loadgep_6.repack58 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 4
  store i8 28, ptr %loadgep_6.repack58, align 1, !tbaa !8
  %loadgep_6.repack60 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 5
  store i8 0, ptr %loadgep_6.repack60, align 2, !tbaa !8
  %loadgep_6.repack62 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 6
  store i8 0, ptr %loadgep_6.repack62, align 1, !tbaa !8
  %loadgep_6.repack64 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7
  store i64 %13, ptr %loadgep_6.repack64, align 8, !tbaa !8
  %loadgep_6.repack64.repack66 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack27.unpack.unpack30, ptr %loadgep_6.repack64.repack66, align 8, !tbaa !8
  %loadgep_6.repack64.repack68 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7, i64 0, i64 2
  store i64 8, ptr %loadgep_6.repack64.repack68, align 8, !tbaa !8
  %14 = load ptr, ptr %loadgep_8, align 8, !tbaa !4
  %15 = getelementptr { ptr, ptr }, ptr %loadgep_8, i64 0, i32 1
  %16 = load ptr, ptr %15, align 8, !tbaa !4
  %17 = sext i32 %6 to i64
  %18 = sext i32 %spec.select to i64
  %reass.sub9.i = sub nsw i64 %18, %17
  %19 = icmp sgt i64 %reass.sub9.i, -1
  br i1 %19, label %.lr.ph8.preheader.i, label %_QFPloop.exit

.lr.ph8.preheader.i:                              ; preds = %omp.par.entry
  %20 = add nuw nsw i64 %reass.sub9.i, 1
  br label %.lr.ph8.i

.lr.ph8.i:                                        ; preds = %.lr.ph8.i, %.lr.ph8.preheader.i
  %21 = phi i64 [ %31, %.lr.ph8.i ], [ %20, %.lr.ph8.preheader.i ]
  %22 = phi i32 [ %30, %.lr.ph8.i ], [ %6, %.lr.ph8.preheader.i ]
  %23 = load i32, ptr %14, align 4, !tbaa !4
  %24 = sitofp i32 %23 to float
  %25 = fdiv contract float 1.000000e+00, %24
  %26 = fpext float %25 to double
  %27 = sext i32 %22 to i64
  %28 = add nsw i64 %27, -1
  %29 = getelementptr double, ptr %.unpack, i64 %28
  store double %26, ptr %29, align 8, !tbaa !4
  store double %26, ptr %16, align 8, !tbaa !4
  %30 = add i32 %22, 1
  %31 = add nsw i64 %21, -1
  %32 = icmp ugt i64 %21, 1
  br i1 %32, label %.lr.ph8.i, label %_QFPloop.exit.loopexit

_QFPloop.exit.loopexit:                           ; preds = %.lr.ph8.i
  br label %_QFPloop.exit

_QFPloop.exit:                                    ; preds = %_QFPloop.exit.loopexit, %omp.par.entry
  ret void
}
*** IR Dump After LoopIdiomRecognizePass on .lr.ph8.i ***

; Preheader:
.lr.ph8.preheader.i:                              ; preds = %omp.par.entry
  %20 = add nuw nsw i64 %reass.sub9.i, 1
  br label %.lr.ph8.i

; Loop:
.lr.ph8.i:                                        ; preds = %.lr.ph8.i, %.lr.ph8.preheader.i
  %21 = phi i64 [ %31, %.lr.ph8.i ], [ %20, %.lr.ph8.preheader.i ]
  %22 = phi i32 [ %30, %.lr.ph8.i ], [ %6, %.lr.ph8.preheader.i ]
  %23 = load i32, ptr %14, align 4, !tbaa !4
  %24 = sitofp i32 %23 to float
  %25 = fdiv contract float 1.000000e+00, %24
  %26 = fpext float %25 to double
  %27 = sext i32 %22 to i64
  %28 = add nsw i64 %27, -1
  %29 = getelementptr double, ptr %.unpack, i64 %28
  store double %26, ptr %29, align 8, !tbaa !4
  store double %26, ptr %16, align 8, !tbaa !4
  %30 = add i32 %22, 1
  %31 = add nsw i64 %21, -1
  %32 = icmp ugt i64 %21, 1
  br i1 %32, label %.lr.ph8.i, label %_QFPloop.exit.loopexit

; Exit blocks
_QFPloop.exit.loopexit:                           ; preds = %.lr.ph8.i
  br label %_QFPloop.exit
*** IR Dump After IndVarSimplifyPass on .lr.ph8.i ***

; Preheader:
.lr.ph8.preheader.i:                              ; preds = %omp.par.entry
  %20 = add nuw nsw i64 %reass.sub9.i, 1
  br label %.lr.ph8.i

; Loop:
.lr.ph8.i:                                        ; preds = %.lr.ph8.i, %.lr.ph8.preheader.i
  %21 = phi i64 [ %31, %.lr.ph8.i ], [ %20, %.lr.ph8.preheader.i ]
  %22 = phi i32 [ %30, %.lr.ph8.i ], [ %6, %.lr.ph8.preheader.i ]
  %23 = load i32, ptr %14, align 4, !tbaa !4
  %24 = sitofp i32 %23 to float
  %25 = fdiv contract float 1.000000e+00, %24
  %26 = fpext float %25 to double
  %27 = sext i32 %22 to i64
  %28 = add nsw i64 %27, -1
  %29 = getelementptr double, ptr %.unpack, i64 %28
  store double %26, ptr %29, align 8, !tbaa !4
  store double %26, ptr %16, align 8, !tbaa !4
  %30 = add i32 %22, 1
  %31 = add nsw i64 %21, -1
  %32 = icmp ugt i64 %21, 1
  br i1 %32, label %.lr.ph8.i, label %_QFPloop.exit.loopexit

; Exit blocks
_QFPloop.exit.loopexit:                           ; preds = %.lr.ph8.i
  br label %_QFPloop.exit
*** IR Dump After LoopDeletionPass on .lr.ph8.i ***

; Preheader:
.lr.ph8.preheader.i:                              ; preds = %omp.par.entry
  %20 = add nuw nsw i64 %reass.sub9.i, 1
  br label %.lr.ph8.i

; Loop:
.lr.ph8.i:                                        ; preds = %.lr.ph8.i, %.lr.ph8.preheader.i
  %21 = phi i64 [ %31, %.lr.ph8.i ], [ %20, %.lr.ph8.preheader.i ]
  %22 = phi i32 [ %30, %.lr.ph8.i ], [ %6, %.lr.ph8.preheader.i ]
  %23 = load i32, ptr %14, align 4, !tbaa !4
  %24 = sitofp i32 %23 to float
  %25 = fdiv contract float 1.000000e+00, %24
  %26 = fpext float %25 to double
  %27 = sext i32 %22 to i64
  %28 = add nsw i64 %27, -1
  %29 = getelementptr double, ptr %.unpack, i64 %28
  store double %26, ptr %29, align 8, !tbaa !4
  store double %26, ptr %16, align 8, !tbaa !4
  %30 = add i32 %22, 1
  %31 = add nsw i64 %21, -1
  %32 = icmp ugt i64 %21, 1
  br i1 %32, label %.lr.ph8.i, label %_QFPloop.exit.loopexit

; Exit blocks
_QFPloop.exit.loopexit:                           ; preds = %.lr.ph8.i
  br label %_QFPloop.exit
*** IR Dump After LoopFullUnrollPass on .lr.ph8.i ***

; Preheader:
.lr.ph8.preheader.i:                              ; preds = %omp.par.entry
  %20 = add nuw nsw i64 %reass.sub9.i, 1
  br label %.lr.ph8.i

; Loop:
.lr.ph8.i:                                        ; preds = %.lr.ph8.i, %.lr.ph8.preheader.i
  %21 = phi i64 [ %31, %.lr.ph8.i ], [ %20, %.lr.ph8.preheader.i ]
  %22 = phi i32 [ %30, %.lr.ph8.i ], [ %6, %.lr.ph8.preheader.i ]
  %23 = load i32, ptr %14, align 4, !tbaa !4
  %24 = sitofp i32 %23 to float
  %25 = fdiv contract float 1.000000e+00, %24
  %26 = fpext float %25 to double
  %27 = sext i32 %22 to i64
  %28 = add nsw i64 %27, -1
  %29 = getelementptr double, ptr %.unpack, i64 %28
  store double %26, ptr %29, align 8, !tbaa !4
  store double %26, ptr %16, align 8, !tbaa !4
  %30 = add i32 %22, 1
  %31 = add nsw i64 %21, -1
  %32 = icmp ugt i64 %21, 1
  br i1 %32, label %.lr.ph8.i, label %_QFPloop.exit.loopexit

; Exit blocks
_QFPloop.exit.loopexit:                           ; preds = %.lr.ph8.i
  br label %_QFPloop.exit
*** IR Dump After SROAPass on _QFPomp_subroutine..omp_par ***
; Function Attrs: norecurse nounwind
define internal void @_QFPomp_subroutine..omp_par(ptr noalias %tid.addr, ptr noalias %zero.addr, ptr %0) #2 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %gep_3 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 2
  %loadgep_4 = load ptr, ptr %gep_3, align 8
  %gep_5 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 3
  %loadgep_6 = load ptr, ptr %gep_5, align 8
  %gep_7 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 4
  %loadgep_8 = load ptr, ptr %gep_7, align 8
  %1 = tail call i32 @omp_get_thread_num()
  %2 = tail call i32 @omp_get_num_threads()
  %3 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %4 = sdiv i32 %3, %2
  %5 = mul i32 %4, %1
  %6 = add i32 %5, 1
  %7 = add i32 %2, -1
  %8 = icmp eq i32 %1, %7
  %9 = add i32 %6, %4
  %spec.select = select i1 %8, i32 %3, i32 %9
  %.unpack = load ptr, ptr %loadgep_2, align 8, !tbaa !8
  %.elt14 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  %.unpack15 = load i64, ptr %.elt14, align 8, !tbaa !8
  %.elt16 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  %.unpack17 = load i32, ptr %.elt16, align 8, !tbaa !8
  %.elt18 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  %.unpack19 = load i8, ptr %.elt18, align 4, !tbaa !8
  %.elt20 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  %.unpack21 = load i8, ptr %.elt20, align 1, !tbaa !8
  %.elt22 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  %.unpack23 = load i8, ptr %.elt22, align 2, !tbaa !8
  %.elt24 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  %.unpack25 = load i8, ptr %.elt24, align 1, !tbaa !8
  %.elt26 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  %.unpack27.unpack.unpack = load i64, ptr %.elt26, align 8, !tbaa !8
  %.unpack27.unpack.elt29 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  %.unpack27.unpack.unpack30 = load i64, ptr %.unpack27.unpack.elt29, align 8, !tbaa !8
  %.unpack27.unpack.elt31 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  %.unpack27.unpack.unpack32 = load i64, ptr %.unpack27.unpack.elt31, align 8, !tbaa !8
  store ptr %.unpack, ptr %loadgep_4, align 8, !tbaa !8
  %loadgep_4.repack34 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 1
  store i64 %.unpack15, ptr %loadgep_4.repack34, align 8, !tbaa !8
  %loadgep_4.repack36 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 2
  store i32 %.unpack17, ptr %loadgep_4.repack36, align 8, !tbaa !8
  %loadgep_4.repack38 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 3
  store i8 %.unpack19, ptr %loadgep_4.repack38, align 4, !tbaa !8
  %loadgep_4.repack40 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 4
  store i8 %.unpack21, ptr %loadgep_4.repack40, align 1, !tbaa !8
  %loadgep_4.repack42 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 5
  store i8 %.unpack23, ptr %loadgep_4.repack42, align 2, !tbaa !8
  %loadgep_4.repack44 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 6
  store i8 %.unpack25, ptr %loadgep_4.repack44, align 1, !tbaa !8
  %loadgep_4.repack46 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7
  store i64 %.unpack27.unpack.unpack, ptr %loadgep_4.repack46, align 8, !tbaa !8
  %loadgep_4.repack46.repack48 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack27.unpack.unpack30, ptr %loadgep_4.repack46.repack48, align 8, !tbaa !8
  %loadgep_4.repack46.repack50 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 2
  store i64 %.unpack27.unpack.unpack32, ptr %loadgep_4.repack46.repack50, align 8, !tbaa !8
  %10 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 0
  %11 = load i64, ptr %10, align 8, !tbaa !8
  %12 = icmp eq i64 %.unpack27.unpack.unpack30, 0
  %13 = select i1 %12, i64 1, i64 %11
  store ptr %.unpack, ptr %loadgep_6, align 8, !tbaa !8
  %loadgep_6.repack52 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 1
  store i64 8, ptr %loadgep_6.repack52, align 8, !tbaa !8
  %loadgep_6.repack54 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 2
  store i32 20180515, ptr %loadgep_6.repack54, align 8, !tbaa !8
  %loadgep_6.repack56 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 3
  store i8 1, ptr %loadgep_6.repack56, align 4, !tbaa !8
  %loadgep_6.repack58 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 4
  store i8 28, ptr %loadgep_6.repack58, align 1, !tbaa !8
  %loadgep_6.repack60 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 5
  store i8 0, ptr %loadgep_6.repack60, align 2, !tbaa !8
  %loadgep_6.repack62 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 6
  store i8 0, ptr %loadgep_6.repack62, align 1, !tbaa !8
  %loadgep_6.repack64 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7
  store i64 %13, ptr %loadgep_6.repack64, align 8, !tbaa !8
  %loadgep_6.repack64.repack66 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack27.unpack.unpack30, ptr %loadgep_6.repack64.repack66, align 8, !tbaa !8
  %loadgep_6.repack64.repack68 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7, i64 0, i64 2
  store i64 8, ptr %loadgep_6.repack64.repack68, align 8, !tbaa !8
  %14 = load ptr, ptr %loadgep_8, align 8, !tbaa !4
  %15 = getelementptr { ptr, ptr }, ptr %loadgep_8, i64 0, i32 1
  %16 = load ptr, ptr %15, align 8, !tbaa !4
  %17 = sext i32 %6 to i64
  %18 = sext i32 %spec.select to i64
  %reass.sub9.i = sub nsw i64 %18, %17
  %19 = icmp sgt i64 %reass.sub9.i, -1
  br i1 %19, label %.lr.ph8.preheader.i, label %_QFPloop.exit

.lr.ph8.preheader.i:                              ; preds = %omp.par.entry
  %20 = add nuw nsw i64 %reass.sub9.i, 1
  br label %.lr.ph8.i

.lr.ph8.i:                                        ; preds = %.lr.ph8.i, %.lr.ph8.preheader.i
  %21 = phi i64 [ %31, %.lr.ph8.i ], [ %20, %.lr.ph8.preheader.i ]
  %22 = phi i32 [ %30, %.lr.ph8.i ], [ %6, %.lr.ph8.preheader.i ]
  %23 = load i32, ptr %14, align 4, !tbaa !4
  %24 = sitofp i32 %23 to float
  %25 = fdiv contract float 1.000000e+00, %24
  %26 = fpext float %25 to double
  %27 = sext i32 %22 to i64
  %28 = add nsw i64 %27, -1
  %29 = getelementptr double, ptr %.unpack, i64 %28
  store double %26, ptr %29, align 8, !tbaa !4
  store double %26, ptr %16, align 8, !tbaa !4
  %30 = add i32 %22, 1
  %31 = add nsw i64 %21, -1
  %32 = icmp ugt i64 %21, 1
  br i1 %32, label %.lr.ph8.i, label %_QFPloop.exit.loopexit

_QFPloop.exit.loopexit:                           ; preds = %.lr.ph8.i
  br label %_QFPloop.exit

_QFPloop.exit:                                    ; preds = %_QFPloop.exit.loopexit, %omp.par.entry
  ret void
}
*** IR Dump After VectorCombinePass on _QFPomp_subroutine..omp_par ***
; Function Attrs: norecurse nounwind
define internal void @_QFPomp_subroutine..omp_par(ptr noalias %tid.addr, ptr noalias %zero.addr, ptr %0) #2 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %gep_3 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 2
  %loadgep_4 = load ptr, ptr %gep_3, align 8
  %gep_5 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 3
  %loadgep_6 = load ptr, ptr %gep_5, align 8
  %gep_7 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 4
  %loadgep_8 = load ptr, ptr %gep_7, align 8
  %1 = tail call i32 @omp_get_thread_num()
  %2 = tail call i32 @omp_get_num_threads()
  %3 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %4 = sdiv i32 %3, %2
  %5 = mul i32 %4, %1
  %6 = add i32 %5, 1
  %7 = add i32 %2, -1
  %8 = icmp eq i32 %1, %7
  %9 = add i32 %6, %4
  %spec.select = select i1 %8, i32 %3, i32 %9
  %.unpack = load ptr, ptr %loadgep_2, align 8, !tbaa !8
  %.elt14 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  %.unpack15 = load i64, ptr %.elt14, align 8, !tbaa !8
  %.elt16 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  %.unpack17 = load i32, ptr %.elt16, align 8, !tbaa !8
  %.elt18 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  %.unpack19 = load i8, ptr %.elt18, align 4, !tbaa !8
  %.elt20 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  %.unpack21 = load i8, ptr %.elt20, align 1, !tbaa !8
  %.elt22 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  %.unpack23 = load i8, ptr %.elt22, align 2, !tbaa !8
  %.elt24 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  %.unpack25 = load i8, ptr %.elt24, align 1, !tbaa !8
  %.elt26 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  %.unpack27.unpack.unpack = load i64, ptr %.elt26, align 8, !tbaa !8
  %.unpack27.unpack.elt29 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  %.unpack27.unpack.unpack30 = load i64, ptr %.unpack27.unpack.elt29, align 8, !tbaa !8
  %.unpack27.unpack.elt31 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  %.unpack27.unpack.unpack32 = load i64, ptr %.unpack27.unpack.elt31, align 8, !tbaa !8
  store ptr %.unpack, ptr %loadgep_4, align 8, !tbaa !8
  %loadgep_4.repack34 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 1
  store i64 %.unpack15, ptr %loadgep_4.repack34, align 8, !tbaa !8
  %loadgep_4.repack36 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 2
  store i32 %.unpack17, ptr %loadgep_4.repack36, align 8, !tbaa !8
  %loadgep_4.repack38 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 3
  store i8 %.unpack19, ptr %loadgep_4.repack38, align 4, !tbaa !8
  %loadgep_4.repack40 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 4
  store i8 %.unpack21, ptr %loadgep_4.repack40, align 1, !tbaa !8
  %loadgep_4.repack42 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 5
  store i8 %.unpack23, ptr %loadgep_4.repack42, align 2, !tbaa !8
  %loadgep_4.repack44 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 6
  store i8 %.unpack25, ptr %loadgep_4.repack44, align 1, !tbaa !8
  %loadgep_4.repack46 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7
  store i64 %.unpack27.unpack.unpack, ptr %loadgep_4.repack46, align 8, !tbaa !8
  %loadgep_4.repack46.repack48 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack27.unpack.unpack30, ptr %loadgep_4.repack46.repack48, align 8, !tbaa !8
  %loadgep_4.repack46.repack50 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 2
  store i64 %.unpack27.unpack.unpack32, ptr %loadgep_4.repack46.repack50, align 8, !tbaa !8
  %10 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 0
  %11 = load i64, ptr %10, align 8, !tbaa !8
  %12 = icmp eq i64 %.unpack27.unpack.unpack30, 0
  %13 = select i1 %12, i64 1, i64 %11
  store ptr %.unpack, ptr %loadgep_6, align 8, !tbaa !8
  %loadgep_6.repack52 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 1
  store i64 8, ptr %loadgep_6.repack52, align 8, !tbaa !8
  %loadgep_6.repack54 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 2
  store i32 20180515, ptr %loadgep_6.repack54, align 8, !tbaa !8
  %loadgep_6.repack56 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 3
  store i8 1, ptr %loadgep_6.repack56, align 4, !tbaa !8
  %loadgep_6.repack58 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 4
  store i8 28, ptr %loadgep_6.repack58, align 1, !tbaa !8
  %loadgep_6.repack60 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 5
  store i8 0, ptr %loadgep_6.repack60, align 2, !tbaa !8
  %loadgep_6.repack62 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 6
  store i8 0, ptr %loadgep_6.repack62, align 1, !tbaa !8
  %loadgep_6.repack64 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7
  store i64 %13, ptr %loadgep_6.repack64, align 8, !tbaa !8
  %loadgep_6.repack64.repack66 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack27.unpack.unpack30, ptr %loadgep_6.repack64.repack66, align 8, !tbaa !8
  %loadgep_6.repack64.repack68 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7, i64 0, i64 2
  store i64 8, ptr %loadgep_6.repack64.repack68, align 8, !tbaa !8
  %14 = load ptr, ptr %loadgep_8, align 8, !tbaa !4
  %15 = getelementptr { ptr, ptr }, ptr %loadgep_8, i64 0, i32 1
  %16 = load ptr, ptr %15, align 8, !tbaa !4
  %17 = sext i32 %6 to i64
  %18 = sext i32 %spec.select to i64
  %reass.sub9.i = sub nsw i64 %18, %17
  %19 = icmp sgt i64 %reass.sub9.i, -1
  br i1 %19, label %.lr.ph8.preheader.i, label %_QFPloop.exit

.lr.ph8.preheader.i:                              ; preds = %omp.par.entry
  %20 = add nuw nsw i64 %reass.sub9.i, 1
  br label %.lr.ph8.i

.lr.ph8.i:                                        ; preds = %.lr.ph8.i, %.lr.ph8.preheader.i
  %21 = phi i64 [ %31, %.lr.ph8.i ], [ %20, %.lr.ph8.preheader.i ]
  %22 = phi i32 [ %30, %.lr.ph8.i ], [ %6, %.lr.ph8.preheader.i ]
  %23 = load i32, ptr %14, align 4, !tbaa !4
  %24 = sitofp i32 %23 to float
  %25 = fdiv contract float 1.000000e+00, %24
  %26 = fpext float %25 to double
  %27 = sext i32 %22 to i64
  %28 = add nsw i64 %27, -1
  %29 = getelementptr double, ptr %.unpack, i64 %28
  store double %26, ptr %29, align 8, !tbaa !4
  store double %26, ptr %16, align 8, !tbaa !4
  %30 = add i32 %22, 1
  %31 = add nsw i64 %21, -1
  %32 = icmp ugt i64 %21, 1
  br i1 %32, label %.lr.ph8.i, label %_QFPloop.exit.loopexit

_QFPloop.exit.loopexit:                           ; preds = %.lr.ph8.i
  br label %_QFPloop.exit

_QFPloop.exit:                                    ; preds = %_QFPloop.exit.loopexit, %omp.par.entry
  ret void
}
*** IR Dump After MergedLoadStoreMotionPass on _QFPomp_subroutine..omp_par ***
; Function Attrs: norecurse nounwind
define internal void @_QFPomp_subroutine..omp_par(ptr noalias %tid.addr, ptr noalias %zero.addr, ptr %0) #2 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %gep_3 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 2
  %loadgep_4 = load ptr, ptr %gep_3, align 8
  %gep_5 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 3
  %loadgep_6 = load ptr, ptr %gep_5, align 8
  %gep_7 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 4
  %loadgep_8 = load ptr, ptr %gep_7, align 8
  %1 = tail call i32 @omp_get_thread_num()
  %2 = tail call i32 @omp_get_num_threads()
  %3 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %4 = sdiv i32 %3, %2
  %5 = mul i32 %4, %1
  %6 = add i32 %5, 1
  %7 = add i32 %2, -1
  %8 = icmp eq i32 %1, %7
  %9 = add i32 %6, %4
  %spec.select = select i1 %8, i32 %3, i32 %9
  %.unpack = load ptr, ptr %loadgep_2, align 8, !tbaa !8
  %.elt14 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  %.unpack15 = load i64, ptr %.elt14, align 8, !tbaa !8
  %.elt16 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  %.unpack17 = load i32, ptr %.elt16, align 8, !tbaa !8
  %.elt18 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  %.unpack19 = load i8, ptr %.elt18, align 4, !tbaa !8
  %.elt20 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  %.unpack21 = load i8, ptr %.elt20, align 1, !tbaa !8
  %.elt22 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  %.unpack23 = load i8, ptr %.elt22, align 2, !tbaa !8
  %.elt24 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  %.unpack25 = load i8, ptr %.elt24, align 1, !tbaa !8
  %.elt26 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  %.unpack27.unpack.unpack = load i64, ptr %.elt26, align 8, !tbaa !8
  %.unpack27.unpack.elt29 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  %.unpack27.unpack.unpack30 = load i64, ptr %.unpack27.unpack.elt29, align 8, !tbaa !8
  %.unpack27.unpack.elt31 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  %.unpack27.unpack.unpack32 = load i64, ptr %.unpack27.unpack.elt31, align 8, !tbaa !8
  store ptr %.unpack, ptr %loadgep_4, align 8, !tbaa !8
  %loadgep_4.repack34 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 1
  store i64 %.unpack15, ptr %loadgep_4.repack34, align 8, !tbaa !8
  %loadgep_4.repack36 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 2
  store i32 %.unpack17, ptr %loadgep_4.repack36, align 8, !tbaa !8
  %loadgep_4.repack38 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 3
  store i8 %.unpack19, ptr %loadgep_4.repack38, align 4, !tbaa !8
  %loadgep_4.repack40 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 4
  store i8 %.unpack21, ptr %loadgep_4.repack40, align 1, !tbaa !8
  %loadgep_4.repack42 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 5
  store i8 %.unpack23, ptr %loadgep_4.repack42, align 2, !tbaa !8
  %loadgep_4.repack44 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 6
  store i8 %.unpack25, ptr %loadgep_4.repack44, align 1, !tbaa !8
  %loadgep_4.repack46 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7
  store i64 %.unpack27.unpack.unpack, ptr %loadgep_4.repack46, align 8, !tbaa !8
  %loadgep_4.repack46.repack48 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack27.unpack.unpack30, ptr %loadgep_4.repack46.repack48, align 8, !tbaa !8
  %loadgep_4.repack46.repack50 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 2
  store i64 %.unpack27.unpack.unpack32, ptr %loadgep_4.repack46.repack50, align 8, !tbaa !8
  %10 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 0
  %11 = load i64, ptr %10, align 8, !tbaa !8
  %12 = icmp eq i64 %.unpack27.unpack.unpack30, 0
  %13 = select i1 %12, i64 1, i64 %11
  store ptr %.unpack, ptr %loadgep_6, align 8, !tbaa !8
  %loadgep_6.repack52 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 1
  store i64 8, ptr %loadgep_6.repack52, align 8, !tbaa !8
  %loadgep_6.repack54 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 2
  store i32 20180515, ptr %loadgep_6.repack54, align 8, !tbaa !8
  %loadgep_6.repack56 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 3
  store i8 1, ptr %loadgep_6.repack56, align 4, !tbaa !8
  %loadgep_6.repack58 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 4
  store i8 28, ptr %loadgep_6.repack58, align 1, !tbaa !8
  %loadgep_6.repack60 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 5
  store i8 0, ptr %loadgep_6.repack60, align 2, !tbaa !8
  %loadgep_6.repack62 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 6
  store i8 0, ptr %loadgep_6.repack62, align 1, !tbaa !8
  %loadgep_6.repack64 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7
  store i64 %13, ptr %loadgep_6.repack64, align 8, !tbaa !8
  %loadgep_6.repack64.repack66 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack27.unpack.unpack30, ptr %loadgep_6.repack64.repack66, align 8, !tbaa !8
  %loadgep_6.repack64.repack68 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7, i64 0, i64 2
  store i64 8, ptr %loadgep_6.repack64.repack68, align 8, !tbaa !8
  %14 = load ptr, ptr %loadgep_8, align 8, !tbaa !4
  %15 = getelementptr { ptr, ptr }, ptr %loadgep_8, i64 0, i32 1
  %16 = load ptr, ptr %15, align 8, !tbaa !4
  %17 = sext i32 %6 to i64
  %18 = sext i32 %spec.select to i64
  %reass.sub9.i = sub nsw i64 %18, %17
  %19 = icmp sgt i64 %reass.sub9.i, -1
  br i1 %19, label %.lr.ph8.preheader.i, label %_QFPloop.exit

.lr.ph8.preheader.i:                              ; preds = %omp.par.entry
  %20 = add nuw nsw i64 %reass.sub9.i, 1
  br label %.lr.ph8.i

.lr.ph8.i:                                        ; preds = %.lr.ph8.i, %.lr.ph8.preheader.i
  %21 = phi i64 [ %31, %.lr.ph8.i ], [ %20, %.lr.ph8.preheader.i ]
  %22 = phi i32 [ %30, %.lr.ph8.i ], [ %6, %.lr.ph8.preheader.i ]
  %23 = load i32, ptr %14, align 4, !tbaa !4
  %24 = sitofp i32 %23 to float
  %25 = fdiv contract float 1.000000e+00, %24
  %26 = fpext float %25 to double
  %27 = sext i32 %22 to i64
  %28 = add nsw i64 %27, -1
  %29 = getelementptr double, ptr %.unpack, i64 %28
  store double %26, ptr %29, align 8, !tbaa !4
  store double %26, ptr %16, align 8, !tbaa !4
  %30 = add i32 %22, 1
  %31 = add nsw i64 %21, -1
  %32 = icmp ugt i64 %21, 1
  br i1 %32, label %.lr.ph8.i, label %_QFPloop.exit.loopexit

_QFPloop.exit.loopexit:                           ; preds = %.lr.ph8.i
  br label %_QFPloop.exit

_QFPloop.exit:                                    ; preds = %_QFPloop.exit.loopexit, %omp.par.entry
  ret void
}
*** IR Dump After GVNPass on _QFPomp_subroutine..omp_par ***
; Function Attrs: norecurse nounwind
define internal void @_QFPomp_subroutine..omp_par(ptr noalias %tid.addr, ptr noalias %zero.addr, ptr %0) #2 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %gep_3 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 2
  %loadgep_4 = load ptr, ptr %gep_3, align 8
  %gep_5 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 3
  %loadgep_6 = load ptr, ptr %gep_5, align 8
  %gep_7 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 4
  %loadgep_8 = load ptr, ptr %gep_7, align 8
  %1 = tail call i32 @omp_get_thread_num()
  %2 = tail call i32 @omp_get_num_threads()
  %3 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %4 = sdiv i32 %3, %2
  %5 = mul i32 %4, %1
  %6 = add i32 %5, 1
  %7 = add i32 %2, -1
  %8 = icmp eq i32 %1, %7
  %9 = add i32 %6, %4
  %spec.select = select i1 %8, i32 %3, i32 %9
  %.unpack = load ptr, ptr %loadgep_2, align 8, !tbaa !8
  %.elt14 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  %.unpack15 = load i64, ptr %.elt14, align 8, !tbaa !8
  %.elt16 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  %.unpack17 = load i32, ptr %.elt16, align 8, !tbaa !8
  %.elt18 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  %.unpack19 = load i8, ptr %.elt18, align 4, !tbaa !8
  %.elt20 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  %.unpack21 = load i8, ptr %.elt20, align 1, !tbaa !8
  %.elt22 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  %.unpack23 = load i8, ptr %.elt22, align 2, !tbaa !8
  %.elt24 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  %.unpack25 = load i8, ptr %.elt24, align 1, !tbaa !8
  %.elt26 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  %.unpack27.unpack.unpack = load i64, ptr %.elt26, align 8, !tbaa !8
  %.unpack27.unpack.elt29 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  %.unpack27.unpack.unpack30 = load i64, ptr %.unpack27.unpack.elt29, align 8, !tbaa !8
  %.unpack27.unpack.elt31 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  %.unpack27.unpack.unpack32 = load i64, ptr %.unpack27.unpack.elt31, align 8, !tbaa !8
  store ptr %.unpack, ptr %loadgep_4, align 8, !tbaa !8
  %loadgep_4.repack34 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 1
  store i64 %.unpack15, ptr %loadgep_4.repack34, align 8, !tbaa !8
  %loadgep_4.repack36 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 2
  store i32 %.unpack17, ptr %loadgep_4.repack36, align 8, !tbaa !8
  %loadgep_4.repack38 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 3
  store i8 %.unpack19, ptr %loadgep_4.repack38, align 4, !tbaa !8
  %loadgep_4.repack40 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 4
  store i8 %.unpack21, ptr %loadgep_4.repack40, align 1, !tbaa !8
  %loadgep_4.repack42 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 5
  store i8 %.unpack23, ptr %loadgep_4.repack42, align 2, !tbaa !8
  %loadgep_4.repack44 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 6
  store i8 %.unpack25, ptr %loadgep_4.repack44, align 1, !tbaa !8
  %loadgep_4.repack46 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7
  store i64 %.unpack27.unpack.unpack, ptr %loadgep_4.repack46, align 8, !tbaa !8
  %loadgep_4.repack46.repack48 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack27.unpack.unpack30, ptr %loadgep_4.repack46.repack48, align 8, !tbaa !8
  %loadgep_4.repack46.repack50 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 2
  store i64 %.unpack27.unpack.unpack32, ptr %loadgep_4.repack46.repack50, align 8, !tbaa !8
  %10 = icmp eq i64 %.unpack27.unpack.unpack30, 0
  %11 = select i1 %10, i64 1, i64 %.unpack27.unpack.unpack
  store ptr %.unpack, ptr %loadgep_6, align 8, !tbaa !8
  %loadgep_6.repack52 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 1
  store i64 8, ptr %loadgep_6.repack52, align 8, !tbaa !8
  %loadgep_6.repack54 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 2
  store i32 20180515, ptr %loadgep_6.repack54, align 8, !tbaa !8
  %loadgep_6.repack56 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 3
  store i8 1, ptr %loadgep_6.repack56, align 4, !tbaa !8
  %loadgep_6.repack58 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 4
  store i8 28, ptr %loadgep_6.repack58, align 1, !tbaa !8
  %loadgep_6.repack60 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 5
  store i8 0, ptr %loadgep_6.repack60, align 2, !tbaa !8
  %loadgep_6.repack62 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 6
  store i8 0, ptr %loadgep_6.repack62, align 1, !tbaa !8
  %loadgep_6.repack64 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7
  store i64 %11, ptr %loadgep_6.repack64, align 8, !tbaa !8
  %loadgep_6.repack64.repack66 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack27.unpack.unpack30, ptr %loadgep_6.repack64.repack66, align 8, !tbaa !8
  %loadgep_6.repack64.repack68 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7, i64 0, i64 2
  store i64 8, ptr %loadgep_6.repack64.repack68, align 8, !tbaa !8
  %12 = load ptr, ptr %loadgep_8, align 8, !tbaa !4
  %13 = getelementptr { ptr, ptr }, ptr %loadgep_8, i64 0, i32 1
  %14 = load ptr, ptr %13, align 8, !tbaa !4
  %15 = sext i32 %6 to i64
  %16 = sext i32 %spec.select to i64
  %reass.sub9.i = sub nsw i64 %16, %15
  %17 = icmp sgt i64 %reass.sub9.i, -1
  br i1 %17, label %.lr.ph8.preheader.i, label %_QFPloop.exit

.lr.ph8.preheader.i:                              ; preds = %omp.par.entry
  %18 = add nuw nsw i64 %reass.sub9.i, 1
  br label %.lr.ph8.i

.lr.ph8.i:                                        ; preds = %.lr.ph8.i, %.lr.ph8.preheader.i
  %19 = phi i64 [ %29, %.lr.ph8.i ], [ %18, %.lr.ph8.preheader.i ]
  %20 = phi i32 [ %28, %.lr.ph8.i ], [ %6, %.lr.ph8.preheader.i ]
  %21 = load i32, ptr %12, align 4, !tbaa !4
  %22 = sitofp i32 %21 to float
  %23 = fdiv contract float 1.000000e+00, %22
  %24 = fpext float %23 to double
  %25 = sext i32 %20 to i64
  %26 = add nsw i64 %25, -1
  %27 = getelementptr double, ptr %.unpack, i64 %26
  store double %24, ptr %27, align 8, !tbaa !4
  store double %24, ptr %14, align 8, !tbaa !4
  %28 = add i32 %20, 1
  %29 = add nsw i64 %19, -1
  %30 = icmp ugt i64 %19, 1
  br i1 %30, label %.lr.ph8.i, label %_QFPloop.exit.loopexit

_QFPloop.exit.loopexit:                           ; preds = %.lr.ph8.i
  br label %_QFPloop.exit

_QFPloop.exit:                                    ; preds = %_QFPloop.exit.loopexit, %omp.par.entry
  ret void
}
*** IR Dump After SCCPPass on _QFPomp_subroutine..omp_par ***
; Function Attrs: norecurse nounwind
define internal void @_QFPomp_subroutine..omp_par(ptr noalias %tid.addr, ptr noalias %zero.addr, ptr %0) #2 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %gep_3 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 2
  %loadgep_4 = load ptr, ptr %gep_3, align 8
  %gep_5 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 3
  %loadgep_6 = load ptr, ptr %gep_5, align 8
  %gep_7 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 4
  %loadgep_8 = load ptr, ptr %gep_7, align 8
  %1 = tail call i32 @omp_get_thread_num()
  %2 = tail call i32 @omp_get_num_threads()
  %3 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %4 = sdiv i32 %3, %2
  %5 = mul i32 %4, %1
  %6 = add i32 %5, 1
  %7 = add i32 %2, -1
  %8 = icmp eq i32 %1, %7
  %9 = add i32 %6, %4
  %spec.select = select i1 %8, i32 %3, i32 %9
  %.unpack = load ptr, ptr %loadgep_2, align 8, !tbaa !8
  %.elt14 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  %.unpack15 = load i64, ptr %.elt14, align 8, !tbaa !8
  %.elt16 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  %.unpack17 = load i32, ptr %.elt16, align 8, !tbaa !8
  %.elt18 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  %.unpack19 = load i8, ptr %.elt18, align 4, !tbaa !8
  %.elt20 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  %.unpack21 = load i8, ptr %.elt20, align 1, !tbaa !8
  %.elt22 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  %.unpack23 = load i8, ptr %.elt22, align 2, !tbaa !8
  %.elt24 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  %.unpack25 = load i8, ptr %.elt24, align 1, !tbaa !8
  %.elt26 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  %.unpack27.unpack.unpack = load i64, ptr %.elt26, align 8, !tbaa !8
  %.unpack27.unpack.elt29 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  %.unpack27.unpack.unpack30 = load i64, ptr %.unpack27.unpack.elt29, align 8, !tbaa !8
  %.unpack27.unpack.elt31 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  %.unpack27.unpack.unpack32 = load i64, ptr %.unpack27.unpack.elt31, align 8, !tbaa !8
  store ptr %.unpack, ptr %loadgep_4, align 8, !tbaa !8
  %loadgep_4.repack34 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 1
  store i64 %.unpack15, ptr %loadgep_4.repack34, align 8, !tbaa !8
  %loadgep_4.repack36 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 2
  store i32 %.unpack17, ptr %loadgep_4.repack36, align 8, !tbaa !8
  %loadgep_4.repack38 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 3
  store i8 %.unpack19, ptr %loadgep_4.repack38, align 4, !tbaa !8
  %loadgep_4.repack40 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 4
  store i8 %.unpack21, ptr %loadgep_4.repack40, align 1, !tbaa !8
  %loadgep_4.repack42 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 5
  store i8 %.unpack23, ptr %loadgep_4.repack42, align 2, !tbaa !8
  %loadgep_4.repack44 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 6
  store i8 %.unpack25, ptr %loadgep_4.repack44, align 1, !tbaa !8
  %loadgep_4.repack46 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7
  store i64 %.unpack27.unpack.unpack, ptr %loadgep_4.repack46, align 8, !tbaa !8
  %loadgep_4.repack46.repack48 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack27.unpack.unpack30, ptr %loadgep_4.repack46.repack48, align 8, !tbaa !8
  %loadgep_4.repack46.repack50 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 2
  store i64 %.unpack27.unpack.unpack32, ptr %loadgep_4.repack46.repack50, align 8, !tbaa !8
  %10 = icmp eq i64 %.unpack27.unpack.unpack30, 0
  %11 = select i1 %10, i64 1, i64 %.unpack27.unpack.unpack
  store ptr %.unpack, ptr %loadgep_6, align 8, !tbaa !8
  %loadgep_6.repack52 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 1
  store i64 8, ptr %loadgep_6.repack52, align 8, !tbaa !8
  %loadgep_6.repack54 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 2
  store i32 20180515, ptr %loadgep_6.repack54, align 8, !tbaa !8
  %loadgep_6.repack56 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 3
  store i8 1, ptr %loadgep_6.repack56, align 4, !tbaa !8
  %loadgep_6.repack58 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 4
  store i8 28, ptr %loadgep_6.repack58, align 1, !tbaa !8
  %loadgep_6.repack60 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 5
  store i8 0, ptr %loadgep_6.repack60, align 2, !tbaa !8
  %loadgep_6.repack62 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 6
  store i8 0, ptr %loadgep_6.repack62, align 1, !tbaa !8
  %loadgep_6.repack64 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7
  store i64 %11, ptr %loadgep_6.repack64, align 8, !tbaa !8
  %loadgep_6.repack64.repack66 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack27.unpack.unpack30, ptr %loadgep_6.repack64.repack66, align 8, !tbaa !8
  %loadgep_6.repack64.repack68 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7, i64 0, i64 2
  store i64 8, ptr %loadgep_6.repack64.repack68, align 8, !tbaa !8
  %12 = load ptr, ptr %loadgep_8, align 8, !tbaa !4
  %13 = getelementptr { ptr, ptr }, ptr %loadgep_8, i64 0, i32 1
  %14 = load ptr, ptr %13, align 8, !tbaa !4
  %15 = sext i32 %6 to i64
  %16 = sext i32 %spec.select to i64
  %reass.sub9.i = sub nsw i64 %16, %15
  %17 = icmp sgt i64 %reass.sub9.i, -1
  br i1 %17, label %.lr.ph8.preheader.i, label %_QFPloop.exit

.lr.ph8.preheader.i:                              ; preds = %omp.par.entry
  %18 = add nuw nsw i64 %reass.sub9.i, 1
  br label %.lr.ph8.i

.lr.ph8.i:                                        ; preds = %.lr.ph8.i, %.lr.ph8.preheader.i
  %19 = phi i64 [ %29, %.lr.ph8.i ], [ %18, %.lr.ph8.preheader.i ]
  %20 = phi i32 [ %28, %.lr.ph8.i ], [ %6, %.lr.ph8.preheader.i ]
  %21 = load i32, ptr %12, align 4, !tbaa !4
  %22 = sitofp i32 %21 to float
  %23 = fdiv contract float 1.000000e+00, %22
  %24 = fpext float %23 to double
  %25 = sext i32 %20 to i64
  %26 = add nsw i64 %25, -1
  %27 = getelementptr double, ptr %.unpack, i64 %26
  store double %24, ptr %27, align 8, !tbaa !4
  store double %24, ptr %14, align 8, !tbaa !4
  %28 = add i32 %20, 1
  %29 = add nsw i64 %19, -1
  %30 = icmp ugt i64 %19, 1
  br i1 %30, label %.lr.ph8.i, label %_QFPloop.exit.loopexit

_QFPloop.exit.loopexit:                           ; preds = %.lr.ph8.i
  br label %_QFPloop.exit

_QFPloop.exit:                                    ; preds = %_QFPloop.exit.loopexit, %omp.par.entry
  ret void
}
*** IR Dump After BDCEPass on _QFPomp_subroutine..omp_par ***
; Function Attrs: norecurse nounwind
define internal void @_QFPomp_subroutine..omp_par(ptr noalias %tid.addr, ptr noalias %zero.addr, ptr %0) #2 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %gep_3 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 2
  %loadgep_4 = load ptr, ptr %gep_3, align 8
  %gep_5 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 3
  %loadgep_6 = load ptr, ptr %gep_5, align 8
  %gep_7 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 4
  %loadgep_8 = load ptr, ptr %gep_7, align 8
  %1 = tail call i32 @omp_get_thread_num()
  %2 = tail call i32 @omp_get_num_threads()
  %3 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %4 = sdiv i32 %3, %2
  %5 = mul i32 %4, %1
  %6 = add i32 %5, 1
  %7 = add i32 %2, -1
  %8 = icmp eq i32 %1, %7
  %9 = add i32 %6, %4
  %spec.select = select i1 %8, i32 %3, i32 %9
  %.unpack = load ptr, ptr %loadgep_2, align 8, !tbaa !8
  %.elt14 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  %.unpack15 = load i64, ptr %.elt14, align 8, !tbaa !8
  %.elt16 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  %.unpack17 = load i32, ptr %.elt16, align 8, !tbaa !8
  %.elt18 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  %.unpack19 = load i8, ptr %.elt18, align 4, !tbaa !8
  %.elt20 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  %.unpack21 = load i8, ptr %.elt20, align 1, !tbaa !8
  %.elt22 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  %.unpack23 = load i8, ptr %.elt22, align 2, !tbaa !8
  %.elt24 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  %.unpack25 = load i8, ptr %.elt24, align 1, !tbaa !8
  %.elt26 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  %.unpack27.unpack.unpack = load i64, ptr %.elt26, align 8, !tbaa !8
  %.unpack27.unpack.elt29 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  %.unpack27.unpack.unpack30 = load i64, ptr %.unpack27.unpack.elt29, align 8, !tbaa !8
  %.unpack27.unpack.elt31 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  %.unpack27.unpack.unpack32 = load i64, ptr %.unpack27.unpack.elt31, align 8, !tbaa !8
  store ptr %.unpack, ptr %loadgep_4, align 8, !tbaa !8
  %loadgep_4.repack34 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 1
  store i64 %.unpack15, ptr %loadgep_4.repack34, align 8, !tbaa !8
  %loadgep_4.repack36 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 2
  store i32 %.unpack17, ptr %loadgep_4.repack36, align 8, !tbaa !8
  %loadgep_4.repack38 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 3
  store i8 %.unpack19, ptr %loadgep_4.repack38, align 4, !tbaa !8
  %loadgep_4.repack40 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 4
  store i8 %.unpack21, ptr %loadgep_4.repack40, align 1, !tbaa !8
  %loadgep_4.repack42 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 5
  store i8 %.unpack23, ptr %loadgep_4.repack42, align 2, !tbaa !8
  %loadgep_4.repack44 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 6
  store i8 %.unpack25, ptr %loadgep_4.repack44, align 1, !tbaa !8
  %loadgep_4.repack46 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7
  store i64 %.unpack27.unpack.unpack, ptr %loadgep_4.repack46, align 8, !tbaa !8
  %loadgep_4.repack46.repack48 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack27.unpack.unpack30, ptr %loadgep_4.repack46.repack48, align 8, !tbaa !8
  %loadgep_4.repack46.repack50 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 2
  store i64 %.unpack27.unpack.unpack32, ptr %loadgep_4.repack46.repack50, align 8, !tbaa !8
  %10 = icmp eq i64 %.unpack27.unpack.unpack30, 0
  %11 = select i1 %10, i64 1, i64 %.unpack27.unpack.unpack
  store ptr %.unpack, ptr %loadgep_6, align 8, !tbaa !8
  %loadgep_6.repack52 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 1
  store i64 8, ptr %loadgep_6.repack52, align 8, !tbaa !8
  %loadgep_6.repack54 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 2
  store i32 20180515, ptr %loadgep_6.repack54, align 8, !tbaa !8
  %loadgep_6.repack56 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 3
  store i8 1, ptr %loadgep_6.repack56, align 4, !tbaa !8
  %loadgep_6.repack58 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 4
  store i8 28, ptr %loadgep_6.repack58, align 1, !tbaa !8
  %loadgep_6.repack60 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 5
  store i8 0, ptr %loadgep_6.repack60, align 2, !tbaa !8
  %loadgep_6.repack62 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 6
  store i8 0, ptr %loadgep_6.repack62, align 1, !tbaa !8
  %loadgep_6.repack64 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7
  store i64 %11, ptr %loadgep_6.repack64, align 8, !tbaa !8
  %loadgep_6.repack64.repack66 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack27.unpack.unpack30, ptr %loadgep_6.repack64.repack66, align 8, !tbaa !8
  %loadgep_6.repack64.repack68 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7, i64 0, i64 2
  store i64 8, ptr %loadgep_6.repack64.repack68, align 8, !tbaa !8
  %12 = load ptr, ptr %loadgep_8, align 8, !tbaa !4
  %13 = getelementptr { ptr, ptr }, ptr %loadgep_8, i64 0, i32 1
  %14 = load ptr, ptr %13, align 8, !tbaa !4
  %15 = sext i32 %6 to i64
  %16 = sext i32 %spec.select to i64
  %reass.sub9.i = sub nsw i64 %16, %15
  %17 = icmp sgt i64 %reass.sub9.i, -1
  br i1 %17, label %.lr.ph8.preheader.i, label %_QFPloop.exit

.lr.ph8.preheader.i:                              ; preds = %omp.par.entry
  %18 = add nuw nsw i64 %reass.sub9.i, 1
  br label %.lr.ph8.i

.lr.ph8.i:                                        ; preds = %.lr.ph8.i, %.lr.ph8.preheader.i
  %19 = phi i64 [ %29, %.lr.ph8.i ], [ %18, %.lr.ph8.preheader.i ]
  %20 = phi i32 [ %28, %.lr.ph8.i ], [ %6, %.lr.ph8.preheader.i ]
  %21 = load i32, ptr %12, align 4, !tbaa !4
  %22 = sitofp i32 %21 to float
  %23 = fdiv contract float 1.000000e+00, %22
  %24 = fpext float %23 to double
  %25 = sext i32 %20 to i64
  %26 = add nsw i64 %25, -1
  %27 = getelementptr double, ptr %.unpack, i64 %26
  store double %24, ptr %27, align 8, !tbaa !4
  store double %24, ptr %14, align 8, !tbaa !4
  %28 = add i32 %20, 1
  %29 = add nsw i64 %19, -1
  %30 = icmp ugt i64 %19, 1
  br i1 %30, label %.lr.ph8.i, label %_QFPloop.exit.loopexit

_QFPloop.exit.loopexit:                           ; preds = %.lr.ph8.i
  br label %_QFPloop.exit

_QFPloop.exit:                                    ; preds = %_QFPloop.exit.loopexit, %omp.par.entry
  ret void
}
*** IR Dump After InstCombinePass on _QFPomp_subroutine..omp_par ***
; Function Attrs: norecurse nounwind
define internal void @_QFPomp_subroutine..omp_par(ptr noalias %tid.addr, ptr noalias %zero.addr, ptr %0) #2 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %gep_3 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 2
  %loadgep_4 = load ptr, ptr %gep_3, align 8
  %gep_5 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 3
  %loadgep_6 = load ptr, ptr %gep_5, align 8
  %gep_7 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 4
  %loadgep_8 = load ptr, ptr %gep_7, align 8
  %1 = tail call i32 @omp_get_thread_num()
  %2 = tail call i32 @omp_get_num_threads()
  %3 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %4 = sdiv i32 %3, %2
  %5 = mul i32 %4, %1
  %6 = add i32 %5, 1
  %7 = add i32 %2, -1
  %8 = icmp eq i32 %1, %7
  %9 = add i32 %6, %4
  %spec.select = select i1 %8, i32 %3, i32 %9
  %.unpack = load ptr, ptr %loadgep_2, align 8, !tbaa !8
  %.elt14 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  %.unpack15 = load i64, ptr %.elt14, align 8, !tbaa !8
  %.elt16 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  %.unpack17 = load i32, ptr %.elt16, align 8, !tbaa !8
  %.elt18 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  %.unpack19 = load i8, ptr %.elt18, align 4, !tbaa !8
  %.elt20 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  %.unpack21 = load i8, ptr %.elt20, align 1, !tbaa !8
  %.elt22 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  %.unpack23 = load i8, ptr %.elt22, align 2, !tbaa !8
  %.elt24 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  %.unpack25 = load i8, ptr %.elt24, align 1, !tbaa !8
  %.elt26 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  %.unpack27.unpack.unpack = load i64, ptr %.elt26, align 8, !tbaa !8
  %.unpack27.unpack.elt29 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  %.unpack27.unpack.unpack30 = load i64, ptr %.unpack27.unpack.elt29, align 8, !tbaa !8
  %.unpack27.unpack.elt31 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  %.unpack27.unpack.unpack32 = load i64, ptr %.unpack27.unpack.elt31, align 8, !tbaa !8
  store ptr %.unpack, ptr %loadgep_4, align 8, !tbaa !8
  %loadgep_4.repack34 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 1
  store i64 %.unpack15, ptr %loadgep_4.repack34, align 8, !tbaa !8
  %loadgep_4.repack36 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 2
  store i32 %.unpack17, ptr %loadgep_4.repack36, align 8, !tbaa !8
  %loadgep_4.repack38 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 3
  store i8 %.unpack19, ptr %loadgep_4.repack38, align 4, !tbaa !8
  %loadgep_4.repack40 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 4
  store i8 %.unpack21, ptr %loadgep_4.repack40, align 1, !tbaa !8
  %loadgep_4.repack42 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 5
  store i8 %.unpack23, ptr %loadgep_4.repack42, align 2, !tbaa !8
  %loadgep_4.repack44 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 6
  store i8 %.unpack25, ptr %loadgep_4.repack44, align 1, !tbaa !8
  %loadgep_4.repack46 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7
  store i64 %.unpack27.unpack.unpack, ptr %loadgep_4.repack46, align 8, !tbaa !8
  %loadgep_4.repack46.repack48 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack27.unpack.unpack30, ptr %loadgep_4.repack46.repack48, align 8, !tbaa !8
  %loadgep_4.repack46.repack50 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 2
  store i64 %.unpack27.unpack.unpack32, ptr %loadgep_4.repack46.repack50, align 8, !tbaa !8
  %10 = icmp eq i64 %.unpack27.unpack.unpack30, 0
  %11 = select i1 %10, i64 1, i64 %.unpack27.unpack.unpack
  store ptr %.unpack, ptr %loadgep_6, align 8, !tbaa !8
  %loadgep_6.repack52 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 1
  store i64 8, ptr %loadgep_6.repack52, align 8, !tbaa !8
  %loadgep_6.repack54 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 2
  store i32 20180515, ptr %loadgep_6.repack54, align 8, !tbaa !8
  %loadgep_6.repack56 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 3
  store i8 1, ptr %loadgep_6.repack56, align 4, !tbaa !8
  %loadgep_6.repack58 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 4
  store i8 28, ptr %loadgep_6.repack58, align 1, !tbaa !8
  %loadgep_6.repack60 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 5
  store i8 0, ptr %loadgep_6.repack60, align 2, !tbaa !8
  %loadgep_6.repack62 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 6
  store i8 0, ptr %loadgep_6.repack62, align 1, !tbaa !8
  %loadgep_6.repack64 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7
  store i64 %11, ptr %loadgep_6.repack64, align 8, !tbaa !8
  %loadgep_6.repack64.repack66 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack27.unpack.unpack30, ptr %loadgep_6.repack64.repack66, align 8, !tbaa !8
  %loadgep_6.repack64.repack68 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7, i64 0, i64 2
  store i64 8, ptr %loadgep_6.repack64.repack68, align 8, !tbaa !8
  %12 = load ptr, ptr %loadgep_8, align 8, !tbaa !4
  %13 = getelementptr { ptr, ptr }, ptr %loadgep_8, i64 0, i32 1
  %14 = load ptr, ptr %13, align 8, !tbaa !4
  %15 = sext i32 %6 to i64
  %16 = sext i32 %spec.select to i64
  %reass.sub9.i = sub nsw i64 %16, %15
  %17 = icmp sgt i64 %reass.sub9.i, -1
  br i1 %17, label %.lr.ph8.preheader.i, label %_QFPloop.exit

.lr.ph8.preheader.i:                              ; preds = %omp.par.entry
  %18 = add nuw nsw i64 %reass.sub9.i, 1
  br label %.lr.ph8.i

.lr.ph8.i:                                        ; preds = %.lr.ph8.i, %.lr.ph8.preheader.i
  %19 = phi i64 [ %29, %.lr.ph8.i ], [ %18, %.lr.ph8.preheader.i ]
  %20 = phi i32 [ %28, %.lr.ph8.i ], [ %6, %.lr.ph8.preheader.i ]
  %21 = load i32, ptr %12, align 4, !tbaa !4
  %22 = sitofp i32 %21 to float
  %23 = fdiv contract float 1.000000e+00, %22
  %24 = fpext float %23 to double
  %25 = sext i32 %20 to i64
  %26 = add nsw i64 %25, -1
  %27 = getelementptr double, ptr %.unpack, i64 %26
  store double %24, ptr %27, align 8, !tbaa !4
  store double %24, ptr %14, align 8, !tbaa !4
  %28 = add i32 %20, 1
  %29 = add nsw i64 %19, -1
  %30 = icmp ugt i64 %19, 1
  br i1 %30, label %.lr.ph8.i, label %_QFPloop.exit.loopexit

_QFPloop.exit.loopexit:                           ; preds = %.lr.ph8.i
  br label %_QFPloop.exit

_QFPloop.exit:                                    ; preds = %_QFPloop.exit.loopexit, %omp.par.entry
  ret void
}
*** IR Dump After JumpThreadingPass on _QFPomp_subroutine..omp_par ***
; Function Attrs: norecurse nounwind
define internal void @_QFPomp_subroutine..omp_par(ptr noalias %tid.addr, ptr noalias %zero.addr, ptr %0) #2 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %gep_3 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 2
  %loadgep_4 = load ptr, ptr %gep_3, align 8
  %gep_5 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 3
  %loadgep_6 = load ptr, ptr %gep_5, align 8
  %gep_7 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 4
  %loadgep_8 = load ptr, ptr %gep_7, align 8
  %1 = tail call i32 @omp_get_thread_num()
  %2 = tail call i32 @omp_get_num_threads()
  %3 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %4 = sdiv i32 %3, %2
  %5 = mul i32 %4, %1
  %6 = add i32 %5, 1
  %7 = add i32 %2, -1
  %8 = icmp eq i32 %1, %7
  %9 = add i32 %6, %4
  %spec.select = select i1 %8, i32 %3, i32 %9
  %.unpack = load ptr, ptr %loadgep_2, align 8, !tbaa !8
  %.elt14 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  %.unpack15 = load i64, ptr %.elt14, align 8, !tbaa !8
  %.elt16 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  %.unpack17 = load i32, ptr %.elt16, align 8, !tbaa !8
  %.elt18 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  %.unpack19 = load i8, ptr %.elt18, align 4, !tbaa !8
  %.elt20 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  %.unpack21 = load i8, ptr %.elt20, align 1, !tbaa !8
  %.elt22 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  %.unpack23 = load i8, ptr %.elt22, align 2, !tbaa !8
  %.elt24 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  %.unpack25 = load i8, ptr %.elt24, align 1, !tbaa !8
  %.elt26 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  %.unpack27.unpack.unpack = load i64, ptr %.elt26, align 8, !tbaa !8
  %.unpack27.unpack.elt29 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  %.unpack27.unpack.unpack30 = load i64, ptr %.unpack27.unpack.elt29, align 8, !tbaa !8
  %.unpack27.unpack.elt31 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  %.unpack27.unpack.unpack32 = load i64, ptr %.unpack27.unpack.elt31, align 8, !tbaa !8
  store ptr %.unpack, ptr %loadgep_4, align 8, !tbaa !8
  %loadgep_4.repack34 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 1
  store i64 %.unpack15, ptr %loadgep_4.repack34, align 8, !tbaa !8
  %loadgep_4.repack36 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 2
  store i32 %.unpack17, ptr %loadgep_4.repack36, align 8, !tbaa !8
  %loadgep_4.repack38 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 3
  store i8 %.unpack19, ptr %loadgep_4.repack38, align 4, !tbaa !8
  %loadgep_4.repack40 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 4
  store i8 %.unpack21, ptr %loadgep_4.repack40, align 1, !tbaa !8
  %loadgep_4.repack42 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 5
  store i8 %.unpack23, ptr %loadgep_4.repack42, align 2, !tbaa !8
  %loadgep_4.repack44 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 6
  store i8 %.unpack25, ptr %loadgep_4.repack44, align 1, !tbaa !8
  %loadgep_4.repack46 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7
  store i64 %.unpack27.unpack.unpack, ptr %loadgep_4.repack46, align 8, !tbaa !8
  %loadgep_4.repack46.repack48 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack27.unpack.unpack30, ptr %loadgep_4.repack46.repack48, align 8, !tbaa !8
  %loadgep_4.repack46.repack50 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 2
  store i64 %.unpack27.unpack.unpack32, ptr %loadgep_4.repack46.repack50, align 8, !tbaa !8
  %10 = icmp eq i64 %.unpack27.unpack.unpack30, 0
  %11 = select i1 %10, i64 1, i64 %.unpack27.unpack.unpack
  store ptr %.unpack, ptr %loadgep_6, align 8, !tbaa !8
  %loadgep_6.repack52 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 1
  store i64 8, ptr %loadgep_6.repack52, align 8, !tbaa !8
  %loadgep_6.repack54 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 2
  store i32 20180515, ptr %loadgep_6.repack54, align 8, !tbaa !8
  %loadgep_6.repack56 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 3
  store i8 1, ptr %loadgep_6.repack56, align 4, !tbaa !8
  %loadgep_6.repack58 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 4
  store i8 28, ptr %loadgep_6.repack58, align 1, !tbaa !8
  %loadgep_6.repack60 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 5
  store i8 0, ptr %loadgep_6.repack60, align 2, !tbaa !8
  %loadgep_6.repack62 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 6
  store i8 0, ptr %loadgep_6.repack62, align 1, !tbaa !8
  %loadgep_6.repack64 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7
  store i64 %11, ptr %loadgep_6.repack64, align 8, !tbaa !8
  %loadgep_6.repack64.repack66 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack27.unpack.unpack30, ptr %loadgep_6.repack64.repack66, align 8, !tbaa !8
  %loadgep_6.repack64.repack68 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7, i64 0, i64 2
  store i64 8, ptr %loadgep_6.repack64.repack68, align 8, !tbaa !8
  %12 = load ptr, ptr %loadgep_8, align 8, !tbaa !4
  %13 = getelementptr { ptr, ptr }, ptr %loadgep_8, i64 0, i32 1
  %14 = load ptr, ptr %13, align 8, !tbaa !4
  %15 = sext i32 %6 to i64
  %16 = sext i32 %spec.select to i64
  %reass.sub9.i = sub nsw i64 %16, %15
  %17 = icmp sgt i64 %reass.sub9.i, -1
  br i1 %17, label %.lr.ph8.preheader.i, label %_QFPloop.exit

.lr.ph8.preheader.i:                              ; preds = %omp.par.entry
  %18 = add nuw nsw i64 %reass.sub9.i, 1
  br label %.lr.ph8.i

.lr.ph8.i:                                        ; preds = %.lr.ph8.i, %.lr.ph8.preheader.i
  %19 = phi i64 [ %29, %.lr.ph8.i ], [ %18, %.lr.ph8.preheader.i ]
  %20 = phi i32 [ %28, %.lr.ph8.i ], [ %6, %.lr.ph8.preheader.i ]
  %21 = load i32, ptr %12, align 4, !tbaa !4
  %22 = sitofp i32 %21 to float
  %23 = fdiv contract float 1.000000e+00, %22
  %24 = fpext float %23 to double
  %25 = sext i32 %20 to i64
  %26 = add nsw i64 %25, -1
  %27 = getelementptr double, ptr %.unpack, i64 %26
  store double %24, ptr %27, align 8, !tbaa !4
  store double %24, ptr %14, align 8, !tbaa !4
  %28 = add i32 %20, 1
  %29 = add nsw i64 %19, -1
  %30 = icmp ugt i64 %19, 1
  br i1 %30, label %.lr.ph8.i, label %_QFPloop.exit

_QFPloop.exit:                                    ; preds = %.lr.ph8.i, %omp.par.entry
  ret void
}
*** IR Dump After CorrelatedValuePropagationPass on _QFPomp_subroutine..omp_par ***
; Function Attrs: norecurse nounwind
define internal void @_QFPomp_subroutine..omp_par(ptr noalias %tid.addr, ptr noalias %zero.addr, ptr %0) #2 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %gep_3 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 2
  %loadgep_4 = load ptr, ptr %gep_3, align 8
  %gep_5 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 3
  %loadgep_6 = load ptr, ptr %gep_5, align 8
  %gep_7 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 4
  %loadgep_8 = load ptr, ptr %gep_7, align 8
  %1 = tail call i32 @omp_get_thread_num()
  %2 = tail call i32 @omp_get_num_threads()
  %3 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %4 = sdiv i32 %3, %2
  %5 = mul i32 %4, %1
  %6 = add i32 %5, 1
  %7 = add i32 %2, -1
  %8 = icmp eq i32 %1, %7
  %9 = add i32 %6, %4
  %spec.select = select i1 %8, i32 %3, i32 %9
  %.unpack = load ptr, ptr %loadgep_2, align 8, !tbaa !8
  %.elt14 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  %.unpack15 = load i64, ptr %.elt14, align 8, !tbaa !8
  %.elt16 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  %.unpack17 = load i32, ptr %.elt16, align 8, !tbaa !8
  %.elt18 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  %.unpack19 = load i8, ptr %.elt18, align 4, !tbaa !8
  %.elt20 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  %.unpack21 = load i8, ptr %.elt20, align 1, !tbaa !8
  %.elt22 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  %.unpack23 = load i8, ptr %.elt22, align 2, !tbaa !8
  %.elt24 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  %.unpack25 = load i8, ptr %.elt24, align 1, !tbaa !8
  %.elt26 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  %.unpack27.unpack.unpack = load i64, ptr %.elt26, align 8, !tbaa !8
  %.unpack27.unpack.elt29 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  %.unpack27.unpack.unpack30 = load i64, ptr %.unpack27.unpack.elt29, align 8, !tbaa !8
  %.unpack27.unpack.elt31 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  %.unpack27.unpack.unpack32 = load i64, ptr %.unpack27.unpack.elt31, align 8, !tbaa !8
  store ptr %.unpack, ptr %loadgep_4, align 8, !tbaa !8
  %loadgep_4.repack34 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 1
  store i64 %.unpack15, ptr %loadgep_4.repack34, align 8, !tbaa !8
  %loadgep_4.repack36 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 2
  store i32 %.unpack17, ptr %loadgep_4.repack36, align 8, !tbaa !8
  %loadgep_4.repack38 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 3
  store i8 %.unpack19, ptr %loadgep_4.repack38, align 4, !tbaa !8
  %loadgep_4.repack40 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 4
  store i8 %.unpack21, ptr %loadgep_4.repack40, align 1, !tbaa !8
  %loadgep_4.repack42 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 5
  store i8 %.unpack23, ptr %loadgep_4.repack42, align 2, !tbaa !8
  %loadgep_4.repack44 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 6
  store i8 %.unpack25, ptr %loadgep_4.repack44, align 1, !tbaa !8
  %loadgep_4.repack46 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7
  store i64 %.unpack27.unpack.unpack, ptr %loadgep_4.repack46, align 8, !tbaa !8
  %loadgep_4.repack46.repack48 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack27.unpack.unpack30, ptr %loadgep_4.repack46.repack48, align 8, !tbaa !8
  %loadgep_4.repack46.repack50 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 2
  store i64 %.unpack27.unpack.unpack32, ptr %loadgep_4.repack46.repack50, align 8, !tbaa !8
  %10 = icmp eq i64 %.unpack27.unpack.unpack30, 0
  %11 = select i1 %10, i64 1, i64 %.unpack27.unpack.unpack
  store ptr %.unpack, ptr %loadgep_6, align 8, !tbaa !8
  %loadgep_6.repack52 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 1
  store i64 8, ptr %loadgep_6.repack52, align 8, !tbaa !8
  %loadgep_6.repack54 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 2
  store i32 20180515, ptr %loadgep_6.repack54, align 8, !tbaa !8
  %loadgep_6.repack56 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 3
  store i8 1, ptr %loadgep_6.repack56, align 4, !tbaa !8
  %loadgep_6.repack58 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 4
  store i8 28, ptr %loadgep_6.repack58, align 1, !tbaa !8
  %loadgep_6.repack60 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 5
  store i8 0, ptr %loadgep_6.repack60, align 2, !tbaa !8
  %loadgep_6.repack62 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 6
  store i8 0, ptr %loadgep_6.repack62, align 1, !tbaa !8
  %loadgep_6.repack64 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7
  store i64 %11, ptr %loadgep_6.repack64, align 8, !tbaa !8
  %loadgep_6.repack64.repack66 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack27.unpack.unpack30, ptr %loadgep_6.repack64.repack66, align 8, !tbaa !8
  %loadgep_6.repack64.repack68 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7, i64 0, i64 2
  store i64 8, ptr %loadgep_6.repack64.repack68, align 8, !tbaa !8
  %12 = load ptr, ptr %loadgep_8, align 8, !tbaa !4
  %13 = getelementptr { ptr, ptr }, ptr %loadgep_8, i64 0, i32 1
  %14 = load ptr, ptr %13, align 8, !tbaa !4
  %15 = sext i32 %6 to i64
  %16 = sext i32 %spec.select to i64
  %reass.sub9.i = sub nsw i64 %16, %15
  %17 = icmp sgt i64 %reass.sub9.i, -1
  br i1 %17, label %.lr.ph8.preheader.i, label %_QFPloop.exit

.lr.ph8.preheader.i:                              ; preds = %omp.par.entry
  %18 = add nuw nsw i64 %reass.sub9.i, 1
  br label %.lr.ph8.i

.lr.ph8.i:                                        ; preds = %.lr.ph8.i, %.lr.ph8.preheader.i
  %19 = phi i64 [ %29, %.lr.ph8.i ], [ %18, %.lr.ph8.preheader.i ]
  %20 = phi i32 [ %28, %.lr.ph8.i ], [ %6, %.lr.ph8.preheader.i ]
  %21 = load i32, ptr %12, align 4, !tbaa !4
  %22 = sitofp i32 %21 to float
  %23 = fdiv contract float 1.000000e+00, %22
  %24 = fpext float %23 to double
  %25 = sext i32 %20 to i64
  %26 = add nsw i64 %25, -1
  %27 = getelementptr double, ptr %.unpack, i64 %26
  store double %24, ptr %27, align 8, !tbaa !4
  store double %24, ptr %14, align 8, !tbaa !4
  %28 = add i32 %20, 1
  %29 = add nsw i64 %19, -1
  %30 = icmp ugt i64 %19, 1
  br i1 %30, label %.lr.ph8.i, label %_QFPloop.exit

_QFPloop.exit:                                    ; preds = %.lr.ph8.i, %omp.par.entry
  ret void
}
*** IR Dump After ADCEPass on _QFPomp_subroutine..omp_par ***
; Function Attrs: norecurse nounwind
define internal void @_QFPomp_subroutine..omp_par(ptr noalias %tid.addr, ptr noalias %zero.addr, ptr %0) #2 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %gep_3 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 2
  %loadgep_4 = load ptr, ptr %gep_3, align 8
  %gep_5 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 3
  %loadgep_6 = load ptr, ptr %gep_5, align 8
  %gep_7 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 4
  %loadgep_8 = load ptr, ptr %gep_7, align 8
  %1 = tail call i32 @omp_get_thread_num()
  %2 = tail call i32 @omp_get_num_threads()
  %3 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %4 = sdiv i32 %3, %2
  %5 = mul i32 %4, %1
  %6 = add i32 %5, 1
  %7 = add i32 %2, -1
  %8 = icmp eq i32 %1, %7
  %9 = add i32 %6, %4
  %spec.select = select i1 %8, i32 %3, i32 %9
  %.unpack = load ptr, ptr %loadgep_2, align 8, !tbaa !8
  %.elt14 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  %.unpack15 = load i64, ptr %.elt14, align 8, !tbaa !8
  %.elt16 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  %.unpack17 = load i32, ptr %.elt16, align 8, !tbaa !8
  %.elt18 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  %.unpack19 = load i8, ptr %.elt18, align 4, !tbaa !8
  %.elt20 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  %.unpack21 = load i8, ptr %.elt20, align 1, !tbaa !8
  %.elt22 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  %.unpack23 = load i8, ptr %.elt22, align 2, !tbaa !8
  %.elt24 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  %.unpack25 = load i8, ptr %.elt24, align 1, !tbaa !8
  %.elt26 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  %.unpack27.unpack.unpack = load i64, ptr %.elt26, align 8, !tbaa !8
  %.unpack27.unpack.elt29 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  %.unpack27.unpack.unpack30 = load i64, ptr %.unpack27.unpack.elt29, align 8, !tbaa !8
  %.unpack27.unpack.elt31 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  %.unpack27.unpack.unpack32 = load i64, ptr %.unpack27.unpack.elt31, align 8, !tbaa !8
  store ptr %.unpack, ptr %loadgep_4, align 8, !tbaa !8
  %loadgep_4.repack34 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 1
  store i64 %.unpack15, ptr %loadgep_4.repack34, align 8, !tbaa !8
  %loadgep_4.repack36 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 2
  store i32 %.unpack17, ptr %loadgep_4.repack36, align 8, !tbaa !8
  %loadgep_4.repack38 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 3
  store i8 %.unpack19, ptr %loadgep_4.repack38, align 4, !tbaa !8
  %loadgep_4.repack40 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 4
  store i8 %.unpack21, ptr %loadgep_4.repack40, align 1, !tbaa !8
  %loadgep_4.repack42 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 5
  store i8 %.unpack23, ptr %loadgep_4.repack42, align 2, !tbaa !8
  %loadgep_4.repack44 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 6
  store i8 %.unpack25, ptr %loadgep_4.repack44, align 1, !tbaa !8
  %loadgep_4.repack46 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7
  store i64 %.unpack27.unpack.unpack, ptr %loadgep_4.repack46, align 8, !tbaa !8
  %loadgep_4.repack46.repack48 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack27.unpack.unpack30, ptr %loadgep_4.repack46.repack48, align 8, !tbaa !8
  %loadgep_4.repack46.repack50 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 2
  store i64 %.unpack27.unpack.unpack32, ptr %loadgep_4.repack46.repack50, align 8, !tbaa !8
  %10 = icmp eq i64 %.unpack27.unpack.unpack30, 0
  %11 = select i1 %10, i64 1, i64 %.unpack27.unpack.unpack
  store ptr %.unpack, ptr %loadgep_6, align 8, !tbaa !8
  %loadgep_6.repack52 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 1
  store i64 8, ptr %loadgep_6.repack52, align 8, !tbaa !8
  %loadgep_6.repack54 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 2
  store i32 20180515, ptr %loadgep_6.repack54, align 8, !tbaa !8
  %loadgep_6.repack56 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 3
  store i8 1, ptr %loadgep_6.repack56, align 4, !tbaa !8
  %loadgep_6.repack58 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 4
  store i8 28, ptr %loadgep_6.repack58, align 1, !tbaa !8
  %loadgep_6.repack60 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 5
  store i8 0, ptr %loadgep_6.repack60, align 2, !tbaa !8
  %loadgep_6.repack62 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 6
  store i8 0, ptr %loadgep_6.repack62, align 1, !tbaa !8
  %loadgep_6.repack64 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7
  store i64 %11, ptr %loadgep_6.repack64, align 8, !tbaa !8
  %loadgep_6.repack64.repack66 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack27.unpack.unpack30, ptr %loadgep_6.repack64.repack66, align 8, !tbaa !8
  %loadgep_6.repack64.repack68 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7, i64 0, i64 2
  store i64 8, ptr %loadgep_6.repack64.repack68, align 8, !tbaa !8
  %12 = load ptr, ptr %loadgep_8, align 8, !tbaa !4
  %13 = getelementptr { ptr, ptr }, ptr %loadgep_8, i64 0, i32 1
  %14 = load ptr, ptr %13, align 8, !tbaa !4
  %15 = sext i32 %6 to i64
  %16 = sext i32 %spec.select to i64
  %reass.sub9.i = sub nsw i64 %16, %15
  %17 = icmp sgt i64 %reass.sub9.i, -1
  br i1 %17, label %.lr.ph8.preheader.i, label %_QFPloop.exit

.lr.ph8.preheader.i:                              ; preds = %omp.par.entry
  %18 = add nuw nsw i64 %reass.sub9.i, 1
  br label %.lr.ph8.i

.lr.ph8.i:                                        ; preds = %.lr.ph8.i, %.lr.ph8.preheader.i
  %19 = phi i64 [ %29, %.lr.ph8.i ], [ %18, %.lr.ph8.preheader.i ]
  %20 = phi i32 [ %28, %.lr.ph8.i ], [ %6, %.lr.ph8.preheader.i ]
  %21 = load i32, ptr %12, align 4, !tbaa !4
  %22 = sitofp i32 %21 to float
  %23 = fdiv contract float 1.000000e+00, %22
  %24 = fpext float %23 to double
  %25 = sext i32 %20 to i64
  %26 = add nsw i64 %25, -1
  %27 = getelementptr double, ptr %.unpack, i64 %26
  store double %24, ptr %27, align 8, !tbaa !4
  store double %24, ptr %14, align 8, !tbaa !4
  %28 = add i32 %20, 1
  %29 = add nsw i64 %19, -1
  %30 = icmp ugt i64 %19, 1
  br i1 %30, label %.lr.ph8.i, label %_QFPloop.exit

_QFPloop.exit:                                    ; preds = %.lr.ph8.i, %omp.par.entry
  ret void
}
*** IR Dump After MemCpyOptPass on _QFPomp_subroutine..omp_par ***
; Function Attrs: norecurse nounwind
define internal void @_QFPomp_subroutine..omp_par(ptr noalias %tid.addr, ptr noalias %zero.addr, ptr %0) #2 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %gep_3 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 2
  %loadgep_4 = load ptr, ptr %gep_3, align 8
  %gep_5 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 3
  %loadgep_6 = load ptr, ptr %gep_5, align 8
  %gep_7 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 4
  %loadgep_8 = load ptr, ptr %gep_7, align 8
  %1 = tail call i32 @omp_get_thread_num()
  %2 = tail call i32 @omp_get_num_threads()
  %3 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %4 = sdiv i32 %3, %2
  %5 = mul i32 %4, %1
  %6 = add i32 %5, 1
  %7 = add i32 %2, -1
  %8 = icmp eq i32 %1, %7
  %9 = add i32 %6, %4
  %spec.select = select i1 %8, i32 %3, i32 %9
  %.unpack = load ptr, ptr %loadgep_2, align 8, !tbaa !8
  %.elt14 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  %.unpack15 = load i64, ptr %.elt14, align 8, !tbaa !8
  %.elt16 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  %.unpack17 = load i32, ptr %.elt16, align 8, !tbaa !8
  %.elt18 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  %.unpack19 = load i8, ptr %.elt18, align 4, !tbaa !8
  %.elt20 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  %.unpack21 = load i8, ptr %.elt20, align 1, !tbaa !8
  %.elt22 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  %.unpack23 = load i8, ptr %.elt22, align 2, !tbaa !8
  %.elt24 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  %.unpack25 = load i8, ptr %.elt24, align 1, !tbaa !8
  %.elt26 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  %.unpack27.unpack.unpack = load i64, ptr %.elt26, align 8, !tbaa !8
  %.unpack27.unpack.elt29 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  %.unpack27.unpack.unpack30 = load i64, ptr %.unpack27.unpack.elt29, align 8, !tbaa !8
  %.unpack27.unpack.elt31 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  %.unpack27.unpack.unpack32 = load i64, ptr %.unpack27.unpack.elt31, align 8, !tbaa !8
  store ptr %.unpack, ptr %loadgep_4, align 8, !tbaa !8
  %loadgep_4.repack34 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 1
  store i64 %.unpack15, ptr %loadgep_4.repack34, align 8, !tbaa !8
  %loadgep_4.repack36 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 2
  store i32 %.unpack17, ptr %loadgep_4.repack36, align 8, !tbaa !8
  %loadgep_4.repack38 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 3
  store i8 %.unpack19, ptr %loadgep_4.repack38, align 4, !tbaa !8
  %loadgep_4.repack40 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 4
  store i8 %.unpack21, ptr %loadgep_4.repack40, align 1, !tbaa !8
  %loadgep_4.repack42 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 5
  store i8 %.unpack23, ptr %loadgep_4.repack42, align 2, !tbaa !8
  %loadgep_4.repack44 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 6
  store i8 %.unpack25, ptr %loadgep_4.repack44, align 1, !tbaa !8
  %loadgep_4.repack46 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7
  store i64 %.unpack27.unpack.unpack, ptr %loadgep_4.repack46, align 8, !tbaa !8
  %loadgep_4.repack46.repack48 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack27.unpack.unpack30, ptr %loadgep_4.repack46.repack48, align 8, !tbaa !8
  %loadgep_4.repack46.repack50 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 2
  store i64 %.unpack27.unpack.unpack32, ptr %loadgep_4.repack46.repack50, align 8, !tbaa !8
  %10 = icmp eq i64 %.unpack27.unpack.unpack30, 0
  %11 = select i1 %10, i64 1, i64 %.unpack27.unpack.unpack
  store ptr %.unpack, ptr %loadgep_6, align 8, !tbaa !8
  %loadgep_6.repack52 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 1
  store i64 8, ptr %loadgep_6.repack52, align 8, !tbaa !8
  %loadgep_6.repack54 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 2
  store i32 20180515, ptr %loadgep_6.repack54, align 8, !tbaa !8
  %loadgep_6.repack56 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 3
  store i8 1, ptr %loadgep_6.repack56, align 4, !tbaa !8
  %loadgep_6.repack58 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 4
  store i8 28, ptr %loadgep_6.repack58, align 1, !tbaa !8
  %loadgep_6.repack60 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 5
  store i8 0, ptr %loadgep_6.repack60, align 2, !tbaa !8
  %loadgep_6.repack62 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 6
  store i8 0, ptr %loadgep_6.repack62, align 1, !tbaa !8
  %loadgep_6.repack64 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7
  store i64 %11, ptr %loadgep_6.repack64, align 8, !tbaa !8
  %loadgep_6.repack64.repack66 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack27.unpack.unpack30, ptr %loadgep_6.repack64.repack66, align 8, !tbaa !8
  %loadgep_6.repack64.repack68 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7, i64 0, i64 2
  store i64 8, ptr %loadgep_6.repack64.repack68, align 8, !tbaa !8
  %12 = load ptr, ptr %loadgep_8, align 8, !tbaa !4
  %13 = getelementptr { ptr, ptr }, ptr %loadgep_8, i64 0, i32 1
  %14 = load ptr, ptr %13, align 8, !tbaa !4
  %15 = sext i32 %6 to i64
  %16 = sext i32 %spec.select to i64
  %reass.sub9.i = sub nsw i64 %16, %15
  %17 = icmp sgt i64 %reass.sub9.i, -1
  br i1 %17, label %.lr.ph8.preheader.i, label %_QFPloop.exit

.lr.ph8.preheader.i:                              ; preds = %omp.par.entry
  %18 = add nuw nsw i64 %reass.sub9.i, 1
  br label %.lr.ph8.i

.lr.ph8.i:                                        ; preds = %.lr.ph8.i, %.lr.ph8.preheader.i
  %19 = phi i64 [ %29, %.lr.ph8.i ], [ %18, %.lr.ph8.preheader.i ]
  %20 = phi i32 [ %28, %.lr.ph8.i ], [ %6, %.lr.ph8.preheader.i ]
  %21 = load i32, ptr %12, align 4, !tbaa !4
  %22 = sitofp i32 %21 to float
  %23 = fdiv contract float 1.000000e+00, %22
  %24 = fpext float %23 to double
  %25 = sext i32 %20 to i64
  %26 = add nsw i64 %25, -1
  %27 = getelementptr double, ptr %.unpack, i64 %26
  store double %24, ptr %27, align 8, !tbaa !4
  store double %24, ptr %14, align 8, !tbaa !4
  %28 = add i32 %20, 1
  %29 = add nsw i64 %19, -1
  %30 = icmp ugt i64 %19, 1
  br i1 %30, label %.lr.ph8.i, label %_QFPloop.exit

_QFPloop.exit:                                    ; preds = %.lr.ph8.i, %omp.par.entry
  ret void
}
*** IR Dump After DSEPass on _QFPomp_subroutine..omp_par ***
; Function Attrs: norecurse nounwind
define internal void @_QFPomp_subroutine..omp_par(ptr noalias %tid.addr, ptr noalias %zero.addr, ptr %0) #2 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %gep_3 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 2
  %loadgep_4 = load ptr, ptr %gep_3, align 8
  %gep_5 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 3
  %loadgep_6 = load ptr, ptr %gep_5, align 8
  %gep_7 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 4
  %loadgep_8 = load ptr, ptr %gep_7, align 8
  %1 = tail call i32 @omp_get_thread_num()
  %2 = tail call i32 @omp_get_num_threads()
  %3 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %4 = sdiv i32 %3, %2
  %5 = mul i32 %4, %1
  %6 = add i32 %5, 1
  %7 = add i32 %2, -1
  %8 = icmp eq i32 %1, %7
  %9 = add i32 %6, %4
  %spec.select = select i1 %8, i32 %3, i32 %9
  %.unpack = load ptr, ptr %loadgep_2, align 8, !tbaa !8
  %.elt14 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  %.unpack15 = load i64, ptr %.elt14, align 8, !tbaa !8
  %.elt16 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  %.unpack17 = load i32, ptr %.elt16, align 8, !tbaa !8
  %.elt18 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  %.unpack19 = load i8, ptr %.elt18, align 4, !tbaa !8
  %.elt20 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  %.unpack21 = load i8, ptr %.elt20, align 1, !tbaa !8
  %.elt22 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  %.unpack23 = load i8, ptr %.elt22, align 2, !tbaa !8
  %.elt24 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  %.unpack25 = load i8, ptr %.elt24, align 1, !tbaa !8
  %.elt26 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  %.unpack27.unpack.unpack = load i64, ptr %.elt26, align 8, !tbaa !8
  %.unpack27.unpack.elt29 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  %.unpack27.unpack.unpack30 = load i64, ptr %.unpack27.unpack.elt29, align 8, !tbaa !8
  %.unpack27.unpack.elt31 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  %.unpack27.unpack.unpack32 = load i64, ptr %.unpack27.unpack.elt31, align 8, !tbaa !8
  store ptr %.unpack, ptr %loadgep_4, align 8, !tbaa !8
  %loadgep_4.repack34 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 1
  store i64 %.unpack15, ptr %loadgep_4.repack34, align 8, !tbaa !8
  %loadgep_4.repack36 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 2
  store i32 %.unpack17, ptr %loadgep_4.repack36, align 8, !tbaa !8
  %loadgep_4.repack38 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 3
  store i8 %.unpack19, ptr %loadgep_4.repack38, align 4, !tbaa !8
  %loadgep_4.repack40 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 4
  store i8 %.unpack21, ptr %loadgep_4.repack40, align 1, !tbaa !8
  %loadgep_4.repack42 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 5
  store i8 %.unpack23, ptr %loadgep_4.repack42, align 2, !tbaa !8
  %loadgep_4.repack44 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 6
  store i8 %.unpack25, ptr %loadgep_4.repack44, align 1, !tbaa !8
  %loadgep_4.repack46 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7
  store i64 %.unpack27.unpack.unpack, ptr %loadgep_4.repack46, align 8, !tbaa !8
  %loadgep_4.repack46.repack48 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack27.unpack.unpack30, ptr %loadgep_4.repack46.repack48, align 8, !tbaa !8
  %loadgep_4.repack46.repack50 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 2
  store i64 %.unpack27.unpack.unpack32, ptr %loadgep_4.repack46.repack50, align 8, !tbaa !8
  %10 = icmp eq i64 %.unpack27.unpack.unpack30, 0
  %11 = select i1 %10, i64 1, i64 %.unpack27.unpack.unpack
  store ptr %.unpack, ptr %loadgep_6, align 8, !tbaa !8
  %loadgep_6.repack52 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 1
  store i64 8, ptr %loadgep_6.repack52, align 8, !tbaa !8
  %loadgep_6.repack54 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 2
  store i32 20180515, ptr %loadgep_6.repack54, align 8, !tbaa !8
  %loadgep_6.repack56 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 3
  store i8 1, ptr %loadgep_6.repack56, align 4, !tbaa !8
  %loadgep_6.repack58 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 4
  store i8 28, ptr %loadgep_6.repack58, align 1, !tbaa !8
  %loadgep_6.repack60 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 5
  store i8 0, ptr %loadgep_6.repack60, align 2, !tbaa !8
  %loadgep_6.repack62 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 6
  store i8 0, ptr %loadgep_6.repack62, align 1, !tbaa !8
  %loadgep_6.repack64 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7
  store i64 %11, ptr %loadgep_6.repack64, align 8, !tbaa !8
  %loadgep_6.repack64.repack66 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack27.unpack.unpack30, ptr %loadgep_6.repack64.repack66, align 8, !tbaa !8
  %loadgep_6.repack64.repack68 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7, i64 0, i64 2
  store i64 8, ptr %loadgep_6.repack64.repack68, align 8, !tbaa !8
  %12 = load ptr, ptr %loadgep_8, align 8, !tbaa !4
  %13 = getelementptr { ptr, ptr }, ptr %loadgep_8, i64 0, i32 1
  %14 = load ptr, ptr %13, align 8, !tbaa !4
  %15 = sext i32 %6 to i64
  %16 = sext i32 %spec.select to i64
  %reass.sub9.i = sub nsw i64 %16, %15
  %17 = icmp sgt i64 %reass.sub9.i, -1
  br i1 %17, label %.lr.ph8.preheader.i, label %_QFPloop.exit

.lr.ph8.preheader.i:                              ; preds = %omp.par.entry
  %18 = add nuw nsw i64 %reass.sub9.i, 1
  br label %.lr.ph8.i

.lr.ph8.i:                                        ; preds = %.lr.ph8.i, %.lr.ph8.preheader.i
  %19 = phi i64 [ %29, %.lr.ph8.i ], [ %18, %.lr.ph8.preheader.i ]
  %20 = phi i32 [ %28, %.lr.ph8.i ], [ %6, %.lr.ph8.preheader.i ]
  %21 = load i32, ptr %12, align 4, !tbaa !4
  %22 = sitofp i32 %21 to float
  %23 = fdiv contract float 1.000000e+00, %22
  %24 = fpext float %23 to double
  %25 = sext i32 %20 to i64
  %26 = add nsw i64 %25, -1
  %27 = getelementptr double, ptr %.unpack, i64 %26
  store double %24, ptr %27, align 8, !tbaa !4
  store double %24, ptr %14, align 8, !tbaa !4
  %28 = add i32 %20, 1
  %29 = add nsw i64 %19, -1
  %30 = icmp ugt i64 %19, 1
  br i1 %30, label %.lr.ph8.i, label %_QFPloop.exit

_QFPloop.exit:                                    ; preds = %.lr.ph8.i, %omp.par.entry
  ret void
}
*** IR Dump After MoveAutoInitPass on _QFPomp_subroutine..omp_par ***
; Function Attrs: norecurse nounwind
define internal void @_QFPomp_subroutine..omp_par(ptr noalias %tid.addr, ptr noalias %zero.addr, ptr %0) #2 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %gep_3 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 2
  %loadgep_4 = load ptr, ptr %gep_3, align 8
  %gep_5 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 3
  %loadgep_6 = load ptr, ptr %gep_5, align 8
  %gep_7 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 4
  %loadgep_8 = load ptr, ptr %gep_7, align 8
  %1 = tail call i32 @omp_get_thread_num()
  %2 = tail call i32 @omp_get_num_threads()
  %3 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %4 = sdiv i32 %3, %2
  %5 = mul i32 %4, %1
  %6 = add i32 %5, 1
  %7 = add i32 %2, -1
  %8 = icmp eq i32 %1, %7
  %9 = add i32 %6, %4
  %spec.select = select i1 %8, i32 %3, i32 %9
  %.unpack = load ptr, ptr %loadgep_2, align 8, !tbaa !8
  %.elt14 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  %.unpack15 = load i64, ptr %.elt14, align 8, !tbaa !8
  %.elt16 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  %.unpack17 = load i32, ptr %.elt16, align 8, !tbaa !8
  %.elt18 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  %.unpack19 = load i8, ptr %.elt18, align 4, !tbaa !8
  %.elt20 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  %.unpack21 = load i8, ptr %.elt20, align 1, !tbaa !8
  %.elt22 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  %.unpack23 = load i8, ptr %.elt22, align 2, !tbaa !8
  %.elt24 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  %.unpack25 = load i8, ptr %.elt24, align 1, !tbaa !8
  %.elt26 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  %.unpack27.unpack.unpack = load i64, ptr %.elt26, align 8, !tbaa !8
  %.unpack27.unpack.elt29 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  %.unpack27.unpack.unpack30 = load i64, ptr %.unpack27.unpack.elt29, align 8, !tbaa !8
  %.unpack27.unpack.elt31 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  %.unpack27.unpack.unpack32 = load i64, ptr %.unpack27.unpack.elt31, align 8, !tbaa !8
  store ptr %.unpack, ptr %loadgep_4, align 8, !tbaa !8
  %loadgep_4.repack34 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 1
  store i64 %.unpack15, ptr %loadgep_4.repack34, align 8, !tbaa !8
  %loadgep_4.repack36 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 2
  store i32 %.unpack17, ptr %loadgep_4.repack36, align 8, !tbaa !8
  %loadgep_4.repack38 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 3
  store i8 %.unpack19, ptr %loadgep_4.repack38, align 4, !tbaa !8
  %loadgep_4.repack40 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 4
  store i8 %.unpack21, ptr %loadgep_4.repack40, align 1, !tbaa !8
  %loadgep_4.repack42 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 5
  store i8 %.unpack23, ptr %loadgep_4.repack42, align 2, !tbaa !8
  %loadgep_4.repack44 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 6
  store i8 %.unpack25, ptr %loadgep_4.repack44, align 1, !tbaa !8
  %loadgep_4.repack46 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7
  store i64 %.unpack27.unpack.unpack, ptr %loadgep_4.repack46, align 8, !tbaa !8
  %loadgep_4.repack46.repack48 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack27.unpack.unpack30, ptr %loadgep_4.repack46.repack48, align 8, !tbaa !8
  %loadgep_4.repack46.repack50 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 2
  store i64 %.unpack27.unpack.unpack32, ptr %loadgep_4.repack46.repack50, align 8, !tbaa !8
  %10 = icmp eq i64 %.unpack27.unpack.unpack30, 0
  %11 = select i1 %10, i64 1, i64 %.unpack27.unpack.unpack
  store ptr %.unpack, ptr %loadgep_6, align 8, !tbaa !8
  %loadgep_6.repack52 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 1
  store i64 8, ptr %loadgep_6.repack52, align 8, !tbaa !8
  %loadgep_6.repack54 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 2
  store i32 20180515, ptr %loadgep_6.repack54, align 8, !tbaa !8
  %loadgep_6.repack56 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 3
  store i8 1, ptr %loadgep_6.repack56, align 4, !tbaa !8
  %loadgep_6.repack58 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 4
  store i8 28, ptr %loadgep_6.repack58, align 1, !tbaa !8
  %loadgep_6.repack60 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 5
  store i8 0, ptr %loadgep_6.repack60, align 2, !tbaa !8
  %loadgep_6.repack62 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 6
  store i8 0, ptr %loadgep_6.repack62, align 1, !tbaa !8
  %loadgep_6.repack64 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7
  store i64 %11, ptr %loadgep_6.repack64, align 8, !tbaa !8
  %loadgep_6.repack64.repack66 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack27.unpack.unpack30, ptr %loadgep_6.repack64.repack66, align 8, !tbaa !8
  %loadgep_6.repack64.repack68 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7, i64 0, i64 2
  store i64 8, ptr %loadgep_6.repack64.repack68, align 8, !tbaa !8
  %12 = load ptr, ptr %loadgep_8, align 8, !tbaa !4
  %13 = getelementptr { ptr, ptr }, ptr %loadgep_8, i64 0, i32 1
  %14 = load ptr, ptr %13, align 8, !tbaa !4
  %15 = sext i32 %6 to i64
  %16 = sext i32 %spec.select to i64
  %reass.sub9.i = sub nsw i64 %16, %15
  %17 = icmp sgt i64 %reass.sub9.i, -1
  br i1 %17, label %.lr.ph8.preheader.i, label %_QFPloop.exit

.lr.ph8.preheader.i:                              ; preds = %omp.par.entry
  %18 = add nuw nsw i64 %reass.sub9.i, 1
  br label %.lr.ph8.i

.lr.ph8.i:                                        ; preds = %.lr.ph8.i, %.lr.ph8.preheader.i
  %19 = phi i64 [ %29, %.lr.ph8.i ], [ %18, %.lr.ph8.preheader.i ]
  %20 = phi i32 [ %28, %.lr.ph8.i ], [ %6, %.lr.ph8.preheader.i ]
  %21 = load i32, ptr %12, align 4, !tbaa !4
  %22 = sitofp i32 %21 to float
  %23 = fdiv contract float 1.000000e+00, %22
  %24 = fpext float %23 to double
  %25 = sext i32 %20 to i64
  %26 = add nsw i64 %25, -1
  %27 = getelementptr double, ptr %.unpack, i64 %26
  store double %24, ptr %27, align 8, !tbaa !4
  store double %24, ptr %14, align 8, !tbaa !4
  %28 = add i32 %20, 1
  %29 = add nsw i64 %19, -1
  %30 = icmp ugt i64 %19, 1
  br i1 %30, label %.lr.ph8.i, label %_QFPloop.exit

_QFPloop.exit:                                    ; preds = %.lr.ph8.i, %omp.par.entry
  ret void
}
*** IR Dump After LoopSimplifyPass on _QFPomp_subroutine..omp_par ***
; Function Attrs: norecurse nounwind
define internal void @_QFPomp_subroutine..omp_par(ptr noalias %tid.addr, ptr noalias %zero.addr, ptr %0) #2 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %gep_3 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 2
  %loadgep_4 = load ptr, ptr %gep_3, align 8
  %gep_5 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 3
  %loadgep_6 = load ptr, ptr %gep_5, align 8
  %gep_7 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 4
  %loadgep_8 = load ptr, ptr %gep_7, align 8
  %1 = tail call i32 @omp_get_thread_num()
  %2 = tail call i32 @omp_get_num_threads()
  %3 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %4 = sdiv i32 %3, %2
  %5 = mul i32 %4, %1
  %6 = add i32 %5, 1
  %7 = add i32 %2, -1
  %8 = icmp eq i32 %1, %7
  %9 = add i32 %6, %4
  %spec.select = select i1 %8, i32 %3, i32 %9
  %.unpack = load ptr, ptr %loadgep_2, align 8, !tbaa !8
  %.elt14 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  %.unpack15 = load i64, ptr %.elt14, align 8, !tbaa !8
  %.elt16 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  %.unpack17 = load i32, ptr %.elt16, align 8, !tbaa !8
  %.elt18 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  %.unpack19 = load i8, ptr %.elt18, align 4, !tbaa !8
  %.elt20 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  %.unpack21 = load i8, ptr %.elt20, align 1, !tbaa !8
  %.elt22 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  %.unpack23 = load i8, ptr %.elt22, align 2, !tbaa !8
  %.elt24 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  %.unpack25 = load i8, ptr %.elt24, align 1, !tbaa !8
  %.elt26 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  %.unpack27.unpack.unpack = load i64, ptr %.elt26, align 8, !tbaa !8
  %.unpack27.unpack.elt29 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  %.unpack27.unpack.unpack30 = load i64, ptr %.unpack27.unpack.elt29, align 8, !tbaa !8
  %.unpack27.unpack.elt31 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  %.unpack27.unpack.unpack32 = load i64, ptr %.unpack27.unpack.elt31, align 8, !tbaa !8
  store ptr %.unpack, ptr %loadgep_4, align 8, !tbaa !8
  %loadgep_4.repack34 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 1
  store i64 %.unpack15, ptr %loadgep_4.repack34, align 8, !tbaa !8
  %loadgep_4.repack36 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 2
  store i32 %.unpack17, ptr %loadgep_4.repack36, align 8, !tbaa !8
  %loadgep_4.repack38 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 3
  store i8 %.unpack19, ptr %loadgep_4.repack38, align 4, !tbaa !8
  %loadgep_4.repack40 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 4
  store i8 %.unpack21, ptr %loadgep_4.repack40, align 1, !tbaa !8
  %loadgep_4.repack42 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 5
  store i8 %.unpack23, ptr %loadgep_4.repack42, align 2, !tbaa !8
  %loadgep_4.repack44 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 6
  store i8 %.unpack25, ptr %loadgep_4.repack44, align 1, !tbaa !8
  %loadgep_4.repack46 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7
  store i64 %.unpack27.unpack.unpack, ptr %loadgep_4.repack46, align 8, !tbaa !8
  %loadgep_4.repack46.repack48 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack27.unpack.unpack30, ptr %loadgep_4.repack46.repack48, align 8, !tbaa !8
  %loadgep_4.repack46.repack50 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 2
  store i64 %.unpack27.unpack.unpack32, ptr %loadgep_4.repack46.repack50, align 8, !tbaa !8
  %10 = icmp eq i64 %.unpack27.unpack.unpack30, 0
  %11 = select i1 %10, i64 1, i64 %.unpack27.unpack.unpack
  store ptr %.unpack, ptr %loadgep_6, align 8, !tbaa !8
  %loadgep_6.repack52 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 1
  store i64 8, ptr %loadgep_6.repack52, align 8, !tbaa !8
  %loadgep_6.repack54 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 2
  store i32 20180515, ptr %loadgep_6.repack54, align 8, !tbaa !8
  %loadgep_6.repack56 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 3
  store i8 1, ptr %loadgep_6.repack56, align 4, !tbaa !8
  %loadgep_6.repack58 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 4
  store i8 28, ptr %loadgep_6.repack58, align 1, !tbaa !8
  %loadgep_6.repack60 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 5
  store i8 0, ptr %loadgep_6.repack60, align 2, !tbaa !8
  %loadgep_6.repack62 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 6
  store i8 0, ptr %loadgep_6.repack62, align 1, !tbaa !8
  %loadgep_6.repack64 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7
  store i64 %11, ptr %loadgep_6.repack64, align 8, !tbaa !8
  %loadgep_6.repack64.repack66 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack27.unpack.unpack30, ptr %loadgep_6.repack64.repack66, align 8, !tbaa !8
  %loadgep_6.repack64.repack68 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7, i64 0, i64 2
  store i64 8, ptr %loadgep_6.repack64.repack68, align 8, !tbaa !8
  %12 = load ptr, ptr %loadgep_8, align 8, !tbaa !4
  %13 = getelementptr { ptr, ptr }, ptr %loadgep_8, i64 0, i32 1
  %14 = load ptr, ptr %13, align 8, !tbaa !4
  %15 = sext i32 %6 to i64
  %16 = sext i32 %spec.select to i64
  %reass.sub9.i = sub nsw i64 %16, %15
  %17 = icmp sgt i64 %reass.sub9.i, -1
  br i1 %17, label %.lr.ph8.preheader.i, label %_QFPloop.exit

.lr.ph8.preheader.i:                              ; preds = %omp.par.entry
  %18 = add nuw nsw i64 %reass.sub9.i, 1
  br label %.lr.ph8.i

.lr.ph8.i:                                        ; preds = %.lr.ph8.i, %.lr.ph8.preheader.i
  %19 = phi i64 [ %29, %.lr.ph8.i ], [ %18, %.lr.ph8.preheader.i ]
  %20 = phi i32 [ %28, %.lr.ph8.i ], [ %6, %.lr.ph8.preheader.i ]
  %21 = load i32, ptr %12, align 4, !tbaa !4
  %22 = sitofp i32 %21 to float
  %23 = fdiv contract float 1.000000e+00, %22
  %24 = fpext float %23 to double
  %25 = sext i32 %20 to i64
  %26 = add nsw i64 %25, -1
  %27 = getelementptr double, ptr %.unpack, i64 %26
  store double %24, ptr %27, align 8, !tbaa !4
  store double %24, ptr %14, align 8, !tbaa !4
  %28 = add i32 %20, 1
  %29 = add nsw i64 %19, -1
  %30 = icmp ugt i64 %19, 1
  br i1 %30, label %.lr.ph8.i, label %_QFPloop.exit.loopexit

_QFPloop.exit.loopexit:                           ; preds = %.lr.ph8.i
  br label %_QFPloop.exit

_QFPloop.exit:                                    ; preds = %_QFPloop.exit.loopexit, %omp.par.entry
  ret void
}
*** IR Dump After LCSSAPass on _QFPomp_subroutine..omp_par ***
; Function Attrs: norecurse nounwind
define internal void @_QFPomp_subroutine..omp_par(ptr noalias %tid.addr, ptr noalias %zero.addr, ptr %0) #2 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %gep_3 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 2
  %loadgep_4 = load ptr, ptr %gep_3, align 8
  %gep_5 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 3
  %loadgep_6 = load ptr, ptr %gep_5, align 8
  %gep_7 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 4
  %loadgep_8 = load ptr, ptr %gep_7, align 8
  %1 = tail call i32 @omp_get_thread_num()
  %2 = tail call i32 @omp_get_num_threads()
  %3 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %4 = sdiv i32 %3, %2
  %5 = mul i32 %4, %1
  %6 = add i32 %5, 1
  %7 = add i32 %2, -1
  %8 = icmp eq i32 %1, %7
  %9 = add i32 %6, %4
  %spec.select = select i1 %8, i32 %3, i32 %9
  %.unpack = load ptr, ptr %loadgep_2, align 8, !tbaa !8
  %.elt14 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  %.unpack15 = load i64, ptr %.elt14, align 8, !tbaa !8
  %.elt16 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  %.unpack17 = load i32, ptr %.elt16, align 8, !tbaa !8
  %.elt18 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  %.unpack19 = load i8, ptr %.elt18, align 4, !tbaa !8
  %.elt20 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  %.unpack21 = load i8, ptr %.elt20, align 1, !tbaa !8
  %.elt22 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  %.unpack23 = load i8, ptr %.elt22, align 2, !tbaa !8
  %.elt24 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  %.unpack25 = load i8, ptr %.elt24, align 1, !tbaa !8
  %.elt26 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  %.unpack27.unpack.unpack = load i64, ptr %.elt26, align 8, !tbaa !8
  %.unpack27.unpack.elt29 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  %.unpack27.unpack.unpack30 = load i64, ptr %.unpack27.unpack.elt29, align 8, !tbaa !8
  %.unpack27.unpack.elt31 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  %.unpack27.unpack.unpack32 = load i64, ptr %.unpack27.unpack.elt31, align 8, !tbaa !8
  store ptr %.unpack, ptr %loadgep_4, align 8, !tbaa !8
  %loadgep_4.repack34 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 1
  store i64 %.unpack15, ptr %loadgep_4.repack34, align 8, !tbaa !8
  %loadgep_4.repack36 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 2
  store i32 %.unpack17, ptr %loadgep_4.repack36, align 8, !tbaa !8
  %loadgep_4.repack38 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 3
  store i8 %.unpack19, ptr %loadgep_4.repack38, align 4, !tbaa !8
  %loadgep_4.repack40 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 4
  store i8 %.unpack21, ptr %loadgep_4.repack40, align 1, !tbaa !8
  %loadgep_4.repack42 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 5
  store i8 %.unpack23, ptr %loadgep_4.repack42, align 2, !tbaa !8
  %loadgep_4.repack44 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 6
  store i8 %.unpack25, ptr %loadgep_4.repack44, align 1, !tbaa !8
  %loadgep_4.repack46 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7
  store i64 %.unpack27.unpack.unpack, ptr %loadgep_4.repack46, align 8, !tbaa !8
  %loadgep_4.repack46.repack48 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack27.unpack.unpack30, ptr %loadgep_4.repack46.repack48, align 8, !tbaa !8
  %loadgep_4.repack46.repack50 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 2
  store i64 %.unpack27.unpack.unpack32, ptr %loadgep_4.repack46.repack50, align 8, !tbaa !8
  %10 = icmp eq i64 %.unpack27.unpack.unpack30, 0
  %11 = select i1 %10, i64 1, i64 %.unpack27.unpack.unpack
  store ptr %.unpack, ptr %loadgep_6, align 8, !tbaa !8
  %loadgep_6.repack52 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 1
  store i64 8, ptr %loadgep_6.repack52, align 8, !tbaa !8
  %loadgep_6.repack54 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 2
  store i32 20180515, ptr %loadgep_6.repack54, align 8, !tbaa !8
  %loadgep_6.repack56 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 3
  store i8 1, ptr %loadgep_6.repack56, align 4, !tbaa !8
  %loadgep_6.repack58 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 4
  store i8 28, ptr %loadgep_6.repack58, align 1, !tbaa !8
  %loadgep_6.repack60 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 5
  store i8 0, ptr %loadgep_6.repack60, align 2, !tbaa !8
  %loadgep_6.repack62 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 6
  store i8 0, ptr %loadgep_6.repack62, align 1, !tbaa !8
  %loadgep_6.repack64 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7
  store i64 %11, ptr %loadgep_6.repack64, align 8, !tbaa !8
  %loadgep_6.repack64.repack66 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack27.unpack.unpack30, ptr %loadgep_6.repack64.repack66, align 8, !tbaa !8
  %loadgep_6.repack64.repack68 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7, i64 0, i64 2
  store i64 8, ptr %loadgep_6.repack64.repack68, align 8, !tbaa !8
  %12 = load ptr, ptr %loadgep_8, align 8, !tbaa !4
  %13 = getelementptr { ptr, ptr }, ptr %loadgep_8, i64 0, i32 1
  %14 = load ptr, ptr %13, align 8, !tbaa !4
  %15 = sext i32 %6 to i64
  %16 = sext i32 %spec.select to i64
  %reass.sub9.i = sub nsw i64 %16, %15
  %17 = icmp sgt i64 %reass.sub9.i, -1
  br i1 %17, label %.lr.ph8.preheader.i, label %_QFPloop.exit

.lr.ph8.preheader.i:                              ; preds = %omp.par.entry
  %18 = add nuw nsw i64 %reass.sub9.i, 1
  br label %.lr.ph8.i

.lr.ph8.i:                                        ; preds = %.lr.ph8.i, %.lr.ph8.preheader.i
  %19 = phi i64 [ %29, %.lr.ph8.i ], [ %18, %.lr.ph8.preheader.i ]
  %20 = phi i32 [ %28, %.lr.ph8.i ], [ %6, %.lr.ph8.preheader.i ]
  %21 = load i32, ptr %12, align 4, !tbaa !4
  %22 = sitofp i32 %21 to float
  %23 = fdiv contract float 1.000000e+00, %22
  %24 = fpext float %23 to double
  %25 = sext i32 %20 to i64
  %26 = add nsw i64 %25, -1
  %27 = getelementptr double, ptr %.unpack, i64 %26
  store double %24, ptr %27, align 8, !tbaa !4
  store double %24, ptr %14, align 8, !tbaa !4
  %28 = add i32 %20, 1
  %29 = add nsw i64 %19, -1
  %30 = icmp ugt i64 %19, 1
  br i1 %30, label %.lr.ph8.i, label %_QFPloop.exit.loopexit

_QFPloop.exit.loopexit:                           ; preds = %.lr.ph8.i
  br label %_QFPloop.exit

_QFPloop.exit:                                    ; preds = %_QFPloop.exit.loopexit, %omp.par.entry
  ret void
}
*** IR Dump After LICMPass on .lr.ph8.i ***

; Preheader:
.lr.ph8.preheader.i:                              ; preds = %omp.par.entry
  %18 = add nuw nsw i64 %reass.sub9.i, 1
  br label %.lr.ph8.i

; Loop:
.lr.ph8.i:                                        ; preds = %.lr.ph8.i, %.lr.ph8.preheader.i
  %19 = phi i64 [ %29, %.lr.ph8.i ], [ %18, %.lr.ph8.preheader.i ]
  %20 = phi i32 [ %28, %.lr.ph8.i ], [ %6, %.lr.ph8.preheader.i ]
  %21 = load i32, ptr %12, align 4, !tbaa !4
  %22 = sitofp i32 %21 to float
  %23 = fdiv contract float 1.000000e+00, %22
  %24 = fpext float %23 to double
  %25 = sext i32 %20 to i64
  %26 = add nsw i64 %25, -1
  %27 = getelementptr double, ptr %.unpack, i64 %26
  store double %24, ptr %27, align 8, !tbaa !4
  store double %24, ptr %14, align 8, !tbaa !4
  %28 = add i32 %20, 1
  %29 = add nsw i64 %19, -1
  %30 = icmp ugt i64 %19, 1
  br i1 %30, label %.lr.ph8.i, label %_QFPloop.exit.loopexit

; Exit blocks
_QFPloop.exit.loopexit:                           ; preds = %.lr.ph8.i
  br label %_QFPloop.exit
*** IR Dump After CoroElidePass on _QFPomp_subroutine..omp_par ***
; Function Attrs: norecurse nounwind
define internal void @_QFPomp_subroutine..omp_par(ptr noalias %tid.addr, ptr noalias %zero.addr, ptr %0) #2 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %gep_3 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 2
  %loadgep_4 = load ptr, ptr %gep_3, align 8
  %gep_5 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 3
  %loadgep_6 = load ptr, ptr %gep_5, align 8
  %gep_7 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 4
  %loadgep_8 = load ptr, ptr %gep_7, align 8
  %1 = tail call i32 @omp_get_thread_num()
  %2 = tail call i32 @omp_get_num_threads()
  %3 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %4 = sdiv i32 %3, %2
  %5 = mul i32 %4, %1
  %6 = add i32 %5, 1
  %7 = add i32 %2, -1
  %8 = icmp eq i32 %1, %7
  %9 = add i32 %6, %4
  %spec.select = select i1 %8, i32 %3, i32 %9
  %.unpack = load ptr, ptr %loadgep_2, align 8, !tbaa !8
  %.elt14 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  %.unpack15 = load i64, ptr %.elt14, align 8, !tbaa !8
  %.elt16 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  %.unpack17 = load i32, ptr %.elt16, align 8, !tbaa !8
  %.elt18 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  %.unpack19 = load i8, ptr %.elt18, align 4, !tbaa !8
  %.elt20 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  %.unpack21 = load i8, ptr %.elt20, align 1, !tbaa !8
  %.elt22 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  %.unpack23 = load i8, ptr %.elt22, align 2, !tbaa !8
  %.elt24 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  %.unpack25 = load i8, ptr %.elt24, align 1, !tbaa !8
  %.elt26 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  %.unpack27.unpack.unpack = load i64, ptr %.elt26, align 8, !tbaa !8
  %.unpack27.unpack.elt29 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  %.unpack27.unpack.unpack30 = load i64, ptr %.unpack27.unpack.elt29, align 8, !tbaa !8
  %.unpack27.unpack.elt31 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  %.unpack27.unpack.unpack32 = load i64, ptr %.unpack27.unpack.elt31, align 8, !tbaa !8
  store ptr %.unpack, ptr %loadgep_4, align 8, !tbaa !8
  %loadgep_4.repack34 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 1
  store i64 %.unpack15, ptr %loadgep_4.repack34, align 8, !tbaa !8
  %loadgep_4.repack36 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 2
  store i32 %.unpack17, ptr %loadgep_4.repack36, align 8, !tbaa !8
  %loadgep_4.repack38 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 3
  store i8 %.unpack19, ptr %loadgep_4.repack38, align 4, !tbaa !8
  %loadgep_4.repack40 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 4
  store i8 %.unpack21, ptr %loadgep_4.repack40, align 1, !tbaa !8
  %loadgep_4.repack42 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 5
  store i8 %.unpack23, ptr %loadgep_4.repack42, align 2, !tbaa !8
  %loadgep_4.repack44 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 6
  store i8 %.unpack25, ptr %loadgep_4.repack44, align 1, !tbaa !8
  %loadgep_4.repack46 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7
  store i64 %.unpack27.unpack.unpack, ptr %loadgep_4.repack46, align 8, !tbaa !8
  %loadgep_4.repack46.repack48 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack27.unpack.unpack30, ptr %loadgep_4.repack46.repack48, align 8, !tbaa !8
  %loadgep_4.repack46.repack50 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 2
  store i64 %.unpack27.unpack.unpack32, ptr %loadgep_4.repack46.repack50, align 8, !tbaa !8
  %10 = icmp eq i64 %.unpack27.unpack.unpack30, 0
  %11 = select i1 %10, i64 1, i64 %.unpack27.unpack.unpack
  store ptr %.unpack, ptr %loadgep_6, align 8, !tbaa !8
  %loadgep_6.repack52 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 1
  store i64 8, ptr %loadgep_6.repack52, align 8, !tbaa !8
  %loadgep_6.repack54 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 2
  store i32 20180515, ptr %loadgep_6.repack54, align 8, !tbaa !8
  %loadgep_6.repack56 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 3
  store i8 1, ptr %loadgep_6.repack56, align 4, !tbaa !8
  %loadgep_6.repack58 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 4
  store i8 28, ptr %loadgep_6.repack58, align 1, !tbaa !8
  %loadgep_6.repack60 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 5
  store i8 0, ptr %loadgep_6.repack60, align 2, !tbaa !8
  %loadgep_6.repack62 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 6
  store i8 0, ptr %loadgep_6.repack62, align 1, !tbaa !8
  %loadgep_6.repack64 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7
  store i64 %11, ptr %loadgep_6.repack64, align 8, !tbaa !8
  %loadgep_6.repack64.repack66 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack27.unpack.unpack30, ptr %loadgep_6.repack64.repack66, align 8, !tbaa !8
  %loadgep_6.repack64.repack68 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7, i64 0, i64 2
  store i64 8, ptr %loadgep_6.repack64.repack68, align 8, !tbaa !8
  %12 = load ptr, ptr %loadgep_8, align 8, !tbaa !4
  %13 = getelementptr { ptr, ptr }, ptr %loadgep_8, i64 0, i32 1
  %14 = load ptr, ptr %13, align 8, !tbaa !4
  %15 = sext i32 %6 to i64
  %16 = sext i32 %spec.select to i64
  %reass.sub9.i = sub nsw i64 %16, %15
  %17 = icmp sgt i64 %reass.sub9.i, -1
  br i1 %17, label %.lr.ph8.preheader.i, label %_QFPloop.exit

.lr.ph8.preheader.i:                              ; preds = %omp.par.entry
  %18 = add nuw nsw i64 %reass.sub9.i, 1
  br label %.lr.ph8.i

.lr.ph8.i:                                        ; preds = %.lr.ph8.i, %.lr.ph8.preheader.i
  %19 = phi i64 [ %29, %.lr.ph8.i ], [ %18, %.lr.ph8.preheader.i ]
  %20 = phi i32 [ %28, %.lr.ph8.i ], [ %6, %.lr.ph8.preheader.i ]
  %21 = load i32, ptr %12, align 4, !tbaa !4
  %22 = sitofp i32 %21 to float
  %23 = fdiv contract float 1.000000e+00, %22
  %24 = fpext float %23 to double
  %25 = sext i32 %20 to i64
  %26 = add nsw i64 %25, -1
  %27 = getelementptr double, ptr %.unpack, i64 %26
  store double %24, ptr %27, align 8, !tbaa !4
  store double %24, ptr %14, align 8, !tbaa !4
  %28 = add i32 %20, 1
  %29 = add nsw i64 %19, -1
  %30 = icmp ugt i64 %19, 1
  br i1 %30, label %.lr.ph8.i, label %_QFPloop.exit.loopexit

_QFPloop.exit.loopexit:                           ; preds = %.lr.ph8.i
  br label %_QFPloop.exit

_QFPloop.exit:                                    ; preds = %_QFPloop.exit.loopexit, %omp.par.entry
  ret void
}
*** IR Dump After SimplifyCFGPass on _QFPomp_subroutine..omp_par ***
; Function Attrs: norecurse nounwind
define internal void @_QFPomp_subroutine..omp_par(ptr noalias %tid.addr, ptr noalias %zero.addr, ptr %0) #2 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %gep_3 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 2
  %loadgep_4 = load ptr, ptr %gep_3, align 8
  %gep_5 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 3
  %loadgep_6 = load ptr, ptr %gep_5, align 8
  %gep_7 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 4
  %loadgep_8 = load ptr, ptr %gep_7, align 8
  %1 = tail call i32 @omp_get_thread_num()
  %2 = tail call i32 @omp_get_num_threads()
  %3 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %4 = sdiv i32 %3, %2
  %5 = mul i32 %4, %1
  %6 = add i32 %5, 1
  %7 = add i32 %2, -1
  %8 = icmp eq i32 %1, %7
  %9 = add i32 %6, %4
  %spec.select = select i1 %8, i32 %3, i32 %9
  %.unpack = load ptr, ptr %loadgep_2, align 8, !tbaa !8
  %.elt14 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  %.unpack15 = load i64, ptr %.elt14, align 8, !tbaa !8
  %.elt16 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  %.unpack17 = load i32, ptr %.elt16, align 8, !tbaa !8
  %.elt18 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  %.unpack19 = load i8, ptr %.elt18, align 4, !tbaa !8
  %.elt20 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  %.unpack21 = load i8, ptr %.elt20, align 1, !tbaa !8
  %.elt22 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  %.unpack23 = load i8, ptr %.elt22, align 2, !tbaa !8
  %.elt24 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  %.unpack25 = load i8, ptr %.elt24, align 1, !tbaa !8
  %.elt26 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  %.unpack27.unpack.unpack = load i64, ptr %.elt26, align 8, !tbaa !8
  %.unpack27.unpack.elt29 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  %.unpack27.unpack.unpack30 = load i64, ptr %.unpack27.unpack.elt29, align 8, !tbaa !8
  %.unpack27.unpack.elt31 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  %.unpack27.unpack.unpack32 = load i64, ptr %.unpack27.unpack.elt31, align 8, !tbaa !8
  store ptr %.unpack, ptr %loadgep_4, align 8, !tbaa !8
  %loadgep_4.repack34 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 1
  store i64 %.unpack15, ptr %loadgep_4.repack34, align 8, !tbaa !8
  %loadgep_4.repack36 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 2
  store i32 %.unpack17, ptr %loadgep_4.repack36, align 8, !tbaa !8
  %loadgep_4.repack38 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 3
  store i8 %.unpack19, ptr %loadgep_4.repack38, align 4, !tbaa !8
  %loadgep_4.repack40 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 4
  store i8 %.unpack21, ptr %loadgep_4.repack40, align 1, !tbaa !8
  %loadgep_4.repack42 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 5
  store i8 %.unpack23, ptr %loadgep_4.repack42, align 2, !tbaa !8
  %loadgep_4.repack44 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 6
  store i8 %.unpack25, ptr %loadgep_4.repack44, align 1, !tbaa !8
  %loadgep_4.repack46 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7
  store i64 %.unpack27.unpack.unpack, ptr %loadgep_4.repack46, align 8, !tbaa !8
  %loadgep_4.repack46.repack48 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack27.unpack.unpack30, ptr %loadgep_4.repack46.repack48, align 8, !tbaa !8
  %loadgep_4.repack46.repack50 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 2
  store i64 %.unpack27.unpack.unpack32, ptr %loadgep_4.repack46.repack50, align 8, !tbaa !8
  %10 = icmp eq i64 %.unpack27.unpack.unpack30, 0
  %11 = select i1 %10, i64 1, i64 %.unpack27.unpack.unpack
  store ptr %.unpack, ptr %loadgep_6, align 8, !tbaa !8
  %loadgep_6.repack52 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 1
  store i64 8, ptr %loadgep_6.repack52, align 8, !tbaa !8
  %loadgep_6.repack54 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 2
  store i32 20180515, ptr %loadgep_6.repack54, align 8, !tbaa !8
  %loadgep_6.repack56 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 3
  store i8 1, ptr %loadgep_6.repack56, align 4, !tbaa !8
  %loadgep_6.repack58 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 4
  store i8 28, ptr %loadgep_6.repack58, align 1, !tbaa !8
  %loadgep_6.repack60 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 5
  store i8 0, ptr %loadgep_6.repack60, align 2, !tbaa !8
  %loadgep_6.repack62 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 6
  store i8 0, ptr %loadgep_6.repack62, align 1, !tbaa !8
  %loadgep_6.repack64 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7
  store i64 %11, ptr %loadgep_6.repack64, align 8, !tbaa !8
  %loadgep_6.repack64.repack66 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack27.unpack.unpack30, ptr %loadgep_6.repack64.repack66, align 8, !tbaa !8
  %loadgep_6.repack64.repack68 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7, i64 0, i64 2
  store i64 8, ptr %loadgep_6.repack64.repack68, align 8, !tbaa !8
  %12 = load ptr, ptr %loadgep_8, align 8, !tbaa !4
  %13 = getelementptr { ptr, ptr }, ptr %loadgep_8, i64 0, i32 1
  %14 = load ptr, ptr %13, align 8, !tbaa !4
  %15 = sext i32 %6 to i64
  %16 = sext i32 %spec.select to i64
  %reass.sub9.i = sub nsw i64 %16, %15
  %17 = icmp sgt i64 %reass.sub9.i, -1
  br i1 %17, label %.lr.ph8.preheader.i, label %_QFPloop.exit

.lr.ph8.preheader.i:                              ; preds = %omp.par.entry
  %18 = add nuw nsw i64 %reass.sub9.i, 1
  br label %.lr.ph8.i

.lr.ph8.i:                                        ; preds = %.lr.ph8.i, %.lr.ph8.preheader.i
  %19 = phi i64 [ %29, %.lr.ph8.i ], [ %18, %.lr.ph8.preheader.i ]
  %20 = phi i32 [ %28, %.lr.ph8.i ], [ %6, %.lr.ph8.preheader.i ]
  %21 = load i32, ptr %12, align 4, !tbaa !4
  %22 = sitofp i32 %21 to float
  %23 = fdiv contract float 1.000000e+00, %22
  %24 = fpext float %23 to double
  %25 = sext i32 %20 to i64
  %26 = add nsw i64 %25, -1
  %27 = getelementptr double, ptr %.unpack, i64 %26
  store double %24, ptr %27, align 8, !tbaa !4
  store double %24, ptr %14, align 8, !tbaa !4
  %28 = add i32 %20, 1
  %29 = add nsw i64 %19, -1
  %30 = icmp ugt i64 %19, 1
  br i1 %30, label %.lr.ph8.i, label %_QFPloop.exit

_QFPloop.exit:                                    ; preds = %.lr.ph8.i, %omp.par.entry
  ret void
}
*** IR Dump After InstCombinePass on _QFPomp_subroutine..omp_par ***
; Function Attrs: norecurse nounwind
define internal void @_QFPomp_subroutine..omp_par(ptr noalias %tid.addr, ptr noalias %zero.addr, ptr %0) #2 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %gep_3 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 2
  %loadgep_4 = load ptr, ptr %gep_3, align 8
  %gep_5 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 3
  %loadgep_6 = load ptr, ptr %gep_5, align 8
  %gep_7 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 4
  %loadgep_8 = load ptr, ptr %gep_7, align 8
  %1 = tail call i32 @omp_get_thread_num()
  %2 = tail call i32 @omp_get_num_threads()
  %3 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %4 = sdiv i32 %3, %2
  %5 = mul i32 %4, %1
  %6 = add i32 %5, 1
  %7 = add i32 %2, -1
  %8 = icmp eq i32 %1, %7
  %9 = add i32 %6, %4
  %spec.select = select i1 %8, i32 %3, i32 %9
  %.unpack = load ptr, ptr %loadgep_2, align 8, !tbaa !8
  %.elt14 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  %.unpack15 = load i64, ptr %.elt14, align 8, !tbaa !8
  %.elt16 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  %.unpack17 = load i32, ptr %.elt16, align 8, !tbaa !8
  %.elt18 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  %.unpack19 = load i8, ptr %.elt18, align 4, !tbaa !8
  %.elt20 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  %.unpack21 = load i8, ptr %.elt20, align 1, !tbaa !8
  %.elt22 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  %.unpack23 = load i8, ptr %.elt22, align 2, !tbaa !8
  %.elt24 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  %.unpack25 = load i8, ptr %.elt24, align 1, !tbaa !8
  %.elt26 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  %.unpack27.unpack.unpack = load i64, ptr %.elt26, align 8, !tbaa !8
  %.unpack27.unpack.elt29 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  %.unpack27.unpack.unpack30 = load i64, ptr %.unpack27.unpack.elt29, align 8, !tbaa !8
  %.unpack27.unpack.elt31 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  %.unpack27.unpack.unpack32 = load i64, ptr %.unpack27.unpack.elt31, align 8, !tbaa !8
  store ptr %.unpack, ptr %loadgep_4, align 8, !tbaa !8
  %loadgep_4.repack34 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 1
  store i64 %.unpack15, ptr %loadgep_4.repack34, align 8, !tbaa !8
  %loadgep_4.repack36 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 2
  store i32 %.unpack17, ptr %loadgep_4.repack36, align 8, !tbaa !8
  %loadgep_4.repack38 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 3
  store i8 %.unpack19, ptr %loadgep_4.repack38, align 4, !tbaa !8
  %loadgep_4.repack40 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 4
  store i8 %.unpack21, ptr %loadgep_4.repack40, align 1, !tbaa !8
  %loadgep_4.repack42 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 5
  store i8 %.unpack23, ptr %loadgep_4.repack42, align 2, !tbaa !8
  %loadgep_4.repack44 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 6
  store i8 %.unpack25, ptr %loadgep_4.repack44, align 1, !tbaa !8
  %loadgep_4.repack46 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7
  store i64 %.unpack27.unpack.unpack, ptr %loadgep_4.repack46, align 8, !tbaa !8
  %loadgep_4.repack46.repack48 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack27.unpack.unpack30, ptr %loadgep_4.repack46.repack48, align 8, !tbaa !8
  %loadgep_4.repack46.repack50 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 2
  store i64 %.unpack27.unpack.unpack32, ptr %loadgep_4.repack46.repack50, align 8, !tbaa !8
  %10 = icmp eq i64 %.unpack27.unpack.unpack30, 0
  %11 = select i1 %10, i64 1, i64 %.unpack27.unpack.unpack
  store ptr %.unpack, ptr %loadgep_6, align 8, !tbaa !8
  %loadgep_6.repack52 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 1
  store i64 8, ptr %loadgep_6.repack52, align 8, !tbaa !8
  %loadgep_6.repack54 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 2
  store i32 20180515, ptr %loadgep_6.repack54, align 8, !tbaa !8
  %loadgep_6.repack56 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 3
  store i8 1, ptr %loadgep_6.repack56, align 4, !tbaa !8
  %loadgep_6.repack58 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 4
  store i8 28, ptr %loadgep_6.repack58, align 1, !tbaa !8
  %loadgep_6.repack60 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 5
  store i8 0, ptr %loadgep_6.repack60, align 2, !tbaa !8
  %loadgep_6.repack62 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 6
  store i8 0, ptr %loadgep_6.repack62, align 1, !tbaa !8
  %loadgep_6.repack64 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7
  store i64 %11, ptr %loadgep_6.repack64, align 8, !tbaa !8
  %loadgep_6.repack64.repack66 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack27.unpack.unpack30, ptr %loadgep_6.repack64.repack66, align 8, !tbaa !8
  %loadgep_6.repack64.repack68 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7, i64 0, i64 2
  store i64 8, ptr %loadgep_6.repack64.repack68, align 8, !tbaa !8
  %12 = load ptr, ptr %loadgep_8, align 8, !tbaa !4
  %13 = getelementptr { ptr, ptr }, ptr %loadgep_8, i64 0, i32 1
  %14 = load ptr, ptr %13, align 8, !tbaa !4
  %15 = sext i32 %6 to i64
  %16 = sext i32 %spec.select to i64
  %reass.sub9.i = sub nsw i64 %16, %15
  %17 = icmp sgt i64 %reass.sub9.i, -1
  br i1 %17, label %.lr.ph8.preheader.i, label %_QFPloop.exit

.lr.ph8.preheader.i:                              ; preds = %omp.par.entry
  %18 = add nuw nsw i64 %reass.sub9.i, 1
  br label %.lr.ph8.i

.lr.ph8.i:                                        ; preds = %.lr.ph8.i, %.lr.ph8.preheader.i
  %19 = phi i64 [ %29, %.lr.ph8.i ], [ %18, %.lr.ph8.preheader.i ]
  %20 = phi i32 [ %28, %.lr.ph8.i ], [ %6, %.lr.ph8.preheader.i ]
  %21 = load i32, ptr %12, align 4, !tbaa !4
  %22 = sitofp i32 %21 to float
  %23 = fdiv contract float 1.000000e+00, %22
  %24 = fpext float %23 to double
  %25 = sext i32 %20 to i64
  %26 = add nsw i64 %25, -1
  %27 = getelementptr double, ptr %.unpack, i64 %26
  store double %24, ptr %27, align 8, !tbaa !4
  store double %24, ptr %14, align 8, !tbaa !4
  %28 = add i32 %20, 1
  %29 = add nsw i64 %19, -1
  %30 = icmp ugt i64 %19, 1
  br i1 %30, label %.lr.ph8.i, label %_QFPloop.exit

_QFPloop.exit:                                    ; preds = %.lr.ph8.i, %omp.par.entry
  ret void
}
*** IR Dump After PostOrderFunctionAttrsPass on (_QFPomp_subroutine..omp_par) ***
; Function Attrs: norecurse nounwind
define internal void @_QFPomp_subroutine..omp_par(ptr noalias nocapture readnone %tid.addr, ptr noalias nocapture readnone %zero.addr, ptr nocapture readonly %0) #2 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %gep_3 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 2
  %loadgep_4 = load ptr, ptr %gep_3, align 8
  %gep_5 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 3
  %loadgep_6 = load ptr, ptr %gep_5, align 8
  %gep_7 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 4
  %loadgep_8 = load ptr, ptr %gep_7, align 8
  %1 = tail call i32 @omp_get_thread_num()
  %2 = tail call i32 @omp_get_num_threads()
  %3 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %4 = sdiv i32 %3, %2
  %5 = mul i32 %4, %1
  %6 = add i32 %5, 1
  %7 = add i32 %2, -1
  %8 = icmp eq i32 %1, %7
  %9 = add i32 %6, %4
  %spec.select = select i1 %8, i32 %3, i32 %9
  %.unpack = load ptr, ptr %loadgep_2, align 8, !tbaa !8
  %.elt14 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  %.unpack15 = load i64, ptr %.elt14, align 8, !tbaa !8
  %.elt16 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  %.unpack17 = load i32, ptr %.elt16, align 8, !tbaa !8
  %.elt18 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  %.unpack19 = load i8, ptr %.elt18, align 4, !tbaa !8
  %.elt20 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  %.unpack21 = load i8, ptr %.elt20, align 1, !tbaa !8
  %.elt22 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  %.unpack23 = load i8, ptr %.elt22, align 2, !tbaa !8
  %.elt24 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  %.unpack25 = load i8, ptr %.elt24, align 1, !tbaa !8
  %.elt26 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  %.unpack27.unpack.unpack = load i64, ptr %.elt26, align 8, !tbaa !8
  %.unpack27.unpack.elt29 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  %.unpack27.unpack.unpack30 = load i64, ptr %.unpack27.unpack.elt29, align 8, !tbaa !8
  %.unpack27.unpack.elt31 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  %.unpack27.unpack.unpack32 = load i64, ptr %.unpack27.unpack.elt31, align 8, !tbaa !8
  store ptr %.unpack, ptr %loadgep_4, align 8, !tbaa !8
  %loadgep_4.repack34 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 1
  store i64 %.unpack15, ptr %loadgep_4.repack34, align 8, !tbaa !8
  %loadgep_4.repack36 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 2
  store i32 %.unpack17, ptr %loadgep_4.repack36, align 8, !tbaa !8
  %loadgep_4.repack38 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 3
  store i8 %.unpack19, ptr %loadgep_4.repack38, align 4, !tbaa !8
  %loadgep_4.repack40 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 4
  store i8 %.unpack21, ptr %loadgep_4.repack40, align 1, !tbaa !8
  %loadgep_4.repack42 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 5
  store i8 %.unpack23, ptr %loadgep_4.repack42, align 2, !tbaa !8
  %loadgep_4.repack44 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 6
  store i8 %.unpack25, ptr %loadgep_4.repack44, align 1, !tbaa !8
  %loadgep_4.repack46 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7
  store i64 %.unpack27.unpack.unpack, ptr %loadgep_4.repack46, align 8, !tbaa !8
  %loadgep_4.repack46.repack48 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack27.unpack.unpack30, ptr %loadgep_4.repack46.repack48, align 8, !tbaa !8
  %loadgep_4.repack46.repack50 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 2
  store i64 %.unpack27.unpack.unpack32, ptr %loadgep_4.repack46.repack50, align 8, !tbaa !8
  %10 = icmp eq i64 %.unpack27.unpack.unpack30, 0
  %11 = select i1 %10, i64 1, i64 %.unpack27.unpack.unpack
  store ptr %.unpack, ptr %loadgep_6, align 8, !tbaa !8
  %loadgep_6.repack52 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 1
  store i64 8, ptr %loadgep_6.repack52, align 8, !tbaa !8
  %loadgep_6.repack54 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 2
  store i32 20180515, ptr %loadgep_6.repack54, align 8, !tbaa !8
  %loadgep_6.repack56 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 3
  store i8 1, ptr %loadgep_6.repack56, align 4, !tbaa !8
  %loadgep_6.repack58 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 4
  store i8 28, ptr %loadgep_6.repack58, align 1, !tbaa !8
  %loadgep_6.repack60 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 5
  store i8 0, ptr %loadgep_6.repack60, align 2, !tbaa !8
  %loadgep_6.repack62 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 6
  store i8 0, ptr %loadgep_6.repack62, align 1, !tbaa !8
  %loadgep_6.repack64 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7
  store i64 %11, ptr %loadgep_6.repack64, align 8, !tbaa !8
  %loadgep_6.repack64.repack66 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack27.unpack.unpack30, ptr %loadgep_6.repack64.repack66, align 8, !tbaa !8
  %loadgep_6.repack64.repack68 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7, i64 0, i64 2
  store i64 8, ptr %loadgep_6.repack64.repack68, align 8, !tbaa !8
  %12 = load ptr, ptr %loadgep_8, align 8, !tbaa !4
  %13 = getelementptr { ptr, ptr }, ptr %loadgep_8, i64 0, i32 1
  %14 = load ptr, ptr %13, align 8, !tbaa !4
  %15 = sext i32 %6 to i64
  %16 = sext i32 %spec.select to i64
  %reass.sub9.i = sub nsw i64 %16, %15
  %17 = icmp sgt i64 %reass.sub9.i, -1
  br i1 %17, label %.lr.ph8.preheader.i, label %_QFPloop.exit

.lr.ph8.preheader.i:                              ; preds = %omp.par.entry
  %18 = add nuw nsw i64 %reass.sub9.i, 1
  br label %.lr.ph8.i

.lr.ph8.i:                                        ; preds = %.lr.ph8.i, %.lr.ph8.preheader.i
  %19 = phi i64 [ %29, %.lr.ph8.i ], [ %18, %.lr.ph8.preheader.i ]
  %20 = phi i32 [ %28, %.lr.ph8.i ], [ %6, %.lr.ph8.preheader.i ]
  %21 = load i32, ptr %12, align 4, !tbaa !4
  %22 = sitofp i32 %21 to float
  %23 = fdiv contract float 1.000000e+00, %22
  %24 = fpext float %23 to double
  %25 = sext i32 %20 to i64
  %26 = add nsw i64 %25, -1
  %27 = getelementptr double, ptr %.unpack, i64 %26
  store double %24, ptr %27, align 8, !tbaa !4
  store double %24, ptr %14, align 8, !tbaa !4
  %28 = add i32 %20, 1
  %29 = add nsw i64 %19, -1
  %30 = icmp ugt i64 %19, 1
  br i1 %30, label %.lr.ph8.i, label %_QFPloop.exit

_QFPloop.exit:                                    ; preds = %.lr.ph8.i, %omp.par.entry
  ret void
}
*** IR Dump After RequireAnalysisPass<llvm::ShouldNotRunFunctionPassesAnalysis, llvm::Function> on _QFPomp_subroutine..omp_par ***
; Function Attrs: norecurse nounwind
define internal void @_QFPomp_subroutine..omp_par(ptr noalias nocapture readnone %tid.addr, ptr noalias nocapture readnone %zero.addr, ptr nocapture readonly %0) #2 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %gep_3 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 2
  %loadgep_4 = load ptr, ptr %gep_3, align 8
  %gep_5 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 3
  %loadgep_6 = load ptr, ptr %gep_5, align 8
  %gep_7 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 4
  %loadgep_8 = load ptr, ptr %gep_7, align 8
  %1 = tail call i32 @omp_get_thread_num()
  %2 = tail call i32 @omp_get_num_threads()
  %3 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %4 = sdiv i32 %3, %2
  %5 = mul i32 %4, %1
  %6 = add i32 %5, 1
  %7 = add i32 %2, -1
  %8 = icmp eq i32 %1, %7
  %9 = add i32 %6, %4
  %spec.select = select i1 %8, i32 %3, i32 %9
  %.unpack = load ptr, ptr %loadgep_2, align 8, !tbaa !8
  %.elt14 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  %.unpack15 = load i64, ptr %.elt14, align 8, !tbaa !8
  %.elt16 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  %.unpack17 = load i32, ptr %.elt16, align 8, !tbaa !8
  %.elt18 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  %.unpack19 = load i8, ptr %.elt18, align 4, !tbaa !8
  %.elt20 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  %.unpack21 = load i8, ptr %.elt20, align 1, !tbaa !8
  %.elt22 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  %.unpack23 = load i8, ptr %.elt22, align 2, !tbaa !8
  %.elt24 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  %.unpack25 = load i8, ptr %.elt24, align 1, !tbaa !8
  %.elt26 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  %.unpack27.unpack.unpack = load i64, ptr %.elt26, align 8, !tbaa !8
  %.unpack27.unpack.elt29 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  %.unpack27.unpack.unpack30 = load i64, ptr %.unpack27.unpack.elt29, align 8, !tbaa !8
  %.unpack27.unpack.elt31 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  %.unpack27.unpack.unpack32 = load i64, ptr %.unpack27.unpack.elt31, align 8, !tbaa !8
  store ptr %.unpack, ptr %loadgep_4, align 8, !tbaa !8
  %loadgep_4.repack34 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 1
  store i64 %.unpack15, ptr %loadgep_4.repack34, align 8, !tbaa !8
  %loadgep_4.repack36 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 2
  store i32 %.unpack17, ptr %loadgep_4.repack36, align 8, !tbaa !8
  %loadgep_4.repack38 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 3
  store i8 %.unpack19, ptr %loadgep_4.repack38, align 4, !tbaa !8
  %loadgep_4.repack40 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 4
  store i8 %.unpack21, ptr %loadgep_4.repack40, align 1, !tbaa !8
  %loadgep_4.repack42 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 5
  store i8 %.unpack23, ptr %loadgep_4.repack42, align 2, !tbaa !8
  %loadgep_4.repack44 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 6
  store i8 %.unpack25, ptr %loadgep_4.repack44, align 1, !tbaa !8
  %loadgep_4.repack46 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7
  store i64 %.unpack27.unpack.unpack, ptr %loadgep_4.repack46, align 8, !tbaa !8
  %loadgep_4.repack46.repack48 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack27.unpack.unpack30, ptr %loadgep_4.repack46.repack48, align 8, !tbaa !8
  %loadgep_4.repack46.repack50 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 2
  store i64 %.unpack27.unpack.unpack32, ptr %loadgep_4.repack46.repack50, align 8, !tbaa !8
  %10 = icmp eq i64 %.unpack27.unpack.unpack30, 0
  %11 = select i1 %10, i64 1, i64 %.unpack27.unpack.unpack
  store ptr %.unpack, ptr %loadgep_6, align 8, !tbaa !8
  %loadgep_6.repack52 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 1
  store i64 8, ptr %loadgep_6.repack52, align 8, !tbaa !8
  %loadgep_6.repack54 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 2
  store i32 20180515, ptr %loadgep_6.repack54, align 8, !tbaa !8
  %loadgep_6.repack56 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 3
  store i8 1, ptr %loadgep_6.repack56, align 4, !tbaa !8
  %loadgep_6.repack58 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 4
  store i8 28, ptr %loadgep_6.repack58, align 1, !tbaa !8
  %loadgep_6.repack60 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 5
  store i8 0, ptr %loadgep_6.repack60, align 2, !tbaa !8
  %loadgep_6.repack62 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 6
  store i8 0, ptr %loadgep_6.repack62, align 1, !tbaa !8
  %loadgep_6.repack64 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7
  store i64 %11, ptr %loadgep_6.repack64, align 8, !tbaa !8
  %loadgep_6.repack64.repack66 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack27.unpack.unpack30, ptr %loadgep_6.repack64.repack66, align 8, !tbaa !8
  %loadgep_6.repack64.repack68 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7, i64 0, i64 2
  store i64 8, ptr %loadgep_6.repack64.repack68, align 8, !tbaa !8
  %12 = load ptr, ptr %loadgep_8, align 8, !tbaa !4
  %13 = getelementptr { ptr, ptr }, ptr %loadgep_8, i64 0, i32 1
  %14 = load ptr, ptr %13, align 8, !tbaa !4
  %15 = sext i32 %6 to i64
  %16 = sext i32 %spec.select to i64
  %reass.sub9.i = sub nsw i64 %16, %15
  %17 = icmp sgt i64 %reass.sub9.i, -1
  br i1 %17, label %.lr.ph8.preheader.i, label %_QFPloop.exit

.lr.ph8.preheader.i:                              ; preds = %omp.par.entry
  %18 = add nuw nsw i64 %reass.sub9.i, 1
  br label %.lr.ph8.i

.lr.ph8.i:                                        ; preds = %.lr.ph8.i, %.lr.ph8.preheader.i
  %19 = phi i64 [ %29, %.lr.ph8.i ], [ %18, %.lr.ph8.preheader.i ]
  %20 = phi i32 [ %28, %.lr.ph8.i ], [ %6, %.lr.ph8.preheader.i ]
  %21 = load i32, ptr %12, align 4, !tbaa !4
  %22 = sitofp i32 %21 to float
  %23 = fdiv contract float 1.000000e+00, %22
  %24 = fpext float %23 to double
  %25 = sext i32 %20 to i64
  %26 = add nsw i64 %25, -1
  %27 = getelementptr double, ptr %.unpack, i64 %26
  store double %24, ptr %27, align 8, !tbaa !4
  store double %24, ptr %14, align 8, !tbaa !4
  %28 = add i32 %20, 1
  %29 = add nsw i64 %19, -1
  %30 = icmp ugt i64 %19, 1
  br i1 %30, label %.lr.ph8.i, label %_QFPloop.exit

_QFPloop.exit:                                    ; preds = %.lr.ph8.i, %omp.par.entry
  ret void
}
*** IR Dump After CoroSplitPass on (_QFPomp_subroutine..omp_par) ***
; Function Attrs: norecurse nounwind
define internal void @_QFPomp_subroutine..omp_par(ptr noalias nocapture readnone %tid.addr, ptr noalias nocapture readnone %zero.addr, ptr nocapture readonly %0) #2 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %gep_3 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 2
  %loadgep_4 = load ptr, ptr %gep_3, align 8
  %gep_5 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 3
  %loadgep_6 = load ptr, ptr %gep_5, align 8
  %gep_7 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 4
  %loadgep_8 = load ptr, ptr %gep_7, align 8
  %1 = tail call i32 @omp_get_thread_num()
  %2 = tail call i32 @omp_get_num_threads()
  %3 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %4 = sdiv i32 %3, %2
  %5 = mul i32 %4, %1
  %6 = add i32 %5, 1
  %7 = add i32 %2, -1
  %8 = icmp eq i32 %1, %7
  %9 = add i32 %6, %4
  %spec.select = select i1 %8, i32 %3, i32 %9
  %.unpack = load ptr, ptr %loadgep_2, align 8, !tbaa !8
  %.elt14 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  %.unpack15 = load i64, ptr %.elt14, align 8, !tbaa !8
  %.elt16 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  %.unpack17 = load i32, ptr %.elt16, align 8, !tbaa !8
  %.elt18 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  %.unpack19 = load i8, ptr %.elt18, align 4, !tbaa !8
  %.elt20 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  %.unpack21 = load i8, ptr %.elt20, align 1, !tbaa !8
  %.elt22 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  %.unpack23 = load i8, ptr %.elt22, align 2, !tbaa !8
  %.elt24 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  %.unpack25 = load i8, ptr %.elt24, align 1, !tbaa !8
  %.elt26 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  %.unpack27.unpack.unpack = load i64, ptr %.elt26, align 8, !tbaa !8
  %.unpack27.unpack.elt29 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  %.unpack27.unpack.unpack30 = load i64, ptr %.unpack27.unpack.elt29, align 8, !tbaa !8
  %.unpack27.unpack.elt31 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  %.unpack27.unpack.unpack32 = load i64, ptr %.unpack27.unpack.elt31, align 8, !tbaa !8
  store ptr %.unpack, ptr %loadgep_4, align 8, !tbaa !8
  %loadgep_4.repack34 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 1
  store i64 %.unpack15, ptr %loadgep_4.repack34, align 8, !tbaa !8
  %loadgep_4.repack36 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 2
  store i32 %.unpack17, ptr %loadgep_4.repack36, align 8, !tbaa !8
  %loadgep_4.repack38 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 3
  store i8 %.unpack19, ptr %loadgep_4.repack38, align 4, !tbaa !8
  %loadgep_4.repack40 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 4
  store i8 %.unpack21, ptr %loadgep_4.repack40, align 1, !tbaa !8
  %loadgep_4.repack42 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 5
  store i8 %.unpack23, ptr %loadgep_4.repack42, align 2, !tbaa !8
  %loadgep_4.repack44 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 6
  store i8 %.unpack25, ptr %loadgep_4.repack44, align 1, !tbaa !8
  %loadgep_4.repack46 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7
  store i64 %.unpack27.unpack.unpack, ptr %loadgep_4.repack46, align 8, !tbaa !8
  %loadgep_4.repack46.repack48 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack27.unpack.unpack30, ptr %loadgep_4.repack46.repack48, align 8, !tbaa !8
  %loadgep_4.repack46.repack50 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 2
  store i64 %.unpack27.unpack.unpack32, ptr %loadgep_4.repack46.repack50, align 8, !tbaa !8
  %10 = icmp eq i64 %.unpack27.unpack.unpack30, 0
  %11 = select i1 %10, i64 1, i64 %.unpack27.unpack.unpack
  store ptr %.unpack, ptr %loadgep_6, align 8, !tbaa !8
  %loadgep_6.repack52 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 1
  store i64 8, ptr %loadgep_6.repack52, align 8, !tbaa !8
  %loadgep_6.repack54 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 2
  store i32 20180515, ptr %loadgep_6.repack54, align 8, !tbaa !8
  %loadgep_6.repack56 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 3
  store i8 1, ptr %loadgep_6.repack56, align 4, !tbaa !8
  %loadgep_6.repack58 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 4
  store i8 28, ptr %loadgep_6.repack58, align 1, !tbaa !8
  %loadgep_6.repack60 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 5
  store i8 0, ptr %loadgep_6.repack60, align 2, !tbaa !8
  %loadgep_6.repack62 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 6
  store i8 0, ptr %loadgep_6.repack62, align 1, !tbaa !8
  %loadgep_6.repack64 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7
  store i64 %11, ptr %loadgep_6.repack64, align 8, !tbaa !8
  %loadgep_6.repack64.repack66 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack27.unpack.unpack30, ptr %loadgep_6.repack64.repack66, align 8, !tbaa !8
  %loadgep_6.repack64.repack68 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7, i64 0, i64 2
  store i64 8, ptr %loadgep_6.repack64.repack68, align 8, !tbaa !8
  %12 = load ptr, ptr %loadgep_8, align 8, !tbaa !4
  %13 = getelementptr { ptr, ptr }, ptr %loadgep_8, i64 0, i32 1
  %14 = load ptr, ptr %13, align 8, !tbaa !4
  %15 = sext i32 %6 to i64
  %16 = sext i32 %spec.select to i64
  %reass.sub9.i = sub nsw i64 %16, %15
  %17 = icmp sgt i64 %reass.sub9.i, -1
  br i1 %17, label %.lr.ph8.preheader.i, label %_QFPloop.exit

.lr.ph8.preheader.i:                              ; preds = %omp.par.entry
  %18 = add nuw nsw i64 %reass.sub9.i, 1
  br label %.lr.ph8.i

.lr.ph8.i:                                        ; preds = %.lr.ph8.i, %.lr.ph8.preheader.i
  %19 = phi i64 [ %29, %.lr.ph8.i ], [ %18, %.lr.ph8.preheader.i ]
  %20 = phi i32 [ %28, %.lr.ph8.i ], [ %6, %.lr.ph8.preheader.i ]
  %21 = load i32, ptr %12, align 4, !tbaa !4
  %22 = sitofp i32 %21 to float
  %23 = fdiv contract float 1.000000e+00, %22
  %24 = fpext float %23 to double
  %25 = sext i32 %20 to i64
  %26 = add nsw i64 %25, -1
  %27 = getelementptr double, ptr %.unpack, i64 %26
  store double %24, ptr %27, align 8, !tbaa !4
  store double %24, ptr %14, align 8, !tbaa !4
  %28 = add i32 %20, 1
  %29 = add nsw i64 %19, -1
  %30 = icmp ugt i64 %19, 1
  br i1 %30, label %.lr.ph8.i, label %_QFPloop.exit

_QFPloop.exit:                                    ; preds = %.lr.ph8.i, %omp.par.entry
  ret void
}
*** IR Dump After InlinerPass on (_QFPomp_subroutine) ***
define void @_QFPomp_subroutine(ptr %0, ptr %1, ptr nest %2) local_unnamed_addr {
entry:
  %structArg = alloca { ptr, ptr, ptr, ptr, ptr }, align 8
  %3 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %4 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %5 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  store ptr null, ptr %5, align 8, !tbaa !4
  %.fca.1.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 1
  store i64 8, ptr %.fca.1.gep, align 8, !tbaa !4
  %.fca.2.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 2
  store i32 20180515, ptr %.fca.2.gep, align 8, !tbaa !4
  %.fca.3.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 3
  store i8 1, ptr %.fca.3.gep, align 4, !tbaa !4
  %.fca.4.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 4
  store i8 28, ptr %.fca.4.gep, align 1, !tbaa !4
  %.fca.5.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 5
  store i8 2, ptr %.fca.5.gep, align 2, !tbaa !4
  %.fca.6.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 6
  store i8 0, ptr %.fca.6.gep, align 1, !tbaa !4
  %.fca.7.0.0.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 0
  store i64 1, ptr %.fca.7.0.0.gep, align 8, !tbaa !4
  %.fca.7.0.1.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 1
  store i64 0, ptr %.fca.7.0.1.gep, align 8, !tbaa !4
  %.fca.7.0.2.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 2
  store i64 8, ptr %.fca.7.0.2.gep, align 8, !tbaa !4
  %6 = load i32, ptr %0, align 4, !tbaa !8
  %7 = call i32 @llvm.smax.i32(i32 %6, i32 0)
  %8 = zext i32 %7 to i64
  %9 = shl nuw nsw i64 %8, 3
  %10 = call ptr @malloc(i64 %9)
  store ptr %10, ptr %5, align 8, !tbaa !4
  store i64 8, ptr %.fca.1.gep, align 8, !tbaa !4
  store i32 20180515, ptr %.fca.2.gep, align 8, !tbaa !4
  store i8 1, ptr %.fca.3.gep, align 4, !tbaa !4
  store i8 28, ptr %.fca.4.gep, align 1, !tbaa !4
  store i8 2, ptr %.fca.5.gep, align 2, !tbaa !4
  store i8 0, ptr %.fca.6.gep, align 1, !tbaa !4
  store i64 1, ptr %.fca.7.0.0.gep, align 8, !tbaa !4
  store i64 %8, ptr %.fca.7.0.1.gep, align 8, !tbaa !4
  store i64 8, ptr %.fca.7.0.2.gep, align 8, !tbaa !4
  %omp_global_thread_num = call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %0, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %5, ptr %gep_5, align 8
  %gep_6 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 2
  store ptr %4, ptr %gep_6, align 8
  %gep_7 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 3
  store ptr %3, ptr %gep_7, align 8
  %gep_8 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 4
  store ptr %2, ptr %gep_8, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QFPomp_subroutine..omp_par, ptr nonnull %structArg)
  %.fca.0.load = load ptr, ptr %5, align 8, !tbaa !4
  %.fca.7.0.0.load = load i64, ptr %.fca.7.0.0.gep, align 8, !tbaa !4
  %11 = sub i64 1, %.fca.7.0.0.load
  %12 = getelementptr double, ptr %.fca.0.load, i64 %11
  %13 = load double, ptr %12, align 8, !tbaa !8
  %14 = load i32, ptr %0, align 4, !tbaa !8
  %15 = sext i32 %14 to i64
  %16 = sub i64 %15, %.fca.7.0.0.load
  %17 = getelementptr double, ptr %.fca.0.load, i64 %16
  %18 = load double, ptr %17, align 8, !tbaa !8
  %19 = fadd contract double %13, %18
  store double %19, ptr %1, align 8, !tbaa !8
  %.fca.0.load40 = load ptr, ptr %5, align 8, !tbaa !4
  call void @free(ptr %.fca.0.load40)
  store ptr null, ptr %5, align 8, !tbaa !4
  store i64 8, ptr %.fca.1.gep, align 8, !tbaa !4
  store i32 20180515, ptr %.fca.2.gep, align 8, !tbaa !4
  store i8 1, ptr %.fca.3.gep, align 4, !tbaa !4
  store i8 28, ptr %.fca.4.gep, align 1, !tbaa !4
  store i8 2, ptr %.fca.5.gep, align 2, !tbaa !4
  store i8 0, ptr %.fca.6.gep, align 1, !tbaa !4
  store i64 1, ptr %.fca.7.0.0.gep, align 8, !tbaa !4
  store i64 0, ptr %.fca.7.0.1.gep, align 8, !tbaa !4
  store i64 8, ptr %.fca.7.0.2.gep, align 8, !tbaa !4
  ret void
}
*** IR Dump After InlinerPass on (_QFPomp_subroutine) ***
define void @_QFPomp_subroutine(ptr %0, ptr %1, ptr nest %2) local_unnamed_addr {
entry:
  %structArg = alloca { ptr, ptr, ptr, ptr, ptr }, align 8
  %3 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %4 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %5 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  store ptr null, ptr %5, align 8, !tbaa !4
  %.fca.1.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 1
  store i64 8, ptr %.fca.1.gep, align 8, !tbaa !4
  %.fca.2.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 2
  store i32 20180515, ptr %.fca.2.gep, align 8, !tbaa !4
  %.fca.3.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 3
  store i8 1, ptr %.fca.3.gep, align 4, !tbaa !4
  %.fca.4.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 4
  store i8 28, ptr %.fca.4.gep, align 1, !tbaa !4
  %.fca.5.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 5
  store i8 2, ptr %.fca.5.gep, align 2, !tbaa !4
  %.fca.6.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 6
  store i8 0, ptr %.fca.6.gep, align 1, !tbaa !4
  %.fca.7.0.0.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 0
  store i64 1, ptr %.fca.7.0.0.gep, align 8, !tbaa !4
  %.fca.7.0.1.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 1
  store i64 0, ptr %.fca.7.0.1.gep, align 8, !tbaa !4
  %.fca.7.0.2.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 2
  store i64 8, ptr %.fca.7.0.2.gep, align 8, !tbaa !4
  %6 = load i32, ptr %0, align 4, !tbaa !8
  %7 = call i32 @llvm.smax.i32(i32 %6, i32 0)
  %8 = zext i32 %7 to i64
  %9 = shl nuw nsw i64 %8, 3
  %10 = call ptr @malloc(i64 %9)
  store ptr %10, ptr %5, align 8, !tbaa !4
  store i64 8, ptr %.fca.1.gep, align 8, !tbaa !4
  store i32 20180515, ptr %.fca.2.gep, align 8, !tbaa !4
  store i8 1, ptr %.fca.3.gep, align 4, !tbaa !4
  store i8 28, ptr %.fca.4.gep, align 1, !tbaa !4
  store i8 2, ptr %.fca.5.gep, align 2, !tbaa !4
  store i8 0, ptr %.fca.6.gep, align 1, !tbaa !4
  store i64 1, ptr %.fca.7.0.0.gep, align 8, !tbaa !4
  store i64 %8, ptr %.fca.7.0.1.gep, align 8, !tbaa !4
  store i64 8, ptr %.fca.7.0.2.gep, align 8, !tbaa !4
  %omp_global_thread_num = call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %0, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %5, ptr %gep_5, align 8
  %gep_6 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 2
  store ptr %4, ptr %gep_6, align 8
  %gep_7 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 3
  store ptr %3, ptr %gep_7, align 8
  %gep_8 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 4
  store ptr %2, ptr %gep_8, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QFPomp_subroutine..omp_par, ptr nonnull %structArg)
  %.fca.0.load = load ptr, ptr %5, align 8, !tbaa !4
  %.fca.7.0.0.load = load i64, ptr %.fca.7.0.0.gep, align 8, !tbaa !4
  %11 = sub i64 1, %.fca.7.0.0.load
  %12 = getelementptr double, ptr %.fca.0.load, i64 %11
  %13 = load double, ptr %12, align 8, !tbaa !8
  %14 = load i32, ptr %0, align 4, !tbaa !8
  %15 = sext i32 %14 to i64
  %16 = sub i64 %15, %.fca.7.0.0.load
  %17 = getelementptr double, ptr %.fca.0.load, i64 %16
  %18 = load double, ptr %17, align 8, !tbaa !8
  %19 = fadd contract double %13, %18
  store double %19, ptr %1, align 8, !tbaa !8
  %.fca.0.load40 = load ptr, ptr %5, align 8, !tbaa !4
  call void @free(ptr %.fca.0.load40)
  store ptr null, ptr %5, align 8, !tbaa !4
  store i64 8, ptr %.fca.1.gep, align 8, !tbaa !4
  store i32 20180515, ptr %.fca.2.gep, align 8, !tbaa !4
  store i8 1, ptr %.fca.3.gep, align 4, !tbaa !4
  store i8 28, ptr %.fca.4.gep, align 1, !tbaa !4
  store i8 2, ptr %.fca.5.gep, align 2, !tbaa !4
  store i8 0, ptr %.fca.6.gep, align 1, !tbaa !4
  store i64 1, ptr %.fca.7.0.0.gep, align 8, !tbaa !4
  store i64 0, ptr %.fca.7.0.1.gep, align 8, !tbaa !4
  store i64 8, ptr %.fca.7.0.2.gep, align 8, !tbaa !4
  ret void
}
*** IR Dump After PostOrderFunctionAttrsPass on (_QFPomp_subroutine) ***
define void @_QFPomp_subroutine(ptr %0, ptr %1, ptr nest %2) local_unnamed_addr {
entry:
  %structArg = alloca { ptr, ptr, ptr, ptr, ptr }, align 8
  %3 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %4 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %5 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  store ptr null, ptr %5, align 8, !tbaa !4
  %.fca.1.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 1
  store i64 8, ptr %.fca.1.gep, align 8, !tbaa !4
  %.fca.2.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 2
  store i32 20180515, ptr %.fca.2.gep, align 8, !tbaa !4
  %.fca.3.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 3
  store i8 1, ptr %.fca.3.gep, align 4, !tbaa !4
  %.fca.4.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 4
  store i8 28, ptr %.fca.4.gep, align 1, !tbaa !4
  %.fca.5.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 5
  store i8 2, ptr %.fca.5.gep, align 2, !tbaa !4
  %.fca.6.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 6
  store i8 0, ptr %.fca.6.gep, align 1, !tbaa !4
  %.fca.7.0.0.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 0
  store i64 1, ptr %.fca.7.0.0.gep, align 8, !tbaa !4
  %.fca.7.0.1.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 1
  store i64 0, ptr %.fca.7.0.1.gep, align 8, !tbaa !4
  %.fca.7.0.2.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 2
  store i64 8, ptr %.fca.7.0.2.gep, align 8, !tbaa !4
  %6 = load i32, ptr %0, align 4, !tbaa !8
  %7 = call i32 @llvm.smax.i32(i32 %6, i32 0)
  %8 = zext i32 %7 to i64
  %9 = shl nuw nsw i64 %8, 3
  %10 = call ptr @malloc(i64 %9)
  store ptr %10, ptr %5, align 8, !tbaa !4
  store i64 8, ptr %.fca.1.gep, align 8, !tbaa !4
  store i32 20180515, ptr %.fca.2.gep, align 8, !tbaa !4
  store i8 1, ptr %.fca.3.gep, align 4, !tbaa !4
  store i8 28, ptr %.fca.4.gep, align 1, !tbaa !4
  store i8 2, ptr %.fca.5.gep, align 2, !tbaa !4
  store i8 0, ptr %.fca.6.gep, align 1, !tbaa !4
  store i64 1, ptr %.fca.7.0.0.gep, align 8, !tbaa !4
  store i64 %8, ptr %.fca.7.0.1.gep, align 8, !tbaa !4
  store i64 8, ptr %.fca.7.0.2.gep, align 8, !tbaa !4
  %omp_global_thread_num = call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %0, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %5, ptr %gep_5, align 8
  %gep_6 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 2
  store ptr %4, ptr %gep_6, align 8
  %gep_7 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 3
  store ptr %3, ptr %gep_7, align 8
  %gep_8 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 4
  store ptr %2, ptr %gep_8, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QFPomp_subroutine..omp_par, ptr nonnull %structArg)
  %.fca.0.load = load ptr, ptr %5, align 8, !tbaa !4
  %.fca.7.0.0.load = load i64, ptr %.fca.7.0.0.gep, align 8, !tbaa !4
  %11 = sub i64 1, %.fca.7.0.0.load
  %12 = getelementptr double, ptr %.fca.0.load, i64 %11
  %13 = load double, ptr %12, align 8, !tbaa !8
  %14 = load i32, ptr %0, align 4, !tbaa !8
  %15 = sext i32 %14 to i64
  %16 = sub i64 %15, %.fca.7.0.0.load
  %17 = getelementptr double, ptr %.fca.0.load, i64 %16
  %18 = load double, ptr %17, align 8, !tbaa !8
  %19 = fadd contract double %13, %18
  store double %19, ptr %1, align 8, !tbaa !8
  %.fca.0.load40 = load ptr, ptr %5, align 8, !tbaa !4
  call void @free(ptr %.fca.0.load40)
  store ptr null, ptr %5, align 8, !tbaa !4
  store i64 8, ptr %.fca.1.gep, align 8, !tbaa !4
  store i32 20180515, ptr %.fca.2.gep, align 8, !tbaa !4
  store i8 1, ptr %.fca.3.gep, align 4, !tbaa !4
  store i8 28, ptr %.fca.4.gep, align 1, !tbaa !4
  store i8 2, ptr %.fca.5.gep, align 2, !tbaa !4
  store i8 0, ptr %.fca.6.gep, align 1, !tbaa !4
  store i64 1, ptr %.fca.7.0.0.gep, align 8, !tbaa !4
  store i64 0, ptr %.fca.7.0.1.gep, align 8, !tbaa !4
  store i64 8, ptr %.fca.7.0.2.gep, align 8, !tbaa !4
  ret void
}
*** IR Dump After ArgumentPromotionPass on (_QFPomp_subroutine) ***
define void @_QFPomp_subroutine(ptr %0, ptr %1, ptr nest %2) local_unnamed_addr {
entry:
  %structArg = alloca { ptr, ptr, ptr, ptr, ptr }, align 8
  %3 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %4 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %5 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  store ptr null, ptr %5, align 8, !tbaa !4
  %.fca.1.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 1
  store i64 8, ptr %.fca.1.gep, align 8, !tbaa !4
  %.fca.2.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 2
  store i32 20180515, ptr %.fca.2.gep, align 8, !tbaa !4
  %.fca.3.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 3
  store i8 1, ptr %.fca.3.gep, align 4, !tbaa !4
  %.fca.4.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 4
  store i8 28, ptr %.fca.4.gep, align 1, !tbaa !4
  %.fca.5.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 5
  store i8 2, ptr %.fca.5.gep, align 2, !tbaa !4
  %.fca.6.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 6
  store i8 0, ptr %.fca.6.gep, align 1, !tbaa !4
  %.fca.7.0.0.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 0
  store i64 1, ptr %.fca.7.0.0.gep, align 8, !tbaa !4
  %.fca.7.0.1.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 1
  store i64 0, ptr %.fca.7.0.1.gep, align 8, !tbaa !4
  %.fca.7.0.2.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 2
  store i64 8, ptr %.fca.7.0.2.gep, align 8, !tbaa !4
  %6 = load i32, ptr %0, align 4, !tbaa !8
  %7 = call i32 @llvm.smax.i32(i32 %6, i32 0)
  %8 = zext i32 %7 to i64
  %9 = shl nuw nsw i64 %8, 3
  %10 = call ptr @malloc(i64 %9)
  store ptr %10, ptr %5, align 8, !tbaa !4
  store i64 8, ptr %.fca.1.gep, align 8, !tbaa !4
  store i32 20180515, ptr %.fca.2.gep, align 8, !tbaa !4
  store i8 1, ptr %.fca.3.gep, align 4, !tbaa !4
  store i8 28, ptr %.fca.4.gep, align 1, !tbaa !4
  store i8 2, ptr %.fca.5.gep, align 2, !tbaa !4
  store i8 0, ptr %.fca.6.gep, align 1, !tbaa !4
  store i64 1, ptr %.fca.7.0.0.gep, align 8, !tbaa !4
  store i64 %8, ptr %.fca.7.0.1.gep, align 8, !tbaa !4
  store i64 8, ptr %.fca.7.0.2.gep, align 8, !tbaa !4
  %omp_global_thread_num = call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %0, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %5, ptr %gep_5, align 8
  %gep_6 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 2
  store ptr %4, ptr %gep_6, align 8
  %gep_7 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 3
  store ptr %3, ptr %gep_7, align 8
  %gep_8 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 4
  store ptr %2, ptr %gep_8, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QFPomp_subroutine..omp_par, ptr nonnull %structArg)
  %.fca.0.load = load ptr, ptr %5, align 8, !tbaa !4
  %.fca.7.0.0.load = load i64, ptr %.fca.7.0.0.gep, align 8, !tbaa !4
  %11 = sub i64 1, %.fca.7.0.0.load
  %12 = getelementptr double, ptr %.fca.0.load, i64 %11
  %13 = load double, ptr %12, align 8, !tbaa !8
  %14 = load i32, ptr %0, align 4, !tbaa !8
  %15 = sext i32 %14 to i64
  %16 = sub i64 %15, %.fca.7.0.0.load
  %17 = getelementptr double, ptr %.fca.0.load, i64 %16
  %18 = load double, ptr %17, align 8, !tbaa !8
  %19 = fadd contract double %13, %18
  store double %19, ptr %1, align 8, !tbaa !8
  %.fca.0.load40 = load ptr, ptr %5, align 8, !tbaa !4
  call void @free(ptr %.fca.0.load40)
  store ptr null, ptr %5, align 8, !tbaa !4
  store i64 8, ptr %.fca.1.gep, align 8, !tbaa !4
  store i32 20180515, ptr %.fca.2.gep, align 8, !tbaa !4
  store i8 1, ptr %.fca.3.gep, align 4, !tbaa !4
  store i8 28, ptr %.fca.4.gep, align 1, !tbaa !4
  store i8 2, ptr %.fca.5.gep, align 2, !tbaa !4
  store i8 0, ptr %.fca.6.gep, align 1, !tbaa !4
  store i64 1, ptr %.fca.7.0.0.gep, align 8, !tbaa !4
  store i64 0, ptr %.fca.7.0.1.gep, align 8, !tbaa !4
  store i64 8, ptr %.fca.7.0.2.gep, align 8, !tbaa !4
  ret void
}
*** IR Dump After OpenMPOptCGSCCPass on (_QFPomp_subroutine) ***
define void @_QFPomp_subroutine(ptr %0, ptr %1, ptr nest %2) local_unnamed_addr {
entry:
  %structArg = alloca { ptr, ptr, ptr, ptr, ptr }, align 8
  %3 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %4 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %5 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  store ptr null, ptr %5, align 8, !tbaa !4
  %.fca.1.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 1
  store i64 8, ptr %.fca.1.gep, align 8, !tbaa !4
  %.fca.2.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 2
  store i32 20180515, ptr %.fca.2.gep, align 8, !tbaa !4
  %.fca.3.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 3
  store i8 1, ptr %.fca.3.gep, align 4, !tbaa !4
  %.fca.4.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 4
  store i8 28, ptr %.fca.4.gep, align 1, !tbaa !4
  %.fca.5.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 5
  store i8 2, ptr %.fca.5.gep, align 2, !tbaa !4
  %.fca.6.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 6
  store i8 0, ptr %.fca.6.gep, align 1, !tbaa !4
  %.fca.7.0.0.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 0
  store i64 1, ptr %.fca.7.0.0.gep, align 8, !tbaa !4
  %.fca.7.0.1.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 1
  store i64 0, ptr %.fca.7.0.1.gep, align 8, !tbaa !4
  %.fca.7.0.2.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 2
  store i64 8, ptr %.fca.7.0.2.gep, align 8, !tbaa !4
  %6 = load i32, ptr %0, align 4, !tbaa !8
  %7 = call i32 @llvm.smax.i32(i32 %6, i32 0)
  %8 = zext i32 %7 to i64
  %9 = shl nuw nsw i64 %8, 3
  %10 = call ptr @malloc(i64 %9)
  store ptr %10, ptr %5, align 8, !tbaa !4
  store i64 8, ptr %.fca.1.gep, align 8, !tbaa !4
  store i32 20180515, ptr %.fca.2.gep, align 8, !tbaa !4
  store i8 1, ptr %.fca.3.gep, align 4, !tbaa !4
  store i8 28, ptr %.fca.4.gep, align 1, !tbaa !4
  store i8 2, ptr %.fca.5.gep, align 2, !tbaa !4
  store i8 0, ptr %.fca.6.gep, align 1, !tbaa !4
  store i64 1, ptr %.fca.7.0.0.gep, align 8, !tbaa !4
  store i64 %8, ptr %.fca.7.0.1.gep, align 8, !tbaa !4
  store i64 8, ptr %.fca.7.0.2.gep, align 8, !tbaa !4
  %omp_global_thread_num = call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %0, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %5, ptr %gep_5, align 8
  %gep_6 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 2
  store ptr %4, ptr %gep_6, align 8
  %gep_7 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 3
  store ptr %3, ptr %gep_7, align 8
  %gep_8 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 4
  store ptr %2, ptr %gep_8, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QFPomp_subroutine..omp_par, ptr nonnull %structArg)
  %.fca.0.load = load ptr, ptr %5, align 8, !tbaa !4
  %.fca.7.0.0.load = load i64, ptr %.fca.7.0.0.gep, align 8, !tbaa !4
  %11 = sub i64 1, %.fca.7.0.0.load
  %12 = getelementptr double, ptr %.fca.0.load, i64 %11
  %13 = load double, ptr %12, align 8, !tbaa !8
  %14 = load i32, ptr %0, align 4, !tbaa !8
  %15 = sext i32 %14 to i64
  %16 = sub i64 %15, %.fca.7.0.0.load
  %17 = getelementptr double, ptr %.fca.0.load, i64 %16
  %18 = load double, ptr %17, align 8, !tbaa !8
  %19 = fadd contract double %13, %18
  store double %19, ptr %1, align 8, !tbaa !8
  %.fca.0.load40 = load ptr, ptr %5, align 8, !tbaa !4
  call void @free(ptr %.fca.0.load40)
  store ptr null, ptr %5, align 8, !tbaa !4
  store i64 8, ptr %.fca.1.gep, align 8, !tbaa !4
  store i32 20180515, ptr %.fca.2.gep, align 8, !tbaa !4
  store i8 1, ptr %.fca.3.gep, align 4, !tbaa !4
  store i8 28, ptr %.fca.4.gep, align 1, !tbaa !4
  store i8 2, ptr %.fca.5.gep, align 2, !tbaa !4
  store i8 0, ptr %.fca.6.gep, align 1, !tbaa !4
  store i64 1, ptr %.fca.7.0.0.gep, align 8, !tbaa !4
  store i64 0, ptr %.fca.7.0.1.gep, align 8, !tbaa !4
  store i64 8, ptr %.fca.7.0.2.gep, align 8, !tbaa !4
  ret void
}
*** IR Dump After SROAPass on _QFPomp_subroutine ***
define void @_QFPomp_subroutine(ptr %0, ptr %1, ptr nest %2) local_unnamed_addr {
entry:
  %structArg = alloca { ptr, ptr, ptr, ptr, ptr }, align 8
  %3 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %4 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %5 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  store ptr null, ptr %5, align 8, !tbaa !8
  %.fca.1.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 1
  store i64 8, ptr %.fca.1.gep, align 8, !tbaa !8
  %.fca.2.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 2
  store i32 20180515, ptr %.fca.2.gep, align 8, !tbaa !8
  %.fca.3.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 3
  store i8 1, ptr %.fca.3.gep, align 4, !tbaa !8
  %.fca.4.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 4
  store i8 28, ptr %.fca.4.gep, align 1, !tbaa !8
  %.fca.5.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 5
  store i8 2, ptr %.fca.5.gep, align 2, !tbaa !8
  %.fca.6.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 6
  store i8 0, ptr %.fca.6.gep, align 1, !tbaa !8
  %.fca.7.0.0.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 0
  store i64 1, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  %.fca.7.0.1.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 1
  store i64 0, ptr %.fca.7.0.1.gep, align 8, !tbaa !8
  %.fca.7.0.2.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 2
  store i64 8, ptr %.fca.7.0.2.gep, align 8, !tbaa !8
  %6 = load i32, ptr %0, align 4, !tbaa !4
  %7 = call i32 @llvm.smax.i32(i32 %6, i32 0)
  %8 = zext i32 %7 to i64
  %9 = shl nuw nsw i64 %8, 3
  %10 = call ptr @malloc(i64 %9)
  store ptr %10, ptr %5, align 8, !tbaa !8
  store i64 8, ptr %.fca.1.gep, align 8, !tbaa !8
  store i32 20180515, ptr %.fca.2.gep, align 8, !tbaa !8
  store i8 1, ptr %.fca.3.gep, align 4, !tbaa !8
  store i8 28, ptr %.fca.4.gep, align 1, !tbaa !8
  store i8 2, ptr %.fca.5.gep, align 2, !tbaa !8
  store i8 0, ptr %.fca.6.gep, align 1, !tbaa !8
  store i64 1, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  store i64 %8, ptr %.fca.7.0.1.gep, align 8, !tbaa !8
  store i64 8, ptr %.fca.7.0.2.gep, align 8, !tbaa !8
  %omp_global_thread_num = call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %0, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %5, ptr %gep_5, align 8
  %gep_6 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 2
  store ptr %4, ptr %gep_6, align 8
  %gep_7 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 3
  store ptr %3, ptr %gep_7, align 8
  %gep_8 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 4
  store ptr %2, ptr %gep_8, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QFPomp_subroutine..omp_par, ptr nonnull %structArg)
  %.fca.0.load = load ptr, ptr %5, align 8, !tbaa !8
  %.fca.7.0.0.load = load i64, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  %11 = sub i64 1, %.fca.7.0.0.load
  %12 = getelementptr double, ptr %.fca.0.load, i64 %11
  %13 = load double, ptr %12, align 8, !tbaa !4
  %14 = load i32, ptr %0, align 4, !tbaa !4
  %15 = sext i32 %14 to i64
  %16 = sub i64 %15, %.fca.7.0.0.load
  %17 = getelementptr double, ptr %.fca.0.load, i64 %16
  %18 = load double, ptr %17, align 8, !tbaa !4
  %19 = fadd contract double %13, %18
  store double %19, ptr %1, align 8, !tbaa !4
  %.fca.0.load40 = load ptr, ptr %5, align 8, !tbaa !8
  call void @free(ptr %.fca.0.load40)
  store ptr null, ptr %5, align 8, !tbaa !8
  store i64 8, ptr %.fca.1.gep, align 8, !tbaa !8
  store i32 20180515, ptr %.fca.2.gep, align 8, !tbaa !8
  store i8 1, ptr %.fca.3.gep, align 4, !tbaa !8
  store i8 28, ptr %.fca.4.gep, align 1, !tbaa !8
  store i8 2, ptr %.fca.5.gep, align 2, !tbaa !8
  store i8 0, ptr %.fca.6.gep, align 1, !tbaa !8
  store i64 1, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  store i64 0, ptr %.fca.7.0.1.gep, align 8, !tbaa !8
  store i64 8, ptr %.fca.7.0.2.gep, align 8, !tbaa !8
  ret void
}
*** IR Dump After EarlyCSEPass on _QFPomp_subroutine ***
define void @_QFPomp_subroutine(ptr %0, ptr %1, ptr nest %2) local_unnamed_addr {
entry:
  %structArg = alloca { ptr, ptr, ptr, ptr, ptr }, align 8
  %3 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %4 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %5 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  store ptr null, ptr %5, align 8, !tbaa !8
  %.fca.1.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 1
  store i64 8, ptr %.fca.1.gep, align 8, !tbaa !8
  %.fca.2.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 2
  store i32 20180515, ptr %.fca.2.gep, align 8, !tbaa !8
  %.fca.3.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 3
  store i8 1, ptr %.fca.3.gep, align 4, !tbaa !8
  %.fca.4.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 4
  store i8 28, ptr %.fca.4.gep, align 1, !tbaa !8
  %.fca.5.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 5
  store i8 2, ptr %.fca.5.gep, align 2, !tbaa !8
  %.fca.6.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 6
  store i8 0, ptr %.fca.6.gep, align 1, !tbaa !8
  %.fca.7.0.0.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 0
  store i64 1, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  %.fca.7.0.1.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 1
  store i64 0, ptr %.fca.7.0.1.gep, align 8, !tbaa !8
  %.fca.7.0.2.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 2
  store i64 8, ptr %.fca.7.0.2.gep, align 8, !tbaa !8
  %6 = load i32, ptr %0, align 4, !tbaa !4
  %7 = call i32 @llvm.smax.i32(i32 %6, i32 0)
  %8 = zext i32 %7 to i64
  %9 = shl nuw nsw i64 %8, 3
  %10 = call ptr @malloc(i64 %9)
  store ptr %10, ptr %5, align 8, !tbaa !8
  store i64 8, ptr %.fca.1.gep, align 8, !tbaa !8
  store i32 20180515, ptr %.fca.2.gep, align 8, !tbaa !8
  store i8 1, ptr %.fca.3.gep, align 4, !tbaa !8
  store i8 28, ptr %.fca.4.gep, align 1, !tbaa !8
  store i8 2, ptr %.fca.5.gep, align 2, !tbaa !8
  store i8 0, ptr %.fca.6.gep, align 1, !tbaa !8
  store i64 1, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  store i64 %8, ptr %.fca.7.0.1.gep, align 8, !tbaa !8
  store i64 8, ptr %.fca.7.0.2.gep, align 8, !tbaa !8
  %omp_global_thread_num = call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %0, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %5, ptr %gep_5, align 8
  %gep_6 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 2
  store ptr %4, ptr %gep_6, align 8
  %gep_7 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 3
  store ptr %3, ptr %gep_7, align 8
  %gep_8 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 4
  store ptr %2, ptr %gep_8, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QFPomp_subroutine..omp_par, ptr nonnull %structArg)
  %.fca.0.load = load ptr, ptr %5, align 8, !tbaa !8
  %.fca.7.0.0.load = load i64, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  %11 = sub i64 1, %.fca.7.0.0.load
  %12 = getelementptr double, ptr %.fca.0.load, i64 %11
  %13 = load double, ptr %12, align 8, !tbaa !4
  %14 = load i32, ptr %0, align 4, !tbaa !4
  %15 = sext i32 %14 to i64
  %16 = sub i64 %15, %.fca.7.0.0.load
  %17 = getelementptr double, ptr %.fca.0.load, i64 %16
  %18 = load double, ptr %17, align 8, !tbaa !4
  %19 = fadd contract double %13, %18
  store double %19, ptr %1, align 8, !tbaa !4
  call void @free(ptr %.fca.0.load)
  store ptr null, ptr %5, align 8, !tbaa !8
  store i64 8, ptr %.fca.1.gep, align 8, !tbaa !8
  store i32 20180515, ptr %.fca.2.gep, align 8, !tbaa !8
  store i8 1, ptr %.fca.3.gep, align 4, !tbaa !8
  store i8 28, ptr %.fca.4.gep, align 1, !tbaa !8
  store i8 2, ptr %.fca.5.gep, align 2, !tbaa !8
  store i8 0, ptr %.fca.6.gep, align 1, !tbaa !8
  store i64 1, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  store i64 0, ptr %.fca.7.0.1.gep, align 8, !tbaa !8
  store i64 8, ptr %.fca.7.0.2.gep, align 8, !tbaa !8
  ret void
}
*** IR Dump After SpeculativeExecutionPass on _QFPomp_subroutine ***
define void @_QFPomp_subroutine(ptr %0, ptr %1, ptr nest %2) local_unnamed_addr {
entry:
  %structArg = alloca { ptr, ptr, ptr, ptr, ptr }, align 8
  %3 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %4 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %5 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  store ptr null, ptr %5, align 8, !tbaa !8
  %.fca.1.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 1
  store i64 8, ptr %.fca.1.gep, align 8, !tbaa !8
  %.fca.2.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 2
  store i32 20180515, ptr %.fca.2.gep, align 8, !tbaa !8
  %.fca.3.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 3
  store i8 1, ptr %.fca.3.gep, align 4, !tbaa !8
  %.fca.4.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 4
  store i8 28, ptr %.fca.4.gep, align 1, !tbaa !8
  %.fca.5.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 5
  store i8 2, ptr %.fca.5.gep, align 2, !tbaa !8
  %.fca.6.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 6
  store i8 0, ptr %.fca.6.gep, align 1, !tbaa !8
  %.fca.7.0.0.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 0
  store i64 1, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  %.fca.7.0.1.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 1
  store i64 0, ptr %.fca.7.0.1.gep, align 8, !tbaa !8
  %.fca.7.0.2.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 2
  store i64 8, ptr %.fca.7.0.2.gep, align 8, !tbaa !8
  %6 = load i32, ptr %0, align 4, !tbaa !4
  %7 = call i32 @llvm.smax.i32(i32 %6, i32 0)
  %8 = zext i32 %7 to i64
  %9 = shl nuw nsw i64 %8, 3
  %10 = call ptr @malloc(i64 %9)
  store ptr %10, ptr %5, align 8, !tbaa !8
  store i64 8, ptr %.fca.1.gep, align 8, !tbaa !8
  store i32 20180515, ptr %.fca.2.gep, align 8, !tbaa !8
  store i8 1, ptr %.fca.3.gep, align 4, !tbaa !8
  store i8 28, ptr %.fca.4.gep, align 1, !tbaa !8
  store i8 2, ptr %.fca.5.gep, align 2, !tbaa !8
  store i8 0, ptr %.fca.6.gep, align 1, !tbaa !8
  store i64 1, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  store i64 %8, ptr %.fca.7.0.1.gep, align 8, !tbaa !8
  store i64 8, ptr %.fca.7.0.2.gep, align 8, !tbaa !8
  %omp_global_thread_num = call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %0, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %5, ptr %gep_5, align 8
  %gep_6 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 2
  store ptr %4, ptr %gep_6, align 8
  %gep_7 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 3
  store ptr %3, ptr %gep_7, align 8
  %gep_8 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 4
  store ptr %2, ptr %gep_8, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QFPomp_subroutine..omp_par, ptr nonnull %structArg)
  %.fca.0.load = load ptr, ptr %5, align 8, !tbaa !8
  %.fca.7.0.0.load = load i64, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  %11 = sub i64 1, %.fca.7.0.0.load
  %12 = getelementptr double, ptr %.fca.0.load, i64 %11
  %13 = load double, ptr %12, align 8, !tbaa !4
  %14 = load i32, ptr %0, align 4, !tbaa !4
  %15 = sext i32 %14 to i64
  %16 = sub i64 %15, %.fca.7.0.0.load
  %17 = getelementptr double, ptr %.fca.0.load, i64 %16
  %18 = load double, ptr %17, align 8, !tbaa !4
  %19 = fadd contract double %13, %18
  store double %19, ptr %1, align 8, !tbaa !4
  call void @free(ptr %.fca.0.load)
  store ptr null, ptr %5, align 8, !tbaa !8
  store i64 8, ptr %.fca.1.gep, align 8, !tbaa !8
  store i32 20180515, ptr %.fca.2.gep, align 8, !tbaa !8
  store i8 1, ptr %.fca.3.gep, align 4, !tbaa !8
  store i8 28, ptr %.fca.4.gep, align 1, !tbaa !8
  store i8 2, ptr %.fca.5.gep, align 2, !tbaa !8
  store i8 0, ptr %.fca.6.gep, align 1, !tbaa !8
  store i64 1, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  store i64 0, ptr %.fca.7.0.1.gep, align 8, !tbaa !8
  store i64 8, ptr %.fca.7.0.2.gep, align 8, !tbaa !8
  ret void
}
*** IR Dump After JumpThreadingPass on _QFPomp_subroutine ***
define void @_QFPomp_subroutine(ptr %0, ptr %1, ptr nest %2) local_unnamed_addr {
entry:
  %structArg = alloca { ptr, ptr, ptr, ptr, ptr }, align 8
  %3 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %4 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %5 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  store ptr null, ptr %5, align 8, !tbaa !8
  %.fca.1.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 1
  store i64 8, ptr %.fca.1.gep, align 8, !tbaa !8
  %.fca.2.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 2
  store i32 20180515, ptr %.fca.2.gep, align 8, !tbaa !8
  %.fca.3.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 3
  store i8 1, ptr %.fca.3.gep, align 4, !tbaa !8
  %.fca.4.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 4
  store i8 28, ptr %.fca.4.gep, align 1, !tbaa !8
  %.fca.5.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 5
  store i8 2, ptr %.fca.5.gep, align 2, !tbaa !8
  %.fca.6.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 6
  store i8 0, ptr %.fca.6.gep, align 1, !tbaa !8
  %.fca.7.0.0.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 0
  store i64 1, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  %.fca.7.0.1.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 1
  store i64 0, ptr %.fca.7.0.1.gep, align 8, !tbaa !8
  %.fca.7.0.2.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 2
  store i64 8, ptr %.fca.7.0.2.gep, align 8, !tbaa !8
  %6 = load i32, ptr %0, align 4, !tbaa !4
  %7 = call i32 @llvm.smax.i32(i32 %6, i32 0)
  %8 = zext i32 %7 to i64
  %9 = shl nuw nsw i64 %8, 3
  %10 = call ptr @malloc(i64 %9)
  store ptr %10, ptr %5, align 8, !tbaa !8
  store i64 8, ptr %.fca.1.gep, align 8, !tbaa !8
  store i32 20180515, ptr %.fca.2.gep, align 8, !tbaa !8
  store i8 1, ptr %.fca.3.gep, align 4, !tbaa !8
  store i8 28, ptr %.fca.4.gep, align 1, !tbaa !8
  store i8 2, ptr %.fca.5.gep, align 2, !tbaa !8
  store i8 0, ptr %.fca.6.gep, align 1, !tbaa !8
  store i64 1, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  store i64 %8, ptr %.fca.7.0.1.gep, align 8, !tbaa !8
  store i64 8, ptr %.fca.7.0.2.gep, align 8, !tbaa !8
  %omp_global_thread_num = call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %0, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %5, ptr %gep_5, align 8
  %gep_6 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 2
  store ptr %4, ptr %gep_6, align 8
  %gep_7 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 3
  store ptr %3, ptr %gep_7, align 8
  %gep_8 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 4
  store ptr %2, ptr %gep_8, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QFPomp_subroutine..omp_par, ptr nonnull %structArg)
  %.fca.0.load = load ptr, ptr %5, align 8, !tbaa !8
  %.fca.7.0.0.load = load i64, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  %11 = sub i64 1, %.fca.7.0.0.load
  %12 = getelementptr double, ptr %.fca.0.load, i64 %11
  %13 = load double, ptr %12, align 8, !tbaa !4
  %14 = load i32, ptr %0, align 4, !tbaa !4
  %15 = sext i32 %14 to i64
  %16 = sub i64 %15, %.fca.7.0.0.load
  %17 = getelementptr double, ptr %.fca.0.load, i64 %16
  %18 = load double, ptr %17, align 8, !tbaa !4
  %19 = fadd contract double %13, %18
  store double %19, ptr %1, align 8, !tbaa !4
  call void @free(ptr %.fca.0.load)
  store ptr null, ptr %5, align 8, !tbaa !8
  store i64 8, ptr %.fca.1.gep, align 8, !tbaa !8
  store i32 20180515, ptr %.fca.2.gep, align 8, !tbaa !8
  store i8 1, ptr %.fca.3.gep, align 4, !tbaa !8
  store i8 28, ptr %.fca.4.gep, align 1, !tbaa !8
  store i8 2, ptr %.fca.5.gep, align 2, !tbaa !8
  store i8 0, ptr %.fca.6.gep, align 1, !tbaa !8
  store i64 1, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  store i64 0, ptr %.fca.7.0.1.gep, align 8, !tbaa !8
  store i64 8, ptr %.fca.7.0.2.gep, align 8, !tbaa !8
  ret void
}
*** IR Dump After CorrelatedValuePropagationPass on _QFPomp_subroutine ***
define void @_QFPomp_subroutine(ptr %0, ptr %1, ptr nest %2) local_unnamed_addr {
entry:
  %structArg = alloca { ptr, ptr, ptr, ptr, ptr }, align 8
  %3 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %4 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %5 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  store ptr null, ptr %5, align 8, !tbaa !8
  %.fca.1.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 1
  store i64 8, ptr %.fca.1.gep, align 8, !tbaa !8
  %.fca.2.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 2
  store i32 20180515, ptr %.fca.2.gep, align 8, !tbaa !8
  %.fca.3.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 3
  store i8 1, ptr %.fca.3.gep, align 4, !tbaa !8
  %.fca.4.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 4
  store i8 28, ptr %.fca.4.gep, align 1, !tbaa !8
  %.fca.5.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 5
  store i8 2, ptr %.fca.5.gep, align 2, !tbaa !8
  %.fca.6.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 6
  store i8 0, ptr %.fca.6.gep, align 1, !tbaa !8
  %.fca.7.0.0.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 0
  store i64 1, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  %.fca.7.0.1.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 1
  store i64 0, ptr %.fca.7.0.1.gep, align 8, !tbaa !8
  %.fca.7.0.2.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 2
  store i64 8, ptr %.fca.7.0.2.gep, align 8, !tbaa !8
  %6 = load i32, ptr %0, align 4, !tbaa !4
  %7 = call i32 @llvm.smax.i32(i32 %6, i32 0)
  %8 = zext i32 %7 to i64
  %9 = shl nuw nsw i64 %8, 3
  %10 = call ptr @malloc(i64 %9)
  store ptr %10, ptr %5, align 8, !tbaa !8
  store i64 8, ptr %.fca.1.gep, align 8, !tbaa !8
  store i32 20180515, ptr %.fca.2.gep, align 8, !tbaa !8
  store i8 1, ptr %.fca.3.gep, align 4, !tbaa !8
  store i8 28, ptr %.fca.4.gep, align 1, !tbaa !8
  store i8 2, ptr %.fca.5.gep, align 2, !tbaa !8
  store i8 0, ptr %.fca.6.gep, align 1, !tbaa !8
  store i64 1, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  store i64 %8, ptr %.fca.7.0.1.gep, align 8, !tbaa !8
  store i64 8, ptr %.fca.7.0.2.gep, align 8, !tbaa !8
  %omp_global_thread_num = call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %0, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %5, ptr %gep_5, align 8
  %gep_6 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 2
  store ptr %4, ptr %gep_6, align 8
  %gep_7 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 3
  store ptr %3, ptr %gep_7, align 8
  %gep_8 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 4
  store ptr %2, ptr %gep_8, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QFPomp_subroutine..omp_par, ptr nonnull %structArg)
  %.fca.0.load = load ptr, ptr %5, align 8, !tbaa !8
  %.fca.7.0.0.load = load i64, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  %11 = sub i64 1, %.fca.7.0.0.load
  %12 = getelementptr double, ptr %.fca.0.load, i64 %11
  %13 = load double, ptr %12, align 8, !tbaa !4
  %14 = load i32, ptr %0, align 4, !tbaa !4
  %15 = sext i32 %14 to i64
  %16 = sub i64 %15, %.fca.7.0.0.load
  %17 = getelementptr double, ptr %.fca.0.load, i64 %16
  %18 = load double, ptr %17, align 8, !tbaa !4
  %19 = fadd contract double %13, %18
  store double %19, ptr %1, align 8, !tbaa !4
  call void @free(ptr %.fca.0.load)
  store ptr null, ptr %5, align 8, !tbaa !8
  store i64 8, ptr %.fca.1.gep, align 8, !tbaa !8
  store i32 20180515, ptr %.fca.2.gep, align 8, !tbaa !8
  store i8 1, ptr %.fca.3.gep, align 4, !tbaa !8
  store i8 28, ptr %.fca.4.gep, align 1, !tbaa !8
  store i8 2, ptr %.fca.5.gep, align 2, !tbaa !8
  store i8 0, ptr %.fca.6.gep, align 1, !tbaa !8
  store i64 1, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  store i64 0, ptr %.fca.7.0.1.gep, align 8, !tbaa !8
  store i64 8, ptr %.fca.7.0.2.gep, align 8, !tbaa !8
  ret void
}
*** IR Dump After SimplifyCFGPass on _QFPomp_subroutine ***
define void @_QFPomp_subroutine(ptr %0, ptr %1, ptr nest %2) local_unnamed_addr {
entry:
  %structArg = alloca { ptr, ptr, ptr, ptr, ptr }, align 8
  %3 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %4 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %5 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  store ptr null, ptr %5, align 8, !tbaa !8
  %.fca.1.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 1
  store i64 8, ptr %.fca.1.gep, align 8, !tbaa !8
  %.fca.2.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 2
  store i32 20180515, ptr %.fca.2.gep, align 8, !tbaa !8
  %.fca.3.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 3
  store i8 1, ptr %.fca.3.gep, align 4, !tbaa !8
  %.fca.4.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 4
  store i8 28, ptr %.fca.4.gep, align 1, !tbaa !8
  %.fca.5.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 5
  store i8 2, ptr %.fca.5.gep, align 2, !tbaa !8
  %.fca.6.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 6
  store i8 0, ptr %.fca.6.gep, align 1, !tbaa !8
  %.fca.7.0.0.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 0
  store i64 1, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  %.fca.7.0.1.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 1
  store i64 0, ptr %.fca.7.0.1.gep, align 8, !tbaa !8
  %.fca.7.0.2.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 2
  store i64 8, ptr %.fca.7.0.2.gep, align 8, !tbaa !8
  %6 = load i32, ptr %0, align 4, !tbaa !4
  %7 = call i32 @llvm.smax.i32(i32 %6, i32 0)
  %8 = zext i32 %7 to i64
  %9 = shl nuw nsw i64 %8, 3
  %10 = call ptr @malloc(i64 %9)
  store ptr %10, ptr %5, align 8, !tbaa !8
  store i64 8, ptr %.fca.1.gep, align 8, !tbaa !8
  store i32 20180515, ptr %.fca.2.gep, align 8, !tbaa !8
  store i8 1, ptr %.fca.3.gep, align 4, !tbaa !8
  store i8 28, ptr %.fca.4.gep, align 1, !tbaa !8
  store i8 2, ptr %.fca.5.gep, align 2, !tbaa !8
  store i8 0, ptr %.fca.6.gep, align 1, !tbaa !8
  store i64 1, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  store i64 %8, ptr %.fca.7.0.1.gep, align 8, !tbaa !8
  store i64 8, ptr %.fca.7.0.2.gep, align 8, !tbaa !8
  %omp_global_thread_num = call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %0, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %5, ptr %gep_5, align 8
  %gep_6 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 2
  store ptr %4, ptr %gep_6, align 8
  %gep_7 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 3
  store ptr %3, ptr %gep_7, align 8
  %gep_8 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 4
  store ptr %2, ptr %gep_8, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QFPomp_subroutine..omp_par, ptr nonnull %structArg)
  %.fca.0.load = load ptr, ptr %5, align 8, !tbaa !8
  %.fca.7.0.0.load = load i64, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  %11 = sub i64 1, %.fca.7.0.0.load
  %12 = getelementptr double, ptr %.fca.0.load, i64 %11
  %13 = load double, ptr %12, align 8, !tbaa !4
  %14 = load i32, ptr %0, align 4, !tbaa !4
  %15 = sext i32 %14 to i64
  %16 = sub i64 %15, %.fca.7.0.0.load
  %17 = getelementptr double, ptr %.fca.0.load, i64 %16
  %18 = load double, ptr %17, align 8, !tbaa !4
  %19 = fadd contract double %13, %18
  store double %19, ptr %1, align 8, !tbaa !4
  call void @free(ptr %.fca.0.load)
  store ptr null, ptr %5, align 8, !tbaa !8
  store i64 8, ptr %.fca.1.gep, align 8, !tbaa !8
  store i32 20180515, ptr %.fca.2.gep, align 8, !tbaa !8
  store i8 1, ptr %.fca.3.gep, align 4, !tbaa !8
  store i8 28, ptr %.fca.4.gep, align 1, !tbaa !8
  store i8 2, ptr %.fca.5.gep, align 2, !tbaa !8
  store i8 0, ptr %.fca.6.gep, align 1, !tbaa !8
  store i64 1, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  store i64 0, ptr %.fca.7.0.1.gep, align 8, !tbaa !8
  store i64 8, ptr %.fca.7.0.2.gep, align 8, !tbaa !8
  ret void
}
*** IR Dump After InstCombinePass on _QFPomp_subroutine ***
define void @_QFPomp_subroutine(ptr %0, ptr %1, ptr nest %2) local_unnamed_addr {
entry:
  %structArg = alloca { ptr, ptr, ptr, ptr, ptr }, align 8
  %3 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %4 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %5 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  store ptr null, ptr %5, align 8, !tbaa !8
  %.fca.1.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 1
  store i64 8, ptr %.fca.1.gep, align 8, !tbaa !8
  %.fca.2.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 2
  store i32 20180515, ptr %.fca.2.gep, align 8, !tbaa !8
  %.fca.3.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 3
  store i8 1, ptr %.fca.3.gep, align 4, !tbaa !8
  %.fca.4.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 4
  store i8 28, ptr %.fca.4.gep, align 1, !tbaa !8
  %.fca.5.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 5
  store i8 2, ptr %.fca.5.gep, align 2, !tbaa !8
  %.fca.6.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 6
  store i8 0, ptr %.fca.6.gep, align 1, !tbaa !8
  %.fca.7.0.0.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 0
  store i64 1, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  %.fca.7.0.1.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 1
  store i64 0, ptr %.fca.7.0.1.gep, align 8, !tbaa !8
  %.fca.7.0.2.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 2
  store i64 8, ptr %.fca.7.0.2.gep, align 8, !tbaa !8
  %6 = load i32, ptr %0, align 4, !tbaa !4
  %7 = call i32 @llvm.smax.i32(i32 %6, i32 0)
  %8 = zext i32 %7 to i64
  %9 = shl nuw nsw i64 %8, 3
  %10 = call ptr @malloc(i64 %9)
  store ptr %10, ptr %5, align 8, !tbaa !8
  store i64 8, ptr %.fca.1.gep, align 8, !tbaa !8
  store i32 20180515, ptr %.fca.2.gep, align 8, !tbaa !8
  store i8 1, ptr %.fca.3.gep, align 4, !tbaa !8
  store i8 28, ptr %.fca.4.gep, align 1, !tbaa !8
  store i8 2, ptr %.fca.5.gep, align 2, !tbaa !8
  store i8 0, ptr %.fca.6.gep, align 1, !tbaa !8
  store i64 1, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  store i64 %8, ptr %.fca.7.0.1.gep, align 8, !tbaa !8
  store i64 8, ptr %.fca.7.0.2.gep, align 8, !tbaa !8
  %omp_global_thread_num = call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %0, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %5, ptr %gep_5, align 8
  %gep_6 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 2
  store ptr %4, ptr %gep_6, align 8
  %gep_7 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 3
  store ptr %3, ptr %gep_7, align 8
  %gep_8 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 4
  store ptr %2, ptr %gep_8, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QFPomp_subroutine..omp_par, ptr nonnull %structArg)
  %.fca.0.load = load ptr, ptr %5, align 8, !tbaa !8
  %.fca.7.0.0.load = load i64, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  %11 = sub i64 1, %.fca.7.0.0.load
  %12 = getelementptr double, ptr %.fca.0.load, i64 %11
  %13 = load double, ptr %12, align 8, !tbaa !4
  %14 = load i32, ptr %0, align 4, !tbaa !4
  %15 = sext i32 %14 to i64
  %16 = sub i64 %15, %.fca.7.0.0.load
  %17 = getelementptr double, ptr %.fca.0.load, i64 %16
  %18 = load double, ptr %17, align 8, !tbaa !4
  %19 = fadd contract double %13, %18
  store double %19, ptr %1, align 8, !tbaa !4
  call void @free(ptr %.fca.0.load)
  store ptr null, ptr %5, align 8, !tbaa !8
  store i64 8, ptr %.fca.1.gep, align 8, !tbaa !8
  store i32 20180515, ptr %.fca.2.gep, align 8, !tbaa !8
  store i8 1, ptr %.fca.3.gep, align 4, !tbaa !8
  store i8 28, ptr %.fca.4.gep, align 1, !tbaa !8
  store i8 2, ptr %.fca.5.gep, align 2, !tbaa !8
  store i8 0, ptr %.fca.6.gep, align 1, !tbaa !8
  store i64 1, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  store i64 0, ptr %.fca.7.0.1.gep, align 8, !tbaa !8
  store i64 8, ptr %.fca.7.0.2.gep, align 8, !tbaa !8
  ret void
}
*** IR Dump After AggressiveInstCombinePass on _QFPomp_subroutine ***
define void @_QFPomp_subroutine(ptr %0, ptr %1, ptr nest %2) local_unnamed_addr {
entry:
  %structArg = alloca { ptr, ptr, ptr, ptr, ptr }, align 8
  %3 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %4 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %5 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  store ptr null, ptr %5, align 8, !tbaa !8
  %.fca.1.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 1
  store i64 8, ptr %.fca.1.gep, align 8, !tbaa !8
  %.fca.2.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 2
  store i32 20180515, ptr %.fca.2.gep, align 8, !tbaa !8
  %.fca.3.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 3
  store i8 1, ptr %.fca.3.gep, align 4, !tbaa !8
  %.fca.4.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 4
  store i8 28, ptr %.fca.4.gep, align 1, !tbaa !8
  %.fca.5.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 5
  store i8 2, ptr %.fca.5.gep, align 2, !tbaa !8
  %.fca.6.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 6
  store i8 0, ptr %.fca.6.gep, align 1, !tbaa !8
  %.fca.7.0.0.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 0
  store i64 1, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  %.fca.7.0.1.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 1
  store i64 0, ptr %.fca.7.0.1.gep, align 8, !tbaa !8
  %.fca.7.0.2.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 2
  store i64 8, ptr %.fca.7.0.2.gep, align 8, !tbaa !8
  %6 = load i32, ptr %0, align 4, !tbaa !4
  %7 = call i32 @llvm.smax.i32(i32 %6, i32 0)
  %8 = zext i32 %7 to i64
  %9 = shl nuw nsw i64 %8, 3
  %10 = call ptr @malloc(i64 %9)
  store ptr %10, ptr %5, align 8, !tbaa !8
  store i64 8, ptr %.fca.1.gep, align 8, !tbaa !8
  store i32 20180515, ptr %.fca.2.gep, align 8, !tbaa !8
  store i8 1, ptr %.fca.3.gep, align 4, !tbaa !8
  store i8 28, ptr %.fca.4.gep, align 1, !tbaa !8
  store i8 2, ptr %.fca.5.gep, align 2, !tbaa !8
  store i8 0, ptr %.fca.6.gep, align 1, !tbaa !8
  store i64 1, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  store i64 %8, ptr %.fca.7.0.1.gep, align 8, !tbaa !8
  store i64 8, ptr %.fca.7.0.2.gep, align 8, !tbaa !8
  %omp_global_thread_num = call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %0, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %5, ptr %gep_5, align 8
  %gep_6 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 2
  store ptr %4, ptr %gep_6, align 8
  %gep_7 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 3
  store ptr %3, ptr %gep_7, align 8
  %gep_8 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 4
  store ptr %2, ptr %gep_8, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QFPomp_subroutine..omp_par, ptr nonnull %structArg)
  %.fca.0.load = load ptr, ptr %5, align 8, !tbaa !8
  %.fca.7.0.0.load = load i64, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  %11 = sub i64 1, %.fca.7.0.0.load
  %12 = getelementptr double, ptr %.fca.0.load, i64 %11
  %13 = load double, ptr %12, align 8, !tbaa !4
  %14 = load i32, ptr %0, align 4, !tbaa !4
  %15 = sext i32 %14 to i64
  %16 = sub i64 %15, %.fca.7.0.0.load
  %17 = getelementptr double, ptr %.fca.0.load, i64 %16
  %18 = load double, ptr %17, align 8, !tbaa !4
  %19 = fadd contract double %13, %18
  store double %19, ptr %1, align 8, !tbaa !4
  call void @free(ptr %.fca.0.load)
  store ptr null, ptr %5, align 8, !tbaa !8
  store i64 8, ptr %.fca.1.gep, align 8, !tbaa !8
  store i32 20180515, ptr %.fca.2.gep, align 8, !tbaa !8
  store i8 1, ptr %.fca.3.gep, align 4, !tbaa !8
  store i8 28, ptr %.fca.4.gep, align 1, !tbaa !8
  store i8 2, ptr %.fca.5.gep, align 2, !tbaa !8
  store i8 0, ptr %.fca.6.gep, align 1, !tbaa !8
  store i64 1, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  store i64 0, ptr %.fca.7.0.1.gep, align 8, !tbaa !8
  store i64 8, ptr %.fca.7.0.2.gep, align 8, !tbaa !8
  ret void
}
*** IR Dump After ConstraintEliminationPass on _QFPomp_subroutine ***
define void @_QFPomp_subroutine(ptr %0, ptr %1, ptr nest %2) local_unnamed_addr {
entry:
  %structArg = alloca { ptr, ptr, ptr, ptr, ptr }, align 8
  %3 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %4 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %5 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  store ptr null, ptr %5, align 8, !tbaa !8
  %.fca.1.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 1
  store i64 8, ptr %.fca.1.gep, align 8, !tbaa !8
  %.fca.2.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 2
  store i32 20180515, ptr %.fca.2.gep, align 8, !tbaa !8
  %.fca.3.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 3
  store i8 1, ptr %.fca.3.gep, align 4, !tbaa !8
  %.fca.4.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 4
  store i8 28, ptr %.fca.4.gep, align 1, !tbaa !8
  %.fca.5.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 5
  store i8 2, ptr %.fca.5.gep, align 2, !tbaa !8
  %.fca.6.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 6
  store i8 0, ptr %.fca.6.gep, align 1, !tbaa !8
  %.fca.7.0.0.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 0
  store i64 1, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  %.fca.7.0.1.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 1
  store i64 0, ptr %.fca.7.0.1.gep, align 8, !tbaa !8
  %.fca.7.0.2.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 2
  store i64 8, ptr %.fca.7.0.2.gep, align 8, !tbaa !8
  %6 = load i32, ptr %0, align 4, !tbaa !4
  %7 = call i32 @llvm.smax.i32(i32 %6, i32 0)
  %8 = zext i32 %7 to i64
  %9 = shl nuw nsw i64 %8, 3
  %10 = call ptr @malloc(i64 %9)
  store ptr %10, ptr %5, align 8, !tbaa !8
  store i64 8, ptr %.fca.1.gep, align 8, !tbaa !8
  store i32 20180515, ptr %.fca.2.gep, align 8, !tbaa !8
  store i8 1, ptr %.fca.3.gep, align 4, !tbaa !8
  store i8 28, ptr %.fca.4.gep, align 1, !tbaa !8
  store i8 2, ptr %.fca.5.gep, align 2, !tbaa !8
  store i8 0, ptr %.fca.6.gep, align 1, !tbaa !8
  store i64 1, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  store i64 %8, ptr %.fca.7.0.1.gep, align 8, !tbaa !8
  store i64 8, ptr %.fca.7.0.2.gep, align 8, !tbaa !8
  %omp_global_thread_num = call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %0, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %5, ptr %gep_5, align 8
  %gep_6 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 2
  store ptr %4, ptr %gep_6, align 8
  %gep_7 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 3
  store ptr %3, ptr %gep_7, align 8
  %gep_8 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 4
  store ptr %2, ptr %gep_8, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QFPomp_subroutine..omp_par, ptr nonnull %structArg)
  %.fca.0.load = load ptr, ptr %5, align 8, !tbaa !8
  %.fca.7.0.0.load = load i64, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  %11 = sub i64 1, %.fca.7.0.0.load
  %12 = getelementptr double, ptr %.fca.0.load, i64 %11
  %13 = load double, ptr %12, align 8, !tbaa !4
  %14 = load i32, ptr %0, align 4, !tbaa !4
  %15 = sext i32 %14 to i64
  %16 = sub i64 %15, %.fca.7.0.0.load
  %17 = getelementptr double, ptr %.fca.0.load, i64 %16
  %18 = load double, ptr %17, align 8, !tbaa !4
  %19 = fadd contract double %13, %18
  store double %19, ptr %1, align 8, !tbaa !4
  call void @free(ptr %.fca.0.load)
  store ptr null, ptr %5, align 8, !tbaa !8
  store i64 8, ptr %.fca.1.gep, align 8, !tbaa !8
  store i32 20180515, ptr %.fca.2.gep, align 8, !tbaa !8
  store i8 1, ptr %.fca.3.gep, align 4, !tbaa !8
  store i8 28, ptr %.fca.4.gep, align 1, !tbaa !8
  store i8 2, ptr %.fca.5.gep, align 2, !tbaa !8
  store i8 0, ptr %.fca.6.gep, align 1, !tbaa !8
  store i64 1, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  store i64 0, ptr %.fca.7.0.1.gep, align 8, !tbaa !8
  store i64 8, ptr %.fca.7.0.2.gep, align 8, !tbaa !8
  ret void
}
*** IR Dump After LibCallsShrinkWrapPass on _QFPomp_subroutine ***
define void @_QFPomp_subroutine(ptr %0, ptr %1, ptr nest %2) local_unnamed_addr {
entry:
  %structArg = alloca { ptr, ptr, ptr, ptr, ptr }, align 8
  %3 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %4 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %5 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  store ptr null, ptr %5, align 8, !tbaa !8
  %.fca.1.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 1
  store i64 8, ptr %.fca.1.gep, align 8, !tbaa !8
  %.fca.2.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 2
  store i32 20180515, ptr %.fca.2.gep, align 8, !tbaa !8
  %.fca.3.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 3
  store i8 1, ptr %.fca.3.gep, align 4, !tbaa !8
  %.fca.4.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 4
  store i8 28, ptr %.fca.4.gep, align 1, !tbaa !8
  %.fca.5.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 5
  store i8 2, ptr %.fca.5.gep, align 2, !tbaa !8
  %.fca.6.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 6
  store i8 0, ptr %.fca.6.gep, align 1, !tbaa !8
  %.fca.7.0.0.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 0
  store i64 1, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  %.fca.7.0.1.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 1
  store i64 0, ptr %.fca.7.0.1.gep, align 8, !tbaa !8
  %.fca.7.0.2.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 2
  store i64 8, ptr %.fca.7.0.2.gep, align 8, !tbaa !8
  %6 = load i32, ptr %0, align 4, !tbaa !4
  %7 = call i32 @llvm.smax.i32(i32 %6, i32 0)
  %8 = zext i32 %7 to i64
  %9 = shl nuw nsw i64 %8, 3
  %10 = call ptr @malloc(i64 %9)
  store ptr %10, ptr %5, align 8, !tbaa !8
  store i64 8, ptr %.fca.1.gep, align 8, !tbaa !8
  store i32 20180515, ptr %.fca.2.gep, align 8, !tbaa !8
  store i8 1, ptr %.fca.3.gep, align 4, !tbaa !8
  store i8 28, ptr %.fca.4.gep, align 1, !tbaa !8
  store i8 2, ptr %.fca.5.gep, align 2, !tbaa !8
  store i8 0, ptr %.fca.6.gep, align 1, !tbaa !8
  store i64 1, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  store i64 %8, ptr %.fca.7.0.1.gep, align 8, !tbaa !8
  store i64 8, ptr %.fca.7.0.2.gep, align 8, !tbaa !8
  %omp_global_thread_num = call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %0, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %5, ptr %gep_5, align 8
  %gep_6 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 2
  store ptr %4, ptr %gep_6, align 8
  %gep_7 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 3
  store ptr %3, ptr %gep_7, align 8
  %gep_8 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 4
  store ptr %2, ptr %gep_8, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QFPomp_subroutine..omp_par, ptr nonnull %structArg)
  %.fca.0.load = load ptr, ptr %5, align 8, !tbaa !8
  %.fca.7.0.0.load = load i64, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  %11 = sub i64 1, %.fca.7.0.0.load
  %12 = getelementptr double, ptr %.fca.0.load, i64 %11
  %13 = load double, ptr %12, align 8, !tbaa !4
  %14 = load i32, ptr %0, align 4, !tbaa !4
  %15 = sext i32 %14 to i64
  %16 = sub i64 %15, %.fca.7.0.0.load
  %17 = getelementptr double, ptr %.fca.0.load, i64 %16
  %18 = load double, ptr %17, align 8, !tbaa !4
  %19 = fadd contract double %13, %18
  store double %19, ptr %1, align 8, !tbaa !4
  call void @free(ptr %.fca.0.load)
  store ptr null, ptr %5, align 8, !tbaa !8
  store i64 8, ptr %.fca.1.gep, align 8, !tbaa !8
  store i32 20180515, ptr %.fca.2.gep, align 8, !tbaa !8
  store i8 1, ptr %.fca.3.gep, align 4, !tbaa !8
  store i8 28, ptr %.fca.4.gep, align 1, !tbaa !8
  store i8 2, ptr %.fca.5.gep, align 2, !tbaa !8
  store i8 0, ptr %.fca.6.gep, align 1, !tbaa !8
  store i64 1, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  store i64 0, ptr %.fca.7.0.1.gep, align 8, !tbaa !8
  store i64 8, ptr %.fca.7.0.2.gep, align 8, !tbaa !8
  ret void
}
*** IR Dump After TailCallElimPass on _QFPomp_subroutine ***
define void @_QFPomp_subroutine(ptr %0, ptr %1, ptr nest %2) local_unnamed_addr {
entry:
  %structArg = alloca { ptr, ptr, ptr, ptr, ptr }, align 8
  %3 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %4 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %5 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  store ptr null, ptr %5, align 8, !tbaa !8
  %.fca.1.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 1
  store i64 8, ptr %.fca.1.gep, align 8, !tbaa !8
  %.fca.2.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 2
  store i32 20180515, ptr %.fca.2.gep, align 8, !tbaa !8
  %.fca.3.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 3
  store i8 1, ptr %.fca.3.gep, align 4, !tbaa !8
  %.fca.4.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 4
  store i8 28, ptr %.fca.4.gep, align 1, !tbaa !8
  %.fca.5.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 5
  store i8 2, ptr %.fca.5.gep, align 2, !tbaa !8
  %.fca.6.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 6
  store i8 0, ptr %.fca.6.gep, align 1, !tbaa !8
  %.fca.7.0.0.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 0
  store i64 1, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  %.fca.7.0.1.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 1
  store i64 0, ptr %.fca.7.0.1.gep, align 8, !tbaa !8
  %.fca.7.0.2.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 2
  store i64 8, ptr %.fca.7.0.2.gep, align 8, !tbaa !8
  %6 = load i32, ptr %0, align 4, !tbaa !4
  %7 = tail call i32 @llvm.smax.i32(i32 %6, i32 0)
  %8 = zext i32 %7 to i64
  %9 = shl nuw nsw i64 %8, 3
  %10 = tail call ptr @malloc(i64 %9)
  store ptr %10, ptr %5, align 8, !tbaa !8
  store i64 8, ptr %.fca.1.gep, align 8, !tbaa !8
  store i32 20180515, ptr %.fca.2.gep, align 8, !tbaa !8
  store i8 1, ptr %.fca.3.gep, align 4, !tbaa !8
  store i8 28, ptr %.fca.4.gep, align 1, !tbaa !8
  store i8 2, ptr %.fca.5.gep, align 2, !tbaa !8
  store i8 0, ptr %.fca.6.gep, align 1, !tbaa !8
  store i64 1, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  store i64 %8, ptr %.fca.7.0.1.gep, align 8, !tbaa !8
  store i64 8, ptr %.fca.7.0.2.gep, align 8, !tbaa !8
  %omp_global_thread_num = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %0, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %5, ptr %gep_5, align 8
  %gep_6 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 2
  store ptr %4, ptr %gep_6, align 8
  %gep_7 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 3
  store ptr %3, ptr %gep_7, align 8
  %gep_8 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 4
  store ptr %2, ptr %gep_8, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QFPomp_subroutine..omp_par, ptr nonnull %structArg)
  %.fca.0.load = load ptr, ptr %5, align 8, !tbaa !8
  %.fca.7.0.0.load = load i64, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  %11 = sub i64 1, %.fca.7.0.0.load
  %12 = getelementptr double, ptr %.fca.0.load, i64 %11
  %13 = load double, ptr %12, align 8, !tbaa !4
  %14 = load i32, ptr %0, align 4, !tbaa !4
  %15 = sext i32 %14 to i64
  %16 = sub i64 %15, %.fca.7.0.0.load
  %17 = getelementptr double, ptr %.fca.0.load, i64 %16
  %18 = load double, ptr %17, align 8, !tbaa !4
  %19 = fadd contract double %13, %18
  store double %19, ptr %1, align 8, !tbaa !4
  call void @free(ptr %.fca.0.load)
  store ptr null, ptr %5, align 8, !tbaa !8
  store i64 8, ptr %.fca.1.gep, align 8, !tbaa !8
  store i32 20180515, ptr %.fca.2.gep, align 8, !tbaa !8
  store i8 1, ptr %.fca.3.gep, align 4, !tbaa !8
  store i8 28, ptr %.fca.4.gep, align 1, !tbaa !8
  store i8 2, ptr %.fca.5.gep, align 2, !tbaa !8
  store i8 0, ptr %.fca.6.gep, align 1, !tbaa !8
  store i64 1, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  store i64 0, ptr %.fca.7.0.1.gep, align 8, !tbaa !8
  store i64 8, ptr %.fca.7.0.2.gep, align 8, !tbaa !8
  ret void
}
*** IR Dump After SimplifyCFGPass on _QFPomp_subroutine ***
define void @_QFPomp_subroutine(ptr %0, ptr %1, ptr nest %2) local_unnamed_addr {
entry:
  %structArg = alloca { ptr, ptr, ptr, ptr, ptr }, align 8
  %3 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %4 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %5 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  store ptr null, ptr %5, align 8, !tbaa !8
  %.fca.1.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 1
  store i64 8, ptr %.fca.1.gep, align 8, !tbaa !8
  %.fca.2.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 2
  store i32 20180515, ptr %.fca.2.gep, align 8, !tbaa !8
  %.fca.3.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 3
  store i8 1, ptr %.fca.3.gep, align 4, !tbaa !8
  %.fca.4.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 4
  store i8 28, ptr %.fca.4.gep, align 1, !tbaa !8
  %.fca.5.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 5
  store i8 2, ptr %.fca.5.gep, align 2, !tbaa !8
  %.fca.6.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 6
  store i8 0, ptr %.fca.6.gep, align 1, !tbaa !8
  %.fca.7.0.0.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 0
  store i64 1, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  %.fca.7.0.1.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 1
  store i64 0, ptr %.fca.7.0.1.gep, align 8, !tbaa !8
  %.fca.7.0.2.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 2
  store i64 8, ptr %.fca.7.0.2.gep, align 8, !tbaa !8
  %6 = load i32, ptr %0, align 4, !tbaa !4
  %7 = tail call i32 @llvm.smax.i32(i32 %6, i32 0)
  %8 = zext i32 %7 to i64
  %9 = shl nuw nsw i64 %8, 3
  %10 = tail call ptr @malloc(i64 %9)
  store ptr %10, ptr %5, align 8, !tbaa !8
  store i64 8, ptr %.fca.1.gep, align 8, !tbaa !8
  store i32 20180515, ptr %.fca.2.gep, align 8, !tbaa !8
  store i8 1, ptr %.fca.3.gep, align 4, !tbaa !8
  store i8 28, ptr %.fca.4.gep, align 1, !tbaa !8
  store i8 2, ptr %.fca.5.gep, align 2, !tbaa !8
  store i8 0, ptr %.fca.6.gep, align 1, !tbaa !8
  store i64 1, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  store i64 %8, ptr %.fca.7.0.1.gep, align 8, !tbaa !8
  store i64 8, ptr %.fca.7.0.2.gep, align 8, !tbaa !8
  %omp_global_thread_num = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %0, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %5, ptr %gep_5, align 8
  %gep_6 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 2
  store ptr %4, ptr %gep_6, align 8
  %gep_7 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 3
  store ptr %3, ptr %gep_7, align 8
  %gep_8 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 4
  store ptr %2, ptr %gep_8, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QFPomp_subroutine..omp_par, ptr nonnull %structArg)
  %.fca.0.load = load ptr, ptr %5, align 8, !tbaa !8
  %.fca.7.0.0.load = load i64, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  %11 = sub i64 1, %.fca.7.0.0.load
  %12 = getelementptr double, ptr %.fca.0.load, i64 %11
  %13 = load double, ptr %12, align 8, !tbaa !4
  %14 = load i32, ptr %0, align 4, !tbaa !4
  %15 = sext i32 %14 to i64
  %16 = sub i64 %15, %.fca.7.0.0.load
  %17 = getelementptr double, ptr %.fca.0.load, i64 %16
  %18 = load double, ptr %17, align 8, !tbaa !4
  %19 = fadd contract double %13, %18
  store double %19, ptr %1, align 8, !tbaa !4
  call void @free(ptr %.fca.0.load)
  store ptr null, ptr %5, align 8, !tbaa !8
  store i64 8, ptr %.fca.1.gep, align 8, !tbaa !8
  store i32 20180515, ptr %.fca.2.gep, align 8, !tbaa !8
  store i8 1, ptr %.fca.3.gep, align 4, !tbaa !8
  store i8 28, ptr %.fca.4.gep, align 1, !tbaa !8
  store i8 2, ptr %.fca.5.gep, align 2, !tbaa !8
  store i8 0, ptr %.fca.6.gep, align 1, !tbaa !8
  store i64 1, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  store i64 0, ptr %.fca.7.0.1.gep, align 8, !tbaa !8
  store i64 8, ptr %.fca.7.0.2.gep, align 8, !tbaa !8
  ret void
}
*** IR Dump After ReassociatePass on _QFPomp_subroutine ***
define void @_QFPomp_subroutine(ptr %0, ptr %1, ptr nest %2) local_unnamed_addr {
entry:
  %structArg = alloca { ptr, ptr, ptr, ptr, ptr }, align 8
  %3 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %4 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %5 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  store ptr null, ptr %5, align 8, !tbaa !8
  %.fca.1.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 1
  store i64 8, ptr %.fca.1.gep, align 8, !tbaa !8
  %.fca.2.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 2
  store i32 20180515, ptr %.fca.2.gep, align 8, !tbaa !8
  %.fca.3.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 3
  store i8 1, ptr %.fca.3.gep, align 4, !tbaa !8
  %.fca.4.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 4
  store i8 28, ptr %.fca.4.gep, align 1, !tbaa !8
  %.fca.5.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 5
  store i8 2, ptr %.fca.5.gep, align 2, !tbaa !8
  %.fca.6.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 6
  store i8 0, ptr %.fca.6.gep, align 1, !tbaa !8
  %.fca.7.0.0.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 0
  store i64 1, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  %.fca.7.0.1.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 1
  store i64 0, ptr %.fca.7.0.1.gep, align 8, !tbaa !8
  %.fca.7.0.2.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 2
  store i64 8, ptr %.fca.7.0.2.gep, align 8, !tbaa !8
  %6 = load i32, ptr %0, align 4, !tbaa !4
  %7 = tail call i32 @llvm.smax.i32(i32 %6, i32 0)
  %8 = zext i32 %7 to i64
  %9 = shl nuw nsw i64 %8, 3
  %10 = tail call ptr @malloc(i64 %9)
  store ptr %10, ptr %5, align 8, !tbaa !8
  store i64 8, ptr %.fca.1.gep, align 8, !tbaa !8
  store i32 20180515, ptr %.fca.2.gep, align 8, !tbaa !8
  store i8 1, ptr %.fca.3.gep, align 4, !tbaa !8
  store i8 28, ptr %.fca.4.gep, align 1, !tbaa !8
  store i8 2, ptr %.fca.5.gep, align 2, !tbaa !8
  store i8 0, ptr %.fca.6.gep, align 1, !tbaa !8
  store i64 1, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  store i64 %8, ptr %.fca.7.0.1.gep, align 8, !tbaa !8
  store i64 8, ptr %.fca.7.0.2.gep, align 8, !tbaa !8
  %omp_global_thread_num = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %0, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %5, ptr %gep_5, align 8
  %gep_6 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 2
  store ptr %4, ptr %gep_6, align 8
  %gep_7 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 3
  store ptr %3, ptr %gep_7, align 8
  %gep_8 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 4
  store ptr %2, ptr %gep_8, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QFPomp_subroutine..omp_par, ptr nonnull %structArg)
  %.fca.0.load = load ptr, ptr %5, align 8, !tbaa !8
  %.fca.7.0.0.load = load i64, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  %11 = sub i64 1, %.fca.7.0.0.load
  %12 = getelementptr double, ptr %.fca.0.load, i64 %11
  %13 = load double, ptr %12, align 8, !tbaa !4
  %14 = load i32, ptr %0, align 4, !tbaa !4
  %15 = sext i32 %14 to i64
  %16 = sub i64 %15, %.fca.7.0.0.load
  %17 = getelementptr double, ptr %.fca.0.load, i64 %16
  %18 = load double, ptr %17, align 8, !tbaa !4
  %19 = fadd contract double %13, %18
  store double %19, ptr %1, align 8, !tbaa !4
  call void @free(ptr %.fca.0.load)
  store ptr null, ptr %5, align 8, !tbaa !8
  store i64 8, ptr %.fca.1.gep, align 8, !tbaa !8
  store i32 20180515, ptr %.fca.2.gep, align 8, !tbaa !8
  store i8 1, ptr %.fca.3.gep, align 4, !tbaa !8
  store i8 28, ptr %.fca.4.gep, align 1, !tbaa !8
  store i8 2, ptr %.fca.5.gep, align 2, !tbaa !8
  store i8 0, ptr %.fca.6.gep, align 1, !tbaa !8
  store i64 1, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  store i64 0, ptr %.fca.7.0.1.gep, align 8, !tbaa !8
  store i64 8, ptr %.fca.7.0.2.gep, align 8, !tbaa !8
  ret void
}
*** IR Dump After LoopSimplifyPass on _QFPomp_subroutine ***
define void @_QFPomp_subroutine(ptr %0, ptr %1, ptr nest %2) local_unnamed_addr {
entry:
  %structArg = alloca { ptr, ptr, ptr, ptr, ptr }, align 8
  %3 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %4 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %5 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  store ptr null, ptr %5, align 8, !tbaa !8
  %.fca.1.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 1
  store i64 8, ptr %.fca.1.gep, align 8, !tbaa !8
  %.fca.2.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 2
  store i32 20180515, ptr %.fca.2.gep, align 8, !tbaa !8
  %.fca.3.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 3
  store i8 1, ptr %.fca.3.gep, align 4, !tbaa !8
  %.fca.4.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 4
  store i8 28, ptr %.fca.4.gep, align 1, !tbaa !8
  %.fca.5.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 5
  store i8 2, ptr %.fca.5.gep, align 2, !tbaa !8
  %.fca.6.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 6
  store i8 0, ptr %.fca.6.gep, align 1, !tbaa !8
  %.fca.7.0.0.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 0
  store i64 1, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  %.fca.7.0.1.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 1
  store i64 0, ptr %.fca.7.0.1.gep, align 8, !tbaa !8
  %.fca.7.0.2.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 2
  store i64 8, ptr %.fca.7.0.2.gep, align 8, !tbaa !8
  %6 = load i32, ptr %0, align 4, !tbaa !4
  %7 = tail call i32 @llvm.smax.i32(i32 %6, i32 0)
  %8 = zext i32 %7 to i64
  %9 = shl nuw nsw i64 %8, 3
  %10 = tail call ptr @malloc(i64 %9)
  store ptr %10, ptr %5, align 8, !tbaa !8
  store i64 8, ptr %.fca.1.gep, align 8, !tbaa !8
  store i32 20180515, ptr %.fca.2.gep, align 8, !tbaa !8
  store i8 1, ptr %.fca.3.gep, align 4, !tbaa !8
  store i8 28, ptr %.fca.4.gep, align 1, !tbaa !8
  store i8 2, ptr %.fca.5.gep, align 2, !tbaa !8
  store i8 0, ptr %.fca.6.gep, align 1, !tbaa !8
  store i64 1, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  store i64 %8, ptr %.fca.7.0.1.gep, align 8, !tbaa !8
  store i64 8, ptr %.fca.7.0.2.gep, align 8, !tbaa !8
  %omp_global_thread_num = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %0, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %5, ptr %gep_5, align 8
  %gep_6 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 2
  store ptr %4, ptr %gep_6, align 8
  %gep_7 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 3
  store ptr %3, ptr %gep_7, align 8
  %gep_8 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 4
  store ptr %2, ptr %gep_8, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QFPomp_subroutine..omp_par, ptr nonnull %structArg)
  %.fca.0.load = load ptr, ptr %5, align 8, !tbaa !8
  %.fca.7.0.0.load = load i64, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  %11 = sub i64 1, %.fca.7.0.0.load
  %12 = getelementptr double, ptr %.fca.0.load, i64 %11
  %13 = load double, ptr %12, align 8, !tbaa !4
  %14 = load i32, ptr %0, align 4, !tbaa !4
  %15 = sext i32 %14 to i64
  %16 = sub i64 %15, %.fca.7.0.0.load
  %17 = getelementptr double, ptr %.fca.0.load, i64 %16
  %18 = load double, ptr %17, align 8, !tbaa !4
  %19 = fadd contract double %13, %18
  store double %19, ptr %1, align 8, !tbaa !4
  call void @free(ptr %.fca.0.load)
  store ptr null, ptr %5, align 8, !tbaa !8
  store i64 8, ptr %.fca.1.gep, align 8, !tbaa !8
  store i32 20180515, ptr %.fca.2.gep, align 8, !tbaa !8
  store i8 1, ptr %.fca.3.gep, align 4, !tbaa !8
  store i8 28, ptr %.fca.4.gep, align 1, !tbaa !8
  store i8 2, ptr %.fca.5.gep, align 2, !tbaa !8
  store i8 0, ptr %.fca.6.gep, align 1, !tbaa !8
  store i64 1, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  store i64 0, ptr %.fca.7.0.1.gep, align 8, !tbaa !8
  store i64 8, ptr %.fca.7.0.2.gep, align 8, !tbaa !8
  ret void
}
*** IR Dump After LCSSAPass on _QFPomp_subroutine ***
define void @_QFPomp_subroutine(ptr %0, ptr %1, ptr nest %2) local_unnamed_addr {
entry:
  %structArg = alloca { ptr, ptr, ptr, ptr, ptr }, align 8
  %3 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %4 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %5 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  store ptr null, ptr %5, align 8, !tbaa !8
  %.fca.1.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 1
  store i64 8, ptr %.fca.1.gep, align 8, !tbaa !8
  %.fca.2.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 2
  store i32 20180515, ptr %.fca.2.gep, align 8, !tbaa !8
  %.fca.3.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 3
  store i8 1, ptr %.fca.3.gep, align 4, !tbaa !8
  %.fca.4.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 4
  store i8 28, ptr %.fca.4.gep, align 1, !tbaa !8
  %.fca.5.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 5
  store i8 2, ptr %.fca.5.gep, align 2, !tbaa !8
  %.fca.6.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 6
  store i8 0, ptr %.fca.6.gep, align 1, !tbaa !8
  %.fca.7.0.0.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 0
  store i64 1, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  %.fca.7.0.1.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 1
  store i64 0, ptr %.fca.7.0.1.gep, align 8, !tbaa !8
  %.fca.7.0.2.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 2
  store i64 8, ptr %.fca.7.0.2.gep, align 8, !tbaa !8
  %6 = load i32, ptr %0, align 4, !tbaa !4
  %7 = tail call i32 @llvm.smax.i32(i32 %6, i32 0)
  %8 = zext i32 %7 to i64
  %9 = shl nuw nsw i64 %8, 3
  %10 = tail call ptr @malloc(i64 %9)
  store ptr %10, ptr %5, align 8, !tbaa !8
  store i64 8, ptr %.fca.1.gep, align 8, !tbaa !8
  store i32 20180515, ptr %.fca.2.gep, align 8, !tbaa !8
  store i8 1, ptr %.fca.3.gep, align 4, !tbaa !8
  store i8 28, ptr %.fca.4.gep, align 1, !tbaa !8
  store i8 2, ptr %.fca.5.gep, align 2, !tbaa !8
  store i8 0, ptr %.fca.6.gep, align 1, !tbaa !8
  store i64 1, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  store i64 %8, ptr %.fca.7.0.1.gep, align 8, !tbaa !8
  store i64 8, ptr %.fca.7.0.2.gep, align 8, !tbaa !8
  %omp_global_thread_num = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %0, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %5, ptr %gep_5, align 8
  %gep_6 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 2
  store ptr %4, ptr %gep_6, align 8
  %gep_7 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 3
  store ptr %3, ptr %gep_7, align 8
  %gep_8 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 4
  store ptr %2, ptr %gep_8, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QFPomp_subroutine..omp_par, ptr nonnull %structArg)
  %.fca.0.load = load ptr, ptr %5, align 8, !tbaa !8
  %.fca.7.0.0.load = load i64, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  %11 = sub i64 1, %.fca.7.0.0.load
  %12 = getelementptr double, ptr %.fca.0.load, i64 %11
  %13 = load double, ptr %12, align 8, !tbaa !4
  %14 = load i32, ptr %0, align 4, !tbaa !4
  %15 = sext i32 %14 to i64
  %16 = sub i64 %15, %.fca.7.0.0.load
  %17 = getelementptr double, ptr %.fca.0.load, i64 %16
  %18 = load double, ptr %17, align 8, !tbaa !4
  %19 = fadd contract double %13, %18
  store double %19, ptr %1, align 8, !tbaa !4
  call void @free(ptr %.fca.0.load)
  store ptr null, ptr %5, align 8, !tbaa !8
  store i64 8, ptr %.fca.1.gep, align 8, !tbaa !8
  store i32 20180515, ptr %.fca.2.gep, align 8, !tbaa !8
  store i8 1, ptr %.fca.3.gep, align 4, !tbaa !8
  store i8 28, ptr %.fca.4.gep, align 1, !tbaa !8
  store i8 2, ptr %.fca.5.gep, align 2, !tbaa !8
  store i8 0, ptr %.fca.6.gep, align 1, !tbaa !8
  store i64 1, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  store i64 0, ptr %.fca.7.0.1.gep, align 8, !tbaa !8
  store i64 8, ptr %.fca.7.0.2.gep, align 8, !tbaa !8
  ret void
}
*** IR Dump After SimplifyCFGPass on _QFPomp_subroutine ***
define void @_QFPomp_subroutine(ptr %0, ptr %1, ptr nest %2) local_unnamed_addr {
entry:
  %structArg = alloca { ptr, ptr, ptr, ptr, ptr }, align 8
  %3 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %4 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %5 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  store ptr null, ptr %5, align 8, !tbaa !8
  %.fca.1.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 1
  store i64 8, ptr %.fca.1.gep, align 8, !tbaa !8
  %.fca.2.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 2
  store i32 20180515, ptr %.fca.2.gep, align 8, !tbaa !8
  %.fca.3.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 3
  store i8 1, ptr %.fca.3.gep, align 4, !tbaa !8
  %.fca.4.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 4
  store i8 28, ptr %.fca.4.gep, align 1, !tbaa !8
  %.fca.5.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 5
  store i8 2, ptr %.fca.5.gep, align 2, !tbaa !8
  %.fca.6.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 6
  store i8 0, ptr %.fca.6.gep, align 1, !tbaa !8
  %.fca.7.0.0.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 0
  store i64 1, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  %.fca.7.0.1.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 1
  store i64 0, ptr %.fca.7.0.1.gep, align 8, !tbaa !8
  %.fca.7.0.2.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 2
  store i64 8, ptr %.fca.7.0.2.gep, align 8, !tbaa !8
  %6 = load i32, ptr %0, align 4, !tbaa !4
  %7 = tail call i32 @llvm.smax.i32(i32 %6, i32 0)
  %8 = zext i32 %7 to i64
  %9 = shl nuw nsw i64 %8, 3
  %10 = tail call ptr @malloc(i64 %9)
  store ptr %10, ptr %5, align 8, !tbaa !8
  store i64 8, ptr %.fca.1.gep, align 8, !tbaa !8
  store i32 20180515, ptr %.fca.2.gep, align 8, !tbaa !8
  store i8 1, ptr %.fca.3.gep, align 4, !tbaa !8
  store i8 28, ptr %.fca.4.gep, align 1, !tbaa !8
  store i8 2, ptr %.fca.5.gep, align 2, !tbaa !8
  store i8 0, ptr %.fca.6.gep, align 1, !tbaa !8
  store i64 1, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  store i64 %8, ptr %.fca.7.0.1.gep, align 8, !tbaa !8
  store i64 8, ptr %.fca.7.0.2.gep, align 8, !tbaa !8
  %omp_global_thread_num = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %0, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %5, ptr %gep_5, align 8
  %gep_6 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 2
  store ptr %4, ptr %gep_6, align 8
  %gep_7 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 3
  store ptr %3, ptr %gep_7, align 8
  %gep_8 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 4
  store ptr %2, ptr %gep_8, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QFPomp_subroutine..omp_par, ptr nonnull %structArg)
  %.fca.0.load = load ptr, ptr %5, align 8, !tbaa !8
  %.fca.7.0.0.load = load i64, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  %11 = sub i64 1, %.fca.7.0.0.load
  %12 = getelementptr double, ptr %.fca.0.load, i64 %11
  %13 = load double, ptr %12, align 8, !tbaa !4
  %14 = load i32, ptr %0, align 4, !tbaa !4
  %15 = sext i32 %14 to i64
  %16 = sub i64 %15, %.fca.7.0.0.load
  %17 = getelementptr double, ptr %.fca.0.load, i64 %16
  %18 = load double, ptr %17, align 8, !tbaa !4
  %19 = fadd contract double %13, %18
  store double %19, ptr %1, align 8, !tbaa !4
  call void @free(ptr %.fca.0.load)
  store ptr null, ptr %5, align 8, !tbaa !8
  store i64 8, ptr %.fca.1.gep, align 8, !tbaa !8
  store i32 20180515, ptr %.fca.2.gep, align 8, !tbaa !8
  store i8 1, ptr %.fca.3.gep, align 4, !tbaa !8
  store i8 28, ptr %.fca.4.gep, align 1, !tbaa !8
  store i8 2, ptr %.fca.5.gep, align 2, !tbaa !8
  store i8 0, ptr %.fca.6.gep, align 1, !tbaa !8
  store i64 1, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  store i64 0, ptr %.fca.7.0.1.gep, align 8, !tbaa !8
  store i64 8, ptr %.fca.7.0.2.gep, align 8, !tbaa !8
  ret void
}
*** IR Dump After InstCombinePass on _QFPomp_subroutine ***
define void @_QFPomp_subroutine(ptr %0, ptr %1, ptr nest %2) local_unnamed_addr {
entry:
  %structArg = alloca { ptr, ptr, ptr, ptr, ptr }, align 8
  %3 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %4 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %5 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  store ptr null, ptr %5, align 8, !tbaa !8
  %.fca.1.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 1
  store i64 8, ptr %.fca.1.gep, align 8, !tbaa !8
  %.fca.2.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 2
  store i32 20180515, ptr %.fca.2.gep, align 8, !tbaa !8
  %.fca.3.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 3
  store i8 1, ptr %.fca.3.gep, align 4, !tbaa !8
  %.fca.4.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 4
  store i8 28, ptr %.fca.4.gep, align 1, !tbaa !8
  %.fca.5.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 5
  store i8 2, ptr %.fca.5.gep, align 2, !tbaa !8
  %.fca.6.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 6
  store i8 0, ptr %.fca.6.gep, align 1, !tbaa !8
  %.fca.7.0.0.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 0
  store i64 1, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  %.fca.7.0.1.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 1
  store i64 0, ptr %.fca.7.0.1.gep, align 8, !tbaa !8
  %.fca.7.0.2.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 2
  store i64 8, ptr %.fca.7.0.2.gep, align 8, !tbaa !8
  %6 = load i32, ptr %0, align 4, !tbaa !4
  %7 = tail call i32 @llvm.smax.i32(i32 %6, i32 0)
  %8 = zext i32 %7 to i64
  %9 = shl nuw nsw i64 %8, 3
  %10 = tail call ptr @malloc(i64 %9)
  store ptr %10, ptr %5, align 8, !tbaa !8
  store i64 8, ptr %.fca.1.gep, align 8, !tbaa !8
  store i32 20180515, ptr %.fca.2.gep, align 8, !tbaa !8
  store i8 1, ptr %.fca.3.gep, align 4, !tbaa !8
  store i8 28, ptr %.fca.4.gep, align 1, !tbaa !8
  store i8 2, ptr %.fca.5.gep, align 2, !tbaa !8
  store i8 0, ptr %.fca.6.gep, align 1, !tbaa !8
  store i64 1, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  store i64 %8, ptr %.fca.7.0.1.gep, align 8, !tbaa !8
  store i64 8, ptr %.fca.7.0.2.gep, align 8, !tbaa !8
  %omp_global_thread_num = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %0, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %5, ptr %gep_5, align 8
  %gep_6 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 2
  store ptr %4, ptr %gep_6, align 8
  %gep_7 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 3
  store ptr %3, ptr %gep_7, align 8
  %gep_8 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 4
  store ptr %2, ptr %gep_8, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QFPomp_subroutine..omp_par, ptr nonnull %structArg)
  %.fca.0.load = load ptr, ptr %5, align 8, !tbaa !8
  %.fca.7.0.0.load = load i64, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  %11 = sub i64 1, %.fca.7.0.0.load
  %12 = getelementptr double, ptr %.fca.0.load, i64 %11
  %13 = load double, ptr %12, align 8, !tbaa !4
  %14 = load i32, ptr %0, align 4, !tbaa !4
  %15 = sext i32 %14 to i64
  %16 = sub i64 %15, %.fca.7.0.0.load
  %17 = getelementptr double, ptr %.fca.0.load, i64 %16
  %18 = load double, ptr %17, align 8, !tbaa !4
  %19 = fadd contract double %13, %18
  store double %19, ptr %1, align 8, !tbaa !4
  call void @free(ptr %.fca.0.load)
  store ptr null, ptr %5, align 8, !tbaa !8
  store i64 8, ptr %.fca.1.gep, align 8, !tbaa !8
  store i32 20180515, ptr %.fca.2.gep, align 8, !tbaa !8
  store i8 1, ptr %.fca.3.gep, align 4, !tbaa !8
  store i8 28, ptr %.fca.4.gep, align 1, !tbaa !8
  store i8 2, ptr %.fca.5.gep, align 2, !tbaa !8
  store i8 0, ptr %.fca.6.gep, align 1, !tbaa !8
  store i64 1, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  store i64 0, ptr %.fca.7.0.1.gep, align 8, !tbaa !8
  store i64 8, ptr %.fca.7.0.2.gep, align 8, !tbaa !8
  ret void
}
*** IR Dump After LoopSimplifyPass on _QFPomp_subroutine ***
define void @_QFPomp_subroutine(ptr %0, ptr %1, ptr nest %2) local_unnamed_addr {
entry:
  %structArg = alloca { ptr, ptr, ptr, ptr, ptr }, align 8
  %3 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %4 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %5 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  store ptr null, ptr %5, align 8, !tbaa !8
  %.fca.1.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 1
  store i64 8, ptr %.fca.1.gep, align 8, !tbaa !8
  %.fca.2.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 2
  store i32 20180515, ptr %.fca.2.gep, align 8, !tbaa !8
  %.fca.3.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 3
  store i8 1, ptr %.fca.3.gep, align 4, !tbaa !8
  %.fca.4.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 4
  store i8 28, ptr %.fca.4.gep, align 1, !tbaa !8
  %.fca.5.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 5
  store i8 2, ptr %.fca.5.gep, align 2, !tbaa !8
  %.fca.6.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 6
  store i8 0, ptr %.fca.6.gep, align 1, !tbaa !8
  %.fca.7.0.0.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 0
  store i64 1, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  %.fca.7.0.1.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 1
  store i64 0, ptr %.fca.7.0.1.gep, align 8, !tbaa !8
  %.fca.7.0.2.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 2
  store i64 8, ptr %.fca.7.0.2.gep, align 8, !tbaa !8
  %6 = load i32, ptr %0, align 4, !tbaa !4
  %7 = tail call i32 @llvm.smax.i32(i32 %6, i32 0)
  %8 = zext i32 %7 to i64
  %9 = shl nuw nsw i64 %8, 3
  %10 = tail call ptr @malloc(i64 %9)
  store ptr %10, ptr %5, align 8, !tbaa !8
  store i64 8, ptr %.fca.1.gep, align 8, !tbaa !8
  store i32 20180515, ptr %.fca.2.gep, align 8, !tbaa !8
  store i8 1, ptr %.fca.3.gep, align 4, !tbaa !8
  store i8 28, ptr %.fca.4.gep, align 1, !tbaa !8
  store i8 2, ptr %.fca.5.gep, align 2, !tbaa !8
  store i8 0, ptr %.fca.6.gep, align 1, !tbaa !8
  store i64 1, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  store i64 %8, ptr %.fca.7.0.1.gep, align 8, !tbaa !8
  store i64 8, ptr %.fca.7.0.2.gep, align 8, !tbaa !8
  %omp_global_thread_num = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %0, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %5, ptr %gep_5, align 8
  %gep_6 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 2
  store ptr %4, ptr %gep_6, align 8
  %gep_7 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 3
  store ptr %3, ptr %gep_7, align 8
  %gep_8 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 4
  store ptr %2, ptr %gep_8, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QFPomp_subroutine..omp_par, ptr nonnull %structArg)
  %.fca.0.load = load ptr, ptr %5, align 8, !tbaa !8
  %.fca.7.0.0.load = load i64, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  %11 = sub i64 1, %.fca.7.0.0.load
  %12 = getelementptr double, ptr %.fca.0.load, i64 %11
  %13 = load double, ptr %12, align 8, !tbaa !4
  %14 = load i32, ptr %0, align 4, !tbaa !4
  %15 = sext i32 %14 to i64
  %16 = sub i64 %15, %.fca.7.0.0.load
  %17 = getelementptr double, ptr %.fca.0.load, i64 %16
  %18 = load double, ptr %17, align 8, !tbaa !4
  %19 = fadd contract double %13, %18
  store double %19, ptr %1, align 8, !tbaa !4
  call void @free(ptr %.fca.0.load)
  store ptr null, ptr %5, align 8, !tbaa !8
  store i64 8, ptr %.fca.1.gep, align 8, !tbaa !8
  store i32 20180515, ptr %.fca.2.gep, align 8, !tbaa !8
  store i8 1, ptr %.fca.3.gep, align 4, !tbaa !8
  store i8 28, ptr %.fca.4.gep, align 1, !tbaa !8
  store i8 2, ptr %.fca.5.gep, align 2, !tbaa !8
  store i8 0, ptr %.fca.6.gep, align 1, !tbaa !8
  store i64 1, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  store i64 0, ptr %.fca.7.0.1.gep, align 8, !tbaa !8
  store i64 8, ptr %.fca.7.0.2.gep, align 8, !tbaa !8
  ret void
}
*** IR Dump After LCSSAPass on _QFPomp_subroutine ***
define void @_QFPomp_subroutine(ptr %0, ptr %1, ptr nest %2) local_unnamed_addr {
entry:
  %structArg = alloca { ptr, ptr, ptr, ptr, ptr }, align 8
  %3 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %4 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %5 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  store ptr null, ptr %5, align 8, !tbaa !8
  %.fca.1.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 1
  store i64 8, ptr %.fca.1.gep, align 8, !tbaa !8
  %.fca.2.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 2
  store i32 20180515, ptr %.fca.2.gep, align 8, !tbaa !8
  %.fca.3.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 3
  store i8 1, ptr %.fca.3.gep, align 4, !tbaa !8
  %.fca.4.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 4
  store i8 28, ptr %.fca.4.gep, align 1, !tbaa !8
  %.fca.5.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 5
  store i8 2, ptr %.fca.5.gep, align 2, !tbaa !8
  %.fca.6.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 6
  store i8 0, ptr %.fca.6.gep, align 1, !tbaa !8
  %.fca.7.0.0.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 0
  store i64 1, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  %.fca.7.0.1.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 1
  store i64 0, ptr %.fca.7.0.1.gep, align 8, !tbaa !8
  %.fca.7.0.2.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 2
  store i64 8, ptr %.fca.7.0.2.gep, align 8, !tbaa !8
  %6 = load i32, ptr %0, align 4, !tbaa !4
  %7 = tail call i32 @llvm.smax.i32(i32 %6, i32 0)
  %8 = zext i32 %7 to i64
  %9 = shl nuw nsw i64 %8, 3
  %10 = tail call ptr @malloc(i64 %9)
  store ptr %10, ptr %5, align 8, !tbaa !8
  store i64 8, ptr %.fca.1.gep, align 8, !tbaa !8
  store i32 20180515, ptr %.fca.2.gep, align 8, !tbaa !8
  store i8 1, ptr %.fca.3.gep, align 4, !tbaa !8
  store i8 28, ptr %.fca.4.gep, align 1, !tbaa !8
  store i8 2, ptr %.fca.5.gep, align 2, !tbaa !8
  store i8 0, ptr %.fca.6.gep, align 1, !tbaa !8
  store i64 1, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  store i64 %8, ptr %.fca.7.0.1.gep, align 8, !tbaa !8
  store i64 8, ptr %.fca.7.0.2.gep, align 8, !tbaa !8
  %omp_global_thread_num = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %0, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %5, ptr %gep_5, align 8
  %gep_6 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 2
  store ptr %4, ptr %gep_6, align 8
  %gep_7 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 3
  store ptr %3, ptr %gep_7, align 8
  %gep_8 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 4
  store ptr %2, ptr %gep_8, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QFPomp_subroutine..omp_par, ptr nonnull %structArg)
  %.fca.0.load = load ptr, ptr %5, align 8, !tbaa !8
  %.fca.7.0.0.load = load i64, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  %11 = sub i64 1, %.fca.7.0.0.load
  %12 = getelementptr double, ptr %.fca.0.load, i64 %11
  %13 = load double, ptr %12, align 8, !tbaa !4
  %14 = load i32, ptr %0, align 4, !tbaa !4
  %15 = sext i32 %14 to i64
  %16 = sub i64 %15, %.fca.7.0.0.load
  %17 = getelementptr double, ptr %.fca.0.load, i64 %16
  %18 = load double, ptr %17, align 8, !tbaa !4
  %19 = fadd contract double %13, %18
  store double %19, ptr %1, align 8, !tbaa !4
  call void @free(ptr %.fca.0.load)
  store ptr null, ptr %5, align 8, !tbaa !8
  store i64 8, ptr %.fca.1.gep, align 8, !tbaa !8
  store i32 20180515, ptr %.fca.2.gep, align 8, !tbaa !8
  store i8 1, ptr %.fca.3.gep, align 4, !tbaa !8
  store i8 28, ptr %.fca.4.gep, align 1, !tbaa !8
  store i8 2, ptr %.fca.5.gep, align 2, !tbaa !8
  store i8 0, ptr %.fca.6.gep, align 1, !tbaa !8
  store i64 1, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  store i64 0, ptr %.fca.7.0.1.gep, align 8, !tbaa !8
  store i64 8, ptr %.fca.7.0.2.gep, align 8, !tbaa !8
  ret void
}
*** IR Dump After SROAPass on _QFPomp_subroutine ***
define void @_QFPomp_subroutine(ptr %0, ptr %1, ptr nest %2) local_unnamed_addr {
entry:
  %structArg = alloca { ptr, ptr, ptr, ptr, ptr }, align 8
  %3 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %4 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %5 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  store ptr null, ptr %5, align 8, !tbaa !8
  %.fca.1.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 1
  store i64 8, ptr %.fca.1.gep, align 8, !tbaa !8
  %.fca.2.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 2
  store i32 20180515, ptr %.fca.2.gep, align 8, !tbaa !8
  %.fca.3.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 3
  store i8 1, ptr %.fca.3.gep, align 4, !tbaa !8
  %.fca.4.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 4
  store i8 28, ptr %.fca.4.gep, align 1, !tbaa !8
  %.fca.5.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 5
  store i8 2, ptr %.fca.5.gep, align 2, !tbaa !8
  %.fca.6.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 6
  store i8 0, ptr %.fca.6.gep, align 1, !tbaa !8
  %.fca.7.0.0.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 0
  store i64 1, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  %.fca.7.0.1.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 1
  store i64 0, ptr %.fca.7.0.1.gep, align 8, !tbaa !8
  %.fca.7.0.2.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 2
  store i64 8, ptr %.fca.7.0.2.gep, align 8, !tbaa !8
  %6 = load i32, ptr %0, align 4, !tbaa !4
  %7 = tail call i32 @llvm.smax.i32(i32 %6, i32 0)
  %8 = zext i32 %7 to i64
  %9 = shl nuw nsw i64 %8, 3
  %10 = tail call ptr @malloc(i64 %9)
  store ptr %10, ptr %5, align 8, !tbaa !8
  store i64 8, ptr %.fca.1.gep, align 8, !tbaa !8
  store i32 20180515, ptr %.fca.2.gep, align 8, !tbaa !8
  store i8 1, ptr %.fca.3.gep, align 4, !tbaa !8
  store i8 28, ptr %.fca.4.gep, align 1, !tbaa !8
  store i8 2, ptr %.fca.5.gep, align 2, !tbaa !8
  store i8 0, ptr %.fca.6.gep, align 1, !tbaa !8
  store i64 1, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  store i64 %8, ptr %.fca.7.0.1.gep, align 8, !tbaa !8
  store i64 8, ptr %.fca.7.0.2.gep, align 8, !tbaa !8
  %omp_global_thread_num = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %0, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %5, ptr %gep_5, align 8
  %gep_6 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 2
  store ptr %4, ptr %gep_6, align 8
  %gep_7 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 3
  store ptr %3, ptr %gep_7, align 8
  %gep_8 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 4
  store ptr %2, ptr %gep_8, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QFPomp_subroutine..omp_par, ptr nonnull %structArg)
  %.fca.0.load = load ptr, ptr %5, align 8, !tbaa !8
  %.fca.7.0.0.load = load i64, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  %11 = sub i64 1, %.fca.7.0.0.load
  %12 = getelementptr double, ptr %.fca.0.load, i64 %11
  %13 = load double, ptr %12, align 8, !tbaa !4
  %14 = load i32, ptr %0, align 4, !tbaa !4
  %15 = sext i32 %14 to i64
  %16 = sub i64 %15, %.fca.7.0.0.load
  %17 = getelementptr double, ptr %.fca.0.load, i64 %16
  %18 = load double, ptr %17, align 8, !tbaa !4
  %19 = fadd contract double %13, %18
  store double %19, ptr %1, align 8, !tbaa !4
  call void @free(ptr %.fca.0.load)
  store ptr null, ptr %5, align 8, !tbaa !8
  store i64 8, ptr %.fca.1.gep, align 8, !tbaa !8
  store i32 20180515, ptr %.fca.2.gep, align 8, !tbaa !8
  store i8 1, ptr %.fca.3.gep, align 4, !tbaa !8
  store i8 28, ptr %.fca.4.gep, align 1, !tbaa !8
  store i8 2, ptr %.fca.5.gep, align 2, !tbaa !8
  store i8 0, ptr %.fca.6.gep, align 1, !tbaa !8
  store i64 1, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  store i64 0, ptr %.fca.7.0.1.gep, align 8, !tbaa !8
  store i64 8, ptr %.fca.7.0.2.gep, align 8, !tbaa !8
  ret void
}
*** IR Dump After VectorCombinePass on _QFPomp_subroutine ***
define void @_QFPomp_subroutine(ptr %0, ptr %1, ptr nest %2) local_unnamed_addr {
entry:
  %structArg = alloca { ptr, ptr, ptr, ptr, ptr }, align 8
  %3 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %4 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %5 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  store ptr null, ptr %5, align 8, !tbaa !8
  %.fca.1.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 1
  store i64 8, ptr %.fca.1.gep, align 8, !tbaa !8
  %.fca.2.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 2
  store i32 20180515, ptr %.fca.2.gep, align 8, !tbaa !8
  %.fca.3.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 3
  store i8 1, ptr %.fca.3.gep, align 4, !tbaa !8
  %.fca.4.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 4
  store i8 28, ptr %.fca.4.gep, align 1, !tbaa !8
  %.fca.5.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 5
  store i8 2, ptr %.fca.5.gep, align 2, !tbaa !8
  %.fca.6.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 6
  store i8 0, ptr %.fca.6.gep, align 1, !tbaa !8
  %.fca.7.0.0.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 0
  store i64 1, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  %.fca.7.0.1.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 1
  store i64 0, ptr %.fca.7.0.1.gep, align 8, !tbaa !8
  %.fca.7.0.2.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 2
  store i64 8, ptr %.fca.7.0.2.gep, align 8, !tbaa !8
  %6 = load i32, ptr %0, align 4, !tbaa !4
  %7 = tail call i32 @llvm.smax.i32(i32 %6, i32 0)
  %8 = zext i32 %7 to i64
  %9 = shl nuw nsw i64 %8, 3
  %10 = tail call ptr @malloc(i64 %9)
  store ptr %10, ptr %5, align 8, !tbaa !8
  store i64 8, ptr %.fca.1.gep, align 8, !tbaa !8
  store i32 20180515, ptr %.fca.2.gep, align 8, !tbaa !8
  store i8 1, ptr %.fca.3.gep, align 4, !tbaa !8
  store i8 28, ptr %.fca.4.gep, align 1, !tbaa !8
  store i8 2, ptr %.fca.5.gep, align 2, !tbaa !8
  store i8 0, ptr %.fca.6.gep, align 1, !tbaa !8
  store i64 1, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  store i64 %8, ptr %.fca.7.0.1.gep, align 8, !tbaa !8
  store i64 8, ptr %.fca.7.0.2.gep, align 8, !tbaa !8
  %omp_global_thread_num = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %0, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %5, ptr %gep_5, align 8
  %gep_6 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 2
  store ptr %4, ptr %gep_6, align 8
  %gep_7 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 3
  store ptr %3, ptr %gep_7, align 8
  %gep_8 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 4
  store ptr %2, ptr %gep_8, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QFPomp_subroutine..omp_par, ptr nonnull %structArg)
  %.fca.0.load = load ptr, ptr %5, align 8, !tbaa !8
  %.fca.7.0.0.load = load i64, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  %11 = sub i64 1, %.fca.7.0.0.load
  %12 = getelementptr double, ptr %.fca.0.load, i64 %11
  %13 = load double, ptr %12, align 8, !tbaa !4
  %14 = load i32, ptr %0, align 4, !tbaa !4
  %15 = sext i32 %14 to i64
  %16 = sub i64 %15, %.fca.7.0.0.load
  %17 = getelementptr double, ptr %.fca.0.load, i64 %16
  %18 = load double, ptr %17, align 8, !tbaa !4
  %19 = fadd contract double %13, %18
  store double %19, ptr %1, align 8, !tbaa !4
  call void @free(ptr %.fca.0.load)
  store ptr null, ptr %5, align 8, !tbaa !8
  store i64 8, ptr %.fca.1.gep, align 8, !tbaa !8
  store i32 20180515, ptr %.fca.2.gep, align 8, !tbaa !8
  store i8 1, ptr %.fca.3.gep, align 4, !tbaa !8
  store i8 28, ptr %.fca.4.gep, align 1, !tbaa !8
  store i8 2, ptr %.fca.5.gep, align 2, !tbaa !8
  store i8 0, ptr %.fca.6.gep, align 1, !tbaa !8
  store i64 1, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  store i64 0, ptr %.fca.7.0.1.gep, align 8, !tbaa !8
  store i64 8, ptr %.fca.7.0.2.gep, align 8, !tbaa !8
  ret void
}
*** IR Dump After MergedLoadStoreMotionPass on _QFPomp_subroutine ***
define void @_QFPomp_subroutine(ptr %0, ptr %1, ptr nest %2) local_unnamed_addr {
entry:
  %structArg = alloca { ptr, ptr, ptr, ptr, ptr }, align 8
  %3 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %4 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %5 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  store ptr null, ptr %5, align 8, !tbaa !8
  %.fca.1.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 1
  store i64 8, ptr %.fca.1.gep, align 8, !tbaa !8
  %.fca.2.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 2
  store i32 20180515, ptr %.fca.2.gep, align 8, !tbaa !8
  %.fca.3.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 3
  store i8 1, ptr %.fca.3.gep, align 4, !tbaa !8
  %.fca.4.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 4
  store i8 28, ptr %.fca.4.gep, align 1, !tbaa !8
  %.fca.5.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 5
  store i8 2, ptr %.fca.5.gep, align 2, !tbaa !8
  %.fca.6.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 6
  store i8 0, ptr %.fca.6.gep, align 1, !tbaa !8
  %.fca.7.0.0.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 0
  store i64 1, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  %.fca.7.0.1.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 1
  store i64 0, ptr %.fca.7.0.1.gep, align 8, !tbaa !8
  %.fca.7.0.2.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 2
  store i64 8, ptr %.fca.7.0.2.gep, align 8, !tbaa !8
  %6 = load i32, ptr %0, align 4, !tbaa !4
  %7 = tail call i32 @llvm.smax.i32(i32 %6, i32 0)
  %8 = zext i32 %7 to i64
  %9 = shl nuw nsw i64 %8, 3
  %10 = tail call ptr @malloc(i64 %9)
  store ptr %10, ptr %5, align 8, !tbaa !8
  store i64 8, ptr %.fca.1.gep, align 8, !tbaa !8
  store i32 20180515, ptr %.fca.2.gep, align 8, !tbaa !8
  store i8 1, ptr %.fca.3.gep, align 4, !tbaa !8
  store i8 28, ptr %.fca.4.gep, align 1, !tbaa !8
  store i8 2, ptr %.fca.5.gep, align 2, !tbaa !8
  store i8 0, ptr %.fca.6.gep, align 1, !tbaa !8
  store i64 1, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  store i64 %8, ptr %.fca.7.0.1.gep, align 8, !tbaa !8
  store i64 8, ptr %.fca.7.0.2.gep, align 8, !tbaa !8
  %omp_global_thread_num = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %0, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %5, ptr %gep_5, align 8
  %gep_6 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 2
  store ptr %4, ptr %gep_6, align 8
  %gep_7 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 3
  store ptr %3, ptr %gep_7, align 8
  %gep_8 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 4
  store ptr %2, ptr %gep_8, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QFPomp_subroutine..omp_par, ptr nonnull %structArg)
  %.fca.0.load = load ptr, ptr %5, align 8, !tbaa !8
  %.fca.7.0.0.load = load i64, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  %11 = sub i64 1, %.fca.7.0.0.load
  %12 = getelementptr double, ptr %.fca.0.load, i64 %11
  %13 = load double, ptr %12, align 8, !tbaa !4
  %14 = load i32, ptr %0, align 4, !tbaa !4
  %15 = sext i32 %14 to i64
  %16 = sub i64 %15, %.fca.7.0.0.load
  %17 = getelementptr double, ptr %.fca.0.load, i64 %16
  %18 = load double, ptr %17, align 8, !tbaa !4
  %19 = fadd contract double %13, %18
  store double %19, ptr %1, align 8, !tbaa !4
  call void @free(ptr %.fca.0.load)
  store ptr null, ptr %5, align 8, !tbaa !8
  store i64 8, ptr %.fca.1.gep, align 8, !tbaa !8
  store i32 20180515, ptr %.fca.2.gep, align 8, !tbaa !8
  store i8 1, ptr %.fca.3.gep, align 4, !tbaa !8
  store i8 28, ptr %.fca.4.gep, align 1, !tbaa !8
  store i8 2, ptr %.fca.5.gep, align 2, !tbaa !8
  store i8 0, ptr %.fca.6.gep, align 1, !tbaa !8
  store i64 1, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  store i64 0, ptr %.fca.7.0.1.gep, align 8, !tbaa !8
  store i64 8, ptr %.fca.7.0.2.gep, align 8, !tbaa !8
  ret void
}
*** IR Dump After GVNPass on _QFPomp_subroutine ***
define void @_QFPomp_subroutine(ptr %0, ptr %1, ptr nest %2) local_unnamed_addr {
entry:
  %structArg = alloca { ptr, ptr, ptr, ptr, ptr }, align 8
  %3 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %4 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %5 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  store ptr null, ptr %5, align 8, !tbaa !8
  %.fca.1.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 1
  store i64 8, ptr %.fca.1.gep, align 8, !tbaa !8
  %.fca.2.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 2
  store i32 20180515, ptr %.fca.2.gep, align 8, !tbaa !8
  %.fca.3.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 3
  store i8 1, ptr %.fca.3.gep, align 4, !tbaa !8
  %.fca.4.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 4
  store i8 28, ptr %.fca.4.gep, align 1, !tbaa !8
  %.fca.5.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 5
  store i8 2, ptr %.fca.5.gep, align 2, !tbaa !8
  %.fca.6.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 6
  store i8 0, ptr %.fca.6.gep, align 1, !tbaa !8
  %.fca.7.0.0.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 0
  store i64 1, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  %.fca.7.0.1.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 1
  store i64 0, ptr %.fca.7.0.1.gep, align 8, !tbaa !8
  %.fca.7.0.2.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 2
  store i64 8, ptr %.fca.7.0.2.gep, align 8, !tbaa !8
  %6 = load i32, ptr %0, align 4, !tbaa !4
  %7 = tail call i32 @llvm.smax.i32(i32 %6, i32 0)
  %8 = zext i32 %7 to i64
  %9 = shl nuw nsw i64 %8, 3
  %10 = tail call ptr @malloc(i64 %9)
  store ptr %10, ptr %5, align 8, !tbaa !8
  store i64 8, ptr %.fca.1.gep, align 8, !tbaa !8
  store i32 20180515, ptr %.fca.2.gep, align 8, !tbaa !8
  store i8 1, ptr %.fca.3.gep, align 4, !tbaa !8
  store i8 28, ptr %.fca.4.gep, align 1, !tbaa !8
  store i8 2, ptr %.fca.5.gep, align 2, !tbaa !8
  store i8 0, ptr %.fca.6.gep, align 1, !tbaa !8
  store i64 1, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  store i64 %8, ptr %.fca.7.0.1.gep, align 8, !tbaa !8
  store i64 8, ptr %.fca.7.0.2.gep, align 8, !tbaa !8
  %omp_global_thread_num = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %0, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %5, ptr %gep_5, align 8
  %gep_6 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 2
  store ptr %4, ptr %gep_6, align 8
  %gep_7 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 3
  store ptr %3, ptr %gep_7, align 8
  %gep_8 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 4
  store ptr %2, ptr %gep_8, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QFPomp_subroutine..omp_par, ptr nonnull %structArg)
  %.fca.0.load = load ptr, ptr %5, align 8, !tbaa !8
  %.fca.7.0.0.load = load i64, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  %11 = sub i64 1, %.fca.7.0.0.load
  %12 = getelementptr double, ptr %.fca.0.load, i64 %11
  %13 = load double, ptr %12, align 8, !tbaa !4
  %14 = load i32, ptr %0, align 4, !tbaa !4
  %15 = sext i32 %14 to i64
  %16 = sub i64 %15, %.fca.7.0.0.load
  %17 = getelementptr double, ptr %.fca.0.load, i64 %16
  %18 = load double, ptr %17, align 8, !tbaa !4
  %19 = fadd contract double %13, %18
  store double %19, ptr %1, align 8, !tbaa !4
  call void @free(ptr %.fca.0.load)
  store ptr null, ptr %5, align 8, !tbaa !8
  store i64 8, ptr %.fca.1.gep, align 8, !tbaa !8
  store i32 20180515, ptr %.fca.2.gep, align 8, !tbaa !8
  store i8 1, ptr %.fca.3.gep, align 4, !tbaa !8
  store i8 28, ptr %.fca.4.gep, align 1, !tbaa !8
  store i8 2, ptr %.fca.5.gep, align 2, !tbaa !8
  store i8 0, ptr %.fca.6.gep, align 1, !tbaa !8
  store i64 1, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  store i64 0, ptr %.fca.7.0.1.gep, align 8, !tbaa !8
  store i64 8, ptr %.fca.7.0.2.gep, align 8, !tbaa !8
  ret void
}
*** IR Dump After SCCPPass on _QFPomp_subroutine ***
define void @_QFPomp_subroutine(ptr %0, ptr %1, ptr nest %2) local_unnamed_addr {
entry:
  %structArg = alloca { ptr, ptr, ptr, ptr, ptr }, align 8
  %3 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %4 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %5 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  store ptr null, ptr %5, align 8, !tbaa !8
  %.fca.1.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 1
  store i64 8, ptr %.fca.1.gep, align 8, !tbaa !8
  %.fca.2.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 2
  store i32 20180515, ptr %.fca.2.gep, align 8, !tbaa !8
  %.fca.3.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 3
  store i8 1, ptr %.fca.3.gep, align 4, !tbaa !8
  %.fca.4.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 4
  store i8 28, ptr %.fca.4.gep, align 1, !tbaa !8
  %.fca.5.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 5
  store i8 2, ptr %.fca.5.gep, align 2, !tbaa !8
  %.fca.6.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 6
  store i8 0, ptr %.fca.6.gep, align 1, !tbaa !8
  %.fca.7.0.0.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 0
  store i64 1, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  %.fca.7.0.1.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 1
  store i64 0, ptr %.fca.7.0.1.gep, align 8, !tbaa !8
  %.fca.7.0.2.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 2
  store i64 8, ptr %.fca.7.0.2.gep, align 8, !tbaa !8
  %6 = load i32, ptr %0, align 4, !tbaa !4
  %7 = tail call i32 @llvm.smax.i32(i32 %6, i32 0)
  %8 = zext i32 %7 to i64
  %9 = shl nuw nsw i64 %8, 3
  %10 = tail call ptr @malloc(i64 %9)
  store ptr %10, ptr %5, align 8, !tbaa !8
  store i64 8, ptr %.fca.1.gep, align 8, !tbaa !8
  store i32 20180515, ptr %.fca.2.gep, align 8, !tbaa !8
  store i8 1, ptr %.fca.3.gep, align 4, !tbaa !8
  store i8 28, ptr %.fca.4.gep, align 1, !tbaa !8
  store i8 2, ptr %.fca.5.gep, align 2, !tbaa !8
  store i8 0, ptr %.fca.6.gep, align 1, !tbaa !8
  store i64 1, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  store i64 %8, ptr %.fca.7.0.1.gep, align 8, !tbaa !8
  store i64 8, ptr %.fca.7.0.2.gep, align 8, !tbaa !8
  %omp_global_thread_num = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %0, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %5, ptr %gep_5, align 8
  %gep_6 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 2
  store ptr %4, ptr %gep_6, align 8
  %gep_7 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 3
  store ptr %3, ptr %gep_7, align 8
  %gep_8 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 4
  store ptr %2, ptr %gep_8, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QFPomp_subroutine..omp_par, ptr nonnull %structArg)
  %.fca.0.load = load ptr, ptr %5, align 8, !tbaa !8
  %.fca.7.0.0.load = load i64, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  %11 = sub i64 1, %.fca.7.0.0.load
  %12 = getelementptr double, ptr %.fca.0.load, i64 %11
  %13 = load double, ptr %12, align 8, !tbaa !4
  %14 = load i32, ptr %0, align 4, !tbaa !4
  %15 = sext i32 %14 to i64
  %16 = sub i64 %15, %.fca.7.0.0.load
  %17 = getelementptr double, ptr %.fca.0.load, i64 %16
  %18 = load double, ptr %17, align 8, !tbaa !4
  %19 = fadd contract double %13, %18
  store double %19, ptr %1, align 8, !tbaa !4
  call void @free(ptr %.fca.0.load)
  store ptr null, ptr %5, align 8, !tbaa !8
  store i64 8, ptr %.fca.1.gep, align 8, !tbaa !8
  store i32 20180515, ptr %.fca.2.gep, align 8, !tbaa !8
  store i8 1, ptr %.fca.3.gep, align 4, !tbaa !8
  store i8 28, ptr %.fca.4.gep, align 1, !tbaa !8
  store i8 2, ptr %.fca.5.gep, align 2, !tbaa !8
  store i8 0, ptr %.fca.6.gep, align 1, !tbaa !8
  store i64 1, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  store i64 0, ptr %.fca.7.0.1.gep, align 8, !tbaa !8
  store i64 8, ptr %.fca.7.0.2.gep, align 8, !tbaa !8
  ret void
}
*** IR Dump After BDCEPass on _QFPomp_subroutine ***
define void @_QFPomp_subroutine(ptr %0, ptr %1, ptr nest %2) local_unnamed_addr {
entry:
  %structArg = alloca { ptr, ptr, ptr, ptr, ptr }, align 8
  %3 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %4 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %5 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  store ptr null, ptr %5, align 8, !tbaa !8
  %.fca.1.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 1
  store i64 8, ptr %.fca.1.gep, align 8, !tbaa !8
  %.fca.2.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 2
  store i32 20180515, ptr %.fca.2.gep, align 8, !tbaa !8
  %.fca.3.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 3
  store i8 1, ptr %.fca.3.gep, align 4, !tbaa !8
  %.fca.4.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 4
  store i8 28, ptr %.fca.4.gep, align 1, !tbaa !8
  %.fca.5.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 5
  store i8 2, ptr %.fca.5.gep, align 2, !tbaa !8
  %.fca.6.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 6
  store i8 0, ptr %.fca.6.gep, align 1, !tbaa !8
  %.fca.7.0.0.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 0
  store i64 1, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  %.fca.7.0.1.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 1
  store i64 0, ptr %.fca.7.0.1.gep, align 8, !tbaa !8
  %.fca.7.0.2.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 2
  store i64 8, ptr %.fca.7.0.2.gep, align 8, !tbaa !8
  %6 = load i32, ptr %0, align 4, !tbaa !4
  %7 = tail call i32 @llvm.smax.i32(i32 %6, i32 0)
  %8 = zext i32 %7 to i64
  %9 = shl nuw nsw i64 %8, 3
  %10 = tail call ptr @malloc(i64 %9)
  store ptr %10, ptr %5, align 8, !tbaa !8
  store i64 8, ptr %.fca.1.gep, align 8, !tbaa !8
  store i32 20180515, ptr %.fca.2.gep, align 8, !tbaa !8
  store i8 1, ptr %.fca.3.gep, align 4, !tbaa !8
  store i8 28, ptr %.fca.4.gep, align 1, !tbaa !8
  store i8 2, ptr %.fca.5.gep, align 2, !tbaa !8
  store i8 0, ptr %.fca.6.gep, align 1, !tbaa !8
  store i64 1, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  store i64 %8, ptr %.fca.7.0.1.gep, align 8, !tbaa !8
  store i64 8, ptr %.fca.7.0.2.gep, align 8, !tbaa !8
  %omp_global_thread_num = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %0, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %5, ptr %gep_5, align 8
  %gep_6 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 2
  store ptr %4, ptr %gep_6, align 8
  %gep_7 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 3
  store ptr %3, ptr %gep_7, align 8
  %gep_8 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 4
  store ptr %2, ptr %gep_8, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QFPomp_subroutine..omp_par, ptr nonnull %structArg)
  %.fca.0.load = load ptr, ptr %5, align 8, !tbaa !8
  %.fca.7.0.0.load = load i64, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  %11 = sub i64 1, %.fca.7.0.0.load
  %12 = getelementptr double, ptr %.fca.0.load, i64 %11
  %13 = load double, ptr %12, align 8, !tbaa !4
  %14 = load i32, ptr %0, align 4, !tbaa !4
  %15 = sext i32 %14 to i64
  %16 = sub i64 %15, %.fca.7.0.0.load
  %17 = getelementptr double, ptr %.fca.0.load, i64 %16
  %18 = load double, ptr %17, align 8, !tbaa !4
  %19 = fadd contract double %13, %18
  store double %19, ptr %1, align 8, !tbaa !4
  call void @free(ptr %.fca.0.load)
  store ptr null, ptr %5, align 8, !tbaa !8
  store i64 8, ptr %.fca.1.gep, align 8, !tbaa !8
  store i32 20180515, ptr %.fca.2.gep, align 8, !tbaa !8
  store i8 1, ptr %.fca.3.gep, align 4, !tbaa !8
  store i8 28, ptr %.fca.4.gep, align 1, !tbaa !8
  store i8 2, ptr %.fca.5.gep, align 2, !tbaa !8
  store i8 0, ptr %.fca.6.gep, align 1, !tbaa !8
  store i64 1, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  store i64 0, ptr %.fca.7.0.1.gep, align 8, !tbaa !8
  store i64 8, ptr %.fca.7.0.2.gep, align 8, !tbaa !8
  ret void
}
*** IR Dump After InstCombinePass on _QFPomp_subroutine ***
define void @_QFPomp_subroutine(ptr %0, ptr %1, ptr nest %2) local_unnamed_addr {
entry:
  %structArg = alloca { ptr, ptr, ptr, ptr, ptr }, align 8
  %3 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %4 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %5 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  store ptr null, ptr %5, align 8, !tbaa !8
  %.fca.1.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 1
  store i64 8, ptr %.fca.1.gep, align 8, !tbaa !8
  %.fca.2.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 2
  store i32 20180515, ptr %.fca.2.gep, align 8, !tbaa !8
  %.fca.3.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 3
  store i8 1, ptr %.fca.3.gep, align 4, !tbaa !8
  %.fca.4.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 4
  store i8 28, ptr %.fca.4.gep, align 1, !tbaa !8
  %.fca.5.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 5
  store i8 2, ptr %.fca.5.gep, align 2, !tbaa !8
  %.fca.6.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 6
  store i8 0, ptr %.fca.6.gep, align 1, !tbaa !8
  %.fca.7.0.0.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 0
  store i64 1, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  %.fca.7.0.1.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 1
  store i64 0, ptr %.fca.7.0.1.gep, align 8, !tbaa !8
  %.fca.7.0.2.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 2
  store i64 8, ptr %.fca.7.0.2.gep, align 8, !tbaa !8
  %6 = load i32, ptr %0, align 4, !tbaa !4
  %7 = tail call i32 @llvm.smax.i32(i32 %6, i32 0)
  %8 = zext i32 %7 to i64
  %9 = shl nuw nsw i64 %8, 3
  %10 = tail call ptr @malloc(i64 %9)
  store ptr %10, ptr %5, align 8, !tbaa !8
  store i64 8, ptr %.fca.1.gep, align 8, !tbaa !8
  store i32 20180515, ptr %.fca.2.gep, align 8, !tbaa !8
  store i8 1, ptr %.fca.3.gep, align 4, !tbaa !8
  store i8 28, ptr %.fca.4.gep, align 1, !tbaa !8
  store i8 2, ptr %.fca.5.gep, align 2, !tbaa !8
  store i8 0, ptr %.fca.6.gep, align 1, !tbaa !8
  store i64 1, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  store i64 %8, ptr %.fca.7.0.1.gep, align 8, !tbaa !8
  store i64 8, ptr %.fca.7.0.2.gep, align 8, !tbaa !8
  %omp_global_thread_num = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %0, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %5, ptr %gep_5, align 8
  %gep_6 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 2
  store ptr %4, ptr %gep_6, align 8
  %gep_7 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 3
  store ptr %3, ptr %gep_7, align 8
  %gep_8 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 4
  store ptr %2, ptr %gep_8, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QFPomp_subroutine..omp_par, ptr nonnull %structArg)
  %.fca.0.load = load ptr, ptr %5, align 8, !tbaa !8
  %.fca.7.0.0.load = load i64, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  %11 = sub i64 1, %.fca.7.0.0.load
  %12 = getelementptr double, ptr %.fca.0.load, i64 %11
  %13 = load double, ptr %12, align 8, !tbaa !4
  %14 = load i32, ptr %0, align 4, !tbaa !4
  %15 = sext i32 %14 to i64
  %16 = sub i64 %15, %.fca.7.0.0.load
  %17 = getelementptr double, ptr %.fca.0.load, i64 %16
  %18 = load double, ptr %17, align 8, !tbaa !4
  %19 = fadd contract double %13, %18
  store double %19, ptr %1, align 8, !tbaa !4
  call void @free(ptr %.fca.0.load)
  store ptr null, ptr %5, align 8, !tbaa !8
  store i64 8, ptr %.fca.1.gep, align 8, !tbaa !8
  store i32 20180515, ptr %.fca.2.gep, align 8, !tbaa !8
  store i8 1, ptr %.fca.3.gep, align 4, !tbaa !8
  store i8 28, ptr %.fca.4.gep, align 1, !tbaa !8
  store i8 2, ptr %.fca.5.gep, align 2, !tbaa !8
  store i8 0, ptr %.fca.6.gep, align 1, !tbaa !8
  store i64 1, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  store i64 0, ptr %.fca.7.0.1.gep, align 8, !tbaa !8
  store i64 8, ptr %.fca.7.0.2.gep, align 8, !tbaa !8
  ret void
}
*** IR Dump After JumpThreadingPass on _QFPomp_subroutine ***
define void @_QFPomp_subroutine(ptr %0, ptr %1, ptr nest %2) local_unnamed_addr {
entry:
  %structArg = alloca { ptr, ptr, ptr, ptr, ptr }, align 8
  %3 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %4 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %5 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  store ptr null, ptr %5, align 8, !tbaa !8
  %.fca.1.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 1
  store i64 8, ptr %.fca.1.gep, align 8, !tbaa !8
  %.fca.2.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 2
  store i32 20180515, ptr %.fca.2.gep, align 8, !tbaa !8
  %.fca.3.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 3
  store i8 1, ptr %.fca.3.gep, align 4, !tbaa !8
  %.fca.4.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 4
  store i8 28, ptr %.fca.4.gep, align 1, !tbaa !8
  %.fca.5.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 5
  store i8 2, ptr %.fca.5.gep, align 2, !tbaa !8
  %.fca.6.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 6
  store i8 0, ptr %.fca.6.gep, align 1, !tbaa !8
  %.fca.7.0.0.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 0
  store i64 1, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  %.fca.7.0.1.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 1
  store i64 0, ptr %.fca.7.0.1.gep, align 8, !tbaa !8
  %.fca.7.0.2.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 2
  store i64 8, ptr %.fca.7.0.2.gep, align 8, !tbaa !8
  %6 = load i32, ptr %0, align 4, !tbaa !4
  %7 = tail call i32 @llvm.smax.i32(i32 %6, i32 0)
  %8 = zext i32 %7 to i64
  %9 = shl nuw nsw i64 %8, 3
  %10 = tail call ptr @malloc(i64 %9)
  store ptr %10, ptr %5, align 8, !tbaa !8
  store i64 8, ptr %.fca.1.gep, align 8, !tbaa !8
  store i32 20180515, ptr %.fca.2.gep, align 8, !tbaa !8
  store i8 1, ptr %.fca.3.gep, align 4, !tbaa !8
  store i8 28, ptr %.fca.4.gep, align 1, !tbaa !8
  store i8 2, ptr %.fca.5.gep, align 2, !tbaa !8
  store i8 0, ptr %.fca.6.gep, align 1, !tbaa !8
  store i64 1, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  store i64 %8, ptr %.fca.7.0.1.gep, align 8, !tbaa !8
  store i64 8, ptr %.fca.7.0.2.gep, align 8, !tbaa !8
  %omp_global_thread_num = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %0, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %5, ptr %gep_5, align 8
  %gep_6 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 2
  store ptr %4, ptr %gep_6, align 8
  %gep_7 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 3
  store ptr %3, ptr %gep_7, align 8
  %gep_8 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 4
  store ptr %2, ptr %gep_8, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QFPomp_subroutine..omp_par, ptr nonnull %structArg)
  %.fca.0.load = load ptr, ptr %5, align 8, !tbaa !8
  %.fca.7.0.0.load = load i64, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  %11 = sub i64 1, %.fca.7.0.0.load
  %12 = getelementptr double, ptr %.fca.0.load, i64 %11
  %13 = load double, ptr %12, align 8, !tbaa !4
  %14 = load i32, ptr %0, align 4, !tbaa !4
  %15 = sext i32 %14 to i64
  %16 = sub i64 %15, %.fca.7.0.0.load
  %17 = getelementptr double, ptr %.fca.0.load, i64 %16
  %18 = load double, ptr %17, align 8, !tbaa !4
  %19 = fadd contract double %13, %18
  store double %19, ptr %1, align 8, !tbaa !4
  call void @free(ptr %.fca.0.load)
  store ptr null, ptr %5, align 8, !tbaa !8
  store i64 8, ptr %.fca.1.gep, align 8, !tbaa !8
  store i32 20180515, ptr %.fca.2.gep, align 8, !tbaa !8
  store i8 1, ptr %.fca.3.gep, align 4, !tbaa !8
  store i8 28, ptr %.fca.4.gep, align 1, !tbaa !8
  store i8 2, ptr %.fca.5.gep, align 2, !tbaa !8
  store i8 0, ptr %.fca.6.gep, align 1, !tbaa !8
  store i64 1, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  store i64 0, ptr %.fca.7.0.1.gep, align 8, !tbaa !8
  store i64 8, ptr %.fca.7.0.2.gep, align 8, !tbaa !8
  ret void
}
*** IR Dump After CorrelatedValuePropagationPass on _QFPomp_subroutine ***
define void @_QFPomp_subroutine(ptr %0, ptr %1, ptr nest %2) local_unnamed_addr {
entry:
  %structArg = alloca { ptr, ptr, ptr, ptr, ptr }, align 8
  %3 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %4 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %5 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  store ptr null, ptr %5, align 8, !tbaa !8
  %.fca.1.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 1
  store i64 8, ptr %.fca.1.gep, align 8, !tbaa !8
  %.fca.2.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 2
  store i32 20180515, ptr %.fca.2.gep, align 8, !tbaa !8
  %.fca.3.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 3
  store i8 1, ptr %.fca.3.gep, align 4, !tbaa !8
  %.fca.4.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 4
  store i8 28, ptr %.fca.4.gep, align 1, !tbaa !8
  %.fca.5.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 5
  store i8 2, ptr %.fca.5.gep, align 2, !tbaa !8
  %.fca.6.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 6
  store i8 0, ptr %.fca.6.gep, align 1, !tbaa !8
  %.fca.7.0.0.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 0
  store i64 1, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  %.fca.7.0.1.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 1
  store i64 0, ptr %.fca.7.0.1.gep, align 8, !tbaa !8
  %.fca.7.0.2.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 2
  store i64 8, ptr %.fca.7.0.2.gep, align 8, !tbaa !8
  %6 = load i32, ptr %0, align 4, !tbaa !4
  %7 = tail call i32 @llvm.smax.i32(i32 %6, i32 0)
  %8 = zext i32 %7 to i64
  %9 = shl nuw nsw i64 %8, 3
  %10 = tail call ptr @malloc(i64 %9)
  store ptr %10, ptr %5, align 8, !tbaa !8
  store i64 8, ptr %.fca.1.gep, align 8, !tbaa !8
  store i32 20180515, ptr %.fca.2.gep, align 8, !tbaa !8
  store i8 1, ptr %.fca.3.gep, align 4, !tbaa !8
  store i8 28, ptr %.fca.4.gep, align 1, !tbaa !8
  store i8 2, ptr %.fca.5.gep, align 2, !tbaa !8
  store i8 0, ptr %.fca.6.gep, align 1, !tbaa !8
  store i64 1, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  store i64 %8, ptr %.fca.7.0.1.gep, align 8, !tbaa !8
  store i64 8, ptr %.fca.7.0.2.gep, align 8, !tbaa !8
  %omp_global_thread_num = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %0, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %5, ptr %gep_5, align 8
  %gep_6 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 2
  store ptr %4, ptr %gep_6, align 8
  %gep_7 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 3
  store ptr %3, ptr %gep_7, align 8
  %gep_8 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 4
  store ptr %2, ptr %gep_8, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QFPomp_subroutine..omp_par, ptr nonnull %structArg)
  %.fca.0.load = load ptr, ptr %5, align 8, !tbaa !8
  %.fca.7.0.0.load = load i64, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  %11 = sub i64 1, %.fca.7.0.0.load
  %12 = getelementptr double, ptr %.fca.0.load, i64 %11
  %13 = load double, ptr %12, align 8, !tbaa !4
  %14 = load i32, ptr %0, align 4, !tbaa !4
  %15 = sext i32 %14 to i64
  %16 = sub i64 %15, %.fca.7.0.0.load
  %17 = getelementptr double, ptr %.fca.0.load, i64 %16
  %18 = load double, ptr %17, align 8, !tbaa !4
  %19 = fadd contract double %13, %18
  store double %19, ptr %1, align 8, !tbaa !4
  call void @free(ptr %.fca.0.load)
  store ptr null, ptr %5, align 8, !tbaa !8
  store i64 8, ptr %.fca.1.gep, align 8, !tbaa !8
  store i32 20180515, ptr %.fca.2.gep, align 8, !tbaa !8
  store i8 1, ptr %.fca.3.gep, align 4, !tbaa !8
  store i8 28, ptr %.fca.4.gep, align 1, !tbaa !8
  store i8 2, ptr %.fca.5.gep, align 2, !tbaa !8
  store i8 0, ptr %.fca.6.gep, align 1, !tbaa !8
  store i64 1, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  store i64 0, ptr %.fca.7.0.1.gep, align 8, !tbaa !8
  store i64 8, ptr %.fca.7.0.2.gep, align 8, !tbaa !8
  ret void
}
*** IR Dump After ADCEPass on _QFPomp_subroutine ***
define void @_QFPomp_subroutine(ptr %0, ptr %1, ptr nest %2) local_unnamed_addr {
entry:
  %structArg = alloca { ptr, ptr, ptr, ptr, ptr }, align 8
  %3 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %4 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %5 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  store ptr null, ptr %5, align 8, !tbaa !8
  %.fca.1.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 1
  store i64 8, ptr %.fca.1.gep, align 8, !tbaa !8
  %.fca.2.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 2
  store i32 20180515, ptr %.fca.2.gep, align 8, !tbaa !8
  %.fca.3.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 3
  store i8 1, ptr %.fca.3.gep, align 4, !tbaa !8
  %.fca.4.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 4
  store i8 28, ptr %.fca.4.gep, align 1, !tbaa !8
  %.fca.5.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 5
  store i8 2, ptr %.fca.5.gep, align 2, !tbaa !8
  %.fca.6.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 6
  store i8 0, ptr %.fca.6.gep, align 1, !tbaa !8
  %.fca.7.0.0.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 0
  store i64 1, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  %.fca.7.0.1.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 1
  store i64 0, ptr %.fca.7.0.1.gep, align 8, !tbaa !8
  %.fca.7.0.2.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 2
  store i64 8, ptr %.fca.7.0.2.gep, align 8, !tbaa !8
  %6 = load i32, ptr %0, align 4, !tbaa !4
  %7 = tail call i32 @llvm.smax.i32(i32 %6, i32 0)
  %8 = zext i32 %7 to i64
  %9 = shl nuw nsw i64 %8, 3
  %10 = tail call ptr @malloc(i64 %9)
  store ptr %10, ptr %5, align 8, !tbaa !8
  store i64 8, ptr %.fca.1.gep, align 8, !tbaa !8
  store i32 20180515, ptr %.fca.2.gep, align 8, !tbaa !8
  store i8 1, ptr %.fca.3.gep, align 4, !tbaa !8
  store i8 28, ptr %.fca.4.gep, align 1, !tbaa !8
  store i8 2, ptr %.fca.5.gep, align 2, !tbaa !8
  store i8 0, ptr %.fca.6.gep, align 1, !tbaa !8
  store i64 1, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  store i64 %8, ptr %.fca.7.0.1.gep, align 8, !tbaa !8
  store i64 8, ptr %.fca.7.0.2.gep, align 8, !tbaa !8
  %omp_global_thread_num = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %0, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %5, ptr %gep_5, align 8
  %gep_6 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 2
  store ptr %4, ptr %gep_6, align 8
  %gep_7 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 3
  store ptr %3, ptr %gep_7, align 8
  %gep_8 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 4
  store ptr %2, ptr %gep_8, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QFPomp_subroutine..omp_par, ptr nonnull %structArg)
  %.fca.0.load = load ptr, ptr %5, align 8, !tbaa !8
  %.fca.7.0.0.load = load i64, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  %11 = sub i64 1, %.fca.7.0.0.load
  %12 = getelementptr double, ptr %.fca.0.load, i64 %11
  %13 = load double, ptr %12, align 8, !tbaa !4
  %14 = load i32, ptr %0, align 4, !tbaa !4
  %15 = sext i32 %14 to i64
  %16 = sub i64 %15, %.fca.7.0.0.load
  %17 = getelementptr double, ptr %.fca.0.load, i64 %16
  %18 = load double, ptr %17, align 8, !tbaa !4
  %19 = fadd contract double %13, %18
  store double %19, ptr %1, align 8, !tbaa !4
  call void @free(ptr %.fca.0.load)
  store ptr null, ptr %5, align 8, !tbaa !8
  store i64 8, ptr %.fca.1.gep, align 8, !tbaa !8
  store i32 20180515, ptr %.fca.2.gep, align 8, !tbaa !8
  store i8 1, ptr %.fca.3.gep, align 4, !tbaa !8
  store i8 28, ptr %.fca.4.gep, align 1, !tbaa !8
  store i8 2, ptr %.fca.5.gep, align 2, !tbaa !8
  store i8 0, ptr %.fca.6.gep, align 1, !tbaa !8
  store i64 1, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  store i64 0, ptr %.fca.7.0.1.gep, align 8, !tbaa !8
  store i64 8, ptr %.fca.7.0.2.gep, align 8, !tbaa !8
  ret void
}
*** IR Dump After MemCpyOptPass on _QFPomp_subroutine ***
define void @_QFPomp_subroutine(ptr %0, ptr %1, ptr nest %2) local_unnamed_addr {
entry:
  %structArg = alloca { ptr, ptr, ptr, ptr, ptr }, align 8
  %3 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %4 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %5 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  store ptr null, ptr %5, align 8, !tbaa !8
  %.fca.1.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 1
  store i64 8, ptr %.fca.1.gep, align 8, !tbaa !8
  %.fca.2.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 2
  store i32 20180515, ptr %.fca.2.gep, align 8, !tbaa !8
  %.fca.3.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 3
  store i8 1, ptr %.fca.3.gep, align 4, !tbaa !8
  %.fca.4.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 4
  store i8 28, ptr %.fca.4.gep, align 1, !tbaa !8
  %.fca.5.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 5
  store i8 2, ptr %.fca.5.gep, align 2, !tbaa !8
  %.fca.6.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 6
  store i8 0, ptr %.fca.6.gep, align 1, !tbaa !8
  %.fca.7.0.0.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 0
  store i64 1, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  %.fca.7.0.1.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 1
  store i64 0, ptr %.fca.7.0.1.gep, align 8, !tbaa !8
  %.fca.7.0.2.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 2
  store i64 8, ptr %.fca.7.0.2.gep, align 8, !tbaa !8
  %6 = load i32, ptr %0, align 4, !tbaa !4
  %7 = tail call i32 @llvm.smax.i32(i32 %6, i32 0)
  %8 = zext i32 %7 to i64
  %9 = shl nuw nsw i64 %8, 3
  %10 = tail call ptr @malloc(i64 %9)
  store ptr %10, ptr %5, align 8, !tbaa !8
  store i64 8, ptr %.fca.1.gep, align 8, !tbaa !8
  store i32 20180515, ptr %.fca.2.gep, align 8, !tbaa !8
  store i8 1, ptr %.fca.3.gep, align 4, !tbaa !8
  store i8 28, ptr %.fca.4.gep, align 1, !tbaa !8
  store i8 2, ptr %.fca.5.gep, align 2, !tbaa !8
  store i8 0, ptr %.fca.6.gep, align 1, !tbaa !8
  store i64 1, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  store i64 %8, ptr %.fca.7.0.1.gep, align 8, !tbaa !8
  store i64 8, ptr %.fca.7.0.2.gep, align 8, !tbaa !8
  %omp_global_thread_num = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %0, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %5, ptr %gep_5, align 8
  %gep_6 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 2
  store ptr %4, ptr %gep_6, align 8
  %gep_7 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 3
  store ptr %3, ptr %gep_7, align 8
  %gep_8 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 4
  store ptr %2, ptr %gep_8, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QFPomp_subroutine..omp_par, ptr nonnull %structArg)
  %.fca.0.load = load ptr, ptr %5, align 8, !tbaa !8
  %.fca.7.0.0.load = load i64, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  %11 = sub i64 1, %.fca.7.0.0.load
  %12 = getelementptr double, ptr %.fca.0.load, i64 %11
  %13 = load double, ptr %12, align 8, !tbaa !4
  %14 = load i32, ptr %0, align 4, !tbaa !4
  %15 = sext i32 %14 to i64
  %16 = sub i64 %15, %.fca.7.0.0.load
  %17 = getelementptr double, ptr %.fca.0.load, i64 %16
  %18 = load double, ptr %17, align 8, !tbaa !4
  %19 = fadd contract double %13, %18
  store double %19, ptr %1, align 8, !tbaa !4
  call void @free(ptr %.fca.0.load)
  store ptr null, ptr %5, align 8, !tbaa !8
  store i64 8, ptr %.fca.1.gep, align 8, !tbaa !8
  store i32 20180515, ptr %.fca.2.gep, align 8, !tbaa !8
  store i8 1, ptr %.fca.3.gep, align 4, !tbaa !8
  store i8 28, ptr %.fca.4.gep, align 1, !tbaa !8
  store i8 2, ptr %.fca.5.gep, align 2, !tbaa !8
  store i8 0, ptr %.fca.6.gep, align 1, !tbaa !8
  store i64 1, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  store i64 0, ptr %.fca.7.0.1.gep, align 8, !tbaa !8
  store i64 8, ptr %.fca.7.0.2.gep, align 8, !tbaa !8
  ret void
}
*** IR Dump After DSEPass on _QFPomp_subroutine ***
define void @_QFPomp_subroutine(ptr %0, ptr %1, ptr nest %2) local_unnamed_addr {
entry:
  %structArg = alloca { ptr, ptr, ptr, ptr, ptr }, align 8
  %3 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %4 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %5 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %.fca.1.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 1
  %.fca.2.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 2
  %.fca.3.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 3
  %.fca.4.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 4
  %.fca.5.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 5
  %.fca.6.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 6
  %.fca.7.0.0.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 0
  %.fca.7.0.1.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 1
  %.fca.7.0.2.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 2
  %6 = load i32, ptr %0, align 4, !tbaa !4
  %7 = tail call i32 @llvm.smax.i32(i32 %6, i32 0)
  %8 = zext i32 %7 to i64
  %9 = shl nuw nsw i64 %8, 3
  %10 = tail call ptr @malloc(i64 %9)
  store ptr %10, ptr %5, align 8, !tbaa !8
  store i64 8, ptr %.fca.1.gep, align 8, !tbaa !8
  store i32 20180515, ptr %.fca.2.gep, align 8, !tbaa !8
  store i8 1, ptr %.fca.3.gep, align 4, !tbaa !8
  store i8 28, ptr %.fca.4.gep, align 1, !tbaa !8
  store i8 2, ptr %.fca.5.gep, align 2, !tbaa !8
  store i8 0, ptr %.fca.6.gep, align 1, !tbaa !8
  store i64 1, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  store i64 %8, ptr %.fca.7.0.1.gep, align 8, !tbaa !8
  store i64 8, ptr %.fca.7.0.2.gep, align 8, !tbaa !8
  %omp_global_thread_num = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %0, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %5, ptr %gep_5, align 8
  %gep_6 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 2
  store ptr %4, ptr %gep_6, align 8
  %gep_7 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 3
  store ptr %3, ptr %gep_7, align 8
  %gep_8 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 4
  store ptr %2, ptr %gep_8, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QFPomp_subroutine..omp_par, ptr nonnull %structArg)
  %.fca.0.load = load ptr, ptr %5, align 8, !tbaa !8
  %.fca.7.0.0.load = load i64, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  %11 = sub i64 1, %.fca.7.0.0.load
  %12 = getelementptr double, ptr %.fca.0.load, i64 %11
  %13 = load double, ptr %12, align 8, !tbaa !4
  %14 = load i32, ptr %0, align 4, !tbaa !4
  %15 = sext i32 %14 to i64
  %16 = sub i64 %15, %.fca.7.0.0.load
  %17 = getelementptr double, ptr %.fca.0.load, i64 %16
  %18 = load double, ptr %17, align 8, !tbaa !4
  %19 = fadd contract double %13, %18
  store double %19, ptr %1, align 8, !tbaa !4
  call void @free(ptr %.fca.0.load)
  ret void
}
*** IR Dump After MoveAutoInitPass on _QFPomp_subroutine ***
define void @_QFPomp_subroutine(ptr %0, ptr %1, ptr nest %2) local_unnamed_addr {
entry:
  %structArg = alloca { ptr, ptr, ptr, ptr, ptr }, align 8
  %3 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %4 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %5 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %.fca.1.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 1
  %.fca.2.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 2
  %.fca.3.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 3
  %.fca.4.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 4
  %.fca.5.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 5
  %.fca.6.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 6
  %.fca.7.0.0.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 0
  %.fca.7.0.1.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 1
  %.fca.7.0.2.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 2
  %6 = load i32, ptr %0, align 4, !tbaa !4
  %7 = tail call i32 @llvm.smax.i32(i32 %6, i32 0)
  %8 = zext i32 %7 to i64
  %9 = shl nuw nsw i64 %8, 3
  %10 = tail call ptr @malloc(i64 %9)
  store ptr %10, ptr %5, align 8, !tbaa !8
  store i64 8, ptr %.fca.1.gep, align 8, !tbaa !8
  store i32 20180515, ptr %.fca.2.gep, align 8, !tbaa !8
  store i8 1, ptr %.fca.3.gep, align 4, !tbaa !8
  store i8 28, ptr %.fca.4.gep, align 1, !tbaa !8
  store i8 2, ptr %.fca.5.gep, align 2, !tbaa !8
  store i8 0, ptr %.fca.6.gep, align 1, !tbaa !8
  store i64 1, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  store i64 %8, ptr %.fca.7.0.1.gep, align 8, !tbaa !8
  store i64 8, ptr %.fca.7.0.2.gep, align 8, !tbaa !8
  %omp_global_thread_num = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %0, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %5, ptr %gep_5, align 8
  %gep_6 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 2
  store ptr %4, ptr %gep_6, align 8
  %gep_7 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 3
  store ptr %3, ptr %gep_7, align 8
  %gep_8 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 4
  store ptr %2, ptr %gep_8, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QFPomp_subroutine..omp_par, ptr nonnull %structArg)
  %.fca.0.load = load ptr, ptr %5, align 8, !tbaa !8
  %.fca.7.0.0.load = load i64, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  %11 = sub i64 1, %.fca.7.0.0.load
  %12 = getelementptr double, ptr %.fca.0.load, i64 %11
  %13 = load double, ptr %12, align 8, !tbaa !4
  %14 = load i32, ptr %0, align 4, !tbaa !4
  %15 = sext i32 %14 to i64
  %16 = sub i64 %15, %.fca.7.0.0.load
  %17 = getelementptr double, ptr %.fca.0.load, i64 %16
  %18 = load double, ptr %17, align 8, !tbaa !4
  %19 = fadd contract double %13, %18
  store double %19, ptr %1, align 8, !tbaa !4
  call void @free(ptr %.fca.0.load)
  ret void
}
*** IR Dump After LoopSimplifyPass on _QFPomp_subroutine ***
define void @_QFPomp_subroutine(ptr %0, ptr %1, ptr nest %2) local_unnamed_addr {
entry:
  %structArg = alloca { ptr, ptr, ptr, ptr, ptr }, align 8
  %3 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %4 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %5 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %.fca.1.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 1
  %.fca.2.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 2
  %.fca.3.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 3
  %.fca.4.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 4
  %.fca.5.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 5
  %.fca.6.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 6
  %.fca.7.0.0.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 0
  %.fca.7.0.1.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 1
  %.fca.7.0.2.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 2
  %6 = load i32, ptr %0, align 4, !tbaa !4
  %7 = tail call i32 @llvm.smax.i32(i32 %6, i32 0)
  %8 = zext i32 %7 to i64
  %9 = shl nuw nsw i64 %8, 3
  %10 = tail call ptr @malloc(i64 %9)
  store ptr %10, ptr %5, align 8, !tbaa !8
  store i64 8, ptr %.fca.1.gep, align 8, !tbaa !8
  store i32 20180515, ptr %.fca.2.gep, align 8, !tbaa !8
  store i8 1, ptr %.fca.3.gep, align 4, !tbaa !8
  store i8 28, ptr %.fca.4.gep, align 1, !tbaa !8
  store i8 2, ptr %.fca.5.gep, align 2, !tbaa !8
  store i8 0, ptr %.fca.6.gep, align 1, !tbaa !8
  store i64 1, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  store i64 %8, ptr %.fca.7.0.1.gep, align 8, !tbaa !8
  store i64 8, ptr %.fca.7.0.2.gep, align 8, !tbaa !8
  %omp_global_thread_num = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %0, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %5, ptr %gep_5, align 8
  %gep_6 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 2
  store ptr %4, ptr %gep_6, align 8
  %gep_7 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 3
  store ptr %3, ptr %gep_7, align 8
  %gep_8 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 4
  store ptr %2, ptr %gep_8, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QFPomp_subroutine..omp_par, ptr nonnull %structArg)
  %.fca.0.load = load ptr, ptr %5, align 8, !tbaa !8
  %.fca.7.0.0.load = load i64, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  %11 = sub i64 1, %.fca.7.0.0.load
  %12 = getelementptr double, ptr %.fca.0.load, i64 %11
  %13 = load double, ptr %12, align 8, !tbaa !4
  %14 = load i32, ptr %0, align 4, !tbaa !4
  %15 = sext i32 %14 to i64
  %16 = sub i64 %15, %.fca.7.0.0.load
  %17 = getelementptr double, ptr %.fca.0.load, i64 %16
  %18 = load double, ptr %17, align 8, !tbaa !4
  %19 = fadd contract double %13, %18
  store double %19, ptr %1, align 8, !tbaa !4
  call void @free(ptr %.fca.0.load)
  ret void
}
*** IR Dump After LCSSAPass on _QFPomp_subroutine ***
define void @_QFPomp_subroutine(ptr %0, ptr %1, ptr nest %2) local_unnamed_addr {
entry:
  %structArg = alloca { ptr, ptr, ptr, ptr, ptr }, align 8
  %3 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %4 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %5 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %.fca.1.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 1
  %.fca.2.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 2
  %.fca.3.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 3
  %.fca.4.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 4
  %.fca.5.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 5
  %.fca.6.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 6
  %.fca.7.0.0.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 0
  %.fca.7.0.1.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 1
  %.fca.7.0.2.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 2
  %6 = load i32, ptr %0, align 4, !tbaa !4
  %7 = tail call i32 @llvm.smax.i32(i32 %6, i32 0)
  %8 = zext i32 %7 to i64
  %9 = shl nuw nsw i64 %8, 3
  %10 = tail call ptr @malloc(i64 %9)
  store ptr %10, ptr %5, align 8, !tbaa !8
  store i64 8, ptr %.fca.1.gep, align 8, !tbaa !8
  store i32 20180515, ptr %.fca.2.gep, align 8, !tbaa !8
  store i8 1, ptr %.fca.3.gep, align 4, !tbaa !8
  store i8 28, ptr %.fca.4.gep, align 1, !tbaa !8
  store i8 2, ptr %.fca.5.gep, align 2, !tbaa !8
  store i8 0, ptr %.fca.6.gep, align 1, !tbaa !8
  store i64 1, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  store i64 %8, ptr %.fca.7.0.1.gep, align 8, !tbaa !8
  store i64 8, ptr %.fca.7.0.2.gep, align 8, !tbaa !8
  %omp_global_thread_num = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %0, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %5, ptr %gep_5, align 8
  %gep_6 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 2
  store ptr %4, ptr %gep_6, align 8
  %gep_7 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 3
  store ptr %3, ptr %gep_7, align 8
  %gep_8 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 4
  store ptr %2, ptr %gep_8, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QFPomp_subroutine..omp_par, ptr nonnull %structArg)
  %.fca.0.load = load ptr, ptr %5, align 8, !tbaa !8
  %.fca.7.0.0.load = load i64, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  %11 = sub i64 1, %.fca.7.0.0.load
  %12 = getelementptr double, ptr %.fca.0.load, i64 %11
  %13 = load double, ptr %12, align 8, !tbaa !4
  %14 = load i32, ptr %0, align 4, !tbaa !4
  %15 = sext i32 %14 to i64
  %16 = sub i64 %15, %.fca.7.0.0.load
  %17 = getelementptr double, ptr %.fca.0.load, i64 %16
  %18 = load double, ptr %17, align 8, !tbaa !4
  %19 = fadd contract double %13, %18
  store double %19, ptr %1, align 8, !tbaa !4
  call void @free(ptr %.fca.0.load)
  ret void
}
*** IR Dump After CoroElidePass on _QFPomp_subroutine ***
define void @_QFPomp_subroutine(ptr %0, ptr %1, ptr nest %2) local_unnamed_addr {
entry:
  %structArg = alloca { ptr, ptr, ptr, ptr, ptr }, align 8
  %3 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %4 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %5 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %.fca.1.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 1
  %.fca.2.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 2
  %.fca.3.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 3
  %.fca.4.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 4
  %.fca.5.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 5
  %.fca.6.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 6
  %.fca.7.0.0.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 0
  %.fca.7.0.1.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 1
  %.fca.7.0.2.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 2
  %6 = load i32, ptr %0, align 4, !tbaa !4
  %7 = tail call i32 @llvm.smax.i32(i32 %6, i32 0)
  %8 = zext i32 %7 to i64
  %9 = shl nuw nsw i64 %8, 3
  %10 = tail call ptr @malloc(i64 %9)
  store ptr %10, ptr %5, align 8, !tbaa !8
  store i64 8, ptr %.fca.1.gep, align 8, !tbaa !8
  store i32 20180515, ptr %.fca.2.gep, align 8, !tbaa !8
  store i8 1, ptr %.fca.3.gep, align 4, !tbaa !8
  store i8 28, ptr %.fca.4.gep, align 1, !tbaa !8
  store i8 2, ptr %.fca.5.gep, align 2, !tbaa !8
  store i8 0, ptr %.fca.6.gep, align 1, !tbaa !8
  store i64 1, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  store i64 %8, ptr %.fca.7.0.1.gep, align 8, !tbaa !8
  store i64 8, ptr %.fca.7.0.2.gep, align 8, !tbaa !8
  %omp_global_thread_num = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %0, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %5, ptr %gep_5, align 8
  %gep_6 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 2
  store ptr %4, ptr %gep_6, align 8
  %gep_7 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 3
  store ptr %3, ptr %gep_7, align 8
  %gep_8 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 4
  store ptr %2, ptr %gep_8, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QFPomp_subroutine..omp_par, ptr nonnull %structArg)
  %.fca.0.load = load ptr, ptr %5, align 8, !tbaa !8
  %.fca.7.0.0.load = load i64, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  %11 = sub i64 1, %.fca.7.0.0.load
  %12 = getelementptr double, ptr %.fca.0.load, i64 %11
  %13 = load double, ptr %12, align 8, !tbaa !4
  %14 = load i32, ptr %0, align 4, !tbaa !4
  %15 = sext i32 %14 to i64
  %16 = sub i64 %15, %.fca.7.0.0.load
  %17 = getelementptr double, ptr %.fca.0.load, i64 %16
  %18 = load double, ptr %17, align 8, !tbaa !4
  %19 = fadd contract double %13, %18
  store double %19, ptr %1, align 8, !tbaa !4
  call void @free(ptr %.fca.0.load)
  ret void
}
*** IR Dump After SimplifyCFGPass on _QFPomp_subroutine ***
define void @_QFPomp_subroutine(ptr %0, ptr %1, ptr nest %2) local_unnamed_addr {
entry:
  %structArg = alloca { ptr, ptr, ptr, ptr, ptr }, align 8
  %3 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %4 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %5 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %.fca.1.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 1
  %.fca.2.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 2
  %.fca.3.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 3
  %.fca.4.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 4
  %.fca.5.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 5
  %.fca.6.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 6
  %.fca.7.0.0.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 0
  %.fca.7.0.1.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 1
  %.fca.7.0.2.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 2
  %6 = load i32, ptr %0, align 4, !tbaa !4
  %7 = tail call i32 @llvm.smax.i32(i32 %6, i32 0)
  %8 = zext i32 %7 to i64
  %9 = shl nuw nsw i64 %8, 3
  %10 = tail call ptr @malloc(i64 %9)
  store ptr %10, ptr %5, align 8, !tbaa !8
  store i64 8, ptr %.fca.1.gep, align 8, !tbaa !8
  store i32 20180515, ptr %.fca.2.gep, align 8, !tbaa !8
  store i8 1, ptr %.fca.3.gep, align 4, !tbaa !8
  store i8 28, ptr %.fca.4.gep, align 1, !tbaa !8
  store i8 2, ptr %.fca.5.gep, align 2, !tbaa !8
  store i8 0, ptr %.fca.6.gep, align 1, !tbaa !8
  store i64 1, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  store i64 %8, ptr %.fca.7.0.1.gep, align 8, !tbaa !8
  store i64 8, ptr %.fca.7.0.2.gep, align 8, !tbaa !8
  %omp_global_thread_num = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %0, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %5, ptr %gep_5, align 8
  %gep_6 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 2
  store ptr %4, ptr %gep_6, align 8
  %gep_7 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 3
  store ptr %3, ptr %gep_7, align 8
  %gep_8 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 4
  store ptr %2, ptr %gep_8, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QFPomp_subroutine..omp_par, ptr nonnull %structArg)
  %.fca.0.load = load ptr, ptr %5, align 8, !tbaa !8
  %.fca.7.0.0.load = load i64, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  %11 = sub i64 1, %.fca.7.0.0.load
  %12 = getelementptr double, ptr %.fca.0.load, i64 %11
  %13 = load double, ptr %12, align 8, !tbaa !4
  %14 = load i32, ptr %0, align 4, !tbaa !4
  %15 = sext i32 %14 to i64
  %16 = sub i64 %15, %.fca.7.0.0.load
  %17 = getelementptr double, ptr %.fca.0.load, i64 %16
  %18 = load double, ptr %17, align 8, !tbaa !4
  %19 = fadd contract double %13, %18
  store double %19, ptr %1, align 8, !tbaa !4
  call void @free(ptr %.fca.0.load)
  ret void
}
*** IR Dump After InstCombinePass on _QFPomp_subroutine ***
define void @_QFPomp_subroutine(ptr %0, ptr %1, ptr nest %2) local_unnamed_addr {
entry:
  %structArg = alloca { ptr, ptr, ptr, ptr, ptr }, align 8
  %3 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %4 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %5 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %.fca.1.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 1
  %.fca.2.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 2
  %.fca.3.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 3
  %.fca.4.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 4
  %.fca.5.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 5
  %.fca.6.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 6
  %.fca.7.0.0.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 0
  %.fca.7.0.1.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 1
  %.fca.7.0.2.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 2
  %6 = load i32, ptr %0, align 4, !tbaa !4
  %7 = tail call i32 @llvm.smax.i32(i32 %6, i32 0)
  %8 = zext i32 %7 to i64
  %9 = shl nuw nsw i64 %8, 3
  %10 = tail call ptr @malloc(i64 %9)
  store ptr %10, ptr %5, align 8, !tbaa !8
  store i64 8, ptr %.fca.1.gep, align 8, !tbaa !8
  store i32 20180515, ptr %.fca.2.gep, align 8, !tbaa !8
  store i8 1, ptr %.fca.3.gep, align 4, !tbaa !8
  store i8 28, ptr %.fca.4.gep, align 1, !tbaa !8
  store i8 2, ptr %.fca.5.gep, align 2, !tbaa !8
  store i8 0, ptr %.fca.6.gep, align 1, !tbaa !8
  store i64 1, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  store i64 %8, ptr %.fca.7.0.1.gep, align 8, !tbaa !8
  store i64 8, ptr %.fca.7.0.2.gep, align 8, !tbaa !8
  %omp_global_thread_num = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %0, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %5, ptr %gep_5, align 8
  %gep_6 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 2
  store ptr %4, ptr %gep_6, align 8
  %gep_7 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 3
  store ptr %3, ptr %gep_7, align 8
  %gep_8 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 4
  store ptr %2, ptr %gep_8, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QFPomp_subroutine..omp_par, ptr nonnull %structArg)
  %.fca.0.load = load ptr, ptr %5, align 8, !tbaa !8
  %.fca.7.0.0.load = load i64, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  %11 = sub i64 1, %.fca.7.0.0.load
  %12 = getelementptr double, ptr %.fca.0.load, i64 %11
  %13 = load double, ptr %12, align 8, !tbaa !4
  %14 = load i32, ptr %0, align 4, !tbaa !4
  %15 = sext i32 %14 to i64
  %16 = sub i64 %15, %.fca.7.0.0.load
  %17 = getelementptr double, ptr %.fca.0.load, i64 %16
  %18 = load double, ptr %17, align 8, !tbaa !4
  %19 = fadd contract double %13, %18
  store double %19, ptr %1, align 8, !tbaa !4
  call void @free(ptr %.fca.0.load)
  ret void
}
*** IR Dump After PostOrderFunctionAttrsPass on (_QFPomp_subroutine) ***
; Function Attrs: nounwind
define void @_QFPomp_subroutine(ptr %0, ptr nocapture writeonly %1, ptr nest %2) local_unnamed_addr #2 {
entry:
  %structArg = alloca { ptr, ptr, ptr, ptr, ptr }, align 8
  %3 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %4 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %5 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %.fca.1.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 1
  %.fca.2.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 2
  %.fca.3.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 3
  %.fca.4.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 4
  %.fca.5.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 5
  %.fca.6.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 6
  %.fca.7.0.0.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 0
  %.fca.7.0.1.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 1
  %.fca.7.0.2.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 2
  %6 = load i32, ptr %0, align 4, !tbaa !4
  %7 = tail call i32 @llvm.smax.i32(i32 %6, i32 0)
  %8 = zext i32 %7 to i64
  %9 = shl nuw nsw i64 %8, 3
  %10 = tail call ptr @malloc(i64 %9)
  store ptr %10, ptr %5, align 8, !tbaa !8
  store i64 8, ptr %.fca.1.gep, align 8, !tbaa !8
  store i32 20180515, ptr %.fca.2.gep, align 8, !tbaa !8
  store i8 1, ptr %.fca.3.gep, align 4, !tbaa !8
  store i8 28, ptr %.fca.4.gep, align 1, !tbaa !8
  store i8 2, ptr %.fca.5.gep, align 2, !tbaa !8
  store i8 0, ptr %.fca.6.gep, align 1, !tbaa !8
  store i64 1, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  store i64 %8, ptr %.fca.7.0.1.gep, align 8, !tbaa !8
  store i64 8, ptr %.fca.7.0.2.gep, align 8, !tbaa !8
  %omp_global_thread_num = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %0, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %5, ptr %gep_5, align 8
  %gep_6 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 2
  store ptr %4, ptr %gep_6, align 8
  %gep_7 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 3
  store ptr %3, ptr %gep_7, align 8
  %gep_8 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 4
  store ptr %2, ptr %gep_8, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QFPomp_subroutine..omp_par, ptr nonnull %structArg)
  %.fca.0.load = load ptr, ptr %5, align 8, !tbaa !8
  %.fca.7.0.0.load = load i64, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  %11 = sub i64 1, %.fca.7.0.0.load
  %12 = getelementptr double, ptr %.fca.0.load, i64 %11
  %13 = load double, ptr %12, align 8, !tbaa !4
  %14 = load i32, ptr %0, align 4, !tbaa !4
  %15 = sext i32 %14 to i64
  %16 = sub i64 %15, %.fca.7.0.0.load
  %17 = getelementptr double, ptr %.fca.0.load, i64 %16
  %18 = load double, ptr %17, align 8, !tbaa !4
  %19 = fadd contract double %13, %18
  store double %19, ptr %1, align 8, !tbaa !4
  call void @free(ptr %.fca.0.load)
  ret void
}
*** IR Dump After RequireAnalysisPass<llvm::ShouldNotRunFunctionPassesAnalysis, llvm::Function> on _QFPomp_subroutine ***
; Function Attrs: nounwind
define void @_QFPomp_subroutine(ptr %0, ptr nocapture writeonly %1, ptr nest %2) local_unnamed_addr #2 {
entry:
  %structArg = alloca { ptr, ptr, ptr, ptr, ptr }, align 8
  %3 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %4 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %5 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %.fca.1.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 1
  %.fca.2.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 2
  %.fca.3.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 3
  %.fca.4.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 4
  %.fca.5.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 5
  %.fca.6.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 6
  %.fca.7.0.0.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 0
  %.fca.7.0.1.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 1
  %.fca.7.0.2.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 2
  %6 = load i32, ptr %0, align 4, !tbaa !4
  %7 = tail call i32 @llvm.smax.i32(i32 %6, i32 0)
  %8 = zext i32 %7 to i64
  %9 = shl nuw nsw i64 %8, 3
  %10 = tail call ptr @malloc(i64 %9)
  store ptr %10, ptr %5, align 8, !tbaa !8
  store i64 8, ptr %.fca.1.gep, align 8, !tbaa !8
  store i32 20180515, ptr %.fca.2.gep, align 8, !tbaa !8
  store i8 1, ptr %.fca.3.gep, align 4, !tbaa !8
  store i8 28, ptr %.fca.4.gep, align 1, !tbaa !8
  store i8 2, ptr %.fca.5.gep, align 2, !tbaa !8
  store i8 0, ptr %.fca.6.gep, align 1, !tbaa !8
  store i64 1, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  store i64 %8, ptr %.fca.7.0.1.gep, align 8, !tbaa !8
  store i64 8, ptr %.fca.7.0.2.gep, align 8, !tbaa !8
  %omp_global_thread_num = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %0, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %5, ptr %gep_5, align 8
  %gep_6 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 2
  store ptr %4, ptr %gep_6, align 8
  %gep_7 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 3
  store ptr %3, ptr %gep_7, align 8
  %gep_8 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 4
  store ptr %2, ptr %gep_8, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QFPomp_subroutine..omp_par, ptr nonnull %structArg)
  %.fca.0.load = load ptr, ptr %5, align 8, !tbaa !8
  %.fca.7.0.0.load = load i64, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  %11 = sub i64 1, %.fca.7.0.0.load
  %12 = getelementptr double, ptr %.fca.0.load, i64 %11
  %13 = load double, ptr %12, align 8, !tbaa !4
  %14 = load i32, ptr %0, align 4, !tbaa !4
  %15 = sext i32 %14 to i64
  %16 = sub i64 %15, %.fca.7.0.0.load
  %17 = getelementptr double, ptr %.fca.0.load, i64 %16
  %18 = load double, ptr %17, align 8, !tbaa !4
  %19 = fadd contract double %13, %18
  store double %19, ptr %1, align 8, !tbaa !4
  call void @free(ptr %.fca.0.load)
  ret void
}
*** IR Dump After CoroSplitPass on (_QFPomp_subroutine) ***
; Function Attrs: nounwind
define void @_QFPomp_subroutine(ptr %0, ptr nocapture writeonly %1, ptr nest %2) local_unnamed_addr #2 {
entry:
  %structArg = alloca { ptr, ptr, ptr, ptr, ptr }, align 8
  %3 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %4 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %5 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %.fca.1.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 1
  %.fca.2.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 2
  %.fca.3.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 3
  %.fca.4.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 4
  %.fca.5.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 5
  %.fca.6.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 6
  %.fca.7.0.0.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 0
  %.fca.7.0.1.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 1
  %.fca.7.0.2.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 2
  %6 = load i32, ptr %0, align 4, !tbaa !4
  %7 = tail call i32 @llvm.smax.i32(i32 %6, i32 0)
  %8 = zext i32 %7 to i64
  %9 = shl nuw nsw i64 %8, 3
  %10 = tail call ptr @malloc(i64 %9)
  store ptr %10, ptr %5, align 8, !tbaa !8
  store i64 8, ptr %.fca.1.gep, align 8, !tbaa !8
  store i32 20180515, ptr %.fca.2.gep, align 8, !tbaa !8
  store i8 1, ptr %.fca.3.gep, align 4, !tbaa !8
  store i8 28, ptr %.fca.4.gep, align 1, !tbaa !8
  store i8 2, ptr %.fca.5.gep, align 2, !tbaa !8
  store i8 0, ptr %.fca.6.gep, align 1, !tbaa !8
  store i64 1, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  store i64 %8, ptr %.fca.7.0.1.gep, align 8, !tbaa !8
  store i64 8, ptr %.fca.7.0.2.gep, align 8, !tbaa !8
  %omp_global_thread_num = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %0, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %5, ptr %gep_5, align 8
  %gep_6 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 2
  store ptr %4, ptr %gep_6, align 8
  %gep_7 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 3
  store ptr %3, ptr %gep_7, align 8
  %gep_8 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 4
  store ptr %2, ptr %gep_8, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QFPomp_subroutine..omp_par, ptr nonnull %structArg)
  %.fca.0.load = load ptr, ptr %5, align 8, !tbaa !8
  %.fca.7.0.0.load = load i64, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  %11 = sub i64 1, %.fca.7.0.0.load
  %12 = getelementptr double, ptr %.fca.0.load, i64 %11
  %13 = load double, ptr %12, align 8, !tbaa !4
  %14 = load i32, ptr %0, align 4, !tbaa !4
  %15 = sext i32 %14 to i64
  %16 = sub i64 %15, %.fca.7.0.0.load
  %17 = getelementptr double, ptr %.fca.0.load, i64 %16
  %18 = load double, ptr %17, align 8, !tbaa !4
  %19 = fadd contract double %13, %18
  store double %19, ptr %1, align 8, !tbaa !4
  call void @free(ptr %.fca.0.load)
  ret void
}
*** IR Dump After InlinerPass on (_QQmain) ***
define void @_QQmain() local_unnamed_addr {
  %1 = alloca i32, align 4
  %2 = alloca double, align 8
  %3 = alloca double, align 8
  %4 = alloca { ptr, ptr }, align 8
  store ptr %1, ptr %4, align 8, !tbaa !4
  %5 = getelementptr inbounds { ptr, ptr }, ptr %4, i64 0, i32 1
  store ptr %3, ptr %5, align 8, !tbaa !4
  store i32 1048576, ptr %1, align 4, !tbaa !4
  call void @_QFPomp_subroutine(ptr nonnull %1, ptr nonnull %2, ptr nonnull %4)
  %6 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.e8a0ac9186c064ac8543d822e9060d96, i32 10)
  %7 = call i1 @_FortranAioOutputAscii(ptr %6, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %8 = load i32, ptr %1, align 4, !tbaa !4
  %9 = call i1 @_FortranAioOutputInteger32(ptr %6, i32 %8)
  %10 = call i1 @_FortranAioOutputAscii(ptr %6, ptr nonnull @_QQcl.2920697320, i64 5)
  %11 = load double, ptr %2, align 8, !tbaa !4
  %12 = call i1 @_FortranAioOutputReal64(ptr %6, double %11)
  %13 = call i32 @_FortranAioEndIoStatement(ptr %6)
  ret void
}
*** IR Dump After InlinerPass on (_QQmain) ***
define void @_QQmain() local_unnamed_addr {
  %structArg.i = alloca { ptr, ptr, ptr, ptr, ptr }, align 8
  %1 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %2 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %3 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %4 = alloca i32, align 4
  %5 = alloca double, align 8
  %6 = alloca double, align 8
  %7 = alloca { ptr, ptr }, align 8
  store ptr %4, ptr %7, align 8, !tbaa !4
  %8 = getelementptr inbounds { ptr, ptr }, ptr %7, i64 0, i32 1
  store ptr %6, ptr %8, align 8, !tbaa !4
  store i32 1048576, ptr %4, align 4, !tbaa !4
  call void @llvm.lifetime.start.p0(i64 40, ptr %structArg.i)
  call void @llvm.lifetime.start.p0(i64 48, ptr %1)
  call void @llvm.lifetime.start.p0(i64 48, ptr %2)
  call void @llvm.lifetime.start.p0(i64 48, ptr %3)
  %.fca.1.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 1
  %.fca.2.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 2
  %.fca.3.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 3
  %.fca.4.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 4
  %.fca.5.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 5
  %.fca.6.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 6
  %.fca.7.0.0.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 7, i64 0, i64 0
  %.fca.7.0.1.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 7, i64 0, i64 1
  %.fca.7.0.2.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 7, i64 0, i64 2
  %9 = load i32, ptr %4, align 4, !tbaa !4
  %10 = call i32 @llvm.smax.i32(i32 %9, i32 0)
  %11 = zext i32 %10 to i64
  %12 = shl nuw nsw i64 %11, 3
  %13 = call ptr @malloc(i64 %12)
  store ptr %13, ptr %3, align 8, !tbaa !8
  store i64 8, ptr %.fca.1.gep.i, align 8, !tbaa !8
  store i32 20180515, ptr %.fca.2.gep.i, align 8, !tbaa !8
  store i8 1, ptr %.fca.3.gep.i, align 4, !tbaa !8
  store i8 28, ptr %.fca.4.gep.i, align 1, !tbaa !8
  store i8 2, ptr %.fca.5.gep.i, align 2, !tbaa !8
  store i8 0, ptr %.fca.6.gep.i, align 1, !tbaa !8
  store i64 1, ptr %.fca.7.0.0.gep.i, align 8, !tbaa !8
  store i64 %11, ptr %.fca.7.0.1.gep.i, align 8, !tbaa !8
  store i64 8, ptr %.fca.7.0.2.gep.i, align 8, !tbaa !8
  %omp_global_thread_num.i = call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %4, ptr %structArg.i, align 8
  %gep_5.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 1
  store ptr %3, ptr %gep_5.i, align 8
  %gep_6.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 2
  store ptr %2, ptr %gep_6.i, align 8
  %gep_7.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 3
  store ptr %1, ptr %gep_7.i, align 8
  %gep_8.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 4
  store ptr %7, ptr %gep_8.i, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QFPomp_subroutine..omp_par, ptr nonnull %structArg.i)
  %.fca.0.load.i = load ptr, ptr %3, align 8, !tbaa !8
  %.fca.7.0.0.load.i = load i64, ptr %.fca.7.0.0.gep.i, align 8, !tbaa !8
  %14 = sub i64 1, %.fca.7.0.0.load.i
  %15 = getelementptr double, ptr %.fca.0.load.i, i64 %14
  %16 = load double, ptr %15, align 8, !tbaa !4
  %17 = load i32, ptr %4, align 4, !tbaa !4
  %18 = sext i32 %17 to i64
  %19 = sub i64 %18, %.fca.7.0.0.load.i
  %20 = getelementptr double, ptr %.fca.0.load.i, i64 %19
  %21 = load double, ptr %20, align 8, !tbaa !4
  %22 = fadd contract double %16, %21
  store double %22, ptr %5, align 8, !tbaa !4
  call void @free(ptr %.fca.0.load.i)
  call void @llvm.lifetime.end.p0(i64 40, ptr %structArg.i)
  call void @llvm.lifetime.end.p0(i64 48, ptr %1)
  call void @llvm.lifetime.end.p0(i64 48, ptr %2)
  call void @llvm.lifetime.end.p0(i64 48, ptr %3)
  %23 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.e8a0ac9186c064ac8543d822e9060d96, i32 10)
  %24 = call i1 @_FortranAioOutputAscii(ptr %23, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %25 = load i32, ptr %4, align 4, !tbaa !4
  %26 = call i1 @_FortranAioOutputInteger32(ptr %23, i32 %25)
  %27 = call i1 @_FortranAioOutputAscii(ptr %23, ptr nonnull @_QQcl.2920697320, i64 5)
  %28 = load double, ptr %5, align 8, !tbaa !4
  %29 = call i1 @_FortranAioOutputReal64(ptr %23, double %28)
  %30 = call i32 @_FortranAioEndIoStatement(ptr %23)
  ret void
}
*** IR Dump After PostOrderFunctionAttrsPass on (_QQmain) ***
define void @_QQmain() local_unnamed_addr {
  %structArg.i = alloca { ptr, ptr, ptr, ptr, ptr }, align 8
  %1 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %2 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %3 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %4 = alloca i32, align 4
  %5 = alloca double, align 8
  %6 = alloca double, align 8
  %7 = alloca { ptr, ptr }, align 8
  store ptr %4, ptr %7, align 8, !tbaa !4
  %8 = getelementptr inbounds { ptr, ptr }, ptr %7, i64 0, i32 1
  store ptr %6, ptr %8, align 8, !tbaa !4
  store i32 1048576, ptr %4, align 4, !tbaa !4
  call void @llvm.lifetime.start.p0(i64 40, ptr %structArg.i)
  call void @llvm.lifetime.start.p0(i64 48, ptr %1)
  call void @llvm.lifetime.start.p0(i64 48, ptr %2)
  call void @llvm.lifetime.start.p0(i64 48, ptr %3)
  %.fca.1.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 1
  %.fca.2.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 2
  %.fca.3.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 3
  %.fca.4.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 4
  %.fca.5.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 5
  %.fca.6.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 6
  %.fca.7.0.0.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 7, i64 0, i64 0
  %.fca.7.0.1.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 7, i64 0, i64 1
  %.fca.7.0.2.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 7, i64 0, i64 2
  %9 = load i32, ptr %4, align 4, !tbaa !4
  %10 = call i32 @llvm.smax.i32(i32 %9, i32 0)
  %11 = zext i32 %10 to i64
  %12 = shl nuw nsw i64 %11, 3
  %13 = call ptr @malloc(i64 %12)
  store ptr %13, ptr %3, align 8, !tbaa !8
  store i64 8, ptr %.fca.1.gep.i, align 8, !tbaa !8
  store i32 20180515, ptr %.fca.2.gep.i, align 8, !tbaa !8
  store i8 1, ptr %.fca.3.gep.i, align 4, !tbaa !8
  store i8 28, ptr %.fca.4.gep.i, align 1, !tbaa !8
  store i8 2, ptr %.fca.5.gep.i, align 2, !tbaa !8
  store i8 0, ptr %.fca.6.gep.i, align 1, !tbaa !8
  store i64 1, ptr %.fca.7.0.0.gep.i, align 8, !tbaa !8
  store i64 %11, ptr %.fca.7.0.1.gep.i, align 8, !tbaa !8
  store i64 8, ptr %.fca.7.0.2.gep.i, align 8, !tbaa !8
  %omp_global_thread_num.i = call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %4, ptr %structArg.i, align 8
  %gep_5.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 1
  store ptr %3, ptr %gep_5.i, align 8
  %gep_6.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 2
  store ptr %2, ptr %gep_6.i, align 8
  %gep_7.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 3
  store ptr %1, ptr %gep_7.i, align 8
  %gep_8.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 4
  store ptr %7, ptr %gep_8.i, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QFPomp_subroutine..omp_par, ptr nonnull %structArg.i)
  %.fca.0.load.i = load ptr, ptr %3, align 8, !tbaa !8
  %.fca.7.0.0.load.i = load i64, ptr %.fca.7.0.0.gep.i, align 8, !tbaa !8
  %14 = sub i64 1, %.fca.7.0.0.load.i
  %15 = getelementptr double, ptr %.fca.0.load.i, i64 %14
  %16 = load double, ptr %15, align 8, !tbaa !4
  %17 = load i32, ptr %4, align 4, !tbaa !4
  %18 = sext i32 %17 to i64
  %19 = sub i64 %18, %.fca.7.0.0.load.i
  %20 = getelementptr double, ptr %.fca.0.load.i, i64 %19
  %21 = load double, ptr %20, align 8, !tbaa !4
  %22 = fadd contract double %16, %21
  store double %22, ptr %5, align 8, !tbaa !4
  call void @free(ptr %.fca.0.load.i)
  call void @llvm.lifetime.end.p0(i64 40, ptr %structArg.i)
  call void @llvm.lifetime.end.p0(i64 48, ptr %1)
  call void @llvm.lifetime.end.p0(i64 48, ptr %2)
  call void @llvm.lifetime.end.p0(i64 48, ptr %3)
  %23 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.e8a0ac9186c064ac8543d822e9060d96, i32 10)
  %24 = call i1 @_FortranAioOutputAscii(ptr %23, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %25 = load i32, ptr %4, align 4, !tbaa !4
  %26 = call i1 @_FortranAioOutputInteger32(ptr %23, i32 %25)
  %27 = call i1 @_FortranAioOutputAscii(ptr %23, ptr nonnull @_QQcl.2920697320, i64 5)
  %28 = load double, ptr %5, align 8, !tbaa !4
  %29 = call i1 @_FortranAioOutputReal64(ptr %23, double %28)
  %30 = call i32 @_FortranAioEndIoStatement(ptr %23)
  ret void
}
*** IR Dump After ArgumentPromotionPass on (_QQmain) ***
define void @_QQmain() local_unnamed_addr {
  %structArg.i = alloca { ptr, ptr, ptr, ptr, ptr }, align 8
  %1 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %2 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %3 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %4 = alloca i32, align 4
  %5 = alloca double, align 8
  %6 = alloca double, align 8
  %7 = alloca { ptr, ptr }, align 8
  store ptr %4, ptr %7, align 8, !tbaa !4
  %8 = getelementptr inbounds { ptr, ptr }, ptr %7, i64 0, i32 1
  store ptr %6, ptr %8, align 8, !tbaa !4
  store i32 1048576, ptr %4, align 4, !tbaa !4
  call void @llvm.lifetime.start.p0(i64 40, ptr %structArg.i)
  call void @llvm.lifetime.start.p0(i64 48, ptr %1)
  call void @llvm.lifetime.start.p0(i64 48, ptr %2)
  call void @llvm.lifetime.start.p0(i64 48, ptr %3)
  %.fca.1.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 1
  %.fca.2.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 2
  %.fca.3.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 3
  %.fca.4.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 4
  %.fca.5.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 5
  %.fca.6.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 6
  %.fca.7.0.0.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 7, i64 0, i64 0
  %.fca.7.0.1.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 7, i64 0, i64 1
  %.fca.7.0.2.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 7, i64 0, i64 2
  %9 = load i32, ptr %4, align 4, !tbaa !4
  %10 = call i32 @llvm.smax.i32(i32 %9, i32 0)
  %11 = zext i32 %10 to i64
  %12 = shl nuw nsw i64 %11, 3
  %13 = call ptr @malloc(i64 %12)
  store ptr %13, ptr %3, align 8, !tbaa !8
  store i64 8, ptr %.fca.1.gep.i, align 8, !tbaa !8
  store i32 20180515, ptr %.fca.2.gep.i, align 8, !tbaa !8
  store i8 1, ptr %.fca.3.gep.i, align 4, !tbaa !8
  store i8 28, ptr %.fca.4.gep.i, align 1, !tbaa !8
  store i8 2, ptr %.fca.5.gep.i, align 2, !tbaa !8
  store i8 0, ptr %.fca.6.gep.i, align 1, !tbaa !8
  store i64 1, ptr %.fca.7.0.0.gep.i, align 8, !tbaa !8
  store i64 %11, ptr %.fca.7.0.1.gep.i, align 8, !tbaa !8
  store i64 8, ptr %.fca.7.0.2.gep.i, align 8, !tbaa !8
  %omp_global_thread_num.i = call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %4, ptr %structArg.i, align 8
  %gep_5.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 1
  store ptr %3, ptr %gep_5.i, align 8
  %gep_6.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 2
  store ptr %2, ptr %gep_6.i, align 8
  %gep_7.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 3
  store ptr %1, ptr %gep_7.i, align 8
  %gep_8.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 4
  store ptr %7, ptr %gep_8.i, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QFPomp_subroutine..omp_par, ptr nonnull %structArg.i)
  %.fca.0.load.i = load ptr, ptr %3, align 8, !tbaa !8
  %.fca.7.0.0.load.i = load i64, ptr %.fca.7.0.0.gep.i, align 8, !tbaa !8
  %14 = sub i64 1, %.fca.7.0.0.load.i
  %15 = getelementptr double, ptr %.fca.0.load.i, i64 %14
  %16 = load double, ptr %15, align 8, !tbaa !4
  %17 = load i32, ptr %4, align 4, !tbaa !4
  %18 = sext i32 %17 to i64
  %19 = sub i64 %18, %.fca.7.0.0.load.i
  %20 = getelementptr double, ptr %.fca.0.load.i, i64 %19
  %21 = load double, ptr %20, align 8, !tbaa !4
  %22 = fadd contract double %16, %21
  store double %22, ptr %5, align 8, !tbaa !4
  call void @free(ptr %.fca.0.load.i)
  call void @llvm.lifetime.end.p0(i64 40, ptr %structArg.i)
  call void @llvm.lifetime.end.p0(i64 48, ptr %1)
  call void @llvm.lifetime.end.p0(i64 48, ptr %2)
  call void @llvm.lifetime.end.p0(i64 48, ptr %3)
  %23 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.e8a0ac9186c064ac8543d822e9060d96, i32 10)
  %24 = call i1 @_FortranAioOutputAscii(ptr %23, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %25 = load i32, ptr %4, align 4, !tbaa !4
  %26 = call i1 @_FortranAioOutputInteger32(ptr %23, i32 %25)
  %27 = call i1 @_FortranAioOutputAscii(ptr %23, ptr nonnull @_QQcl.2920697320, i64 5)
  %28 = load double, ptr %5, align 8, !tbaa !4
  %29 = call i1 @_FortranAioOutputReal64(ptr %23, double %28)
  %30 = call i32 @_FortranAioEndIoStatement(ptr %23)
  ret void
}
*** IR Dump After OpenMPOptCGSCCPass on (_QQmain) ***
define void @_QQmain() local_unnamed_addr {
  %structArg.i = alloca { ptr, ptr, ptr, ptr, ptr }, align 8
  %1 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %2 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %3 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %4 = alloca i32, align 4
  %5 = alloca double, align 8
  %6 = alloca double, align 8
  %7 = alloca { ptr, ptr }, align 8
  store ptr %4, ptr %7, align 8, !tbaa !4
  %8 = getelementptr inbounds { ptr, ptr }, ptr %7, i64 0, i32 1
  store ptr %6, ptr %8, align 8, !tbaa !4
  store i32 1048576, ptr %4, align 4, !tbaa !4
  call void @llvm.lifetime.start.p0(i64 40, ptr %structArg.i)
  call void @llvm.lifetime.start.p0(i64 48, ptr %1)
  call void @llvm.lifetime.start.p0(i64 48, ptr %2)
  call void @llvm.lifetime.start.p0(i64 48, ptr %3)
  %.fca.1.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 1
  %.fca.2.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 2
  %.fca.3.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 3
  %.fca.4.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 4
  %.fca.5.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 5
  %.fca.6.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 6
  %.fca.7.0.0.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 7, i64 0, i64 0
  %.fca.7.0.1.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 7, i64 0, i64 1
  %.fca.7.0.2.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 7, i64 0, i64 2
  %9 = load i32, ptr %4, align 4, !tbaa !4
  %10 = call i32 @llvm.smax.i32(i32 %9, i32 0)
  %11 = zext i32 %10 to i64
  %12 = shl nuw nsw i64 %11, 3
  %13 = call ptr @malloc(i64 %12)
  store ptr %13, ptr %3, align 8, !tbaa !8
  store i64 8, ptr %.fca.1.gep.i, align 8, !tbaa !8
  store i32 20180515, ptr %.fca.2.gep.i, align 8, !tbaa !8
  store i8 1, ptr %.fca.3.gep.i, align 4, !tbaa !8
  store i8 28, ptr %.fca.4.gep.i, align 1, !tbaa !8
  store i8 2, ptr %.fca.5.gep.i, align 2, !tbaa !8
  store i8 0, ptr %.fca.6.gep.i, align 1, !tbaa !8
  store i64 1, ptr %.fca.7.0.0.gep.i, align 8, !tbaa !8
  store i64 %11, ptr %.fca.7.0.1.gep.i, align 8, !tbaa !8
  store i64 8, ptr %.fca.7.0.2.gep.i, align 8, !tbaa !8
  %omp_global_thread_num.i = call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %4, ptr %structArg.i, align 8
  %gep_5.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 1
  store ptr %3, ptr %gep_5.i, align 8
  %gep_6.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 2
  store ptr %2, ptr %gep_6.i, align 8
  %gep_7.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 3
  store ptr %1, ptr %gep_7.i, align 8
  %gep_8.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 4
  store ptr %7, ptr %gep_8.i, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QFPomp_subroutine..omp_par, ptr nonnull %structArg.i)
  %.fca.0.load.i = load ptr, ptr %3, align 8, !tbaa !8
  %.fca.7.0.0.load.i = load i64, ptr %.fca.7.0.0.gep.i, align 8, !tbaa !8
  %14 = sub i64 1, %.fca.7.0.0.load.i
  %15 = getelementptr double, ptr %.fca.0.load.i, i64 %14
  %16 = load double, ptr %15, align 8, !tbaa !4
  %17 = load i32, ptr %4, align 4, !tbaa !4
  %18 = sext i32 %17 to i64
  %19 = sub i64 %18, %.fca.7.0.0.load.i
  %20 = getelementptr double, ptr %.fca.0.load.i, i64 %19
  %21 = load double, ptr %20, align 8, !tbaa !4
  %22 = fadd contract double %16, %21
  store double %22, ptr %5, align 8, !tbaa !4
  call void @free(ptr %.fca.0.load.i)
  call void @llvm.lifetime.end.p0(i64 40, ptr %structArg.i)
  call void @llvm.lifetime.end.p0(i64 48, ptr %1)
  call void @llvm.lifetime.end.p0(i64 48, ptr %2)
  call void @llvm.lifetime.end.p0(i64 48, ptr %3)
  %23 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.e8a0ac9186c064ac8543d822e9060d96, i32 10)
  %24 = call i1 @_FortranAioOutputAscii(ptr %23, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %25 = load i32, ptr %4, align 4, !tbaa !4
  %26 = call i1 @_FortranAioOutputInteger32(ptr %23, i32 %25)
  %27 = call i1 @_FortranAioOutputAscii(ptr %23, ptr nonnull @_QQcl.2920697320, i64 5)
  %28 = load double, ptr %5, align 8, !tbaa !4
  %29 = call i1 @_FortranAioOutputReal64(ptr %23, double %28)
  %30 = call i32 @_FortranAioEndIoStatement(ptr %23)
  ret void
}
*** IR Dump After SROAPass on _QQmain ***
define void @_QQmain() local_unnamed_addr {
  %structArg.i = alloca { ptr, ptr, ptr, ptr, ptr }, align 8
  %1 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %2 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %3 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %4 = alloca i32, align 4
  %5 = alloca double, align 8
  %6 = alloca { ptr, ptr }, align 8
  store ptr %4, ptr %6, align 8, !tbaa !4
  %7 = getelementptr inbounds { ptr, ptr }, ptr %6, i64 0, i32 1
  store ptr %5, ptr %7, align 8, !tbaa !4
  store i32 1048576, ptr %4, align 4, !tbaa !4
  call void @llvm.lifetime.start.p0(i64 40, ptr %structArg.i)
  call void @llvm.lifetime.start.p0(i64 48, ptr %1)
  call void @llvm.lifetime.start.p0(i64 48, ptr %2)
  call void @llvm.lifetime.start.p0(i64 48, ptr %3)
  %.fca.1.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 1
  %.fca.2.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 2
  %.fca.3.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 3
  %.fca.4.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 4
  %.fca.5.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 5
  %.fca.6.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 6
  %.fca.7.0.0.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 7, i64 0, i64 0
  %.fca.7.0.1.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 7, i64 0, i64 1
  %.fca.7.0.2.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 7, i64 0, i64 2
  %8 = load i32, ptr %4, align 4, !tbaa !4
  %9 = call i32 @llvm.smax.i32(i32 %8, i32 0)
  %10 = zext i32 %9 to i64
  %11 = shl nuw nsw i64 %10, 3
  %12 = call ptr @malloc(i64 %11)
  store ptr %12, ptr %3, align 8, !tbaa !8
  store i64 8, ptr %.fca.1.gep.i, align 8, !tbaa !8
  store i32 20180515, ptr %.fca.2.gep.i, align 8, !tbaa !8
  store i8 1, ptr %.fca.3.gep.i, align 4, !tbaa !8
  store i8 28, ptr %.fca.4.gep.i, align 1, !tbaa !8
  store i8 2, ptr %.fca.5.gep.i, align 2, !tbaa !8
  store i8 0, ptr %.fca.6.gep.i, align 1, !tbaa !8
  store i64 1, ptr %.fca.7.0.0.gep.i, align 8, !tbaa !8
  store i64 %10, ptr %.fca.7.0.1.gep.i, align 8, !tbaa !8
  store i64 8, ptr %.fca.7.0.2.gep.i, align 8, !tbaa !8
  %omp_global_thread_num.i = call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %4, ptr %structArg.i, align 8
  %gep_5.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 1
  store ptr %3, ptr %gep_5.i, align 8
  %gep_6.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 2
  store ptr %2, ptr %gep_6.i, align 8
  %gep_7.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 3
  store ptr %1, ptr %gep_7.i, align 8
  %gep_8.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 4
  store ptr %6, ptr %gep_8.i, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QFPomp_subroutine..omp_par, ptr nonnull %structArg.i)
  %.fca.0.load.i = load ptr, ptr %3, align 8, !tbaa !8
  %.fca.7.0.0.load.i = load i64, ptr %.fca.7.0.0.gep.i, align 8, !tbaa !8
  %13 = sub i64 1, %.fca.7.0.0.load.i
  %14 = getelementptr double, ptr %.fca.0.load.i, i64 %13
  %15 = load double, ptr %14, align 8, !tbaa !4
  %16 = load i32, ptr %4, align 4, !tbaa !4
  %17 = sext i32 %16 to i64
  %18 = sub i64 %17, %.fca.7.0.0.load.i
  %19 = getelementptr double, ptr %.fca.0.load.i, i64 %18
  %20 = load double, ptr %19, align 8, !tbaa !4
  %21 = fadd contract double %15, %20
  call void @free(ptr %.fca.0.load.i)
  call void @llvm.lifetime.end.p0(i64 40, ptr %structArg.i)
  call void @llvm.lifetime.end.p0(i64 48, ptr %1)
  call void @llvm.lifetime.end.p0(i64 48, ptr %2)
  call void @llvm.lifetime.end.p0(i64 48, ptr %3)
  %22 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.e8a0ac9186c064ac8543d822e9060d96, i32 10)
  %23 = call i1 @_FortranAioOutputAscii(ptr %22, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %24 = load i32, ptr %4, align 4, !tbaa !4
  %25 = call i1 @_FortranAioOutputInteger32(ptr %22, i32 %24)
  %26 = call i1 @_FortranAioOutputAscii(ptr %22, ptr nonnull @_QQcl.2920697320, i64 5)
  %27 = call i1 @_FortranAioOutputReal64(ptr %22, double %21)
  %28 = call i32 @_FortranAioEndIoStatement(ptr %22)
  ret void
}
*** IR Dump After EarlyCSEPass on _QQmain ***
define void @_QQmain() local_unnamed_addr {
  %structArg.i = alloca { ptr, ptr, ptr, ptr, ptr }, align 8
  %1 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %2 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %3 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %4 = alloca i32, align 4
  %5 = alloca double, align 8
  %6 = alloca { ptr, ptr }, align 8
  store ptr %4, ptr %6, align 8, !tbaa !4
  %7 = getelementptr inbounds { ptr, ptr }, ptr %6, i64 0, i32 1
  store ptr %5, ptr %7, align 8, !tbaa !4
  store i32 1048576, ptr %4, align 4, !tbaa !4
  call void @llvm.lifetime.start.p0(i64 40, ptr %structArg.i)
  call void @llvm.lifetime.start.p0(i64 48, ptr %1)
  call void @llvm.lifetime.start.p0(i64 48, ptr %2)
  call void @llvm.lifetime.start.p0(i64 48, ptr %3)
  %.fca.1.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 1
  %.fca.2.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 2
  %.fca.3.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 3
  %.fca.4.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 4
  %.fca.5.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 5
  %.fca.6.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 6
  %.fca.7.0.0.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 7, i64 0, i64 0
  %.fca.7.0.1.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 7, i64 0, i64 1
  %.fca.7.0.2.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 7, i64 0, i64 2
  %8 = call ptr @malloc(i64 8388608)
  store ptr %8, ptr %3, align 8, !tbaa !8
  store i64 8, ptr %.fca.1.gep.i, align 8, !tbaa !8
  store i32 20180515, ptr %.fca.2.gep.i, align 8, !tbaa !8
  store i8 1, ptr %.fca.3.gep.i, align 4, !tbaa !8
  store i8 28, ptr %.fca.4.gep.i, align 1, !tbaa !8
  store i8 2, ptr %.fca.5.gep.i, align 2, !tbaa !8
  store i8 0, ptr %.fca.6.gep.i, align 1, !tbaa !8
  store i64 1, ptr %.fca.7.0.0.gep.i, align 8, !tbaa !8
  store i64 1048576, ptr %.fca.7.0.1.gep.i, align 8, !tbaa !8
  store i64 8, ptr %.fca.7.0.2.gep.i, align 8, !tbaa !8
  %omp_global_thread_num.i = call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %4, ptr %structArg.i, align 8
  %gep_5.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 1
  store ptr %3, ptr %gep_5.i, align 8
  %gep_6.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 2
  store ptr %2, ptr %gep_6.i, align 8
  %gep_7.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 3
  store ptr %1, ptr %gep_7.i, align 8
  %gep_8.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 4
  store ptr %6, ptr %gep_8.i, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QFPomp_subroutine..omp_par, ptr nonnull %structArg.i)
  %.fca.0.load.i = load ptr, ptr %3, align 8, !tbaa !8
  %.fca.7.0.0.load.i = load i64, ptr %.fca.7.0.0.gep.i, align 8, !tbaa !8
  %9 = sub i64 1, %.fca.7.0.0.load.i
  %10 = getelementptr double, ptr %.fca.0.load.i, i64 %9
  %11 = load double, ptr %10, align 8, !tbaa !4
  %12 = load i32, ptr %4, align 4, !tbaa !4
  %13 = sext i32 %12 to i64
  %14 = sub i64 %13, %.fca.7.0.0.load.i
  %15 = getelementptr double, ptr %.fca.0.load.i, i64 %14
  %16 = load double, ptr %15, align 8, !tbaa !4
  %17 = fadd contract double %11, %16
  call void @free(ptr %.fca.0.load.i)
  call void @llvm.lifetime.end.p0(i64 40, ptr %structArg.i)
  call void @llvm.lifetime.end.p0(i64 48, ptr %1)
  call void @llvm.lifetime.end.p0(i64 48, ptr %2)
  call void @llvm.lifetime.end.p0(i64 48, ptr %3)
  %18 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.e8a0ac9186c064ac8543d822e9060d96, i32 10)
  %19 = call i1 @_FortranAioOutputAscii(ptr %18, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %20 = load i32, ptr %4, align 4, !tbaa !4
  %21 = call i1 @_FortranAioOutputInteger32(ptr %18, i32 %20)
  %22 = call i1 @_FortranAioOutputAscii(ptr %18, ptr nonnull @_QQcl.2920697320, i64 5)
  %23 = call i1 @_FortranAioOutputReal64(ptr %18, double %17)
  %24 = call i32 @_FortranAioEndIoStatement(ptr %18)
  ret void
}
*** IR Dump After SpeculativeExecutionPass on _QQmain ***
define void @_QQmain() local_unnamed_addr {
  %structArg.i = alloca { ptr, ptr, ptr, ptr, ptr }, align 8
  %1 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %2 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %3 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %4 = alloca i32, align 4
  %5 = alloca double, align 8
  %6 = alloca { ptr, ptr }, align 8
  store ptr %4, ptr %6, align 8, !tbaa !4
  %7 = getelementptr inbounds { ptr, ptr }, ptr %6, i64 0, i32 1
  store ptr %5, ptr %7, align 8, !tbaa !4
  store i32 1048576, ptr %4, align 4, !tbaa !4
  call void @llvm.lifetime.start.p0(i64 40, ptr %structArg.i)
  call void @llvm.lifetime.start.p0(i64 48, ptr %1)
  call void @llvm.lifetime.start.p0(i64 48, ptr %2)
  call void @llvm.lifetime.start.p0(i64 48, ptr %3)
  %.fca.1.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 1
  %.fca.2.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 2
  %.fca.3.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 3
  %.fca.4.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 4
  %.fca.5.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 5
  %.fca.6.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 6
  %.fca.7.0.0.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 7, i64 0, i64 0
  %.fca.7.0.1.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 7, i64 0, i64 1
  %.fca.7.0.2.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 7, i64 0, i64 2
  %8 = call ptr @malloc(i64 8388608)
  store ptr %8, ptr %3, align 8, !tbaa !8
  store i64 8, ptr %.fca.1.gep.i, align 8, !tbaa !8
  store i32 20180515, ptr %.fca.2.gep.i, align 8, !tbaa !8
  store i8 1, ptr %.fca.3.gep.i, align 4, !tbaa !8
  store i8 28, ptr %.fca.4.gep.i, align 1, !tbaa !8
  store i8 2, ptr %.fca.5.gep.i, align 2, !tbaa !8
  store i8 0, ptr %.fca.6.gep.i, align 1, !tbaa !8
  store i64 1, ptr %.fca.7.0.0.gep.i, align 8, !tbaa !8
  store i64 1048576, ptr %.fca.7.0.1.gep.i, align 8, !tbaa !8
  store i64 8, ptr %.fca.7.0.2.gep.i, align 8, !tbaa !8
  %omp_global_thread_num.i = call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %4, ptr %structArg.i, align 8
  %gep_5.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 1
  store ptr %3, ptr %gep_5.i, align 8
  %gep_6.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 2
  store ptr %2, ptr %gep_6.i, align 8
  %gep_7.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 3
  store ptr %1, ptr %gep_7.i, align 8
  %gep_8.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 4
  store ptr %6, ptr %gep_8.i, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QFPomp_subroutine..omp_par, ptr nonnull %structArg.i)
  %.fca.0.load.i = load ptr, ptr %3, align 8, !tbaa !8
  %.fca.7.0.0.load.i = load i64, ptr %.fca.7.0.0.gep.i, align 8, !tbaa !8
  %9 = sub i64 1, %.fca.7.0.0.load.i
  %10 = getelementptr double, ptr %.fca.0.load.i, i64 %9
  %11 = load double, ptr %10, align 8, !tbaa !4
  %12 = load i32, ptr %4, align 4, !tbaa !4
  %13 = sext i32 %12 to i64
  %14 = sub i64 %13, %.fca.7.0.0.load.i
  %15 = getelementptr double, ptr %.fca.0.load.i, i64 %14
  %16 = load double, ptr %15, align 8, !tbaa !4
  %17 = fadd contract double %11, %16
  call void @free(ptr %.fca.0.load.i)
  call void @llvm.lifetime.end.p0(i64 40, ptr %structArg.i)
  call void @llvm.lifetime.end.p0(i64 48, ptr %1)
  call void @llvm.lifetime.end.p0(i64 48, ptr %2)
  call void @llvm.lifetime.end.p0(i64 48, ptr %3)
  %18 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.e8a0ac9186c064ac8543d822e9060d96, i32 10)
  %19 = call i1 @_FortranAioOutputAscii(ptr %18, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %20 = load i32, ptr %4, align 4, !tbaa !4
  %21 = call i1 @_FortranAioOutputInteger32(ptr %18, i32 %20)
  %22 = call i1 @_FortranAioOutputAscii(ptr %18, ptr nonnull @_QQcl.2920697320, i64 5)
  %23 = call i1 @_FortranAioOutputReal64(ptr %18, double %17)
  %24 = call i32 @_FortranAioEndIoStatement(ptr %18)
  ret void
}
*** IR Dump After JumpThreadingPass on _QQmain ***
define void @_QQmain() local_unnamed_addr {
  %structArg.i = alloca { ptr, ptr, ptr, ptr, ptr }, align 8
  %1 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %2 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %3 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %4 = alloca i32, align 4
  %5 = alloca double, align 8
  %6 = alloca { ptr, ptr }, align 8
  store ptr %4, ptr %6, align 8, !tbaa !4
  %7 = getelementptr inbounds { ptr, ptr }, ptr %6, i64 0, i32 1
  store ptr %5, ptr %7, align 8, !tbaa !4
  store i32 1048576, ptr %4, align 4, !tbaa !4
  call void @llvm.lifetime.start.p0(i64 40, ptr %structArg.i)
  call void @llvm.lifetime.start.p0(i64 48, ptr %1)
  call void @llvm.lifetime.start.p0(i64 48, ptr %2)
  call void @llvm.lifetime.start.p0(i64 48, ptr %3)
  %.fca.1.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 1
  %.fca.2.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 2
  %.fca.3.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 3
  %.fca.4.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 4
  %.fca.5.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 5
  %.fca.6.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 6
  %.fca.7.0.0.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 7, i64 0, i64 0
  %.fca.7.0.1.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 7, i64 0, i64 1
  %.fca.7.0.2.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 7, i64 0, i64 2
  %8 = call ptr @malloc(i64 8388608)
  store ptr %8, ptr %3, align 8, !tbaa !8
  store i64 8, ptr %.fca.1.gep.i, align 8, !tbaa !8
  store i32 20180515, ptr %.fca.2.gep.i, align 8, !tbaa !8
  store i8 1, ptr %.fca.3.gep.i, align 4, !tbaa !8
  store i8 28, ptr %.fca.4.gep.i, align 1, !tbaa !8
  store i8 2, ptr %.fca.5.gep.i, align 2, !tbaa !8
  store i8 0, ptr %.fca.6.gep.i, align 1, !tbaa !8
  store i64 1, ptr %.fca.7.0.0.gep.i, align 8, !tbaa !8
  store i64 1048576, ptr %.fca.7.0.1.gep.i, align 8, !tbaa !8
  store i64 8, ptr %.fca.7.0.2.gep.i, align 8, !tbaa !8
  %omp_global_thread_num.i = call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %4, ptr %structArg.i, align 8
  %gep_5.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 1
  store ptr %3, ptr %gep_5.i, align 8
  %gep_6.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 2
  store ptr %2, ptr %gep_6.i, align 8
  %gep_7.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 3
  store ptr %1, ptr %gep_7.i, align 8
  %gep_8.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 4
  store ptr %6, ptr %gep_8.i, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QFPomp_subroutine..omp_par, ptr nonnull %structArg.i)
  %.fca.0.load.i = load ptr, ptr %3, align 8, !tbaa !8
  %.fca.7.0.0.load.i = load i64, ptr %.fca.7.0.0.gep.i, align 8, !tbaa !8
  %9 = sub i64 1, %.fca.7.0.0.load.i
  %10 = getelementptr double, ptr %.fca.0.load.i, i64 %9
  %11 = load double, ptr %10, align 8, !tbaa !4
  %12 = load i32, ptr %4, align 4, !tbaa !4
  %13 = sext i32 %12 to i64
  %14 = sub i64 %13, %.fca.7.0.0.load.i
  %15 = getelementptr double, ptr %.fca.0.load.i, i64 %14
  %16 = load double, ptr %15, align 8, !tbaa !4
  %17 = fadd contract double %11, %16
  call void @free(ptr %.fca.0.load.i)
  call void @llvm.lifetime.end.p0(i64 40, ptr %structArg.i)
  call void @llvm.lifetime.end.p0(i64 48, ptr %1)
  call void @llvm.lifetime.end.p0(i64 48, ptr %2)
  call void @llvm.lifetime.end.p0(i64 48, ptr %3)
  %18 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.e8a0ac9186c064ac8543d822e9060d96, i32 10)
  %19 = call i1 @_FortranAioOutputAscii(ptr %18, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %20 = load i32, ptr %4, align 4, !tbaa !4
  %21 = call i1 @_FortranAioOutputInteger32(ptr %18, i32 %20)
  %22 = call i1 @_FortranAioOutputAscii(ptr %18, ptr nonnull @_QQcl.2920697320, i64 5)
  %23 = call i1 @_FortranAioOutputReal64(ptr %18, double %17)
  %24 = call i32 @_FortranAioEndIoStatement(ptr %18)
  ret void
}
*** IR Dump After CorrelatedValuePropagationPass on _QQmain ***
define void @_QQmain() local_unnamed_addr {
  %structArg.i = alloca { ptr, ptr, ptr, ptr, ptr }, align 8
  %1 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %2 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %3 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %4 = alloca i32, align 4
  %5 = alloca double, align 8
  %6 = alloca { ptr, ptr }, align 8
  store ptr %4, ptr %6, align 8, !tbaa !4
  %7 = getelementptr inbounds { ptr, ptr }, ptr %6, i64 0, i32 1
  store ptr %5, ptr %7, align 8, !tbaa !4
  store i32 1048576, ptr %4, align 4, !tbaa !4
  call void @llvm.lifetime.start.p0(i64 40, ptr nonnull %structArg.i)
  call void @llvm.lifetime.start.p0(i64 48, ptr nonnull %1)
  call void @llvm.lifetime.start.p0(i64 48, ptr nonnull %2)
  call void @llvm.lifetime.start.p0(i64 48, ptr nonnull %3)
  %.fca.1.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 1
  %.fca.2.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 2
  %.fca.3.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 3
  %.fca.4.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 4
  %.fca.5.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 5
  %.fca.6.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 6
  %.fca.7.0.0.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 7, i64 0, i64 0
  %.fca.7.0.1.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 7, i64 0, i64 1
  %.fca.7.0.2.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 7, i64 0, i64 2
  %8 = call ptr @malloc(i64 8388608)
  store ptr %8, ptr %3, align 8, !tbaa !8
  store i64 8, ptr %.fca.1.gep.i, align 8, !tbaa !8
  store i32 20180515, ptr %.fca.2.gep.i, align 8, !tbaa !8
  store i8 1, ptr %.fca.3.gep.i, align 4, !tbaa !8
  store i8 28, ptr %.fca.4.gep.i, align 1, !tbaa !8
  store i8 2, ptr %.fca.5.gep.i, align 2, !tbaa !8
  store i8 0, ptr %.fca.6.gep.i, align 1, !tbaa !8
  store i64 1, ptr %.fca.7.0.0.gep.i, align 8, !tbaa !8
  store i64 1048576, ptr %.fca.7.0.1.gep.i, align 8, !tbaa !8
  store i64 8, ptr %.fca.7.0.2.gep.i, align 8, !tbaa !8
  %omp_global_thread_num.i = call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %4, ptr %structArg.i, align 8
  %gep_5.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 1
  store ptr %3, ptr %gep_5.i, align 8
  %gep_6.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 2
  store ptr %2, ptr %gep_6.i, align 8
  %gep_7.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 3
  store ptr %1, ptr %gep_7.i, align 8
  %gep_8.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 4
  store ptr %6, ptr %gep_8.i, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QFPomp_subroutine..omp_par, ptr nonnull %structArg.i)
  %.fca.0.load.i = load ptr, ptr %3, align 8, !tbaa !8
  %.fca.7.0.0.load.i = load i64, ptr %.fca.7.0.0.gep.i, align 8, !tbaa !8
  %9 = sub i64 1, %.fca.7.0.0.load.i
  %10 = getelementptr double, ptr %.fca.0.load.i, i64 %9
  %11 = load double, ptr %10, align 8, !tbaa !4
  %12 = load i32, ptr %4, align 4, !tbaa !4
  %13 = sext i32 %12 to i64
  %14 = sub i64 %13, %.fca.7.0.0.load.i
  %15 = getelementptr double, ptr %.fca.0.load.i, i64 %14
  %16 = load double, ptr %15, align 8, !tbaa !4
  %17 = fadd contract double %11, %16
  call void @free(ptr %.fca.0.load.i)
  call void @llvm.lifetime.end.p0(i64 40, ptr nonnull %structArg.i)
  call void @llvm.lifetime.end.p0(i64 48, ptr nonnull %1)
  call void @llvm.lifetime.end.p0(i64 48, ptr nonnull %2)
  call void @llvm.lifetime.end.p0(i64 48, ptr nonnull %3)
  %18 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.e8a0ac9186c064ac8543d822e9060d96, i32 10)
  %19 = call i1 @_FortranAioOutputAscii(ptr %18, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %20 = load i32, ptr %4, align 4, !tbaa !4
  %21 = call i1 @_FortranAioOutputInteger32(ptr %18, i32 %20)
  %22 = call i1 @_FortranAioOutputAscii(ptr %18, ptr nonnull @_QQcl.2920697320, i64 5)
  %23 = call i1 @_FortranAioOutputReal64(ptr %18, double %17)
  %24 = call i32 @_FortranAioEndIoStatement(ptr %18)
  ret void
}
*** IR Dump After SimplifyCFGPass on _QQmain ***
define void @_QQmain() local_unnamed_addr {
  %structArg.i = alloca { ptr, ptr, ptr, ptr, ptr }, align 8
  %1 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %2 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %3 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %4 = alloca i32, align 4
  %5 = alloca double, align 8
  %6 = alloca { ptr, ptr }, align 8
  store ptr %4, ptr %6, align 8, !tbaa !4
  %7 = getelementptr inbounds { ptr, ptr }, ptr %6, i64 0, i32 1
  store ptr %5, ptr %7, align 8, !tbaa !4
  store i32 1048576, ptr %4, align 4, !tbaa !4
  call void @llvm.lifetime.start.p0(i64 40, ptr nonnull %structArg.i)
  call void @llvm.lifetime.start.p0(i64 48, ptr nonnull %1)
  call void @llvm.lifetime.start.p0(i64 48, ptr nonnull %2)
  call void @llvm.lifetime.start.p0(i64 48, ptr nonnull %3)
  %.fca.1.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 1
  %.fca.2.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 2
  %.fca.3.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 3
  %.fca.4.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 4
  %.fca.5.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 5
  %.fca.6.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 6
  %.fca.7.0.0.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 7, i64 0, i64 0
  %.fca.7.0.1.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 7, i64 0, i64 1
  %.fca.7.0.2.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 7, i64 0, i64 2
  %8 = call ptr @malloc(i64 8388608)
  store ptr %8, ptr %3, align 8, !tbaa !8
  store i64 8, ptr %.fca.1.gep.i, align 8, !tbaa !8
  store i32 20180515, ptr %.fca.2.gep.i, align 8, !tbaa !8
  store i8 1, ptr %.fca.3.gep.i, align 4, !tbaa !8
  store i8 28, ptr %.fca.4.gep.i, align 1, !tbaa !8
  store i8 2, ptr %.fca.5.gep.i, align 2, !tbaa !8
  store i8 0, ptr %.fca.6.gep.i, align 1, !tbaa !8
  store i64 1, ptr %.fca.7.0.0.gep.i, align 8, !tbaa !8
  store i64 1048576, ptr %.fca.7.0.1.gep.i, align 8, !tbaa !8
  store i64 8, ptr %.fca.7.0.2.gep.i, align 8, !tbaa !8
  %omp_global_thread_num.i = call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %4, ptr %structArg.i, align 8
  %gep_5.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 1
  store ptr %3, ptr %gep_5.i, align 8
  %gep_6.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 2
  store ptr %2, ptr %gep_6.i, align 8
  %gep_7.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 3
  store ptr %1, ptr %gep_7.i, align 8
  %gep_8.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 4
  store ptr %6, ptr %gep_8.i, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QFPomp_subroutine..omp_par, ptr nonnull %structArg.i)
  %.fca.0.load.i = load ptr, ptr %3, align 8, !tbaa !8
  %.fca.7.0.0.load.i = load i64, ptr %.fca.7.0.0.gep.i, align 8, !tbaa !8
  %9 = sub i64 1, %.fca.7.0.0.load.i
  %10 = getelementptr double, ptr %.fca.0.load.i, i64 %9
  %11 = load double, ptr %10, align 8, !tbaa !4
  %12 = load i32, ptr %4, align 4, !tbaa !4
  %13 = sext i32 %12 to i64
  %14 = sub i64 %13, %.fca.7.0.0.load.i
  %15 = getelementptr double, ptr %.fca.0.load.i, i64 %14
  %16 = load double, ptr %15, align 8, !tbaa !4
  %17 = fadd contract double %11, %16
  call void @free(ptr %.fca.0.load.i)
  call void @llvm.lifetime.end.p0(i64 40, ptr nonnull %structArg.i)
  call void @llvm.lifetime.end.p0(i64 48, ptr nonnull %1)
  call void @llvm.lifetime.end.p0(i64 48, ptr nonnull %2)
  call void @llvm.lifetime.end.p0(i64 48, ptr nonnull %3)
  %18 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.e8a0ac9186c064ac8543d822e9060d96, i32 10)
  %19 = call i1 @_FortranAioOutputAscii(ptr %18, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %20 = load i32, ptr %4, align 4, !tbaa !4
  %21 = call i1 @_FortranAioOutputInteger32(ptr %18, i32 %20)
  %22 = call i1 @_FortranAioOutputAscii(ptr %18, ptr nonnull @_QQcl.2920697320, i64 5)
  %23 = call i1 @_FortranAioOutputReal64(ptr %18, double %17)
  %24 = call i32 @_FortranAioEndIoStatement(ptr %18)
  ret void
}
*** IR Dump After InstCombinePass on _QQmain ***
define void @_QQmain() local_unnamed_addr {
  %structArg.i = alloca { ptr, ptr, ptr, ptr, ptr }, align 8
  %1 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %2 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %3 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %4 = alloca i32, align 4
  %5 = alloca double, align 8
  %6 = alloca { ptr, ptr }, align 8
  store ptr %4, ptr %6, align 8, !tbaa !4
  %7 = getelementptr inbounds { ptr, ptr }, ptr %6, i64 0, i32 1
  store ptr %5, ptr %7, align 8, !tbaa !4
  store i32 1048576, ptr %4, align 4, !tbaa !4
  call void @llvm.lifetime.start.p0(i64 40, ptr nonnull %structArg.i)
  call void @llvm.lifetime.start.p0(i64 48, ptr nonnull %1)
  call void @llvm.lifetime.start.p0(i64 48, ptr nonnull %2)
  call void @llvm.lifetime.start.p0(i64 48, ptr nonnull %3)
  %.fca.1.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 1
  %.fca.2.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 2
  %.fca.3.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 3
  %.fca.4.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 4
  %.fca.5.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 5
  %.fca.6.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 6
  %.fca.7.0.0.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 7, i64 0, i64 0
  %.fca.7.0.1.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 7, i64 0, i64 1
  %.fca.7.0.2.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 7, i64 0, i64 2
  %8 = call dereferenceable_or_null(8388608) ptr @malloc(i64 8388608)
  store ptr %8, ptr %3, align 8, !tbaa !8
  store i64 8, ptr %.fca.1.gep.i, align 8, !tbaa !8
  store i32 20180515, ptr %.fca.2.gep.i, align 8, !tbaa !8
  store i8 1, ptr %.fca.3.gep.i, align 4, !tbaa !8
  store i8 28, ptr %.fca.4.gep.i, align 1, !tbaa !8
  store i8 2, ptr %.fca.5.gep.i, align 2, !tbaa !8
  store i8 0, ptr %.fca.6.gep.i, align 1, !tbaa !8
  store i64 1, ptr %.fca.7.0.0.gep.i, align 8, !tbaa !8
  store i64 1048576, ptr %.fca.7.0.1.gep.i, align 8, !tbaa !8
  store i64 8, ptr %.fca.7.0.2.gep.i, align 8, !tbaa !8
  %omp_global_thread_num.i = call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %4, ptr %structArg.i, align 8
  %gep_5.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 1
  store ptr %3, ptr %gep_5.i, align 8
  %gep_6.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 2
  store ptr %2, ptr %gep_6.i, align 8
  %gep_7.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 3
  store ptr %1, ptr %gep_7.i, align 8
  %gep_8.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 4
  store ptr %6, ptr %gep_8.i, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QFPomp_subroutine..omp_par, ptr nonnull %structArg.i)
  %.fca.0.load.i = load ptr, ptr %3, align 8, !tbaa !8
  %.fca.7.0.0.load.i = load i64, ptr %.fca.7.0.0.gep.i, align 8, !tbaa !8
  %9 = sub i64 1, %.fca.7.0.0.load.i
  %10 = getelementptr double, ptr %.fca.0.load.i, i64 %9
  %11 = load double, ptr %10, align 8, !tbaa !4
  %12 = load i32, ptr %4, align 4, !tbaa !4
  %13 = sext i32 %12 to i64
  %14 = sub i64 %13, %.fca.7.0.0.load.i
  %15 = getelementptr double, ptr %.fca.0.load.i, i64 %14
  %16 = load double, ptr %15, align 8, !tbaa !4
  %17 = fadd contract double %11, %16
  call void @free(ptr %.fca.0.load.i)
  call void @llvm.lifetime.end.p0(i64 40, ptr nonnull %structArg.i)
  call void @llvm.lifetime.end.p0(i64 48, ptr nonnull %1)
  call void @llvm.lifetime.end.p0(i64 48, ptr nonnull %2)
  call void @llvm.lifetime.end.p0(i64 48, ptr nonnull %3)
  %18 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.e8a0ac9186c064ac8543d822e9060d96, i32 10)
  %19 = call i1 @_FortranAioOutputAscii(ptr %18, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %20 = load i32, ptr %4, align 4, !tbaa !4
  %21 = call i1 @_FortranAioOutputInteger32(ptr %18, i32 %20)
  %22 = call i1 @_FortranAioOutputAscii(ptr %18, ptr nonnull @_QQcl.2920697320, i64 5)
  %23 = call i1 @_FortranAioOutputReal64(ptr %18, double %17)
  %24 = call i32 @_FortranAioEndIoStatement(ptr %18)
  ret void
}
*** IR Dump After AggressiveInstCombinePass on _QQmain ***
define void @_QQmain() local_unnamed_addr {
  %structArg.i = alloca { ptr, ptr, ptr, ptr, ptr }, align 8
  %1 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %2 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %3 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %4 = alloca i32, align 4
  %5 = alloca double, align 8
  %6 = alloca { ptr, ptr }, align 8
  store ptr %4, ptr %6, align 8, !tbaa !4
  %7 = getelementptr inbounds { ptr, ptr }, ptr %6, i64 0, i32 1
  store ptr %5, ptr %7, align 8, !tbaa !4
  store i32 1048576, ptr %4, align 4, !tbaa !4
  call void @llvm.lifetime.start.p0(i64 40, ptr nonnull %structArg.i)
  call void @llvm.lifetime.start.p0(i64 48, ptr nonnull %1)
  call void @llvm.lifetime.start.p0(i64 48, ptr nonnull %2)
  call void @llvm.lifetime.start.p0(i64 48, ptr nonnull %3)
  %.fca.1.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 1
  %.fca.2.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 2
  %.fca.3.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 3
  %.fca.4.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 4
  %.fca.5.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 5
  %.fca.6.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 6
  %.fca.7.0.0.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 7, i64 0, i64 0
  %.fca.7.0.1.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 7, i64 0, i64 1
  %.fca.7.0.2.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 7, i64 0, i64 2
  %8 = call dereferenceable_or_null(8388608) ptr @malloc(i64 8388608)
  store ptr %8, ptr %3, align 8, !tbaa !8
  store i64 8, ptr %.fca.1.gep.i, align 8, !tbaa !8
  store i32 20180515, ptr %.fca.2.gep.i, align 8, !tbaa !8
  store i8 1, ptr %.fca.3.gep.i, align 4, !tbaa !8
  store i8 28, ptr %.fca.4.gep.i, align 1, !tbaa !8
  store i8 2, ptr %.fca.5.gep.i, align 2, !tbaa !8
  store i8 0, ptr %.fca.6.gep.i, align 1, !tbaa !8
  store i64 1, ptr %.fca.7.0.0.gep.i, align 8, !tbaa !8
  store i64 1048576, ptr %.fca.7.0.1.gep.i, align 8, !tbaa !8
  store i64 8, ptr %.fca.7.0.2.gep.i, align 8, !tbaa !8
  %omp_global_thread_num.i = call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %4, ptr %structArg.i, align 8
  %gep_5.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 1
  store ptr %3, ptr %gep_5.i, align 8
  %gep_6.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 2
  store ptr %2, ptr %gep_6.i, align 8
  %gep_7.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 3
  store ptr %1, ptr %gep_7.i, align 8
  %gep_8.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 4
  store ptr %6, ptr %gep_8.i, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QFPomp_subroutine..omp_par, ptr nonnull %structArg.i)
  %.fca.0.load.i = load ptr, ptr %3, align 8, !tbaa !8
  %.fca.7.0.0.load.i = load i64, ptr %.fca.7.0.0.gep.i, align 8, !tbaa !8
  %9 = sub i64 1, %.fca.7.0.0.load.i
  %10 = getelementptr double, ptr %.fca.0.load.i, i64 %9
  %11 = load double, ptr %10, align 8, !tbaa !4
  %12 = load i32, ptr %4, align 4, !tbaa !4
  %13 = sext i32 %12 to i64
  %14 = sub i64 %13, %.fca.7.0.0.load.i
  %15 = getelementptr double, ptr %.fca.0.load.i, i64 %14
  %16 = load double, ptr %15, align 8, !tbaa !4
  %17 = fadd contract double %11, %16
  call void @free(ptr %.fca.0.load.i)
  call void @llvm.lifetime.end.p0(i64 40, ptr nonnull %structArg.i)
  call void @llvm.lifetime.end.p0(i64 48, ptr nonnull %1)
  call void @llvm.lifetime.end.p0(i64 48, ptr nonnull %2)
  call void @llvm.lifetime.end.p0(i64 48, ptr nonnull %3)
  %18 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.e8a0ac9186c064ac8543d822e9060d96, i32 10)
  %19 = call i1 @_FortranAioOutputAscii(ptr %18, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %20 = load i32, ptr %4, align 4, !tbaa !4
  %21 = call i1 @_FortranAioOutputInteger32(ptr %18, i32 %20)
  %22 = call i1 @_FortranAioOutputAscii(ptr %18, ptr nonnull @_QQcl.2920697320, i64 5)
  %23 = call i1 @_FortranAioOutputReal64(ptr %18, double %17)
  %24 = call i32 @_FortranAioEndIoStatement(ptr %18)
  ret void
}
*** IR Dump After ConstraintEliminationPass on _QQmain ***
define void @_QQmain() local_unnamed_addr {
  %structArg.i = alloca { ptr, ptr, ptr, ptr, ptr }, align 8
  %1 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %2 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %3 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %4 = alloca i32, align 4
  %5 = alloca double, align 8
  %6 = alloca { ptr, ptr }, align 8
  store ptr %4, ptr %6, align 8, !tbaa !4
  %7 = getelementptr inbounds { ptr, ptr }, ptr %6, i64 0, i32 1
  store ptr %5, ptr %7, align 8, !tbaa !4
  store i32 1048576, ptr %4, align 4, !tbaa !4
  call void @llvm.lifetime.start.p0(i64 40, ptr nonnull %structArg.i)
  call void @llvm.lifetime.start.p0(i64 48, ptr nonnull %1)
  call void @llvm.lifetime.start.p0(i64 48, ptr nonnull %2)
  call void @llvm.lifetime.start.p0(i64 48, ptr nonnull %3)
  %.fca.1.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 1
  %.fca.2.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 2
  %.fca.3.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 3
  %.fca.4.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 4
  %.fca.5.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 5
  %.fca.6.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 6
  %.fca.7.0.0.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 7, i64 0, i64 0
  %.fca.7.0.1.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 7, i64 0, i64 1
  %.fca.7.0.2.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 7, i64 0, i64 2
  %8 = call dereferenceable_or_null(8388608) ptr @malloc(i64 8388608)
  store ptr %8, ptr %3, align 8, !tbaa !8
  store i64 8, ptr %.fca.1.gep.i, align 8, !tbaa !8
  store i32 20180515, ptr %.fca.2.gep.i, align 8, !tbaa !8
  store i8 1, ptr %.fca.3.gep.i, align 4, !tbaa !8
  store i8 28, ptr %.fca.4.gep.i, align 1, !tbaa !8
  store i8 2, ptr %.fca.5.gep.i, align 2, !tbaa !8
  store i8 0, ptr %.fca.6.gep.i, align 1, !tbaa !8
  store i64 1, ptr %.fca.7.0.0.gep.i, align 8, !tbaa !8
  store i64 1048576, ptr %.fca.7.0.1.gep.i, align 8, !tbaa !8
  store i64 8, ptr %.fca.7.0.2.gep.i, align 8, !tbaa !8
  %omp_global_thread_num.i = call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %4, ptr %structArg.i, align 8
  %gep_5.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 1
  store ptr %3, ptr %gep_5.i, align 8
  %gep_6.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 2
  store ptr %2, ptr %gep_6.i, align 8
  %gep_7.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 3
  store ptr %1, ptr %gep_7.i, align 8
  %gep_8.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 4
  store ptr %6, ptr %gep_8.i, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QFPomp_subroutine..omp_par, ptr nonnull %structArg.i)
  %.fca.0.load.i = load ptr, ptr %3, align 8, !tbaa !8
  %.fca.7.0.0.load.i = load i64, ptr %.fca.7.0.0.gep.i, align 8, !tbaa !8
  %9 = sub i64 1, %.fca.7.0.0.load.i
  %10 = getelementptr double, ptr %.fca.0.load.i, i64 %9
  %11 = load double, ptr %10, align 8, !tbaa !4
  %12 = load i32, ptr %4, align 4, !tbaa !4
  %13 = sext i32 %12 to i64
  %14 = sub i64 %13, %.fca.7.0.0.load.i
  %15 = getelementptr double, ptr %.fca.0.load.i, i64 %14
  %16 = load double, ptr %15, align 8, !tbaa !4
  %17 = fadd contract double %11, %16
  call void @free(ptr %.fca.0.load.i)
  call void @llvm.lifetime.end.p0(i64 40, ptr nonnull %structArg.i)
  call void @llvm.lifetime.end.p0(i64 48, ptr nonnull %1)
  call void @llvm.lifetime.end.p0(i64 48, ptr nonnull %2)
  call void @llvm.lifetime.end.p0(i64 48, ptr nonnull %3)
  %18 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.e8a0ac9186c064ac8543d822e9060d96, i32 10)
  %19 = call i1 @_FortranAioOutputAscii(ptr %18, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %20 = load i32, ptr %4, align 4, !tbaa !4
  %21 = call i1 @_FortranAioOutputInteger32(ptr %18, i32 %20)
  %22 = call i1 @_FortranAioOutputAscii(ptr %18, ptr nonnull @_QQcl.2920697320, i64 5)
  %23 = call i1 @_FortranAioOutputReal64(ptr %18, double %17)
  %24 = call i32 @_FortranAioEndIoStatement(ptr %18)
  ret void
}
*** IR Dump After LibCallsShrinkWrapPass on _QQmain ***
define void @_QQmain() local_unnamed_addr {
  %structArg.i = alloca { ptr, ptr, ptr, ptr, ptr }, align 8
  %1 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %2 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %3 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %4 = alloca i32, align 4
  %5 = alloca double, align 8
  %6 = alloca { ptr, ptr }, align 8
  store ptr %4, ptr %6, align 8, !tbaa !4
  %7 = getelementptr inbounds { ptr, ptr }, ptr %6, i64 0, i32 1
  store ptr %5, ptr %7, align 8, !tbaa !4
  store i32 1048576, ptr %4, align 4, !tbaa !4
  call void @llvm.lifetime.start.p0(i64 40, ptr nonnull %structArg.i)
  call void @llvm.lifetime.start.p0(i64 48, ptr nonnull %1)
  call void @llvm.lifetime.start.p0(i64 48, ptr nonnull %2)
  call void @llvm.lifetime.start.p0(i64 48, ptr nonnull %3)
  %.fca.1.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 1
  %.fca.2.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 2
  %.fca.3.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 3
  %.fca.4.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 4
  %.fca.5.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 5
  %.fca.6.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 6
  %.fca.7.0.0.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 7, i64 0, i64 0
  %.fca.7.0.1.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 7, i64 0, i64 1
  %.fca.7.0.2.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 7, i64 0, i64 2
  %8 = call dereferenceable_or_null(8388608) ptr @malloc(i64 8388608)
  store ptr %8, ptr %3, align 8, !tbaa !8
  store i64 8, ptr %.fca.1.gep.i, align 8, !tbaa !8
  store i32 20180515, ptr %.fca.2.gep.i, align 8, !tbaa !8
  store i8 1, ptr %.fca.3.gep.i, align 4, !tbaa !8
  store i8 28, ptr %.fca.4.gep.i, align 1, !tbaa !8
  store i8 2, ptr %.fca.5.gep.i, align 2, !tbaa !8
  store i8 0, ptr %.fca.6.gep.i, align 1, !tbaa !8
  store i64 1, ptr %.fca.7.0.0.gep.i, align 8, !tbaa !8
  store i64 1048576, ptr %.fca.7.0.1.gep.i, align 8, !tbaa !8
  store i64 8, ptr %.fca.7.0.2.gep.i, align 8, !tbaa !8
  %omp_global_thread_num.i = call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %4, ptr %structArg.i, align 8
  %gep_5.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 1
  store ptr %3, ptr %gep_5.i, align 8
  %gep_6.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 2
  store ptr %2, ptr %gep_6.i, align 8
  %gep_7.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 3
  store ptr %1, ptr %gep_7.i, align 8
  %gep_8.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 4
  store ptr %6, ptr %gep_8.i, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QFPomp_subroutine..omp_par, ptr nonnull %structArg.i)
  %.fca.0.load.i = load ptr, ptr %3, align 8, !tbaa !8
  %.fca.7.0.0.load.i = load i64, ptr %.fca.7.0.0.gep.i, align 8, !tbaa !8
  %9 = sub i64 1, %.fca.7.0.0.load.i
  %10 = getelementptr double, ptr %.fca.0.load.i, i64 %9
  %11 = load double, ptr %10, align 8, !tbaa !4
  %12 = load i32, ptr %4, align 4, !tbaa !4
  %13 = sext i32 %12 to i64
  %14 = sub i64 %13, %.fca.7.0.0.load.i
  %15 = getelementptr double, ptr %.fca.0.load.i, i64 %14
  %16 = load double, ptr %15, align 8, !tbaa !4
  %17 = fadd contract double %11, %16
  call void @free(ptr %.fca.0.load.i)
  call void @llvm.lifetime.end.p0(i64 40, ptr nonnull %structArg.i)
  call void @llvm.lifetime.end.p0(i64 48, ptr nonnull %1)
  call void @llvm.lifetime.end.p0(i64 48, ptr nonnull %2)
  call void @llvm.lifetime.end.p0(i64 48, ptr nonnull %3)
  %18 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.e8a0ac9186c064ac8543d822e9060d96, i32 10)
  %19 = call i1 @_FortranAioOutputAscii(ptr %18, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %20 = load i32, ptr %4, align 4, !tbaa !4
  %21 = call i1 @_FortranAioOutputInteger32(ptr %18, i32 %20)
  %22 = call i1 @_FortranAioOutputAscii(ptr %18, ptr nonnull @_QQcl.2920697320, i64 5)
  %23 = call i1 @_FortranAioOutputReal64(ptr %18, double %17)
  %24 = call i32 @_FortranAioEndIoStatement(ptr %18)
  ret void
}
*** IR Dump After TailCallElimPass on _QQmain ***
define void @_QQmain() local_unnamed_addr {
  %structArg.i = alloca { ptr, ptr, ptr, ptr, ptr }, align 8
  %1 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %2 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %3 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %4 = alloca i32, align 4
  %5 = alloca double, align 8
  %6 = alloca { ptr, ptr }, align 8
  store ptr %4, ptr %6, align 8, !tbaa !4
  %7 = getelementptr inbounds { ptr, ptr }, ptr %6, i64 0, i32 1
  store ptr %5, ptr %7, align 8, !tbaa !4
  store i32 1048576, ptr %4, align 4, !tbaa !4
  call void @llvm.lifetime.start.p0(i64 40, ptr nonnull %structArg.i)
  call void @llvm.lifetime.start.p0(i64 48, ptr nonnull %1)
  call void @llvm.lifetime.start.p0(i64 48, ptr nonnull %2)
  call void @llvm.lifetime.start.p0(i64 48, ptr nonnull %3)
  %.fca.1.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 1
  %.fca.2.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 2
  %.fca.3.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 3
  %.fca.4.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 4
  %.fca.5.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 5
  %.fca.6.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 6
  %.fca.7.0.0.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 7, i64 0, i64 0
  %.fca.7.0.1.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 7, i64 0, i64 1
  %.fca.7.0.2.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 7, i64 0, i64 2
  %8 = call dereferenceable_or_null(8388608) ptr @malloc(i64 8388608)
  store ptr %8, ptr %3, align 8, !tbaa !8
  store i64 8, ptr %.fca.1.gep.i, align 8, !tbaa !8
  store i32 20180515, ptr %.fca.2.gep.i, align 8, !tbaa !8
  store i8 1, ptr %.fca.3.gep.i, align 4, !tbaa !8
  store i8 28, ptr %.fca.4.gep.i, align 1, !tbaa !8
  store i8 2, ptr %.fca.5.gep.i, align 2, !tbaa !8
  store i8 0, ptr %.fca.6.gep.i, align 1, !tbaa !8
  store i64 1, ptr %.fca.7.0.0.gep.i, align 8, !tbaa !8
  store i64 1048576, ptr %.fca.7.0.1.gep.i, align 8, !tbaa !8
  store i64 8, ptr %.fca.7.0.2.gep.i, align 8, !tbaa !8
  %omp_global_thread_num.i = call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %4, ptr %structArg.i, align 8
  %gep_5.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 1
  store ptr %3, ptr %gep_5.i, align 8
  %gep_6.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 2
  store ptr %2, ptr %gep_6.i, align 8
  %gep_7.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 3
  store ptr %1, ptr %gep_7.i, align 8
  %gep_8.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 4
  store ptr %6, ptr %gep_8.i, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QFPomp_subroutine..omp_par, ptr nonnull %structArg.i)
  %.fca.0.load.i = load ptr, ptr %3, align 8, !tbaa !8
  %.fca.7.0.0.load.i = load i64, ptr %.fca.7.0.0.gep.i, align 8, !tbaa !8
  %9 = sub i64 1, %.fca.7.0.0.load.i
  %10 = getelementptr double, ptr %.fca.0.load.i, i64 %9
  %11 = load double, ptr %10, align 8, !tbaa !4
  %12 = load i32, ptr %4, align 4, !tbaa !4
  %13 = sext i32 %12 to i64
  %14 = sub i64 %13, %.fca.7.0.0.load.i
  %15 = getelementptr double, ptr %.fca.0.load.i, i64 %14
  %16 = load double, ptr %15, align 8, !tbaa !4
  %17 = fadd contract double %11, %16
  call void @free(ptr %.fca.0.load.i)
  call void @llvm.lifetime.end.p0(i64 40, ptr nonnull %structArg.i)
  call void @llvm.lifetime.end.p0(i64 48, ptr nonnull %1)
  call void @llvm.lifetime.end.p0(i64 48, ptr nonnull %2)
  call void @llvm.lifetime.end.p0(i64 48, ptr nonnull %3)
  %18 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.e8a0ac9186c064ac8543d822e9060d96, i32 10)
  %19 = call i1 @_FortranAioOutputAscii(ptr %18, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %20 = load i32, ptr %4, align 4, !tbaa !4
  %21 = call i1 @_FortranAioOutputInteger32(ptr %18, i32 %20)
  %22 = call i1 @_FortranAioOutputAscii(ptr %18, ptr nonnull @_QQcl.2920697320, i64 5)
  %23 = call i1 @_FortranAioOutputReal64(ptr %18, double %17)
  %24 = call i32 @_FortranAioEndIoStatement(ptr %18)
  ret void
}
*** IR Dump After SimplifyCFGPass on _QQmain ***
define void @_QQmain() local_unnamed_addr {
  %structArg.i = alloca { ptr, ptr, ptr, ptr, ptr }, align 8
  %1 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %2 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %3 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %4 = alloca i32, align 4
  %5 = alloca double, align 8
  %6 = alloca { ptr, ptr }, align 8
  store ptr %4, ptr %6, align 8, !tbaa !4
  %7 = getelementptr inbounds { ptr, ptr }, ptr %6, i64 0, i32 1
  store ptr %5, ptr %7, align 8, !tbaa !4
  store i32 1048576, ptr %4, align 4, !tbaa !4
  call void @llvm.lifetime.start.p0(i64 40, ptr nonnull %structArg.i)
  call void @llvm.lifetime.start.p0(i64 48, ptr nonnull %1)
  call void @llvm.lifetime.start.p0(i64 48, ptr nonnull %2)
  call void @llvm.lifetime.start.p0(i64 48, ptr nonnull %3)
  %.fca.1.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 1
  %.fca.2.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 2
  %.fca.3.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 3
  %.fca.4.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 4
  %.fca.5.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 5
  %.fca.6.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 6
  %.fca.7.0.0.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 7, i64 0, i64 0
  %.fca.7.0.1.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 7, i64 0, i64 1
  %.fca.7.0.2.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 7, i64 0, i64 2
  %8 = call dereferenceable_or_null(8388608) ptr @malloc(i64 8388608)
  store ptr %8, ptr %3, align 8, !tbaa !8
  store i64 8, ptr %.fca.1.gep.i, align 8, !tbaa !8
  store i32 20180515, ptr %.fca.2.gep.i, align 8, !tbaa !8
  store i8 1, ptr %.fca.3.gep.i, align 4, !tbaa !8
  store i8 28, ptr %.fca.4.gep.i, align 1, !tbaa !8
  store i8 2, ptr %.fca.5.gep.i, align 2, !tbaa !8
  store i8 0, ptr %.fca.6.gep.i, align 1, !tbaa !8
  store i64 1, ptr %.fca.7.0.0.gep.i, align 8, !tbaa !8
  store i64 1048576, ptr %.fca.7.0.1.gep.i, align 8, !tbaa !8
  store i64 8, ptr %.fca.7.0.2.gep.i, align 8, !tbaa !8
  %omp_global_thread_num.i = call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %4, ptr %structArg.i, align 8
  %gep_5.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 1
  store ptr %3, ptr %gep_5.i, align 8
  %gep_6.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 2
  store ptr %2, ptr %gep_6.i, align 8
  %gep_7.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 3
  store ptr %1, ptr %gep_7.i, align 8
  %gep_8.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 4
  store ptr %6, ptr %gep_8.i, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QFPomp_subroutine..omp_par, ptr nonnull %structArg.i)
  %.fca.0.load.i = load ptr, ptr %3, align 8, !tbaa !8
  %.fca.7.0.0.load.i = load i64, ptr %.fca.7.0.0.gep.i, align 8, !tbaa !8
  %9 = sub i64 1, %.fca.7.0.0.load.i
  %10 = getelementptr double, ptr %.fca.0.load.i, i64 %9
  %11 = load double, ptr %10, align 8, !tbaa !4
  %12 = load i32, ptr %4, align 4, !tbaa !4
  %13 = sext i32 %12 to i64
  %14 = sub i64 %13, %.fca.7.0.0.load.i
  %15 = getelementptr double, ptr %.fca.0.load.i, i64 %14
  %16 = load double, ptr %15, align 8, !tbaa !4
  %17 = fadd contract double %11, %16
  call void @free(ptr %.fca.0.load.i)
  call void @llvm.lifetime.end.p0(i64 40, ptr nonnull %structArg.i)
  call void @llvm.lifetime.end.p0(i64 48, ptr nonnull %1)
  call void @llvm.lifetime.end.p0(i64 48, ptr nonnull %2)
  call void @llvm.lifetime.end.p0(i64 48, ptr nonnull %3)
  %18 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.e8a0ac9186c064ac8543d822e9060d96, i32 10)
  %19 = call i1 @_FortranAioOutputAscii(ptr %18, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %20 = load i32, ptr %4, align 4, !tbaa !4
  %21 = call i1 @_FortranAioOutputInteger32(ptr %18, i32 %20)
  %22 = call i1 @_FortranAioOutputAscii(ptr %18, ptr nonnull @_QQcl.2920697320, i64 5)
  %23 = call i1 @_FortranAioOutputReal64(ptr %18, double %17)
  %24 = call i32 @_FortranAioEndIoStatement(ptr %18)
  ret void
}
*** IR Dump After ReassociatePass on _QQmain ***
define void @_QQmain() local_unnamed_addr {
  %structArg.i = alloca { ptr, ptr, ptr, ptr, ptr }, align 8
  %1 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %2 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %3 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %4 = alloca i32, align 4
  %5 = alloca double, align 8
  %6 = alloca { ptr, ptr }, align 8
  store ptr %4, ptr %6, align 8, !tbaa !4
  %7 = getelementptr inbounds { ptr, ptr }, ptr %6, i64 0, i32 1
  store ptr %5, ptr %7, align 8, !tbaa !4
  store i32 1048576, ptr %4, align 4, !tbaa !4
  call void @llvm.lifetime.start.p0(i64 40, ptr nonnull %structArg.i)
  call void @llvm.lifetime.start.p0(i64 48, ptr nonnull %1)
  call void @llvm.lifetime.start.p0(i64 48, ptr nonnull %2)
  call void @llvm.lifetime.start.p0(i64 48, ptr nonnull %3)
  %.fca.1.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 1
  %.fca.2.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 2
  %.fca.3.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 3
  %.fca.4.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 4
  %.fca.5.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 5
  %.fca.6.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 6
  %.fca.7.0.0.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 7, i64 0, i64 0
  %.fca.7.0.1.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 7, i64 0, i64 1
  %.fca.7.0.2.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 7, i64 0, i64 2
  %8 = call dereferenceable_or_null(8388608) ptr @malloc(i64 8388608)
  store ptr %8, ptr %3, align 8, !tbaa !8
  store i64 8, ptr %.fca.1.gep.i, align 8, !tbaa !8
  store i32 20180515, ptr %.fca.2.gep.i, align 8, !tbaa !8
  store i8 1, ptr %.fca.3.gep.i, align 4, !tbaa !8
  store i8 28, ptr %.fca.4.gep.i, align 1, !tbaa !8
  store i8 2, ptr %.fca.5.gep.i, align 2, !tbaa !8
  store i8 0, ptr %.fca.6.gep.i, align 1, !tbaa !8
  store i64 1, ptr %.fca.7.0.0.gep.i, align 8, !tbaa !8
  store i64 1048576, ptr %.fca.7.0.1.gep.i, align 8, !tbaa !8
  store i64 8, ptr %.fca.7.0.2.gep.i, align 8, !tbaa !8
  %omp_global_thread_num.i = call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %4, ptr %structArg.i, align 8
  %gep_5.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 1
  store ptr %3, ptr %gep_5.i, align 8
  %gep_6.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 2
  store ptr %2, ptr %gep_6.i, align 8
  %gep_7.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 3
  store ptr %1, ptr %gep_7.i, align 8
  %gep_8.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 4
  store ptr %6, ptr %gep_8.i, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QFPomp_subroutine..omp_par, ptr nonnull %structArg.i)
  %.fca.0.load.i = load ptr, ptr %3, align 8, !tbaa !8
  %.fca.7.0.0.load.i = load i64, ptr %.fca.7.0.0.gep.i, align 8, !tbaa !8
  %9 = sub i64 1, %.fca.7.0.0.load.i
  %10 = getelementptr double, ptr %.fca.0.load.i, i64 %9
  %11 = load double, ptr %10, align 8, !tbaa !4
  %12 = load i32, ptr %4, align 4, !tbaa !4
  %13 = sext i32 %12 to i64
  %14 = sub i64 %13, %.fca.7.0.0.load.i
  %15 = getelementptr double, ptr %.fca.0.load.i, i64 %14
  %16 = load double, ptr %15, align 8, !tbaa !4
  %17 = fadd contract double %11, %16
  call void @free(ptr %.fca.0.load.i)
  call void @llvm.lifetime.end.p0(i64 40, ptr nonnull %structArg.i)
  call void @llvm.lifetime.end.p0(i64 48, ptr nonnull %1)
  call void @llvm.lifetime.end.p0(i64 48, ptr nonnull %2)
  call void @llvm.lifetime.end.p0(i64 48, ptr nonnull %3)
  %18 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.e8a0ac9186c064ac8543d822e9060d96, i32 10)
  %19 = call i1 @_FortranAioOutputAscii(ptr %18, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %20 = load i32, ptr %4, align 4, !tbaa !4
  %21 = call i1 @_FortranAioOutputInteger32(ptr %18, i32 %20)
  %22 = call i1 @_FortranAioOutputAscii(ptr %18, ptr nonnull @_QQcl.2920697320, i64 5)
  %23 = call i1 @_FortranAioOutputReal64(ptr %18, double %17)
  %24 = call i32 @_FortranAioEndIoStatement(ptr %18)
  ret void
}
*** IR Dump After LoopSimplifyPass on _QQmain ***
define void @_QQmain() local_unnamed_addr {
  %structArg.i = alloca { ptr, ptr, ptr, ptr, ptr }, align 8
  %1 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %2 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %3 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %4 = alloca i32, align 4
  %5 = alloca double, align 8
  %6 = alloca { ptr, ptr }, align 8
  store ptr %4, ptr %6, align 8, !tbaa !4
  %7 = getelementptr inbounds { ptr, ptr }, ptr %6, i64 0, i32 1
  store ptr %5, ptr %7, align 8, !tbaa !4
  store i32 1048576, ptr %4, align 4, !tbaa !4
  call void @llvm.lifetime.start.p0(i64 40, ptr nonnull %structArg.i)
  call void @llvm.lifetime.start.p0(i64 48, ptr nonnull %1)
  call void @llvm.lifetime.start.p0(i64 48, ptr nonnull %2)
  call void @llvm.lifetime.start.p0(i64 48, ptr nonnull %3)
  %.fca.1.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 1
  %.fca.2.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 2
  %.fca.3.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 3
  %.fca.4.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 4
  %.fca.5.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 5
  %.fca.6.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 6
  %.fca.7.0.0.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 7, i64 0, i64 0
  %.fca.7.0.1.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 7, i64 0, i64 1
  %.fca.7.0.2.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 7, i64 0, i64 2
  %8 = call dereferenceable_or_null(8388608) ptr @malloc(i64 8388608)
  store ptr %8, ptr %3, align 8, !tbaa !8
  store i64 8, ptr %.fca.1.gep.i, align 8, !tbaa !8
  store i32 20180515, ptr %.fca.2.gep.i, align 8, !tbaa !8
  store i8 1, ptr %.fca.3.gep.i, align 4, !tbaa !8
  store i8 28, ptr %.fca.4.gep.i, align 1, !tbaa !8
  store i8 2, ptr %.fca.5.gep.i, align 2, !tbaa !8
  store i8 0, ptr %.fca.6.gep.i, align 1, !tbaa !8
  store i64 1, ptr %.fca.7.0.0.gep.i, align 8, !tbaa !8
  store i64 1048576, ptr %.fca.7.0.1.gep.i, align 8, !tbaa !8
  store i64 8, ptr %.fca.7.0.2.gep.i, align 8, !tbaa !8
  %omp_global_thread_num.i = call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %4, ptr %structArg.i, align 8
  %gep_5.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 1
  store ptr %3, ptr %gep_5.i, align 8
  %gep_6.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 2
  store ptr %2, ptr %gep_6.i, align 8
  %gep_7.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 3
  store ptr %1, ptr %gep_7.i, align 8
  %gep_8.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 4
  store ptr %6, ptr %gep_8.i, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QFPomp_subroutine..omp_par, ptr nonnull %structArg.i)
  %.fca.0.load.i = load ptr, ptr %3, align 8, !tbaa !8
  %.fca.7.0.0.load.i = load i64, ptr %.fca.7.0.0.gep.i, align 8, !tbaa !8
  %9 = sub i64 1, %.fca.7.0.0.load.i
  %10 = getelementptr double, ptr %.fca.0.load.i, i64 %9
  %11 = load double, ptr %10, align 8, !tbaa !4
  %12 = load i32, ptr %4, align 4, !tbaa !4
  %13 = sext i32 %12 to i64
  %14 = sub i64 %13, %.fca.7.0.0.load.i
  %15 = getelementptr double, ptr %.fca.0.load.i, i64 %14
  %16 = load double, ptr %15, align 8, !tbaa !4
  %17 = fadd contract double %11, %16
  call void @free(ptr %.fca.0.load.i)
  call void @llvm.lifetime.end.p0(i64 40, ptr nonnull %structArg.i)
  call void @llvm.lifetime.end.p0(i64 48, ptr nonnull %1)
  call void @llvm.lifetime.end.p0(i64 48, ptr nonnull %2)
  call void @llvm.lifetime.end.p0(i64 48, ptr nonnull %3)
  %18 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.e8a0ac9186c064ac8543d822e9060d96, i32 10)
  %19 = call i1 @_FortranAioOutputAscii(ptr %18, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %20 = load i32, ptr %4, align 4, !tbaa !4
  %21 = call i1 @_FortranAioOutputInteger32(ptr %18, i32 %20)
  %22 = call i1 @_FortranAioOutputAscii(ptr %18, ptr nonnull @_QQcl.2920697320, i64 5)
  %23 = call i1 @_FortranAioOutputReal64(ptr %18, double %17)
  %24 = call i32 @_FortranAioEndIoStatement(ptr %18)
  ret void
}
*** IR Dump After LCSSAPass on _QQmain ***
define void @_QQmain() local_unnamed_addr {
  %structArg.i = alloca { ptr, ptr, ptr, ptr, ptr }, align 8
  %1 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %2 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %3 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %4 = alloca i32, align 4
  %5 = alloca double, align 8
  %6 = alloca { ptr, ptr }, align 8
  store ptr %4, ptr %6, align 8, !tbaa !4
  %7 = getelementptr inbounds { ptr, ptr }, ptr %6, i64 0, i32 1
  store ptr %5, ptr %7, align 8, !tbaa !4
  store i32 1048576, ptr %4, align 4, !tbaa !4
  call void @llvm.lifetime.start.p0(i64 40, ptr nonnull %structArg.i)
  call void @llvm.lifetime.start.p0(i64 48, ptr nonnull %1)
  call void @llvm.lifetime.start.p0(i64 48, ptr nonnull %2)
  call void @llvm.lifetime.start.p0(i64 48, ptr nonnull %3)
  %.fca.1.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 1
  %.fca.2.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 2
  %.fca.3.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 3
  %.fca.4.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 4
  %.fca.5.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 5
  %.fca.6.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 6
  %.fca.7.0.0.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 7, i64 0, i64 0
  %.fca.7.0.1.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 7, i64 0, i64 1
  %.fca.7.0.2.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 7, i64 0, i64 2
  %8 = call dereferenceable_or_null(8388608) ptr @malloc(i64 8388608)
  store ptr %8, ptr %3, align 8, !tbaa !8
  store i64 8, ptr %.fca.1.gep.i, align 8, !tbaa !8
  store i32 20180515, ptr %.fca.2.gep.i, align 8, !tbaa !8
  store i8 1, ptr %.fca.3.gep.i, align 4, !tbaa !8
  store i8 28, ptr %.fca.4.gep.i, align 1, !tbaa !8
  store i8 2, ptr %.fca.5.gep.i, align 2, !tbaa !8
  store i8 0, ptr %.fca.6.gep.i, align 1, !tbaa !8
  store i64 1, ptr %.fca.7.0.0.gep.i, align 8, !tbaa !8
  store i64 1048576, ptr %.fca.7.0.1.gep.i, align 8, !tbaa !8
  store i64 8, ptr %.fca.7.0.2.gep.i, align 8, !tbaa !8
  %omp_global_thread_num.i = call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %4, ptr %structArg.i, align 8
  %gep_5.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 1
  store ptr %3, ptr %gep_5.i, align 8
  %gep_6.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 2
  store ptr %2, ptr %gep_6.i, align 8
  %gep_7.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 3
  store ptr %1, ptr %gep_7.i, align 8
  %gep_8.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 4
  store ptr %6, ptr %gep_8.i, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QFPomp_subroutine..omp_par, ptr nonnull %structArg.i)
  %.fca.0.load.i = load ptr, ptr %3, align 8, !tbaa !8
  %.fca.7.0.0.load.i = load i64, ptr %.fca.7.0.0.gep.i, align 8, !tbaa !8
  %9 = sub i64 1, %.fca.7.0.0.load.i
  %10 = getelementptr double, ptr %.fca.0.load.i, i64 %9
  %11 = load double, ptr %10, align 8, !tbaa !4
  %12 = load i32, ptr %4, align 4, !tbaa !4
  %13 = sext i32 %12 to i64
  %14 = sub i64 %13, %.fca.7.0.0.load.i
  %15 = getelementptr double, ptr %.fca.0.load.i, i64 %14
  %16 = load double, ptr %15, align 8, !tbaa !4
  %17 = fadd contract double %11, %16
  call void @free(ptr %.fca.0.load.i)
  call void @llvm.lifetime.end.p0(i64 40, ptr nonnull %structArg.i)
  call void @llvm.lifetime.end.p0(i64 48, ptr nonnull %1)
  call void @llvm.lifetime.end.p0(i64 48, ptr nonnull %2)
  call void @llvm.lifetime.end.p0(i64 48, ptr nonnull %3)
  %18 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.e8a0ac9186c064ac8543d822e9060d96, i32 10)
  %19 = call i1 @_FortranAioOutputAscii(ptr %18, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %20 = load i32, ptr %4, align 4, !tbaa !4
  %21 = call i1 @_FortranAioOutputInteger32(ptr %18, i32 %20)
  %22 = call i1 @_FortranAioOutputAscii(ptr %18, ptr nonnull @_QQcl.2920697320, i64 5)
  %23 = call i1 @_FortranAioOutputReal64(ptr %18, double %17)
  %24 = call i32 @_FortranAioEndIoStatement(ptr %18)
  ret void
}
*** IR Dump After SimplifyCFGPass on _QQmain ***
define void @_QQmain() local_unnamed_addr {
  %structArg.i = alloca { ptr, ptr, ptr, ptr, ptr }, align 8
  %1 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %2 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %3 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %4 = alloca i32, align 4
  %5 = alloca double, align 8
  %6 = alloca { ptr, ptr }, align 8
  store ptr %4, ptr %6, align 8, !tbaa !4
  %7 = getelementptr inbounds { ptr, ptr }, ptr %6, i64 0, i32 1
  store ptr %5, ptr %7, align 8, !tbaa !4
  store i32 1048576, ptr %4, align 4, !tbaa !4
  call void @llvm.lifetime.start.p0(i64 40, ptr nonnull %structArg.i)
  call void @llvm.lifetime.start.p0(i64 48, ptr nonnull %1)
  call void @llvm.lifetime.start.p0(i64 48, ptr nonnull %2)
  call void @llvm.lifetime.start.p0(i64 48, ptr nonnull %3)
  %.fca.1.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 1
  %.fca.2.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 2
  %.fca.3.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 3
  %.fca.4.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 4
  %.fca.5.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 5
  %.fca.6.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 6
  %.fca.7.0.0.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 7, i64 0, i64 0
  %.fca.7.0.1.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 7, i64 0, i64 1
  %.fca.7.0.2.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 7, i64 0, i64 2
  %8 = call dereferenceable_or_null(8388608) ptr @malloc(i64 8388608)
  store ptr %8, ptr %3, align 8, !tbaa !8
  store i64 8, ptr %.fca.1.gep.i, align 8, !tbaa !8
  store i32 20180515, ptr %.fca.2.gep.i, align 8, !tbaa !8
  store i8 1, ptr %.fca.3.gep.i, align 4, !tbaa !8
  store i8 28, ptr %.fca.4.gep.i, align 1, !tbaa !8
  store i8 2, ptr %.fca.5.gep.i, align 2, !tbaa !8
  store i8 0, ptr %.fca.6.gep.i, align 1, !tbaa !8
  store i64 1, ptr %.fca.7.0.0.gep.i, align 8, !tbaa !8
  store i64 1048576, ptr %.fca.7.0.1.gep.i, align 8, !tbaa !8
  store i64 8, ptr %.fca.7.0.2.gep.i, align 8, !tbaa !8
  %omp_global_thread_num.i = call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %4, ptr %structArg.i, align 8
  %gep_5.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 1
  store ptr %3, ptr %gep_5.i, align 8
  %gep_6.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 2
  store ptr %2, ptr %gep_6.i, align 8
  %gep_7.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 3
  store ptr %1, ptr %gep_7.i, align 8
  %gep_8.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 4
  store ptr %6, ptr %gep_8.i, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QFPomp_subroutine..omp_par, ptr nonnull %structArg.i)
  %.fca.0.load.i = load ptr, ptr %3, align 8, !tbaa !8
  %.fca.7.0.0.load.i = load i64, ptr %.fca.7.0.0.gep.i, align 8, !tbaa !8
  %9 = sub i64 1, %.fca.7.0.0.load.i
  %10 = getelementptr double, ptr %.fca.0.load.i, i64 %9
  %11 = load double, ptr %10, align 8, !tbaa !4
  %12 = load i32, ptr %4, align 4, !tbaa !4
  %13 = sext i32 %12 to i64
  %14 = sub i64 %13, %.fca.7.0.0.load.i
  %15 = getelementptr double, ptr %.fca.0.load.i, i64 %14
  %16 = load double, ptr %15, align 8, !tbaa !4
  %17 = fadd contract double %11, %16
  call void @free(ptr %.fca.0.load.i)
  call void @llvm.lifetime.end.p0(i64 40, ptr nonnull %structArg.i)
  call void @llvm.lifetime.end.p0(i64 48, ptr nonnull %1)
  call void @llvm.lifetime.end.p0(i64 48, ptr nonnull %2)
  call void @llvm.lifetime.end.p0(i64 48, ptr nonnull %3)
  %18 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.e8a0ac9186c064ac8543d822e9060d96, i32 10)
  %19 = call i1 @_FortranAioOutputAscii(ptr %18, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %20 = load i32, ptr %4, align 4, !tbaa !4
  %21 = call i1 @_FortranAioOutputInteger32(ptr %18, i32 %20)
  %22 = call i1 @_FortranAioOutputAscii(ptr %18, ptr nonnull @_QQcl.2920697320, i64 5)
  %23 = call i1 @_FortranAioOutputReal64(ptr %18, double %17)
  %24 = call i32 @_FortranAioEndIoStatement(ptr %18)
  ret void
}
*** IR Dump After InstCombinePass on _QQmain ***
define void @_QQmain() local_unnamed_addr {
  %structArg.i = alloca { ptr, ptr, ptr, ptr, ptr }, align 8
  %1 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %2 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %3 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %4 = alloca i32, align 4
  %5 = alloca double, align 8
  %6 = alloca { ptr, ptr }, align 8
  store ptr %4, ptr %6, align 8, !tbaa !4
  %7 = getelementptr inbounds { ptr, ptr }, ptr %6, i64 0, i32 1
  store ptr %5, ptr %7, align 8, !tbaa !4
  store i32 1048576, ptr %4, align 4, !tbaa !4
  call void @llvm.lifetime.start.p0(i64 40, ptr nonnull %structArg.i)
  call void @llvm.lifetime.start.p0(i64 48, ptr nonnull %1)
  call void @llvm.lifetime.start.p0(i64 48, ptr nonnull %2)
  call void @llvm.lifetime.start.p0(i64 48, ptr nonnull %3)
  %.fca.1.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 1
  %.fca.2.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 2
  %.fca.3.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 3
  %.fca.4.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 4
  %.fca.5.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 5
  %.fca.6.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 6
  %.fca.7.0.0.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 7, i64 0, i64 0
  %.fca.7.0.1.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 7, i64 0, i64 1
  %.fca.7.0.2.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 7, i64 0, i64 2
  %8 = call dereferenceable_or_null(8388608) ptr @malloc(i64 8388608)
  store ptr %8, ptr %3, align 8, !tbaa !8
  store i64 8, ptr %.fca.1.gep.i, align 8, !tbaa !8
  store i32 20180515, ptr %.fca.2.gep.i, align 8, !tbaa !8
  store i8 1, ptr %.fca.3.gep.i, align 4, !tbaa !8
  store i8 28, ptr %.fca.4.gep.i, align 1, !tbaa !8
  store i8 2, ptr %.fca.5.gep.i, align 2, !tbaa !8
  store i8 0, ptr %.fca.6.gep.i, align 1, !tbaa !8
  store i64 1, ptr %.fca.7.0.0.gep.i, align 8, !tbaa !8
  store i64 1048576, ptr %.fca.7.0.1.gep.i, align 8, !tbaa !8
  store i64 8, ptr %.fca.7.0.2.gep.i, align 8, !tbaa !8
  %omp_global_thread_num.i = call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %4, ptr %structArg.i, align 8
  %gep_5.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 1
  store ptr %3, ptr %gep_5.i, align 8
  %gep_6.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 2
  store ptr %2, ptr %gep_6.i, align 8
  %gep_7.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 3
  store ptr %1, ptr %gep_7.i, align 8
  %gep_8.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 4
  store ptr %6, ptr %gep_8.i, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QFPomp_subroutine..omp_par, ptr nonnull %structArg.i)
  %.fca.0.load.i = load ptr, ptr %3, align 8, !tbaa !8
  %.fca.7.0.0.load.i = load i64, ptr %.fca.7.0.0.gep.i, align 8, !tbaa !8
  %9 = sub i64 1, %.fca.7.0.0.load.i
  %10 = getelementptr double, ptr %.fca.0.load.i, i64 %9
  %11 = load double, ptr %10, align 8, !tbaa !4
  %12 = load i32, ptr %4, align 4, !tbaa !4
  %13 = sext i32 %12 to i64
  %14 = sub i64 %13, %.fca.7.0.0.load.i
  %15 = getelementptr double, ptr %.fca.0.load.i, i64 %14
  %16 = load double, ptr %15, align 8, !tbaa !4
  %17 = fadd contract double %11, %16
  call void @free(ptr %.fca.0.load.i)
  call void @llvm.lifetime.end.p0(i64 40, ptr nonnull %structArg.i)
  call void @llvm.lifetime.end.p0(i64 48, ptr nonnull %1)
  call void @llvm.lifetime.end.p0(i64 48, ptr nonnull %2)
  call void @llvm.lifetime.end.p0(i64 48, ptr nonnull %3)
  %18 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.e8a0ac9186c064ac8543d822e9060d96, i32 10)
  %19 = call i1 @_FortranAioOutputAscii(ptr %18, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %20 = load i32, ptr %4, align 4, !tbaa !4
  %21 = call i1 @_FortranAioOutputInteger32(ptr %18, i32 %20)
  %22 = call i1 @_FortranAioOutputAscii(ptr %18, ptr nonnull @_QQcl.2920697320, i64 5)
  %23 = call i1 @_FortranAioOutputReal64(ptr %18, double %17)
  %24 = call i32 @_FortranAioEndIoStatement(ptr %18)
  ret void
}
*** IR Dump After LoopSimplifyPass on _QQmain ***
define void @_QQmain() local_unnamed_addr {
  %structArg.i = alloca { ptr, ptr, ptr, ptr, ptr }, align 8
  %1 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %2 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %3 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %4 = alloca i32, align 4
  %5 = alloca double, align 8
  %6 = alloca { ptr, ptr }, align 8
  store ptr %4, ptr %6, align 8, !tbaa !4
  %7 = getelementptr inbounds { ptr, ptr }, ptr %6, i64 0, i32 1
  store ptr %5, ptr %7, align 8, !tbaa !4
  store i32 1048576, ptr %4, align 4, !tbaa !4
  call void @llvm.lifetime.start.p0(i64 40, ptr nonnull %structArg.i)
  call void @llvm.lifetime.start.p0(i64 48, ptr nonnull %1)
  call void @llvm.lifetime.start.p0(i64 48, ptr nonnull %2)
  call void @llvm.lifetime.start.p0(i64 48, ptr nonnull %3)
  %.fca.1.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 1
  %.fca.2.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 2
  %.fca.3.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 3
  %.fca.4.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 4
  %.fca.5.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 5
  %.fca.6.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 6
  %.fca.7.0.0.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 7, i64 0, i64 0
  %.fca.7.0.1.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 7, i64 0, i64 1
  %.fca.7.0.2.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 7, i64 0, i64 2
  %8 = call dereferenceable_or_null(8388608) ptr @malloc(i64 8388608)
  store ptr %8, ptr %3, align 8, !tbaa !8
  store i64 8, ptr %.fca.1.gep.i, align 8, !tbaa !8
  store i32 20180515, ptr %.fca.2.gep.i, align 8, !tbaa !8
  store i8 1, ptr %.fca.3.gep.i, align 4, !tbaa !8
  store i8 28, ptr %.fca.4.gep.i, align 1, !tbaa !8
  store i8 2, ptr %.fca.5.gep.i, align 2, !tbaa !8
  store i8 0, ptr %.fca.6.gep.i, align 1, !tbaa !8
  store i64 1, ptr %.fca.7.0.0.gep.i, align 8, !tbaa !8
  store i64 1048576, ptr %.fca.7.0.1.gep.i, align 8, !tbaa !8
  store i64 8, ptr %.fca.7.0.2.gep.i, align 8, !tbaa !8
  %omp_global_thread_num.i = call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %4, ptr %structArg.i, align 8
  %gep_5.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 1
  store ptr %3, ptr %gep_5.i, align 8
  %gep_6.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 2
  store ptr %2, ptr %gep_6.i, align 8
  %gep_7.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 3
  store ptr %1, ptr %gep_7.i, align 8
  %gep_8.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 4
  store ptr %6, ptr %gep_8.i, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QFPomp_subroutine..omp_par, ptr nonnull %structArg.i)
  %.fca.0.load.i = load ptr, ptr %3, align 8, !tbaa !8
  %.fca.7.0.0.load.i = load i64, ptr %.fca.7.0.0.gep.i, align 8, !tbaa !8
  %9 = sub i64 1, %.fca.7.0.0.load.i
  %10 = getelementptr double, ptr %.fca.0.load.i, i64 %9
  %11 = load double, ptr %10, align 8, !tbaa !4
  %12 = load i32, ptr %4, align 4, !tbaa !4
  %13 = sext i32 %12 to i64
  %14 = sub i64 %13, %.fca.7.0.0.load.i
  %15 = getelementptr double, ptr %.fca.0.load.i, i64 %14
  %16 = load double, ptr %15, align 8, !tbaa !4
  %17 = fadd contract double %11, %16
  call void @free(ptr %.fca.0.load.i)
  call void @llvm.lifetime.end.p0(i64 40, ptr nonnull %structArg.i)
  call void @llvm.lifetime.end.p0(i64 48, ptr nonnull %1)
  call void @llvm.lifetime.end.p0(i64 48, ptr nonnull %2)
  call void @llvm.lifetime.end.p0(i64 48, ptr nonnull %3)
  %18 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.e8a0ac9186c064ac8543d822e9060d96, i32 10)
  %19 = call i1 @_FortranAioOutputAscii(ptr %18, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %20 = load i32, ptr %4, align 4, !tbaa !4
  %21 = call i1 @_FortranAioOutputInteger32(ptr %18, i32 %20)
  %22 = call i1 @_FortranAioOutputAscii(ptr %18, ptr nonnull @_QQcl.2920697320, i64 5)
  %23 = call i1 @_FortranAioOutputReal64(ptr %18, double %17)
  %24 = call i32 @_FortranAioEndIoStatement(ptr %18)
  ret void
}
*** IR Dump After LCSSAPass on _QQmain ***
define void @_QQmain() local_unnamed_addr {
  %structArg.i = alloca { ptr, ptr, ptr, ptr, ptr }, align 8
  %1 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %2 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %3 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %4 = alloca i32, align 4
  %5 = alloca double, align 8
  %6 = alloca { ptr, ptr }, align 8
  store ptr %4, ptr %6, align 8, !tbaa !4
  %7 = getelementptr inbounds { ptr, ptr }, ptr %6, i64 0, i32 1
  store ptr %5, ptr %7, align 8, !tbaa !4
  store i32 1048576, ptr %4, align 4, !tbaa !4
  call void @llvm.lifetime.start.p0(i64 40, ptr nonnull %structArg.i)
  call void @llvm.lifetime.start.p0(i64 48, ptr nonnull %1)
  call void @llvm.lifetime.start.p0(i64 48, ptr nonnull %2)
  call void @llvm.lifetime.start.p0(i64 48, ptr nonnull %3)
  %.fca.1.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 1
  %.fca.2.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 2
  %.fca.3.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 3
  %.fca.4.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 4
  %.fca.5.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 5
  %.fca.6.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 6
  %.fca.7.0.0.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 7, i64 0, i64 0
  %.fca.7.0.1.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 7, i64 0, i64 1
  %.fca.7.0.2.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 7, i64 0, i64 2
  %8 = call dereferenceable_or_null(8388608) ptr @malloc(i64 8388608)
  store ptr %8, ptr %3, align 8, !tbaa !8
  store i64 8, ptr %.fca.1.gep.i, align 8, !tbaa !8
  store i32 20180515, ptr %.fca.2.gep.i, align 8, !tbaa !8
  store i8 1, ptr %.fca.3.gep.i, align 4, !tbaa !8
  store i8 28, ptr %.fca.4.gep.i, align 1, !tbaa !8
  store i8 2, ptr %.fca.5.gep.i, align 2, !tbaa !8
  store i8 0, ptr %.fca.6.gep.i, align 1, !tbaa !8
  store i64 1, ptr %.fca.7.0.0.gep.i, align 8, !tbaa !8
  store i64 1048576, ptr %.fca.7.0.1.gep.i, align 8, !tbaa !8
  store i64 8, ptr %.fca.7.0.2.gep.i, align 8, !tbaa !8
  %omp_global_thread_num.i = call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %4, ptr %structArg.i, align 8
  %gep_5.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 1
  store ptr %3, ptr %gep_5.i, align 8
  %gep_6.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 2
  store ptr %2, ptr %gep_6.i, align 8
  %gep_7.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 3
  store ptr %1, ptr %gep_7.i, align 8
  %gep_8.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 4
  store ptr %6, ptr %gep_8.i, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QFPomp_subroutine..omp_par, ptr nonnull %structArg.i)
  %.fca.0.load.i = load ptr, ptr %3, align 8, !tbaa !8
  %.fca.7.0.0.load.i = load i64, ptr %.fca.7.0.0.gep.i, align 8, !tbaa !8
  %9 = sub i64 1, %.fca.7.0.0.load.i
  %10 = getelementptr double, ptr %.fca.0.load.i, i64 %9
  %11 = load double, ptr %10, align 8, !tbaa !4
  %12 = load i32, ptr %4, align 4, !tbaa !4
  %13 = sext i32 %12 to i64
  %14 = sub i64 %13, %.fca.7.0.0.load.i
  %15 = getelementptr double, ptr %.fca.0.load.i, i64 %14
  %16 = load double, ptr %15, align 8, !tbaa !4
  %17 = fadd contract double %11, %16
  call void @free(ptr %.fca.0.load.i)
  call void @llvm.lifetime.end.p0(i64 40, ptr nonnull %structArg.i)
  call void @llvm.lifetime.end.p0(i64 48, ptr nonnull %1)
  call void @llvm.lifetime.end.p0(i64 48, ptr nonnull %2)
  call void @llvm.lifetime.end.p0(i64 48, ptr nonnull %3)
  %18 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.e8a0ac9186c064ac8543d822e9060d96, i32 10)
  %19 = call i1 @_FortranAioOutputAscii(ptr %18, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %20 = load i32, ptr %4, align 4, !tbaa !4
  %21 = call i1 @_FortranAioOutputInteger32(ptr %18, i32 %20)
  %22 = call i1 @_FortranAioOutputAscii(ptr %18, ptr nonnull @_QQcl.2920697320, i64 5)
  %23 = call i1 @_FortranAioOutputReal64(ptr %18, double %17)
  %24 = call i32 @_FortranAioEndIoStatement(ptr %18)
  ret void
}
*** IR Dump After SROAPass on _QQmain ***
define void @_QQmain() local_unnamed_addr {
  %structArg.i = alloca { ptr, ptr, ptr, ptr, ptr }, align 8
  %1 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %2 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %3 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %4 = alloca i32, align 4
  %5 = alloca double, align 8
  %6 = alloca { ptr, ptr }, align 8
  store ptr %4, ptr %6, align 8, !tbaa !4
  %7 = getelementptr inbounds { ptr, ptr }, ptr %6, i64 0, i32 1
  store ptr %5, ptr %7, align 8, !tbaa !4
  store i32 1048576, ptr %4, align 4, !tbaa !4
  call void @llvm.lifetime.start.p0(i64 40, ptr nonnull %structArg.i)
  call void @llvm.lifetime.start.p0(i64 48, ptr nonnull %1)
  call void @llvm.lifetime.start.p0(i64 48, ptr nonnull %2)
  call void @llvm.lifetime.start.p0(i64 48, ptr nonnull %3)
  %.fca.1.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 1
  %.fca.2.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 2
  %.fca.3.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 3
  %.fca.4.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 4
  %.fca.5.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 5
  %.fca.6.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 6
  %.fca.7.0.0.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 7, i64 0, i64 0
  %.fca.7.0.1.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 7, i64 0, i64 1
  %.fca.7.0.2.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 7, i64 0, i64 2
  %8 = call dereferenceable_or_null(8388608) ptr @malloc(i64 8388608)
  store ptr %8, ptr %3, align 8, !tbaa !8
  store i64 8, ptr %.fca.1.gep.i, align 8, !tbaa !8
  store i32 20180515, ptr %.fca.2.gep.i, align 8, !tbaa !8
  store i8 1, ptr %.fca.3.gep.i, align 4, !tbaa !8
  store i8 28, ptr %.fca.4.gep.i, align 1, !tbaa !8
  store i8 2, ptr %.fca.5.gep.i, align 2, !tbaa !8
  store i8 0, ptr %.fca.6.gep.i, align 1, !tbaa !8
  store i64 1, ptr %.fca.7.0.0.gep.i, align 8, !tbaa !8
  store i64 1048576, ptr %.fca.7.0.1.gep.i, align 8, !tbaa !8
  store i64 8, ptr %.fca.7.0.2.gep.i, align 8, !tbaa !8
  %omp_global_thread_num.i = call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %4, ptr %structArg.i, align 8
  %gep_5.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 1
  store ptr %3, ptr %gep_5.i, align 8
  %gep_6.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 2
  store ptr %2, ptr %gep_6.i, align 8
  %gep_7.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 3
  store ptr %1, ptr %gep_7.i, align 8
  %gep_8.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 4
  store ptr %6, ptr %gep_8.i, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QFPomp_subroutine..omp_par, ptr nonnull %structArg.i)
  %.fca.0.load.i = load ptr, ptr %3, align 8, !tbaa !8
  %.fca.7.0.0.load.i = load i64, ptr %.fca.7.0.0.gep.i, align 8, !tbaa !8
  %9 = sub i64 1, %.fca.7.0.0.load.i
  %10 = getelementptr double, ptr %.fca.0.load.i, i64 %9
  %11 = load double, ptr %10, align 8, !tbaa !4
  %12 = load i32, ptr %4, align 4, !tbaa !4
  %13 = sext i32 %12 to i64
  %14 = sub i64 %13, %.fca.7.0.0.load.i
  %15 = getelementptr double, ptr %.fca.0.load.i, i64 %14
  %16 = load double, ptr %15, align 8, !tbaa !4
  %17 = fadd contract double %11, %16
  call void @free(ptr %.fca.0.load.i)
  call void @llvm.lifetime.end.p0(i64 40, ptr nonnull %structArg.i)
  call void @llvm.lifetime.end.p0(i64 48, ptr nonnull %1)
  call void @llvm.lifetime.end.p0(i64 48, ptr nonnull %2)
  call void @llvm.lifetime.end.p0(i64 48, ptr nonnull %3)
  %18 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.e8a0ac9186c064ac8543d822e9060d96, i32 10)
  %19 = call i1 @_FortranAioOutputAscii(ptr %18, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %20 = load i32, ptr %4, align 4, !tbaa !4
  %21 = call i1 @_FortranAioOutputInteger32(ptr %18, i32 %20)
  %22 = call i1 @_FortranAioOutputAscii(ptr %18, ptr nonnull @_QQcl.2920697320, i64 5)
  %23 = call i1 @_FortranAioOutputReal64(ptr %18, double %17)
  %24 = call i32 @_FortranAioEndIoStatement(ptr %18)
  ret void
}
*** IR Dump After VectorCombinePass on _QQmain ***
define void @_QQmain() local_unnamed_addr {
  %structArg.i = alloca { ptr, ptr, ptr, ptr, ptr }, align 8
  %1 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %2 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %3 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %4 = alloca i32, align 4
  %5 = alloca double, align 8
  %6 = alloca { ptr, ptr }, align 8
  store ptr %4, ptr %6, align 8, !tbaa !4
  %7 = getelementptr inbounds { ptr, ptr }, ptr %6, i64 0, i32 1
  store ptr %5, ptr %7, align 8, !tbaa !4
  store i32 1048576, ptr %4, align 4, !tbaa !4
  call void @llvm.lifetime.start.p0(i64 40, ptr nonnull %structArg.i)
  call void @llvm.lifetime.start.p0(i64 48, ptr nonnull %1)
  call void @llvm.lifetime.start.p0(i64 48, ptr nonnull %2)
  call void @llvm.lifetime.start.p0(i64 48, ptr nonnull %3)
  %.fca.1.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 1
  %.fca.2.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 2
  %.fca.3.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 3
  %.fca.4.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 4
  %.fca.5.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 5
  %.fca.6.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 6
  %.fca.7.0.0.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 7, i64 0, i64 0
  %.fca.7.0.1.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 7, i64 0, i64 1
  %.fca.7.0.2.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 7, i64 0, i64 2
  %8 = call dereferenceable_or_null(8388608) ptr @malloc(i64 8388608)
  store ptr %8, ptr %3, align 8, !tbaa !8
  store i64 8, ptr %.fca.1.gep.i, align 8, !tbaa !8
  store i32 20180515, ptr %.fca.2.gep.i, align 8, !tbaa !8
  store i8 1, ptr %.fca.3.gep.i, align 4, !tbaa !8
  store i8 28, ptr %.fca.4.gep.i, align 1, !tbaa !8
  store i8 2, ptr %.fca.5.gep.i, align 2, !tbaa !8
  store i8 0, ptr %.fca.6.gep.i, align 1, !tbaa !8
  store i64 1, ptr %.fca.7.0.0.gep.i, align 8, !tbaa !8
  store i64 1048576, ptr %.fca.7.0.1.gep.i, align 8, !tbaa !8
  store i64 8, ptr %.fca.7.0.2.gep.i, align 8, !tbaa !8
  %omp_global_thread_num.i = call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %4, ptr %structArg.i, align 8
  %gep_5.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 1
  store ptr %3, ptr %gep_5.i, align 8
  %gep_6.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 2
  store ptr %2, ptr %gep_6.i, align 8
  %gep_7.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 3
  store ptr %1, ptr %gep_7.i, align 8
  %gep_8.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 4
  store ptr %6, ptr %gep_8.i, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QFPomp_subroutine..omp_par, ptr nonnull %structArg.i)
  %.fca.0.load.i = load ptr, ptr %3, align 8, !tbaa !8
  %.fca.7.0.0.load.i = load i64, ptr %.fca.7.0.0.gep.i, align 8, !tbaa !8
  %9 = sub i64 1, %.fca.7.0.0.load.i
  %10 = getelementptr double, ptr %.fca.0.load.i, i64 %9
  %11 = load double, ptr %10, align 8, !tbaa !4
  %12 = load i32, ptr %4, align 4, !tbaa !4
  %13 = sext i32 %12 to i64
  %14 = sub i64 %13, %.fca.7.0.0.load.i
  %15 = getelementptr double, ptr %.fca.0.load.i, i64 %14
  %16 = load double, ptr %15, align 8, !tbaa !4
  %17 = fadd contract double %11, %16
  call void @free(ptr %.fca.0.load.i)
  call void @llvm.lifetime.end.p0(i64 40, ptr nonnull %structArg.i)
  call void @llvm.lifetime.end.p0(i64 48, ptr nonnull %1)
  call void @llvm.lifetime.end.p0(i64 48, ptr nonnull %2)
  call void @llvm.lifetime.end.p0(i64 48, ptr nonnull %3)
  %18 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.e8a0ac9186c064ac8543d822e9060d96, i32 10)
  %19 = call i1 @_FortranAioOutputAscii(ptr %18, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %20 = load i32, ptr %4, align 4, !tbaa !4
  %21 = call i1 @_FortranAioOutputInteger32(ptr %18, i32 %20)
  %22 = call i1 @_FortranAioOutputAscii(ptr %18, ptr nonnull @_QQcl.2920697320, i64 5)
  %23 = call i1 @_FortranAioOutputReal64(ptr %18, double %17)
  %24 = call i32 @_FortranAioEndIoStatement(ptr %18)
  ret void
}
*** IR Dump After MergedLoadStoreMotionPass on _QQmain ***
define void @_QQmain() local_unnamed_addr {
  %structArg.i = alloca { ptr, ptr, ptr, ptr, ptr }, align 8
  %1 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %2 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %3 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %4 = alloca i32, align 4
  %5 = alloca double, align 8
  %6 = alloca { ptr, ptr }, align 8
  store ptr %4, ptr %6, align 8, !tbaa !4
  %7 = getelementptr inbounds { ptr, ptr }, ptr %6, i64 0, i32 1
  store ptr %5, ptr %7, align 8, !tbaa !4
  store i32 1048576, ptr %4, align 4, !tbaa !4
  call void @llvm.lifetime.start.p0(i64 40, ptr nonnull %structArg.i)
  call void @llvm.lifetime.start.p0(i64 48, ptr nonnull %1)
  call void @llvm.lifetime.start.p0(i64 48, ptr nonnull %2)
  call void @llvm.lifetime.start.p0(i64 48, ptr nonnull %3)
  %.fca.1.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 1
  %.fca.2.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 2
  %.fca.3.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 3
  %.fca.4.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 4
  %.fca.5.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 5
  %.fca.6.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 6
  %.fca.7.0.0.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 7, i64 0, i64 0
  %.fca.7.0.1.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 7, i64 0, i64 1
  %.fca.7.0.2.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 7, i64 0, i64 2
  %8 = call dereferenceable_or_null(8388608) ptr @malloc(i64 8388608)
  store ptr %8, ptr %3, align 8, !tbaa !8
  store i64 8, ptr %.fca.1.gep.i, align 8, !tbaa !8
  store i32 20180515, ptr %.fca.2.gep.i, align 8, !tbaa !8
  store i8 1, ptr %.fca.3.gep.i, align 4, !tbaa !8
  store i8 28, ptr %.fca.4.gep.i, align 1, !tbaa !8
  store i8 2, ptr %.fca.5.gep.i, align 2, !tbaa !8
  store i8 0, ptr %.fca.6.gep.i, align 1, !tbaa !8
  store i64 1, ptr %.fca.7.0.0.gep.i, align 8, !tbaa !8
  store i64 1048576, ptr %.fca.7.0.1.gep.i, align 8, !tbaa !8
  store i64 8, ptr %.fca.7.0.2.gep.i, align 8, !tbaa !8
  %omp_global_thread_num.i = call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %4, ptr %structArg.i, align 8
  %gep_5.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 1
  store ptr %3, ptr %gep_5.i, align 8
  %gep_6.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 2
  store ptr %2, ptr %gep_6.i, align 8
  %gep_7.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 3
  store ptr %1, ptr %gep_7.i, align 8
  %gep_8.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 4
  store ptr %6, ptr %gep_8.i, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QFPomp_subroutine..omp_par, ptr nonnull %structArg.i)
  %.fca.0.load.i = load ptr, ptr %3, align 8, !tbaa !8
  %.fca.7.0.0.load.i = load i64, ptr %.fca.7.0.0.gep.i, align 8, !tbaa !8
  %9 = sub i64 1, %.fca.7.0.0.load.i
  %10 = getelementptr double, ptr %.fca.0.load.i, i64 %9
  %11 = load double, ptr %10, align 8, !tbaa !4
  %12 = load i32, ptr %4, align 4, !tbaa !4
  %13 = sext i32 %12 to i64
  %14 = sub i64 %13, %.fca.7.0.0.load.i
  %15 = getelementptr double, ptr %.fca.0.load.i, i64 %14
  %16 = load double, ptr %15, align 8, !tbaa !4
  %17 = fadd contract double %11, %16
  call void @free(ptr %.fca.0.load.i)
  call void @llvm.lifetime.end.p0(i64 40, ptr nonnull %structArg.i)
  call void @llvm.lifetime.end.p0(i64 48, ptr nonnull %1)
  call void @llvm.lifetime.end.p0(i64 48, ptr nonnull %2)
  call void @llvm.lifetime.end.p0(i64 48, ptr nonnull %3)
  %18 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.e8a0ac9186c064ac8543d822e9060d96, i32 10)
  %19 = call i1 @_FortranAioOutputAscii(ptr %18, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %20 = load i32, ptr %4, align 4, !tbaa !4
  %21 = call i1 @_FortranAioOutputInteger32(ptr %18, i32 %20)
  %22 = call i1 @_FortranAioOutputAscii(ptr %18, ptr nonnull @_QQcl.2920697320, i64 5)
  %23 = call i1 @_FortranAioOutputReal64(ptr %18, double %17)
  %24 = call i32 @_FortranAioEndIoStatement(ptr %18)
  ret void
}
*** IR Dump After GVNPass on _QQmain ***
define void @_QQmain() local_unnamed_addr {
  %structArg.i = alloca { ptr, ptr, ptr, ptr, ptr }, align 8
  %1 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %2 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %3 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %4 = alloca i32, align 4
  %5 = alloca double, align 8
  %6 = alloca { ptr, ptr }, align 8
  store ptr %4, ptr %6, align 8, !tbaa !4
  %7 = getelementptr inbounds { ptr, ptr }, ptr %6, i64 0, i32 1
  store ptr %5, ptr %7, align 8, !tbaa !4
  store i32 1048576, ptr %4, align 4, !tbaa !4
  call void @llvm.lifetime.start.p0(i64 40, ptr nonnull %structArg.i)
  call void @llvm.lifetime.start.p0(i64 48, ptr nonnull %1)
  call void @llvm.lifetime.start.p0(i64 48, ptr nonnull %2)
  call void @llvm.lifetime.start.p0(i64 48, ptr nonnull %3)
  %.fca.1.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 1
  %.fca.2.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 2
  %.fca.3.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 3
  %.fca.4.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 4
  %.fca.5.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 5
  %.fca.6.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 6
  %.fca.7.0.0.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 7, i64 0, i64 0
  %.fca.7.0.1.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 7, i64 0, i64 1
  %.fca.7.0.2.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 7, i64 0, i64 2
  %8 = call dereferenceable_or_null(8388608) ptr @malloc(i64 8388608)
  store ptr %8, ptr %3, align 8, !tbaa !8
  store i64 8, ptr %.fca.1.gep.i, align 8, !tbaa !8
  store i32 20180515, ptr %.fca.2.gep.i, align 8, !tbaa !8
  store i8 1, ptr %.fca.3.gep.i, align 4, !tbaa !8
  store i8 28, ptr %.fca.4.gep.i, align 1, !tbaa !8
  store i8 2, ptr %.fca.5.gep.i, align 2, !tbaa !8
  store i8 0, ptr %.fca.6.gep.i, align 1, !tbaa !8
  store i64 1, ptr %.fca.7.0.0.gep.i, align 8, !tbaa !8
  store i64 1048576, ptr %.fca.7.0.1.gep.i, align 8, !tbaa !8
  store i64 8, ptr %.fca.7.0.2.gep.i, align 8, !tbaa !8
  %omp_global_thread_num.i = call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %4, ptr %structArg.i, align 8
  %gep_5.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 1
  store ptr %3, ptr %gep_5.i, align 8
  %gep_6.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 2
  store ptr %2, ptr %gep_6.i, align 8
  %gep_7.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 3
  store ptr %1, ptr %gep_7.i, align 8
  %gep_8.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 4
  store ptr %6, ptr %gep_8.i, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QFPomp_subroutine..omp_par, ptr nonnull %structArg.i)
  %.fca.0.load.i = load ptr, ptr %3, align 8, !tbaa !8
  %.fca.7.0.0.load.i = load i64, ptr %.fca.7.0.0.gep.i, align 8, !tbaa !8
  %9 = sub i64 1, %.fca.7.0.0.load.i
  %10 = getelementptr double, ptr %.fca.0.load.i, i64 %9
  %11 = load double, ptr %10, align 8, !tbaa !4
  %12 = load i32, ptr %4, align 4, !tbaa !4
  %13 = sext i32 %12 to i64
  %14 = sub i64 %13, %.fca.7.0.0.load.i
  %15 = getelementptr double, ptr %.fca.0.load.i, i64 %14
  %16 = load double, ptr %15, align 8, !tbaa !4
  %17 = fadd contract double %11, %16
  call void @free(ptr %.fca.0.load.i)
  call void @llvm.lifetime.end.p0(i64 40, ptr nonnull %structArg.i)
  call void @llvm.lifetime.end.p0(i64 48, ptr nonnull %1)
  call void @llvm.lifetime.end.p0(i64 48, ptr nonnull %2)
  call void @llvm.lifetime.end.p0(i64 48, ptr nonnull %3)
  %18 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.e8a0ac9186c064ac8543d822e9060d96, i32 10)
  %19 = call i1 @_FortranAioOutputAscii(ptr %18, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %20 = load i32, ptr %4, align 4, !tbaa !4
  %21 = call i1 @_FortranAioOutputInteger32(ptr %18, i32 %20)
  %22 = call i1 @_FortranAioOutputAscii(ptr %18, ptr nonnull @_QQcl.2920697320, i64 5)
  %23 = call i1 @_FortranAioOutputReal64(ptr %18, double %17)
  %24 = call i32 @_FortranAioEndIoStatement(ptr %18)
  ret void
}
*** IR Dump After SCCPPass on _QQmain ***
define void @_QQmain() local_unnamed_addr {
  %structArg.i = alloca { ptr, ptr, ptr, ptr, ptr }, align 8
  %1 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %2 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %3 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %4 = alloca i32, align 4
  %5 = alloca double, align 8
  %6 = alloca { ptr, ptr }, align 8
  store ptr %4, ptr %6, align 8, !tbaa !4
  %7 = getelementptr inbounds { ptr, ptr }, ptr %6, i64 0, i32 1
  store ptr %5, ptr %7, align 8, !tbaa !4
  store i32 1048576, ptr %4, align 4, !tbaa !4
  call void @llvm.lifetime.start.p0(i64 40, ptr nonnull %structArg.i)
  call void @llvm.lifetime.start.p0(i64 48, ptr nonnull %1)
  call void @llvm.lifetime.start.p0(i64 48, ptr nonnull %2)
  call void @llvm.lifetime.start.p0(i64 48, ptr nonnull %3)
  %.fca.1.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 1
  %.fca.2.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 2
  %.fca.3.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 3
  %.fca.4.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 4
  %.fca.5.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 5
  %.fca.6.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 6
  %.fca.7.0.0.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 7, i64 0, i64 0
  %.fca.7.0.1.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 7, i64 0, i64 1
  %.fca.7.0.2.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 7, i64 0, i64 2
  %8 = call dereferenceable_or_null(8388608) ptr @malloc(i64 8388608)
  store ptr %8, ptr %3, align 8, !tbaa !8
  store i64 8, ptr %.fca.1.gep.i, align 8, !tbaa !8
  store i32 20180515, ptr %.fca.2.gep.i, align 8, !tbaa !8
  store i8 1, ptr %.fca.3.gep.i, align 4, !tbaa !8
  store i8 28, ptr %.fca.4.gep.i, align 1, !tbaa !8
  store i8 2, ptr %.fca.5.gep.i, align 2, !tbaa !8
  store i8 0, ptr %.fca.6.gep.i, align 1, !tbaa !8
  store i64 1, ptr %.fca.7.0.0.gep.i, align 8, !tbaa !8
  store i64 1048576, ptr %.fca.7.0.1.gep.i, align 8, !tbaa !8
  store i64 8, ptr %.fca.7.0.2.gep.i, align 8, !tbaa !8
  %omp_global_thread_num.i = call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %4, ptr %structArg.i, align 8
  %gep_5.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 1
  store ptr %3, ptr %gep_5.i, align 8
  %gep_6.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 2
  store ptr %2, ptr %gep_6.i, align 8
  %gep_7.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 3
  store ptr %1, ptr %gep_7.i, align 8
  %gep_8.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 4
  store ptr %6, ptr %gep_8.i, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QFPomp_subroutine..omp_par, ptr nonnull %structArg.i)
  %.fca.0.load.i = load ptr, ptr %3, align 8, !tbaa !8
  %.fca.7.0.0.load.i = load i64, ptr %.fca.7.0.0.gep.i, align 8, !tbaa !8
  %9 = sub i64 1, %.fca.7.0.0.load.i
  %10 = getelementptr double, ptr %.fca.0.load.i, i64 %9
  %11 = load double, ptr %10, align 8, !tbaa !4
  %12 = load i32, ptr %4, align 4, !tbaa !4
  %13 = sext i32 %12 to i64
  %14 = sub i64 %13, %.fca.7.0.0.load.i
  %15 = getelementptr double, ptr %.fca.0.load.i, i64 %14
  %16 = load double, ptr %15, align 8, !tbaa !4
  %17 = fadd contract double %11, %16
  call void @free(ptr %.fca.0.load.i)
  call void @llvm.lifetime.end.p0(i64 40, ptr nonnull %structArg.i)
  call void @llvm.lifetime.end.p0(i64 48, ptr nonnull %1)
  call void @llvm.lifetime.end.p0(i64 48, ptr nonnull %2)
  call void @llvm.lifetime.end.p0(i64 48, ptr nonnull %3)
  %18 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.e8a0ac9186c064ac8543d822e9060d96, i32 10)
  %19 = call i1 @_FortranAioOutputAscii(ptr %18, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %20 = load i32, ptr %4, align 4, !tbaa !4
  %21 = call i1 @_FortranAioOutputInteger32(ptr %18, i32 %20)
  %22 = call i1 @_FortranAioOutputAscii(ptr %18, ptr nonnull @_QQcl.2920697320, i64 5)
  %23 = call i1 @_FortranAioOutputReal64(ptr %18, double %17)
  %24 = call i32 @_FortranAioEndIoStatement(ptr %18)
  ret void
}
*** IR Dump After BDCEPass on _QQmain ***
define void @_QQmain() local_unnamed_addr {
  %structArg.i = alloca { ptr, ptr, ptr, ptr, ptr }, align 8
  %1 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %2 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %3 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %4 = alloca i32, align 4
  %5 = alloca double, align 8
  %6 = alloca { ptr, ptr }, align 8
  store ptr %4, ptr %6, align 8, !tbaa !4
  %7 = getelementptr inbounds { ptr, ptr }, ptr %6, i64 0, i32 1
  store ptr %5, ptr %7, align 8, !tbaa !4
  store i32 1048576, ptr %4, align 4, !tbaa !4
  call void @llvm.lifetime.start.p0(i64 40, ptr nonnull %structArg.i)
  call void @llvm.lifetime.start.p0(i64 48, ptr nonnull %1)
  call void @llvm.lifetime.start.p0(i64 48, ptr nonnull %2)
  call void @llvm.lifetime.start.p0(i64 48, ptr nonnull %3)
  %.fca.1.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 1
  %.fca.2.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 2
  %.fca.3.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 3
  %.fca.4.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 4
  %.fca.5.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 5
  %.fca.6.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 6
  %.fca.7.0.0.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 7, i64 0, i64 0
  %.fca.7.0.1.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 7, i64 0, i64 1
  %.fca.7.0.2.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 7, i64 0, i64 2
  %8 = call dereferenceable_or_null(8388608) ptr @malloc(i64 8388608)
  store ptr %8, ptr %3, align 8, !tbaa !8
  store i64 8, ptr %.fca.1.gep.i, align 8, !tbaa !8
  store i32 20180515, ptr %.fca.2.gep.i, align 8, !tbaa !8
  store i8 1, ptr %.fca.3.gep.i, align 4, !tbaa !8
  store i8 28, ptr %.fca.4.gep.i, align 1, !tbaa !8
  store i8 2, ptr %.fca.5.gep.i, align 2, !tbaa !8
  store i8 0, ptr %.fca.6.gep.i, align 1, !tbaa !8
  store i64 1, ptr %.fca.7.0.0.gep.i, align 8, !tbaa !8
  store i64 1048576, ptr %.fca.7.0.1.gep.i, align 8, !tbaa !8
  store i64 8, ptr %.fca.7.0.2.gep.i, align 8, !tbaa !8
  %omp_global_thread_num.i = call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %4, ptr %structArg.i, align 8
  %gep_5.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 1
  store ptr %3, ptr %gep_5.i, align 8
  %gep_6.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 2
  store ptr %2, ptr %gep_6.i, align 8
  %gep_7.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 3
  store ptr %1, ptr %gep_7.i, align 8
  %gep_8.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 4
  store ptr %6, ptr %gep_8.i, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QFPomp_subroutine..omp_par, ptr nonnull %structArg.i)
  %.fca.0.load.i = load ptr, ptr %3, align 8, !tbaa !8
  %.fca.7.0.0.load.i = load i64, ptr %.fca.7.0.0.gep.i, align 8, !tbaa !8
  %9 = sub i64 1, %.fca.7.0.0.load.i
  %10 = getelementptr double, ptr %.fca.0.load.i, i64 %9
  %11 = load double, ptr %10, align 8, !tbaa !4
  %12 = load i32, ptr %4, align 4, !tbaa !4
  %13 = sext i32 %12 to i64
  %14 = sub i64 %13, %.fca.7.0.0.load.i
  %15 = getelementptr double, ptr %.fca.0.load.i, i64 %14
  %16 = load double, ptr %15, align 8, !tbaa !4
  %17 = fadd contract double %11, %16
  call void @free(ptr %.fca.0.load.i)
  call void @llvm.lifetime.end.p0(i64 40, ptr nonnull %structArg.i)
  call void @llvm.lifetime.end.p0(i64 48, ptr nonnull %1)
  call void @llvm.lifetime.end.p0(i64 48, ptr nonnull %2)
  call void @llvm.lifetime.end.p0(i64 48, ptr nonnull %3)
  %18 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.e8a0ac9186c064ac8543d822e9060d96, i32 10)
  %19 = call i1 @_FortranAioOutputAscii(ptr %18, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %20 = load i32, ptr %4, align 4, !tbaa !4
  %21 = call i1 @_FortranAioOutputInteger32(ptr %18, i32 %20)
  %22 = call i1 @_FortranAioOutputAscii(ptr %18, ptr nonnull @_QQcl.2920697320, i64 5)
  %23 = call i1 @_FortranAioOutputReal64(ptr %18, double %17)
  %24 = call i32 @_FortranAioEndIoStatement(ptr %18)
  ret void
}
*** IR Dump After InstCombinePass on _QQmain ***
define void @_QQmain() local_unnamed_addr {
  %structArg.i = alloca { ptr, ptr, ptr, ptr, ptr }, align 8
  %1 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %2 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %3 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %4 = alloca i32, align 4
  %5 = alloca double, align 8
  %6 = alloca { ptr, ptr }, align 8
  store ptr %4, ptr %6, align 8, !tbaa !4
  %7 = getelementptr inbounds { ptr, ptr }, ptr %6, i64 0, i32 1
  store ptr %5, ptr %7, align 8, !tbaa !4
  store i32 1048576, ptr %4, align 4, !tbaa !4
  call void @llvm.lifetime.start.p0(i64 40, ptr nonnull %structArg.i)
  call void @llvm.lifetime.start.p0(i64 48, ptr nonnull %1)
  call void @llvm.lifetime.start.p0(i64 48, ptr nonnull %2)
  call void @llvm.lifetime.start.p0(i64 48, ptr nonnull %3)
  %.fca.1.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 1
  %.fca.2.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 2
  %.fca.3.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 3
  %.fca.4.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 4
  %.fca.5.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 5
  %.fca.6.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 6
  %.fca.7.0.0.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 7, i64 0, i64 0
  %.fca.7.0.1.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 7, i64 0, i64 1
  %.fca.7.0.2.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 7, i64 0, i64 2
  %8 = call dereferenceable_or_null(8388608) ptr @malloc(i64 8388608)
  store ptr %8, ptr %3, align 8, !tbaa !8
  store i64 8, ptr %.fca.1.gep.i, align 8, !tbaa !8
  store i32 20180515, ptr %.fca.2.gep.i, align 8, !tbaa !8
  store i8 1, ptr %.fca.3.gep.i, align 4, !tbaa !8
  store i8 28, ptr %.fca.4.gep.i, align 1, !tbaa !8
  store i8 2, ptr %.fca.5.gep.i, align 2, !tbaa !8
  store i8 0, ptr %.fca.6.gep.i, align 1, !tbaa !8
  store i64 1, ptr %.fca.7.0.0.gep.i, align 8, !tbaa !8
  store i64 1048576, ptr %.fca.7.0.1.gep.i, align 8, !tbaa !8
  store i64 8, ptr %.fca.7.0.2.gep.i, align 8, !tbaa !8
  %omp_global_thread_num.i = call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %4, ptr %structArg.i, align 8
  %gep_5.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 1
  store ptr %3, ptr %gep_5.i, align 8
  %gep_6.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 2
  store ptr %2, ptr %gep_6.i, align 8
  %gep_7.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 3
  store ptr %1, ptr %gep_7.i, align 8
  %gep_8.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 4
  store ptr %6, ptr %gep_8.i, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QFPomp_subroutine..omp_par, ptr nonnull %structArg.i)
  %.fca.0.load.i = load ptr, ptr %3, align 8, !tbaa !8
  %.fca.7.0.0.load.i = load i64, ptr %.fca.7.0.0.gep.i, align 8, !tbaa !8
  %9 = sub i64 1, %.fca.7.0.0.load.i
  %10 = getelementptr double, ptr %.fca.0.load.i, i64 %9
  %11 = load double, ptr %10, align 8, !tbaa !4
  %12 = load i32, ptr %4, align 4, !tbaa !4
  %13 = sext i32 %12 to i64
  %14 = sub i64 %13, %.fca.7.0.0.load.i
  %15 = getelementptr double, ptr %.fca.0.load.i, i64 %14
  %16 = load double, ptr %15, align 8, !tbaa !4
  %17 = fadd contract double %11, %16
  call void @free(ptr %.fca.0.load.i)
  call void @llvm.lifetime.end.p0(i64 40, ptr nonnull %structArg.i)
  call void @llvm.lifetime.end.p0(i64 48, ptr nonnull %1)
  call void @llvm.lifetime.end.p0(i64 48, ptr nonnull %2)
  call void @llvm.lifetime.end.p0(i64 48, ptr nonnull %3)
  %18 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.e8a0ac9186c064ac8543d822e9060d96, i32 10)
  %19 = call i1 @_FortranAioOutputAscii(ptr %18, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %20 = load i32, ptr %4, align 4, !tbaa !4
  %21 = call i1 @_FortranAioOutputInteger32(ptr %18, i32 %20)
  %22 = call i1 @_FortranAioOutputAscii(ptr %18, ptr nonnull @_QQcl.2920697320, i64 5)
  %23 = call i1 @_FortranAioOutputReal64(ptr %18, double %17)
  %24 = call i32 @_FortranAioEndIoStatement(ptr %18)
  ret void
}
*** IR Dump After JumpThreadingPass on _QQmain ***
define void @_QQmain() local_unnamed_addr {
  %structArg.i = alloca { ptr, ptr, ptr, ptr, ptr }, align 8
  %1 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %2 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %3 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %4 = alloca i32, align 4
  %5 = alloca double, align 8
  %6 = alloca { ptr, ptr }, align 8
  store ptr %4, ptr %6, align 8, !tbaa !4
  %7 = getelementptr inbounds { ptr, ptr }, ptr %6, i64 0, i32 1
  store ptr %5, ptr %7, align 8, !tbaa !4
  store i32 1048576, ptr %4, align 4, !tbaa !4
  call void @llvm.lifetime.start.p0(i64 40, ptr nonnull %structArg.i)
  call void @llvm.lifetime.start.p0(i64 48, ptr nonnull %1)
  call void @llvm.lifetime.start.p0(i64 48, ptr nonnull %2)
  call void @llvm.lifetime.start.p0(i64 48, ptr nonnull %3)
  %.fca.1.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 1
  %.fca.2.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 2
  %.fca.3.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 3
  %.fca.4.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 4
  %.fca.5.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 5
  %.fca.6.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 6
  %.fca.7.0.0.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 7, i64 0, i64 0
  %.fca.7.0.1.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 7, i64 0, i64 1
  %.fca.7.0.2.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 7, i64 0, i64 2
  %8 = call dereferenceable_or_null(8388608) ptr @malloc(i64 8388608)
  store ptr %8, ptr %3, align 8, !tbaa !8
  store i64 8, ptr %.fca.1.gep.i, align 8, !tbaa !8
  store i32 20180515, ptr %.fca.2.gep.i, align 8, !tbaa !8
  store i8 1, ptr %.fca.3.gep.i, align 4, !tbaa !8
  store i8 28, ptr %.fca.4.gep.i, align 1, !tbaa !8
  store i8 2, ptr %.fca.5.gep.i, align 2, !tbaa !8
  store i8 0, ptr %.fca.6.gep.i, align 1, !tbaa !8
  store i64 1, ptr %.fca.7.0.0.gep.i, align 8, !tbaa !8
  store i64 1048576, ptr %.fca.7.0.1.gep.i, align 8, !tbaa !8
  store i64 8, ptr %.fca.7.0.2.gep.i, align 8, !tbaa !8
  %omp_global_thread_num.i = call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %4, ptr %structArg.i, align 8
  %gep_5.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 1
  store ptr %3, ptr %gep_5.i, align 8
  %gep_6.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 2
  store ptr %2, ptr %gep_6.i, align 8
  %gep_7.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 3
  store ptr %1, ptr %gep_7.i, align 8
  %gep_8.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 4
  store ptr %6, ptr %gep_8.i, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QFPomp_subroutine..omp_par, ptr nonnull %structArg.i)
  %.fca.0.load.i = load ptr, ptr %3, align 8, !tbaa !8
  %.fca.7.0.0.load.i = load i64, ptr %.fca.7.0.0.gep.i, align 8, !tbaa !8
  %9 = sub i64 1, %.fca.7.0.0.load.i
  %10 = getelementptr double, ptr %.fca.0.load.i, i64 %9
  %11 = load double, ptr %10, align 8, !tbaa !4
  %12 = load i32, ptr %4, align 4, !tbaa !4
  %13 = sext i32 %12 to i64
  %14 = sub i64 %13, %.fca.7.0.0.load.i
  %15 = getelementptr double, ptr %.fca.0.load.i, i64 %14
  %16 = load double, ptr %15, align 8, !tbaa !4
  %17 = fadd contract double %11, %16
  call void @free(ptr %.fca.0.load.i)
  call void @llvm.lifetime.end.p0(i64 40, ptr nonnull %structArg.i)
  call void @llvm.lifetime.end.p0(i64 48, ptr nonnull %1)
  call void @llvm.lifetime.end.p0(i64 48, ptr nonnull %2)
  call void @llvm.lifetime.end.p0(i64 48, ptr nonnull %3)
  %18 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.e8a0ac9186c064ac8543d822e9060d96, i32 10)
  %19 = call i1 @_FortranAioOutputAscii(ptr %18, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %20 = load i32, ptr %4, align 4, !tbaa !4
  %21 = call i1 @_FortranAioOutputInteger32(ptr %18, i32 %20)
  %22 = call i1 @_FortranAioOutputAscii(ptr %18, ptr nonnull @_QQcl.2920697320, i64 5)
  %23 = call i1 @_FortranAioOutputReal64(ptr %18, double %17)
  %24 = call i32 @_FortranAioEndIoStatement(ptr %18)
  ret void
}
*** IR Dump After CorrelatedValuePropagationPass on _QQmain ***
define void @_QQmain() local_unnamed_addr {
  %structArg.i = alloca { ptr, ptr, ptr, ptr, ptr }, align 8
  %1 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %2 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %3 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %4 = alloca i32, align 4
  %5 = alloca double, align 8
  %6 = alloca { ptr, ptr }, align 8
  store ptr %4, ptr %6, align 8, !tbaa !4
  %7 = getelementptr inbounds { ptr, ptr }, ptr %6, i64 0, i32 1
  store ptr %5, ptr %7, align 8, !tbaa !4
  store i32 1048576, ptr %4, align 4, !tbaa !4
  call void @llvm.lifetime.start.p0(i64 40, ptr nonnull %structArg.i)
  call void @llvm.lifetime.start.p0(i64 48, ptr nonnull %1)
  call void @llvm.lifetime.start.p0(i64 48, ptr nonnull %2)
  call void @llvm.lifetime.start.p0(i64 48, ptr nonnull %3)
  %.fca.1.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 1
  %.fca.2.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 2
  %.fca.3.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 3
  %.fca.4.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 4
  %.fca.5.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 5
  %.fca.6.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 6
  %.fca.7.0.0.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 7, i64 0, i64 0
  %.fca.7.0.1.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 7, i64 0, i64 1
  %.fca.7.0.2.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 7, i64 0, i64 2
  %8 = call dereferenceable_or_null(8388608) ptr @malloc(i64 8388608)
  store ptr %8, ptr %3, align 8, !tbaa !8
  store i64 8, ptr %.fca.1.gep.i, align 8, !tbaa !8
  store i32 20180515, ptr %.fca.2.gep.i, align 8, !tbaa !8
  store i8 1, ptr %.fca.3.gep.i, align 4, !tbaa !8
  store i8 28, ptr %.fca.4.gep.i, align 1, !tbaa !8
  store i8 2, ptr %.fca.5.gep.i, align 2, !tbaa !8
  store i8 0, ptr %.fca.6.gep.i, align 1, !tbaa !8
  store i64 1, ptr %.fca.7.0.0.gep.i, align 8, !tbaa !8
  store i64 1048576, ptr %.fca.7.0.1.gep.i, align 8, !tbaa !8
  store i64 8, ptr %.fca.7.0.2.gep.i, align 8, !tbaa !8
  %omp_global_thread_num.i = call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %4, ptr %structArg.i, align 8
  %gep_5.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 1
  store ptr %3, ptr %gep_5.i, align 8
  %gep_6.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 2
  store ptr %2, ptr %gep_6.i, align 8
  %gep_7.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 3
  store ptr %1, ptr %gep_7.i, align 8
  %gep_8.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 4
  store ptr %6, ptr %gep_8.i, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QFPomp_subroutine..omp_par, ptr nonnull %structArg.i)
  %.fca.0.load.i = load ptr, ptr %3, align 8, !tbaa !8
  %.fca.7.0.0.load.i = load i64, ptr %.fca.7.0.0.gep.i, align 8, !tbaa !8
  %9 = sub i64 1, %.fca.7.0.0.load.i
  %10 = getelementptr double, ptr %.fca.0.load.i, i64 %9
  %11 = load double, ptr %10, align 8, !tbaa !4
  %12 = load i32, ptr %4, align 4, !tbaa !4
  %13 = sext i32 %12 to i64
  %14 = sub i64 %13, %.fca.7.0.0.load.i
  %15 = getelementptr double, ptr %.fca.0.load.i, i64 %14
  %16 = load double, ptr %15, align 8, !tbaa !4
  %17 = fadd contract double %11, %16
  call void @free(ptr %.fca.0.load.i)
  call void @llvm.lifetime.end.p0(i64 40, ptr nonnull %structArg.i)
  call void @llvm.lifetime.end.p0(i64 48, ptr nonnull %1)
  call void @llvm.lifetime.end.p0(i64 48, ptr nonnull %2)
  call void @llvm.lifetime.end.p0(i64 48, ptr nonnull %3)
  %18 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.e8a0ac9186c064ac8543d822e9060d96, i32 10)
  %19 = call i1 @_FortranAioOutputAscii(ptr %18, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %20 = load i32, ptr %4, align 4, !tbaa !4
  %21 = call i1 @_FortranAioOutputInteger32(ptr %18, i32 %20)
  %22 = call i1 @_FortranAioOutputAscii(ptr %18, ptr nonnull @_QQcl.2920697320, i64 5)
  %23 = call i1 @_FortranAioOutputReal64(ptr %18, double %17)
  %24 = call i32 @_FortranAioEndIoStatement(ptr %18)
  ret void
}
*** IR Dump After ADCEPass on _QQmain ***
define void @_QQmain() local_unnamed_addr {
  %structArg.i = alloca { ptr, ptr, ptr, ptr, ptr }, align 8
  %1 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %2 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %3 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %4 = alloca i32, align 4
  %5 = alloca double, align 8
  %6 = alloca { ptr, ptr }, align 8
  store ptr %4, ptr %6, align 8, !tbaa !4
  %7 = getelementptr inbounds { ptr, ptr }, ptr %6, i64 0, i32 1
  store ptr %5, ptr %7, align 8, !tbaa !4
  store i32 1048576, ptr %4, align 4, !tbaa !4
  call void @llvm.lifetime.start.p0(i64 40, ptr nonnull %structArg.i)
  call void @llvm.lifetime.start.p0(i64 48, ptr nonnull %1)
  call void @llvm.lifetime.start.p0(i64 48, ptr nonnull %2)
  call void @llvm.lifetime.start.p0(i64 48, ptr nonnull %3)
  %.fca.1.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 1
  %.fca.2.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 2
  %.fca.3.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 3
  %.fca.4.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 4
  %.fca.5.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 5
  %.fca.6.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 6
  %.fca.7.0.0.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 7, i64 0, i64 0
  %.fca.7.0.1.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 7, i64 0, i64 1
  %.fca.7.0.2.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 7, i64 0, i64 2
  %8 = call dereferenceable_or_null(8388608) ptr @malloc(i64 8388608)
  store ptr %8, ptr %3, align 8, !tbaa !8
  store i64 8, ptr %.fca.1.gep.i, align 8, !tbaa !8
  store i32 20180515, ptr %.fca.2.gep.i, align 8, !tbaa !8
  store i8 1, ptr %.fca.3.gep.i, align 4, !tbaa !8
  store i8 28, ptr %.fca.4.gep.i, align 1, !tbaa !8
  store i8 2, ptr %.fca.5.gep.i, align 2, !tbaa !8
  store i8 0, ptr %.fca.6.gep.i, align 1, !tbaa !8
  store i64 1, ptr %.fca.7.0.0.gep.i, align 8, !tbaa !8
  store i64 1048576, ptr %.fca.7.0.1.gep.i, align 8, !tbaa !8
  store i64 8, ptr %.fca.7.0.2.gep.i, align 8, !tbaa !8
  %omp_global_thread_num.i = call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %4, ptr %structArg.i, align 8
  %gep_5.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 1
  store ptr %3, ptr %gep_5.i, align 8
  %gep_6.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 2
  store ptr %2, ptr %gep_6.i, align 8
  %gep_7.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 3
  store ptr %1, ptr %gep_7.i, align 8
  %gep_8.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 4
  store ptr %6, ptr %gep_8.i, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QFPomp_subroutine..omp_par, ptr nonnull %structArg.i)
  %.fca.0.load.i = load ptr, ptr %3, align 8, !tbaa !8
  %.fca.7.0.0.load.i = load i64, ptr %.fca.7.0.0.gep.i, align 8, !tbaa !8
  %9 = sub i64 1, %.fca.7.0.0.load.i
  %10 = getelementptr double, ptr %.fca.0.load.i, i64 %9
  %11 = load double, ptr %10, align 8, !tbaa !4
  %12 = load i32, ptr %4, align 4, !tbaa !4
  %13 = sext i32 %12 to i64
  %14 = sub i64 %13, %.fca.7.0.0.load.i
  %15 = getelementptr double, ptr %.fca.0.load.i, i64 %14
  %16 = load double, ptr %15, align 8, !tbaa !4
  %17 = fadd contract double %11, %16
  call void @free(ptr %.fca.0.load.i)
  call void @llvm.lifetime.end.p0(i64 40, ptr nonnull %structArg.i)
  call void @llvm.lifetime.end.p0(i64 48, ptr nonnull %1)
  call void @llvm.lifetime.end.p0(i64 48, ptr nonnull %2)
  call void @llvm.lifetime.end.p0(i64 48, ptr nonnull %3)
  %18 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.e8a0ac9186c064ac8543d822e9060d96, i32 10)
  %19 = call i1 @_FortranAioOutputAscii(ptr %18, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %20 = load i32, ptr %4, align 4, !tbaa !4
  %21 = call i1 @_FortranAioOutputInteger32(ptr %18, i32 %20)
  %22 = call i1 @_FortranAioOutputAscii(ptr %18, ptr nonnull @_QQcl.2920697320, i64 5)
  %23 = call i1 @_FortranAioOutputReal64(ptr %18, double %17)
  %24 = call i32 @_FortranAioEndIoStatement(ptr %18)
  ret void
}
*** IR Dump After MemCpyOptPass on _QQmain ***
define void @_QQmain() local_unnamed_addr {
  %structArg.i = alloca { ptr, ptr, ptr, ptr, ptr }, align 8
  %1 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %2 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %3 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %4 = alloca i32, align 4
  %5 = alloca double, align 8
  %6 = alloca { ptr, ptr }, align 8
  store ptr %4, ptr %6, align 8, !tbaa !4
  %7 = getelementptr inbounds { ptr, ptr }, ptr %6, i64 0, i32 1
  store ptr %5, ptr %7, align 8, !tbaa !4
  store i32 1048576, ptr %4, align 4, !tbaa !4
  call void @llvm.lifetime.start.p0(i64 40, ptr nonnull %structArg.i)
  call void @llvm.lifetime.start.p0(i64 48, ptr nonnull %1)
  call void @llvm.lifetime.start.p0(i64 48, ptr nonnull %2)
  call void @llvm.lifetime.start.p0(i64 48, ptr nonnull %3)
  %.fca.1.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 1
  %.fca.2.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 2
  %.fca.3.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 3
  %.fca.4.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 4
  %.fca.5.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 5
  %.fca.6.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 6
  %.fca.7.0.0.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 7, i64 0, i64 0
  %.fca.7.0.1.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 7, i64 0, i64 1
  %.fca.7.0.2.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 7, i64 0, i64 2
  %8 = call dereferenceable_or_null(8388608) ptr @malloc(i64 8388608)
  store ptr %8, ptr %3, align 8, !tbaa !8
  store i64 8, ptr %.fca.1.gep.i, align 8, !tbaa !8
  store i32 20180515, ptr %.fca.2.gep.i, align 8, !tbaa !8
  store i8 1, ptr %.fca.3.gep.i, align 4, !tbaa !8
  store i8 28, ptr %.fca.4.gep.i, align 1, !tbaa !8
  store i8 2, ptr %.fca.5.gep.i, align 2, !tbaa !8
  store i8 0, ptr %.fca.6.gep.i, align 1, !tbaa !8
  store i64 1, ptr %.fca.7.0.0.gep.i, align 8, !tbaa !8
  store i64 1048576, ptr %.fca.7.0.1.gep.i, align 8, !tbaa !8
  store i64 8, ptr %.fca.7.0.2.gep.i, align 8, !tbaa !8
  %omp_global_thread_num.i = call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %4, ptr %structArg.i, align 8
  %gep_5.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 1
  store ptr %3, ptr %gep_5.i, align 8
  %gep_6.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 2
  store ptr %2, ptr %gep_6.i, align 8
  %gep_7.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 3
  store ptr %1, ptr %gep_7.i, align 8
  %gep_8.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 4
  store ptr %6, ptr %gep_8.i, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QFPomp_subroutine..omp_par, ptr nonnull %structArg.i)
  %.fca.0.load.i = load ptr, ptr %3, align 8, !tbaa !8
  %.fca.7.0.0.load.i = load i64, ptr %.fca.7.0.0.gep.i, align 8, !tbaa !8
  %9 = sub i64 1, %.fca.7.0.0.load.i
  %10 = getelementptr double, ptr %.fca.0.load.i, i64 %9
  %11 = load double, ptr %10, align 8, !tbaa !4
  %12 = load i32, ptr %4, align 4, !tbaa !4
  %13 = sext i32 %12 to i64
  %14 = sub i64 %13, %.fca.7.0.0.load.i
  %15 = getelementptr double, ptr %.fca.0.load.i, i64 %14
  %16 = load double, ptr %15, align 8, !tbaa !4
  %17 = fadd contract double %11, %16
  call void @free(ptr %.fca.0.load.i)
  call void @llvm.lifetime.end.p0(i64 40, ptr nonnull %structArg.i)
  call void @llvm.lifetime.end.p0(i64 48, ptr nonnull %1)
  call void @llvm.lifetime.end.p0(i64 48, ptr nonnull %2)
  call void @llvm.lifetime.end.p0(i64 48, ptr nonnull %3)
  %18 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.e8a0ac9186c064ac8543d822e9060d96, i32 10)
  %19 = call i1 @_FortranAioOutputAscii(ptr %18, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %20 = load i32, ptr %4, align 4, !tbaa !4
  %21 = call i1 @_FortranAioOutputInteger32(ptr %18, i32 %20)
  %22 = call i1 @_FortranAioOutputAscii(ptr %18, ptr nonnull @_QQcl.2920697320, i64 5)
  %23 = call i1 @_FortranAioOutputReal64(ptr %18, double %17)
  %24 = call i32 @_FortranAioEndIoStatement(ptr %18)
  ret void
}
*** IR Dump After DSEPass on _QQmain ***
define void @_QQmain() local_unnamed_addr {
  %structArg.i = alloca { ptr, ptr, ptr, ptr, ptr }, align 8
  %1 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %2 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %3 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %4 = alloca i32, align 4
  %5 = alloca double, align 8
  %6 = alloca { ptr, ptr }, align 8
  store ptr %4, ptr %6, align 8, !tbaa !4
  %7 = getelementptr inbounds { ptr, ptr }, ptr %6, i64 0, i32 1
  store ptr %5, ptr %7, align 8, !tbaa !4
  store i32 1048576, ptr %4, align 4, !tbaa !4
  call void @llvm.lifetime.start.p0(i64 40, ptr nonnull %structArg.i)
  call void @llvm.lifetime.start.p0(i64 48, ptr nonnull %1)
  call void @llvm.lifetime.start.p0(i64 48, ptr nonnull %2)
  call void @llvm.lifetime.start.p0(i64 48, ptr nonnull %3)
  %.fca.1.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 1
  %.fca.2.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 2
  %.fca.3.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 3
  %.fca.4.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 4
  %.fca.5.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 5
  %.fca.6.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 6
  %.fca.7.0.0.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 7, i64 0, i64 0
  %.fca.7.0.1.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 7, i64 0, i64 1
  %.fca.7.0.2.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 7, i64 0, i64 2
  %8 = call dereferenceable_or_null(8388608) ptr @malloc(i64 8388608)
  store ptr %8, ptr %3, align 8, !tbaa !8
  store i64 8, ptr %.fca.1.gep.i, align 8, !tbaa !8
  store i32 20180515, ptr %.fca.2.gep.i, align 8, !tbaa !8
  store i8 1, ptr %.fca.3.gep.i, align 4, !tbaa !8
  store i8 28, ptr %.fca.4.gep.i, align 1, !tbaa !8
  store i8 2, ptr %.fca.5.gep.i, align 2, !tbaa !8
  store i8 0, ptr %.fca.6.gep.i, align 1, !tbaa !8
  store i64 1, ptr %.fca.7.0.0.gep.i, align 8, !tbaa !8
  store i64 1048576, ptr %.fca.7.0.1.gep.i, align 8, !tbaa !8
  store i64 8, ptr %.fca.7.0.2.gep.i, align 8, !tbaa !8
  %omp_global_thread_num.i = call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %4, ptr %structArg.i, align 8
  %gep_5.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 1
  store ptr %3, ptr %gep_5.i, align 8
  %gep_6.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 2
  store ptr %2, ptr %gep_6.i, align 8
  %gep_7.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 3
  store ptr %1, ptr %gep_7.i, align 8
  %gep_8.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 4
  store ptr %6, ptr %gep_8.i, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QFPomp_subroutine..omp_par, ptr nonnull %structArg.i)
  %.fca.0.load.i = load ptr, ptr %3, align 8, !tbaa !8
  %.fca.7.0.0.load.i = load i64, ptr %.fca.7.0.0.gep.i, align 8, !tbaa !8
  %9 = sub i64 1, %.fca.7.0.0.load.i
  %10 = getelementptr double, ptr %.fca.0.load.i, i64 %9
  %11 = load double, ptr %10, align 8, !tbaa !4
  %12 = load i32, ptr %4, align 4, !tbaa !4
  %13 = sext i32 %12 to i64
  %14 = sub i64 %13, %.fca.7.0.0.load.i
  %15 = getelementptr double, ptr %.fca.0.load.i, i64 %14
  %16 = load double, ptr %15, align 8, !tbaa !4
  %17 = fadd contract double %11, %16
  call void @free(ptr %.fca.0.load.i)
  call void @llvm.lifetime.end.p0(i64 40, ptr nonnull %structArg.i)
  call void @llvm.lifetime.end.p0(i64 48, ptr nonnull %1)
  call void @llvm.lifetime.end.p0(i64 48, ptr nonnull %2)
  call void @llvm.lifetime.end.p0(i64 48, ptr nonnull %3)
  %18 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.e8a0ac9186c064ac8543d822e9060d96, i32 10)
  %19 = call i1 @_FortranAioOutputAscii(ptr %18, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %20 = load i32, ptr %4, align 4, !tbaa !4
  %21 = call i1 @_FortranAioOutputInteger32(ptr %18, i32 %20)
  %22 = call i1 @_FortranAioOutputAscii(ptr %18, ptr nonnull @_QQcl.2920697320, i64 5)
  %23 = call i1 @_FortranAioOutputReal64(ptr %18, double %17)
  %24 = call i32 @_FortranAioEndIoStatement(ptr %18)
  ret void
}
*** IR Dump After MoveAutoInitPass on _QQmain ***
define void @_QQmain() local_unnamed_addr {
  %structArg.i = alloca { ptr, ptr, ptr, ptr, ptr }, align 8
  %1 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %2 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %3 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %4 = alloca i32, align 4
  %5 = alloca double, align 8
  %6 = alloca { ptr, ptr }, align 8
  store ptr %4, ptr %6, align 8, !tbaa !4
  %7 = getelementptr inbounds { ptr, ptr }, ptr %6, i64 0, i32 1
  store ptr %5, ptr %7, align 8, !tbaa !4
  store i32 1048576, ptr %4, align 4, !tbaa !4
  call void @llvm.lifetime.start.p0(i64 40, ptr nonnull %structArg.i)
  call void @llvm.lifetime.start.p0(i64 48, ptr nonnull %1)
  call void @llvm.lifetime.start.p0(i64 48, ptr nonnull %2)
  call void @llvm.lifetime.start.p0(i64 48, ptr nonnull %3)
  %.fca.1.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 1
  %.fca.2.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 2
  %.fca.3.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 3
  %.fca.4.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 4
  %.fca.5.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 5
  %.fca.6.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 6
  %.fca.7.0.0.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 7, i64 0, i64 0
  %.fca.7.0.1.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 7, i64 0, i64 1
  %.fca.7.0.2.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 7, i64 0, i64 2
  %8 = call dereferenceable_or_null(8388608) ptr @malloc(i64 8388608)
  store ptr %8, ptr %3, align 8, !tbaa !8
  store i64 8, ptr %.fca.1.gep.i, align 8, !tbaa !8
  store i32 20180515, ptr %.fca.2.gep.i, align 8, !tbaa !8
  store i8 1, ptr %.fca.3.gep.i, align 4, !tbaa !8
  store i8 28, ptr %.fca.4.gep.i, align 1, !tbaa !8
  store i8 2, ptr %.fca.5.gep.i, align 2, !tbaa !8
  store i8 0, ptr %.fca.6.gep.i, align 1, !tbaa !8
  store i64 1, ptr %.fca.7.0.0.gep.i, align 8, !tbaa !8
  store i64 1048576, ptr %.fca.7.0.1.gep.i, align 8, !tbaa !8
  store i64 8, ptr %.fca.7.0.2.gep.i, align 8, !tbaa !8
  %omp_global_thread_num.i = call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %4, ptr %structArg.i, align 8
  %gep_5.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 1
  store ptr %3, ptr %gep_5.i, align 8
  %gep_6.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 2
  store ptr %2, ptr %gep_6.i, align 8
  %gep_7.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 3
  store ptr %1, ptr %gep_7.i, align 8
  %gep_8.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 4
  store ptr %6, ptr %gep_8.i, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QFPomp_subroutine..omp_par, ptr nonnull %structArg.i)
  %.fca.0.load.i = load ptr, ptr %3, align 8, !tbaa !8
  %.fca.7.0.0.load.i = load i64, ptr %.fca.7.0.0.gep.i, align 8, !tbaa !8
  %9 = sub i64 1, %.fca.7.0.0.load.i
  %10 = getelementptr double, ptr %.fca.0.load.i, i64 %9
  %11 = load double, ptr %10, align 8, !tbaa !4
  %12 = load i32, ptr %4, align 4, !tbaa !4
  %13 = sext i32 %12 to i64
  %14 = sub i64 %13, %.fca.7.0.0.load.i
  %15 = getelementptr double, ptr %.fca.0.load.i, i64 %14
  %16 = load double, ptr %15, align 8, !tbaa !4
  %17 = fadd contract double %11, %16
  call void @free(ptr %.fca.0.load.i)
  call void @llvm.lifetime.end.p0(i64 40, ptr nonnull %structArg.i)
  call void @llvm.lifetime.end.p0(i64 48, ptr nonnull %1)
  call void @llvm.lifetime.end.p0(i64 48, ptr nonnull %2)
  call void @llvm.lifetime.end.p0(i64 48, ptr nonnull %3)
  %18 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.e8a0ac9186c064ac8543d822e9060d96, i32 10)
  %19 = call i1 @_FortranAioOutputAscii(ptr %18, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %20 = load i32, ptr %4, align 4, !tbaa !4
  %21 = call i1 @_FortranAioOutputInteger32(ptr %18, i32 %20)
  %22 = call i1 @_FortranAioOutputAscii(ptr %18, ptr nonnull @_QQcl.2920697320, i64 5)
  %23 = call i1 @_FortranAioOutputReal64(ptr %18, double %17)
  %24 = call i32 @_FortranAioEndIoStatement(ptr %18)
  ret void
}
*** IR Dump After LoopSimplifyPass on _QQmain ***
define void @_QQmain() local_unnamed_addr {
  %structArg.i = alloca { ptr, ptr, ptr, ptr, ptr }, align 8
  %1 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %2 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %3 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %4 = alloca i32, align 4
  %5 = alloca double, align 8
  %6 = alloca { ptr, ptr }, align 8
  store ptr %4, ptr %6, align 8, !tbaa !4
  %7 = getelementptr inbounds { ptr, ptr }, ptr %6, i64 0, i32 1
  store ptr %5, ptr %7, align 8, !tbaa !4
  store i32 1048576, ptr %4, align 4, !tbaa !4
  call void @llvm.lifetime.start.p0(i64 40, ptr nonnull %structArg.i)
  call void @llvm.lifetime.start.p0(i64 48, ptr nonnull %1)
  call void @llvm.lifetime.start.p0(i64 48, ptr nonnull %2)
  call void @llvm.lifetime.start.p0(i64 48, ptr nonnull %3)
  %.fca.1.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 1
  %.fca.2.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 2
  %.fca.3.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 3
  %.fca.4.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 4
  %.fca.5.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 5
  %.fca.6.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 6
  %.fca.7.0.0.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 7, i64 0, i64 0
  %.fca.7.0.1.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 7, i64 0, i64 1
  %.fca.7.0.2.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 7, i64 0, i64 2
  %8 = call dereferenceable_or_null(8388608) ptr @malloc(i64 8388608)
  store ptr %8, ptr %3, align 8, !tbaa !8
  store i64 8, ptr %.fca.1.gep.i, align 8, !tbaa !8
  store i32 20180515, ptr %.fca.2.gep.i, align 8, !tbaa !8
  store i8 1, ptr %.fca.3.gep.i, align 4, !tbaa !8
  store i8 28, ptr %.fca.4.gep.i, align 1, !tbaa !8
  store i8 2, ptr %.fca.5.gep.i, align 2, !tbaa !8
  store i8 0, ptr %.fca.6.gep.i, align 1, !tbaa !8
  store i64 1, ptr %.fca.7.0.0.gep.i, align 8, !tbaa !8
  store i64 1048576, ptr %.fca.7.0.1.gep.i, align 8, !tbaa !8
  store i64 8, ptr %.fca.7.0.2.gep.i, align 8, !tbaa !8
  %omp_global_thread_num.i = call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %4, ptr %structArg.i, align 8
  %gep_5.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 1
  store ptr %3, ptr %gep_5.i, align 8
  %gep_6.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 2
  store ptr %2, ptr %gep_6.i, align 8
  %gep_7.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 3
  store ptr %1, ptr %gep_7.i, align 8
  %gep_8.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 4
  store ptr %6, ptr %gep_8.i, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QFPomp_subroutine..omp_par, ptr nonnull %structArg.i)
  %.fca.0.load.i = load ptr, ptr %3, align 8, !tbaa !8
  %.fca.7.0.0.load.i = load i64, ptr %.fca.7.0.0.gep.i, align 8, !tbaa !8
  %9 = sub i64 1, %.fca.7.0.0.load.i
  %10 = getelementptr double, ptr %.fca.0.load.i, i64 %9
  %11 = load double, ptr %10, align 8, !tbaa !4
  %12 = load i32, ptr %4, align 4, !tbaa !4
  %13 = sext i32 %12 to i64
  %14 = sub i64 %13, %.fca.7.0.0.load.i
  %15 = getelementptr double, ptr %.fca.0.load.i, i64 %14
  %16 = load double, ptr %15, align 8, !tbaa !4
  %17 = fadd contract double %11, %16
  call void @free(ptr %.fca.0.load.i)
  call void @llvm.lifetime.end.p0(i64 40, ptr nonnull %structArg.i)
  call void @llvm.lifetime.end.p0(i64 48, ptr nonnull %1)
  call void @llvm.lifetime.end.p0(i64 48, ptr nonnull %2)
  call void @llvm.lifetime.end.p0(i64 48, ptr nonnull %3)
  %18 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.e8a0ac9186c064ac8543d822e9060d96, i32 10)
  %19 = call i1 @_FortranAioOutputAscii(ptr %18, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %20 = load i32, ptr %4, align 4, !tbaa !4
  %21 = call i1 @_FortranAioOutputInteger32(ptr %18, i32 %20)
  %22 = call i1 @_FortranAioOutputAscii(ptr %18, ptr nonnull @_QQcl.2920697320, i64 5)
  %23 = call i1 @_FortranAioOutputReal64(ptr %18, double %17)
  %24 = call i32 @_FortranAioEndIoStatement(ptr %18)
  ret void
}
*** IR Dump After LCSSAPass on _QQmain ***
define void @_QQmain() local_unnamed_addr {
  %structArg.i = alloca { ptr, ptr, ptr, ptr, ptr }, align 8
  %1 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %2 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %3 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %4 = alloca i32, align 4
  %5 = alloca double, align 8
  %6 = alloca { ptr, ptr }, align 8
  store ptr %4, ptr %6, align 8, !tbaa !4
  %7 = getelementptr inbounds { ptr, ptr }, ptr %6, i64 0, i32 1
  store ptr %5, ptr %7, align 8, !tbaa !4
  store i32 1048576, ptr %4, align 4, !tbaa !4
  call void @llvm.lifetime.start.p0(i64 40, ptr nonnull %structArg.i)
  call void @llvm.lifetime.start.p0(i64 48, ptr nonnull %1)
  call void @llvm.lifetime.start.p0(i64 48, ptr nonnull %2)
  call void @llvm.lifetime.start.p0(i64 48, ptr nonnull %3)
  %.fca.1.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 1
  %.fca.2.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 2
  %.fca.3.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 3
  %.fca.4.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 4
  %.fca.5.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 5
  %.fca.6.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 6
  %.fca.7.0.0.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 7, i64 0, i64 0
  %.fca.7.0.1.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 7, i64 0, i64 1
  %.fca.7.0.2.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 7, i64 0, i64 2
  %8 = call dereferenceable_or_null(8388608) ptr @malloc(i64 8388608)
  store ptr %8, ptr %3, align 8, !tbaa !8
  store i64 8, ptr %.fca.1.gep.i, align 8, !tbaa !8
  store i32 20180515, ptr %.fca.2.gep.i, align 8, !tbaa !8
  store i8 1, ptr %.fca.3.gep.i, align 4, !tbaa !8
  store i8 28, ptr %.fca.4.gep.i, align 1, !tbaa !8
  store i8 2, ptr %.fca.5.gep.i, align 2, !tbaa !8
  store i8 0, ptr %.fca.6.gep.i, align 1, !tbaa !8
  store i64 1, ptr %.fca.7.0.0.gep.i, align 8, !tbaa !8
  store i64 1048576, ptr %.fca.7.0.1.gep.i, align 8, !tbaa !8
  store i64 8, ptr %.fca.7.0.2.gep.i, align 8, !tbaa !8
  %omp_global_thread_num.i = call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %4, ptr %structArg.i, align 8
  %gep_5.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 1
  store ptr %3, ptr %gep_5.i, align 8
  %gep_6.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 2
  store ptr %2, ptr %gep_6.i, align 8
  %gep_7.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 3
  store ptr %1, ptr %gep_7.i, align 8
  %gep_8.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 4
  store ptr %6, ptr %gep_8.i, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QFPomp_subroutine..omp_par, ptr nonnull %structArg.i)
  %.fca.0.load.i = load ptr, ptr %3, align 8, !tbaa !8
  %.fca.7.0.0.load.i = load i64, ptr %.fca.7.0.0.gep.i, align 8, !tbaa !8
  %9 = sub i64 1, %.fca.7.0.0.load.i
  %10 = getelementptr double, ptr %.fca.0.load.i, i64 %9
  %11 = load double, ptr %10, align 8, !tbaa !4
  %12 = load i32, ptr %4, align 4, !tbaa !4
  %13 = sext i32 %12 to i64
  %14 = sub i64 %13, %.fca.7.0.0.load.i
  %15 = getelementptr double, ptr %.fca.0.load.i, i64 %14
  %16 = load double, ptr %15, align 8, !tbaa !4
  %17 = fadd contract double %11, %16
  call void @free(ptr %.fca.0.load.i)
  call void @llvm.lifetime.end.p0(i64 40, ptr nonnull %structArg.i)
  call void @llvm.lifetime.end.p0(i64 48, ptr nonnull %1)
  call void @llvm.lifetime.end.p0(i64 48, ptr nonnull %2)
  call void @llvm.lifetime.end.p0(i64 48, ptr nonnull %3)
  %18 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.e8a0ac9186c064ac8543d822e9060d96, i32 10)
  %19 = call i1 @_FortranAioOutputAscii(ptr %18, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %20 = load i32, ptr %4, align 4, !tbaa !4
  %21 = call i1 @_FortranAioOutputInteger32(ptr %18, i32 %20)
  %22 = call i1 @_FortranAioOutputAscii(ptr %18, ptr nonnull @_QQcl.2920697320, i64 5)
  %23 = call i1 @_FortranAioOutputReal64(ptr %18, double %17)
  %24 = call i32 @_FortranAioEndIoStatement(ptr %18)
  ret void
}
*** IR Dump After CoroElidePass on _QQmain ***
define void @_QQmain() local_unnamed_addr {
  %structArg.i = alloca { ptr, ptr, ptr, ptr, ptr }, align 8
  %1 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %2 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %3 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %4 = alloca i32, align 4
  %5 = alloca double, align 8
  %6 = alloca { ptr, ptr }, align 8
  store ptr %4, ptr %6, align 8, !tbaa !4
  %7 = getelementptr inbounds { ptr, ptr }, ptr %6, i64 0, i32 1
  store ptr %5, ptr %7, align 8, !tbaa !4
  store i32 1048576, ptr %4, align 4, !tbaa !4
  call void @llvm.lifetime.start.p0(i64 40, ptr nonnull %structArg.i)
  call void @llvm.lifetime.start.p0(i64 48, ptr nonnull %1)
  call void @llvm.lifetime.start.p0(i64 48, ptr nonnull %2)
  call void @llvm.lifetime.start.p0(i64 48, ptr nonnull %3)
  %.fca.1.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 1
  %.fca.2.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 2
  %.fca.3.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 3
  %.fca.4.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 4
  %.fca.5.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 5
  %.fca.6.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 6
  %.fca.7.0.0.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 7, i64 0, i64 0
  %.fca.7.0.1.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 7, i64 0, i64 1
  %.fca.7.0.2.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 7, i64 0, i64 2
  %8 = call dereferenceable_or_null(8388608) ptr @malloc(i64 8388608)
  store ptr %8, ptr %3, align 8, !tbaa !8
  store i64 8, ptr %.fca.1.gep.i, align 8, !tbaa !8
  store i32 20180515, ptr %.fca.2.gep.i, align 8, !tbaa !8
  store i8 1, ptr %.fca.3.gep.i, align 4, !tbaa !8
  store i8 28, ptr %.fca.4.gep.i, align 1, !tbaa !8
  store i8 2, ptr %.fca.5.gep.i, align 2, !tbaa !8
  store i8 0, ptr %.fca.6.gep.i, align 1, !tbaa !8
  store i64 1, ptr %.fca.7.0.0.gep.i, align 8, !tbaa !8
  store i64 1048576, ptr %.fca.7.0.1.gep.i, align 8, !tbaa !8
  store i64 8, ptr %.fca.7.0.2.gep.i, align 8, !tbaa !8
  %omp_global_thread_num.i = call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %4, ptr %structArg.i, align 8
  %gep_5.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 1
  store ptr %3, ptr %gep_5.i, align 8
  %gep_6.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 2
  store ptr %2, ptr %gep_6.i, align 8
  %gep_7.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 3
  store ptr %1, ptr %gep_7.i, align 8
  %gep_8.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 4
  store ptr %6, ptr %gep_8.i, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QFPomp_subroutine..omp_par, ptr nonnull %structArg.i)
  %.fca.0.load.i = load ptr, ptr %3, align 8, !tbaa !8
  %.fca.7.0.0.load.i = load i64, ptr %.fca.7.0.0.gep.i, align 8, !tbaa !8
  %9 = sub i64 1, %.fca.7.0.0.load.i
  %10 = getelementptr double, ptr %.fca.0.load.i, i64 %9
  %11 = load double, ptr %10, align 8, !tbaa !4
  %12 = load i32, ptr %4, align 4, !tbaa !4
  %13 = sext i32 %12 to i64
  %14 = sub i64 %13, %.fca.7.0.0.load.i
  %15 = getelementptr double, ptr %.fca.0.load.i, i64 %14
  %16 = load double, ptr %15, align 8, !tbaa !4
  %17 = fadd contract double %11, %16
  call void @free(ptr %.fca.0.load.i)
  call void @llvm.lifetime.end.p0(i64 40, ptr nonnull %structArg.i)
  call void @llvm.lifetime.end.p0(i64 48, ptr nonnull %1)
  call void @llvm.lifetime.end.p0(i64 48, ptr nonnull %2)
  call void @llvm.lifetime.end.p0(i64 48, ptr nonnull %3)
  %18 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.e8a0ac9186c064ac8543d822e9060d96, i32 10)
  %19 = call i1 @_FortranAioOutputAscii(ptr %18, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %20 = load i32, ptr %4, align 4, !tbaa !4
  %21 = call i1 @_FortranAioOutputInteger32(ptr %18, i32 %20)
  %22 = call i1 @_FortranAioOutputAscii(ptr %18, ptr nonnull @_QQcl.2920697320, i64 5)
  %23 = call i1 @_FortranAioOutputReal64(ptr %18, double %17)
  %24 = call i32 @_FortranAioEndIoStatement(ptr %18)
  ret void
}
*** IR Dump After SimplifyCFGPass on _QQmain ***
define void @_QQmain() local_unnamed_addr {
  %structArg.i = alloca { ptr, ptr, ptr, ptr, ptr }, align 8
  %1 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %2 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %3 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %4 = alloca i32, align 4
  %5 = alloca double, align 8
  %6 = alloca { ptr, ptr }, align 8
  store ptr %4, ptr %6, align 8, !tbaa !4
  %7 = getelementptr inbounds { ptr, ptr }, ptr %6, i64 0, i32 1
  store ptr %5, ptr %7, align 8, !tbaa !4
  store i32 1048576, ptr %4, align 4, !tbaa !4
  call void @llvm.lifetime.start.p0(i64 40, ptr nonnull %structArg.i)
  call void @llvm.lifetime.start.p0(i64 48, ptr nonnull %1)
  call void @llvm.lifetime.start.p0(i64 48, ptr nonnull %2)
  call void @llvm.lifetime.start.p0(i64 48, ptr nonnull %3)
  %.fca.1.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 1
  %.fca.2.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 2
  %.fca.3.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 3
  %.fca.4.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 4
  %.fca.5.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 5
  %.fca.6.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 6
  %.fca.7.0.0.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 7, i64 0, i64 0
  %.fca.7.0.1.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 7, i64 0, i64 1
  %.fca.7.0.2.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 7, i64 0, i64 2
  %8 = call dereferenceable_or_null(8388608) ptr @malloc(i64 8388608)
  store ptr %8, ptr %3, align 8, !tbaa !8
  store i64 8, ptr %.fca.1.gep.i, align 8, !tbaa !8
  store i32 20180515, ptr %.fca.2.gep.i, align 8, !tbaa !8
  store i8 1, ptr %.fca.3.gep.i, align 4, !tbaa !8
  store i8 28, ptr %.fca.4.gep.i, align 1, !tbaa !8
  store i8 2, ptr %.fca.5.gep.i, align 2, !tbaa !8
  store i8 0, ptr %.fca.6.gep.i, align 1, !tbaa !8
  store i64 1, ptr %.fca.7.0.0.gep.i, align 8, !tbaa !8
  store i64 1048576, ptr %.fca.7.0.1.gep.i, align 8, !tbaa !8
  store i64 8, ptr %.fca.7.0.2.gep.i, align 8, !tbaa !8
  %omp_global_thread_num.i = call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %4, ptr %structArg.i, align 8
  %gep_5.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 1
  store ptr %3, ptr %gep_5.i, align 8
  %gep_6.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 2
  store ptr %2, ptr %gep_6.i, align 8
  %gep_7.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 3
  store ptr %1, ptr %gep_7.i, align 8
  %gep_8.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 4
  store ptr %6, ptr %gep_8.i, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QFPomp_subroutine..omp_par, ptr nonnull %structArg.i)
  %.fca.0.load.i = load ptr, ptr %3, align 8, !tbaa !8
  %.fca.7.0.0.load.i = load i64, ptr %.fca.7.0.0.gep.i, align 8, !tbaa !8
  %9 = sub i64 1, %.fca.7.0.0.load.i
  %10 = getelementptr double, ptr %.fca.0.load.i, i64 %9
  %11 = load double, ptr %10, align 8, !tbaa !4
  %12 = load i32, ptr %4, align 4, !tbaa !4
  %13 = sext i32 %12 to i64
  %14 = sub i64 %13, %.fca.7.0.0.load.i
  %15 = getelementptr double, ptr %.fca.0.load.i, i64 %14
  %16 = load double, ptr %15, align 8, !tbaa !4
  %17 = fadd contract double %11, %16
  call void @free(ptr %.fca.0.load.i)
  call void @llvm.lifetime.end.p0(i64 40, ptr nonnull %structArg.i)
  call void @llvm.lifetime.end.p0(i64 48, ptr nonnull %1)
  call void @llvm.lifetime.end.p0(i64 48, ptr nonnull %2)
  call void @llvm.lifetime.end.p0(i64 48, ptr nonnull %3)
  %18 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.e8a0ac9186c064ac8543d822e9060d96, i32 10)
  %19 = call i1 @_FortranAioOutputAscii(ptr %18, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %20 = load i32, ptr %4, align 4, !tbaa !4
  %21 = call i1 @_FortranAioOutputInteger32(ptr %18, i32 %20)
  %22 = call i1 @_FortranAioOutputAscii(ptr %18, ptr nonnull @_QQcl.2920697320, i64 5)
  %23 = call i1 @_FortranAioOutputReal64(ptr %18, double %17)
  %24 = call i32 @_FortranAioEndIoStatement(ptr %18)
  ret void
}
*** IR Dump After InstCombinePass on _QQmain ***
define void @_QQmain() local_unnamed_addr {
  %structArg.i = alloca { ptr, ptr, ptr, ptr, ptr }, align 8
  %1 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %2 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %3 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %4 = alloca i32, align 4
  %5 = alloca double, align 8
  %6 = alloca { ptr, ptr }, align 8
  store ptr %4, ptr %6, align 8, !tbaa !4
  %7 = getelementptr inbounds { ptr, ptr }, ptr %6, i64 0, i32 1
  store ptr %5, ptr %7, align 8, !tbaa !4
  store i32 1048576, ptr %4, align 4, !tbaa !4
  call void @llvm.lifetime.start.p0(i64 40, ptr nonnull %structArg.i)
  call void @llvm.lifetime.start.p0(i64 48, ptr nonnull %1)
  call void @llvm.lifetime.start.p0(i64 48, ptr nonnull %2)
  call void @llvm.lifetime.start.p0(i64 48, ptr nonnull %3)
  %.fca.1.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 1
  %.fca.2.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 2
  %.fca.3.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 3
  %.fca.4.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 4
  %.fca.5.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 5
  %.fca.6.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 6
  %.fca.7.0.0.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 7, i64 0, i64 0
  %.fca.7.0.1.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 7, i64 0, i64 1
  %.fca.7.0.2.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 7, i64 0, i64 2
  %8 = call dereferenceable_or_null(8388608) ptr @malloc(i64 8388608)
  store ptr %8, ptr %3, align 8, !tbaa !8
  store i64 8, ptr %.fca.1.gep.i, align 8, !tbaa !8
  store i32 20180515, ptr %.fca.2.gep.i, align 8, !tbaa !8
  store i8 1, ptr %.fca.3.gep.i, align 4, !tbaa !8
  store i8 28, ptr %.fca.4.gep.i, align 1, !tbaa !8
  store i8 2, ptr %.fca.5.gep.i, align 2, !tbaa !8
  store i8 0, ptr %.fca.6.gep.i, align 1, !tbaa !8
  store i64 1, ptr %.fca.7.0.0.gep.i, align 8, !tbaa !8
  store i64 1048576, ptr %.fca.7.0.1.gep.i, align 8, !tbaa !8
  store i64 8, ptr %.fca.7.0.2.gep.i, align 8, !tbaa !8
  %omp_global_thread_num.i = call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %4, ptr %structArg.i, align 8
  %gep_5.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 1
  store ptr %3, ptr %gep_5.i, align 8
  %gep_6.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 2
  store ptr %2, ptr %gep_6.i, align 8
  %gep_7.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 3
  store ptr %1, ptr %gep_7.i, align 8
  %gep_8.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 4
  store ptr %6, ptr %gep_8.i, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QFPomp_subroutine..omp_par, ptr nonnull %structArg.i)
  %.fca.0.load.i = load ptr, ptr %3, align 8, !tbaa !8
  %.fca.7.0.0.load.i = load i64, ptr %.fca.7.0.0.gep.i, align 8, !tbaa !8
  %9 = sub i64 1, %.fca.7.0.0.load.i
  %10 = getelementptr double, ptr %.fca.0.load.i, i64 %9
  %11 = load double, ptr %10, align 8, !tbaa !4
  %12 = load i32, ptr %4, align 4, !tbaa !4
  %13 = sext i32 %12 to i64
  %14 = sub i64 %13, %.fca.7.0.0.load.i
  %15 = getelementptr double, ptr %.fca.0.load.i, i64 %14
  %16 = load double, ptr %15, align 8, !tbaa !4
  %17 = fadd contract double %11, %16
  call void @free(ptr %.fca.0.load.i)
  call void @llvm.lifetime.end.p0(i64 40, ptr nonnull %structArg.i)
  call void @llvm.lifetime.end.p0(i64 48, ptr nonnull %1)
  call void @llvm.lifetime.end.p0(i64 48, ptr nonnull %2)
  call void @llvm.lifetime.end.p0(i64 48, ptr nonnull %3)
  %18 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.e8a0ac9186c064ac8543d822e9060d96, i32 10)
  %19 = call i1 @_FortranAioOutputAscii(ptr %18, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %20 = load i32, ptr %4, align 4, !tbaa !4
  %21 = call i1 @_FortranAioOutputInteger32(ptr %18, i32 %20)
  %22 = call i1 @_FortranAioOutputAscii(ptr %18, ptr nonnull @_QQcl.2920697320, i64 5)
  %23 = call i1 @_FortranAioOutputReal64(ptr %18, double %17)
  %24 = call i32 @_FortranAioEndIoStatement(ptr %18)
  ret void
}
*** IR Dump After PostOrderFunctionAttrsPass on (_QQmain) ***
define void @_QQmain() local_unnamed_addr {
  %structArg.i = alloca { ptr, ptr, ptr, ptr, ptr }, align 8
  %1 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %2 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %3 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %4 = alloca i32, align 4
  %5 = alloca double, align 8
  %6 = alloca { ptr, ptr }, align 8
  store ptr %4, ptr %6, align 8, !tbaa !4
  %7 = getelementptr inbounds { ptr, ptr }, ptr %6, i64 0, i32 1
  store ptr %5, ptr %7, align 8, !tbaa !4
  store i32 1048576, ptr %4, align 4, !tbaa !4
  call void @llvm.lifetime.start.p0(i64 40, ptr nonnull %structArg.i)
  call void @llvm.lifetime.start.p0(i64 48, ptr nonnull %1)
  call void @llvm.lifetime.start.p0(i64 48, ptr nonnull %2)
  call void @llvm.lifetime.start.p0(i64 48, ptr nonnull %3)
  %.fca.1.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 1
  %.fca.2.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 2
  %.fca.3.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 3
  %.fca.4.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 4
  %.fca.5.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 5
  %.fca.6.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 6
  %.fca.7.0.0.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 7, i64 0, i64 0
  %.fca.7.0.1.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 7, i64 0, i64 1
  %.fca.7.0.2.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 7, i64 0, i64 2
  %8 = call dereferenceable_or_null(8388608) ptr @malloc(i64 8388608)
  store ptr %8, ptr %3, align 8, !tbaa !8
  store i64 8, ptr %.fca.1.gep.i, align 8, !tbaa !8
  store i32 20180515, ptr %.fca.2.gep.i, align 8, !tbaa !8
  store i8 1, ptr %.fca.3.gep.i, align 4, !tbaa !8
  store i8 28, ptr %.fca.4.gep.i, align 1, !tbaa !8
  store i8 2, ptr %.fca.5.gep.i, align 2, !tbaa !8
  store i8 0, ptr %.fca.6.gep.i, align 1, !tbaa !8
  store i64 1, ptr %.fca.7.0.0.gep.i, align 8, !tbaa !8
  store i64 1048576, ptr %.fca.7.0.1.gep.i, align 8, !tbaa !8
  store i64 8, ptr %.fca.7.0.2.gep.i, align 8, !tbaa !8
  %omp_global_thread_num.i = call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %4, ptr %structArg.i, align 8
  %gep_5.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 1
  store ptr %3, ptr %gep_5.i, align 8
  %gep_6.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 2
  store ptr %2, ptr %gep_6.i, align 8
  %gep_7.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 3
  store ptr %1, ptr %gep_7.i, align 8
  %gep_8.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 4
  store ptr %6, ptr %gep_8.i, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QFPomp_subroutine..omp_par, ptr nonnull %structArg.i)
  %.fca.0.load.i = load ptr, ptr %3, align 8, !tbaa !8
  %.fca.7.0.0.load.i = load i64, ptr %.fca.7.0.0.gep.i, align 8, !tbaa !8
  %9 = sub i64 1, %.fca.7.0.0.load.i
  %10 = getelementptr double, ptr %.fca.0.load.i, i64 %9
  %11 = load double, ptr %10, align 8, !tbaa !4
  %12 = load i32, ptr %4, align 4, !tbaa !4
  %13 = sext i32 %12 to i64
  %14 = sub i64 %13, %.fca.7.0.0.load.i
  %15 = getelementptr double, ptr %.fca.0.load.i, i64 %14
  %16 = load double, ptr %15, align 8, !tbaa !4
  %17 = fadd contract double %11, %16
  call void @free(ptr %.fca.0.load.i)
  call void @llvm.lifetime.end.p0(i64 40, ptr nonnull %structArg.i)
  call void @llvm.lifetime.end.p0(i64 48, ptr nonnull %1)
  call void @llvm.lifetime.end.p0(i64 48, ptr nonnull %2)
  call void @llvm.lifetime.end.p0(i64 48, ptr nonnull %3)
  %18 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.e8a0ac9186c064ac8543d822e9060d96, i32 10)
  %19 = call i1 @_FortranAioOutputAscii(ptr %18, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %20 = load i32, ptr %4, align 4, !tbaa !4
  %21 = call i1 @_FortranAioOutputInteger32(ptr %18, i32 %20)
  %22 = call i1 @_FortranAioOutputAscii(ptr %18, ptr nonnull @_QQcl.2920697320, i64 5)
  %23 = call i1 @_FortranAioOutputReal64(ptr %18, double %17)
  %24 = call i32 @_FortranAioEndIoStatement(ptr %18)
  ret void
}
*** IR Dump After RequireAnalysisPass<llvm::ShouldNotRunFunctionPassesAnalysis, llvm::Function> on _QQmain ***
define void @_QQmain() local_unnamed_addr {
  %structArg.i = alloca { ptr, ptr, ptr, ptr, ptr }, align 8
  %1 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %2 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %3 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %4 = alloca i32, align 4
  %5 = alloca double, align 8
  %6 = alloca { ptr, ptr }, align 8
  store ptr %4, ptr %6, align 8, !tbaa !4
  %7 = getelementptr inbounds { ptr, ptr }, ptr %6, i64 0, i32 1
  store ptr %5, ptr %7, align 8, !tbaa !4
  store i32 1048576, ptr %4, align 4, !tbaa !4
  call void @llvm.lifetime.start.p0(i64 40, ptr nonnull %structArg.i)
  call void @llvm.lifetime.start.p0(i64 48, ptr nonnull %1)
  call void @llvm.lifetime.start.p0(i64 48, ptr nonnull %2)
  call void @llvm.lifetime.start.p0(i64 48, ptr nonnull %3)
  %.fca.1.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 1
  %.fca.2.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 2
  %.fca.3.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 3
  %.fca.4.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 4
  %.fca.5.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 5
  %.fca.6.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 6
  %.fca.7.0.0.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 7, i64 0, i64 0
  %.fca.7.0.1.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 7, i64 0, i64 1
  %.fca.7.0.2.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 7, i64 0, i64 2
  %8 = call dereferenceable_or_null(8388608) ptr @malloc(i64 8388608)
  store ptr %8, ptr %3, align 8, !tbaa !8
  store i64 8, ptr %.fca.1.gep.i, align 8, !tbaa !8
  store i32 20180515, ptr %.fca.2.gep.i, align 8, !tbaa !8
  store i8 1, ptr %.fca.3.gep.i, align 4, !tbaa !8
  store i8 28, ptr %.fca.4.gep.i, align 1, !tbaa !8
  store i8 2, ptr %.fca.5.gep.i, align 2, !tbaa !8
  store i8 0, ptr %.fca.6.gep.i, align 1, !tbaa !8
  store i64 1, ptr %.fca.7.0.0.gep.i, align 8, !tbaa !8
  store i64 1048576, ptr %.fca.7.0.1.gep.i, align 8, !tbaa !8
  store i64 8, ptr %.fca.7.0.2.gep.i, align 8, !tbaa !8
  %omp_global_thread_num.i = call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %4, ptr %structArg.i, align 8
  %gep_5.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 1
  store ptr %3, ptr %gep_5.i, align 8
  %gep_6.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 2
  store ptr %2, ptr %gep_6.i, align 8
  %gep_7.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 3
  store ptr %1, ptr %gep_7.i, align 8
  %gep_8.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 4
  store ptr %6, ptr %gep_8.i, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QFPomp_subroutine..omp_par, ptr nonnull %structArg.i)
  %.fca.0.load.i = load ptr, ptr %3, align 8, !tbaa !8
  %.fca.7.0.0.load.i = load i64, ptr %.fca.7.0.0.gep.i, align 8, !tbaa !8
  %9 = sub i64 1, %.fca.7.0.0.load.i
  %10 = getelementptr double, ptr %.fca.0.load.i, i64 %9
  %11 = load double, ptr %10, align 8, !tbaa !4
  %12 = load i32, ptr %4, align 4, !tbaa !4
  %13 = sext i32 %12 to i64
  %14 = sub i64 %13, %.fca.7.0.0.load.i
  %15 = getelementptr double, ptr %.fca.0.load.i, i64 %14
  %16 = load double, ptr %15, align 8, !tbaa !4
  %17 = fadd contract double %11, %16
  call void @free(ptr %.fca.0.load.i)
  call void @llvm.lifetime.end.p0(i64 40, ptr nonnull %structArg.i)
  call void @llvm.lifetime.end.p0(i64 48, ptr nonnull %1)
  call void @llvm.lifetime.end.p0(i64 48, ptr nonnull %2)
  call void @llvm.lifetime.end.p0(i64 48, ptr nonnull %3)
  %18 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.e8a0ac9186c064ac8543d822e9060d96, i32 10)
  %19 = call i1 @_FortranAioOutputAscii(ptr %18, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %20 = load i32, ptr %4, align 4, !tbaa !4
  %21 = call i1 @_FortranAioOutputInteger32(ptr %18, i32 %20)
  %22 = call i1 @_FortranAioOutputAscii(ptr %18, ptr nonnull @_QQcl.2920697320, i64 5)
  %23 = call i1 @_FortranAioOutputReal64(ptr %18, double %17)
  %24 = call i32 @_FortranAioEndIoStatement(ptr %18)
  ret void
}
*** IR Dump After CoroSplitPass on (_QQmain) ***
define void @_QQmain() local_unnamed_addr {
  %structArg.i = alloca { ptr, ptr, ptr, ptr, ptr }, align 8
  %1 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %2 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %3 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %4 = alloca i32, align 4
  %5 = alloca double, align 8
  %6 = alloca { ptr, ptr }, align 8
  store ptr %4, ptr %6, align 8, !tbaa !4
  %7 = getelementptr inbounds { ptr, ptr }, ptr %6, i64 0, i32 1
  store ptr %5, ptr %7, align 8, !tbaa !4
  store i32 1048576, ptr %4, align 4, !tbaa !4
  call void @llvm.lifetime.start.p0(i64 40, ptr nonnull %structArg.i)
  call void @llvm.lifetime.start.p0(i64 48, ptr nonnull %1)
  call void @llvm.lifetime.start.p0(i64 48, ptr nonnull %2)
  call void @llvm.lifetime.start.p0(i64 48, ptr nonnull %3)
  %.fca.1.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 1
  %.fca.2.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 2
  %.fca.3.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 3
  %.fca.4.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 4
  %.fca.5.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 5
  %.fca.6.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 6
  %.fca.7.0.0.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 7, i64 0, i64 0
  %.fca.7.0.1.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 7, i64 0, i64 1
  %.fca.7.0.2.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 7, i64 0, i64 2
  %8 = call dereferenceable_or_null(8388608) ptr @malloc(i64 8388608)
  store ptr %8, ptr %3, align 8, !tbaa !8
  store i64 8, ptr %.fca.1.gep.i, align 8, !tbaa !8
  store i32 20180515, ptr %.fca.2.gep.i, align 8, !tbaa !8
  store i8 1, ptr %.fca.3.gep.i, align 4, !tbaa !8
  store i8 28, ptr %.fca.4.gep.i, align 1, !tbaa !8
  store i8 2, ptr %.fca.5.gep.i, align 2, !tbaa !8
  store i8 0, ptr %.fca.6.gep.i, align 1, !tbaa !8
  store i64 1, ptr %.fca.7.0.0.gep.i, align 8, !tbaa !8
  store i64 1048576, ptr %.fca.7.0.1.gep.i, align 8, !tbaa !8
  store i64 8, ptr %.fca.7.0.2.gep.i, align 8, !tbaa !8
  %omp_global_thread_num.i = call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %4, ptr %structArg.i, align 8
  %gep_5.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 1
  store ptr %3, ptr %gep_5.i, align 8
  %gep_6.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 2
  store ptr %2, ptr %gep_6.i, align 8
  %gep_7.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 3
  store ptr %1, ptr %gep_7.i, align 8
  %gep_8.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 4
  store ptr %6, ptr %gep_8.i, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QFPomp_subroutine..omp_par, ptr nonnull %structArg.i)
  %.fca.0.load.i = load ptr, ptr %3, align 8, !tbaa !8
  %.fca.7.0.0.load.i = load i64, ptr %.fca.7.0.0.gep.i, align 8, !tbaa !8
  %9 = sub i64 1, %.fca.7.0.0.load.i
  %10 = getelementptr double, ptr %.fca.0.load.i, i64 %9
  %11 = load double, ptr %10, align 8, !tbaa !4
  %12 = load i32, ptr %4, align 4, !tbaa !4
  %13 = sext i32 %12 to i64
  %14 = sub i64 %13, %.fca.7.0.0.load.i
  %15 = getelementptr double, ptr %.fca.0.load.i, i64 %14
  %16 = load double, ptr %15, align 8, !tbaa !4
  %17 = fadd contract double %11, %16
  call void @free(ptr %.fca.0.load.i)
  call void @llvm.lifetime.end.p0(i64 40, ptr nonnull %structArg.i)
  call void @llvm.lifetime.end.p0(i64 48, ptr nonnull %1)
  call void @llvm.lifetime.end.p0(i64 48, ptr nonnull %2)
  call void @llvm.lifetime.end.p0(i64 48, ptr nonnull %3)
  %18 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.e8a0ac9186c064ac8543d822e9060d96, i32 10)
  %19 = call i1 @_FortranAioOutputAscii(ptr %18, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %20 = load i32, ptr %4, align 4, !tbaa !4
  %21 = call i1 @_FortranAioOutputInteger32(ptr %18, i32 %20)
  %22 = call i1 @_FortranAioOutputAscii(ptr %18, ptr nonnull @_QQcl.2920697320, i64 5)
  %23 = call i1 @_FortranAioOutputReal64(ptr %18, double %17)
  %24 = call i32 @_FortranAioEndIoStatement(ptr %18)
  ret void
}
*** IR Dump After InvalidateAnalysisPass<llvm::ShouldNotRunFunctionPassesAnalysis> on _QQmain ***
define void @_QQmain() local_unnamed_addr {
  %structArg.i = alloca { ptr, ptr, ptr, ptr, ptr }, align 8
  %1 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %2 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %3 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %4 = alloca i32, align 4
  %5 = alloca double, align 8
  %6 = alloca { ptr, ptr }, align 8
  store ptr %4, ptr %6, align 8, !tbaa !4
  %7 = getelementptr inbounds { ptr, ptr }, ptr %6, i64 0, i32 1
  store ptr %5, ptr %7, align 8, !tbaa !4
  store i32 1048576, ptr %4, align 4, !tbaa !4
  call void @llvm.lifetime.start.p0(i64 40, ptr nonnull %structArg.i)
  call void @llvm.lifetime.start.p0(i64 48, ptr nonnull %1)
  call void @llvm.lifetime.start.p0(i64 48, ptr nonnull %2)
  call void @llvm.lifetime.start.p0(i64 48, ptr nonnull %3)
  %.fca.1.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 1
  %.fca.2.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 2
  %.fca.3.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 3
  %.fca.4.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 4
  %.fca.5.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 5
  %.fca.6.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 6
  %.fca.7.0.0.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 7, i64 0, i64 0
  %.fca.7.0.1.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 7, i64 0, i64 1
  %.fca.7.0.2.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 7, i64 0, i64 2
  %8 = call dereferenceable_or_null(8388608) ptr @malloc(i64 8388608)
  store ptr %8, ptr %3, align 8, !tbaa !8
  store i64 8, ptr %.fca.1.gep.i, align 8, !tbaa !8
  store i32 20180515, ptr %.fca.2.gep.i, align 8, !tbaa !8
  store i8 1, ptr %.fca.3.gep.i, align 4, !tbaa !8
  store i8 28, ptr %.fca.4.gep.i, align 1, !tbaa !8
  store i8 2, ptr %.fca.5.gep.i, align 2, !tbaa !8
  store i8 0, ptr %.fca.6.gep.i, align 1, !tbaa !8
  store i64 1, ptr %.fca.7.0.0.gep.i, align 8, !tbaa !8
  store i64 1048576, ptr %.fca.7.0.1.gep.i, align 8, !tbaa !8
  store i64 8, ptr %.fca.7.0.2.gep.i, align 8, !tbaa !8
  %omp_global_thread_num.i = call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %4, ptr %structArg.i, align 8
  %gep_5.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 1
  store ptr %3, ptr %gep_5.i, align 8
  %gep_6.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 2
  store ptr %2, ptr %gep_6.i, align 8
  %gep_7.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 3
  store ptr %1, ptr %gep_7.i, align 8
  %gep_8.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 4
  store ptr %6, ptr %gep_8.i, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QFPomp_subroutine..omp_par, ptr nonnull %structArg.i)
  %.fca.0.load.i = load ptr, ptr %3, align 8, !tbaa !8
  %.fca.7.0.0.load.i = load i64, ptr %.fca.7.0.0.gep.i, align 8, !tbaa !8
  %9 = sub i64 1, %.fca.7.0.0.load.i
  %10 = getelementptr double, ptr %.fca.0.load.i, i64 %9
  %11 = load double, ptr %10, align 8, !tbaa !4
  %12 = load i32, ptr %4, align 4, !tbaa !4
  %13 = sext i32 %12 to i64
  %14 = sub i64 %13, %.fca.7.0.0.load.i
  %15 = getelementptr double, ptr %.fca.0.load.i, i64 %14
  %16 = load double, ptr %15, align 8, !tbaa !4
  %17 = fadd contract double %11, %16
  call void @free(ptr %.fca.0.load.i)
  call void @llvm.lifetime.end.p0(i64 40, ptr nonnull %structArg.i)
  call void @llvm.lifetime.end.p0(i64 48, ptr nonnull %1)
  call void @llvm.lifetime.end.p0(i64 48, ptr nonnull %2)
  call void @llvm.lifetime.end.p0(i64 48, ptr nonnull %3)
  %18 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.e8a0ac9186c064ac8543d822e9060d96, i32 10)
  %19 = call i1 @_FortranAioOutputAscii(ptr %18, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %20 = load i32, ptr %4, align 4, !tbaa !4
  %21 = call i1 @_FortranAioOutputInteger32(ptr %18, i32 %20)
  %22 = call i1 @_FortranAioOutputAscii(ptr %18, ptr nonnull @_QQcl.2920697320, i64 5)
  %23 = call i1 @_FortranAioOutputReal64(ptr %18, double %17)
  %24 = call i32 @_FortranAioEndIoStatement(ptr %18)
  ret void
}
*** IR Dump After InvalidateAnalysisPass<llvm::ShouldNotRunFunctionPassesAnalysis> on _QFPomp_subroutine ***
; Function Attrs: nounwind
define void @_QFPomp_subroutine(ptr %0, ptr nocapture writeonly %1, ptr nest %2) local_unnamed_addr #2 {
entry:
  %structArg = alloca { ptr, ptr, ptr, ptr, ptr }, align 8
  %3 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %4 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %5 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %.fca.1.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 1
  %.fca.2.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 2
  %.fca.3.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 3
  %.fca.4.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 4
  %.fca.5.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 5
  %.fca.6.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 6
  %.fca.7.0.0.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 0
  %.fca.7.0.1.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 1
  %.fca.7.0.2.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 2
  %6 = load i32, ptr %0, align 4, !tbaa !4
  %7 = tail call i32 @llvm.smax.i32(i32 %6, i32 0)
  %8 = zext i32 %7 to i64
  %9 = shl nuw nsw i64 %8, 3
  %10 = tail call ptr @malloc(i64 %9)
  store ptr %10, ptr %5, align 8, !tbaa !8
  store i64 8, ptr %.fca.1.gep, align 8, !tbaa !8
  store i32 20180515, ptr %.fca.2.gep, align 8, !tbaa !8
  store i8 1, ptr %.fca.3.gep, align 4, !tbaa !8
  store i8 28, ptr %.fca.4.gep, align 1, !tbaa !8
  store i8 2, ptr %.fca.5.gep, align 2, !tbaa !8
  store i8 0, ptr %.fca.6.gep, align 1, !tbaa !8
  store i64 1, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  store i64 %8, ptr %.fca.7.0.1.gep, align 8, !tbaa !8
  store i64 8, ptr %.fca.7.0.2.gep, align 8, !tbaa !8
  %omp_global_thread_num = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %0, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %5, ptr %gep_5, align 8
  %gep_6 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 2
  store ptr %4, ptr %gep_6, align 8
  %gep_7 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 3
  store ptr %3, ptr %gep_7, align 8
  %gep_8 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 4
  store ptr %2, ptr %gep_8, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QFPomp_subroutine..omp_par, ptr nonnull %structArg)
  %.fca.0.load = load ptr, ptr %5, align 8, !tbaa !8
  %.fca.7.0.0.load = load i64, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  %11 = sub i64 1, %.fca.7.0.0.load
  %12 = getelementptr double, ptr %.fca.0.load, i64 %11
  %13 = load double, ptr %12, align 8, !tbaa !4
  %14 = load i32, ptr %0, align 4, !tbaa !4
  %15 = sext i32 %14 to i64
  %16 = sub i64 %15, %.fca.7.0.0.load
  %17 = getelementptr double, ptr %.fca.0.load, i64 %16
  %18 = load double, ptr %17, align 8, !tbaa !4
  %19 = fadd contract double %13, %18
  store double %19, ptr %1, align 8, !tbaa !4
  call void @free(ptr %.fca.0.load)
  ret void
}
*** IR Dump After InvalidateAnalysisPass<llvm::ShouldNotRunFunctionPassesAnalysis> on _QFPomp_subroutine..omp_par ***
; Function Attrs: norecurse nounwind
define internal void @_QFPomp_subroutine..omp_par(ptr noalias nocapture readnone %tid.addr, ptr noalias nocapture readnone %zero.addr, ptr nocapture readonly %0) #3 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %gep_3 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 2
  %loadgep_4 = load ptr, ptr %gep_3, align 8
  %gep_5 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 3
  %loadgep_6 = load ptr, ptr %gep_5, align 8
  %gep_7 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 4
  %loadgep_8 = load ptr, ptr %gep_7, align 8
  %1 = tail call i32 @omp_get_thread_num()
  %2 = tail call i32 @omp_get_num_threads()
  %3 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %4 = sdiv i32 %3, %2
  %5 = mul i32 %4, %1
  %6 = add i32 %5, 1
  %7 = add i32 %2, -1
  %8 = icmp eq i32 %1, %7
  %9 = add i32 %6, %4
  %spec.select = select i1 %8, i32 %3, i32 %9
  %.unpack = load ptr, ptr %loadgep_2, align 8, !tbaa !8
  %.elt14 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  %.unpack15 = load i64, ptr %.elt14, align 8, !tbaa !8
  %.elt16 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  %.unpack17 = load i32, ptr %.elt16, align 8, !tbaa !8
  %.elt18 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  %.unpack19 = load i8, ptr %.elt18, align 4, !tbaa !8
  %.elt20 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  %.unpack21 = load i8, ptr %.elt20, align 1, !tbaa !8
  %.elt22 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  %.unpack23 = load i8, ptr %.elt22, align 2, !tbaa !8
  %.elt24 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  %.unpack25 = load i8, ptr %.elt24, align 1, !tbaa !8
  %.elt26 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  %.unpack27.unpack.unpack = load i64, ptr %.elt26, align 8, !tbaa !8
  %.unpack27.unpack.elt29 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  %.unpack27.unpack.unpack30 = load i64, ptr %.unpack27.unpack.elt29, align 8, !tbaa !8
  %.unpack27.unpack.elt31 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  %.unpack27.unpack.unpack32 = load i64, ptr %.unpack27.unpack.elt31, align 8, !tbaa !8
  store ptr %.unpack, ptr %loadgep_4, align 8, !tbaa !8
  %loadgep_4.repack34 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 1
  store i64 %.unpack15, ptr %loadgep_4.repack34, align 8, !tbaa !8
  %loadgep_4.repack36 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 2
  store i32 %.unpack17, ptr %loadgep_4.repack36, align 8, !tbaa !8
  %loadgep_4.repack38 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 3
  store i8 %.unpack19, ptr %loadgep_4.repack38, align 4, !tbaa !8
  %loadgep_4.repack40 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 4
  store i8 %.unpack21, ptr %loadgep_4.repack40, align 1, !tbaa !8
  %loadgep_4.repack42 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 5
  store i8 %.unpack23, ptr %loadgep_4.repack42, align 2, !tbaa !8
  %loadgep_4.repack44 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 6
  store i8 %.unpack25, ptr %loadgep_4.repack44, align 1, !tbaa !8
  %loadgep_4.repack46 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7
  store i64 %.unpack27.unpack.unpack, ptr %loadgep_4.repack46, align 8, !tbaa !8
  %loadgep_4.repack46.repack48 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack27.unpack.unpack30, ptr %loadgep_4.repack46.repack48, align 8, !tbaa !8
  %loadgep_4.repack46.repack50 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 2
  store i64 %.unpack27.unpack.unpack32, ptr %loadgep_4.repack46.repack50, align 8, !tbaa !8
  %10 = icmp eq i64 %.unpack27.unpack.unpack30, 0
  %11 = select i1 %10, i64 1, i64 %.unpack27.unpack.unpack
  store ptr %.unpack, ptr %loadgep_6, align 8, !tbaa !8
  %loadgep_6.repack52 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 1
  store i64 8, ptr %loadgep_6.repack52, align 8, !tbaa !8
  %loadgep_6.repack54 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 2
  store i32 20180515, ptr %loadgep_6.repack54, align 8, !tbaa !8
  %loadgep_6.repack56 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 3
  store i8 1, ptr %loadgep_6.repack56, align 4, !tbaa !8
  %loadgep_6.repack58 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 4
  store i8 28, ptr %loadgep_6.repack58, align 1, !tbaa !8
  %loadgep_6.repack60 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 5
  store i8 0, ptr %loadgep_6.repack60, align 2, !tbaa !8
  %loadgep_6.repack62 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 6
  store i8 0, ptr %loadgep_6.repack62, align 1, !tbaa !8
  %loadgep_6.repack64 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7
  store i64 %11, ptr %loadgep_6.repack64, align 8, !tbaa !8
  %loadgep_6.repack64.repack66 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack27.unpack.unpack30, ptr %loadgep_6.repack64.repack66, align 8, !tbaa !8
  %loadgep_6.repack64.repack68 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7, i64 0, i64 2
  store i64 8, ptr %loadgep_6.repack64.repack68, align 8, !tbaa !8
  %12 = load ptr, ptr %loadgep_8, align 8, !tbaa !4
  %13 = getelementptr { ptr, ptr }, ptr %loadgep_8, i64 0, i32 1
  %14 = load ptr, ptr %13, align 8, !tbaa !4
  %15 = sext i32 %6 to i64
  %16 = sext i32 %spec.select to i64
  %reass.sub9.i = sub nsw i64 %16, %15
  %17 = icmp sgt i64 %reass.sub9.i, -1
  br i1 %17, label %.lr.ph8.preheader.i, label %_QFPloop.exit

.lr.ph8.preheader.i:                              ; preds = %omp.par.entry
  %18 = add nuw nsw i64 %reass.sub9.i, 1
  br label %.lr.ph8.i

.lr.ph8.i:                                        ; preds = %.lr.ph8.i, %.lr.ph8.preheader.i
  %19 = phi i64 [ %29, %.lr.ph8.i ], [ %18, %.lr.ph8.preheader.i ]
  %20 = phi i32 [ %28, %.lr.ph8.i ], [ %6, %.lr.ph8.preheader.i ]
  %21 = load i32, ptr %12, align 4, !tbaa !4
  %22 = sitofp i32 %21 to float
  %23 = fdiv contract float 1.000000e+00, %22
  %24 = fpext float %23 to double
  %25 = sext i32 %20 to i64
  %26 = add nsw i64 %25, -1
  %27 = getelementptr double, ptr %.unpack, i64 %26
  store double %24, ptr %27, align 8, !tbaa !4
  store double %24, ptr %14, align 8, !tbaa !4
  %28 = add i32 %20, 1
  %29 = add nsw i64 %19, -1
  %30 = icmp ugt i64 %19, 1
  br i1 %30, label %.lr.ph8.i, label %_QFPloop.exit

_QFPloop.exit:                                    ; preds = %.lr.ph8.i, %omp.par.entry
  ret void
}
*** IR Dump After InvalidateAnalysisPass<llvm::ShouldNotRunFunctionPassesAnalysis> on _QFPloop ***
; Function Attrs: nofree norecurse nosync nounwind memory(readwrite, inaccessiblemem: none)
define void @_QFPloop(ptr nocapture readonly %0, ptr nocapture readonly %1, ptr nocapture readonly %2, ptr nest nocapture readonly %3) local_unnamed_addr #4 {
  %5 = load ptr, ptr %3, align 8, !tbaa !4
  %6 = getelementptr { ptr, ptr }, ptr %3, i64 0, i32 1
  %7 = load ptr, ptr %6, align 8, !tbaa !4
  %8 = load i32, ptr %0, align 4, !tbaa !4
  %9 = sext i32 %8 to i64
  %10 = load i32, ptr %1, align 4, !tbaa !4
  %11 = sext i32 %10 to i64
  %12 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %2, i64 0, i32 7, i64 0, i64 2
  %13 = load i64, ptr %12, align 8, !tbaa !8
  %14 = icmp eq i64 %13, 8
  br i1 %14, label %15, label %31

15:                                               ; preds = %4
  %16 = load ptr, ptr %2, align 8, !tbaa !8
  %reass.sub9 = sub nsw i64 %11, %9
  %17 = icmp sgt i64 %reass.sub9, -1
  br i1 %17, label %.lr.ph8.preheader, label %.loopexit

.lr.ph8.preheader:                                ; preds = %15
  %18 = add nuw nsw i64 %reass.sub9, 1
  br label %.lr.ph8

.lr.ph8:                                          ; preds = %.lr.ph8.preheader, %.lr.ph8
  %19 = phi i64 [ %29, %.lr.ph8 ], [ %18, %.lr.ph8.preheader ]
  %20 = phi i32 [ %28, %.lr.ph8 ], [ %8, %.lr.ph8.preheader ]
  %21 = load i32, ptr %5, align 4, !tbaa !4
  %22 = sitofp i32 %21 to float
  %23 = fdiv contract float 1.000000e+00, %22
  %24 = fpext float %23 to double
  %25 = sext i32 %20 to i64
  %26 = add nsw i64 %25, -1
  %27 = getelementptr double, ptr %16, i64 %26
  store double %24, ptr %27, align 8, !tbaa !4
  store double %24, ptr %7, align 8, !tbaa !4
  %28 = add i32 %20, 1
  %29 = add nsw i64 %19, -1
  %30 = icmp ugt i64 %19, 1
  br i1 %30, label %.lr.ph8, label %.loopexit

31:                                               ; preds = %4
  %reass.sub = sub nsw i64 %11, %9
  %32 = icmp sgt i64 %reass.sub, -1
  br i1 %32, label %.lr.ph, label %.loopexit

.lr.ph:                                           ; preds = %31
  %33 = add nuw nsw i64 %reass.sub, 1
  %34 = load ptr, ptr %2, align 8, !tbaa !8
  br label %35

35:                                               ; preds = %.lr.ph, %35
  %36 = phi i64 [ %33, %.lr.ph ], [ %47, %35 ]
  %37 = phi i32 [ %8, %.lr.ph ], [ %46, %35 ]
  %38 = load i32, ptr %5, align 4, !tbaa !4
  %39 = sitofp i32 %38 to float
  %40 = fdiv contract float 1.000000e+00, %39
  %41 = fpext float %40 to double
  %42 = sext i32 %37 to i64
  %43 = add nsw i64 %42, -1
  %44 = mul i64 %43, %13
  %45 = getelementptr i8, ptr %34, i64 %44
  store double %41, ptr %45, align 8, !tbaa !4
  store double %41, ptr %7, align 8, !tbaa !4
  %46 = add i32 %37, 1
  %47 = add nsw i64 %36, -1
  %48 = icmp ugt i64 %36, 1
  br i1 %48, label %35, label %.loopexit

.loopexit:                                        ; preds = %35, %.lr.ph8, %31, %15
  ret void
}
*** IR Dump After DeadArgumentEliminationPass on [module] ***
; ModuleID = 'FIRModule'
source_filename = "FIRModule"
target datalayout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128"
target triple = "x86_64-unknown-linux-gnu"

%struct.ident_t = type { i32, i32, i32, i32, ptr }

@_QQcl.28612C69372C612C6531332E36653229 = internal constant [16 x i8] c"(a,i7,a,e13.6e2)"
@_QQcl.e8a0ac9186c064ac8543d822e9060d96 = internal constant [59 x i8] c"/g/g92/rydahl1/flangtests/src/parallel_region_outlined.f90\00"
@_QQcl.54686520726573756C74206F6620286172722831292B61727228 = internal constant [26 x i8] c"The result of (arr(1)+arr("
@_QQcl.2920697320 = internal constant [5 x i8] c") is "
@_QQEnvironmentDefaults = local_unnamed_addr constant ptr null
@0 = private unnamed_addr constant [23 x i8] c";unknown;unknown;0;0;;\00", align 1
@1 = private unnamed_addr constant %struct.ident_t { i32 0, i32 2, i32 0, i32 22, ptr @0 }, align 8

; Function Attrs: mustprogress nofree nounwind willreturn allockind("alloc,uninitialized") allocsize(0) memory(inaccessiblemem: readwrite)
declare noalias noundef ptr @malloc(i64 noundef) local_unnamed_addr #0

; Function Attrs: mustprogress nounwind willreturn allockind("free") memory(argmem: readwrite, inaccessiblemem: readwrite)
declare void @free(ptr allocptr nocapture noundef) local_unnamed_addr #1

define void @_QQmain() local_unnamed_addr {
  %structArg.i = alloca { ptr, ptr, ptr, ptr, ptr }, align 8
  %1 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %2 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %3 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %4 = alloca i32, align 4
  %5 = alloca double, align 8
  %6 = alloca { ptr, ptr }, align 8
  store ptr %4, ptr %6, align 8, !tbaa !4
  %7 = getelementptr inbounds { ptr, ptr }, ptr %6, i64 0, i32 1
  store ptr %5, ptr %7, align 8, !tbaa !4
  store i32 1048576, ptr %4, align 4, !tbaa !4
  call void @llvm.lifetime.start.p0(i64 40, ptr nonnull %structArg.i)
  call void @llvm.lifetime.start.p0(i64 48, ptr nonnull %1)
  call void @llvm.lifetime.start.p0(i64 48, ptr nonnull %2)
  call void @llvm.lifetime.start.p0(i64 48, ptr nonnull %3)
  %.fca.1.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 1
  %.fca.2.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 2
  %.fca.3.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 3
  %.fca.4.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 4
  %.fca.5.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 5
  %.fca.6.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 6
  %.fca.7.0.0.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 7, i64 0, i64 0
  %.fca.7.0.1.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 7, i64 0, i64 1
  %.fca.7.0.2.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 7, i64 0, i64 2
  %8 = call dereferenceable_or_null(8388608) ptr @malloc(i64 8388608)
  store ptr %8, ptr %3, align 8, !tbaa !8
  store i64 8, ptr %.fca.1.gep.i, align 8, !tbaa !8
  store i32 20180515, ptr %.fca.2.gep.i, align 8, !tbaa !8
  store i8 1, ptr %.fca.3.gep.i, align 4, !tbaa !8
  store i8 28, ptr %.fca.4.gep.i, align 1, !tbaa !8
  store i8 2, ptr %.fca.5.gep.i, align 2, !tbaa !8
  store i8 0, ptr %.fca.6.gep.i, align 1, !tbaa !8
  store i64 1, ptr %.fca.7.0.0.gep.i, align 8, !tbaa !8
  store i64 1048576, ptr %.fca.7.0.1.gep.i, align 8, !tbaa !8
  store i64 8, ptr %.fca.7.0.2.gep.i, align 8, !tbaa !8
  %omp_global_thread_num.i = call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %4, ptr %structArg.i, align 8
  %gep_5.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 1
  store ptr %3, ptr %gep_5.i, align 8
  %gep_6.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 2
  store ptr %2, ptr %gep_6.i, align 8
  %gep_7.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 3
  store ptr %1, ptr %gep_7.i, align 8
  %gep_8.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 4
  store ptr %6, ptr %gep_8.i, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QFPomp_subroutine..omp_par, ptr nonnull %structArg.i)
  %.fca.0.load.i = load ptr, ptr %3, align 8, !tbaa !8
  %.fca.7.0.0.load.i = load i64, ptr %.fca.7.0.0.gep.i, align 8, !tbaa !8
  %9 = sub i64 1, %.fca.7.0.0.load.i
  %10 = getelementptr double, ptr %.fca.0.load.i, i64 %9
  %11 = load double, ptr %10, align 8, !tbaa !4
  %12 = load i32, ptr %4, align 4, !tbaa !4
  %13 = sext i32 %12 to i64
  %14 = sub i64 %13, %.fca.7.0.0.load.i
  %15 = getelementptr double, ptr %.fca.0.load.i, i64 %14
  %16 = load double, ptr %15, align 8, !tbaa !4
  %17 = fadd contract double %11, %16
  call void @free(ptr %.fca.0.load.i)
  call void @llvm.lifetime.end.p0(i64 40, ptr nonnull %structArg.i)
  call void @llvm.lifetime.end.p0(i64 48, ptr nonnull %1)
  call void @llvm.lifetime.end.p0(i64 48, ptr nonnull %2)
  call void @llvm.lifetime.end.p0(i64 48, ptr nonnull %3)
  %18 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.e8a0ac9186c064ac8543d822e9060d96, i32 10)
  %19 = call i1 @_FortranAioOutputAscii(ptr %18, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %20 = load i32, ptr %4, align 4, !tbaa !4
  %21 = call i1 @_FortranAioOutputInteger32(ptr %18, i32 %20)
  %22 = call i1 @_FortranAioOutputAscii(ptr %18, ptr nonnull @_QQcl.2920697320, i64 5)
  %23 = call i1 @_FortranAioOutputReal64(ptr %18, double %17)
  %24 = call i32 @_FortranAioEndIoStatement(ptr %18)
  ret void
}

; Function Attrs: nounwind
define void @_QFPomp_subroutine(ptr %0, ptr nocapture writeonly %1, ptr nest %2) local_unnamed_addr #2 {
entry:
  %structArg = alloca { ptr, ptr, ptr, ptr, ptr }, align 8
  %3 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %4 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %5 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %.fca.1.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 1
  %.fca.2.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 2
  %.fca.3.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 3
  %.fca.4.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 4
  %.fca.5.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 5
  %.fca.6.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 6
  %.fca.7.0.0.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 0
  %.fca.7.0.1.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 1
  %.fca.7.0.2.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 2
  %6 = load i32, ptr %0, align 4, !tbaa !4
  %7 = tail call i32 @llvm.smax.i32(i32 %6, i32 0)
  %8 = zext i32 %7 to i64
  %9 = shl nuw nsw i64 %8, 3
  %10 = tail call ptr @malloc(i64 %9)
  store ptr %10, ptr %5, align 8, !tbaa !8
  store i64 8, ptr %.fca.1.gep, align 8, !tbaa !8
  store i32 20180515, ptr %.fca.2.gep, align 8, !tbaa !8
  store i8 1, ptr %.fca.3.gep, align 4, !tbaa !8
  store i8 28, ptr %.fca.4.gep, align 1, !tbaa !8
  store i8 2, ptr %.fca.5.gep, align 2, !tbaa !8
  store i8 0, ptr %.fca.6.gep, align 1, !tbaa !8
  store i64 1, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  store i64 %8, ptr %.fca.7.0.1.gep, align 8, !tbaa !8
  store i64 8, ptr %.fca.7.0.2.gep, align 8, !tbaa !8
  %omp_global_thread_num = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %0, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %5, ptr %gep_5, align 8
  %gep_6 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 2
  store ptr %4, ptr %gep_6, align 8
  %gep_7 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 3
  store ptr %3, ptr %gep_7, align 8
  %gep_8 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 4
  store ptr %2, ptr %gep_8, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QFPomp_subroutine..omp_par, ptr nonnull %structArg)
  %.fca.0.load = load ptr, ptr %5, align 8, !tbaa !8
  %.fca.7.0.0.load = load i64, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  %11 = sub i64 1, %.fca.7.0.0.load
  %12 = getelementptr double, ptr %.fca.0.load, i64 %11
  %13 = load double, ptr %12, align 8, !tbaa !4
  %14 = load i32, ptr %0, align 4, !tbaa !4
  %15 = sext i32 %14 to i64
  %16 = sub i64 %15, %.fca.7.0.0.load
  %17 = getelementptr double, ptr %.fca.0.load, i64 %16
  %18 = load double, ptr %17, align 8, !tbaa !4
  %19 = fadd contract double %13, %18
  store double %19, ptr %1, align 8, !tbaa !4
  call void @free(ptr %.fca.0.load)
  ret void
}

; Function Attrs: norecurse nounwind
define internal void @_QFPomp_subroutine..omp_par(ptr noalias nocapture readnone %tid.addr, ptr noalias nocapture readnone %zero.addr, ptr nocapture readonly %0) #3 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %gep_3 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 2
  %loadgep_4 = load ptr, ptr %gep_3, align 8
  %gep_5 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 3
  %loadgep_6 = load ptr, ptr %gep_5, align 8
  %gep_7 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 4
  %loadgep_8 = load ptr, ptr %gep_7, align 8
  %1 = tail call i32 @omp_get_thread_num()
  %2 = tail call i32 @omp_get_num_threads()
  %3 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %4 = sdiv i32 %3, %2
  %5 = mul i32 %4, %1
  %6 = add i32 %5, 1
  %7 = add i32 %2, -1
  %8 = icmp eq i32 %1, %7
  %9 = add i32 %6, %4
  %spec.select = select i1 %8, i32 %3, i32 %9
  %.unpack = load ptr, ptr %loadgep_2, align 8, !tbaa !8
  %.elt14 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  %.unpack15 = load i64, ptr %.elt14, align 8, !tbaa !8
  %.elt16 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  %.unpack17 = load i32, ptr %.elt16, align 8, !tbaa !8
  %.elt18 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  %.unpack19 = load i8, ptr %.elt18, align 4, !tbaa !8
  %.elt20 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  %.unpack21 = load i8, ptr %.elt20, align 1, !tbaa !8
  %.elt22 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  %.unpack23 = load i8, ptr %.elt22, align 2, !tbaa !8
  %.elt24 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  %.unpack25 = load i8, ptr %.elt24, align 1, !tbaa !8
  %.elt26 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  %.unpack27.unpack.unpack = load i64, ptr %.elt26, align 8, !tbaa !8
  %.unpack27.unpack.elt29 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  %.unpack27.unpack.unpack30 = load i64, ptr %.unpack27.unpack.elt29, align 8, !tbaa !8
  %.unpack27.unpack.elt31 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  %.unpack27.unpack.unpack32 = load i64, ptr %.unpack27.unpack.elt31, align 8, !tbaa !8
  store ptr %.unpack, ptr %loadgep_4, align 8, !tbaa !8
  %loadgep_4.repack34 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 1
  store i64 %.unpack15, ptr %loadgep_4.repack34, align 8, !tbaa !8
  %loadgep_4.repack36 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 2
  store i32 %.unpack17, ptr %loadgep_4.repack36, align 8, !tbaa !8
  %loadgep_4.repack38 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 3
  store i8 %.unpack19, ptr %loadgep_4.repack38, align 4, !tbaa !8
  %loadgep_4.repack40 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 4
  store i8 %.unpack21, ptr %loadgep_4.repack40, align 1, !tbaa !8
  %loadgep_4.repack42 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 5
  store i8 %.unpack23, ptr %loadgep_4.repack42, align 2, !tbaa !8
  %loadgep_4.repack44 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 6
  store i8 %.unpack25, ptr %loadgep_4.repack44, align 1, !tbaa !8
  %loadgep_4.repack46 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7
  store i64 %.unpack27.unpack.unpack, ptr %loadgep_4.repack46, align 8, !tbaa !8
  %loadgep_4.repack46.repack48 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack27.unpack.unpack30, ptr %loadgep_4.repack46.repack48, align 8, !tbaa !8
  %loadgep_4.repack46.repack50 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 2
  store i64 %.unpack27.unpack.unpack32, ptr %loadgep_4.repack46.repack50, align 8, !tbaa !8
  %10 = icmp eq i64 %.unpack27.unpack.unpack30, 0
  %11 = select i1 %10, i64 1, i64 %.unpack27.unpack.unpack
  store ptr %.unpack, ptr %loadgep_6, align 8, !tbaa !8
  %loadgep_6.repack52 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 1
  store i64 8, ptr %loadgep_6.repack52, align 8, !tbaa !8
  %loadgep_6.repack54 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 2
  store i32 20180515, ptr %loadgep_6.repack54, align 8, !tbaa !8
  %loadgep_6.repack56 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 3
  store i8 1, ptr %loadgep_6.repack56, align 4, !tbaa !8
  %loadgep_6.repack58 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 4
  store i8 28, ptr %loadgep_6.repack58, align 1, !tbaa !8
  %loadgep_6.repack60 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 5
  store i8 0, ptr %loadgep_6.repack60, align 2, !tbaa !8
  %loadgep_6.repack62 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 6
  store i8 0, ptr %loadgep_6.repack62, align 1, !tbaa !8
  %loadgep_6.repack64 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7
  store i64 %11, ptr %loadgep_6.repack64, align 8, !tbaa !8
  %loadgep_6.repack64.repack66 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack27.unpack.unpack30, ptr %loadgep_6.repack64.repack66, align 8, !tbaa !8
  %loadgep_6.repack64.repack68 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7, i64 0, i64 2
  store i64 8, ptr %loadgep_6.repack64.repack68, align 8, !tbaa !8
  %12 = load ptr, ptr %loadgep_8, align 8, !tbaa !4
  %13 = getelementptr { ptr, ptr }, ptr %loadgep_8, i64 0, i32 1
  %14 = load ptr, ptr %13, align 8, !tbaa !4
  %15 = sext i32 %6 to i64
  %16 = sext i32 %spec.select to i64
  %reass.sub9.i = sub nsw i64 %16, %15
  %17 = icmp sgt i64 %reass.sub9.i, -1
  br i1 %17, label %.lr.ph8.preheader.i, label %_QFPloop.exit

.lr.ph8.preheader.i:                              ; preds = %omp.par.entry
  %18 = add nuw nsw i64 %reass.sub9.i, 1
  br label %.lr.ph8.i

.lr.ph8.i:                                        ; preds = %.lr.ph8.i, %.lr.ph8.preheader.i
  %19 = phi i64 [ %29, %.lr.ph8.i ], [ %18, %.lr.ph8.preheader.i ]
  %20 = phi i32 [ %28, %.lr.ph8.i ], [ %6, %.lr.ph8.preheader.i ]
  %21 = load i32, ptr %12, align 4, !tbaa !4
  %22 = sitofp i32 %21 to float
  %23 = fdiv contract float 1.000000e+00, %22
  %24 = fpext float %23 to double
  %25 = sext i32 %20 to i64
  %26 = add nsw i64 %25, -1
  %27 = getelementptr double, ptr %.unpack, i64 %26
  store double %24, ptr %27, align 8, !tbaa !4
  store double %24, ptr %14, align 8, !tbaa !4
  %28 = add i32 %20, 1
  %29 = add nsw i64 %19, -1
  %30 = icmp ugt i64 %19, 1
  br i1 %30, label %.lr.ph8.i, label %_QFPloop.exit

_QFPloop.exit:                                    ; preds = %.lr.ph8.i, %omp.par.entry
  ret void
}

; Function Attrs: nofree norecurse nosync nounwind memory(readwrite, inaccessiblemem: none)
define void @_QFPloop(ptr nocapture readonly %0, ptr nocapture readonly %1, ptr nocapture readonly %2, ptr nest nocapture readonly %3) local_unnamed_addr #4 {
  %5 = load ptr, ptr %3, align 8, !tbaa !4
  %6 = getelementptr { ptr, ptr }, ptr %3, i64 0, i32 1
  %7 = load ptr, ptr %6, align 8, !tbaa !4
  %8 = load i32, ptr %0, align 4, !tbaa !4
  %9 = sext i32 %8 to i64
  %10 = load i32, ptr %1, align 4, !tbaa !4
  %11 = sext i32 %10 to i64
  %12 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %2, i64 0, i32 7, i64 0, i64 2
  %13 = load i64, ptr %12, align 8, !tbaa !8
  %14 = icmp eq i64 %13, 8
  br i1 %14, label %15, label %31

15:                                               ; preds = %4
  %16 = load ptr, ptr %2, align 8, !tbaa !8
  %reass.sub9 = sub nsw i64 %11, %9
  %17 = icmp sgt i64 %reass.sub9, -1
  br i1 %17, label %.lr.ph8.preheader, label %.loopexit

.lr.ph8.preheader:                                ; preds = %15
  %18 = add nuw nsw i64 %reass.sub9, 1
  br label %.lr.ph8

.lr.ph8:                                          ; preds = %.lr.ph8.preheader, %.lr.ph8
  %19 = phi i64 [ %29, %.lr.ph8 ], [ %18, %.lr.ph8.preheader ]
  %20 = phi i32 [ %28, %.lr.ph8 ], [ %8, %.lr.ph8.preheader ]
  %21 = load i32, ptr %5, align 4, !tbaa !4
  %22 = sitofp i32 %21 to float
  %23 = fdiv contract float 1.000000e+00, %22
  %24 = fpext float %23 to double
  %25 = sext i32 %20 to i64
  %26 = add nsw i64 %25, -1
  %27 = getelementptr double, ptr %16, i64 %26
  store double %24, ptr %27, align 8, !tbaa !4
  store double %24, ptr %7, align 8, !tbaa !4
  %28 = add i32 %20, 1
  %29 = add nsw i64 %19, -1
  %30 = icmp ugt i64 %19, 1
  br i1 %30, label %.lr.ph8, label %.loopexit

31:                                               ; preds = %4
  %reass.sub = sub nsw i64 %11, %9
  %32 = icmp sgt i64 %reass.sub, -1
  br i1 %32, label %.lr.ph, label %.loopexit

.lr.ph:                                           ; preds = %31
  %33 = add nuw nsw i64 %reass.sub, 1
  %34 = load ptr, ptr %2, align 8, !tbaa !8
  br label %35

35:                                               ; preds = %.lr.ph, %35
  %36 = phi i64 [ %33, %.lr.ph ], [ %47, %35 ]
  %37 = phi i32 [ %8, %.lr.ph ], [ %46, %35 ]
  %38 = load i32, ptr %5, align 4, !tbaa !4
  %39 = sitofp i32 %38 to float
  %40 = fdiv contract float 1.000000e+00, %39
  %41 = fpext float %40 to double
  %42 = sext i32 %37 to i64
  %43 = add nsw i64 %42, -1
  %44 = mul i64 %43, %13
  %45 = getelementptr i8, ptr %34, i64 %44
  store double %41, ptr %45, align 8, !tbaa !4
  store double %41, ptr %7, align 8, !tbaa !4
  %46 = add i32 %37, 1
  %47 = add nsw i64 %36, -1
  %48 = icmp ugt i64 %36, 1
  br i1 %48, label %35, label %.loopexit

.loopexit:                                        ; preds = %35, %.lr.ph8, %31, %15
  ret void
}

declare ptr @_FortranAioBeginExternalFormattedOutput(ptr, i64, ptr, i32, ptr, i32) local_unnamed_addr

declare zeroext i1 @_FortranAioOutputAscii(ptr, ptr, i64) local_unnamed_addr

declare zeroext i1 @_FortranAioOutputInteger32(ptr, i32) local_unnamed_addr

declare zeroext i1 @_FortranAioOutputReal64(ptr, double) local_unnamed_addr

declare i32 @_FortranAioEndIoStatement(ptr) local_unnamed_addr

; Function Attrs: nounwind
declare i32 @omp_get_thread_num() local_unnamed_addr #2

; Function Attrs: nounwind
declare i32 @omp_get_num_threads() local_unnamed_addr #2

; Function Attrs: nounwind
declare i32 @__kmpc_global_thread_num(ptr) local_unnamed_addr #2

; Function Attrs: nounwind
declare !callback !10 void @__kmpc_fork_call(ptr, i32, ptr, ...) local_unnamed_addr #2

; Function Attrs: nocallback nofree nosync nounwind speculatable willreturn memory(none)
declare i64 @llvm.smax.i64(i64, i64) #5

; Function Attrs: nocallback nofree nosync nounwind speculatable willreturn memory(none)
declare i32 @llvm.smax.i32(i32, i32) #5

; Function Attrs: nocallback nofree nosync nounwind willreturn memory(argmem: readwrite)
declare void @llvm.lifetime.start.p0(i64 immarg, ptr nocapture) #6

; Function Attrs: nocallback nofree nosync nounwind willreturn memory(argmem: readwrite)
declare void @llvm.lifetime.end.p0(i64 immarg, ptr nocapture) #6

attributes #0 = { mustprogress nofree nounwind willreturn allockind("alloc,uninitialized") allocsize(0) memory(inaccessiblemem: readwrite) "alloc-family"="malloc" }
attributes #1 = { mustprogress nounwind willreturn allockind("free") memory(argmem: readwrite, inaccessiblemem: readwrite) "alloc-family"="malloc" }
attributes #2 = { nounwind }
attributes #3 = { norecurse nounwind }
attributes #4 = { nofree norecurse nosync nounwind memory(readwrite, inaccessiblemem: none) }
attributes #5 = { nocallback nofree nosync nounwind speculatable willreturn memory(none) }
attributes #6 = { nocallback nofree nosync nounwind willreturn memory(argmem: readwrite) }

!llvm.module.flags = !{!0, !1, !2, !3}

!0 = !{i32 2, !"Debug Info Version", i32 3}
!1 = !{i32 7, !"openmp", i32 11}
!2 = !{i32 8, !"PIC Level", i32 2}
!3 = !{i32 7, !"PIE Level", i32 2}
!4 = !{!5, !5, i64 0}
!5 = !{!"any data access", !6, i64 0}
!6 = !{!"any access", !7, i64 0}
!7 = !{!"Flang Type TBAA Root"}
!8 = !{!9, !9, i64 0}
!9 = !{!"descriptor member", !6, i64 0}
!10 = !{!11}
!11 = !{i64 2, i64 -1, i64 -1, i1 true}
*** IR Dump After CoroCleanupPass on [module] ***
; ModuleID = 'FIRModule'
source_filename = "FIRModule"
target datalayout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128"
target triple = "x86_64-unknown-linux-gnu"

%struct.ident_t = type { i32, i32, i32, i32, ptr }

@_QQcl.28612C69372C612C6531332E36653229 = internal constant [16 x i8] c"(a,i7,a,e13.6e2)"
@_QQcl.e8a0ac9186c064ac8543d822e9060d96 = internal constant [59 x i8] c"/g/g92/rydahl1/flangtests/src/parallel_region_outlined.f90\00"
@_QQcl.54686520726573756C74206F6620286172722831292B61727228 = internal constant [26 x i8] c"The result of (arr(1)+arr("
@_QQcl.2920697320 = internal constant [5 x i8] c") is "
@_QQEnvironmentDefaults = local_unnamed_addr constant ptr null
@0 = private unnamed_addr constant [23 x i8] c";unknown;unknown;0;0;;\00", align 1
@1 = private unnamed_addr constant %struct.ident_t { i32 0, i32 2, i32 0, i32 22, ptr @0 }, align 8

; Function Attrs: mustprogress nofree nounwind willreturn allockind("alloc,uninitialized") allocsize(0) memory(inaccessiblemem: readwrite)
declare noalias noundef ptr @malloc(i64 noundef) local_unnamed_addr #0

; Function Attrs: mustprogress nounwind willreturn allockind("free") memory(argmem: readwrite, inaccessiblemem: readwrite)
declare void @free(ptr allocptr nocapture noundef) local_unnamed_addr #1

define void @_QQmain() local_unnamed_addr {
  %structArg.i = alloca { ptr, ptr, ptr, ptr, ptr }, align 8
  %1 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %2 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %3 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %4 = alloca i32, align 4
  %5 = alloca double, align 8
  %6 = alloca { ptr, ptr }, align 8
  store ptr %4, ptr %6, align 8, !tbaa !4
  %7 = getelementptr inbounds { ptr, ptr }, ptr %6, i64 0, i32 1
  store ptr %5, ptr %7, align 8, !tbaa !4
  store i32 1048576, ptr %4, align 4, !tbaa !4
  call void @llvm.lifetime.start.p0(i64 40, ptr nonnull %structArg.i)
  call void @llvm.lifetime.start.p0(i64 48, ptr nonnull %1)
  call void @llvm.lifetime.start.p0(i64 48, ptr nonnull %2)
  call void @llvm.lifetime.start.p0(i64 48, ptr nonnull %3)
  %.fca.1.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 1
  %.fca.2.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 2
  %.fca.3.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 3
  %.fca.4.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 4
  %.fca.5.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 5
  %.fca.6.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 6
  %.fca.7.0.0.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 7, i64 0, i64 0
  %.fca.7.0.1.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 7, i64 0, i64 1
  %.fca.7.0.2.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 7, i64 0, i64 2
  %8 = call dereferenceable_or_null(8388608) ptr @malloc(i64 8388608)
  store ptr %8, ptr %3, align 8, !tbaa !8
  store i64 8, ptr %.fca.1.gep.i, align 8, !tbaa !8
  store i32 20180515, ptr %.fca.2.gep.i, align 8, !tbaa !8
  store i8 1, ptr %.fca.3.gep.i, align 4, !tbaa !8
  store i8 28, ptr %.fca.4.gep.i, align 1, !tbaa !8
  store i8 2, ptr %.fca.5.gep.i, align 2, !tbaa !8
  store i8 0, ptr %.fca.6.gep.i, align 1, !tbaa !8
  store i64 1, ptr %.fca.7.0.0.gep.i, align 8, !tbaa !8
  store i64 1048576, ptr %.fca.7.0.1.gep.i, align 8, !tbaa !8
  store i64 8, ptr %.fca.7.0.2.gep.i, align 8, !tbaa !8
  %omp_global_thread_num.i = call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %4, ptr %structArg.i, align 8
  %gep_5.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 1
  store ptr %3, ptr %gep_5.i, align 8
  %gep_6.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 2
  store ptr %2, ptr %gep_6.i, align 8
  %gep_7.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 3
  store ptr %1, ptr %gep_7.i, align 8
  %gep_8.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 4
  store ptr %6, ptr %gep_8.i, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QFPomp_subroutine..omp_par, ptr nonnull %structArg.i)
  %.fca.0.load.i = load ptr, ptr %3, align 8, !tbaa !8
  %.fca.7.0.0.load.i = load i64, ptr %.fca.7.0.0.gep.i, align 8, !tbaa !8
  %9 = sub i64 1, %.fca.7.0.0.load.i
  %10 = getelementptr double, ptr %.fca.0.load.i, i64 %9
  %11 = load double, ptr %10, align 8, !tbaa !4
  %12 = load i32, ptr %4, align 4, !tbaa !4
  %13 = sext i32 %12 to i64
  %14 = sub i64 %13, %.fca.7.0.0.load.i
  %15 = getelementptr double, ptr %.fca.0.load.i, i64 %14
  %16 = load double, ptr %15, align 8, !tbaa !4
  %17 = fadd contract double %11, %16
  call void @free(ptr %.fca.0.load.i)
  call void @llvm.lifetime.end.p0(i64 40, ptr nonnull %structArg.i)
  call void @llvm.lifetime.end.p0(i64 48, ptr nonnull %1)
  call void @llvm.lifetime.end.p0(i64 48, ptr nonnull %2)
  call void @llvm.lifetime.end.p0(i64 48, ptr nonnull %3)
  %18 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.e8a0ac9186c064ac8543d822e9060d96, i32 10)
  %19 = call i1 @_FortranAioOutputAscii(ptr %18, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %20 = load i32, ptr %4, align 4, !tbaa !4
  %21 = call i1 @_FortranAioOutputInteger32(ptr %18, i32 %20)
  %22 = call i1 @_FortranAioOutputAscii(ptr %18, ptr nonnull @_QQcl.2920697320, i64 5)
  %23 = call i1 @_FortranAioOutputReal64(ptr %18, double %17)
  %24 = call i32 @_FortranAioEndIoStatement(ptr %18)
  ret void
}

; Function Attrs: nounwind
define void @_QFPomp_subroutine(ptr %0, ptr nocapture writeonly %1, ptr nest %2) local_unnamed_addr #2 {
entry:
  %structArg = alloca { ptr, ptr, ptr, ptr, ptr }, align 8
  %3 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %4 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %5 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %.fca.1.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 1
  %.fca.2.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 2
  %.fca.3.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 3
  %.fca.4.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 4
  %.fca.5.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 5
  %.fca.6.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 6
  %.fca.7.0.0.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 0
  %.fca.7.0.1.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 1
  %.fca.7.0.2.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 2
  %6 = load i32, ptr %0, align 4, !tbaa !4
  %7 = tail call i32 @llvm.smax.i32(i32 %6, i32 0)
  %8 = zext i32 %7 to i64
  %9 = shl nuw nsw i64 %8, 3
  %10 = tail call ptr @malloc(i64 %9)
  store ptr %10, ptr %5, align 8, !tbaa !8
  store i64 8, ptr %.fca.1.gep, align 8, !tbaa !8
  store i32 20180515, ptr %.fca.2.gep, align 8, !tbaa !8
  store i8 1, ptr %.fca.3.gep, align 4, !tbaa !8
  store i8 28, ptr %.fca.4.gep, align 1, !tbaa !8
  store i8 2, ptr %.fca.5.gep, align 2, !tbaa !8
  store i8 0, ptr %.fca.6.gep, align 1, !tbaa !8
  store i64 1, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  store i64 %8, ptr %.fca.7.0.1.gep, align 8, !tbaa !8
  store i64 8, ptr %.fca.7.0.2.gep, align 8, !tbaa !8
  %omp_global_thread_num = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %0, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %5, ptr %gep_5, align 8
  %gep_6 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 2
  store ptr %4, ptr %gep_6, align 8
  %gep_7 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 3
  store ptr %3, ptr %gep_7, align 8
  %gep_8 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 4
  store ptr %2, ptr %gep_8, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QFPomp_subroutine..omp_par, ptr nonnull %structArg)
  %.fca.0.load = load ptr, ptr %5, align 8, !tbaa !8
  %.fca.7.0.0.load = load i64, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  %11 = sub i64 1, %.fca.7.0.0.load
  %12 = getelementptr double, ptr %.fca.0.load, i64 %11
  %13 = load double, ptr %12, align 8, !tbaa !4
  %14 = load i32, ptr %0, align 4, !tbaa !4
  %15 = sext i32 %14 to i64
  %16 = sub i64 %15, %.fca.7.0.0.load
  %17 = getelementptr double, ptr %.fca.0.load, i64 %16
  %18 = load double, ptr %17, align 8, !tbaa !4
  %19 = fadd contract double %13, %18
  store double %19, ptr %1, align 8, !tbaa !4
  call void @free(ptr %.fca.0.load)
  ret void
}

; Function Attrs: norecurse nounwind
define internal void @_QFPomp_subroutine..omp_par(ptr noalias nocapture readnone %tid.addr, ptr noalias nocapture readnone %zero.addr, ptr nocapture readonly %0) #3 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %gep_3 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 2
  %loadgep_4 = load ptr, ptr %gep_3, align 8
  %gep_5 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 3
  %loadgep_6 = load ptr, ptr %gep_5, align 8
  %gep_7 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 4
  %loadgep_8 = load ptr, ptr %gep_7, align 8
  %1 = tail call i32 @omp_get_thread_num()
  %2 = tail call i32 @omp_get_num_threads()
  %3 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %4 = sdiv i32 %3, %2
  %5 = mul i32 %4, %1
  %6 = add i32 %5, 1
  %7 = add i32 %2, -1
  %8 = icmp eq i32 %1, %7
  %9 = add i32 %6, %4
  %spec.select = select i1 %8, i32 %3, i32 %9
  %.unpack = load ptr, ptr %loadgep_2, align 8, !tbaa !8
  %.elt14 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  %.unpack15 = load i64, ptr %.elt14, align 8, !tbaa !8
  %.elt16 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  %.unpack17 = load i32, ptr %.elt16, align 8, !tbaa !8
  %.elt18 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  %.unpack19 = load i8, ptr %.elt18, align 4, !tbaa !8
  %.elt20 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  %.unpack21 = load i8, ptr %.elt20, align 1, !tbaa !8
  %.elt22 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  %.unpack23 = load i8, ptr %.elt22, align 2, !tbaa !8
  %.elt24 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  %.unpack25 = load i8, ptr %.elt24, align 1, !tbaa !8
  %.elt26 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  %.unpack27.unpack.unpack = load i64, ptr %.elt26, align 8, !tbaa !8
  %.unpack27.unpack.elt29 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  %.unpack27.unpack.unpack30 = load i64, ptr %.unpack27.unpack.elt29, align 8, !tbaa !8
  %.unpack27.unpack.elt31 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  %.unpack27.unpack.unpack32 = load i64, ptr %.unpack27.unpack.elt31, align 8, !tbaa !8
  store ptr %.unpack, ptr %loadgep_4, align 8, !tbaa !8
  %loadgep_4.repack34 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 1
  store i64 %.unpack15, ptr %loadgep_4.repack34, align 8, !tbaa !8
  %loadgep_4.repack36 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 2
  store i32 %.unpack17, ptr %loadgep_4.repack36, align 8, !tbaa !8
  %loadgep_4.repack38 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 3
  store i8 %.unpack19, ptr %loadgep_4.repack38, align 4, !tbaa !8
  %loadgep_4.repack40 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 4
  store i8 %.unpack21, ptr %loadgep_4.repack40, align 1, !tbaa !8
  %loadgep_4.repack42 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 5
  store i8 %.unpack23, ptr %loadgep_4.repack42, align 2, !tbaa !8
  %loadgep_4.repack44 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 6
  store i8 %.unpack25, ptr %loadgep_4.repack44, align 1, !tbaa !8
  %loadgep_4.repack46 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7
  store i64 %.unpack27.unpack.unpack, ptr %loadgep_4.repack46, align 8, !tbaa !8
  %loadgep_4.repack46.repack48 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack27.unpack.unpack30, ptr %loadgep_4.repack46.repack48, align 8, !tbaa !8
  %loadgep_4.repack46.repack50 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 2
  store i64 %.unpack27.unpack.unpack32, ptr %loadgep_4.repack46.repack50, align 8, !tbaa !8
  %10 = icmp eq i64 %.unpack27.unpack.unpack30, 0
  %11 = select i1 %10, i64 1, i64 %.unpack27.unpack.unpack
  store ptr %.unpack, ptr %loadgep_6, align 8, !tbaa !8
  %loadgep_6.repack52 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 1
  store i64 8, ptr %loadgep_6.repack52, align 8, !tbaa !8
  %loadgep_6.repack54 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 2
  store i32 20180515, ptr %loadgep_6.repack54, align 8, !tbaa !8
  %loadgep_6.repack56 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 3
  store i8 1, ptr %loadgep_6.repack56, align 4, !tbaa !8
  %loadgep_6.repack58 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 4
  store i8 28, ptr %loadgep_6.repack58, align 1, !tbaa !8
  %loadgep_6.repack60 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 5
  store i8 0, ptr %loadgep_6.repack60, align 2, !tbaa !8
  %loadgep_6.repack62 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 6
  store i8 0, ptr %loadgep_6.repack62, align 1, !tbaa !8
  %loadgep_6.repack64 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7
  store i64 %11, ptr %loadgep_6.repack64, align 8, !tbaa !8
  %loadgep_6.repack64.repack66 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack27.unpack.unpack30, ptr %loadgep_6.repack64.repack66, align 8, !tbaa !8
  %loadgep_6.repack64.repack68 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7, i64 0, i64 2
  store i64 8, ptr %loadgep_6.repack64.repack68, align 8, !tbaa !8
  %12 = load ptr, ptr %loadgep_8, align 8, !tbaa !4
  %13 = getelementptr { ptr, ptr }, ptr %loadgep_8, i64 0, i32 1
  %14 = load ptr, ptr %13, align 8, !tbaa !4
  %15 = sext i32 %6 to i64
  %16 = sext i32 %spec.select to i64
  %reass.sub9.i = sub nsw i64 %16, %15
  %17 = icmp sgt i64 %reass.sub9.i, -1
  br i1 %17, label %.lr.ph8.preheader.i, label %_QFPloop.exit

.lr.ph8.preheader.i:                              ; preds = %omp.par.entry
  %18 = add nuw nsw i64 %reass.sub9.i, 1
  br label %.lr.ph8.i

.lr.ph8.i:                                        ; preds = %.lr.ph8.i, %.lr.ph8.preheader.i
  %19 = phi i64 [ %29, %.lr.ph8.i ], [ %18, %.lr.ph8.preheader.i ]
  %20 = phi i32 [ %28, %.lr.ph8.i ], [ %6, %.lr.ph8.preheader.i ]
  %21 = load i32, ptr %12, align 4, !tbaa !4
  %22 = sitofp i32 %21 to float
  %23 = fdiv contract float 1.000000e+00, %22
  %24 = fpext float %23 to double
  %25 = sext i32 %20 to i64
  %26 = add nsw i64 %25, -1
  %27 = getelementptr double, ptr %.unpack, i64 %26
  store double %24, ptr %27, align 8, !tbaa !4
  store double %24, ptr %14, align 8, !tbaa !4
  %28 = add i32 %20, 1
  %29 = add nsw i64 %19, -1
  %30 = icmp ugt i64 %19, 1
  br i1 %30, label %.lr.ph8.i, label %_QFPloop.exit

_QFPloop.exit:                                    ; preds = %.lr.ph8.i, %omp.par.entry
  ret void
}

; Function Attrs: nofree norecurse nosync nounwind memory(readwrite, inaccessiblemem: none)
define void @_QFPloop(ptr nocapture readonly %0, ptr nocapture readonly %1, ptr nocapture readonly %2, ptr nest nocapture readonly %3) local_unnamed_addr #4 {
  %5 = load ptr, ptr %3, align 8, !tbaa !4
  %6 = getelementptr { ptr, ptr }, ptr %3, i64 0, i32 1
  %7 = load ptr, ptr %6, align 8, !tbaa !4
  %8 = load i32, ptr %0, align 4, !tbaa !4
  %9 = sext i32 %8 to i64
  %10 = load i32, ptr %1, align 4, !tbaa !4
  %11 = sext i32 %10 to i64
  %12 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %2, i64 0, i32 7, i64 0, i64 2
  %13 = load i64, ptr %12, align 8, !tbaa !8
  %14 = icmp eq i64 %13, 8
  br i1 %14, label %15, label %31

15:                                               ; preds = %4
  %16 = load ptr, ptr %2, align 8, !tbaa !8
  %reass.sub9 = sub nsw i64 %11, %9
  %17 = icmp sgt i64 %reass.sub9, -1
  br i1 %17, label %.lr.ph8.preheader, label %.loopexit

.lr.ph8.preheader:                                ; preds = %15
  %18 = add nuw nsw i64 %reass.sub9, 1
  br label %.lr.ph8

.lr.ph8:                                          ; preds = %.lr.ph8.preheader, %.lr.ph8
  %19 = phi i64 [ %29, %.lr.ph8 ], [ %18, %.lr.ph8.preheader ]
  %20 = phi i32 [ %28, %.lr.ph8 ], [ %8, %.lr.ph8.preheader ]
  %21 = load i32, ptr %5, align 4, !tbaa !4
  %22 = sitofp i32 %21 to float
  %23 = fdiv contract float 1.000000e+00, %22
  %24 = fpext float %23 to double
  %25 = sext i32 %20 to i64
  %26 = add nsw i64 %25, -1
  %27 = getelementptr double, ptr %16, i64 %26
  store double %24, ptr %27, align 8, !tbaa !4
  store double %24, ptr %7, align 8, !tbaa !4
  %28 = add i32 %20, 1
  %29 = add nsw i64 %19, -1
  %30 = icmp ugt i64 %19, 1
  br i1 %30, label %.lr.ph8, label %.loopexit

31:                                               ; preds = %4
  %reass.sub = sub nsw i64 %11, %9
  %32 = icmp sgt i64 %reass.sub, -1
  br i1 %32, label %.lr.ph, label %.loopexit

.lr.ph:                                           ; preds = %31
  %33 = add nuw nsw i64 %reass.sub, 1
  %34 = load ptr, ptr %2, align 8, !tbaa !8
  br label %35

35:                                               ; preds = %.lr.ph, %35
  %36 = phi i64 [ %33, %.lr.ph ], [ %47, %35 ]
  %37 = phi i32 [ %8, %.lr.ph ], [ %46, %35 ]
  %38 = load i32, ptr %5, align 4, !tbaa !4
  %39 = sitofp i32 %38 to float
  %40 = fdiv contract float 1.000000e+00, %39
  %41 = fpext float %40 to double
  %42 = sext i32 %37 to i64
  %43 = add nsw i64 %42, -1
  %44 = mul i64 %43, %13
  %45 = getelementptr i8, ptr %34, i64 %44
  store double %41, ptr %45, align 8, !tbaa !4
  store double %41, ptr %7, align 8, !tbaa !4
  %46 = add i32 %37, 1
  %47 = add nsw i64 %36, -1
  %48 = icmp ugt i64 %36, 1
  br i1 %48, label %35, label %.loopexit

.loopexit:                                        ; preds = %35, %.lr.ph8, %31, %15
  ret void
}

declare ptr @_FortranAioBeginExternalFormattedOutput(ptr, i64, ptr, i32, ptr, i32) local_unnamed_addr

declare zeroext i1 @_FortranAioOutputAscii(ptr, ptr, i64) local_unnamed_addr

declare zeroext i1 @_FortranAioOutputInteger32(ptr, i32) local_unnamed_addr

declare zeroext i1 @_FortranAioOutputReal64(ptr, double) local_unnamed_addr

declare i32 @_FortranAioEndIoStatement(ptr) local_unnamed_addr

; Function Attrs: nounwind
declare i32 @omp_get_thread_num() local_unnamed_addr #2

; Function Attrs: nounwind
declare i32 @omp_get_num_threads() local_unnamed_addr #2

; Function Attrs: nounwind
declare i32 @__kmpc_global_thread_num(ptr) local_unnamed_addr #2

; Function Attrs: nounwind
declare !callback !10 void @__kmpc_fork_call(ptr, i32, ptr, ...) local_unnamed_addr #2

; Function Attrs: nocallback nofree nosync nounwind speculatable willreturn memory(none)
declare i64 @llvm.smax.i64(i64, i64) #5

; Function Attrs: nocallback nofree nosync nounwind speculatable willreturn memory(none)
declare i32 @llvm.smax.i32(i32, i32) #5

; Function Attrs: nocallback nofree nosync nounwind willreturn memory(argmem: readwrite)
declare void @llvm.lifetime.start.p0(i64 immarg, ptr nocapture) #6

; Function Attrs: nocallback nofree nosync nounwind willreturn memory(argmem: readwrite)
declare void @llvm.lifetime.end.p0(i64 immarg, ptr nocapture) #6

attributes #0 = { mustprogress nofree nounwind willreturn allockind("alloc,uninitialized") allocsize(0) memory(inaccessiblemem: readwrite) "alloc-family"="malloc" }
attributes #1 = { mustprogress nounwind willreturn allockind("free") memory(argmem: readwrite, inaccessiblemem: readwrite) "alloc-family"="malloc" }
attributes #2 = { nounwind }
attributes #3 = { norecurse nounwind }
attributes #4 = { nofree norecurse nosync nounwind memory(readwrite, inaccessiblemem: none) }
attributes #5 = { nocallback nofree nosync nounwind speculatable willreturn memory(none) }
attributes #6 = { nocallback nofree nosync nounwind willreturn memory(argmem: readwrite) }

!llvm.module.flags = !{!0, !1, !2, !3}

!0 = !{i32 2, !"Debug Info Version", i32 3}
!1 = !{i32 7, !"openmp", i32 11}
!2 = !{i32 8, !"PIC Level", i32 2}
!3 = !{i32 7, !"PIE Level", i32 2}
!4 = !{!5, !5, i64 0}
!5 = !{!"any data access", !6, i64 0}
!6 = !{!"any access", !7, i64 0}
!7 = !{!"Flang Type TBAA Root"}
!8 = !{!9, !9, i64 0}
!9 = !{!"descriptor member", !6, i64 0}
!10 = !{!11}
!11 = !{i64 2, i64 -1, i64 -1, i1 true}
*** IR Dump After GlobalOptPass on [module] ***
; ModuleID = 'FIRModule'
source_filename = "FIRModule"
target datalayout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128"
target triple = "x86_64-unknown-linux-gnu"

%struct.ident_t = type { i32, i32, i32, i32, ptr }

@_QQcl.28612C69372C612C6531332E36653229 = internal constant [16 x i8] c"(a,i7,a,e13.6e2)"
@_QQcl.e8a0ac9186c064ac8543d822e9060d96 = internal constant [59 x i8] c"/g/g92/rydahl1/flangtests/src/parallel_region_outlined.f90\00"
@_QQcl.54686520726573756C74206F6620286172722831292B61727228 = internal constant [26 x i8] c"The result of (arr(1)+arr("
@_QQcl.2920697320 = internal constant [5 x i8] c") is "
@_QQEnvironmentDefaults = local_unnamed_addr constant ptr null
@0 = private unnamed_addr constant [23 x i8] c";unknown;unknown;0;0;;\00", align 1
@1 = private unnamed_addr constant %struct.ident_t { i32 0, i32 2, i32 0, i32 22, ptr @0 }, align 8

; Function Attrs: mustprogress nofree nounwind willreturn allockind("alloc,uninitialized") allocsize(0) memory(inaccessiblemem: readwrite)
declare noalias noundef ptr @malloc(i64 noundef) local_unnamed_addr #0

; Function Attrs: mustprogress nounwind willreturn allockind("free") memory(argmem: readwrite, inaccessiblemem: readwrite)
declare void @free(ptr allocptr nocapture noundef) local_unnamed_addr #1

define void @_QQmain() local_unnamed_addr {
  %structArg.i = alloca { ptr, ptr, ptr, ptr, ptr }, align 8
  %1 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %2 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %3 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %4 = alloca i32, align 4
  %5 = alloca double, align 8
  %6 = alloca { ptr, ptr }, align 8
  store ptr %4, ptr %6, align 8, !tbaa !4
  %7 = getelementptr inbounds { ptr, ptr }, ptr %6, i64 0, i32 1
  store ptr %5, ptr %7, align 8, !tbaa !4
  store i32 1048576, ptr %4, align 4, !tbaa !4
  call void @llvm.lifetime.start.p0(i64 40, ptr nonnull %structArg.i)
  call void @llvm.lifetime.start.p0(i64 48, ptr nonnull %1)
  call void @llvm.lifetime.start.p0(i64 48, ptr nonnull %2)
  call void @llvm.lifetime.start.p0(i64 48, ptr nonnull %3)
  %.fca.1.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 1
  %.fca.2.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 2
  %.fca.3.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 3
  %.fca.4.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 4
  %.fca.5.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 5
  %.fca.6.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 6
  %.fca.7.0.0.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 7, i64 0, i64 0
  %.fca.7.0.1.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 7, i64 0, i64 1
  %.fca.7.0.2.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 7, i64 0, i64 2
  %8 = call dereferenceable_or_null(8388608) ptr @malloc(i64 8388608)
  store ptr %8, ptr %3, align 8, !tbaa !8
  store i64 8, ptr %.fca.1.gep.i, align 8, !tbaa !8
  store i32 20180515, ptr %.fca.2.gep.i, align 8, !tbaa !8
  store i8 1, ptr %.fca.3.gep.i, align 4, !tbaa !8
  store i8 28, ptr %.fca.4.gep.i, align 1, !tbaa !8
  store i8 2, ptr %.fca.5.gep.i, align 2, !tbaa !8
  store i8 0, ptr %.fca.6.gep.i, align 1, !tbaa !8
  store i64 1, ptr %.fca.7.0.0.gep.i, align 8, !tbaa !8
  store i64 1048576, ptr %.fca.7.0.1.gep.i, align 8, !tbaa !8
  store i64 8, ptr %.fca.7.0.2.gep.i, align 8, !tbaa !8
  %omp_global_thread_num.i = call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %4, ptr %structArg.i, align 8
  %gep_5.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 1
  store ptr %3, ptr %gep_5.i, align 8
  %gep_6.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 2
  store ptr %2, ptr %gep_6.i, align 8
  %gep_7.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 3
  store ptr %1, ptr %gep_7.i, align 8
  %gep_8.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 4
  store ptr %6, ptr %gep_8.i, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QFPomp_subroutine..omp_par, ptr nonnull %structArg.i)
  %.fca.0.load.i = load ptr, ptr %3, align 8, !tbaa !8
  %.fca.7.0.0.load.i = load i64, ptr %.fca.7.0.0.gep.i, align 8, !tbaa !8
  %9 = sub i64 1, %.fca.7.0.0.load.i
  %10 = getelementptr double, ptr %.fca.0.load.i, i64 %9
  %11 = load double, ptr %10, align 8, !tbaa !4
  %12 = load i32, ptr %4, align 4, !tbaa !4
  %13 = sext i32 %12 to i64
  %14 = sub i64 %13, %.fca.7.0.0.load.i
  %15 = getelementptr double, ptr %.fca.0.load.i, i64 %14
  %16 = load double, ptr %15, align 8, !tbaa !4
  %17 = fadd contract double %11, %16
  call void @free(ptr %.fca.0.load.i)
  call void @llvm.lifetime.end.p0(i64 40, ptr nonnull %structArg.i)
  call void @llvm.lifetime.end.p0(i64 48, ptr nonnull %1)
  call void @llvm.lifetime.end.p0(i64 48, ptr nonnull %2)
  call void @llvm.lifetime.end.p0(i64 48, ptr nonnull %3)
  %18 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.e8a0ac9186c064ac8543d822e9060d96, i32 10)
  %19 = call i1 @_FortranAioOutputAscii(ptr %18, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %20 = load i32, ptr %4, align 4, !tbaa !4
  %21 = call i1 @_FortranAioOutputInteger32(ptr %18, i32 %20)
  %22 = call i1 @_FortranAioOutputAscii(ptr %18, ptr nonnull @_QQcl.2920697320, i64 5)
  %23 = call i1 @_FortranAioOutputReal64(ptr %18, double %17)
  %24 = call i32 @_FortranAioEndIoStatement(ptr %18)
  ret void
}

; Function Attrs: nounwind
define void @_QFPomp_subroutine(ptr %0, ptr nocapture writeonly %1, ptr nest %2) local_unnamed_addr #2 {
entry:
  %structArg = alloca { ptr, ptr, ptr, ptr, ptr }, align 8
  %3 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %4 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %5 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %.fca.1.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 1
  %.fca.2.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 2
  %.fca.3.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 3
  %.fca.4.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 4
  %.fca.5.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 5
  %.fca.6.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 6
  %.fca.7.0.0.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 0
  %.fca.7.0.1.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 1
  %.fca.7.0.2.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 2
  %6 = load i32, ptr %0, align 4, !tbaa !4
  %7 = tail call i32 @llvm.smax.i32(i32 %6, i32 0)
  %8 = zext i32 %7 to i64
  %9 = shl nuw nsw i64 %8, 3
  %10 = tail call ptr @malloc(i64 %9)
  store ptr %10, ptr %5, align 8, !tbaa !8
  store i64 8, ptr %.fca.1.gep, align 8, !tbaa !8
  store i32 20180515, ptr %.fca.2.gep, align 8, !tbaa !8
  store i8 1, ptr %.fca.3.gep, align 4, !tbaa !8
  store i8 28, ptr %.fca.4.gep, align 1, !tbaa !8
  store i8 2, ptr %.fca.5.gep, align 2, !tbaa !8
  store i8 0, ptr %.fca.6.gep, align 1, !tbaa !8
  store i64 1, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  store i64 %8, ptr %.fca.7.0.1.gep, align 8, !tbaa !8
  store i64 8, ptr %.fca.7.0.2.gep, align 8, !tbaa !8
  %omp_global_thread_num = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %0, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %5, ptr %gep_5, align 8
  %gep_6 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 2
  store ptr %4, ptr %gep_6, align 8
  %gep_7 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 3
  store ptr %3, ptr %gep_7, align 8
  %gep_8 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 4
  store ptr %2, ptr %gep_8, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QFPomp_subroutine..omp_par, ptr nonnull %structArg)
  %.fca.0.load = load ptr, ptr %5, align 8, !tbaa !8
  %.fca.7.0.0.load = load i64, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  %11 = sub i64 1, %.fca.7.0.0.load
  %12 = getelementptr double, ptr %.fca.0.load, i64 %11
  %13 = load double, ptr %12, align 8, !tbaa !4
  %14 = load i32, ptr %0, align 4, !tbaa !4
  %15 = sext i32 %14 to i64
  %16 = sub i64 %15, %.fca.7.0.0.load
  %17 = getelementptr double, ptr %.fca.0.load, i64 %16
  %18 = load double, ptr %17, align 8, !tbaa !4
  %19 = fadd contract double %13, %18
  store double %19, ptr %1, align 8, !tbaa !4
  call void @free(ptr %.fca.0.load)
  ret void
}

; Function Attrs: norecurse nounwind
define internal void @_QFPomp_subroutine..omp_par(ptr noalias nocapture readnone %tid.addr, ptr noalias nocapture readnone %zero.addr, ptr nocapture readonly %0) #3 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %gep_3 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 2
  %loadgep_4 = load ptr, ptr %gep_3, align 8
  %gep_5 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 3
  %loadgep_6 = load ptr, ptr %gep_5, align 8
  %gep_7 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 4
  %loadgep_8 = load ptr, ptr %gep_7, align 8
  %1 = tail call i32 @omp_get_thread_num()
  %2 = tail call i32 @omp_get_num_threads()
  %3 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %4 = sdiv i32 %3, %2
  %5 = mul i32 %4, %1
  %6 = add i32 %5, 1
  %7 = add i32 %2, -1
  %8 = icmp eq i32 %1, %7
  %9 = add i32 %6, %4
  %spec.select = select i1 %8, i32 %3, i32 %9
  %.unpack = load ptr, ptr %loadgep_2, align 8, !tbaa !8
  %.elt14 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  %.unpack15 = load i64, ptr %.elt14, align 8, !tbaa !8
  %.elt16 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  %.unpack17 = load i32, ptr %.elt16, align 8, !tbaa !8
  %.elt18 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  %.unpack19 = load i8, ptr %.elt18, align 4, !tbaa !8
  %.elt20 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  %.unpack21 = load i8, ptr %.elt20, align 1, !tbaa !8
  %.elt22 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  %.unpack23 = load i8, ptr %.elt22, align 2, !tbaa !8
  %.elt24 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  %.unpack25 = load i8, ptr %.elt24, align 1, !tbaa !8
  %.elt26 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  %.unpack27.unpack.unpack = load i64, ptr %.elt26, align 8, !tbaa !8
  %.unpack27.unpack.elt29 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  %.unpack27.unpack.unpack30 = load i64, ptr %.unpack27.unpack.elt29, align 8, !tbaa !8
  %.unpack27.unpack.elt31 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  %.unpack27.unpack.unpack32 = load i64, ptr %.unpack27.unpack.elt31, align 8, !tbaa !8
  store ptr %.unpack, ptr %loadgep_4, align 8, !tbaa !8
  %loadgep_4.repack34 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 1
  store i64 %.unpack15, ptr %loadgep_4.repack34, align 8, !tbaa !8
  %loadgep_4.repack36 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 2
  store i32 %.unpack17, ptr %loadgep_4.repack36, align 8, !tbaa !8
  %loadgep_4.repack38 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 3
  store i8 %.unpack19, ptr %loadgep_4.repack38, align 4, !tbaa !8
  %loadgep_4.repack40 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 4
  store i8 %.unpack21, ptr %loadgep_4.repack40, align 1, !tbaa !8
  %loadgep_4.repack42 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 5
  store i8 %.unpack23, ptr %loadgep_4.repack42, align 2, !tbaa !8
  %loadgep_4.repack44 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 6
  store i8 %.unpack25, ptr %loadgep_4.repack44, align 1, !tbaa !8
  %loadgep_4.repack46 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7
  store i64 %.unpack27.unpack.unpack, ptr %loadgep_4.repack46, align 8, !tbaa !8
  %loadgep_4.repack46.repack48 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack27.unpack.unpack30, ptr %loadgep_4.repack46.repack48, align 8, !tbaa !8
  %loadgep_4.repack46.repack50 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 2
  store i64 %.unpack27.unpack.unpack32, ptr %loadgep_4.repack46.repack50, align 8, !tbaa !8
  %10 = icmp eq i64 %.unpack27.unpack.unpack30, 0
  %11 = select i1 %10, i64 1, i64 %.unpack27.unpack.unpack
  store ptr %.unpack, ptr %loadgep_6, align 8, !tbaa !8
  %loadgep_6.repack52 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 1
  store i64 8, ptr %loadgep_6.repack52, align 8, !tbaa !8
  %loadgep_6.repack54 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 2
  store i32 20180515, ptr %loadgep_6.repack54, align 8, !tbaa !8
  %loadgep_6.repack56 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 3
  store i8 1, ptr %loadgep_6.repack56, align 4, !tbaa !8
  %loadgep_6.repack58 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 4
  store i8 28, ptr %loadgep_6.repack58, align 1, !tbaa !8
  %loadgep_6.repack60 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 5
  store i8 0, ptr %loadgep_6.repack60, align 2, !tbaa !8
  %loadgep_6.repack62 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 6
  store i8 0, ptr %loadgep_6.repack62, align 1, !tbaa !8
  %loadgep_6.repack64 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7
  store i64 %11, ptr %loadgep_6.repack64, align 8, !tbaa !8
  %loadgep_6.repack64.repack66 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack27.unpack.unpack30, ptr %loadgep_6.repack64.repack66, align 8, !tbaa !8
  %loadgep_6.repack64.repack68 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7, i64 0, i64 2
  store i64 8, ptr %loadgep_6.repack64.repack68, align 8, !tbaa !8
  %12 = load ptr, ptr %loadgep_8, align 8, !tbaa !4
  %13 = getelementptr { ptr, ptr }, ptr %loadgep_8, i64 0, i32 1
  %14 = load ptr, ptr %13, align 8, !tbaa !4
  %15 = sext i32 %6 to i64
  %16 = sext i32 %spec.select to i64
  %reass.sub9.i = sub nsw i64 %16, %15
  %17 = icmp sgt i64 %reass.sub9.i, -1
  br i1 %17, label %.lr.ph8.preheader.i, label %_QFPloop.exit

.lr.ph8.preheader.i:                              ; preds = %omp.par.entry
  %18 = add nuw nsw i64 %reass.sub9.i, 1
  br label %.lr.ph8.i

.lr.ph8.i:                                        ; preds = %.lr.ph8.i, %.lr.ph8.preheader.i
  %19 = phi i64 [ %29, %.lr.ph8.i ], [ %18, %.lr.ph8.preheader.i ]
  %20 = phi i32 [ %28, %.lr.ph8.i ], [ %6, %.lr.ph8.preheader.i ]
  %21 = load i32, ptr %12, align 4, !tbaa !4
  %22 = sitofp i32 %21 to float
  %23 = fdiv contract float 1.000000e+00, %22
  %24 = fpext float %23 to double
  %25 = sext i32 %20 to i64
  %26 = add nsw i64 %25, -1
  %27 = getelementptr double, ptr %.unpack, i64 %26
  store double %24, ptr %27, align 8, !tbaa !4
  store double %24, ptr %14, align 8, !tbaa !4
  %28 = add i32 %20, 1
  %29 = add nsw i64 %19, -1
  %30 = icmp ugt i64 %19, 1
  br i1 %30, label %.lr.ph8.i, label %_QFPloop.exit

_QFPloop.exit:                                    ; preds = %.lr.ph8.i, %omp.par.entry
  ret void
}

; Function Attrs: nofree norecurse nosync nounwind memory(readwrite, inaccessiblemem: none)
define void @_QFPloop(ptr nocapture readonly %0, ptr nocapture readonly %1, ptr nocapture readonly %2, ptr nest nocapture readonly %3) local_unnamed_addr #4 {
  %5 = load ptr, ptr %3, align 8, !tbaa !4
  %6 = getelementptr { ptr, ptr }, ptr %3, i64 0, i32 1
  %7 = load ptr, ptr %6, align 8, !tbaa !4
  %8 = load i32, ptr %0, align 4, !tbaa !4
  %9 = sext i32 %8 to i64
  %10 = load i32, ptr %1, align 4, !tbaa !4
  %11 = sext i32 %10 to i64
  %12 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %2, i64 0, i32 7, i64 0, i64 2
  %13 = load i64, ptr %12, align 8, !tbaa !8
  %14 = icmp eq i64 %13, 8
  br i1 %14, label %15, label %31

15:                                               ; preds = %4
  %16 = load ptr, ptr %2, align 8, !tbaa !8
  %reass.sub9 = sub nsw i64 %11, %9
  %17 = icmp sgt i64 %reass.sub9, -1
  br i1 %17, label %.lr.ph8.preheader, label %.loopexit

.lr.ph8.preheader:                                ; preds = %15
  %18 = add nuw nsw i64 %reass.sub9, 1
  br label %.lr.ph8

.lr.ph8:                                          ; preds = %.lr.ph8.preheader, %.lr.ph8
  %19 = phi i64 [ %29, %.lr.ph8 ], [ %18, %.lr.ph8.preheader ]
  %20 = phi i32 [ %28, %.lr.ph8 ], [ %8, %.lr.ph8.preheader ]
  %21 = load i32, ptr %5, align 4, !tbaa !4
  %22 = sitofp i32 %21 to float
  %23 = fdiv contract float 1.000000e+00, %22
  %24 = fpext float %23 to double
  %25 = sext i32 %20 to i64
  %26 = add nsw i64 %25, -1
  %27 = getelementptr double, ptr %16, i64 %26
  store double %24, ptr %27, align 8, !tbaa !4
  store double %24, ptr %7, align 8, !tbaa !4
  %28 = add i32 %20, 1
  %29 = add nsw i64 %19, -1
  %30 = icmp ugt i64 %19, 1
  br i1 %30, label %.lr.ph8, label %.loopexit

31:                                               ; preds = %4
  %reass.sub = sub nsw i64 %11, %9
  %32 = icmp sgt i64 %reass.sub, -1
  br i1 %32, label %.lr.ph, label %.loopexit

.lr.ph:                                           ; preds = %31
  %33 = add nuw nsw i64 %reass.sub, 1
  %34 = load ptr, ptr %2, align 8, !tbaa !8
  br label %35

35:                                               ; preds = %.lr.ph, %35
  %36 = phi i64 [ %33, %.lr.ph ], [ %47, %35 ]
  %37 = phi i32 [ %8, %.lr.ph ], [ %46, %35 ]
  %38 = load i32, ptr %5, align 4, !tbaa !4
  %39 = sitofp i32 %38 to float
  %40 = fdiv contract float 1.000000e+00, %39
  %41 = fpext float %40 to double
  %42 = sext i32 %37 to i64
  %43 = add nsw i64 %42, -1
  %44 = mul i64 %43, %13
  %45 = getelementptr i8, ptr %34, i64 %44
  store double %41, ptr %45, align 8, !tbaa !4
  store double %41, ptr %7, align 8, !tbaa !4
  %46 = add i32 %37, 1
  %47 = add nsw i64 %36, -1
  %48 = icmp ugt i64 %36, 1
  br i1 %48, label %35, label %.loopexit

.loopexit:                                        ; preds = %35, %.lr.ph8, %31, %15
  ret void
}

declare ptr @_FortranAioBeginExternalFormattedOutput(ptr, i64, ptr, i32, ptr, i32) local_unnamed_addr

declare zeroext i1 @_FortranAioOutputAscii(ptr, ptr, i64) local_unnamed_addr

declare zeroext i1 @_FortranAioOutputInteger32(ptr, i32) local_unnamed_addr

declare zeroext i1 @_FortranAioOutputReal64(ptr, double) local_unnamed_addr

declare i32 @_FortranAioEndIoStatement(ptr) local_unnamed_addr

; Function Attrs: nounwind
declare i32 @omp_get_thread_num() local_unnamed_addr #2

; Function Attrs: nounwind
declare i32 @omp_get_num_threads() local_unnamed_addr #2

; Function Attrs: nounwind
declare i32 @__kmpc_global_thread_num(ptr) local_unnamed_addr #2

; Function Attrs: nounwind
declare !callback !10 void @__kmpc_fork_call(ptr, i32, ptr, ...) local_unnamed_addr #2

; Function Attrs: nocallback nofree nosync nounwind speculatable willreturn memory(none)
declare i32 @llvm.smax.i32(i32, i32) #5

; Function Attrs: nocallback nofree nosync nounwind willreturn memory(argmem: readwrite)
declare void @llvm.lifetime.start.p0(i64 immarg, ptr nocapture) #6

; Function Attrs: nocallback nofree nosync nounwind willreturn memory(argmem: readwrite)
declare void @llvm.lifetime.end.p0(i64 immarg, ptr nocapture) #6

attributes #0 = { mustprogress nofree nounwind willreturn allockind("alloc,uninitialized") allocsize(0) memory(inaccessiblemem: readwrite) "alloc-family"="malloc" }
attributes #1 = { mustprogress nounwind willreturn allockind("free") memory(argmem: readwrite, inaccessiblemem: readwrite) "alloc-family"="malloc" }
attributes #2 = { nounwind }
attributes #3 = { norecurse nounwind }
attributes #4 = { nofree norecurse nosync nounwind memory(readwrite, inaccessiblemem: none) }
attributes #5 = { nocallback nofree nosync nounwind speculatable willreturn memory(none) }
attributes #6 = { nocallback nofree nosync nounwind willreturn memory(argmem: readwrite) }

!llvm.module.flags = !{!0, !1, !2, !3}

!0 = !{i32 2, !"Debug Info Version", i32 3}
!1 = !{i32 7, !"openmp", i32 11}
!2 = !{i32 8, !"PIC Level", i32 2}
!3 = !{i32 7, !"PIE Level", i32 2}
!4 = !{!5, !5, i64 0}
!5 = !{!"any data access", !6, i64 0}
!6 = !{!"any access", !7, i64 0}
!7 = !{!"Flang Type TBAA Root"}
!8 = !{!9, !9, i64 0}
!9 = !{!"descriptor member", !6, i64 0}
!10 = !{!11}
!11 = !{i64 2, i64 -1, i64 -1, i1 true}
*** IR Dump After GlobalDCEPass on [module] ***
; ModuleID = 'FIRModule'
source_filename = "FIRModule"
target datalayout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128"
target triple = "x86_64-unknown-linux-gnu"

%struct.ident_t = type { i32, i32, i32, i32, ptr }

@_QQcl.28612C69372C612C6531332E36653229 = internal constant [16 x i8] c"(a,i7,a,e13.6e2)"
@_QQcl.e8a0ac9186c064ac8543d822e9060d96 = internal constant [59 x i8] c"/g/g92/rydahl1/flangtests/src/parallel_region_outlined.f90\00"
@_QQcl.54686520726573756C74206F6620286172722831292B61727228 = internal constant [26 x i8] c"The result of (arr(1)+arr("
@_QQcl.2920697320 = internal constant [5 x i8] c") is "
@_QQEnvironmentDefaults = local_unnamed_addr constant ptr null
@0 = private unnamed_addr constant [23 x i8] c";unknown;unknown;0;0;;\00", align 1
@1 = private unnamed_addr constant %struct.ident_t { i32 0, i32 2, i32 0, i32 22, ptr @0 }, align 8

; Function Attrs: mustprogress nofree nounwind willreturn allockind("alloc,uninitialized") allocsize(0) memory(inaccessiblemem: readwrite)
declare noalias noundef ptr @malloc(i64 noundef) local_unnamed_addr #0

; Function Attrs: mustprogress nounwind willreturn allockind("free") memory(argmem: readwrite, inaccessiblemem: readwrite)
declare void @free(ptr allocptr nocapture noundef) local_unnamed_addr #1

define void @_QQmain() local_unnamed_addr {
  %structArg.i = alloca { ptr, ptr, ptr, ptr, ptr }, align 8
  %1 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %2 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %3 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %4 = alloca i32, align 4
  %5 = alloca double, align 8
  %6 = alloca { ptr, ptr }, align 8
  store ptr %4, ptr %6, align 8, !tbaa !4
  %7 = getelementptr inbounds { ptr, ptr }, ptr %6, i64 0, i32 1
  store ptr %5, ptr %7, align 8, !tbaa !4
  store i32 1048576, ptr %4, align 4, !tbaa !4
  call void @llvm.lifetime.start.p0(i64 40, ptr nonnull %structArg.i)
  call void @llvm.lifetime.start.p0(i64 48, ptr nonnull %1)
  call void @llvm.lifetime.start.p0(i64 48, ptr nonnull %2)
  call void @llvm.lifetime.start.p0(i64 48, ptr nonnull %3)
  %.fca.1.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 1
  %.fca.2.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 2
  %.fca.3.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 3
  %.fca.4.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 4
  %.fca.5.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 5
  %.fca.6.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 6
  %.fca.7.0.0.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 7, i64 0, i64 0
  %.fca.7.0.1.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 7, i64 0, i64 1
  %.fca.7.0.2.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 7, i64 0, i64 2
  %8 = call dereferenceable_or_null(8388608) ptr @malloc(i64 8388608)
  store ptr %8, ptr %3, align 8, !tbaa !8
  store i64 8, ptr %.fca.1.gep.i, align 8, !tbaa !8
  store i32 20180515, ptr %.fca.2.gep.i, align 8, !tbaa !8
  store i8 1, ptr %.fca.3.gep.i, align 4, !tbaa !8
  store i8 28, ptr %.fca.4.gep.i, align 1, !tbaa !8
  store i8 2, ptr %.fca.5.gep.i, align 2, !tbaa !8
  store i8 0, ptr %.fca.6.gep.i, align 1, !tbaa !8
  store i64 1, ptr %.fca.7.0.0.gep.i, align 8, !tbaa !8
  store i64 1048576, ptr %.fca.7.0.1.gep.i, align 8, !tbaa !8
  store i64 8, ptr %.fca.7.0.2.gep.i, align 8, !tbaa !8
  %omp_global_thread_num.i = call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %4, ptr %structArg.i, align 8
  %gep_5.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 1
  store ptr %3, ptr %gep_5.i, align 8
  %gep_6.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 2
  store ptr %2, ptr %gep_6.i, align 8
  %gep_7.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 3
  store ptr %1, ptr %gep_7.i, align 8
  %gep_8.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 4
  store ptr %6, ptr %gep_8.i, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QFPomp_subroutine..omp_par, ptr nonnull %structArg.i)
  %.fca.0.load.i = load ptr, ptr %3, align 8, !tbaa !8
  %.fca.7.0.0.load.i = load i64, ptr %.fca.7.0.0.gep.i, align 8, !tbaa !8
  %9 = sub i64 1, %.fca.7.0.0.load.i
  %10 = getelementptr double, ptr %.fca.0.load.i, i64 %9
  %11 = load double, ptr %10, align 8, !tbaa !4
  %12 = load i32, ptr %4, align 4, !tbaa !4
  %13 = sext i32 %12 to i64
  %14 = sub i64 %13, %.fca.7.0.0.load.i
  %15 = getelementptr double, ptr %.fca.0.load.i, i64 %14
  %16 = load double, ptr %15, align 8, !tbaa !4
  %17 = fadd contract double %11, %16
  call void @free(ptr %.fca.0.load.i)
  call void @llvm.lifetime.end.p0(i64 40, ptr nonnull %structArg.i)
  call void @llvm.lifetime.end.p0(i64 48, ptr nonnull %1)
  call void @llvm.lifetime.end.p0(i64 48, ptr nonnull %2)
  call void @llvm.lifetime.end.p0(i64 48, ptr nonnull %3)
  %18 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.e8a0ac9186c064ac8543d822e9060d96, i32 10)
  %19 = call i1 @_FortranAioOutputAscii(ptr %18, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %20 = load i32, ptr %4, align 4, !tbaa !4
  %21 = call i1 @_FortranAioOutputInteger32(ptr %18, i32 %20)
  %22 = call i1 @_FortranAioOutputAscii(ptr %18, ptr nonnull @_QQcl.2920697320, i64 5)
  %23 = call i1 @_FortranAioOutputReal64(ptr %18, double %17)
  %24 = call i32 @_FortranAioEndIoStatement(ptr %18)
  ret void
}

; Function Attrs: nounwind
define void @_QFPomp_subroutine(ptr %0, ptr nocapture writeonly %1, ptr nest %2) local_unnamed_addr #2 {
entry:
  %structArg = alloca { ptr, ptr, ptr, ptr, ptr }, align 8
  %3 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %4 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %5 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %.fca.1.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 1
  %.fca.2.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 2
  %.fca.3.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 3
  %.fca.4.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 4
  %.fca.5.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 5
  %.fca.6.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 6
  %.fca.7.0.0.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 0
  %.fca.7.0.1.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 1
  %.fca.7.0.2.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 2
  %6 = load i32, ptr %0, align 4, !tbaa !4
  %7 = tail call i32 @llvm.smax.i32(i32 %6, i32 0)
  %8 = zext i32 %7 to i64
  %9 = shl nuw nsw i64 %8, 3
  %10 = tail call ptr @malloc(i64 %9)
  store ptr %10, ptr %5, align 8, !tbaa !8
  store i64 8, ptr %.fca.1.gep, align 8, !tbaa !8
  store i32 20180515, ptr %.fca.2.gep, align 8, !tbaa !8
  store i8 1, ptr %.fca.3.gep, align 4, !tbaa !8
  store i8 28, ptr %.fca.4.gep, align 1, !tbaa !8
  store i8 2, ptr %.fca.5.gep, align 2, !tbaa !8
  store i8 0, ptr %.fca.6.gep, align 1, !tbaa !8
  store i64 1, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  store i64 %8, ptr %.fca.7.0.1.gep, align 8, !tbaa !8
  store i64 8, ptr %.fca.7.0.2.gep, align 8, !tbaa !8
  %omp_global_thread_num = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %0, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %5, ptr %gep_5, align 8
  %gep_6 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 2
  store ptr %4, ptr %gep_6, align 8
  %gep_7 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 3
  store ptr %3, ptr %gep_7, align 8
  %gep_8 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 4
  store ptr %2, ptr %gep_8, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QFPomp_subroutine..omp_par, ptr nonnull %structArg)
  %.fca.0.load = load ptr, ptr %5, align 8, !tbaa !8
  %.fca.7.0.0.load = load i64, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  %11 = sub i64 1, %.fca.7.0.0.load
  %12 = getelementptr double, ptr %.fca.0.load, i64 %11
  %13 = load double, ptr %12, align 8, !tbaa !4
  %14 = load i32, ptr %0, align 4, !tbaa !4
  %15 = sext i32 %14 to i64
  %16 = sub i64 %15, %.fca.7.0.0.load
  %17 = getelementptr double, ptr %.fca.0.load, i64 %16
  %18 = load double, ptr %17, align 8, !tbaa !4
  %19 = fadd contract double %13, %18
  store double %19, ptr %1, align 8, !tbaa !4
  call void @free(ptr %.fca.0.load)
  ret void
}

; Function Attrs: norecurse nounwind
define internal void @_QFPomp_subroutine..omp_par(ptr noalias nocapture readnone %tid.addr, ptr noalias nocapture readnone %zero.addr, ptr nocapture readonly %0) #3 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %gep_3 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 2
  %loadgep_4 = load ptr, ptr %gep_3, align 8
  %gep_5 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 3
  %loadgep_6 = load ptr, ptr %gep_5, align 8
  %gep_7 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 4
  %loadgep_8 = load ptr, ptr %gep_7, align 8
  %1 = tail call i32 @omp_get_thread_num()
  %2 = tail call i32 @omp_get_num_threads()
  %3 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %4 = sdiv i32 %3, %2
  %5 = mul i32 %4, %1
  %6 = add i32 %5, 1
  %7 = add i32 %2, -1
  %8 = icmp eq i32 %1, %7
  %9 = add i32 %6, %4
  %spec.select = select i1 %8, i32 %3, i32 %9
  %.unpack = load ptr, ptr %loadgep_2, align 8, !tbaa !8
  %.elt14 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  %.unpack15 = load i64, ptr %.elt14, align 8, !tbaa !8
  %.elt16 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  %.unpack17 = load i32, ptr %.elt16, align 8, !tbaa !8
  %.elt18 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  %.unpack19 = load i8, ptr %.elt18, align 4, !tbaa !8
  %.elt20 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  %.unpack21 = load i8, ptr %.elt20, align 1, !tbaa !8
  %.elt22 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  %.unpack23 = load i8, ptr %.elt22, align 2, !tbaa !8
  %.elt24 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  %.unpack25 = load i8, ptr %.elt24, align 1, !tbaa !8
  %.elt26 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  %.unpack27.unpack.unpack = load i64, ptr %.elt26, align 8, !tbaa !8
  %.unpack27.unpack.elt29 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  %.unpack27.unpack.unpack30 = load i64, ptr %.unpack27.unpack.elt29, align 8, !tbaa !8
  %.unpack27.unpack.elt31 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  %.unpack27.unpack.unpack32 = load i64, ptr %.unpack27.unpack.elt31, align 8, !tbaa !8
  store ptr %.unpack, ptr %loadgep_4, align 8, !tbaa !8
  %loadgep_4.repack34 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 1
  store i64 %.unpack15, ptr %loadgep_4.repack34, align 8, !tbaa !8
  %loadgep_4.repack36 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 2
  store i32 %.unpack17, ptr %loadgep_4.repack36, align 8, !tbaa !8
  %loadgep_4.repack38 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 3
  store i8 %.unpack19, ptr %loadgep_4.repack38, align 4, !tbaa !8
  %loadgep_4.repack40 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 4
  store i8 %.unpack21, ptr %loadgep_4.repack40, align 1, !tbaa !8
  %loadgep_4.repack42 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 5
  store i8 %.unpack23, ptr %loadgep_4.repack42, align 2, !tbaa !8
  %loadgep_4.repack44 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 6
  store i8 %.unpack25, ptr %loadgep_4.repack44, align 1, !tbaa !8
  %loadgep_4.repack46 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7
  store i64 %.unpack27.unpack.unpack, ptr %loadgep_4.repack46, align 8, !tbaa !8
  %loadgep_4.repack46.repack48 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack27.unpack.unpack30, ptr %loadgep_4.repack46.repack48, align 8, !tbaa !8
  %loadgep_4.repack46.repack50 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 2
  store i64 %.unpack27.unpack.unpack32, ptr %loadgep_4.repack46.repack50, align 8, !tbaa !8
  %10 = icmp eq i64 %.unpack27.unpack.unpack30, 0
  %11 = select i1 %10, i64 1, i64 %.unpack27.unpack.unpack
  store ptr %.unpack, ptr %loadgep_6, align 8, !tbaa !8
  %loadgep_6.repack52 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 1
  store i64 8, ptr %loadgep_6.repack52, align 8, !tbaa !8
  %loadgep_6.repack54 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 2
  store i32 20180515, ptr %loadgep_6.repack54, align 8, !tbaa !8
  %loadgep_6.repack56 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 3
  store i8 1, ptr %loadgep_6.repack56, align 4, !tbaa !8
  %loadgep_6.repack58 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 4
  store i8 28, ptr %loadgep_6.repack58, align 1, !tbaa !8
  %loadgep_6.repack60 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 5
  store i8 0, ptr %loadgep_6.repack60, align 2, !tbaa !8
  %loadgep_6.repack62 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 6
  store i8 0, ptr %loadgep_6.repack62, align 1, !tbaa !8
  %loadgep_6.repack64 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7
  store i64 %11, ptr %loadgep_6.repack64, align 8, !tbaa !8
  %loadgep_6.repack64.repack66 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack27.unpack.unpack30, ptr %loadgep_6.repack64.repack66, align 8, !tbaa !8
  %loadgep_6.repack64.repack68 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7, i64 0, i64 2
  store i64 8, ptr %loadgep_6.repack64.repack68, align 8, !tbaa !8
  %12 = load ptr, ptr %loadgep_8, align 8, !tbaa !4
  %13 = getelementptr { ptr, ptr }, ptr %loadgep_8, i64 0, i32 1
  %14 = load ptr, ptr %13, align 8, !tbaa !4
  %15 = sext i32 %6 to i64
  %16 = sext i32 %spec.select to i64
  %reass.sub9.i = sub nsw i64 %16, %15
  %17 = icmp sgt i64 %reass.sub9.i, -1
  br i1 %17, label %.lr.ph8.preheader.i, label %_QFPloop.exit

.lr.ph8.preheader.i:                              ; preds = %omp.par.entry
  %18 = add nuw nsw i64 %reass.sub9.i, 1
  br label %.lr.ph8.i

.lr.ph8.i:                                        ; preds = %.lr.ph8.i, %.lr.ph8.preheader.i
  %19 = phi i64 [ %29, %.lr.ph8.i ], [ %18, %.lr.ph8.preheader.i ]
  %20 = phi i32 [ %28, %.lr.ph8.i ], [ %6, %.lr.ph8.preheader.i ]
  %21 = load i32, ptr %12, align 4, !tbaa !4
  %22 = sitofp i32 %21 to float
  %23 = fdiv contract float 1.000000e+00, %22
  %24 = fpext float %23 to double
  %25 = sext i32 %20 to i64
  %26 = add nsw i64 %25, -1
  %27 = getelementptr double, ptr %.unpack, i64 %26
  store double %24, ptr %27, align 8, !tbaa !4
  store double %24, ptr %14, align 8, !tbaa !4
  %28 = add i32 %20, 1
  %29 = add nsw i64 %19, -1
  %30 = icmp ugt i64 %19, 1
  br i1 %30, label %.lr.ph8.i, label %_QFPloop.exit

_QFPloop.exit:                                    ; preds = %.lr.ph8.i, %omp.par.entry
  ret void
}

; Function Attrs: nofree norecurse nosync nounwind memory(readwrite, inaccessiblemem: none)
define void @_QFPloop(ptr nocapture readonly %0, ptr nocapture readonly %1, ptr nocapture readonly %2, ptr nest nocapture readonly %3) local_unnamed_addr #4 {
  %5 = load ptr, ptr %3, align 8, !tbaa !4
  %6 = getelementptr { ptr, ptr }, ptr %3, i64 0, i32 1
  %7 = load ptr, ptr %6, align 8, !tbaa !4
  %8 = load i32, ptr %0, align 4, !tbaa !4
  %9 = sext i32 %8 to i64
  %10 = load i32, ptr %1, align 4, !tbaa !4
  %11 = sext i32 %10 to i64
  %12 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %2, i64 0, i32 7, i64 0, i64 2
  %13 = load i64, ptr %12, align 8, !tbaa !8
  %14 = icmp eq i64 %13, 8
  br i1 %14, label %15, label %31

15:                                               ; preds = %4
  %16 = load ptr, ptr %2, align 8, !tbaa !8
  %reass.sub9 = sub nsw i64 %11, %9
  %17 = icmp sgt i64 %reass.sub9, -1
  br i1 %17, label %.lr.ph8.preheader, label %.loopexit

.lr.ph8.preheader:                                ; preds = %15
  %18 = add nuw nsw i64 %reass.sub9, 1
  br label %.lr.ph8

.lr.ph8:                                          ; preds = %.lr.ph8.preheader, %.lr.ph8
  %19 = phi i64 [ %29, %.lr.ph8 ], [ %18, %.lr.ph8.preheader ]
  %20 = phi i32 [ %28, %.lr.ph8 ], [ %8, %.lr.ph8.preheader ]
  %21 = load i32, ptr %5, align 4, !tbaa !4
  %22 = sitofp i32 %21 to float
  %23 = fdiv contract float 1.000000e+00, %22
  %24 = fpext float %23 to double
  %25 = sext i32 %20 to i64
  %26 = add nsw i64 %25, -1
  %27 = getelementptr double, ptr %16, i64 %26
  store double %24, ptr %27, align 8, !tbaa !4
  store double %24, ptr %7, align 8, !tbaa !4
  %28 = add i32 %20, 1
  %29 = add nsw i64 %19, -1
  %30 = icmp ugt i64 %19, 1
  br i1 %30, label %.lr.ph8, label %.loopexit

31:                                               ; preds = %4
  %reass.sub = sub nsw i64 %11, %9
  %32 = icmp sgt i64 %reass.sub, -1
  br i1 %32, label %.lr.ph, label %.loopexit

.lr.ph:                                           ; preds = %31
  %33 = add nuw nsw i64 %reass.sub, 1
  %34 = load ptr, ptr %2, align 8, !tbaa !8
  br label %35

35:                                               ; preds = %.lr.ph, %35
  %36 = phi i64 [ %33, %.lr.ph ], [ %47, %35 ]
  %37 = phi i32 [ %8, %.lr.ph ], [ %46, %35 ]
  %38 = load i32, ptr %5, align 4, !tbaa !4
  %39 = sitofp i32 %38 to float
  %40 = fdiv contract float 1.000000e+00, %39
  %41 = fpext float %40 to double
  %42 = sext i32 %37 to i64
  %43 = add nsw i64 %42, -1
  %44 = mul i64 %43, %13
  %45 = getelementptr i8, ptr %34, i64 %44
  store double %41, ptr %45, align 8, !tbaa !4
  store double %41, ptr %7, align 8, !tbaa !4
  %46 = add i32 %37, 1
  %47 = add nsw i64 %36, -1
  %48 = icmp ugt i64 %36, 1
  br i1 %48, label %35, label %.loopexit

.loopexit:                                        ; preds = %35, %.lr.ph8, %31, %15
  ret void
}

declare ptr @_FortranAioBeginExternalFormattedOutput(ptr, i64, ptr, i32, ptr, i32) local_unnamed_addr

declare zeroext i1 @_FortranAioOutputAscii(ptr, ptr, i64) local_unnamed_addr

declare zeroext i1 @_FortranAioOutputInteger32(ptr, i32) local_unnamed_addr

declare zeroext i1 @_FortranAioOutputReal64(ptr, double) local_unnamed_addr

declare i32 @_FortranAioEndIoStatement(ptr) local_unnamed_addr

; Function Attrs: nounwind
declare i32 @omp_get_thread_num() local_unnamed_addr #2

; Function Attrs: nounwind
declare i32 @omp_get_num_threads() local_unnamed_addr #2

; Function Attrs: nounwind
declare i32 @__kmpc_global_thread_num(ptr) local_unnamed_addr #2

; Function Attrs: nounwind
declare !callback !10 void @__kmpc_fork_call(ptr, i32, ptr, ...) local_unnamed_addr #2

; Function Attrs: nocallback nofree nosync nounwind speculatable willreturn memory(none)
declare i32 @llvm.smax.i32(i32, i32) #5

; Function Attrs: nocallback nofree nosync nounwind willreturn memory(argmem: readwrite)
declare void @llvm.lifetime.start.p0(i64 immarg, ptr nocapture) #6

; Function Attrs: nocallback nofree nosync nounwind willreturn memory(argmem: readwrite)
declare void @llvm.lifetime.end.p0(i64 immarg, ptr nocapture) #6

attributes #0 = { mustprogress nofree nounwind willreturn allockind("alloc,uninitialized") allocsize(0) memory(inaccessiblemem: readwrite) "alloc-family"="malloc" }
attributes #1 = { mustprogress nounwind willreturn allockind("free") memory(argmem: readwrite, inaccessiblemem: readwrite) "alloc-family"="malloc" }
attributes #2 = { nounwind }
attributes #3 = { norecurse nounwind }
attributes #4 = { nofree norecurse nosync nounwind memory(readwrite, inaccessiblemem: none) }
attributes #5 = { nocallback nofree nosync nounwind speculatable willreturn memory(none) }
attributes #6 = { nocallback nofree nosync nounwind willreturn memory(argmem: readwrite) }

!llvm.module.flags = !{!0, !1, !2, !3}

!0 = !{i32 2, !"Debug Info Version", i32 3}
!1 = !{i32 7, !"openmp", i32 11}
!2 = !{i32 8, !"PIC Level", i32 2}
!3 = !{i32 7, !"PIE Level", i32 2}
!4 = !{!5, !5, i64 0}
!5 = !{!"any data access", !6, i64 0}
!6 = !{!"any access", !7, i64 0}
!7 = !{!"Flang Type TBAA Root"}
!8 = !{!9, !9, i64 0}
!9 = !{!"descriptor member", !6, i64 0}
!10 = !{!11}
!11 = !{i64 2, i64 -1, i64 -1, i1 true}
*** IR Dump After EliminateAvailableExternallyPass on [module] ***
; ModuleID = 'FIRModule'
source_filename = "FIRModule"
target datalayout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128"
target triple = "x86_64-unknown-linux-gnu"

%struct.ident_t = type { i32, i32, i32, i32, ptr }

@_QQcl.28612C69372C612C6531332E36653229 = internal constant [16 x i8] c"(a,i7,a,e13.6e2)"
@_QQcl.e8a0ac9186c064ac8543d822e9060d96 = internal constant [59 x i8] c"/g/g92/rydahl1/flangtests/src/parallel_region_outlined.f90\00"
@_QQcl.54686520726573756C74206F6620286172722831292B61727228 = internal constant [26 x i8] c"The result of (arr(1)+arr("
@_QQcl.2920697320 = internal constant [5 x i8] c") is "
@_QQEnvironmentDefaults = local_unnamed_addr constant ptr null
@0 = private unnamed_addr constant [23 x i8] c";unknown;unknown;0;0;;\00", align 1
@1 = private unnamed_addr constant %struct.ident_t { i32 0, i32 2, i32 0, i32 22, ptr @0 }, align 8

; Function Attrs: mustprogress nofree nounwind willreturn allockind("alloc,uninitialized") allocsize(0) memory(inaccessiblemem: readwrite)
declare noalias noundef ptr @malloc(i64 noundef) local_unnamed_addr #0

; Function Attrs: mustprogress nounwind willreturn allockind("free") memory(argmem: readwrite, inaccessiblemem: readwrite)
declare void @free(ptr allocptr nocapture noundef) local_unnamed_addr #1

define void @_QQmain() local_unnamed_addr {
  %structArg.i = alloca { ptr, ptr, ptr, ptr, ptr }, align 8
  %1 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %2 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %3 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %4 = alloca i32, align 4
  %5 = alloca double, align 8
  %6 = alloca { ptr, ptr }, align 8
  store ptr %4, ptr %6, align 8, !tbaa !4
  %7 = getelementptr inbounds { ptr, ptr }, ptr %6, i64 0, i32 1
  store ptr %5, ptr %7, align 8, !tbaa !4
  store i32 1048576, ptr %4, align 4, !tbaa !4
  call void @llvm.lifetime.start.p0(i64 40, ptr nonnull %structArg.i)
  call void @llvm.lifetime.start.p0(i64 48, ptr nonnull %1)
  call void @llvm.lifetime.start.p0(i64 48, ptr nonnull %2)
  call void @llvm.lifetime.start.p0(i64 48, ptr nonnull %3)
  %.fca.1.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 1
  %.fca.2.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 2
  %.fca.3.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 3
  %.fca.4.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 4
  %.fca.5.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 5
  %.fca.6.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 6
  %.fca.7.0.0.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 7, i64 0, i64 0
  %.fca.7.0.1.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 7, i64 0, i64 1
  %.fca.7.0.2.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 7, i64 0, i64 2
  %8 = call dereferenceable_or_null(8388608) ptr @malloc(i64 8388608)
  store ptr %8, ptr %3, align 8, !tbaa !8
  store i64 8, ptr %.fca.1.gep.i, align 8, !tbaa !8
  store i32 20180515, ptr %.fca.2.gep.i, align 8, !tbaa !8
  store i8 1, ptr %.fca.3.gep.i, align 4, !tbaa !8
  store i8 28, ptr %.fca.4.gep.i, align 1, !tbaa !8
  store i8 2, ptr %.fca.5.gep.i, align 2, !tbaa !8
  store i8 0, ptr %.fca.6.gep.i, align 1, !tbaa !8
  store i64 1, ptr %.fca.7.0.0.gep.i, align 8, !tbaa !8
  store i64 1048576, ptr %.fca.7.0.1.gep.i, align 8, !tbaa !8
  store i64 8, ptr %.fca.7.0.2.gep.i, align 8, !tbaa !8
  %omp_global_thread_num.i = call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %4, ptr %structArg.i, align 8
  %gep_5.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 1
  store ptr %3, ptr %gep_5.i, align 8
  %gep_6.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 2
  store ptr %2, ptr %gep_6.i, align 8
  %gep_7.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 3
  store ptr %1, ptr %gep_7.i, align 8
  %gep_8.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 4
  store ptr %6, ptr %gep_8.i, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QFPomp_subroutine..omp_par, ptr nonnull %structArg.i)
  %.fca.0.load.i = load ptr, ptr %3, align 8, !tbaa !8
  %.fca.7.0.0.load.i = load i64, ptr %.fca.7.0.0.gep.i, align 8, !tbaa !8
  %9 = sub i64 1, %.fca.7.0.0.load.i
  %10 = getelementptr double, ptr %.fca.0.load.i, i64 %9
  %11 = load double, ptr %10, align 8, !tbaa !4
  %12 = load i32, ptr %4, align 4, !tbaa !4
  %13 = sext i32 %12 to i64
  %14 = sub i64 %13, %.fca.7.0.0.load.i
  %15 = getelementptr double, ptr %.fca.0.load.i, i64 %14
  %16 = load double, ptr %15, align 8, !tbaa !4
  %17 = fadd contract double %11, %16
  call void @free(ptr %.fca.0.load.i)
  call void @llvm.lifetime.end.p0(i64 40, ptr nonnull %structArg.i)
  call void @llvm.lifetime.end.p0(i64 48, ptr nonnull %1)
  call void @llvm.lifetime.end.p0(i64 48, ptr nonnull %2)
  call void @llvm.lifetime.end.p0(i64 48, ptr nonnull %3)
  %18 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.e8a0ac9186c064ac8543d822e9060d96, i32 10)
  %19 = call i1 @_FortranAioOutputAscii(ptr %18, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %20 = load i32, ptr %4, align 4, !tbaa !4
  %21 = call i1 @_FortranAioOutputInteger32(ptr %18, i32 %20)
  %22 = call i1 @_FortranAioOutputAscii(ptr %18, ptr nonnull @_QQcl.2920697320, i64 5)
  %23 = call i1 @_FortranAioOutputReal64(ptr %18, double %17)
  %24 = call i32 @_FortranAioEndIoStatement(ptr %18)
  ret void
}

; Function Attrs: nounwind
define void @_QFPomp_subroutine(ptr %0, ptr nocapture writeonly %1, ptr nest %2) local_unnamed_addr #2 {
entry:
  %structArg = alloca { ptr, ptr, ptr, ptr, ptr }, align 8
  %3 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %4 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %5 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %.fca.1.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 1
  %.fca.2.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 2
  %.fca.3.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 3
  %.fca.4.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 4
  %.fca.5.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 5
  %.fca.6.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 6
  %.fca.7.0.0.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 0
  %.fca.7.0.1.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 1
  %.fca.7.0.2.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 2
  %6 = load i32, ptr %0, align 4, !tbaa !4
  %7 = tail call i32 @llvm.smax.i32(i32 %6, i32 0)
  %8 = zext i32 %7 to i64
  %9 = shl nuw nsw i64 %8, 3
  %10 = tail call ptr @malloc(i64 %9)
  store ptr %10, ptr %5, align 8, !tbaa !8
  store i64 8, ptr %.fca.1.gep, align 8, !tbaa !8
  store i32 20180515, ptr %.fca.2.gep, align 8, !tbaa !8
  store i8 1, ptr %.fca.3.gep, align 4, !tbaa !8
  store i8 28, ptr %.fca.4.gep, align 1, !tbaa !8
  store i8 2, ptr %.fca.5.gep, align 2, !tbaa !8
  store i8 0, ptr %.fca.6.gep, align 1, !tbaa !8
  store i64 1, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  store i64 %8, ptr %.fca.7.0.1.gep, align 8, !tbaa !8
  store i64 8, ptr %.fca.7.0.2.gep, align 8, !tbaa !8
  %omp_global_thread_num = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %0, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %5, ptr %gep_5, align 8
  %gep_6 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 2
  store ptr %4, ptr %gep_6, align 8
  %gep_7 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 3
  store ptr %3, ptr %gep_7, align 8
  %gep_8 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 4
  store ptr %2, ptr %gep_8, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QFPomp_subroutine..omp_par, ptr nonnull %structArg)
  %.fca.0.load = load ptr, ptr %5, align 8, !tbaa !8
  %.fca.7.0.0.load = load i64, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  %11 = sub i64 1, %.fca.7.0.0.load
  %12 = getelementptr double, ptr %.fca.0.load, i64 %11
  %13 = load double, ptr %12, align 8, !tbaa !4
  %14 = load i32, ptr %0, align 4, !tbaa !4
  %15 = sext i32 %14 to i64
  %16 = sub i64 %15, %.fca.7.0.0.load
  %17 = getelementptr double, ptr %.fca.0.load, i64 %16
  %18 = load double, ptr %17, align 8, !tbaa !4
  %19 = fadd contract double %13, %18
  store double %19, ptr %1, align 8, !tbaa !4
  call void @free(ptr %.fca.0.load)
  ret void
}

; Function Attrs: norecurse nounwind
define internal void @_QFPomp_subroutine..omp_par(ptr noalias nocapture readnone %tid.addr, ptr noalias nocapture readnone %zero.addr, ptr nocapture readonly %0) #3 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %gep_3 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 2
  %loadgep_4 = load ptr, ptr %gep_3, align 8
  %gep_5 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 3
  %loadgep_6 = load ptr, ptr %gep_5, align 8
  %gep_7 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 4
  %loadgep_8 = load ptr, ptr %gep_7, align 8
  %1 = tail call i32 @omp_get_thread_num()
  %2 = tail call i32 @omp_get_num_threads()
  %3 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %4 = sdiv i32 %3, %2
  %5 = mul i32 %4, %1
  %6 = add i32 %5, 1
  %7 = add i32 %2, -1
  %8 = icmp eq i32 %1, %7
  %9 = add i32 %6, %4
  %spec.select = select i1 %8, i32 %3, i32 %9
  %.unpack = load ptr, ptr %loadgep_2, align 8, !tbaa !8
  %.elt14 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  %.unpack15 = load i64, ptr %.elt14, align 8, !tbaa !8
  %.elt16 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  %.unpack17 = load i32, ptr %.elt16, align 8, !tbaa !8
  %.elt18 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  %.unpack19 = load i8, ptr %.elt18, align 4, !tbaa !8
  %.elt20 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  %.unpack21 = load i8, ptr %.elt20, align 1, !tbaa !8
  %.elt22 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  %.unpack23 = load i8, ptr %.elt22, align 2, !tbaa !8
  %.elt24 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  %.unpack25 = load i8, ptr %.elt24, align 1, !tbaa !8
  %.elt26 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  %.unpack27.unpack.unpack = load i64, ptr %.elt26, align 8, !tbaa !8
  %.unpack27.unpack.elt29 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  %.unpack27.unpack.unpack30 = load i64, ptr %.unpack27.unpack.elt29, align 8, !tbaa !8
  %.unpack27.unpack.elt31 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  %.unpack27.unpack.unpack32 = load i64, ptr %.unpack27.unpack.elt31, align 8, !tbaa !8
  store ptr %.unpack, ptr %loadgep_4, align 8, !tbaa !8
  %loadgep_4.repack34 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 1
  store i64 %.unpack15, ptr %loadgep_4.repack34, align 8, !tbaa !8
  %loadgep_4.repack36 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 2
  store i32 %.unpack17, ptr %loadgep_4.repack36, align 8, !tbaa !8
  %loadgep_4.repack38 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 3
  store i8 %.unpack19, ptr %loadgep_4.repack38, align 4, !tbaa !8
  %loadgep_4.repack40 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 4
  store i8 %.unpack21, ptr %loadgep_4.repack40, align 1, !tbaa !8
  %loadgep_4.repack42 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 5
  store i8 %.unpack23, ptr %loadgep_4.repack42, align 2, !tbaa !8
  %loadgep_4.repack44 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 6
  store i8 %.unpack25, ptr %loadgep_4.repack44, align 1, !tbaa !8
  %loadgep_4.repack46 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7
  store i64 %.unpack27.unpack.unpack, ptr %loadgep_4.repack46, align 8, !tbaa !8
  %loadgep_4.repack46.repack48 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack27.unpack.unpack30, ptr %loadgep_4.repack46.repack48, align 8, !tbaa !8
  %loadgep_4.repack46.repack50 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 2
  store i64 %.unpack27.unpack.unpack32, ptr %loadgep_4.repack46.repack50, align 8, !tbaa !8
  %10 = icmp eq i64 %.unpack27.unpack.unpack30, 0
  %11 = select i1 %10, i64 1, i64 %.unpack27.unpack.unpack
  store ptr %.unpack, ptr %loadgep_6, align 8, !tbaa !8
  %loadgep_6.repack52 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 1
  store i64 8, ptr %loadgep_6.repack52, align 8, !tbaa !8
  %loadgep_6.repack54 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 2
  store i32 20180515, ptr %loadgep_6.repack54, align 8, !tbaa !8
  %loadgep_6.repack56 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 3
  store i8 1, ptr %loadgep_6.repack56, align 4, !tbaa !8
  %loadgep_6.repack58 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 4
  store i8 28, ptr %loadgep_6.repack58, align 1, !tbaa !8
  %loadgep_6.repack60 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 5
  store i8 0, ptr %loadgep_6.repack60, align 2, !tbaa !8
  %loadgep_6.repack62 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 6
  store i8 0, ptr %loadgep_6.repack62, align 1, !tbaa !8
  %loadgep_6.repack64 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7
  store i64 %11, ptr %loadgep_6.repack64, align 8, !tbaa !8
  %loadgep_6.repack64.repack66 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack27.unpack.unpack30, ptr %loadgep_6.repack64.repack66, align 8, !tbaa !8
  %loadgep_6.repack64.repack68 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7, i64 0, i64 2
  store i64 8, ptr %loadgep_6.repack64.repack68, align 8, !tbaa !8
  %12 = load ptr, ptr %loadgep_8, align 8, !tbaa !4
  %13 = getelementptr { ptr, ptr }, ptr %loadgep_8, i64 0, i32 1
  %14 = load ptr, ptr %13, align 8, !tbaa !4
  %15 = sext i32 %6 to i64
  %16 = sext i32 %spec.select to i64
  %reass.sub9.i = sub nsw i64 %16, %15
  %17 = icmp sgt i64 %reass.sub9.i, -1
  br i1 %17, label %.lr.ph8.preheader.i, label %_QFPloop.exit

.lr.ph8.preheader.i:                              ; preds = %omp.par.entry
  %18 = add nuw nsw i64 %reass.sub9.i, 1
  br label %.lr.ph8.i

.lr.ph8.i:                                        ; preds = %.lr.ph8.i, %.lr.ph8.preheader.i
  %19 = phi i64 [ %29, %.lr.ph8.i ], [ %18, %.lr.ph8.preheader.i ]
  %20 = phi i32 [ %28, %.lr.ph8.i ], [ %6, %.lr.ph8.preheader.i ]
  %21 = load i32, ptr %12, align 4, !tbaa !4
  %22 = sitofp i32 %21 to float
  %23 = fdiv contract float 1.000000e+00, %22
  %24 = fpext float %23 to double
  %25 = sext i32 %20 to i64
  %26 = add nsw i64 %25, -1
  %27 = getelementptr double, ptr %.unpack, i64 %26
  store double %24, ptr %27, align 8, !tbaa !4
  store double %24, ptr %14, align 8, !tbaa !4
  %28 = add i32 %20, 1
  %29 = add nsw i64 %19, -1
  %30 = icmp ugt i64 %19, 1
  br i1 %30, label %.lr.ph8.i, label %_QFPloop.exit

_QFPloop.exit:                                    ; preds = %.lr.ph8.i, %omp.par.entry
  ret void
}

; Function Attrs: nofree norecurse nosync nounwind memory(readwrite, inaccessiblemem: none)
define void @_QFPloop(ptr nocapture readonly %0, ptr nocapture readonly %1, ptr nocapture readonly %2, ptr nest nocapture readonly %3) local_unnamed_addr #4 {
  %5 = load ptr, ptr %3, align 8, !tbaa !4
  %6 = getelementptr { ptr, ptr }, ptr %3, i64 0, i32 1
  %7 = load ptr, ptr %6, align 8, !tbaa !4
  %8 = load i32, ptr %0, align 4, !tbaa !4
  %9 = sext i32 %8 to i64
  %10 = load i32, ptr %1, align 4, !tbaa !4
  %11 = sext i32 %10 to i64
  %12 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %2, i64 0, i32 7, i64 0, i64 2
  %13 = load i64, ptr %12, align 8, !tbaa !8
  %14 = icmp eq i64 %13, 8
  br i1 %14, label %15, label %31

15:                                               ; preds = %4
  %16 = load ptr, ptr %2, align 8, !tbaa !8
  %reass.sub9 = sub nsw i64 %11, %9
  %17 = icmp sgt i64 %reass.sub9, -1
  br i1 %17, label %.lr.ph8.preheader, label %.loopexit

.lr.ph8.preheader:                                ; preds = %15
  %18 = add nuw nsw i64 %reass.sub9, 1
  br label %.lr.ph8

.lr.ph8:                                          ; preds = %.lr.ph8.preheader, %.lr.ph8
  %19 = phi i64 [ %29, %.lr.ph8 ], [ %18, %.lr.ph8.preheader ]
  %20 = phi i32 [ %28, %.lr.ph8 ], [ %8, %.lr.ph8.preheader ]
  %21 = load i32, ptr %5, align 4, !tbaa !4
  %22 = sitofp i32 %21 to float
  %23 = fdiv contract float 1.000000e+00, %22
  %24 = fpext float %23 to double
  %25 = sext i32 %20 to i64
  %26 = add nsw i64 %25, -1
  %27 = getelementptr double, ptr %16, i64 %26
  store double %24, ptr %27, align 8, !tbaa !4
  store double %24, ptr %7, align 8, !tbaa !4
  %28 = add i32 %20, 1
  %29 = add nsw i64 %19, -1
  %30 = icmp ugt i64 %19, 1
  br i1 %30, label %.lr.ph8, label %.loopexit

31:                                               ; preds = %4
  %reass.sub = sub nsw i64 %11, %9
  %32 = icmp sgt i64 %reass.sub, -1
  br i1 %32, label %.lr.ph, label %.loopexit

.lr.ph:                                           ; preds = %31
  %33 = add nuw nsw i64 %reass.sub, 1
  %34 = load ptr, ptr %2, align 8, !tbaa !8
  br label %35

35:                                               ; preds = %.lr.ph, %35
  %36 = phi i64 [ %33, %.lr.ph ], [ %47, %35 ]
  %37 = phi i32 [ %8, %.lr.ph ], [ %46, %35 ]
  %38 = load i32, ptr %5, align 4, !tbaa !4
  %39 = sitofp i32 %38 to float
  %40 = fdiv contract float 1.000000e+00, %39
  %41 = fpext float %40 to double
  %42 = sext i32 %37 to i64
  %43 = add nsw i64 %42, -1
  %44 = mul i64 %43, %13
  %45 = getelementptr i8, ptr %34, i64 %44
  store double %41, ptr %45, align 8, !tbaa !4
  store double %41, ptr %7, align 8, !tbaa !4
  %46 = add i32 %37, 1
  %47 = add nsw i64 %36, -1
  %48 = icmp ugt i64 %36, 1
  br i1 %48, label %35, label %.loopexit

.loopexit:                                        ; preds = %35, %.lr.ph8, %31, %15
  ret void
}

declare ptr @_FortranAioBeginExternalFormattedOutput(ptr, i64, ptr, i32, ptr, i32) local_unnamed_addr

declare zeroext i1 @_FortranAioOutputAscii(ptr, ptr, i64) local_unnamed_addr

declare zeroext i1 @_FortranAioOutputInteger32(ptr, i32) local_unnamed_addr

declare zeroext i1 @_FortranAioOutputReal64(ptr, double) local_unnamed_addr

declare i32 @_FortranAioEndIoStatement(ptr) local_unnamed_addr

; Function Attrs: nounwind
declare i32 @omp_get_thread_num() local_unnamed_addr #2

; Function Attrs: nounwind
declare i32 @omp_get_num_threads() local_unnamed_addr #2

; Function Attrs: nounwind
declare i32 @__kmpc_global_thread_num(ptr) local_unnamed_addr #2

; Function Attrs: nounwind
declare !callback !10 void @__kmpc_fork_call(ptr, i32, ptr, ...) local_unnamed_addr #2

; Function Attrs: nocallback nofree nosync nounwind speculatable willreturn memory(none)
declare i32 @llvm.smax.i32(i32, i32) #5

; Function Attrs: nocallback nofree nosync nounwind willreturn memory(argmem: readwrite)
declare void @llvm.lifetime.start.p0(i64 immarg, ptr nocapture) #6

; Function Attrs: nocallback nofree nosync nounwind willreturn memory(argmem: readwrite)
declare void @llvm.lifetime.end.p0(i64 immarg, ptr nocapture) #6

attributes #0 = { mustprogress nofree nounwind willreturn allockind("alloc,uninitialized") allocsize(0) memory(inaccessiblemem: readwrite) "alloc-family"="malloc" }
attributes #1 = { mustprogress nounwind willreturn allockind("free") memory(argmem: readwrite, inaccessiblemem: readwrite) "alloc-family"="malloc" }
attributes #2 = { nounwind }
attributes #3 = { norecurse nounwind }
attributes #4 = { nofree norecurse nosync nounwind memory(readwrite, inaccessiblemem: none) }
attributes #5 = { nocallback nofree nosync nounwind speculatable willreturn memory(none) }
attributes #6 = { nocallback nofree nosync nounwind willreturn memory(argmem: readwrite) }

!llvm.module.flags = !{!0, !1, !2, !3}

!0 = !{i32 2, !"Debug Info Version", i32 3}
!1 = !{i32 7, !"openmp", i32 11}
!2 = !{i32 8, !"PIC Level", i32 2}
!3 = !{i32 7, !"PIE Level", i32 2}
!4 = !{!5, !5, i64 0}
!5 = !{!"any data access", !6, i64 0}
!6 = !{!"any access", !7, i64 0}
!7 = !{!"Flang Type TBAA Root"}
!8 = !{!9, !9, i64 0}
!9 = !{!"descriptor member", !6, i64 0}
!10 = !{!11}
!11 = !{i64 2, i64 -1, i64 -1, i1 true}
*** IR Dump After ReversePostOrderFunctionAttrsPass on [module] ***
; ModuleID = 'FIRModule'
source_filename = "FIRModule"
target datalayout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128"
target triple = "x86_64-unknown-linux-gnu"

%struct.ident_t = type { i32, i32, i32, i32, ptr }

@_QQcl.28612C69372C612C6531332E36653229 = internal constant [16 x i8] c"(a,i7,a,e13.6e2)"
@_QQcl.e8a0ac9186c064ac8543d822e9060d96 = internal constant [59 x i8] c"/g/g92/rydahl1/flangtests/src/parallel_region_outlined.f90\00"
@_QQcl.54686520726573756C74206F6620286172722831292B61727228 = internal constant [26 x i8] c"The result of (arr(1)+arr("
@_QQcl.2920697320 = internal constant [5 x i8] c") is "
@_QQEnvironmentDefaults = local_unnamed_addr constant ptr null
@0 = private unnamed_addr constant [23 x i8] c";unknown;unknown;0;0;;\00", align 1
@1 = private unnamed_addr constant %struct.ident_t { i32 0, i32 2, i32 0, i32 22, ptr @0 }, align 8

; Function Attrs: mustprogress nofree nounwind willreturn allockind("alloc,uninitialized") allocsize(0) memory(inaccessiblemem: readwrite)
declare noalias noundef ptr @malloc(i64 noundef) local_unnamed_addr #0

; Function Attrs: mustprogress nounwind willreturn allockind("free") memory(argmem: readwrite, inaccessiblemem: readwrite)
declare void @free(ptr allocptr nocapture noundef) local_unnamed_addr #1

define void @_QQmain() local_unnamed_addr {
  %structArg.i = alloca { ptr, ptr, ptr, ptr, ptr }, align 8
  %1 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %2 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %3 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %4 = alloca i32, align 4
  %5 = alloca double, align 8
  %6 = alloca { ptr, ptr }, align 8
  store ptr %4, ptr %6, align 8, !tbaa !4
  %7 = getelementptr inbounds { ptr, ptr }, ptr %6, i64 0, i32 1
  store ptr %5, ptr %7, align 8, !tbaa !4
  store i32 1048576, ptr %4, align 4, !tbaa !4
  call void @llvm.lifetime.start.p0(i64 40, ptr nonnull %structArg.i)
  call void @llvm.lifetime.start.p0(i64 48, ptr nonnull %1)
  call void @llvm.lifetime.start.p0(i64 48, ptr nonnull %2)
  call void @llvm.lifetime.start.p0(i64 48, ptr nonnull %3)
  %.fca.1.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 1
  %.fca.2.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 2
  %.fca.3.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 3
  %.fca.4.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 4
  %.fca.5.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 5
  %.fca.6.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 6
  %.fca.7.0.0.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 7, i64 0, i64 0
  %.fca.7.0.1.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 7, i64 0, i64 1
  %.fca.7.0.2.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 7, i64 0, i64 2
  %8 = call dereferenceable_or_null(8388608) ptr @malloc(i64 8388608)
  store ptr %8, ptr %3, align 8, !tbaa !8
  store i64 8, ptr %.fca.1.gep.i, align 8, !tbaa !8
  store i32 20180515, ptr %.fca.2.gep.i, align 8, !tbaa !8
  store i8 1, ptr %.fca.3.gep.i, align 4, !tbaa !8
  store i8 28, ptr %.fca.4.gep.i, align 1, !tbaa !8
  store i8 2, ptr %.fca.5.gep.i, align 2, !tbaa !8
  store i8 0, ptr %.fca.6.gep.i, align 1, !tbaa !8
  store i64 1, ptr %.fca.7.0.0.gep.i, align 8, !tbaa !8
  store i64 1048576, ptr %.fca.7.0.1.gep.i, align 8, !tbaa !8
  store i64 8, ptr %.fca.7.0.2.gep.i, align 8, !tbaa !8
  %omp_global_thread_num.i = call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %4, ptr %structArg.i, align 8
  %gep_5.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 1
  store ptr %3, ptr %gep_5.i, align 8
  %gep_6.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 2
  store ptr %2, ptr %gep_6.i, align 8
  %gep_7.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 3
  store ptr %1, ptr %gep_7.i, align 8
  %gep_8.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 4
  store ptr %6, ptr %gep_8.i, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QFPomp_subroutine..omp_par, ptr nonnull %structArg.i)
  %.fca.0.load.i = load ptr, ptr %3, align 8, !tbaa !8
  %.fca.7.0.0.load.i = load i64, ptr %.fca.7.0.0.gep.i, align 8, !tbaa !8
  %9 = sub i64 1, %.fca.7.0.0.load.i
  %10 = getelementptr double, ptr %.fca.0.load.i, i64 %9
  %11 = load double, ptr %10, align 8, !tbaa !4
  %12 = load i32, ptr %4, align 4, !tbaa !4
  %13 = sext i32 %12 to i64
  %14 = sub i64 %13, %.fca.7.0.0.load.i
  %15 = getelementptr double, ptr %.fca.0.load.i, i64 %14
  %16 = load double, ptr %15, align 8, !tbaa !4
  %17 = fadd contract double %11, %16
  call void @free(ptr %.fca.0.load.i)
  call void @llvm.lifetime.end.p0(i64 40, ptr nonnull %structArg.i)
  call void @llvm.lifetime.end.p0(i64 48, ptr nonnull %1)
  call void @llvm.lifetime.end.p0(i64 48, ptr nonnull %2)
  call void @llvm.lifetime.end.p0(i64 48, ptr nonnull %3)
  %18 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.e8a0ac9186c064ac8543d822e9060d96, i32 10)
  %19 = call i1 @_FortranAioOutputAscii(ptr %18, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %20 = load i32, ptr %4, align 4, !tbaa !4
  %21 = call i1 @_FortranAioOutputInteger32(ptr %18, i32 %20)
  %22 = call i1 @_FortranAioOutputAscii(ptr %18, ptr nonnull @_QQcl.2920697320, i64 5)
  %23 = call i1 @_FortranAioOutputReal64(ptr %18, double %17)
  %24 = call i32 @_FortranAioEndIoStatement(ptr %18)
  ret void
}

; Function Attrs: nounwind
define void @_QFPomp_subroutine(ptr %0, ptr nocapture writeonly %1, ptr nest %2) local_unnamed_addr #2 {
entry:
  %structArg = alloca { ptr, ptr, ptr, ptr, ptr }, align 8
  %3 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %4 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %5 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %.fca.1.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 1
  %.fca.2.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 2
  %.fca.3.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 3
  %.fca.4.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 4
  %.fca.5.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 5
  %.fca.6.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 6
  %.fca.7.0.0.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 0
  %.fca.7.0.1.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 1
  %.fca.7.0.2.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 2
  %6 = load i32, ptr %0, align 4, !tbaa !4
  %7 = tail call i32 @llvm.smax.i32(i32 %6, i32 0)
  %8 = zext i32 %7 to i64
  %9 = shl nuw nsw i64 %8, 3
  %10 = tail call ptr @malloc(i64 %9)
  store ptr %10, ptr %5, align 8, !tbaa !8
  store i64 8, ptr %.fca.1.gep, align 8, !tbaa !8
  store i32 20180515, ptr %.fca.2.gep, align 8, !tbaa !8
  store i8 1, ptr %.fca.3.gep, align 4, !tbaa !8
  store i8 28, ptr %.fca.4.gep, align 1, !tbaa !8
  store i8 2, ptr %.fca.5.gep, align 2, !tbaa !8
  store i8 0, ptr %.fca.6.gep, align 1, !tbaa !8
  store i64 1, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  store i64 %8, ptr %.fca.7.0.1.gep, align 8, !tbaa !8
  store i64 8, ptr %.fca.7.0.2.gep, align 8, !tbaa !8
  %omp_global_thread_num = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %0, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %5, ptr %gep_5, align 8
  %gep_6 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 2
  store ptr %4, ptr %gep_6, align 8
  %gep_7 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 3
  store ptr %3, ptr %gep_7, align 8
  %gep_8 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 4
  store ptr %2, ptr %gep_8, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QFPomp_subroutine..omp_par, ptr nonnull %structArg)
  %.fca.0.load = load ptr, ptr %5, align 8, !tbaa !8
  %.fca.7.0.0.load = load i64, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  %11 = sub i64 1, %.fca.7.0.0.load
  %12 = getelementptr double, ptr %.fca.0.load, i64 %11
  %13 = load double, ptr %12, align 8, !tbaa !4
  %14 = load i32, ptr %0, align 4, !tbaa !4
  %15 = sext i32 %14 to i64
  %16 = sub i64 %15, %.fca.7.0.0.load
  %17 = getelementptr double, ptr %.fca.0.load, i64 %16
  %18 = load double, ptr %17, align 8, !tbaa !4
  %19 = fadd contract double %13, %18
  store double %19, ptr %1, align 8, !tbaa !4
  call void @free(ptr %.fca.0.load)
  ret void
}

; Function Attrs: norecurse nounwind
define internal void @_QFPomp_subroutine..omp_par(ptr noalias nocapture readnone %tid.addr, ptr noalias nocapture readnone %zero.addr, ptr nocapture readonly %0) #3 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %gep_3 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 2
  %loadgep_4 = load ptr, ptr %gep_3, align 8
  %gep_5 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 3
  %loadgep_6 = load ptr, ptr %gep_5, align 8
  %gep_7 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 4
  %loadgep_8 = load ptr, ptr %gep_7, align 8
  %1 = tail call i32 @omp_get_thread_num()
  %2 = tail call i32 @omp_get_num_threads()
  %3 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %4 = sdiv i32 %3, %2
  %5 = mul i32 %4, %1
  %6 = add i32 %5, 1
  %7 = add i32 %2, -1
  %8 = icmp eq i32 %1, %7
  %9 = add i32 %6, %4
  %spec.select = select i1 %8, i32 %3, i32 %9
  %.unpack = load ptr, ptr %loadgep_2, align 8, !tbaa !8
  %.elt14 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  %.unpack15 = load i64, ptr %.elt14, align 8, !tbaa !8
  %.elt16 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  %.unpack17 = load i32, ptr %.elt16, align 8, !tbaa !8
  %.elt18 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  %.unpack19 = load i8, ptr %.elt18, align 4, !tbaa !8
  %.elt20 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  %.unpack21 = load i8, ptr %.elt20, align 1, !tbaa !8
  %.elt22 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  %.unpack23 = load i8, ptr %.elt22, align 2, !tbaa !8
  %.elt24 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  %.unpack25 = load i8, ptr %.elt24, align 1, !tbaa !8
  %.elt26 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  %.unpack27.unpack.unpack = load i64, ptr %.elt26, align 8, !tbaa !8
  %.unpack27.unpack.elt29 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  %.unpack27.unpack.unpack30 = load i64, ptr %.unpack27.unpack.elt29, align 8, !tbaa !8
  %.unpack27.unpack.elt31 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  %.unpack27.unpack.unpack32 = load i64, ptr %.unpack27.unpack.elt31, align 8, !tbaa !8
  store ptr %.unpack, ptr %loadgep_4, align 8, !tbaa !8
  %loadgep_4.repack34 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 1
  store i64 %.unpack15, ptr %loadgep_4.repack34, align 8, !tbaa !8
  %loadgep_4.repack36 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 2
  store i32 %.unpack17, ptr %loadgep_4.repack36, align 8, !tbaa !8
  %loadgep_4.repack38 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 3
  store i8 %.unpack19, ptr %loadgep_4.repack38, align 4, !tbaa !8
  %loadgep_4.repack40 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 4
  store i8 %.unpack21, ptr %loadgep_4.repack40, align 1, !tbaa !8
  %loadgep_4.repack42 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 5
  store i8 %.unpack23, ptr %loadgep_4.repack42, align 2, !tbaa !8
  %loadgep_4.repack44 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 6
  store i8 %.unpack25, ptr %loadgep_4.repack44, align 1, !tbaa !8
  %loadgep_4.repack46 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7
  store i64 %.unpack27.unpack.unpack, ptr %loadgep_4.repack46, align 8, !tbaa !8
  %loadgep_4.repack46.repack48 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack27.unpack.unpack30, ptr %loadgep_4.repack46.repack48, align 8, !tbaa !8
  %loadgep_4.repack46.repack50 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 2
  store i64 %.unpack27.unpack.unpack32, ptr %loadgep_4.repack46.repack50, align 8, !tbaa !8
  %10 = icmp eq i64 %.unpack27.unpack.unpack30, 0
  %11 = select i1 %10, i64 1, i64 %.unpack27.unpack.unpack
  store ptr %.unpack, ptr %loadgep_6, align 8, !tbaa !8
  %loadgep_6.repack52 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 1
  store i64 8, ptr %loadgep_6.repack52, align 8, !tbaa !8
  %loadgep_6.repack54 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 2
  store i32 20180515, ptr %loadgep_6.repack54, align 8, !tbaa !8
  %loadgep_6.repack56 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 3
  store i8 1, ptr %loadgep_6.repack56, align 4, !tbaa !8
  %loadgep_6.repack58 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 4
  store i8 28, ptr %loadgep_6.repack58, align 1, !tbaa !8
  %loadgep_6.repack60 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 5
  store i8 0, ptr %loadgep_6.repack60, align 2, !tbaa !8
  %loadgep_6.repack62 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 6
  store i8 0, ptr %loadgep_6.repack62, align 1, !tbaa !8
  %loadgep_6.repack64 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7
  store i64 %11, ptr %loadgep_6.repack64, align 8, !tbaa !8
  %loadgep_6.repack64.repack66 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack27.unpack.unpack30, ptr %loadgep_6.repack64.repack66, align 8, !tbaa !8
  %loadgep_6.repack64.repack68 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7, i64 0, i64 2
  store i64 8, ptr %loadgep_6.repack64.repack68, align 8, !tbaa !8
  %12 = load ptr, ptr %loadgep_8, align 8, !tbaa !4
  %13 = getelementptr { ptr, ptr }, ptr %loadgep_8, i64 0, i32 1
  %14 = load ptr, ptr %13, align 8, !tbaa !4
  %15 = sext i32 %6 to i64
  %16 = sext i32 %spec.select to i64
  %reass.sub9.i = sub nsw i64 %16, %15
  %17 = icmp sgt i64 %reass.sub9.i, -1
  br i1 %17, label %.lr.ph8.preheader.i, label %_QFPloop.exit

.lr.ph8.preheader.i:                              ; preds = %omp.par.entry
  %18 = add nuw nsw i64 %reass.sub9.i, 1
  br label %.lr.ph8.i

.lr.ph8.i:                                        ; preds = %.lr.ph8.i, %.lr.ph8.preheader.i
  %19 = phi i64 [ %29, %.lr.ph8.i ], [ %18, %.lr.ph8.preheader.i ]
  %20 = phi i32 [ %28, %.lr.ph8.i ], [ %6, %.lr.ph8.preheader.i ]
  %21 = load i32, ptr %12, align 4, !tbaa !4
  %22 = sitofp i32 %21 to float
  %23 = fdiv contract float 1.000000e+00, %22
  %24 = fpext float %23 to double
  %25 = sext i32 %20 to i64
  %26 = add nsw i64 %25, -1
  %27 = getelementptr double, ptr %.unpack, i64 %26
  store double %24, ptr %27, align 8, !tbaa !4
  store double %24, ptr %14, align 8, !tbaa !4
  %28 = add i32 %20, 1
  %29 = add nsw i64 %19, -1
  %30 = icmp ugt i64 %19, 1
  br i1 %30, label %.lr.ph8.i, label %_QFPloop.exit

_QFPloop.exit:                                    ; preds = %.lr.ph8.i, %omp.par.entry
  ret void
}

; Function Attrs: nofree norecurse nosync nounwind memory(readwrite, inaccessiblemem: none)
define void @_QFPloop(ptr nocapture readonly %0, ptr nocapture readonly %1, ptr nocapture readonly %2, ptr nest nocapture readonly %3) local_unnamed_addr #4 {
  %5 = load ptr, ptr %3, align 8, !tbaa !4
  %6 = getelementptr { ptr, ptr }, ptr %3, i64 0, i32 1
  %7 = load ptr, ptr %6, align 8, !tbaa !4
  %8 = load i32, ptr %0, align 4, !tbaa !4
  %9 = sext i32 %8 to i64
  %10 = load i32, ptr %1, align 4, !tbaa !4
  %11 = sext i32 %10 to i64
  %12 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %2, i64 0, i32 7, i64 0, i64 2
  %13 = load i64, ptr %12, align 8, !tbaa !8
  %14 = icmp eq i64 %13, 8
  br i1 %14, label %15, label %31

15:                                               ; preds = %4
  %16 = load ptr, ptr %2, align 8, !tbaa !8
  %reass.sub9 = sub nsw i64 %11, %9
  %17 = icmp sgt i64 %reass.sub9, -1
  br i1 %17, label %.lr.ph8.preheader, label %.loopexit

.lr.ph8.preheader:                                ; preds = %15
  %18 = add nuw nsw i64 %reass.sub9, 1
  br label %.lr.ph8

.lr.ph8:                                          ; preds = %.lr.ph8.preheader, %.lr.ph8
  %19 = phi i64 [ %29, %.lr.ph8 ], [ %18, %.lr.ph8.preheader ]
  %20 = phi i32 [ %28, %.lr.ph8 ], [ %8, %.lr.ph8.preheader ]
  %21 = load i32, ptr %5, align 4, !tbaa !4
  %22 = sitofp i32 %21 to float
  %23 = fdiv contract float 1.000000e+00, %22
  %24 = fpext float %23 to double
  %25 = sext i32 %20 to i64
  %26 = add nsw i64 %25, -1
  %27 = getelementptr double, ptr %16, i64 %26
  store double %24, ptr %27, align 8, !tbaa !4
  store double %24, ptr %7, align 8, !tbaa !4
  %28 = add i32 %20, 1
  %29 = add nsw i64 %19, -1
  %30 = icmp ugt i64 %19, 1
  br i1 %30, label %.lr.ph8, label %.loopexit

31:                                               ; preds = %4
  %reass.sub = sub nsw i64 %11, %9
  %32 = icmp sgt i64 %reass.sub, -1
  br i1 %32, label %.lr.ph, label %.loopexit

.lr.ph:                                           ; preds = %31
  %33 = add nuw nsw i64 %reass.sub, 1
  %34 = load ptr, ptr %2, align 8, !tbaa !8
  br label %35

35:                                               ; preds = %.lr.ph, %35
  %36 = phi i64 [ %33, %.lr.ph ], [ %47, %35 ]
  %37 = phi i32 [ %8, %.lr.ph ], [ %46, %35 ]
  %38 = load i32, ptr %5, align 4, !tbaa !4
  %39 = sitofp i32 %38 to float
  %40 = fdiv contract float 1.000000e+00, %39
  %41 = fpext float %40 to double
  %42 = sext i32 %37 to i64
  %43 = add nsw i64 %42, -1
  %44 = mul i64 %43, %13
  %45 = getelementptr i8, ptr %34, i64 %44
  store double %41, ptr %45, align 8, !tbaa !4
  store double %41, ptr %7, align 8, !tbaa !4
  %46 = add i32 %37, 1
  %47 = add nsw i64 %36, -1
  %48 = icmp ugt i64 %36, 1
  br i1 %48, label %35, label %.loopexit

.loopexit:                                        ; preds = %35, %.lr.ph8, %31, %15
  ret void
}

declare ptr @_FortranAioBeginExternalFormattedOutput(ptr, i64, ptr, i32, ptr, i32) local_unnamed_addr

declare zeroext i1 @_FortranAioOutputAscii(ptr, ptr, i64) local_unnamed_addr

declare zeroext i1 @_FortranAioOutputInteger32(ptr, i32) local_unnamed_addr

declare zeroext i1 @_FortranAioOutputReal64(ptr, double) local_unnamed_addr

declare i32 @_FortranAioEndIoStatement(ptr) local_unnamed_addr

; Function Attrs: nounwind
declare i32 @omp_get_thread_num() local_unnamed_addr #2

; Function Attrs: nounwind
declare i32 @omp_get_num_threads() local_unnamed_addr #2

; Function Attrs: nounwind
declare i32 @__kmpc_global_thread_num(ptr) local_unnamed_addr #2

; Function Attrs: nounwind
declare !callback !10 void @__kmpc_fork_call(ptr, i32, ptr, ...) local_unnamed_addr #2

; Function Attrs: nocallback nofree nosync nounwind speculatable willreturn memory(none)
declare i32 @llvm.smax.i32(i32, i32) #5

; Function Attrs: nocallback nofree nosync nounwind willreturn memory(argmem: readwrite)
declare void @llvm.lifetime.start.p0(i64 immarg, ptr nocapture) #6

; Function Attrs: nocallback nofree nosync nounwind willreturn memory(argmem: readwrite)
declare void @llvm.lifetime.end.p0(i64 immarg, ptr nocapture) #6

attributes #0 = { mustprogress nofree nounwind willreturn allockind("alloc,uninitialized") allocsize(0) memory(inaccessiblemem: readwrite) "alloc-family"="malloc" }
attributes #1 = { mustprogress nounwind willreturn allockind("free") memory(argmem: readwrite, inaccessiblemem: readwrite) "alloc-family"="malloc" }
attributes #2 = { nounwind }
attributes #3 = { norecurse nounwind }
attributes #4 = { nofree norecurse nosync nounwind memory(readwrite, inaccessiblemem: none) }
attributes #5 = { nocallback nofree nosync nounwind speculatable willreturn memory(none) }
attributes #6 = { nocallback nofree nosync nounwind willreturn memory(argmem: readwrite) }

!llvm.module.flags = !{!0, !1, !2, !3}

!0 = !{i32 2, !"Debug Info Version", i32 3}
!1 = !{i32 7, !"openmp", i32 11}
!2 = !{i32 8, !"PIC Level", i32 2}
!3 = !{i32 7, !"PIE Level", i32 2}
!4 = !{!5, !5, i64 0}
!5 = !{!"any data access", !6, i64 0}
!6 = !{!"any access", !7, i64 0}
!7 = !{!"Flang Type TBAA Root"}
!8 = !{!9, !9, i64 0}
!9 = !{!"descriptor member", !6, i64 0}
!10 = !{!11}
!11 = !{i64 2, i64 -1, i64 -1, i1 true}
*** IR Dump After RecomputeGlobalsAAPass on [module] ***
; ModuleID = 'FIRModule'
source_filename = "FIRModule"
target datalayout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128"
target triple = "x86_64-unknown-linux-gnu"

%struct.ident_t = type { i32, i32, i32, i32, ptr }

@_QQcl.28612C69372C612C6531332E36653229 = internal constant [16 x i8] c"(a,i7,a,e13.6e2)"
@_QQcl.e8a0ac9186c064ac8543d822e9060d96 = internal constant [59 x i8] c"/g/g92/rydahl1/flangtests/src/parallel_region_outlined.f90\00"
@_QQcl.54686520726573756C74206F6620286172722831292B61727228 = internal constant [26 x i8] c"The result of (arr(1)+arr("
@_QQcl.2920697320 = internal constant [5 x i8] c") is "
@_QQEnvironmentDefaults = local_unnamed_addr constant ptr null
@0 = private unnamed_addr constant [23 x i8] c";unknown;unknown;0;0;;\00", align 1
@1 = private unnamed_addr constant %struct.ident_t { i32 0, i32 2, i32 0, i32 22, ptr @0 }, align 8

; Function Attrs: mustprogress nofree nounwind willreturn allockind("alloc,uninitialized") allocsize(0) memory(inaccessiblemem: readwrite)
declare noalias noundef ptr @malloc(i64 noundef) local_unnamed_addr #0

; Function Attrs: mustprogress nounwind willreturn allockind("free") memory(argmem: readwrite, inaccessiblemem: readwrite)
declare void @free(ptr allocptr nocapture noundef) local_unnamed_addr #1

define void @_QQmain() local_unnamed_addr {
  %structArg.i = alloca { ptr, ptr, ptr, ptr, ptr }, align 8
  %1 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %2 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %3 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %4 = alloca i32, align 4
  %5 = alloca double, align 8
  %6 = alloca { ptr, ptr }, align 8
  store ptr %4, ptr %6, align 8, !tbaa !4
  %7 = getelementptr inbounds { ptr, ptr }, ptr %6, i64 0, i32 1
  store ptr %5, ptr %7, align 8, !tbaa !4
  store i32 1048576, ptr %4, align 4, !tbaa !4
  call void @llvm.lifetime.start.p0(i64 40, ptr nonnull %structArg.i)
  call void @llvm.lifetime.start.p0(i64 48, ptr nonnull %1)
  call void @llvm.lifetime.start.p0(i64 48, ptr nonnull %2)
  call void @llvm.lifetime.start.p0(i64 48, ptr nonnull %3)
  %.fca.1.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 1
  %.fca.2.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 2
  %.fca.3.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 3
  %.fca.4.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 4
  %.fca.5.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 5
  %.fca.6.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 6
  %.fca.7.0.0.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 7, i64 0, i64 0
  %.fca.7.0.1.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 7, i64 0, i64 1
  %.fca.7.0.2.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 7, i64 0, i64 2
  %8 = call dereferenceable_or_null(8388608) ptr @malloc(i64 8388608)
  store ptr %8, ptr %3, align 8, !tbaa !8
  store i64 8, ptr %.fca.1.gep.i, align 8, !tbaa !8
  store i32 20180515, ptr %.fca.2.gep.i, align 8, !tbaa !8
  store i8 1, ptr %.fca.3.gep.i, align 4, !tbaa !8
  store i8 28, ptr %.fca.4.gep.i, align 1, !tbaa !8
  store i8 2, ptr %.fca.5.gep.i, align 2, !tbaa !8
  store i8 0, ptr %.fca.6.gep.i, align 1, !tbaa !8
  store i64 1, ptr %.fca.7.0.0.gep.i, align 8, !tbaa !8
  store i64 1048576, ptr %.fca.7.0.1.gep.i, align 8, !tbaa !8
  store i64 8, ptr %.fca.7.0.2.gep.i, align 8, !tbaa !8
  %omp_global_thread_num.i = call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %4, ptr %structArg.i, align 8
  %gep_5.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 1
  store ptr %3, ptr %gep_5.i, align 8
  %gep_6.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 2
  store ptr %2, ptr %gep_6.i, align 8
  %gep_7.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 3
  store ptr %1, ptr %gep_7.i, align 8
  %gep_8.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 4
  store ptr %6, ptr %gep_8.i, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QFPomp_subroutine..omp_par, ptr nonnull %structArg.i)
  %.fca.0.load.i = load ptr, ptr %3, align 8, !tbaa !8
  %.fca.7.0.0.load.i = load i64, ptr %.fca.7.0.0.gep.i, align 8, !tbaa !8
  %9 = sub i64 1, %.fca.7.0.0.load.i
  %10 = getelementptr double, ptr %.fca.0.load.i, i64 %9
  %11 = load double, ptr %10, align 8, !tbaa !4
  %12 = load i32, ptr %4, align 4, !tbaa !4
  %13 = sext i32 %12 to i64
  %14 = sub i64 %13, %.fca.7.0.0.load.i
  %15 = getelementptr double, ptr %.fca.0.load.i, i64 %14
  %16 = load double, ptr %15, align 8, !tbaa !4
  %17 = fadd contract double %11, %16
  call void @free(ptr %.fca.0.load.i)
  call void @llvm.lifetime.end.p0(i64 40, ptr nonnull %structArg.i)
  call void @llvm.lifetime.end.p0(i64 48, ptr nonnull %1)
  call void @llvm.lifetime.end.p0(i64 48, ptr nonnull %2)
  call void @llvm.lifetime.end.p0(i64 48, ptr nonnull %3)
  %18 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.e8a0ac9186c064ac8543d822e9060d96, i32 10)
  %19 = call i1 @_FortranAioOutputAscii(ptr %18, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %20 = load i32, ptr %4, align 4, !tbaa !4
  %21 = call i1 @_FortranAioOutputInteger32(ptr %18, i32 %20)
  %22 = call i1 @_FortranAioOutputAscii(ptr %18, ptr nonnull @_QQcl.2920697320, i64 5)
  %23 = call i1 @_FortranAioOutputReal64(ptr %18, double %17)
  %24 = call i32 @_FortranAioEndIoStatement(ptr %18)
  ret void
}

; Function Attrs: nounwind
define void @_QFPomp_subroutine(ptr %0, ptr nocapture writeonly %1, ptr nest %2) local_unnamed_addr #2 {
entry:
  %structArg = alloca { ptr, ptr, ptr, ptr, ptr }, align 8
  %3 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %4 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %5 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %.fca.1.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 1
  %.fca.2.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 2
  %.fca.3.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 3
  %.fca.4.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 4
  %.fca.5.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 5
  %.fca.6.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 6
  %.fca.7.0.0.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 0
  %.fca.7.0.1.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 1
  %.fca.7.0.2.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 2
  %6 = load i32, ptr %0, align 4, !tbaa !4
  %7 = tail call i32 @llvm.smax.i32(i32 %6, i32 0)
  %8 = zext i32 %7 to i64
  %9 = shl nuw nsw i64 %8, 3
  %10 = tail call ptr @malloc(i64 %9)
  store ptr %10, ptr %5, align 8, !tbaa !8
  store i64 8, ptr %.fca.1.gep, align 8, !tbaa !8
  store i32 20180515, ptr %.fca.2.gep, align 8, !tbaa !8
  store i8 1, ptr %.fca.3.gep, align 4, !tbaa !8
  store i8 28, ptr %.fca.4.gep, align 1, !tbaa !8
  store i8 2, ptr %.fca.5.gep, align 2, !tbaa !8
  store i8 0, ptr %.fca.6.gep, align 1, !tbaa !8
  store i64 1, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  store i64 %8, ptr %.fca.7.0.1.gep, align 8, !tbaa !8
  store i64 8, ptr %.fca.7.0.2.gep, align 8, !tbaa !8
  %omp_global_thread_num = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %0, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %5, ptr %gep_5, align 8
  %gep_6 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 2
  store ptr %4, ptr %gep_6, align 8
  %gep_7 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 3
  store ptr %3, ptr %gep_7, align 8
  %gep_8 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 4
  store ptr %2, ptr %gep_8, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QFPomp_subroutine..omp_par, ptr nonnull %structArg)
  %.fca.0.load = load ptr, ptr %5, align 8, !tbaa !8
  %.fca.7.0.0.load = load i64, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  %11 = sub i64 1, %.fca.7.0.0.load
  %12 = getelementptr double, ptr %.fca.0.load, i64 %11
  %13 = load double, ptr %12, align 8, !tbaa !4
  %14 = load i32, ptr %0, align 4, !tbaa !4
  %15 = sext i32 %14 to i64
  %16 = sub i64 %15, %.fca.7.0.0.load
  %17 = getelementptr double, ptr %.fca.0.load, i64 %16
  %18 = load double, ptr %17, align 8, !tbaa !4
  %19 = fadd contract double %13, %18
  store double %19, ptr %1, align 8, !tbaa !4
  call void @free(ptr %.fca.0.load)
  ret void
}

; Function Attrs: norecurse nounwind
define internal void @_QFPomp_subroutine..omp_par(ptr noalias nocapture readnone %tid.addr, ptr noalias nocapture readnone %zero.addr, ptr nocapture readonly %0) #3 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %gep_3 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 2
  %loadgep_4 = load ptr, ptr %gep_3, align 8
  %gep_5 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 3
  %loadgep_6 = load ptr, ptr %gep_5, align 8
  %gep_7 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 4
  %loadgep_8 = load ptr, ptr %gep_7, align 8
  %1 = tail call i32 @omp_get_thread_num()
  %2 = tail call i32 @omp_get_num_threads()
  %3 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %4 = sdiv i32 %3, %2
  %5 = mul i32 %4, %1
  %6 = add i32 %5, 1
  %7 = add i32 %2, -1
  %8 = icmp eq i32 %1, %7
  %9 = add i32 %6, %4
  %spec.select = select i1 %8, i32 %3, i32 %9
  %.unpack = load ptr, ptr %loadgep_2, align 8, !tbaa !8
  %.elt14 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  %.unpack15 = load i64, ptr %.elt14, align 8, !tbaa !8
  %.elt16 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  %.unpack17 = load i32, ptr %.elt16, align 8, !tbaa !8
  %.elt18 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  %.unpack19 = load i8, ptr %.elt18, align 4, !tbaa !8
  %.elt20 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  %.unpack21 = load i8, ptr %.elt20, align 1, !tbaa !8
  %.elt22 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  %.unpack23 = load i8, ptr %.elt22, align 2, !tbaa !8
  %.elt24 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  %.unpack25 = load i8, ptr %.elt24, align 1, !tbaa !8
  %.elt26 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  %.unpack27.unpack.unpack = load i64, ptr %.elt26, align 8, !tbaa !8
  %.unpack27.unpack.elt29 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  %.unpack27.unpack.unpack30 = load i64, ptr %.unpack27.unpack.elt29, align 8, !tbaa !8
  %.unpack27.unpack.elt31 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  %.unpack27.unpack.unpack32 = load i64, ptr %.unpack27.unpack.elt31, align 8, !tbaa !8
  store ptr %.unpack, ptr %loadgep_4, align 8, !tbaa !8
  %loadgep_4.repack34 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 1
  store i64 %.unpack15, ptr %loadgep_4.repack34, align 8, !tbaa !8
  %loadgep_4.repack36 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 2
  store i32 %.unpack17, ptr %loadgep_4.repack36, align 8, !tbaa !8
  %loadgep_4.repack38 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 3
  store i8 %.unpack19, ptr %loadgep_4.repack38, align 4, !tbaa !8
  %loadgep_4.repack40 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 4
  store i8 %.unpack21, ptr %loadgep_4.repack40, align 1, !tbaa !8
  %loadgep_4.repack42 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 5
  store i8 %.unpack23, ptr %loadgep_4.repack42, align 2, !tbaa !8
  %loadgep_4.repack44 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 6
  store i8 %.unpack25, ptr %loadgep_4.repack44, align 1, !tbaa !8
  %loadgep_4.repack46 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7
  store i64 %.unpack27.unpack.unpack, ptr %loadgep_4.repack46, align 8, !tbaa !8
  %loadgep_4.repack46.repack48 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack27.unpack.unpack30, ptr %loadgep_4.repack46.repack48, align 8, !tbaa !8
  %loadgep_4.repack46.repack50 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 2
  store i64 %.unpack27.unpack.unpack32, ptr %loadgep_4.repack46.repack50, align 8, !tbaa !8
  %10 = icmp eq i64 %.unpack27.unpack.unpack30, 0
  %11 = select i1 %10, i64 1, i64 %.unpack27.unpack.unpack
  store ptr %.unpack, ptr %loadgep_6, align 8, !tbaa !8
  %loadgep_6.repack52 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 1
  store i64 8, ptr %loadgep_6.repack52, align 8, !tbaa !8
  %loadgep_6.repack54 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 2
  store i32 20180515, ptr %loadgep_6.repack54, align 8, !tbaa !8
  %loadgep_6.repack56 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 3
  store i8 1, ptr %loadgep_6.repack56, align 4, !tbaa !8
  %loadgep_6.repack58 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 4
  store i8 28, ptr %loadgep_6.repack58, align 1, !tbaa !8
  %loadgep_6.repack60 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 5
  store i8 0, ptr %loadgep_6.repack60, align 2, !tbaa !8
  %loadgep_6.repack62 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 6
  store i8 0, ptr %loadgep_6.repack62, align 1, !tbaa !8
  %loadgep_6.repack64 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7
  store i64 %11, ptr %loadgep_6.repack64, align 8, !tbaa !8
  %loadgep_6.repack64.repack66 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack27.unpack.unpack30, ptr %loadgep_6.repack64.repack66, align 8, !tbaa !8
  %loadgep_6.repack64.repack68 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7, i64 0, i64 2
  store i64 8, ptr %loadgep_6.repack64.repack68, align 8, !tbaa !8
  %12 = load ptr, ptr %loadgep_8, align 8, !tbaa !4
  %13 = getelementptr { ptr, ptr }, ptr %loadgep_8, i64 0, i32 1
  %14 = load ptr, ptr %13, align 8, !tbaa !4
  %15 = sext i32 %6 to i64
  %16 = sext i32 %spec.select to i64
  %reass.sub9.i = sub nsw i64 %16, %15
  %17 = icmp sgt i64 %reass.sub9.i, -1
  br i1 %17, label %.lr.ph8.preheader.i, label %_QFPloop.exit

.lr.ph8.preheader.i:                              ; preds = %omp.par.entry
  %18 = add nuw nsw i64 %reass.sub9.i, 1
  br label %.lr.ph8.i

.lr.ph8.i:                                        ; preds = %.lr.ph8.i, %.lr.ph8.preheader.i
  %19 = phi i64 [ %29, %.lr.ph8.i ], [ %18, %.lr.ph8.preheader.i ]
  %20 = phi i32 [ %28, %.lr.ph8.i ], [ %6, %.lr.ph8.preheader.i ]
  %21 = load i32, ptr %12, align 4, !tbaa !4
  %22 = sitofp i32 %21 to float
  %23 = fdiv contract float 1.000000e+00, %22
  %24 = fpext float %23 to double
  %25 = sext i32 %20 to i64
  %26 = add nsw i64 %25, -1
  %27 = getelementptr double, ptr %.unpack, i64 %26
  store double %24, ptr %27, align 8, !tbaa !4
  store double %24, ptr %14, align 8, !tbaa !4
  %28 = add i32 %20, 1
  %29 = add nsw i64 %19, -1
  %30 = icmp ugt i64 %19, 1
  br i1 %30, label %.lr.ph8.i, label %_QFPloop.exit

_QFPloop.exit:                                    ; preds = %.lr.ph8.i, %omp.par.entry
  ret void
}

; Function Attrs: nofree norecurse nosync nounwind memory(readwrite, inaccessiblemem: none)
define void @_QFPloop(ptr nocapture readonly %0, ptr nocapture readonly %1, ptr nocapture readonly %2, ptr nest nocapture readonly %3) local_unnamed_addr #4 {
  %5 = load ptr, ptr %3, align 8, !tbaa !4
  %6 = getelementptr { ptr, ptr }, ptr %3, i64 0, i32 1
  %7 = load ptr, ptr %6, align 8, !tbaa !4
  %8 = load i32, ptr %0, align 4, !tbaa !4
  %9 = sext i32 %8 to i64
  %10 = load i32, ptr %1, align 4, !tbaa !4
  %11 = sext i32 %10 to i64
  %12 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %2, i64 0, i32 7, i64 0, i64 2
  %13 = load i64, ptr %12, align 8, !tbaa !8
  %14 = icmp eq i64 %13, 8
  br i1 %14, label %15, label %31

15:                                               ; preds = %4
  %16 = load ptr, ptr %2, align 8, !tbaa !8
  %reass.sub9 = sub nsw i64 %11, %9
  %17 = icmp sgt i64 %reass.sub9, -1
  br i1 %17, label %.lr.ph8.preheader, label %.loopexit

.lr.ph8.preheader:                                ; preds = %15
  %18 = add nuw nsw i64 %reass.sub9, 1
  br label %.lr.ph8

.lr.ph8:                                          ; preds = %.lr.ph8.preheader, %.lr.ph8
  %19 = phi i64 [ %29, %.lr.ph8 ], [ %18, %.lr.ph8.preheader ]
  %20 = phi i32 [ %28, %.lr.ph8 ], [ %8, %.lr.ph8.preheader ]
  %21 = load i32, ptr %5, align 4, !tbaa !4
  %22 = sitofp i32 %21 to float
  %23 = fdiv contract float 1.000000e+00, %22
  %24 = fpext float %23 to double
  %25 = sext i32 %20 to i64
  %26 = add nsw i64 %25, -1
  %27 = getelementptr double, ptr %16, i64 %26
  store double %24, ptr %27, align 8, !tbaa !4
  store double %24, ptr %7, align 8, !tbaa !4
  %28 = add i32 %20, 1
  %29 = add nsw i64 %19, -1
  %30 = icmp ugt i64 %19, 1
  br i1 %30, label %.lr.ph8, label %.loopexit

31:                                               ; preds = %4
  %reass.sub = sub nsw i64 %11, %9
  %32 = icmp sgt i64 %reass.sub, -1
  br i1 %32, label %.lr.ph, label %.loopexit

.lr.ph:                                           ; preds = %31
  %33 = add nuw nsw i64 %reass.sub, 1
  %34 = load ptr, ptr %2, align 8, !tbaa !8
  br label %35

35:                                               ; preds = %.lr.ph, %35
  %36 = phi i64 [ %33, %.lr.ph ], [ %47, %35 ]
  %37 = phi i32 [ %8, %.lr.ph ], [ %46, %35 ]
  %38 = load i32, ptr %5, align 4, !tbaa !4
  %39 = sitofp i32 %38 to float
  %40 = fdiv contract float 1.000000e+00, %39
  %41 = fpext float %40 to double
  %42 = sext i32 %37 to i64
  %43 = add nsw i64 %42, -1
  %44 = mul i64 %43, %13
  %45 = getelementptr i8, ptr %34, i64 %44
  store double %41, ptr %45, align 8, !tbaa !4
  store double %41, ptr %7, align 8, !tbaa !4
  %46 = add i32 %37, 1
  %47 = add nsw i64 %36, -1
  %48 = icmp ugt i64 %36, 1
  br i1 %48, label %35, label %.loopexit

.loopexit:                                        ; preds = %35, %.lr.ph8, %31, %15
  ret void
}

declare ptr @_FortranAioBeginExternalFormattedOutput(ptr, i64, ptr, i32, ptr, i32) local_unnamed_addr

declare zeroext i1 @_FortranAioOutputAscii(ptr, ptr, i64) local_unnamed_addr

declare zeroext i1 @_FortranAioOutputInteger32(ptr, i32) local_unnamed_addr

declare zeroext i1 @_FortranAioOutputReal64(ptr, double) local_unnamed_addr

declare i32 @_FortranAioEndIoStatement(ptr) local_unnamed_addr

; Function Attrs: nounwind
declare i32 @omp_get_thread_num() local_unnamed_addr #2

; Function Attrs: nounwind
declare i32 @omp_get_num_threads() local_unnamed_addr #2

; Function Attrs: nounwind
declare i32 @__kmpc_global_thread_num(ptr) local_unnamed_addr #2

; Function Attrs: nounwind
declare !callback !10 void @__kmpc_fork_call(ptr, i32, ptr, ...) local_unnamed_addr #2

; Function Attrs: nocallback nofree nosync nounwind speculatable willreturn memory(none)
declare i32 @llvm.smax.i32(i32, i32) #5

; Function Attrs: nocallback nofree nosync nounwind willreturn memory(argmem: readwrite)
declare void @llvm.lifetime.start.p0(i64 immarg, ptr nocapture) #6

; Function Attrs: nocallback nofree nosync nounwind willreturn memory(argmem: readwrite)
declare void @llvm.lifetime.end.p0(i64 immarg, ptr nocapture) #6

attributes #0 = { mustprogress nofree nounwind willreturn allockind("alloc,uninitialized") allocsize(0) memory(inaccessiblemem: readwrite) "alloc-family"="malloc" }
attributes #1 = { mustprogress nounwind willreturn allockind("free") memory(argmem: readwrite, inaccessiblemem: readwrite) "alloc-family"="malloc" }
attributes #2 = { nounwind }
attributes #3 = { norecurse nounwind }
attributes #4 = { nofree norecurse nosync nounwind memory(readwrite, inaccessiblemem: none) }
attributes #5 = { nocallback nofree nosync nounwind speculatable willreturn memory(none) }
attributes #6 = { nocallback nofree nosync nounwind willreturn memory(argmem: readwrite) }

!llvm.module.flags = !{!0, !1, !2, !3}

!0 = !{i32 2, !"Debug Info Version", i32 3}
!1 = !{i32 7, !"openmp", i32 11}
!2 = !{i32 8, !"PIC Level", i32 2}
!3 = !{i32 7, !"PIE Level", i32 2}
!4 = !{!5, !5, i64 0}
!5 = !{!"any data access", !6, i64 0}
!6 = !{!"any access", !7, i64 0}
!7 = !{!"Flang Type TBAA Root"}
!8 = !{!9, !9, i64 0}
!9 = !{!"descriptor member", !6, i64 0}
!10 = !{!11}
!11 = !{i64 2, i64 -1, i64 -1, i1 true}
*** IR Dump After Float2IntPass on _QQmain ***
define void @_QQmain() local_unnamed_addr {
  %structArg.i = alloca { ptr, ptr, ptr, ptr, ptr }, align 8
  %1 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %2 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %3 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %4 = alloca i32, align 4
  %5 = alloca double, align 8
  %6 = alloca { ptr, ptr }, align 8
  store ptr %4, ptr %6, align 8, !tbaa !4
  %7 = getelementptr inbounds { ptr, ptr }, ptr %6, i64 0, i32 1
  store ptr %5, ptr %7, align 8, !tbaa !4
  store i32 1048576, ptr %4, align 4, !tbaa !4
  call void @llvm.lifetime.start.p0(i64 40, ptr nonnull %structArg.i)
  call void @llvm.lifetime.start.p0(i64 48, ptr nonnull %1)
  call void @llvm.lifetime.start.p0(i64 48, ptr nonnull %2)
  call void @llvm.lifetime.start.p0(i64 48, ptr nonnull %3)
  %.fca.1.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 1
  %.fca.2.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 2
  %.fca.3.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 3
  %.fca.4.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 4
  %.fca.5.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 5
  %.fca.6.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 6
  %.fca.7.0.0.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 7, i64 0, i64 0
  %.fca.7.0.1.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 7, i64 0, i64 1
  %.fca.7.0.2.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 7, i64 0, i64 2
  %8 = call dereferenceable_or_null(8388608) ptr @malloc(i64 8388608)
  store ptr %8, ptr %3, align 8, !tbaa !8
  store i64 8, ptr %.fca.1.gep.i, align 8, !tbaa !8
  store i32 20180515, ptr %.fca.2.gep.i, align 8, !tbaa !8
  store i8 1, ptr %.fca.3.gep.i, align 4, !tbaa !8
  store i8 28, ptr %.fca.4.gep.i, align 1, !tbaa !8
  store i8 2, ptr %.fca.5.gep.i, align 2, !tbaa !8
  store i8 0, ptr %.fca.6.gep.i, align 1, !tbaa !8
  store i64 1, ptr %.fca.7.0.0.gep.i, align 8, !tbaa !8
  store i64 1048576, ptr %.fca.7.0.1.gep.i, align 8, !tbaa !8
  store i64 8, ptr %.fca.7.0.2.gep.i, align 8, !tbaa !8
  %omp_global_thread_num.i = call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %4, ptr %structArg.i, align 8
  %gep_5.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 1
  store ptr %3, ptr %gep_5.i, align 8
  %gep_6.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 2
  store ptr %2, ptr %gep_6.i, align 8
  %gep_7.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 3
  store ptr %1, ptr %gep_7.i, align 8
  %gep_8.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 4
  store ptr %6, ptr %gep_8.i, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QFPomp_subroutine..omp_par, ptr nonnull %structArg.i)
  %.fca.0.load.i = load ptr, ptr %3, align 8, !tbaa !8
  %.fca.7.0.0.load.i = load i64, ptr %.fca.7.0.0.gep.i, align 8, !tbaa !8
  %9 = sub i64 1, %.fca.7.0.0.load.i
  %10 = getelementptr double, ptr %.fca.0.load.i, i64 %9
  %11 = load double, ptr %10, align 8, !tbaa !4
  %12 = load i32, ptr %4, align 4, !tbaa !4
  %13 = sext i32 %12 to i64
  %14 = sub i64 %13, %.fca.7.0.0.load.i
  %15 = getelementptr double, ptr %.fca.0.load.i, i64 %14
  %16 = load double, ptr %15, align 8, !tbaa !4
  %17 = fadd contract double %11, %16
  call void @free(ptr %.fca.0.load.i)
  call void @llvm.lifetime.end.p0(i64 40, ptr nonnull %structArg.i)
  call void @llvm.lifetime.end.p0(i64 48, ptr nonnull %1)
  call void @llvm.lifetime.end.p0(i64 48, ptr nonnull %2)
  call void @llvm.lifetime.end.p0(i64 48, ptr nonnull %3)
  %18 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.e8a0ac9186c064ac8543d822e9060d96, i32 10)
  %19 = call i1 @_FortranAioOutputAscii(ptr %18, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %20 = load i32, ptr %4, align 4, !tbaa !4
  %21 = call i1 @_FortranAioOutputInteger32(ptr %18, i32 %20)
  %22 = call i1 @_FortranAioOutputAscii(ptr %18, ptr nonnull @_QQcl.2920697320, i64 5)
  %23 = call i1 @_FortranAioOutputReal64(ptr %18, double %17)
  %24 = call i32 @_FortranAioEndIoStatement(ptr %18)
  ret void
}
*** IR Dump After LowerConstantIntrinsicsPass on _QQmain ***
define void @_QQmain() local_unnamed_addr {
  %structArg.i = alloca { ptr, ptr, ptr, ptr, ptr }, align 8
  %1 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %2 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %3 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %4 = alloca i32, align 4
  %5 = alloca double, align 8
  %6 = alloca { ptr, ptr }, align 8
  store ptr %4, ptr %6, align 8, !tbaa !4
  %7 = getelementptr inbounds { ptr, ptr }, ptr %6, i64 0, i32 1
  store ptr %5, ptr %7, align 8, !tbaa !4
  store i32 1048576, ptr %4, align 4, !tbaa !4
  call void @llvm.lifetime.start.p0(i64 40, ptr nonnull %structArg.i)
  call void @llvm.lifetime.start.p0(i64 48, ptr nonnull %1)
  call void @llvm.lifetime.start.p0(i64 48, ptr nonnull %2)
  call void @llvm.lifetime.start.p0(i64 48, ptr nonnull %3)
  %.fca.1.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 1
  %.fca.2.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 2
  %.fca.3.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 3
  %.fca.4.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 4
  %.fca.5.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 5
  %.fca.6.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 6
  %.fca.7.0.0.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 7, i64 0, i64 0
  %.fca.7.0.1.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 7, i64 0, i64 1
  %.fca.7.0.2.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 7, i64 0, i64 2
  %8 = call dereferenceable_or_null(8388608) ptr @malloc(i64 8388608)
  store ptr %8, ptr %3, align 8, !tbaa !8
  store i64 8, ptr %.fca.1.gep.i, align 8, !tbaa !8
  store i32 20180515, ptr %.fca.2.gep.i, align 8, !tbaa !8
  store i8 1, ptr %.fca.3.gep.i, align 4, !tbaa !8
  store i8 28, ptr %.fca.4.gep.i, align 1, !tbaa !8
  store i8 2, ptr %.fca.5.gep.i, align 2, !tbaa !8
  store i8 0, ptr %.fca.6.gep.i, align 1, !tbaa !8
  store i64 1, ptr %.fca.7.0.0.gep.i, align 8, !tbaa !8
  store i64 1048576, ptr %.fca.7.0.1.gep.i, align 8, !tbaa !8
  store i64 8, ptr %.fca.7.0.2.gep.i, align 8, !tbaa !8
  %omp_global_thread_num.i = call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %4, ptr %structArg.i, align 8
  %gep_5.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 1
  store ptr %3, ptr %gep_5.i, align 8
  %gep_6.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 2
  store ptr %2, ptr %gep_6.i, align 8
  %gep_7.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 3
  store ptr %1, ptr %gep_7.i, align 8
  %gep_8.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 4
  store ptr %6, ptr %gep_8.i, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QFPomp_subroutine..omp_par, ptr nonnull %structArg.i)
  %.fca.0.load.i = load ptr, ptr %3, align 8, !tbaa !8
  %.fca.7.0.0.load.i = load i64, ptr %.fca.7.0.0.gep.i, align 8, !tbaa !8
  %9 = sub i64 1, %.fca.7.0.0.load.i
  %10 = getelementptr double, ptr %.fca.0.load.i, i64 %9
  %11 = load double, ptr %10, align 8, !tbaa !4
  %12 = load i32, ptr %4, align 4, !tbaa !4
  %13 = sext i32 %12 to i64
  %14 = sub i64 %13, %.fca.7.0.0.load.i
  %15 = getelementptr double, ptr %.fca.0.load.i, i64 %14
  %16 = load double, ptr %15, align 8, !tbaa !4
  %17 = fadd contract double %11, %16
  call void @free(ptr %.fca.0.load.i)
  call void @llvm.lifetime.end.p0(i64 40, ptr nonnull %structArg.i)
  call void @llvm.lifetime.end.p0(i64 48, ptr nonnull %1)
  call void @llvm.lifetime.end.p0(i64 48, ptr nonnull %2)
  call void @llvm.lifetime.end.p0(i64 48, ptr nonnull %3)
  %18 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.e8a0ac9186c064ac8543d822e9060d96, i32 10)
  %19 = call i1 @_FortranAioOutputAscii(ptr %18, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %20 = load i32, ptr %4, align 4, !tbaa !4
  %21 = call i1 @_FortranAioOutputInteger32(ptr %18, i32 %20)
  %22 = call i1 @_FortranAioOutputAscii(ptr %18, ptr nonnull @_QQcl.2920697320, i64 5)
  %23 = call i1 @_FortranAioOutputReal64(ptr %18, double %17)
  %24 = call i32 @_FortranAioEndIoStatement(ptr %18)
  ret void
}
*** IR Dump After ControlHeightReductionPass on _QQmain ***
define void @_QQmain() local_unnamed_addr {
  %structArg.i = alloca { ptr, ptr, ptr, ptr, ptr }, align 8
  %1 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %2 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %3 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %4 = alloca i32, align 4
  %5 = alloca double, align 8
  %6 = alloca { ptr, ptr }, align 8
  store ptr %4, ptr %6, align 8, !tbaa !4
  %7 = getelementptr inbounds { ptr, ptr }, ptr %6, i64 0, i32 1
  store ptr %5, ptr %7, align 8, !tbaa !4
  store i32 1048576, ptr %4, align 4, !tbaa !4
  call void @llvm.lifetime.start.p0(i64 40, ptr nonnull %structArg.i)
  call void @llvm.lifetime.start.p0(i64 48, ptr nonnull %1)
  call void @llvm.lifetime.start.p0(i64 48, ptr nonnull %2)
  call void @llvm.lifetime.start.p0(i64 48, ptr nonnull %3)
  %.fca.1.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 1
  %.fca.2.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 2
  %.fca.3.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 3
  %.fca.4.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 4
  %.fca.5.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 5
  %.fca.6.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 6
  %.fca.7.0.0.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 7, i64 0, i64 0
  %.fca.7.0.1.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 7, i64 0, i64 1
  %.fca.7.0.2.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 7, i64 0, i64 2
  %8 = call dereferenceable_or_null(8388608) ptr @malloc(i64 8388608)
  store ptr %8, ptr %3, align 8, !tbaa !8
  store i64 8, ptr %.fca.1.gep.i, align 8, !tbaa !8
  store i32 20180515, ptr %.fca.2.gep.i, align 8, !tbaa !8
  store i8 1, ptr %.fca.3.gep.i, align 4, !tbaa !8
  store i8 28, ptr %.fca.4.gep.i, align 1, !tbaa !8
  store i8 2, ptr %.fca.5.gep.i, align 2, !tbaa !8
  store i8 0, ptr %.fca.6.gep.i, align 1, !tbaa !8
  store i64 1, ptr %.fca.7.0.0.gep.i, align 8, !tbaa !8
  store i64 1048576, ptr %.fca.7.0.1.gep.i, align 8, !tbaa !8
  store i64 8, ptr %.fca.7.0.2.gep.i, align 8, !tbaa !8
  %omp_global_thread_num.i = call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %4, ptr %structArg.i, align 8
  %gep_5.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 1
  store ptr %3, ptr %gep_5.i, align 8
  %gep_6.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 2
  store ptr %2, ptr %gep_6.i, align 8
  %gep_7.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 3
  store ptr %1, ptr %gep_7.i, align 8
  %gep_8.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 4
  store ptr %6, ptr %gep_8.i, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QFPomp_subroutine..omp_par, ptr nonnull %structArg.i)
  %.fca.0.load.i = load ptr, ptr %3, align 8, !tbaa !8
  %.fca.7.0.0.load.i = load i64, ptr %.fca.7.0.0.gep.i, align 8, !tbaa !8
  %9 = sub i64 1, %.fca.7.0.0.load.i
  %10 = getelementptr double, ptr %.fca.0.load.i, i64 %9
  %11 = load double, ptr %10, align 8, !tbaa !4
  %12 = load i32, ptr %4, align 4, !tbaa !4
  %13 = sext i32 %12 to i64
  %14 = sub i64 %13, %.fca.7.0.0.load.i
  %15 = getelementptr double, ptr %.fca.0.load.i, i64 %14
  %16 = load double, ptr %15, align 8, !tbaa !4
  %17 = fadd contract double %11, %16
  call void @free(ptr %.fca.0.load.i)
  call void @llvm.lifetime.end.p0(i64 40, ptr nonnull %structArg.i)
  call void @llvm.lifetime.end.p0(i64 48, ptr nonnull %1)
  call void @llvm.lifetime.end.p0(i64 48, ptr nonnull %2)
  call void @llvm.lifetime.end.p0(i64 48, ptr nonnull %3)
  %18 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.e8a0ac9186c064ac8543d822e9060d96, i32 10)
  %19 = call i1 @_FortranAioOutputAscii(ptr %18, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %20 = load i32, ptr %4, align 4, !tbaa !4
  %21 = call i1 @_FortranAioOutputInteger32(ptr %18, i32 %20)
  %22 = call i1 @_FortranAioOutputAscii(ptr %18, ptr nonnull @_QQcl.2920697320, i64 5)
  %23 = call i1 @_FortranAioOutputReal64(ptr %18, double %17)
  %24 = call i32 @_FortranAioEndIoStatement(ptr %18)
  ret void
}
*** IR Dump After LoopSimplifyPass on _QQmain ***
define void @_QQmain() local_unnamed_addr {
  %structArg.i = alloca { ptr, ptr, ptr, ptr, ptr }, align 8
  %1 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %2 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %3 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %4 = alloca i32, align 4
  %5 = alloca double, align 8
  %6 = alloca { ptr, ptr }, align 8
  store ptr %4, ptr %6, align 8, !tbaa !4
  %7 = getelementptr inbounds { ptr, ptr }, ptr %6, i64 0, i32 1
  store ptr %5, ptr %7, align 8, !tbaa !4
  store i32 1048576, ptr %4, align 4, !tbaa !4
  call void @llvm.lifetime.start.p0(i64 40, ptr nonnull %structArg.i)
  call void @llvm.lifetime.start.p0(i64 48, ptr nonnull %1)
  call void @llvm.lifetime.start.p0(i64 48, ptr nonnull %2)
  call void @llvm.lifetime.start.p0(i64 48, ptr nonnull %3)
  %.fca.1.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 1
  %.fca.2.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 2
  %.fca.3.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 3
  %.fca.4.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 4
  %.fca.5.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 5
  %.fca.6.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 6
  %.fca.7.0.0.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 7, i64 0, i64 0
  %.fca.7.0.1.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 7, i64 0, i64 1
  %.fca.7.0.2.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 7, i64 0, i64 2
  %8 = call dereferenceable_or_null(8388608) ptr @malloc(i64 8388608)
  store ptr %8, ptr %3, align 8, !tbaa !8
  store i64 8, ptr %.fca.1.gep.i, align 8, !tbaa !8
  store i32 20180515, ptr %.fca.2.gep.i, align 8, !tbaa !8
  store i8 1, ptr %.fca.3.gep.i, align 4, !tbaa !8
  store i8 28, ptr %.fca.4.gep.i, align 1, !tbaa !8
  store i8 2, ptr %.fca.5.gep.i, align 2, !tbaa !8
  store i8 0, ptr %.fca.6.gep.i, align 1, !tbaa !8
  store i64 1, ptr %.fca.7.0.0.gep.i, align 8, !tbaa !8
  store i64 1048576, ptr %.fca.7.0.1.gep.i, align 8, !tbaa !8
  store i64 8, ptr %.fca.7.0.2.gep.i, align 8, !tbaa !8
  %omp_global_thread_num.i = call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %4, ptr %structArg.i, align 8
  %gep_5.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 1
  store ptr %3, ptr %gep_5.i, align 8
  %gep_6.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 2
  store ptr %2, ptr %gep_6.i, align 8
  %gep_7.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 3
  store ptr %1, ptr %gep_7.i, align 8
  %gep_8.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 4
  store ptr %6, ptr %gep_8.i, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QFPomp_subroutine..omp_par, ptr nonnull %structArg.i)
  %.fca.0.load.i = load ptr, ptr %3, align 8, !tbaa !8
  %.fca.7.0.0.load.i = load i64, ptr %.fca.7.0.0.gep.i, align 8, !tbaa !8
  %9 = sub i64 1, %.fca.7.0.0.load.i
  %10 = getelementptr double, ptr %.fca.0.load.i, i64 %9
  %11 = load double, ptr %10, align 8, !tbaa !4
  %12 = load i32, ptr %4, align 4, !tbaa !4
  %13 = sext i32 %12 to i64
  %14 = sub i64 %13, %.fca.7.0.0.load.i
  %15 = getelementptr double, ptr %.fca.0.load.i, i64 %14
  %16 = load double, ptr %15, align 8, !tbaa !4
  %17 = fadd contract double %11, %16
  call void @free(ptr %.fca.0.load.i)
  call void @llvm.lifetime.end.p0(i64 40, ptr nonnull %structArg.i)
  call void @llvm.lifetime.end.p0(i64 48, ptr nonnull %1)
  call void @llvm.lifetime.end.p0(i64 48, ptr nonnull %2)
  call void @llvm.lifetime.end.p0(i64 48, ptr nonnull %3)
  %18 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.e8a0ac9186c064ac8543d822e9060d96, i32 10)
  %19 = call i1 @_FortranAioOutputAscii(ptr %18, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %20 = load i32, ptr %4, align 4, !tbaa !4
  %21 = call i1 @_FortranAioOutputInteger32(ptr %18, i32 %20)
  %22 = call i1 @_FortranAioOutputAscii(ptr %18, ptr nonnull @_QQcl.2920697320, i64 5)
  %23 = call i1 @_FortranAioOutputReal64(ptr %18, double %17)
  %24 = call i32 @_FortranAioEndIoStatement(ptr %18)
  ret void
}
*** IR Dump After LCSSAPass on _QQmain ***
define void @_QQmain() local_unnamed_addr {
  %structArg.i = alloca { ptr, ptr, ptr, ptr, ptr }, align 8
  %1 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %2 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %3 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %4 = alloca i32, align 4
  %5 = alloca double, align 8
  %6 = alloca { ptr, ptr }, align 8
  store ptr %4, ptr %6, align 8, !tbaa !4
  %7 = getelementptr inbounds { ptr, ptr }, ptr %6, i64 0, i32 1
  store ptr %5, ptr %7, align 8, !tbaa !4
  store i32 1048576, ptr %4, align 4, !tbaa !4
  call void @llvm.lifetime.start.p0(i64 40, ptr nonnull %structArg.i)
  call void @llvm.lifetime.start.p0(i64 48, ptr nonnull %1)
  call void @llvm.lifetime.start.p0(i64 48, ptr nonnull %2)
  call void @llvm.lifetime.start.p0(i64 48, ptr nonnull %3)
  %.fca.1.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 1
  %.fca.2.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 2
  %.fca.3.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 3
  %.fca.4.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 4
  %.fca.5.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 5
  %.fca.6.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 6
  %.fca.7.0.0.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 7, i64 0, i64 0
  %.fca.7.0.1.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 7, i64 0, i64 1
  %.fca.7.0.2.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 7, i64 0, i64 2
  %8 = call dereferenceable_or_null(8388608) ptr @malloc(i64 8388608)
  store ptr %8, ptr %3, align 8, !tbaa !8
  store i64 8, ptr %.fca.1.gep.i, align 8, !tbaa !8
  store i32 20180515, ptr %.fca.2.gep.i, align 8, !tbaa !8
  store i8 1, ptr %.fca.3.gep.i, align 4, !tbaa !8
  store i8 28, ptr %.fca.4.gep.i, align 1, !tbaa !8
  store i8 2, ptr %.fca.5.gep.i, align 2, !tbaa !8
  store i8 0, ptr %.fca.6.gep.i, align 1, !tbaa !8
  store i64 1, ptr %.fca.7.0.0.gep.i, align 8, !tbaa !8
  store i64 1048576, ptr %.fca.7.0.1.gep.i, align 8, !tbaa !8
  store i64 8, ptr %.fca.7.0.2.gep.i, align 8, !tbaa !8
  %omp_global_thread_num.i = call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %4, ptr %structArg.i, align 8
  %gep_5.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 1
  store ptr %3, ptr %gep_5.i, align 8
  %gep_6.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 2
  store ptr %2, ptr %gep_6.i, align 8
  %gep_7.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 3
  store ptr %1, ptr %gep_7.i, align 8
  %gep_8.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 4
  store ptr %6, ptr %gep_8.i, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QFPomp_subroutine..omp_par, ptr nonnull %structArg.i)
  %.fca.0.load.i = load ptr, ptr %3, align 8, !tbaa !8
  %.fca.7.0.0.load.i = load i64, ptr %.fca.7.0.0.gep.i, align 8, !tbaa !8
  %9 = sub i64 1, %.fca.7.0.0.load.i
  %10 = getelementptr double, ptr %.fca.0.load.i, i64 %9
  %11 = load double, ptr %10, align 8, !tbaa !4
  %12 = load i32, ptr %4, align 4, !tbaa !4
  %13 = sext i32 %12 to i64
  %14 = sub i64 %13, %.fca.7.0.0.load.i
  %15 = getelementptr double, ptr %.fca.0.load.i, i64 %14
  %16 = load double, ptr %15, align 8, !tbaa !4
  %17 = fadd contract double %11, %16
  call void @free(ptr %.fca.0.load.i)
  call void @llvm.lifetime.end.p0(i64 40, ptr nonnull %structArg.i)
  call void @llvm.lifetime.end.p0(i64 48, ptr nonnull %1)
  call void @llvm.lifetime.end.p0(i64 48, ptr nonnull %2)
  call void @llvm.lifetime.end.p0(i64 48, ptr nonnull %3)
  %18 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.e8a0ac9186c064ac8543d822e9060d96, i32 10)
  %19 = call i1 @_FortranAioOutputAscii(ptr %18, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %20 = load i32, ptr %4, align 4, !tbaa !4
  %21 = call i1 @_FortranAioOutputInteger32(ptr %18, i32 %20)
  %22 = call i1 @_FortranAioOutputAscii(ptr %18, ptr nonnull @_QQcl.2920697320, i64 5)
  %23 = call i1 @_FortranAioOutputReal64(ptr %18, double %17)
  %24 = call i32 @_FortranAioEndIoStatement(ptr %18)
  ret void
}
*** IR Dump After LoopDistributePass on _QQmain ***
define void @_QQmain() local_unnamed_addr {
  %structArg.i = alloca { ptr, ptr, ptr, ptr, ptr }, align 8
  %1 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %2 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %3 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %4 = alloca i32, align 4
  %5 = alloca double, align 8
  %6 = alloca { ptr, ptr }, align 8
  store ptr %4, ptr %6, align 8, !tbaa !4
  %7 = getelementptr inbounds { ptr, ptr }, ptr %6, i64 0, i32 1
  store ptr %5, ptr %7, align 8, !tbaa !4
  store i32 1048576, ptr %4, align 4, !tbaa !4
  call void @llvm.lifetime.start.p0(i64 40, ptr nonnull %structArg.i)
  call void @llvm.lifetime.start.p0(i64 48, ptr nonnull %1)
  call void @llvm.lifetime.start.p0(i64 48, ptr nonnull %2)
  call void @llvm.lifetime.start.p0(i64 48, ptr nonnull %3)
  %.fca.1.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 1
  %.fca.2.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 2
  %.fca.3.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 3
  %.fca.4.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 4
  %.fca.5.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 5
  %.fca.6.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 6
  %.fca.7.0.0.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 7, i64 0, i64 0
  %.fca.7.0.1.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 7, i64 0, i64 1
  %.fca.7.0.2.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 7, i64 0, i64 2
  %8 = call dereferenceable_or_null(8388608) ptr @malloc(i64 8388608)
  store ptr %8, ptr %3, align 8, !tbaa !8
  store i64 8, ptr %.fca.1.gep.i, align 8, !tbaa !8
  store i32 20180515, ptr %.fca.2.gep.i, align 8, !tbaa !8
  store i8 1, ptr %.fca.3.gep.i, align 4, !tbaa !8
  store i8 28, ptr %.fca.4.gep.i, align 1, !tbaa !8
  store i8 2, ptr %.fca.5.gep.i, align 2, !tbaa !8
  store i8 0, ptr %.fca.6.gep.i, align 1, !tbaa !8
  store i64 1, ptr %.fca.7.0.0.gep.i, align 8, !tbaa !8
  store i64 1048576, ptr %.fca.7.0.1.gep.i, align 8, !tbaa !8
  store i64 8, ptr %.fca.7.0.2.gep.i, align 8, !tbaa !8
  %omp_global_thread_num.i = call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %4, ptr %structArg.i, align 8
  %gep_5.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 1
  store ptr %3, ptr %gep_5.i, align 8
  %gep_6.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 2
  store ptr %2, ptr %gep_6.i, align 8
  %gep_7.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 3
  store ptr %1, ptr %gep_7.i, align 8
  %gep_8.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 4
  store ptr %6, ptr %gep_8.i, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QFPomp_subroutine..omp_par, ptr nonnull %structArg.i)
  %.fca.0.load.i = load ptr, ptr %3, align 8, !tbaa !8
  %.fca.7.0.0.load.i = load i64, ptr %.fca.7.0.0.gep.i, align 8, !tbaa !8
  %9 = sub i64 1, %.fca.7.0.0.load.i
  %10 = getelementptr double, ptr %.fca.0.load.i, i64 %9
  %11 = load double, ptr %10, align 8, !tbaa !4
  %12 = load i32, ptr %4, align 4, !tbaa !4
  %13 = sext i32 %12 to i64
  %14 = sub i64 %13, %.fca.7.0.0.load.i
  %15 = getelementptr double, ptr %.fca.0.load.i, i64 %14
  %16 = load double, ptr %15, align 8, !tbaa !4
  %17 = fadd contract double %11, %16
  call void @free(ptr %.fca.0.load.i)
  call void @llvm.lifetime.end.p0(i64 40, ptr nonnull %structArg.i)
  call void @llvm.lifetime.end.p0(i64 48, ptr nonnull %1)
  call void @llvm.lifetime.end.p0(i64 48, ptr nonnull %2)
  call void @llvm.lifetime.end.p0(i64 48, ptr nonnull %3)
  %18 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.e8a0ac9186c064ac8543d822e9060d96, i32 10)
  %19 = call i1 @_FortranAioOutputAscii(ptr %18, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %20 = load i32, ptr %4, align 4, !tbaa !4
  %21 = call i1 @_FortranAioOutputInteger32(ptr %18, i32 %20)
  %22 = call i1 @_FortranAioOutputAscii(ptr %18, ptr nonnull @_QQcl.2920697320, i64 5)
  %23 = call i1 @_FortranAioOutputReal64(ptr %18, double %17)
  %24 = call i32 @_FortranAioEndIoStatement(ptr %18)
  ret void
}
*** IR Dump After InjectTLIMappings on _QQmain ***
define void @_QQmain() local_unnamed_addr {
  %structArg.i = alloca { ptr, ptr, ptr, ptr, ptr }, align 8
  %1 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %2 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %3 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %4 = alloca i32, align 4
  %5 = alloca double, align 8
  %6 = alloca { ptr, ptr }, align 8
  store ptr %4, ptr %6, align 8, !tbaa !4
  %7 = getelementptr inbounds { ptr, ptr }, ptr %6, i64 0, i32 1
  store ptr %5, ptr %7, align 8, !tbaa !4
  store i32 1048576, ptr %4, align 4, !tbaa !4
  call void @llvm.lifetime.start.p0(i64 40, ptr nonnull %structArg.i)
  call void @llvm.lifetime.start.p0(i64 48, ptr nonnull %1)
  call void @llvm.lifetime.start.p0(i64 48, ptr nonnull %2)
  call void @llvm.lifetime.start.p0(i64 48, ptr nonnull %3)
  %.fca.1.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 1
  %.fca.2.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 2
  %.fca.3.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 3
  %.fca.4.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 4
  %.fca.5.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 5
  %.fca.6.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 6
  %.fca.7.0.0.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 7, i64 0, i64 0
  %.fca.7.0.1.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 7, i64 0, i64 1
  %.fca.7.0.2.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 7, i64 0, i64 2
  %8 = call dereferenceable_or_null(8388608) ptr @malloc(i64 8388608)
  store ptr %8, ptr %3, align 8, !tbaa !8
  store i64 8, ptr %.fca.1.gep.i, align 8, !tbaa !8
  store i32 20180515, ptr %.fca.2.gep.i, align 8, !tbaa !8
  store i8 1, ptr %.fca.3.gep.i, align 4, !tbaa !8
  store i8 28, ptr %.fca.4.gep.i, align 1, !tbaa !8
  store i8 2, ptr %.fca.5.gep.i, align 2, !tbaa !8
  store i8 0, ptr %.fca.6.gep.i, align 1, !tbaa !8
  store i64 1, ptr %.fca.7.0.0.gep.i, align 8, !tbaa !8
  store i64 1048576, ptr %.fca.7.0.1.gep.i, align 8, !tbaa !8
  store i64 8, ptr %.fca.7.0.2.gep.i, align 8, !tbaa !8
  %omp_global_thread_num.i = call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %4, ptr %structArg.i, align 8
  %gep_5.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 1
  store ptr %3, ptr %gep_5.i, align 8
  %gep_6.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 2
  store ptr %2, ptr %gep_6.i, align 8
  %gep_7.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 3
  store ptr %1, ptr %gep_7.i, align 8
  %gep_8.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 4
  store ptr %6, ptr %gep_8.i, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QFPomp_subroutine..omp_par, ptr nonnull %structArg.i)
  %.fca.0.load.i = load ptr, ptr %3, align 8, !tbaa !8
  %.fca.7.0.0.load.i = load i64, ptr %.fca.7.0.0.gep.i, align 8, !tbaa !8
  %9 = sub i64 1, %.fca.7.0.0.load.i
  %10 = getelementptr double, ptr %.fca.0.load.i, i64 %9
  %11 = load double, ptr %10, align 8, !tbaa !4
  %12 = load i32, ptr %4, align 4, !tbaa !4
  %13 = sext i32 %12 to i64
  %14 = sub i64 %13, %.fca.7.0.0.load.i
  %15 = getelementptr double, ptr %.fca.0.load.i, i64 %14
  %16 = load double, ptr %15, align 8, !tbaa !4
  %17 = fadd contract double %11, %16
  call void @free(ptr %.fca.0.load.i)
  call void @llvm.lifetime.end.p0(i64 40, ptr nonnull %structArg.i)
  call void @llvm.lifetime.end.p0(i64 48, ptr nonnull %1)
  call void @llvm.lifetime.end.p0(i64 48, ptr nonnull %2)
  call void @llvm.lifetime.end.p0(i64 48, ptr nonnull %3)
  %18 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.e8a0ac9186c064ac8543d822e9060d96, i32 10)
  %19 = call i1 @_FortranAioOutputAscii(ptr %18, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %20 = load i32, ptr %4, align 4, !tbaa !4
  %21 = call i1 @_FortranAioOutputInteger32(ptr %18, i32 %20)
  %22 = call i1 @_FortranAioOutputAscii(ptr %18, ptr nonnull @_QQcl.2920697320, i64 5)
  %23 = call i1 @_FortranAioOutputReal64(ptr %18, double %17)
  %24 = call i32 @_FortranAioEndIoStatement(ptr %18)
  ret void
}
*** IR Dump After LoopVectorizePass on _QQmain ***
define void @_QQmain() local_unnamed_addr {
  %structArg.i = alloca { ptr, ptr, ptr, ptr, ptr }, align 8
  %1 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %2 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %3 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %4 = alloca i32, align 4
  %5 = alloca double, align 8
  %6 = alloca { ptr, ptr }, align 8
  store ptr %4, ptr %6, align 8, !tbaa !4
  %7 = getelementptr inbounds { ptr, ptr }, ptr %6, i64 0, i32 1
  store ptr %5, ptr %7, align 8, !tbaa !4
  store i32 1048576, ptr %4, align 4, !tbaa !4
  call void @llvm.lifetime.start.p0(i64 40, ptr nonnull %structArg.i)
  call void @llvm.lifetime.start.p0(i64 48, ptr nonnull %1)
  call void @llvm.lifetime.start.p0(i64 48, ptr nonnull %2)
  call void @llvm.lifetime.start.p0(i64 48, ptr nonnull %3)
  %.fca.1.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 1
  %.fca.2.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 2
  %.fca.3.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 3
  %.fca.4.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 4
  %.fca.5.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 5
  %.fca.6.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 6
  %.fca.7.0.0.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 7, i64 0, i64 0
  %.fca.7.0.1.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 7, i64 0, i64 1
  %.fca.7.0.2.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 7, i64 0, i64 2
  %8 = call dereferenceable_or_null(8388608) ptr @malloc(i64 8388608)
  store ptr %8, ptr %3, align 8, !tbaa !8
  store i64 8, ptr %.fca.1.gep.i, align 8, !tbaa !8
  store i32 20180515, ptr %.fca.2.gep.i, align 8, !tbaa !8
  store i8 1, ptr %.fca.3.gep.i, align 4, !tbaa !8
  store i8 28, ptr %.fca.4.gep.i, align 1, !tbaa !8
  store i8 2, ptr %.fca.5.gep.i, align 2, !tbaa !8
  store i8 0, ptr %.fca.6.gep.i, align 1, !tbaa !8
  store i64 1, ptr %.fca.7.0.0.gep.i, align 8, !tbaa !8
  store i64 1048576, ptr %.fca.7.0.1.gep.i, align 8, !tbaa !8
  store i64 8, ptr %.fca.7.0.2.gep.i, align 8, !tbaa !8
  %omp_global_thread_num.i = call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %4, ptr %structArg.i, align 8
  %gep_5.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 1
  store ptr %3, ptr %gep_5.i, align 8
  %gep_6.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 2
  store ptr %2, ptr %gep_6.i, align 8
  %gep_7.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 3
  store ptr %1, ptr %gep_7.i, align 8
  %gep_8.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 4
  store ptr %6, ptr %gep_8.i, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QFPomp_subroutine..omp_par, ptr nonnull %structArg.i)
  %.fca.0.load.i = load ptr, ptr %3, align 8, !tbaa !8
  %.fca.7.0.0.load.i = load i64, ptr %.fca.7.0.0.gep.i, align 8, !tbaa !8
  %9 = sub i64 1, %.fca.7.0.0.load.i
  %10 = getelementptr double, ptr %.fca.0.load.i, i64 %9
  %11 = load double, ptr %10, align 8, !tbaa !4
  %12 = load i32, ptr %4, align 4, !tbaa !4
  %13 = sext i32 %12 to i64
  %14 = sub i64 %13, %.fca.7.0.0.load.i
  %15 = getelementptr double, ptr %.fca.0.load.i, i64 %14
  %16 = load double, ptr %15, align 8, !tbaa !4
  %17 = fadd contract double %11, %16
  call void @free(ptr %.fca.0.load.i)
  call void @llvm.lifetime.end.p0(i64 40, ptr nonnull %structArg.i)
  call void @llvm.lifetime.end.p0(i64 48, ptr nonnull %1)
  call void @llvm.lifetime.end.p0(i64 48, ptr nonnull %2)
  call void @llvm.lifetime.end.p0(i64 48, ptr nonnull %3)
  %18 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.e8a0ac9186c064ac8543d822e9060d96, i32 10)
  %19 = call i1 @_FortranAioOutputAscii(ptr %18, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %20 = load i32, ptr %4, align 4, !tbaa !4
  %21 = call i1 @_FortranAioOutputInteger32(ptr %18, i32 %20)
  %22 = call i1 @_FortranAioOutputAscii(ptr %18, ptr nonnull @_QQcl.2920697320, i64 5)
  %23 = call i1 @_FortranAioOutputReal64(ptr %18, double %17)
  %24 = call i32 @_FortranAioEndIoStatement(ptr %18)
  ret void
}
*** IR Dump After LoopLoadEliminationPass on _QQmain ***
define void @_QQmain() local_unnamed_addr {
  %structArg.i = alloca { ptr, ptr, ptr, ptr, ptr }, align 8
  %1 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %2 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %3 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %4 = alloca i32, align 4
  %5 = alloca double, align 8
  %6 = alloca { ptr, ptr }, align 8
  store ptr %4, ptr %6, align 8, !tbaa !4
  %7 = getelementptr inbounds { ptr, ptr }, ptr %6, i64 0, i32 1
  store ptr %5, ptr %7, align 8, !tbaa !4
  store i32 1048576, ptr %4, align 4, !tbaa !4
  call void @llvm.lifetime.start.p0(i64 40, ptr nonnull %structArg.i)
  call void @llvm.lifetime.start.p0(i64 48, ptr nonnull %1)
  call void @llvm.lifetime.start.p0(i64 48, ptr nonnull %2)
  call void @llvm.lifetime.start.p0(i64 48, ptr nonnull %3)
  %.fca.1.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 1
  %.fca.2.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 2
  %.fca.3.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 3
  %.fca.4.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 4
  %.fca.5.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 5
  %.fca.6.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 6
  %.fca.7.0.0.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 7, i64 0, i64 0
  %.fca.7.0.1.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 7, i64 0, i64 1
  %.fca.7.0.2.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 7, i64 0, i64 2
  %8 = call dereferenceable_or_null(8388608) ptr @malloc(i64 8388608)
  store ptr %8, ptr %3, align 8, !tbaa !8
  store i64 8, ptr %.fca.1.gep.i, align 8, !tbaa !8
  store i32 20180515, ptr %.fca.2.gep.i, align 8, !tbaa !8
  store i8 1, ptr %.fca.3.gep.i, align 4, !tbaa !8
  store i8 28, ptr %.fca.4.gep.i, align 1, !tbaa !8
  store i8 2, ptr %.fca.5.gep.i, align 2, !tbaa !8
  store i8 0, ptr %.fca.6.gep.i, align 1, !tbaa !8
  store i64 1, ptr %.fca.7.0.0.gep.i, align 8, !tbaa !8
  store i64 1048576, ptr %.fca.7.0.1.gep.i, align 8, !tbaa !8
  store i64 8, ptr %.fca.7.0.2.gep.i, align 8, !tbaa !8
  %omp_global_thread_num.i = call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %4, ptr %structArg.i, align 8
  %gep_5.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 1
  store ptr %3, ptr %gep_5.i, align 8
  %gep_6.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 2
  store ptr %2, ptr %gep_6.i, align 8
  %gep_7.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 3
  store ptr %1, ptr %gep_7.i, align 8
  %gep_8.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 4
  store ptr %6, ptr %gep_8.i, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QFPomp_subroutine..omp_par, ptr nonnull %structArg.i)
  %.fca.0.load.i = load ptr, ptr %3, align 8, !tbaa !8
  %.fca.7.0.0.load.i = load i64, ptr %.fca.7.0.0.gep.i, align 8, !tbaa !8
  %9 = sub i64 1, %.fca.7.0.0.load.i
  %10 = getelementptr double, ptr %.fca.0.load.i, i64 %9
  %11 = load double, ptr %10, align 8, !tbaa !4
  %12 = load i32, ptr %4, align 4, !tbaa !4
  %13 = sext i32 %12 to i64
  %14 = sub i64 %13, %.fca.7.0.0.load.i
  %15 = getelementptr double, ptr %.fca.0.load.i, i64 %14
  %16 = load double, ptr %15, align 8, !tbaa !4
  %17 = fadd contract double %11, %16
  call void @free(ptr %.fca.0.load.i)
  call void @llvm.lifetime.end.p0(i64 40, ptr nonnull %structArg.i)
  call void @llvm.lifetime.end.p0(i64 48, ptr nonnull %1)
  call void @llvm.lifetime.end.p0(i64 48, ptr nonnull %2)
  call void @llvm.lifetime.end.p0(i64 48, ptr nonnull %3)
  %18 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.e8a0ac9186c064ac8543d822e9060d96, i32 10)
  %19 = call i1 @_FortranAioOutputAscii(ptr %18, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %20 = load i32, ptr %4, align 4, !tbaa !4
  %21 = call i1 @_FortranAioOutputInteger32(ptr %18, i32 %20)
  %22 = call i1 @_FortranAioOutputAscii(ptr %18, ptr nonnull @_QQcl.2920697320, i64 5)
  %23 = call i1 @_FortranAioOutputReal64(ptr %18, double %17)
  %24 = call i32 @_FortranAioEndIoStatement(ptr %18)
  ret void
}
*** IR Dump After InstCombinePass on _QQmain ***
define void @_QQmain() local_unnamed_addr {
  %structArg.i = alloca { ptr, ptr, ptr, ptr, ptr }, align 8
  %1 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %2 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %3 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %4 = alloca i32, align 4
  %5 = alloca double, align 8
  %6 = alloca { ptr, ptr }, align 8
  store ptr %4, ptr %6, align 8, !tbaa !4
  %7 = getelementptr inbounds { ptr, ptr }, ptr %6, i64 0, i32 1
  store ptr %5, ptr %7, align 8, !tbaa !4
  store i32 1048576, ptr %4, align 4, !tbaa !4
  call void @llvm.lifetime.start.p0(i64 40, ptr nonnull %structArg.i)
  call void @llvm.lifetime.start.p0(i64 48, ptr nonnull %1)
  call void @llvm.lifetime.start.p0(i64 48, ptr nonnull %2)
  call void @llvm.lifetime.start.p0(i64 48, ptr nonnull %3)
  %.fca.1.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 1
  %.fca.2.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 2
  %.fca.3.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 3
  %.fca.4.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 4
  %.fca.5.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 5
  %.fca.6.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 6
  %.fca.7.0.0.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 7, i64 0, i64 0
  %.fca.7.0.1.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 7, i64 0, i64 1
  %.fca.7.0.2.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 7, i64 0, i64 2
  %8 = call dereferenceable_or_null(8388608) ptr @malloc(i64 8388608)
  store ptr %8, ptr %3, align 8, !tbaa !8
  store i64 8, ptr %.fca.1.gep.i, align 8, !tbaa !8
  store i32 20180515, ptr %.fca.2.gep.i, align 8, !tbaa !8
  store i8 1, ptr %.fca.3.gep.i, align 4, !tbaa !8
  store i8 28, ptr %.fca.4.gep.i, align 1, !tbaa !8
  store i8 2, ptr %.fca.5.gep.i, align 2, !tbaa !8
  store i8 0, ptr %.fca.6.gep.i, align 1, !tbaa !8
  store i64 1, ptr %.fca.7.0.0.gep.i, align 8, !tbaa !8
  store i64 1048576, ptr %.fca.7.0.1.gep.i, align 8, !tbaa !8
  store i64 8, ptr %.fca.7.0.2.gep.i, align 8, !tbaa !8
  %omp_global_thread_num.i = call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %4, ptr %structArg.i, align 8
  %gep_5.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 1
  store ptr %3, ptr %gep_5.i, align 8
  %gep_6.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 2
  store ptr %2, ptr %gep_6.i, align 8
  %gep_7.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 3
  store ptr %1, ptr %gep_7.i, align 8
  %gep_8.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 4
  store ptr %6, ptr %gep_8.i, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QFPomp_subroutine..omp_par, ptr nonnull %structArg.i)
  %.fca.0.load.i = load ptr, ptr %3, align 8, !tbaa !8
  %.fca.7.0.0.load.i = load i64, ptr %.fca.7.0.0.gep.i, align 8, !tbaa !8
  %9 = sub i64 1, %.fca.7.0.0.load.i
  %10 = getelementptr double, ptr %.fca.0.load.i, i64 %9
  %11 = load double, ptr %10, align 8, !tbaa !4
  %12 = load i32, ptr %4, align 4, !tbaa !4
  %13 = sext i32 %12 to i64
  %14 = sub i64 %13, %.fca.7.0.0.load.i
  %15 = getelementptr double, ptr %.fca.0.load.i, i64 %14
  %16 = load double, ptr %15, align 8, !tbaa !4
  %17 = fadd contract double %11, %16
  call void @free(ptr %.fca.0.load.i)
  call void @llvm.lifetime.end.p0(i64 40, ptr nonnull %structArg.i)
  call void @llvm.lifetime.end.p0(i64 48, ptr nonnull %1)
  call void @llvm.lifetime.end.p0(i64 48, ptr nonnull %2)
  call void @llvm.lifetime.end.p0(i64 48, ptr nonnull %3)
  %18 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.e8a0ac9186c064ac8543d822e9060d96, i32 10)
  %19 = call i1 @_FortranAioOutputAscii(ptr %18, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %20 = load i32, ptr %4, align 4, !tbaa !4
  %21 = call i1 @_FortranAioOutputInteger32(ptr %18, i32 %20)
  %22 = call i1 @_FortranAioOutputAscii(ptr %18, ptr nonnull @_QQcl.2920697320, i64 5)
  %23 = call i1 @_FortranAioOutputReal64(ptr %18, double %17)
  %24 = call i32 @_FortranAioEndIoStatement(ptr %18)
  ret void
}
*** IR Dump After SimplifyCFGPass on _QQmain ***
define void @_QQmain() local_unnamed_addr {
  %structArg.i = alloca { ptr, ptr, ptr, ptr, ptr }, align 8
  %1 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %2 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %3 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %4 = alloca i32, align 4
  %5 = alloca double, align 8
  %6 = alloca { ptr, ptr }, align 8
  store ptr %4, ptr %6, align 8, !tbaa !4
  %7 = getelementptr inbounds { ptr, ptr }, ptr %6, i64 0, i32 1
  store ptr %5, ptr %7, align 8, !tbaa !4
  store i32 1048576, ptr %4, align 4, !tbaa !4
  call void @llvm.lifetime.start.p0(i64 40, ptr nonnull %structArg.i)
  call void @llvm.lifetime.start.p0(i64 48, ptr nonnull %1)
  call void @llvm.lifetime.start.p0(i64 48, ptr nonnull %2)
  call void @llvm.lifetime.start.p0(i64 48, ptr nonnull %3)
  %.fca.1.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 1
  %.fca.2.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 2
  %.fca.3.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 3
  %.fca.4.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 4
  %.fca.5.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 5
  %.fca.6.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 6
  %.fca.7.0.0.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 7, i64 0, i64 0
  %.fca.7.0.1.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 7, i64 0, i64 1
  %.fca.7.0.2.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 7, i64 0, i64 2
  %8 = call dereferenceable_or_null(8388608) ptr @malloc(i64 8388608)
  store ptr %8, ptr %3, align 8, !tbaa !8
  store i64 8, ptr %.fca.1.gep.i, align 8, !tbaa !8
  store i32 20180515, ptr %.fca.2.gep.i, align 8, !tbaa !8
  store i8 1, ptr %.fca.3.gep.i, align 4, !tbaa !8
  store i8 28, ptr %.fca.4.gep.i, align 1, !tbaa !8
  store i8 2, ptr %.fca.5.gep.i, align 2, !tbaa !8
  store i8 0, ptr %.fca.6.gep.i, align 1, !tbaa !8
  store i64 1, ptr %.fca.7.0.0.gep.i, align 8, !tbaa !8
  store i64 1048576, ptr %.fca.7.0.1.gep.i, align 8, !tbaa !8
  store i64 8, ptr %.fca.7.0.2.gep.i, align 8, !tbaa !8
  %omp_global_thread_num.i = call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %4, ptr %structArg.i, align 8
  %gep_5.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 1
  store ptr %3, ptr %gep_5.i, align 8
  %gep_6.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 2
  store ptr %2, ptr %gep_6.i, align 8
  %gep_7.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 3
  store ptr %1, ptr %gep_7.i, align 8
  %gep_8.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 4
  store ptr %6, ptr %gep_8.i, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QFPomp_subroutine..omp_par, ptr nonnull %structArg.i)
  %.fca.0.load.i = load ptr, ptr %3, align 8, !tbaa !8
  %.fca.7.0.0.load.i = load i64, ptr %.fca.7.0.0.gep.i, align 8, !tbaa !8
  %9 = sub i64 1, %.fca.7.0.0.load.i
  %10 = getelementptr double, ptr %.fca.0.load.i, i64 %9
  %11 = load double, ptr %10, align 8, !tbaa !4
  %12 = load i32, ptr %4, align 4, !tbaa !4
  %13 = sext i32 %12 to i64
  %14 = sub i64 %13, %.fca.7.0.0.load.i
  %15 = getelementptr double, ptr %.fca.0.load.i, i64 %14
  %16 = load double, ptr %15, align 8, !tbaa !4
  %17 = fadd contract double %11, %16
  call void @free(ptr %.fca.0.load.i)
  call void @llvm.lifetime.end.p0(i64 40, ptr nonnull %structArg.i)
  call void @llvm.lifetime.end.p0(i64 48, ptr nonnull %1)
  call void @llvm.lifetime.end.p0(i64 48, ptr nonnull %2)
  call void @llvm.lifetime.end.p0(i64 48, ptr nonnull %3)
  %18 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.e8a0ac9186c064ac8543d822e9060d96, i32 10)
  %19 = call i1 @_FortranAioOutputAscii(ptr %18, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %20 = load i32, ptr %4, align 4, !tbaa !4
  %21 = call i1 @_FortranAioOutputInteger32(ptr %18, i32 %20)
  %22 = call i1 @_FortranAioOutputAscii(ptr %18, ptr nonnull @_QQcl.2920697320, i64 5)
  %23 = call i1 @_FortranAioOutputReal64(ptr %18, double %17)
  %24 = call i32 @_FortranAioEndIoStatement(ptr %18)
  ret void
}
*** IR Dump After VectorCombinePass on _QQmain ***
define void @_QQmain() local_unnamed_addr {
  %structArg.i = alloca { ptr, ptr, ptr, ptr, ptr }, align 8
  %1 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %2 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %3 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %4 = alloca i32, align 4
  %5 = alloca double, align 8
  %6 = alloca { ptr, ptr }, align 8
  store ptr %4, ptr %6, align 8, !tbaa !4
  %7 = getelementptr inbounds { ptr, ptr }, ptr %6, i64 0, i32 1
  store ptr %5, ptr %7, align 8, !tbaa !4
  store i32 1048576, ptr %4, align 4, !tbaa !4
  call void @llvm.lifetime.start.p0(i64 40, ptr nonnull %structArg.i)
  call void @llvm.lifetime.start.p0(i64 48, ptr nonnull %1)
  call void @llvm.lifetime.start.p0(i64 48, ptr nonnull %2)
  call void @llvm.lifetime.start.p0(i64 48, ptr nonnull %3)
  %.fca.1.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 1
  %.fca.2.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 2
  %.fca.3.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 3
  %.fca.4.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 4
  %.fca.5.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 5
  %.fca.6.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 6
  %.fca.7.0.0.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 7, i64 0, i64 0
  %.fca.7.0.1.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 7, i64 0, i64 1
  %.fca.7.0.2.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 7, i64 0, i64 2
  %8 = call dereferenceable_or_null(8388608) ptr @malloc(i64 8388608)
  store ptr %8, ptr %3, align 8, !tbaa !8
  store i64 8, ptr %.fca.1.gep.i, align 8, !tbaa !8
  store i32 20180515, ptr %.fca.2.gep.i, align 8, !tbaa !8
  store i8 1, ptr %.fca.3.gep.i, align 4, !tbaa !8
  store i8 28, ptr %.fca.4.gep.i, align 1, !tbaa !8
  store i8 2, ptr %.fca.5.gep.i, align 2, !tbaa !8
  store i8 0, ptr %.fca.6.gep.i, align 1, !tbaa !8
  store i64 1, ptr %.fca.7.0.0.gep.i, align 8, !tbaa !8
  store i64 1048576, ptr %.fca.7.0.1.gep.i, align 8, !tbaa !8
  store i64 8, ptr %.fca.7.0.2.gep.i, align 8, !tbaa !8
  %omp_global_thread_num.i = call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %4, ptr %structArg.i, align 8
  %gep_5.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 1
  store ptr %3, ptr %gep_5.i, align 8
  %gep_6.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 2
  store ptr %2, ptr %gep_6.i, align 8
  %gep_7.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 3
  store ptr %1, ptr %gep_7.i, align 8
  %gep_8.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 4
  store ptr %6, ptr %gep_8.i, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QFPomp_subroutine..omp_par, ptr nonnull %structArg.i)
  %.fca.0.load.i = load ptr, ptr %3, align 8, !tbaa !8
  %.fca.7.0.0.load.i = load i64, ptr %.fca.7.0.0.gep.i, align 8, !tbaa !8
  %9 = sub i64 1, %.fca.7.0.0.load.i
  %10 = getelementptr double, ptr %.fca.0.load.i, i64 %9
  %11 = load double, ptr %10, align 8, !tbaa !4
  %12 = load i32, ptr %4, align 4, !tbaa !4
  %13 = sext i32 %12 to i64
  %14 = sub i64 %13, %.fca.7.0.0.load.i
  %15 = getelementptr double, ptr %.fca.0.load.i, i64 %14
  %16 = load double, ptr %15, align 8, !tbaa !4
  %17 = fadd contract double %11, %16
  call void @free(ptr %.fca.0.load.i)
  call void @llvm.lifetime.end.p0(i64 40, ptr nonnull %structArg.i)
  call void @llvm.lifetime.end.p0(i64 48, ptr nonnull %1)
  call void @llvm.lifetime.end.p0(i64 48, ptr nonnull %2)
  call void @llvm.lifetime.end.p0(i64 48, ptr nonnull %3)
  %18 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.e8a0ac9186c064ac8543d822e9060d96, i32 10)
  %19 = call i1 @_FortranAioOutputAscii(ptr %18, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %20 = load i32, ptr %4, align 4, !tbaa !4
  %21 = call i1 @_FortranAioOutputInteger32(ptr %18, i32 %20)
  %22 = call i1 @_FortranAioOutputAscii(ptr %18, ptr nonnull @_QQcl.2920697320, i64 5)
  %23 = call i1 @_FortranAioOutputReal64(ptr %18, double %17)
  %24 = call i32 @_FortranAioEndIoStatement(ptr %18)
  ret void
}
*** IR Dump After InstCombinePass on _QQmain ***
define void @_QQmain() local_unnamed_addr {
  %structArg.i = alloca { ptr, ptr, ptr, ptr, ptr }, align 8
  %1 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %2 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %3 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %4 = alloca i32, align 4
  %5 = alloca double, align 8
  %6 = alloca { ptr, ptr }, align 8
  store ptr %4, ptr %6, align 8, !tbaa !4
  %7 = getelementptr inbounds { ptr, ptr }, ptr %6, i64 0, i32 1
  store ptr %5, ptr %7, align 8, !tbaa !4
  store i32 1048576, ptr %4, align 4, !tbaa !4
  call void @llvm.lifetime.start.p0(i64 40, ptr nonnull %structArg.i)
  call void @llvm.lifetime.start.p0(i64 48, ptr nonnull %1)
  call void @llvm.lifetime.start.p0(i64 48, ptr nonnull %2)
  call void @llvm.lifetime.start.p0(i64 48, ptr nonnull %3)
  %.fca.1.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 1
  %.fca.2.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 2
  %.fca.3.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 3
  %.fca.4.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 4
  %.fca.5.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 5
  %.fca.6.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 6
  %.fca.7.0.0.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 7, i64 0, i64 0
  %.fca.7.0.1.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 7, i64 0, i64 1
  %.fca.7.0.2.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 7, i64 0, i64 2
  %8 = call dereferenceable_or_null(8388608) ptr @malloc(i64 8388608)
  store ptr %8, ptr %3, align 8, !tbaa !8
  store i64 8, ptr %.fca.1.gep.i, align 8, !tbaa !8
  store i32 20180515, ptr %.fca.2.gep.i, align 8, !tbaa !8
  store i8 1, ptr %.fca.3.gep.i, align 4, !tbaa !8
  store i8 28, ptr %.fca.4.gep.i, align 1, !tbaa !8
  store i8 2, ptr %.fca.5.gep.i, align 2, !tbaa !8
  store i8 0, ptr %.fca.6.gep.i, align 1, !tbaa !8
  store i64 1, ptr %.fca.7.0.0.gep.i, align 8, !tbaa !8
  store i64 1048576, ptr %.fca.7.0.1.gep.i, align 8, !tbaa !8
  store i64 8, ptr %.fca.7.0.2.gep.i, align 8, !tbaa !8
  %omp_global_thread_num.i = call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %4, ptr %structArg.i, align 8
  %gep_5.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 1
  store ptr %3, ptr %gep_5.i, align 8
  %gep_6.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 2
  store ptr %2, ptr %gep_6.i, align 8
  %gep_7.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 3
  store ptr %1, ptr %gep_7.i, align 8
  %gep_8.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 4
  store ptr %6, ptr %gep_8.i, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QFPomp_subroutine..omp_par, ptr nonnull %structArg.i)
  %.fca.0.load.i = load ptr, ptr %3, align 8, !tbaa !8
  %.fca.7.0.0.load.i = load i64, ptr %.fca.7.0.0.gep.i, align 8, !tbaa !8
  %9 = sub i64 1, %.fca.7.0.0.load.i
  %10 = getelementptr double, ptr %.fca.0.load.i, i64 %9
  %11 = load double, ptr %10, align 8, !tbaa !4
  %12 = load i32, ptr %4, align 4, !tbaa !4
  %13 = sext i32 %12 to i64
  %14 = sub i64 %13, %.fca.7.0.0.load.i
  %15 = getelementptr double, ptr %.fca.0.load.i, i64 %14
  %16 = load double, ptr %15, align 8, !tbaa !4
  %17 = fadd contract double %11, %16
  call void @free(ptr %.fca.0.load.i)
  call void @llvm.lifetime.end.p0(i64 40, ptr nonnull %structArg.i)
  call void @llvm.lifetime.end.p0(i64 48, ptr nonnull %1)
  call void @llvm.lifetime.end.p0(i64 48, ptr nonnull %2)
  call void @llvm.lifetime.end.p0(i64 48, ptr nonnull %3)
  %18 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.e8a0ac9186c064ac8543d822e9060d96, i32 10)
  %19 = call i1 @_FortranAioOutputAscii(ptr %18, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %20 = load i32, ptr %4, align 4, !tbaa !4
  %21 = call i1 @_FortranAioOutputInteger32(ptr %18, i32 %20)
  %22 = call i1 @_FortranAioOutputAscii(ptr %18, ptr nonnull @_QQcl.2920697320, i64 5)
  %23 = call i1 @_FortranAioOutputReal64(ptr %18, double %17)
  %24 = call i32 @_FortranAioEndIoStatement(ptr %18)
  ret void
}
*** IR Dump After LoopUnrollPass on _QQmain ***
define void @_QQmain() local_unnamed_addr {
  %structArg.i = alloca { ptr, ptr, ptr, ptr, ptr }, align 8
  %1 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %2 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %3 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %4 = alloca i32, align 4
  %5 = alloca double, align 8
  %6 = alloca { ptr, ptr }, align 8
  store ptr %4, ptr %6, align 8, !tbaa !4
  %7 = getelementptr inbounds { ptr, ptr }, ptr %6, i64 0, i32 1
  store ptr %5, ptr %7, align 8, !tbaa !4
  store i32 1048576, ptr %4, align 4, !tbaa !4
  call void @llvm.lifetime.start.p0(i64 40, ptr nonnull %structArg.i)
  call void @llvm.lifetime.start.p0(i64 48, ptr nonnull %1)
  call void @llvm.lifetime.start.p0(i64 48, ptr nonnull %2)
  call void @llvm.lifetime.start.p0(i64 48, ptr nonnull %3)
  %.fca.1.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 1
  %.fca.2.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 2
  %.fca.3.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 3
  %.fca.4.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 4
  %.fca.5.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 5
  %.fca.6.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 6
  %.fca.7.0.0.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 7, i64 0, i64 0
  %.fca.7.0.1.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 7, i64 0, i64 1
  %.fca.7.0.2.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 7, i64 0, i64 2
  %8 = call dereferenceable_or_null(8388608) ptr @malloc(i64 8388608)
  store ptr %8, ptr %3, align 8, !tbaa !8
  store i64 8, ptr %.fca.1.gep.i, align 8, !tbaa !8
  store i32 20180515, ptr %.fca.2.gep.i, align 8, !tbaa !8
  store i8 1, ptr %.fca.3.gep.i, align 4, !tbaa !8
  store i8 28, ptr %.fca.4.gep.i, align 1, !tbaa !8
  store i8 2, ptr %.fca.5.gep.i, align 2, !tbaa !8
  store i8 0, ptr %.fca.6.gep.i, align 1, !tbaa !8
  store i64 1, ptr %.fca.7.0.0.gep.i, align 8, !tbaa !8
  store i64 1048576, ptr %.fca.7.0.1.gep.i, align 8, !tbaa !8
  store i64 8, ptr %.fca.7.0.2.gep.i, align 8, !tbaa !8
  %omp_global_thread_num.i = call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %4, ptr %structArg.i, align 8
  %gep_5.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 1
  store ptr %3, ptr %gep_5.i, align 8
  %gep_6.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 2
  store ptr %2, ptr %gep_6.i, align 8
  %gep_7.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 3
  store ptr %1, ptr %gep_7.i, align 8
  %gep_8.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 4
  store ptr %6, ptr %gep_8.i, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QFPomp_subroutine..omp_par, ptr nonnull %structArg.i)
  %.fca.0.load.i = load ptr, ptr %3, align 8, !tbaa !8
  %.fca.7.0.0.load.i = load i64, ptr %.fca.7.0.0.gep.i, align 8, !tbaa !8
  %9 = sub i64 1, %.fca.7.0.0.load.i
  %10 = getelementptr double, ptr %.fca.0.load.i, i64 %9
  %11 = load double, ptr %10, align 8, !tbaa !4
  %12 = load i32, ptr %4, align 4, !tbaa !4
  %13 = sext i32 %12 to i64
  %14 = sub i64 %13, %.fca.7.0.0.load.i
  %15 = getelementptr double, ptr %.fca.0.load.i, i64 %14
  %16 = load double, ptr %15, align 8, !tbaa !4
  %17 = fadd contract double %11, %16
  call void @free(ptr %.fca.0.load.i)
  call void @llvm.lifetime.end.p0(i64 40, ptr nonnull %structArg.i)
  call void @llvm.lifetime.end.p0(i64 48, ptr nonnull %1)
  call void @llvm.lifetime.end.p0(i64 48, ptr nonnull %2)
  call void @llvm.lifetime.end.p0(i64 48, ptr nonnull %3)
  %18 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.e8a0ac9186c064ac8543d822e9060d96, i32 10)
  %19 = call i1 @_FortranAioOutputAscii(ptr %18, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %20 = load i32, ptr %4, align 4, !tbaa !4
  %21 = call i1 @_FortranAioOutputInteger32(ptr %18, i32 %20)
  %22 = call i1 @_FortranAioOutputAscii(ptr %18, ptr nonnull @_QQcl.2920697320, i64 5)
  %23 = call i1 @_FortranAioOutputReal64(ptr %18, double %17)
  %24 = call i32 @_FortranAioEndIoStatement(ptr %18)
  ret void
}
*** IR Dump After WarnMissedTransformationsPass on _QQmain ***
define void @_QQmain() local_unnamed_addr {
  %structArg.i = alloca { ptr, ptr, ptr, ptr, ptr }, align 8
  %1 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %2 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %3 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %4 = alloca i32, align 4
  %5 = alloca double, align 8
  %6 = alloca { ptr, ptr }, align 8
  store ptr %4, ptr %6, align 8, !tbaa !4
  %7 = getelementptr inbounds { ptr, ptr }, ptr %6, i64 0, i32 1
  store ptr %5, ptr %7, align 8, !tbaa !4
  store i32 1048576, ptr %4, align 4, !tbaa !4
  call void @llvm.lifetime.start.p0(i64 40, ptr nonnull %structArg.i)
  call void @llvm.lifetime.start.p0(i64 48, ptr nonnull %1)
  call void @llvm.lifetime.start.p0(i64 48, ptr nonnull %2)
  call void @llvm.lifetime.start.p0(i64 48, ptr nonnull %3)
  %.fca.1.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 1
  %.fca.2.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 2
  %.fca.3.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 3
  %.fca.4.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 4
  %.fca.5.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 5
  %.fca.6.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 6
  %.fca.7.0.0.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 7, i64 0, i64 0
  %.fca.7.0.1.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 7, i64 0, i64 1
  %.fca.7.0.2.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 7, i64 0, i64 2
  %8 = call dereferenceable_or_null(8388608) ptr @malloc(i64 8388608)
  store ptr %8, ptr %3, align 8, !tbaa !8
  store i64 8, ptr %.fca.1.gep.i, align 8, !tbaa !8
  store i32 20180515, ptr %.fca.2.gep.i, align 8, !tbaa !8
  store i8 1, ptr %.fca.3.gep.i, align 4, !tbaa !8
  store i8 28, ptr %.fca.4.gep.i, align 1, !tbaa !8
  store i8 2, ptr %.fca.5.gep.i, align 2, !tbaa !8
  store i8 0, ptr %.fca.6.gep.i, align 1, !tbaa !8
  store i64 1, ptr %.fca.7.0.0.gep.i, align 8, !tbaa !8
  store i64 1048576, ptr %.fca.7.0.1.gep.i, align 8, !tbaa !8
  store i64 8, ptr %.fca.7.0.2.gep.i, align 8, !tbaa !8
  %omp_global_thread_num.i = call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %4, ptr %structArg.i, align 8
  %gep_5.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 1
  store ptr %3, ptr %gep_5.i, align 8
  %gep_6.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 2
  store ptr %2, ptr %gep_6.i, align 8
  %gep_7.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 3
  store ptr %1, ptr %gep_7.i, align 8
  %gep_8.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 4
  store ptr %6, ptr %gep_8.i, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QFPomp_subroutine..omp_par, ptr nonnull %structArg.i)
  %.fca.0.load.i = load ptr, ptr %3, align 8, !tbaa !8
  %.fca.7.0.0.load.i = load i64, ptr %.fca.7.0.0.gep.i, align 8, !tbaa !8
  %9 = sub i64 1, %.fca.7.0.0.load.i
  %10 = getelementptr double, ptr %.fca.0.load.i, i64 %9
  %11 = load double, ptr %10, align 8, !tbaa !4
  %12 = load i32, ptr %4, align 4, !tbaa !4
  %13 = sext i32 %12 to i64
  %14 = sub i64 %13, %.fca.7.0.0.load.i
  %15 = getelementptr double, ptr %.fca.0.load.i, i64 %14
  %16 = load double, ptr %15, align 8, !tbaa !4
  %17 = fadd contract double %11, %16
  call void @free(ptr %.fca.0.load.i)
  call void @llvm.lifetime.end.p0(i64 40, ptr nonnull %structArg.i)
  call void @llvm.lifetime.end.p0(i64 48, ptr nonnull %1)
  call void @llvm.lifetime.end.p0(i64 48, ptr nonnull %2)
  call void @llvm.lifetime.end.p0(i64 48, ptr nonnull %3)
  %18 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.e8a0ac9186c064ac8543d822e9060d96, i32 10)
  %19 = call i1 @_FortranAioOutputAscii(ptr %18, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %20 = load i32, ptr %4, align 4, !tbaa !4
  %21 = call i1 @_FortranAioOutputInteger32(ptr %18, i32 %20)
  %22 = call i1 @_FortranAioOutputAscii(ptr %18, ptr nonnull @_QQcl.2920697320, i64 5)
  %23 = call i1 @_FortranAioOutputReal64(ptr %18, double %17)
  %24 = call i32 @_FortranAioEndIoStatement(ptr %18)
  ret void
}
*** IR Dump After SROAPass on _QQmain ***
define void @_QQmain() local_unnamed_addr {
  %structArg.i = alloca { ptr, ptr, ptr, ptr, ptr }, align 8
  %1 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %2 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %3 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %4 = alloca i32, align 4
  %5 = alloca double, align 8
  %6 = alloca { ptr, ptr }, align 8
  store ptr %4, ptr %6, align 8, !tbaa !4
  %7 = getelementptr inbounds { ptr, ptr }, ptr %6, i64 0, i32 1
  store ptr %5, ptr %7, align 8, !tbaa !4
  store i32 1048576, ptr %4, align 4, !tbaa !4
  call void @llvm.lifetime.start.p0(i64 40, ptr nonnull %structArg.i)
  call void @llvm.lifetime.start.p0(i64 48, ptr nonnull %1)
  call void @llvm.lifetime.start.p0(i64 48, ptr nonnull %2)
  call void @llvm.lifetime.start.p0(i64 48, ptr nonnull %3)
  %.fca.1.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 1
  %.fca.2.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 2
  %.fca.3.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 3
  %.fca.4.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 4
  %.fca.5.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 5
  %.fca.6.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 6
  %.fca.7.0.0.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 7, i64 0, i64 0
  %.fca.7.0.1.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 7, i64 0, i64 1
  %.fca.7.0.2.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 7, i64 0, i64 2
  %8 = call dereferenceable_or_null(8388608) ptr @malloc(i64 8388608)
  store ptr %8, ptr %3, align 8, !tbaa !8
  store i64 8, ptr %.fca.1.gep.i, align 8, !tbaa !8
  store i32 20180515, ptr %.fca.2.gep.i, align 8, !tbaa !8
  store i8 1, ptr %.fca.3.gep.i, align 4, !tbaa !8
  store i8 28, ptr %.fca.4.gep.i, align 1, !tbaa !8
  store i8 2, ptr %.fca.5.gep.i, align 2, !tbaa !8
  store i8 0, ptr %.fca.6.gep.i, align 1, !tbaa !8
  store i64 1, ptr %.fca.7.0.0.gep.i, align 8, !tbaa !8
  store i64 1048576, ptr %.fca.7.0.1.gep.i, align 8, !tbaa !8
  store i64 8, ptr %.fca.7.0.2.gep.i, align 8, !tbaa !8
  %omp_global_thread_num.i = call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %4, ptr %structArg.i, align 8
  %gep_5.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 1
  store ptr %3, ptr %gep_5.i, align 8
  %gep_6.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 2
  store ptr %2, ptr %gep_6.i, align 8
  %gep_7.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 3
  store ptr %1, ptr %gep_7.i, align 8
  %gep_8.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 4
  store ptr %6, ptr %gep_8.i, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QFPomp_subroutine..omp_par, ptr nonnull %structArg.i)
  %.fca.0.load.i = load ptr, ptr %3, align 8, !tbaa !8
  %.fca.7.0.0.load.i = load i64, ptr %.fca.7.0.0.gep.i, align 8, !tbaa !8
  %9 = sub i64 1, %.fca.7.0.0.load.i
  %10 = getelementptr double, ptr %.fca.0.load.i, i64 %9
  %11 = load double, ptr %10, align 8, !tbaa !4
  %12 = load i32, ptr %4, align 4, !tbaa !4
  %13 = sext i32 %12 to i64
  %14 = sub i64 %13, %.fca.7.0.0.load.i
  %15 = getelementptr double, ptr %.fca.0.load.i, i64 %14
  %16 = load double, ptr %15, align 8, !tbaa !4
  %17 = fadd contract double %11, %16
  call void @free(ptr %.fca.0.load.i)
  call void @llvm.lifetime.end.p0(i64 40, ptr nonnull %structArg.i)
  call void @llvm.lifetime.end.p0(i64 48, ptr nonnull %1)
  call void @llvm.lifetime.end.p0(i64 48, ptr nonnull %2)
  call void @llvm.lifetime.end.p0(i64 48, ptr nonnull %3)
  %18 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.e8a0ac9186c064ac8543d822e9060d96, i32 10)
  %19 = call i1 @_FortranAioOutputAscii(ptr %18, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %20 = load i32, ptr %4, align 4, !tbaa !4
  %21 = call i1 @_FortranAioOutputInteger32(ptr %18, i32 %20)
  %22 = call i1 @_FortranAioOutputAscii(ptr %18, ptr nonnull @_QQcl.2920697320, i64 5)
  %23 = call i1 @_FortranAioOutputReal64(ptr %18, double %17)
  %24 = call i32 @_FortranAioEndIoStatement(ptr %18)
  ret void
}
*** IR Dump After InstCombinePass on _QQmain ***
define void @_QQmain() local_unnamed_addr {
  %structArg.i = alloca { ptr, ptr, ptr, ptr, ptr }, align 8
  %1 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %2 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %3 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %4 = alloca i32, align 4
  %5 = alloca double, align 8
  %6 = alloca { ptr, ptr }, align 8
  store ptr %4, ptr %6, align 8, !tbaa !4
  %7 = getelementptr inbounds { ptr, ptr }, ptr %6, i64 0, i32 1
  store ptr %5, ptr %7, align 8, !tbaa !4
  store i32 1048576, ptr %4, align 4, !tbaa !4
  call void @llvm.lifetime.start.p0(i64 40, ptr nonnull %structArg.i)
  call void @llvm.lifetime.start.p0(i64 48, ptr nonnull %1)
  call void @llvm.lifetime.start.p0(i64 48, ptr nonnull %2)
  call void @llvm.lifetime.start.p0(i64 48, ptr nonnull %3)
  %.fca.1.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 1
  %.fca.2.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 2
  %.fca.3.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 3
  %.fca.4.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 4
  %.fca.5.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 5
  %.fca.6.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 6
  %.fca.7.0.0.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 7, i64 0, i64 0
  %.fca.7.0.1.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 7, i64 0, i64 1
  %.fca.7.0.2.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 7, i64 0, i64 2
  %8 = call dereferenceable_or_null(8388608) ptr @malloc(i64 8388608)
  store ptr %8, ptr %3, align 8, !tbaa !8
  store i64 8, ptr %.fca.1.gep.i, align 8, !tbaa !8
  store i32 20180515, ptr %.fca.2.gep.i, align 8, !tbaa !8
  store i8 1, ptr %.fca.3.gep.i, align 4, !tbaa !8
  store i8 28, ptr %.fca.4.gep.i, align 1, !tbaa !8
  store i8 2, ptr %.fca.5.gep.i, align 2, !tbaa !8
  store i8 0, ptr %.fca.6.gep.i, align 1, !tbaa !8
  store i64 1, ptr %.fca.7.0.0.gep.i, align 8, !tbaa !8
  store i64 1048576, ptr %.fca.7.0.1.gep.i, align 8, !tbaa !8
  store i64 8, ptr %.fca.7.0.2.gep.i, align 8, !tbaa !8
  %omp_global_thread_num.i = call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %4, ptr %structArg.i, align 8
  %gep_5.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 1
  store ptr %3, ptr %gep_5.i, align 8
  %gep_6.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 2
  store ptr %2, ptr %gep_6.i, align 8
  %gep_7.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 3
  store ptr %1, ptr %gep_7.i, align 8
  %gep_8.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 4
  store ptr %6, ptr %gep_8.i, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QFPomp_subroutine..omp_par, ptr nonnull %structArg.i)
  %.fca.0.load.i = load ptr, ptr %3, align 8, !tbaa !8
  %.fca.7.0.0.load.i = load i64, ptr %.fca.7.0.0.gep.i, align 8, !tbaa !8
  %9 = sub i64 1, %.fca.7.0.0.load.i
  %10 = getelementptr double, ptr %.fca.0.load.i, i64 %9
  %11 = load double, ptr %10, align 8, !tbaa !4
  %12 = load i32, ptr %4, align 4, !tbaa !4
  %13 = sext i32 %12 to i64
  %14 = sub i64 %13, %.fca.7.0.0.load.i
  %15 = getelementptr double, ptr %.fca.0.load.i, i64 %14
  %16 = load double, ptr %15, align 8, !tbaa !4
  %17 = fadd contract double %11, %16
  call void @free(ptr %.fca.0.load.i)
  call void @llvm.lifetime.end.p0(i64 40, ptr nonnull %structArg.i)
  call void @llvm.lifetime.end.p0(i64 48, ptr nonnull %1)
  call void @llvm.lifetime.end.p0(i64 48, ptr nonnull %2)
  call void @llvm.lifetime.end.p0(i64 48, ptr nonnull %3)
  %18 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.e8a0ac9186c064ac8543d822e9060d96, i32 10)
  %19 = call i1 @_FortranAioOutputAscii(ptr %18, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %20 = load i32, ptr %4, align 4, !tbaa !4
  %21 = call i1 @_FortranAioOutputInteger32(ptr %18, i32 %20)
  %22 = call i1 @_FortranAioOutputAscii(ptr %18, ptr nonnull @_QQcl.2920697320, i64 5)
  %23 = call i1 @_FortranAioOutputReal64(ptr %18, double %17)
  %24 = call i32 @_FortranAioEndIoStatement(ptr %18)
  ret void
}
*** IR Dump After LoopSimplifyPass on _QQmain ***
define void @_QQmain() local_unnamed_addr {
  %structArg.i = alloca { ptr, ptr, ptr, ptr, ptr }, align 8
  %1 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %2 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %3 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %4 = alloca i32, align 4
  %5 = alloca double, align 8
  %6 = alloca { ptr, ptr }, align 8
  store ptr %4, ptr %6, align 8, !tbaa !4
  %7 = getelementptr inbounds { ptr, ptr }, ptr %6, i64 0, i32 1
  store ptr %5, ptr %7, align 8, !tbaa !4
  store i32 1048576, ptr %4, align 4, !tbaa !4
  call void @llvm.lifetime.start.p0(i64 40, ptr nonnull %structArg.i)
  call void @llvm.lifetime.start.p0(i64 48, ptr nonnull %1)
  call void @llvm.lifetime.start.p0(i64 48, ptr nonnull %2)
  call void @llvm.lifetime.start.p0(i64 48, ptr nonnull %3)
  %.fca.1.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 1
  %.fca.2.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 2
  %.fca.3.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 3
  %.fca.4.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 4
  %.fca.5.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 5
  %.fca.6.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 6
  %.fca.7.0.0.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 7, i64 0, i64 0
  %.fca.7.0.1.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 7, i64 0, i64 1
  %.fca.7.0.2.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 7, i64 0, i64 2
  %8 = call dereferenceable_or_null(8388608) ptr @malloc(i64 8388608)
  store ptr %8, ptr %3, align 8, !tbaa !8
  store i64 8, ptr %.fca.1.gep.i, align 8, !tbaa !8
  store i32 20180515, ptr %.fca.2.gep.i, align 8, !tbaa !8
  store i8 1, ptr %.fca.3.gep.i, align 4, !tbaa !8
  store i8 28, ptr %.fca.4.gep.i, align 1, !tbaa !8
  store i8 2, ptr %.fca.5.gep.i, align 2, !tbaa !8
  store i8 0, ptr %.fca.6.gep.i, align 1, !tbaa !8
  store i64 1, ptr %.fca.7.0.0.gep.i, align 8, !tbaa !8
  store i64 1048576, ptr %.fca.7.0.1.gep.i, align 8, !tbaa !8
  store i64 8, ptr %.fca.7.0.2.gep.i, align 8, !tbaa !8
  %omp_global_thread_num.i = call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %4, ptr %structArg.i, align 8
  %gep_5.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 1
  store ptr %3, ptr %gep_5.i, align 8
  %gep_6.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 2
  store ptr %2, ptr %gep_6.i, align 8
  %gep_7.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 3
  store ptr %1, ptr %gep_7.i, align 8
  %gep_8.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 4
  store ptr %6, ptr %gep_8.i, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QFPomp_subroutine..omp_par, ptr nonnull %structArg.i)
  %.fca.0.load.i = load ptr, ptr %3, align 8, !tbaa !8
  %.fca.7.0.0.load.i = load i64, ptr %.fca.7.0.0.gep.i, align 8, !tbaa !8
  %9 = sub i64 1, %.fca.7.0.0.load.i
  %10 = getelementptr double, ptr %.fca.0.load.i, i64 %9
  %11 = load double, ptr %10, align 8, !tbaa !4
  %12 = load i32, ptr %4, align 4, !tbaa !4
  %13 = sext i32 %12 to i64
  %14 = sub i64 %13, %.fca.7.0.0.load.i
  %15 = getelementptr double, ptr %.fca.0.load.i, i64 %14
  %16 = load double, ptr %15, align 8, !tbaa !4
  %17 = fadd contract double %11, %16
  call void @free(ptr %.fca.0.load.i)
  call void @llvm.lifetime.end.p0(i64 40, ptr nonnull %structArg.i)
  call void @llvm.lifetime.end.p0(i64 48, ptr nonnull %1)
  call void @llvm.lifetime.end.p0(i64 48, ptr nonnull %2)
  call void @llvm.lifetime.end.p0(i64 48, ptr nonnull %3)
  %18 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.e8a0ac9186c064ac8543d822e9060d96, i32 10)
  %19 = call i1 @_FortranAioOutputAscii(ptr %18, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %20 = load i32, ptr %4, align 4, !tbaa !4
  %21 = call i1 @_FortranAioOutputInteger32(ptr %18, i32 %20)
  %22 = call i1 @_FortranAioOutputAscii(ptr %18, ptr nonnull @_QQcl.2920697320, i64 5)
  %23 = call i1 @_FortranAioOutputReal64(ptr %18, double %17)
  %24 = call i32 @_FortranAioEndIoStatement(ptr %18)
  ret void
}
*** IR Dump After LCSSAPass on _QQmain ***
define void @_QQmain() local_unnamed_addr {
  %structArg.i = alloca { ptr, ptr, ptr, ptr, ptr }, align 8
  %1 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %2 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %3 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %4 = alloca i32, align 4
  %5 = alloca double, align 8
  %6 = alloca { ptr, ptr }, align 8
  store ptr %4, ptr %6, align 8, !tbaa !4
  %7 = getelementptr inbounds { ptr, ptr }, ptr %6, i64 0, i32 1
  store ptr %5, ptr %7, align 8, !tbaa !4
  store i32 1048576, ptr %4, align 4, !tbaa !4
  call void @llvm.lifetime.start.p0(i64 40, ptr nonnull %structArg.i)
  call void @llvm.lifetime.start.p0(i64 48, ptr nonnull %1)
  call void @llvm.lifetime.start.p0(i64 48, ptr nonnull %2)
  call void @llvm.lifetime.start.p0(i64 48, ptr nonnull %3)
  %.fca.1.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 1
  %.fca.2.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 2
  %.fca.3.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 3
  %.fca.4.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 4
  %.fca.5.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 5
  %.fca.6.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 6
  %.fca.7.0.0.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 7, i64 0, i64 0
  %.fca.7.0.1.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 7, i64 0, i64 1
  %.fca.7.0.2.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 7, i64 0, i64 2
  %8 = call dereferenceable_or_null(8388608) ptr @malloc(i64 8388608)
  store ptr %8, ptr %3, align 8, !tbaa !8
  store i64 8, ptr %.fca.1.gep.i, align 8, !tbaa !8
  store i32 20180515, ptr %.fca.2.gep.i, align 8, !tbaa !8
  store i8 1, ptr %.fca.3.gep.i, align 4, !tbaa !8
  store i8 28, ptr %.fca.4.gep.i, align 1, !tbaa !8
  store i8 2, ptr %.fca.5.gep.i, align 2, !tbaa !8
  store i8 0, ptr %.fca.6.gep.i, align 1, !tbaa !8
  store i64 1, ptr %.fca.7.0.0.gep.i, align 8, !tbaa !8
  store i64 1048576, ptr %.fca.7.0.1.gep.i, align 8, !tbaa !8
  store i64 8, ptr %.fca.7.0.2.gep.i, align 8, !tbaa !8
  %omp_global_thread_num.i = call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %4, ptr %structArg.i, align 8
  %gep_5.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 1
  store ptr %3, ptr %gep_5.i, align 8
  %gep_6.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 2
  store ptr %2, ptr %gep_6.i, align 8
  %gep_7.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 3
  store ptr %1, ptr %gep_7.i, align 8
  %gep_8.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 4
  store ptr %6, ptr %gep_8.i, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QFPomp_subroutine..omp_par, ptr nonnull %structArg.i)
  %.fca.0.load.i = load ptr, ptr %3, align 8, !tbaa !8
  %.fca.7.0.0.load.i = load i64, ptr %.fca.7.0.0.gep.i, align 8, !tbaa !8
  %9 = sub i64 1, %.fca.7.0.0.load.i
  %10 = getelementptr double, ptr %.fca.0.load.i, i64 %9
  %11 = load double, ptr %10, align 8, !tbaa !4
  %12 = load i32, ptr %4, align 4, !tbaa !4
  %13 = sext i32 %12 to i64
  %14 = sub i64 %13, %.fca.7.0.0.load.i
  %15 = getelementptr double, ptr %.fca.0.load.i, i64 %14
  %16 = load double, ptr %15, align 8, !tbaa !4
  %17 = fadd contract double %11, %16
  call void @free(ptr %.fca.0.load.i)
  call void @llvm.lifetime.end.p0(i64 40, ptr nonnull %structArg.i)
  call void @llvm.lifetime.end.p0(i64 48, ptr nonnull %1)
  call void @llvm.lifetime.end.p0(i64 48, ptr nonnull %2)
  call void @llvm.lifetime.end.p0(i64 48, ptr nonnull %3)
  %18 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.e8a0ac9186c064ac8543d822e9060d96, i32 10)
  %19 = call i1 @_FortranAioOutputAscii(ptr %18, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %20 = load i32, ptr %4, align 4, !tbaa !4
  %21 = call i1 @_FortranAioOutputInteger32(ptr %18, i32 %20)
  %22 = call i1 @_FortranAioOutputAscii(ptr %18, ptr nonnull @_QQcl.2920697320, i64 5)
  %23 = call i1 @_FortranAioOutputReal64(ptr %18, double %17)
  %24 = call i32 @_FortranAioEndIoStatement(ptr %18)
  ret void
}
*** IR Dump After AlignmentFromAssumptionsPass on _QQmain ***
define void @_QQmain() local_unnamed_addr {
  %structArg.i = alloca { ptr, ptr, ptr, ptr, ptr }, align 8
  %1 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %2 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %3 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %4 = alloca i32, align 4
  %5 = alloca double, align 8
  %6 = alloca { ptr, ptr }, align 8
  store ptr %4, ptr %6, align 8, !tbaa !4
  %7 = getelementptr inbounds { ptr, ptr }, ptr %6, i64 0, i32 1
  store ptr %5, ptr %7, align 8, !tbaa !4
  store i32 1048576, ptr %4, align 4, !tbaa !4
  call void @llvm.lifetime.start.p0(i64 40, ptr nonnull %structArg.i)
  call void @llvm.lifetime.start.p0(i64 48, ptr nonnull %1)
  call void @llvm.lifetime.start.p0(i64 48, ptr nonnull %2)
  call void @llvm.lifetime.start.p0(i64 48, ptr nonnull %3)
  %.fca.1.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 1
  %.fca.2.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 2
  %.fca.3.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 3
  %.fca.4.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 4
  %.fca.5.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 5
  %.fca.6.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 6
  %.fca.7.0.0.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 7, i64 0, i64 0
  %.fca.7.0.1.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 7, i64 0, i64 1
  %.fca.7.0.2.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 7, i64 0, i64 2
  %8 = call dereferenceable_or_null(8388608) ptr @malloc(i64 8388608)
  store ptr %8, ptr %3, align 8, !tbaa !8
  store i64 8, ptr %.fca.1.gep.i, align 8, !tbaa !8
  store i32 20180515, ptr %.fca.2.gep.i, align 8, !tbaa !8
  store i8 1, ptr %.fca.3.gep.i, align 4, !tbaa !8
  store i8 28, ptr %.fca.4.gep.i, align 1, !tbaa !8
  store i8 2, ptr %.fca.5.gep.i, align 2, !tbaa !8
  store i8 0, ptr %.fca.6.gep.i, align 1, !tbaa !8
  store i64 1, ptr %.fca.7.0.0.gep.i, align 8, !tbaa !8
  store i64 1048576, ptr %.fca.7.0.1.gep.i, align 8, !tbaa !8
  store i64 8, ptr %.fca.7.0.2.gep.i, align 8, !tbaa !8
  %omp_global_thread_num.i = call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %4, ptr %structArg.i, align 8
  %gep_5.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 1
  store ptr %3, ptr %gep_5.i, align 8
  %gep_6.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 2
  store ptr %2, ptr %gep_6.i, align 8
  %gep_7.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 3
  store ptr %1, ptr %gep_7.i, align 8
  %gep_8.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 4
  store ptr %6, ptr %gep_8.i, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QFPomp_subroutine..omp_par, ptr nonnull %structArg.i)
  %.fca.0.load.i = load ptr, ptr %3, align 8, !tbaa !8
  %.fca.7.0.0.load.i = load i64, ptr %.fca.7.0.0.gep.i, align 8, !tbaa !8
  %9 = sub i64 1, %.fca.7.0.0.load.i
  %10 = getelementptr double, ptr %.fca.0.load.i, i64 %9
  %11 = load double, ptr %10, align 8, !tbaa !4
  %12 = load i32, ptr %4, align 4, !tbaa !4
  %13 = sext i32 %12 to i64
  %14 = sub i64 %13, %.fca.7.0.0.load.i
  %15 = getelementptr double, ptr %.fca.0.load.i, i64 %14
  %16 = load double, ptr %15, align 8, !tbaa !4
  %17 = fadd contract double %11, %16
  call void @free(ptr %.fca.0.load.i)
  call void @llvm.lifetime.end.p0(i64 40, ptr nonnull %structArg.i)
  call void @llvm.lifetime.end.p0(i64 48, ptr nonnull %1)
  call void @llvm.lifetime.end.p0(i64 48, ptr nonnull %2)
  call void @llvm.lifetime.end.p0(i64 48, ptr nonnull %3)
  %18 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.e8a0ac9186c064ac8543d822e9060d96, i32 10)
  %19 = call i1 @_FortranAioOutputAscii(ptr %18, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %20 = load i32, ptr %4, align 4, !tbaa !4
  %21 = call i1 @_FortranAioOutputInteger32(ptr %18, i32 %20)
  %22 = call i1 @_FortranAioOutputAscii(ptr %18, ptr nonnull @_QQcl.2920697320, i64 5)
  %23 = call i1 @_FortranAioOutputReal64(ptr %18, double %17)
  %24 = call i32 @_FortranAioEndIoStatement(ptr %18)
  ret void
}
*** IR Dump After LoopSinkPass on _QQmain ***
define void @_QQmain() local_unnamed_addr {
  %structArg.i = alloca { ptr, ptr, ptr, ptr, ptr }, align 8
  %1 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %2 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %3 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %4 = alloca i32, align 4
  %5 = alloca double, align 8
  %6 = alloca { ptr, ptr }, align 8
  store ptr %4, ptr %6, align 8, !tbaa !4
  %7 = getelementptr inbounds { ptr, ptr }, ptr %6, i64 0, i32 1
  store ptr %5, ptr %7, align 8, !tbaa !4
  store i32 1048576, ptr %4, align 4, !tbaa !4
  call void @llvm.lifetime.start.p0(i64 40, ptr nonnull %structArg.i)
  call void @llvm.lifetime.start.p0(i64 48, ptr nonnull %1)
  call void @llvm.lifetime.start.p0(i64 48, ptr nonnull %2)
  call void @llvm.lifetime.start.p0(i64 48, ptr nonnull %3)
  %.fca.1.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 1
  %.fca.2.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 2
  %.fca.3.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 3
  %.fca.4.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 4
  %.fca.5.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 5
  %.fca.6.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 6
  %.fca.7.0.0.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 7, i64 0, i64 0
  %.fca.7.0.1.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 7, i64 0, i64 1
  %.fca.7.0.2.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 7, i64 0, i64 2
  %8 = call dereferenceable_or_null(8388608) ptr @malloc(i64 8388608)
  store ptr %8, ptr %3, align 8, !tbaa !8
  store i64 8, ptr %.fca.1.gep.i, align 8, !tbaa !8
  store i32 20180515, ptr %.fca.2.gep.i, align 8, !tbaa !8
  store i8 1, ptr %.fca.3.gep.i, align 4, !tbaa !8
  store i8 28, ptr %.fca.4.gep.i, align 1, !tbaa !8
  store i8 2, ptr %.fca.5.gep.i, align 2, !tbaa !8
  store i8 0, ptr %.fca.6.gep.i, align 1, !tbaa !8
  store i64 1, ptr %.fca.7.0.0.gep.i, align 8, !tbaa !8
  store i64 1048576, ptr %.fca.7.0.1.gep.i, align 8, !tbaa !8
  store i64 8, ptr %.fca.7.0.2.gep.i, align 8, !tbaa !8
  %omp_global_thread_num.i = call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %4, ptr %structArg.i, align 8
  %gep_5.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 1
  store ptr %3, ptr %gep_5.i, align 8
  %gep_6.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 2
  store ptr %2, ptr %gep_6.i, align 8
  %gep_7.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 3
  store ptr %1, ptr %gep_7.i, align 8
  %gep_8.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 4
  store ptr %6, ptr %gep_8.i, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QFPomp_subroutine..omp_par, ptr nonnull %structArg.i)
  %.fca.0.load.i = load ptr, ptr %3, align 8, !tbaa !8
  %.fca.7.0.0.load.i = load i64, ptr %.fca.7.0.0.gep.i, align 8, !tbaa !8
  %9 = sub i64 1, %.fca.7.0.0.load.i
  %10 = getelementptr double, ptr %.fca.0.load.i, i64 %9
  %11 = load double, ptr %10, align 8, !tbaa !4
  %12 = load i32, ptr %4, align 4, !tbaa !4
  %13 = sext i32 %12 to i64
  %14 = sub i64 %13, %.fca.7.0.0.load.i
  %15 = getelementptr double, ptr %.fca.0.load.i, i64 %14
  %16 = load double, ptr %15, align 8, !tbaa !4
  %17 = fadd contract double %11, %16
  call void @free(ptr %.fca.0.load.i)
  call void @llvm.lifetime.end.p0(i64 40, ptr nonnull %structArg.i)
  call void @llvm.lifetime.end.p0(i64 48, ptr nonnull %1)
  call void @llvm.lifetime.end.p0(i64 48, ptr nonnull %2)
  call void @llvm.lifetime.end.p0(i64 48, ptr nonnull %3)
  %18 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.e8a0ac9186c064ac8543d822e9060d96, i32 10)
  %19 = call i1 @_FortranAioOutputAscii(ptr %18, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %20 = load i32, ptr %4, align 4, !tbaa !4
  %21 = call i1 @_FortranAioOutputInteger32(ptr %18, i32 %20)
  %22 = call i1 @_FortranAioOutputAscii(ptr %18, ptr nonnull @_QQcl.2920697320, i64 5)
  %23 = call i1 @_FortranAioOutputReal64(ptr %18, double %17)
  %24 = call i32 @_FortranAioEndIoStatement(ptr %18)
  ret void
}
*** IR Dump After InstSimplifyPass on _QQmain ***
define void @_QQmain() local_unnamed_addr {
  %structArg.i = alloca { ptr, ptr, ptr, ptr, ptr }, align 8
  %1 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %2 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %3 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %4 = alloca i32, align 4
  %5 = alloca double, align 8
  %6 = alloca { ptr, ptr }, align 8
  store ptr %4, ptr %6, align 8, !tbaa !4
  %7 = getelementptr inbounds { ptr, ptr }, ptr %6, i64 0, i32 1
  store ptr %5, ptr %7, align 8, !tbaa !4
  store i32 1048576, ptr %4, align 4, !tbaa !4
  call void @llvm.lifetime.start.p0(i64 40, ptr nonnull %structArg.i)
  call void @llvm.lifetime.start.p0(i64 48, ptr nonnull %1)
  call void @llvm.lifetime.start.p0(i64 48, ptr nonnull %2)
  call void @llvm.lifetime.start.p0(i64 48, ptr nonnull %3)
  %.fca.1.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 1
  %.fca.2.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 2
  %.fca.3.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 3
  %.fca.4.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 4
  %.fca.5.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 5
  %.fca.6.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 6
  %.fca.7.0.0.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 7, i64 0, i64 0
  %.fca.7.0.1.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 7, i64 0, i64 1
  %.fca.7.0.2.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 7, i64 0, i64 2
  %8 = call dereferenceable_or_null(8388608) ptr @malloc(i64 8388608)
  store ptr %8, ptr %3, align 8, !tbaa !8
  store i64 8, ptr %.fca.1.gep.i, align 8, !tbaa !8
  store i32 20180515, ptr %.fca.2.gep.i, align 8, !tbaa !8
  store i8 1, ptr %.fca.3.gep.i, align 4, !tbaa !8
  store i8 28, ptr %.fca.4.gep.i, align 1, !tbaa !8
  store i8 2, ptr %.fca.5.gep.i, align 2, !tbaa !8
  store i8 0, ptr %.fca.6.gep.i, align 1, !tbaa !8
  store i64 1, ptr %.fca.7.0.0.gep.i, align 8, !tbaa !8
  store i64 1048576, ptr %.fca.7.0.1.gep.i, align 8, !tbaa !8
  store i64 8, ptr %.fca.7.0.2.gep.i, align 8, !tbaa !8
  %omp_global_thread_num.i = call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %4, ptr %structArg.i, align 8
  %gep_5.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 1
  store ptr %3, ptr %gep_5.i, align 8
  %gep_6.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 2
  store ptr %2, ptr %gep_6.i, align 8
  %gep_7.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 3
  store ptr %1, ptr %gep_7.i, align 8
  %gep_8.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 4
  store ptr %6, ptr %gep_8.i, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QFPomp_subroutine..omp_par, ptr nonnull %structArg.i)
  %.fca.0.load.i = load ptr, ptr %3, align 8, !tbaa !8
  %.fca.7.0.0.load.i = load i64, ptr %.fca.7.0.0.gep.i, align 8, !tbaa !8
  %9 = sub i64 1, %.fca.7.0.0.load.i
  %10 = getelementptr double, ptr %.fca.0.load.i, i64 %9
  %11 = load double, ptr %10, align 8, !tbaa !4
  %12 = load i32, ptr %4, align 4, !tbaa !4
  %13 = sext i32 %12 to i64
  %14 = sub i64 %13, %.fca.7.0.0.load.i
  %15 = getelementptr double, ptr %.fca.0.load.i, i64 %14
  %16 = load double, ptr %15, align 8, !tbaa !4
  %17 = fadd contract double %11, %16
  call void @free(ptr %.fca.0.load.i)
  call void @llvm.lifetime.end.p0(i64 40, ptr nonnull %structArg.i)
  call void @llvm.lifetime.end.p0(i64 48, ptr nonnull %1)
  call void @llvm.lifetime.end.p0(i64 48, ptr nonnull %2)
  call void @llvm.lifetime.end.p0(i64 48, ptr nonnull %3)
  %18 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.e8a0ac9186c064ac8543d822e9060d96, i32 10)
  %19 = call i1 @_FortranAioOutputAscii(ptr %18, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %20 = load i32, ptr %4, align 4, !tbaa !4
  %21 = call i1 @_FortranAioOutputInteger32(ptr %18, i32 %20)
  %22 = call i1 @_FortranAioOutputAscii(ptr %18, ptr nonnull @_QQcl.2920697320, i64 5)
  %23 = call i1 @_FortranAioOutputReal64(ptr %18, double %17)
  %24 = call i32 @_FortranAioEndIoStatement(ptr %18)
  ret void
}
*** IR Dump After DivRemPairsPass on _QQmain ***
define void @_QQmain() local_unnamed_addr {
  %structArg.i = alloca { ptr, ptr, ptr, ptr, ptr }, align 8
  %1 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %2 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %3 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %4 = alloca i32, align 4
  %5 = alloca double, align 8
  %6 = alloca { ptr, ptr }, align 8
  store ptr %4, ptr %6, align 8, !tbaa !4
  %7 = getelementptr inbounds { ptr, ptr }, ptr %6, i64 0, i32 1
  store ptr %5, ptr %7, align 8, !tbaa !4
  store i32 1048576, ptr %4, align 4, !tbaa !4
  call void @llvm.lifetime.start.p0(i64 40, ptr nonnull %structArg.i)
  call void @llvm.lifetime.start.p0(i64 48, ptr nonnull %1)
  call void @llvm.lifetime.start.p0(i64 48, ptr nonnull %2)
  call void @llvm.lifetime.start.p0(i64 48, ptr nonnull %3)
  %.fca.1.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 1
  %.fca.2.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 2
  %.fca.3.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 3
  %.fca.4.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 4
  %.fca.5.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 5
  %.fca.6.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 6
  %.fca.7.0.0.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 7, i64 0, i64 0
  %.fca.7.0.1.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 7, i64 0, i64 1
  %.fca.7.0.2.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 7, i64 0, i64 2
  %8 = call dereferenceable_or_null(8388608) ptr @malloc(i64 8388608)
  store ptr %8, ptr %3, align 8, !tbaa !8
  store i64 8, ptr %.fca.1.gep.i, align 8, !tbaa !8
  store i32 20180515, ptr %.fca.2.gep.i, align 8, !tbaa !8
  store i8 1, ptr %.fca.3.gep.i, align 4, !tbaa !8
  store i8 28, ptr %.fca.4.gep.i, align 1, !tbaa !8
  store i8 2, ptr %.fca.5.gep.i, align 2, !tbaa !8
  store i8 0, ptr %.fca.6.gep.i, align 1, !tbaa !8
  store i64 1, ptr %.fca.7.0.0.gep.i, align 8, !tbaa !8
  store i64 1048576, ptr %.fca.7.0.1.gep.i, align 8, !tbaa !8
  store i64 8, ptr %.fca.7.0.2.gep.i, align 8, !tbaa !8
  %omp_global_thread_num.i = call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %4, ptr %structArg.i, align 8
  %gep_5.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 1
  store ptr %3, ptr %gep_5.i, align 8
  %gep_6.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 2
  store ptr %2, ptr %gep_6.i, align 8
  %gep_7.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 3
  store ptr %1, ptr %gep_7.i, align 8
  %gep_8.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 4
  store ptr %6, ptr %gep_8.i, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QFPomp_subroutine..omp_par, ptr nonnull %structArg.i)
  %.fca.0.load.i = load ptr, ptr %3, align 8, !tbaa !8
  %.fca.7.0.0.load.i = load i64, ptr %.fca.7.0.0.gep.i, align 8, !tbaa !8
  %9 = sub i64 1, %.fca.7.0.0.load.i
  %10 = getelementptr double, ptr %.fca.0.load.i, i64 %9
  %11 = load double, ptr %10, align 8, !tbaa !4
  %12 = load i32, ptr %4, align 4, !tbaa !4
  %13 = sext i32 %12 to i64
  %14 = sub i64 %13, %.fca.7.0.0.load.i
  %15 = getelementptr double, ptr %.fca.0.load.i, i64 %14
  %16 = load double, ptr %15, align 8, !tbaa !4
  %17 = fadd contract double %11, %16
  call void @free(ptr %.fca.0.load.i)
  call void @llvm.lifetime.end.p0(i64 40, ptr nonnull %structArg.i)
  call void @llvm.lifetime.end.p0(i64 48, ptr nonnull %1)
  call void @llvm.lifetime.end.p0(i64 48, ptr nonnull %2)
  call void @llvm.lifetime.end.p0(i64 48, ptr nonnull %3)
  %18 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.e8a0ac9186c064ac8543d822e9060d96, i32 10)
  %19 = call i1 @_FortranAioOutputAscii(ptr %18, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %20 = load i32, ptr %4, align 4, !tbaa !4
  %21 = call i1 @_FortranAioOutputInteger32(ptr %18, i32 %20)
  %22 = call i1 @_FortranAioOutputAscii(ptr %18, ptr nonnull @_QQcl.2920697320, i64 5)
  %23 = call i1 @_FortranAioOutputReal64(ptr %18, double %17)
  %24 = call i32 @_FortranAioEndIoStatement(ptr %18)
  ret void
}
*** IR Dump After TailCallElimPass on _QQmain ***
define void @_QQmain() local_unnamed_addr {
  %structArg.i = alloca { ptr, ptr, ptr, ptr, ptr }, align 8
  %1 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %2 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %3 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %4 = alloca i32, align 4
  %5 = alloca double, align 8
  %6 = alloca { ptr, ptr }, align 8
  store ptr %4, ptr %6, align 8, !tbaa !4
  %7 = getelementptr inbounds { ptr, ptr }, ptr %6, i64 0, i32 1
  store ptr %5, ptr %7, align 8, !tbaa !4
  store i32 1048576, ptr %4, align 4, !tbaa !4
  call void @llvm.lifetime.start.p0(i64 40, ptr nonnull %structArg.i)
  call void @llvm.lifetime.start.p0(i64 48, ptr nonnull %1)
  call void @llvm.lifetime.start.p0(i64 48, ptr nonnull %2)
  call void @llvm.lifetime.start.p0(i64 48, ptr nonnull %3)
  %.fca.1.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 1
  %.fca.2.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 2
  %.fca.3.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 3
  %.fca.4.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 4
  %.fca.5.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 5
  %.fca.6.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 6
  %.fca.7.0.0.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 7, i64 0, i64 0
  %.fca.7.0.1.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 7, i64 0, i64 1
  %.fca.7.0.2.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 7, i64 0, i64 2
  %8 = call dereferenceable_or_null(8388608) ptr @malloc(i64 8388608)
  store ptr %8, ptr %3, align 8, !tbaa !8
  store i64 8, ptr %.fca.1.gep.i, align 8, !tbaa !8
  store i32 20180515, ptr %.fca.2.gep.i, align 8, !tbaa !8
  store i8 1, ptr %.fca.3.gep.i, align 4, !tbaa !8
  store i8 28, ptr %.fca.4.gep.i, align 1, !tbaa !8
  store i8 2, ptr %.fca.5.gep.i, align 2, !tbaa !8
  store i8 0, ptr %.fca.6.gep.i, align 1, !tbaa !8
  store i64 1, ptr %.fca.7.0.0.gep.i, align 8, !tbaa !8
  store i64 1048576, ptr %.fca.7.0.1.gep.i, align 8, !tbaa !8
  store i64 8, ptr %.fca.7.0.2.gep.i, align 8, !tbaa !8
  %omp_global_thread_num.i = call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %4, ptr %structArg.i, align 8
  %gep_5.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 1
  store ptr %3, ptr %gep_5.i, align 8
  %gep_6.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 2
  store ptr %2, ptr %gep_6.i, align 8
  %gep_7.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 3
  store ptr %1, ptr %gep_7.i, align 8
  %gep_8.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 4
  store ptr %6, ptr %gep_8.i, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QFPomp_subroutine..omp_par, ptr nonnull %structArg.i)
  %.fca.0.load.i = load ptr, ptr %3, align 8, !tbaa !8
  %.fca.7.0.0.load.i = load i64, ptr %.fca.7.0.0.gep.i, align 8, !tbaa !8
  %9 = sub i64 1, %.fca.7.0.0.load.i
  %10 = getelementptr double, ptr %.fca.0.load.i, i64 %9
  %11 = load double, ptr %10, align 8, !tbaa !4
  %12 = load i32, ptr %4, align 4, !tbaa !4
  %13 = sext i32 %12 to i64
  %14 = sub i64 %13, %.fca.7.0.0.load.i
  %15 = getelementptr double, ptr %.fca.0.load.i, i64 %14
  %16 = load double, ptr %15, align 8, !tbaa !4
  %17 = fadd contract double %11, %16
  call void @free(ptr %.fca.0.load.i)
  call void @llvm.lifetime.end.p0(i64 40, ptr nonnull %structArg.i)
  call void @llvm.lifetime.end.p0(i64 48, ptr nonnull %1)
  call void @llvm.lifetime.end.p0(i64 48, ptr nonnull %2)
  call void @llvm.lifetime.end.p0(i64 48, ptr nonnull %3)
  %18 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.e8a0ac9186c064ac8543d822e9060d96, i32 10)
  %19 = call i1 @_FortranAioOutputAscii(ptr %18, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %20 = load i32, ptr %4, align 4, !tbaa !4
  %21 = call i1 @_FortranAioOutputInteger32(ptr %18, i32 %20)
  %22 = call i1 @_FortranAioOutputAscii(ptr %18, ptr nonnull @_QQcl.2920697320, i64 5)
  %23 = call i1 @_FortranAioOutputReal64(ptr %18, double %17)
  %24 = call i32 @_FortranAioEndIoStatement(ptr %18)
  ret void
}
*** IR Dump After SimplifyCFGPass on _QQmain ***
define void @_QQmain() local_unnamed_addr {
  %structArg.i = alloca { ptr, ptr, ptr, ptr, ptr }, align 8
  %1 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %2 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %3 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %4 = alloca i32, align 4
  %5 = alloca double, align 8
  %6 = alloca { ptr, ptr }, align 8
  store ptr %4, ptr %6, align 8, !tbaa !4
  %7 = getelementptr inbounds { ptr, ptr }, ptr %6, i64 0, i32 1
  store ptr %5, ptr %7, align 8, !tbaa !4
  store i32 1048576, ptr %4, align 4, !tbaa !4
  call void @llvm.lifetime.start.p0(i64 40, ptr nonnull %structArg.i)
  call void @llvm.lifetime.start.p0(i64 48, ptr nonnull %1)
  call void @llvm.lifetime.start.p0(i64 48, ptr nonnull %2)
  call void @llvm.lifetime.start.p0(i64 48, ptr nonnull %3)
  %.fca.1.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 1
  %.fca.2.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 2
  %.fca.3.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 3
  %.fca.4.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 4
  %.fca.5.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 5
  %.fca.6.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 6
  %.fca.7.0.0.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 7, i64 0, i64 0
  %.fca.7.0.1.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 7, i64 0, i64 1
  %.fca.7.0.2.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 7, i64 0, i64 2
  %8 = call dereferenceable_or_null(8388608) ptr @malloc(i64 8388608)
  store ptr %8, ptr %3, align 8, !tbaa !8
  store i64 8, ptr %.fca.1.gep.i, align 8, !tbaa !8
  store i32 20180515, ptr %.fca.2.gep.i, align 8, !tbaa !8
  store i8 1, ptr %.fca.3.gep.i, align 4, !tbaa !8
  store i8 28, ptr %.fca.4.gep.i, align 1, !tbaa !8
  store i8 2, ptr %.fca.5.gep.i, align 2, !tbaa !8
  store i8 0, ptr %.fca.6.gep.i, align 1, !tbaa !8
  store i64 1, ptr %.fca.7.0.0.gep.i, align 8, !tbaa !8
  store i64 1048576, ptr %.fca.7.0.1.gep.i, align 8, !tbaa !8
  store i64 8, ptr %.fca.7.0.2.gep.i, align 8, !tbaa !8
  %omp_global_thread_num.i = call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %4, ptr %structArg.i, align 8
  %gep_5.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 1
  store ptr %3, ptr %gep_5.i, align 8
  %gep_6.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 2
  store ptr %2, ptr %gep_6.i, align 8
  %gep_7.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 3
  store ptr %1, ptr %gep_7.i, align 8
  %gep_8.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 4
  store ptr %6, ptr %gep_8.i, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QFPomp_subroutine..omp_par, ptr nonnull %structArg.i)
  %.fca.0.load.i = load ptr, ptr %3, align 8, !tbaa !8
  %.fca.7.0.0.load.i = load i64, ptr %.fca.7.0.0.gep.i, align 8, !tbaa !8
  %9 = sub i64 1, %.fca.7.0.0.load.i
  %10 = getelementptr double, ptr %.fca.0.load.i, i64 %9
  %11 = load double, ptr %10, align 8, !tbaa !4
  %12 = load i32, ptr %4, align 4, !tbaa !4
  %13 = sext i32 %12 to i64
  %14 = sub i64 %13, %.fca.7.0.0.load.i
  %15 = getelementptr double, ptr %.fca.0.load.i, i64 %14
  %16 = load double, ptr %15, align 8, !tbaa !4
  %17 = fadd contract double %11, %16
  call void @free(ptr %.fca.0.load.i)
  call void @llvm.lifetime.end.p0(i64 40, ptr nonnull %structArg.i)
  call void @llvm.lifetime.end.p0(i64 48, ptr nonnull %1)
  call void @llvm.lifetime.end.p0(i64 48, ptr nonnull %2)
  call void @llvm.lifetime.end.p0(i64 48, ptr nonnull %3)
  %18 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.e8a0ac9186c064ac8543d822e9060d96, i32 10)
  %19 = call i1 @_FortranAioOutputAscii(ptr %18, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %20 = load i32, ptr %4, align 4, !tbaa !4
  %21 = call i1 @_FortranAioOutputInteger32(ptr %18, i32 %20)
  %22 = call i1 @_FortranAioOutputAscii(ptr %18, ptr nonnull @_QQcl.2920697320, i64 5)
  %23 = call i1 @_FortranAioOutputReal64(ptr %18, double %17)
  %24 = call i32 @_FortranAioEndIoStatement(ptr %18)
  ret void
}
*** IR Dump After Float2IntPass on _QFPomp_subroutine ***
; Function Attrs: nounwind
define void @_QFPomp_subroutine(ptr %0, ptr nocapture writeonly %1, ptr nest %2) local_unnamed_addr #2 {
entry:
  %structArg = alloca { ptr, ptr, ptr, ptr, ptr }, align 8
  %3 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %4 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %5 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %.fca.1.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 1
  %.fca.2.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 2
  %.fca.3.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 3
  %.fca.4.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 4
  %.fca.5.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 5
  %.fca.6.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 6
  %.fca.7.0.0.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 0
  %.fca.7.0.1.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 1
  %.fca.7.0.2.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 2
  %6 = load i32, ptr %0, align 4, !tbaa !4
  %7 = tail call i32 @llvm.smax.i32(i32 %6, i32 0)
  %8 = zext i32 %7 to i64
  %9 = shl nuw nsw i64 %8, 3
  %10 = tail call ptr @malloc(i64 %9)
  store ptr %10, ptr %5, align 8, !tbaa !8
  store i64 8, ptr %.fca.1.gep, align 8, !tbaa !8
  store i32 20180515, ptr %.fca.2.gep, align 8, !tbaa !8
  store i8 1, ptr %.fca.3.gep, align 4, !tbaa !8
  store i8 28, ptr %.fca.4.gep, align 1, !tbaa !8
  store i8 2, ptr %.fca.5.gep, align 2, !tbaa !8
  store i8 0, ptr %.fca.6.gep, align 1, !tbaa !8
  store i64 1, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  store i64 %8, ptr %.fca.7.0.1.gep, align 8, !tbaa !8
  store i64 8, ptr %.fca.7.0.2.gep, align 8, !tbaa !8
  %omp_global_thread_num = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %0, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %5, ptr %gep_5, align 8
  %gep_6 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 2
  store ptr %4, ptr %gep_6, align 8
  %gep_7 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 3
  store ptr %3, ptr %gep_7, align 8
  %gep_8 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 4
  store ptr %2, ptr %gep_8, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QFPomp_subroutine..omp_par, ptr nonnull %structArg)
  %.fca.0.load = load ptr, ptr %5, align 8, !tbaa !8
  %.fca.7.0.0.load = load i64, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  %11 = sub i64 1, %.fca.7.0.0.load
  %12 = getelementptr double, ptr %.fca.0.load, i64 %11
  %13 = load double, ptr %12, align 8, !tbaa !4
  %14 = load i32, ptr %0, align 4, !tbaa !4
  %15 = sext i32 %14 to i64
  %16 = sub i64 %15, %.fca.7.0.0.load
  %17 = getelementptr double, ptr %.fca.0.load, i64 %16
  %18 = load double, ptr %17, align 8, !tbaa !4
  %19 = fadd contract double %13, %18
  store double %19, ptr %1, align 8, !tbaa !4
  call void @free(ptr %.fca.0.load)
  ret void
}
*** IR Dump After LowerConstantIntrinsicsPass on _QFPomp_subroutine ***
; Function Attrs: nounwind
define void @_QFPomp_subroutine(ptr %0, ptr nocapture writeonly %1, ptr nest %2) local_unnamed_addr #2 {
entry:
  %structArg = alloca { ptr, ptr, ptr, ptr, ptr }, align 8
  %3 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %4 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %5 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %.fca.1.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 1
  %.fca.2.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 2
  %.fca.3.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 3
  %.fca.4.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 4
  %.fca.5.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 5
  %.fca.6.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 6
  %.fca.7.0.0.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 0
  %.fca.7.0.1.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 1
  %.fca.7.0.2.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 2
  %6 = load i32, ptr %0, align 4, !tbaa !4
  %7 = tail call i32 @llvm.smax.i32(i32 %6, i32 0)
  %8 = zext i32 %7 to i64
  %9 = shl nuw nsw i64 %8, 3
  %10 = tail call ptr @malloc(i64 %9)
  store ptr %10, ptr %5, align 8, !tbaa !8
  store i64 8, ptr %.fca.1.gep, align 8, !tbaa !8
  store i32 20180515, ptr %.fca.2.gep, align 8, !tbaa !8
  store i8 1, ptr %.fca.3.gep, align 4, !tbaa !8
  store i8 28, ptr %.fca.4.gep, align 1, !tbaa !8
  store i8 2, ptr %.fca.5.gep, align 2, !tbaa !8
  store i8 0, ptr %.fca.6.gep, align 1, !tbaa !8
  store i64 1, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  store i64 %8, ptr %.fca.7.0.1.gep, align 8, !tbaa !8
  store i64 8, ptr %.fca.7.0.2.gep, align 8, !tbaa !8
  %omp_global_thread_num = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %0, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %5, ptr %gep_5, align 8
  %gep_6 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 2
  store ptr %4, ptr %gep_6, align 8
  %gep_7 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 3
  store ptr %3, ptr %gep_7, align 8
  %gep_8 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 4
  store ptr %2, ptr %gep_8, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QFPomp_subroutine..omp_par, ptr nonnull %structArg)
  %.fca.0.load = load ptr, ptr %5, align 8, !tbaa !8
  %.fca.7.0.0.load = load i64, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  %11 = sub i64 1, %.fca.7.0.0.load
  %12 = getelementptr double, ptr %.fca.0.load, i64 %11
  %13 = load double, ptr %12, align 8, !tbaa !4
  %14 = load i32, ptr %0, align 4, !tbaa !4
  %15 = sext i32 %14 to i64
  %16 = sub i64 %15, %.fca.7.0.0.load
  %17 = getelementptr double, ptr %.fca.0.load, i64 %16
  %18 = load double, ptr %17, align 8, !tbaa !4
  %19 = fadd contract double %13, %18
  store double %19, ptr %1, align 8, !tbaa !4
  call void @free(ptr %.fca.0.load)
  ret void
}
*** IR Dump After ControlHeightReductionPass on _QFPomp_subroutine ***
; Function Attrs: nounwind
define void @_QFPomp_subroutine(ptr %0, ptr nocapture writeonly %1, ptr nest %2) local_unnamed_addr #2 {
entry:
  %structArg = alloca { ptr, ptr, ptr, ptr, ptr }, align 8
  %3 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %4 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %5 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %.fca.1.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 1
  %.fca.2.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 2
  %.fca.3.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 3
  %.fca.4.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 4
  %.fca.5.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 5
  %.fca.6.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 6
  %.fca.7.0.0.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 0
  %.fca.7.0.1.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 1
  %.fca.7.0.2.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 2
  %6 = load i32, ptr %0, align 4, !tbaa !4
  %7 = tail call i32 @llvm.smax.i32(i32 %6, i32 0)
  %8 = zext i32 %7 to i64
  %9 = shl nuw nsw i64 %8, 3
  %10 = tail call ptr @malloc(i64 %9)
  store ptr %10, ptr %5, align 8, !tbaa !8
  store i64 8, ptr %.fca.1.gep, align 8, !tbaa !8
  store i32 20180515, ptr %.fca.2.gep, align 8, !tbaa !8
  store i8 1, ptr %.fca.3.gep, align 4, !tbaa !8
  store i8 28, ptr %.fca.4.gep, align 1, !tbaa !8
  store i8 2, ptr %.fca.5.gep, align 2, !tbaa !8
  store i8 0, ptr %.fca.6.gep, align 1, !tbaa !8
  store i64 1, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  store i64 %8, ptr %.fca.7.0.1.gep, align 8, !tbaa !8
  store i64 8, ptr %.fca.7.0.2.gep, align 8, !tbaa !8
  %omp_global_thread_num = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %0, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %5, ptr %gep_5, align 8
  %gep_6 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 2
  store ptr %4, ptr %gep_6, align 8
  %gep_7 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 3
  store ptr %3, ptr %gep_7, align 8
  %gep_8 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 4
  store ptr %2, ptr %gep_8, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QFPomp_subroutine..omp_par, ptr nonnull %structArg)
  %.fca.0.load = load ptr, ptr %5, align 8, !tbaa !8
  %.fca.7.0.0.load = load i64, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  %11 = sub i64 1, %.fca.7.0.0.load
  %12 = getelementptr double, ptr %.fca.0.load, i64 %11
  %13 = load double, ptr %12, align 8, !tbaa !4
  %14 = load i32, ptr %0, align 4, !tbaa !4
  %15 = sext i32 %14 to i64
  %16 = sub i64 %15, %.fca.7.0.0.load
  %17 = getelementptr double, ptr %.fca.0.load, i64 %16
  %18 = load double, ptr %17, align 8, !tbaa !4
  %19 = fadd contract double %13, %18
  store double %19, ptr %1, align 8, !tbaa !4
  call void @free(ptr %.fca.0.load)
  ret void
}
*** IR Dump After LoopSimplifyPass on _QFPomp_subroutine ***
; Function Attrs: nounwind
define void @_QFPomp_subroutine(ptr %0, ptr nocapture writeonly %1, ptr nest %2) local_unnamed_addr #2 {
entry:
  %structArg = alloca { ptr, ptr, ptr, ptr, ptr }, align 8
  %3 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %4 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %5 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %.fca.1.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 1
  %.fca.2.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 2
  %.fca.3.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 3
  %.fca.4.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 4
  %.fca.5.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 5
  %.fca.6.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 6
  %.fca.7.0.0.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 0
  %.fca.7.0.1.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 1
  %.fca.7.0.2.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 2
  %6 = load i32, ptr %0, align 4, !tbaa !4
  %7 = tail call i32 @llvm.smax.i32(i32 %6, i32 0)
  %8 = zext i32 %7 to i64
  %9 = shl nuw nsw i64 %8, 3
  %10 = tail call ptr @malloc(i64 %9)
  store ptr %10, ptr %5, align 8, !tbaa !8
  store i64 8, ptr %.fca.1.gep, align 8, !tbaa !8
  store i32 20180515, ptr %.fca.2.gep, align 8, !tbaa !8
  store i8 1, ptr %.fca.3.gep, align 4, !tbaa !8
  store i8 28, ptr %.fca.4.gep, align 1, !tbaa !8
  store i8 2, ptr %.fca.5.gep, align 2, !tbaa !8
  store i8 0, ptr %.fca.6.gep, align 1, !tbaa !8
  store i64 1, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  store i64 %8, ptr %.fca.7.0.1.gep, align 8, !tbaa !8
  store i64 8, ptr %.fca.7.0.2.gep, align 8, !tbaa !8
  %omp_global_thread_num = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %0, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %5, ptr %gep_5, align 8
  %gep_6 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 2
  store ptr %4, ptr %gep_6, align 8
  %gep_7 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 3
  store ptr %3, ptr %gep_7, align 8
  %gep_8 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 4
  store ptr %2, ptr %gep_8, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QFPomp_subroutine..omp_par, ptr nonnull %structArg)
  %.fca.0.load = load ptr, ptr %5, align 8, !tbaa !8
  %.fca.7.0.0.load = load i64, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  %11 = sub i64 1, %.fca.7.0.0.load
  %12 = getelementptr double, ptr %.fca.0.load, i64 %11
  %13 = load double, ptr %12, align 8, !tbaa !4
  %14 = load i32, ptr %0, align 4, !tbaa !4
  %15 = sext i32 %14 to i64
  %16 = sub i64 %15, %.fca.7.0.0.load
  %17 = getelementptr double, ptr %.fca.0.load, i64 %16
  %18 = load double, ptr %17, align 8, !tbaa !4
  %19 = fadd contract double %13, %18
  store double %19, ptr %1, align 8, !tbaa !4
  call void @free(ptr %.fca.0.load)
  ret void
}
*** IR Dump After LCSSAPass on _QFPomp_subroutine ***
; Function Attrs: nounwind
define void @_QFPomp_subroutine(ptr %0, ptr nocapture writeonly %1, ptr nest %2) local_unnamed_addr #2 {
entry:
  %structArg = alloca { ptr, ptr, ptr, ptr, ptr }, align 8
  %3 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %4 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %5 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %.fca.1.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 1
  %.fca.2.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 2
  %.fca.3.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 3
  %.fca.4.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 4
  %.fca.5.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 5
  %.fca.6.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 6
  %.fca.7.0.0.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 0
  %.fca.7.0.1.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 1
  %.fca.7.0.2.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 2
  %6 = load i32, ptr %0, align 4, !tbaa !4
  %7 = tail call i32 @llvm.smax.i32(i32 %6, i32 0)
  %8 = zext i32 %7 to i64
  %9 = shl nuw nsw i64 %8, 3
  %10 = tail call ptr @malloc(i64 %9)
  store ptr %10, ptr %5, align 8, !tbaa !8
  store i64 8, ptr %.fca.1.gep, align 8, !tbaa !8
  store i32 20180515, ptr %.fca.2.gep, align 8, !tbaa !8
  store i8 1, ptr %.fca.3.gep, align 4, !tbaa !8
  store i8 28, ptr %.fca.4.gep, align 1, !tbaa !8
  store i8 2, ptr %.fca.5.gep, align 2, !tbaa !8
  store i8 0, ptr %.fca.6.gep, align 1, !tbaa !8
  store i64 1, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  store i64 %8, ptr %.fca.7.0.1.gep, align 8, !tbaa !8
  store i64 8, ptr %.fca.7.0.2.gep, align 8, !tbaa !8
  %omp_global_thread_num = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %0, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %5, ptr %gep_5, align 8
  %gep_6 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 2
  store ptr %4, ptr %gep_6, align 8
  %gep_7 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 3
  store ptr %3, ptr %gep_7, align 8
  %gep_8 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 4
  store ptr %2, ptr %gep_8, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QFPomp_subroutine..omp_par, ptr nonnull %structArg)
  %.fca.0.load = load ptr, ptr %5, align 8, !tbaa !8
  %.fca.7.0.0.load = load i64, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  %11 = sub i64 1, %.fca.7.0.0.load
  %12 = getelementptr double, ptr %.fca.0.load, i64 %11
  %13 = load double, ptr %12, align 8, !tbaa !4
  %14 = load i32, ptr %0, align 4, !tbaa !4
  %15 = sext i32 %14 to i64
  %16 = sub i64 %15, %.fca.7.0.0.load
  %17 = getelementptr double, ptr %.fca.0.load, i64 %16
  %18 = load double, ptr %17, align 8, !tbaa !4
  %19 = fadd contract double %13, %18
  store double %19, ptr %1, align 8, !tbaa !4
  call void @free(ptr %.fca.0.load)
  ret void
}
*** IR Dump After LoopDistributePass on _QFPomp_subroutine ***
; Function Attrs: nounwind
define void @_QFPomp_subroutine(ptr %0, ptr nocapture writeonly %1, ptr nest %2) local_unnamed_addr #2 {
entry:
  %structArg = alloca { ptr, ptr, ptr, ptr, ptr }, align 8
  %3 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %4 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %5 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %.fca.1.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 1
  %.fca.2.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 2
  %.fca.3.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 3
  %.fca.4.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 4
  %.fca.5.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 5
  %.fca.6.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 6
  %.fca.7.0.0.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 0
  %.fca.7.0.1.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 1
  %.fca.7.0.2.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 2
  %6 = load i32, ptr %0, align 4, !tbaa !4
  %7 = tail call i32 @llvm.smax.i32(i32 %6, i32 0)
  %8 = zext i32 %7 to i64
  %9 = shl nuw nsw i64 %8, 3
  %10 = tail call ptr @malloc(i64 %9)
  store ptr %10, ptr %5, align 8, !tbaa !8
  store i64 8, ptr %.fca.1.gep, align 8, !tbaa !8
  store i32 20180515, ptr %.fca.2.gep, align 8, !tbaa !8
  store i8 1, ptr %.fca.3.gep, align 4, !tbaa !8
  store i8 28, ptr %.fca.4.gep, align 1, !tbaa !8
  store i8 2, ptr %.fca.5.gep, align 2, !tbaa !8
  store i8 0, ptr %.fca.6.gep, align 1, !tbaa !8
  store i64 1, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  store i64 %8, ptr %.fca.7.0.1.gep, align 8, !tbaa !8
  store i64 8, ptr %.fca.7.0.2.gep, align 8, !tbaa !8
  %omp_global_thread_num = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %0, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %5, ptr %gep_5, align 8
  %gep_6 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 2
  store ptr %4, ptr %gep_6, align 8
  %gep_7 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 3
  store ptr %3, ptr %gep_7, align 8
  %gep_8 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 4
  store ptr %2, ptr %gep_8, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QFPomp_subroutine..omp_par, ptr nonnull %structArg)
  %.fca.0.load = load ptr, ptr %5, align 8, !tbaa !8
  %.fca.7.0.0.load = load i64, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  %11 = sub i64 1, %.fca.7.0.0.load
  %12 = getelementptr double, ptr %.fca.0.load, i64 %11
  %13 = load double, ptr %12, align 8, !tbaa !4
  %14 = load i32, ptr %0, align 4, !tbaa !4
  %15 = sext i32 %14 to i64
  %16 = sub i64 %15, %.fca.7.0.0.load
  %17 = getelementptr double, ptr %.fca.0.load, i64 %16
  %18 = load double, ptr %17, align 8, !tbaa !4
  %19 = fadd contract double %13, %18
  store double %19, ptr %1, align 8, !tbaa !4
  call void @free(ptr %.fca.0.load)
  ret void
}
*** IR Dump After InjectTLIMappings on _QFPomp_subroutine ***
; Function Attrs: nounwind
define void @_QFPomp_subroutine(ptr %0, ptr nocapture writeonly %1, ptr nest %2) local_unnamed_addr #2 {
entry:
  %structArg = alloca { ptr, ptr, ptr, ptr, ptr }, align 8
  %3 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %4 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %5 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %.fca.1.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 1
  %.fca.2.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 2
  %.fca.3.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 3
  %.fca.4.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 4
  %.fca.5.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 5
  %.fca.6.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 6
  %.fca.7.0.0.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 0
  %.fca.7.0.1.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 1
  %.fca.7.0.2.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 2
  %6 = load i32, ptr %0, align 4, !tbaa !4
  %7 = tail call i32 @llvm.smax.i32(i32 %6, i32 0)
  %8 = zext i32 %7 to i64
  %9 = shl nuw nsw i64 %8, 3
  %10 = tail call ptr @malloc(i64 %9)
  store ptr %10, ptr %5, align 8, !tbaa !8
  store i64 8, ptr %.fca.1.gep, align 8, !tbaa !8
  store i32 20180515, ptr %.fca.2.gep, align 8, !tbaa !8
  store i8 1, ptr %.fca.3.gep, align 4, !tbaa !8
  store i8 28, ptr %.fca.4.gep, align 1, !tbaa !8
  store i8 2, ptr %.fca.5.gep, align 2, !tbaa !8
  store i8 0, ptr %.fca.6.gep, align 1, !tbaa !8
  store i64 1, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  store i64 %8, ptr %.fca.7.0.1.gep, align 8, !tbaa !8
  store i64 8, ptr %.fca.7.0.2.gep, align 8, !tbaa !8
  %omp_global_thread_num = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %0, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %5, ptr %gep_5, align 8
  %gep_6 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 2
  store ptr %4, ptr %gep_6, align 8
  %gep_7 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 3
  store ptr %3, ptr %gep_7, align 8
  %gep_8 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 4
  store ptr %2, ptr %gep_8, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QFPomp_subroutine..omp_par, ptr nonnull %structArg)
  %.fca.0.load = load ptr, ptr %5, align 8, !tbaa !8
  %.fca.7.0.0.load = load i64, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  %11 = sub i64 1, %.fca.7.0.0.load
  %12 = getelementptr double, ptr %.fca.0.load, i64 %11
  %13 = load double, ptr %12, align 8, !tbaa !4
  %14 = load i32, ptr %0, align 4, !tbaa !4
  %15 = sext i32 %14 to i64
  %16 = sub i64 %15, %.fca.7.0.0.load
  %17 = getelementptr double, ptr %.fca.0.load, i64 %16
  %18 = load double, ptr %17, align 8, !tbaa !4
  %19 = fadd contract double %13, %18
  store double %19, ptr %1, align 8, !tbaa !4
  call void @free(ptr %.fca.0.load)
  ret void
}
*** IR Dump After LoopVectorizePass on _QFPomp_subroutine ***
; Function Attrs: nounwind
define void @_QFPomp_subroutine(ptr %0, ptr nocapture writeonly %1, ptr nest %2) local_unnamed_addr #2 {
entry:
  %structArg = alloca { ptr, ptr, ptr, ptr, ptr }, align 8
  %3 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %4 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %5 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %.fca.1.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 1
  %.fca.2.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 2
  %.fca.3.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 3
  %.fca.4.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 4
  %.fca.5.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 5
  %.fca.6.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 6
  %.fca.7.0.0.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 0
  %.fca.7.0.1.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 1
  %.fca.7.0.2.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 2
  %6 = load i32, ptr %0, align 4, !tbaa !4
  %7 = tail call i32 @llvm.smax.i32(i32 %6, i32 0)
  %8 = zext i32 %7 to i64
  %9 = shl nuw nsw i64 %8, 3
  %10 = tail call ptr @malloc(i64 %9)
  store ptr %10, ptr %5, align 8, !tbaa !8
  store i64 8, ptr %.fca.1.gep, align 8, !tbaa !8
  store i32 20180515, ptr %.fca.2.gep, align 8, !tbaa !8
  store i8 1, ptr %.fca.3.gep, align 4, !tbaa !8
  store i8 28, ptr %.fca.4.gep, align 1, !tbaa !8
  store i8 2, ptr %.fca.5.gep, align 2, !tbaa !8
  store i8 0, ptr %.fca.6.gep, align 1, !tbaa !8
  store i64 1, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  store i64 %8, ptr %.fca.7.0.1.gep, align 8, !tbaa !8
  store i64 8, ptr %.fca.7.0.2.gep, align 8, !tbaa !8
  %omp_global_thread_num = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %0, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %5, ptr %gep_5, align 8
  %gep_6 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 2
  store ptr %4, ptr %gep_6, align 8
  %gep_7 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 3
  store ptr %3, ptr %gep_7, align 8
  %gep_8 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 4
  store ptr %2, ptr %gep_8, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QFPomp_subroutine..omp_par, ptr nonnull %structArg)
  %.fca.0.load = load ptr, ptr %5, align 8, !tbaa !8
  %.fca.7.0.0.load = load i64, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  %11 = sub i64 1, %.fca.7.0.0.load
  %12 = getelementptr double, ptr %.fca.0.load, i64 %11
  %13 = load double, ptr %12, align 8, !tbaa !4
  %14 = load i32, ptr %0, align 4, !tbaa !4
  %15 = sext i32 %14 to i64
  %16 = sub i64 %15, %.fca.7.0.0.load
  %17 = getelementptr double, ptr %.fca.0.load, i64 %16
  %18 = load double, ptr %17, align 8, !tbaa !4
  %19 = fadd contract double %13, %18
  store double %19, ptr %1, align 8, !tbaa !4
  call void @free(ptr %.fca.0.load)
  ret void
}
*** IR Dump After LoopLoadEliminationPass on _QFPomp_subroutine ***
; Function Attrs: nounwind
define void @_QFPomp_subroutine(ptr %0, ptr nocapture writeonly %1, ptr nest %2) local_unnamed_addr #2 {
entry:
  %structArg = alloca { ptr, ptr, ptr, ptr, ptr }, align 8
  %3 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %4 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %5 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %.fca.1.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 1
  %.fca.2.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 2
  %.fca.3.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 3
  %.fca.4.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 4
  %.fca.5.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 5
  %.fca.6.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 6
  %.fca.7.0.0.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 0
  %.fca.7.0.1.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 1
  %.fca.7.0.2.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 2
  %6 = load i32, ptr %0, align 4, !tbaa !4
  %7 = tail call i32 @llvm.smax.i32(i32 %6, i32 0)
  %8 = zext i32 %7 to i64
  %9 = shl nuw nsw i64 %8, 3
  %10 = tail call ptr @malloc(i64 %9)
  store ptr %10, ptr %5, align 8, !tbaa !8
  store i64 8, ptr %.fca.1.gep, align 8, !tbaa !8
  store i32 20180515, ptr %.fca.2.gep, align 8, !tbaa !8
  store i8 1, ptr %.fca.3.gep, align 4, !tbaa !8
  store i8 28, ptr %.fca.4.gep, align 1, !tbaa !8
  store i8 2, ptr %.fca.5.gep, align 2, !tbaa !8
  store i8 0, ptr %.fca.6.gep, align 1, !tbaa !8
  store i64 1, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  store i64 %8, ptr %.fca.7.0.1.gep, align 8, !tbaa !8
  store i64 8, ptr %.fca.7.0.2.gep, align 8, !tbaa !8
  %omp_global_thread_num = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %0, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %5, ptr %gep_5, align 8
  %gep_6 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 2
  store ptr %4, ptr %gep_6, align 8
  %gep_7 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 3
  store ptr %3, ptr %gep_7, align 8
  %gep_8 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 4
  store ptr %2, ptr %gep_8, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QFPomp_subroutine..omp_par, ptr nonnull %structArg)
  %.fca.0.load = load ptr, ptr %5, align 8, !tbaa !8
  %.fca.7.0.0.load = load i64, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  %11 = sub i64 1, %.fca.7.0.0.load
  %12 = getelementptr double, ptr %.fca.0.load, i64 %11
  %13 = load double, ptr %12, align 8, !tbaa !4
  %14 = load i32, ptr %0, align 4, !tbaa !4
  %15 = sext i32 %14 to i64
  %16 = sub i64 %15, %.fca.7.0.0.load
  %17 = getelementptr double, ptr %.fca.0.load, i64 %16
  %18 = load double, ptr %17, align 8, !tbaa !4
  %19 = fadd contract double %13, %18
  store double %19, ptr %1, align 8, !tbaa !4
  call void @free(ptr %.fca.0.load)
  ret void
}
*** IR Dump After InstCombinePass on _QFPomp_subroutine ***
; Function Attrs: nounwind
define void @_QFPomp_subroutine(ptr %0, ptr nocapture writeonly %1, ptr nest %2) local_unnamed_addr #2 {
entry:
  %structArg = alloca { ptr, ptr, ptr, ptr, ptr }, align 8
  %3 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %4 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %5 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %.fca.1.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 1
  %.fca.2.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 2
  %.fca.3.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 3
  %.fca.4.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 4
  %.fca.5.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 5
  %.fca.6.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 6
  %.fca.7.0.0.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 0
  %.fca.7.0.1.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 1
  %.fca.7.0.2.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 2
  %6 = load i32, ptr %0, align 4, !tbaa !4
  %7 = tail call i32 @llvm.smax.i32(i32 %6, i32 0)
  %8 = zext i32 %7 to i64
  %9 = shl nuw nsw i64 %8, 3
  %10 = tail call ptr @malloc(i64 %9)
  store ptr %10, ptr %5, align 8, !tbaa !8
  store i64 8, ptr %.fca.1.gep, align 8, !tbaa !8
  store i32 20180515, ptr %.fca.2.gep, align 8, !tbaa !8
  store i8 1, ptr %.fca.3.gep, align 4, !tbaa !8
  store i8 28, ptr %.fca.4.gep, align 1, !tbaa !8
  store i8 2, ptr %.fca.5.gep, align 2, !tbaa !8
  store i8 0, ptr %.fca.6.gep, align 1, !tbaa !8
  store i64 1, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  store i64 %8, ptr %.fca.7.0.1.gep, align 8, !tbaa !8
  store i64 8, ptr %.fca.7.0.2.gep, align 8, !tbaa !8
  %omp_global_thread_num = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %0, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %5, ptr %gep_5, align 8
  %gep_6 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 2
  store ptr %4, ptr %gep_6, align 8
  %gep_7 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 3
  store ptr %3, ptr %gep_7, align 8
  %gep_8 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 4
  store ptr %2, ptr %gep_8, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QFPomp_subroutine..omp_par, ptr nonnull %structArg)
  %.fca.0.load = load ptr, ptr %5, align 8, !tbaa !8
  %.fca.7.0.0.load = load i64, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  %11 = sub i64 1, %.fca.7.0.0.load
  %12 = getelementptr double, ptr %.fca.0.load, i64 %11
  %13 = load double, ptr %12, align 8, !tbaa !4
  %14 = load i32, ptr %0, align 4, !tbaa !4
  %15 = sext i32 %14 to i64
  %16 = sub i64 %15, %.fca.7.0.0.load
  %17 = getelementptr double, ptr %.fca.0.load, i64 %16
  %18 = load double, ptr %17, align 8, !tbaa !4
  %19 = fadd contract double %13, %18
  store double %19, ptr %1, align 8, !tbaa !4
  call void @free(ptr %.fca.0.load)
  ret void
}
*** IR Dump After SimplifyCFGPass on _QFPomp_subroutine ***
; Function Attrs: nounwind
define void @_QFPomp_subroutine(ptr %0, ptr nocapture writeonly %1, ptr nest %2) local_unnamed_addr #2 {
entry:
  %structArg = alloca { ptr, ptr, ptr, ptr, ptr }, align 8
  %3 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %4 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %5 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %.fca.1.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 1
  %.fca.2.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 2
  %.fca.3.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 3
  %.fca.4.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 4
  %.fca.5.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 5
  %.fca.6.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 6
  %.fca.7.0.0.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 0
  %.fca.7.0.1.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 1
  %.fca.7.0.2.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 2
  %6 = load i32, ptr %0, align 4, !tbaa !4
  %7 = tail call i32 @llvm.smax.i32(i32 %6, i32 0)
  %8 = zext i32 %7 to i64
  %9 = shl nuw nsw i64 %8, 3
  %10 = tail call ptr @malloc(i64 %9)
  store ptr %10, ptr %5, align 8, !tbaa !8
  store i64 8, ptr %.fca.1.gep, align 8, !tbaa !8
  store i32 20180515, ptr %.fca.2.gep, align 8, !tbaa !8
  store i8 1, ptr %.fca.3.gep, align 4, !tbaa !8
  store i8 28, ptr %.fca.4.gep, align 1, !tbaa !8
  store i8 2, ptr %.fca.5.gep, align 2, !tbaa !8
  store i8 0, ptr %.fca.6.gep, align 1, !tbaa !8
  store i64 1, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  store i64 %8, ptr %.fca.7.0.1.gep, align 8, !tbaa !8
  store i64 8, ptr %.fca.7.0.2.gep, align 8, !tbaa !8
  %omp_global_thread_num = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %0, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %5, ptr %gep_5, align 8
  %gep_6 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 2
  store ptr %4, ptr %gep_6, align 8
  %gep_7 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 3
  store ptr %3, ptr %gep_7, align 8
  %gep_8 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 4
  store ptr %2, ptr %gep_8, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QFPomp_subroutine..omp_par, ptr nonnull %structArg)
  %.fca.0.load = load ptr, ptr %5, align 8, !tbaa !8
  %.fca.7.0.0.load = load i64, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  %11 = sub i64 1, %.fca.7.0.0.load
  %12 = getelementptr double, ptr %.fca.0.load, i64 %11
  %13 = load double, ptr %12, align 8, !tbaa !4
  %14 = load i32, ptr %0, align 4, !tbaa !4
  %15 = sext i32 %14 to i64
  %16 = sub i64 %15, %.fca.7.0.0.load
  %17 = getelementptr double, ptr %.fca.0.load, i64 %16
  %18 = load double, ptr %17, align 8, !tbaa !4
  %19 = fadd contract double %13, %18
  store double %19, ptr %1, align 8, !tbaa !4
  call void @free(ptr %.fca.0.load)
  ret void
}
*** IR Dump After VectorCombinePass on _QFPomp_subroutine ***
; Function Attrs: nounwind
define void @_QFPomp_subroutine(ptr %0, ptr nocapture writeonly %1, ptr nest %2) local_unnamed_addr #2 {
entry:
  %structArg = alloca { ptr, ptr, ptr, ptr, ptr }, align 8
  %3 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %4 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %5 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %.fca.1.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 1
  %.fca.2.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 2
  %.fca.3.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 3
  %.fca.4.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 4
  %.fca.5.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 5
  %.fca.6.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 6
  %.fca.7.0.0.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 0
  %.fca.7.0.1.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 1
  %.fca.7.0.2.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 2
  %6 = load i32, ptr %0, align 4, !tbaa !4
  %7 = tail call i32 @llvm.smax.i32(i32 %6, i32 0)
  %8 = zext i32 %7 to i64
  %9 = shl nuw nsw i64 %8, 3
  %10 = tail call ptr @malloc(i64 %9)
  store ptr %10, ptr %5, align 8, !tbaa !8
  store i64 8, ptr %.fca.1.gep, align 8, !tbaa !8
  store i32 20180515, ptr %.fca.2.gep, align 8, !tbaa !8
  store i8 1, ptr %.fca.3.gep, align 4, !tbaa !8
  store i8 28, ptr %.fca.4.gep, align 1, !tbaa !8
  store i8 2, ptr %.fca.5.gep, align 2, !tbaa !8
  store i8 0, ptr %.fca.6.gep, align 1, !tbaa !8
  store i64 1, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  store i64 %8, ptr %.fca.7.0.1.gep, align 8, !tbaa !8
  store i64 8, ptr %.fca.7.0.2.gep, align 8, !tbaa !8
  %omp_global_thread_num = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %0, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %5, ptr %gep_5, align 8
  %gep_6 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 2
  store ptr %4, ptr %gep_6, align 8
  %gep_7 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 3
  store ptr %3, ptr %gep_7, align 8
  %gep_8 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 4
  store ptr %2, ptr %gep_8, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QFPomp_subroutine..omp_par, ptr nonnull %structArg)
  %.fca.0.load = load ptr, ptr %5, align 8, !tbaa !8
  %.fca.7.0.0.load = load i64, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  %11 = sub i64 1, %.fca.7.0.0.load
  %12 = getelementptr double, ptr %.fca.0.load, i64 %11
  %13 = load double, ptr %12, align 8, !tbaa !4
  %14 = load i32, ptr %0, align 4, !tbaa !4
  %15 = sext i32 %14 to i64
  %16 = sub i64 %15, %.fca.7.0.0.load
  %17 = getelementptr double, ptr %.fca.0.load, i64 %16
  %18 = load double, ptr %17, align 8, !tbaa !4
  %19 = fadd contract double %13, %18
  store double %19, ptr %1, align 8, !tbaa !4
  call void @free(ptr %.fca.0.load)
  ret void
}
*** IR Dump After InstCombinePass on _QFPomp_subroutine ***
; Function Attrs: nounwind
define void @_QFPomp_subroutine(ptr %0, ptr nocapture writeonly %1, ptr nest %2) local_unnamed_addr #2 {
entry:
  %structArg = alloca { ptr, ptr, ptr, ptr, ptr }, align 8
  %3 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %4 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %5 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %.fca.1.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 1
  %.fca.2.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 2
  %.fca.3.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 3
  %.fca.4.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 4
  %.fca.5.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 5
  %.fca.6.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 6
  %.fca.7.0.0.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 0
  %.fca.7.0.1.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 1
  %.fca.7.0.2.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 2
  %6 = load i32, ptr %0, align 4, !tbaa !4
  %7 = tail call i32 @llvm.smax.i32(i32 %6, i32 0)
  %8 = zext i32 %7 to i64
  %9 = shl nuw nsw i64 %8, 3
  %10 = tail call ptr @malloc(i64 %9)
  store ptr %10, ptr %5, align 8, !tbaa !8
  store i64 8, ptr %.fca.1.gep, align 8, !tbaa !8
  store i32 20180515, ptr %.fca.2.gep, align 8, !tbaa !8
  store i8 1, ptr %.fca.3.gep, align 4, !tbaa !8
  store i8 28, ptr %.fca.4.gep, align 1, !tbaa !8
  store i8 2, ptr %.fca.5.gep, align 2, !tbaa !8
  store i8 0, ptr %.fca.6.gep, align 1, !tbaa !8
  store i64 1, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  store i64 %8, ptr %.fca.7.0.1.gep, align 8, !tbaa !8
  store i64 8, ptr %.fca.7.0.2.gep, align 8, !tbaa !8
  %omp_global_thread_num = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %0, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %5, ptr %gep_5, align 8
  %gep_6 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 2
  store ptr %4, ptr %gep_6, align 8
  %gep_7 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 3
  store ptr %3, ptr %gep_7, align 8
  %gep_8 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 4
  store ptr %2, ptr %gep_8, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QFPomp_subroutine..omp_par, ptr nonnull %structArg)
  %.fca.0.load = load ptr, ptr %5, align 8, !tbaa !8
  %.fca.7.0.0.load = load i64, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  %11 = sub i64 1, %.fca.7.0.0.load
  %12 = getelementptr double, ptr %.fca.0.load, i64 %11
  %13 = load double, ptr %12, align 8, !tbaa !4
  %14 = load i32, ptr %0, align 4, !tbaa !4
  %15 = sext i32 %14 to i64
  %16 = sub i64 %15, %.fca.7.0.0.load
  %17 = getelementptr double, ptr %.fca.0.load, i64 %16
  %18 = load double, ptr %17, align 8, !tbaa !4
  %19 = fadd contract double %13, %18
  store double %19, ptr %1, align 8, !tbaa !4
  call void @free(ptr %.fca.0.load)
  ret void
}
*** IR Dump After LoopUnrollPass on _QFPomp_subroutine ***
; Function Attrs: nounwind
define void @_QFPomp_subroutine(ptr %0, ptr nocapture writeonly %1, ptr nest %2) local_unnamed_addr #2 {
entry:
  %structArg = alloca { ptr, ptr, ptr, ptr, ptr }, align 8
  %3 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %4 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %5 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %.fca.1.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 1
  %.fca.2.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 2
  %.fca.3.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 3
  %.fca.4.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 4
  %.fca.5.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 5
  %.fca.6.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 6
  %.fca.7.0.0.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 0
  %.fca.7.0.1.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 1
  %.fca.7.0.2.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 2
  %6 = load i32, ptr %0, align 4, !tbaa !4
  %7 = tail call i32 @llvm.smax.i32(i32 %6, i32 0)
  %8 = zext i32 %7 to i64
  %9 = shl nuw nsw i64 %8, 3
  %10 = tail call ptr @malloc(i64 %9)
  store ptr %10, ptr %5, align 8, !tbaa !8
  store i64 8, ptr %.fca.1.gep, align 8, !tbaa !8
  store i32 20180515, ptr %.fca.2.gep, align 8, !tbaa !8
  store i8 1, ptr %.fca.3.gep, align 4, !tbaa !8
  store i8 28, ptr %.fca.4.gep, align 1, !tbaa !8
  store i8 2, ptr %.fca.5.gep, align 2, !tbaa !8
  store i8 0, ptr %.fca.6.gep, align 1, !tbaa !8
  store i64 1, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  store i64 %8, ptr %.fca.7.0.1.gep, align 8, !tbaa !8
  store i64 8, ptr %.fca.7.0.2.gep, align 8, !tbaa !8
  %omp_global_thread_num = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %0, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %5, ptr %gep_5, align 8
  %gep_6 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 2
  store ptr %4, ptr %gep_6, align 8
  %gep_7 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 3
  store ptr %3, ptr %gep_7, align 8
  %gep_8 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 4
  store ptr %2, ptr %gep_8, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QFPomp_subroutine..omp_par, ptr nonnull %structArg)
  %.fca.0.load = load ptr, ptr %5, align 8, !tbaa !8
  %.fca.7.0.0.load = load i64, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  %11 = sub i64 1, %.fca.7.0.0.load
  %12 = getelementptr double, ptr %.fca.0.load, i64 %11
  %13 = load double, ptr %12, align 8, !tbaa !4
  %14 = load i32, ptr %0, align 4, !tbaa !4
  %15 = sext i32 %14 to i64
  %16 = sub i64 %15, %.fca.7.0.0.load
  %17 = getelementptr double, ptr %.fca.0.load, i64 %16
  %18 = load double, ptr %17, align 8, !tbaa !4
  %19 = fadd contract double %13, %18
  store double %19, ptr %1, align 8, !tbaa !4
  call void @free(ptr %.fca.0.load)
  ret void
}
*** IR Dump After WarnMissedTransformationsPass on _QFPomp_subroutine ***
; Function Attrs: nounwind
define void @_QFPomp_subroutine(ptr %0, ptr nocapture writeonly %1, ptr nest %2) local_unnamed_addr #2 {
entry:
  %structArg = alloca { ptr, ptr, ptr, ptr, ptr }, align 8
  %3 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %4 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %5 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %.fca.1.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 1
  %.fca.2.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 2
  %.fca.3.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 3
  %.fca.4.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 4
  %.fca.5.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 5
  %.fca.6.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 6
  %.fca.7.0.0.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 0
  %.fca.7.0.1.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 1
  %.fca.7.0.2.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 2
  %6 = load i32, ptr %0, align 4, !tbaa !4
  %7 = tail call i32 @llvm.smax.i32(i32 %6, i32 0)
  %8 = zext i32 %7 to i64
  %9 = shl nuw nsw i64 %8, 3
  %10 = tail call ptr @malloc(i64 %9)
  store ptr %10, ptr %5, align 8, !tbaa !8
  store i64 8, ptr %.fca.1.gep, align 8, !tbaa !8
  store i32 20180515, ptr %.fca.2.gep, align 8, !tbaa !8
  store i8 1, ptr %.fca.3.gep, align 4, !tbaa !8
  store i8 28, ptr %.fca.4.gep, align 1, !tbaa !8
  store i8 2, ptr %.fca.5.gep, align 2, !tbaa !8
  store i8 0, ptr %.fca.6.gep, align 1, !tbaa !8
  store i64 1, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  store i64 %8, ptr %.fca.7.0.1.gep, align 8, !tbaa !8
  store i64 8, ptr %.fca.7.0.2.gep, align 8, !tbaa !8
  %omp_global_thread_num = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %0, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %5, ptr %gep_5, align 8
  %gep_6 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 2
  store ptr %4, ptr %gep_6, align 8
  %gep_7 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 3
  store ptr %3, ptr %gep_7, align 8
  %gep_8 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 4
  store ptr %2, ptr %gep_8, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QFPomp_subroutine..omp_par, ptr nonnull %structArg)
  %.fca.0.load = load ptr, ptr %5, align 8, !tbaa !8
  %.fca.7.0.0.load = load i64, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  %11 = sub i64 1, %.fca.7.0.0.load
  %12 = getelementptr double, ptr %.fca.0.load, i64 %11
  %13 = load double, ptr %12, align 8, !tbaa !4
  %14 = load i32, ptr %0, align 4, !tbaa !4
  %15 = sext i32 %14 to i64
  %16 = sub i64 %15, %.fca.7.0.0.load
  %17 = getelementptr double, ptr %.fca.0.load, i64 %16
  %18 = load double, ptr %17, align 8, !tbaa !4
  %19 = fadd contract double %13, %18
  store double %19, ptr %1, align 8, !tbaa !4
  call void @free(ptr %.fca.0.load)
  ret void
}
*** IR Dump After SROAPass on _QFPomp_subroutine ***
; Function Attrs: nounwind
define void @_QFPomp_subroutine(ptr %0, ptr nocapture writeonly %1, ptr nest %2) local_unnamed_addr #2 {
entry:
  %structArg = alloca { ptr, ptr, ptr, ptr, ptr }, align 8
  %3 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %4 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %5 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %.fca.1.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 1
  %.fca.2.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 2
  %.fca.3.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 3
  %.fca.4.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 4
  %.fca.5.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 5
  %.fca.6.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 6
  %.fca.7.0.0.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 0
  %.fca.7.0.1.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 1
  %.fca.7.0.2.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 2
  %6 = load i32, ptr %0, align 4, !tbaa !4
  %7 = tail call i32 @llvm.smax.i32(i32 %6, i32 0)
  %8 = zext i32 %7 to i64
  %9 = shl nuw nsw i64 %8, 3
  %10 = tail call ptr @malloc(i64 %9)
  store ptr %10, ptr %5, align 8, !tbaa !8
  store i64 8, ptr %.fca.1.gep, align 8, !tbaa !8
  store i32 20180515, ptr %.fca.2.gep, align 8, !tbaa !8
  store i8 1, ptr %.fca.3.gep, align 4, !tbaa !8
  store i8 28, ptr %.fca.4.gep, align 1, !tbaa !8
  store i8 2, ptr %.fca.5.gep, align 2, !tbaa !8
  store i8 0, ptr %.fca.6.gep, align 1, !tbaa !8
  store i64 1, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  store i64 %8, ptr %.fca.7.0.1.gep, align 8, !tbaa !8
  store i64 8, ptr %.fca.7.0.2.gep, align 8, !tbaa !8
  %omp_global_thread_num = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %0, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %5, ptr %gep_5, align 8
  %gep_6 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 2
  store ptr %4, ptr %gep_6, align 8
  %gep_7 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 3
  store ptr %3, ptr %gep_7, align 8
  %gep_8 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 4
  store ptr %2, ptr %gep_8, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QFPomp_subroutine..omp_par, ptr nonnull %structArg)
  %.fca.0.load = load ptr, ptr %5, align 8, !tbaa !8
  %.fca.7.0.0.load = load i64, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  %11 = sub i64 1, %.fca.7.0.0.load
  %12 = getelementptr double, ptr %.fca.0.load, i64 %11
  %13 = load double, ptr %12, align 8, !tbaa !4
  %14 = load i32, ptr %0, align 4, !tbaa !4
  %15 = sext i32 %14 to i64
  %16 = sub i64 %15, %.fca.7.0.0.load
  %17 = getelementptr double, ptr %.fca.0.load, i64 %16
  %18 = load double, ptr %17, align 8, !tbaa !4
  %19 = fadd contract double %13, %18
  store double %19, ptr %1, align 8, !tbaa !4
  call void @free(ptr %.fca.0.load)
  ret void
}
*** IR Dump After InstCombinePass on _QFPomp_subroutine ***
; Function Attrs: nounwind
define void @_QFPomp_subroutine(ptr %0, ptr nocapture writeonly %1, ptr nest %2) local_unnamed_addr #2 {
entry:
  %structArg = alloca { ptr, ptr, ptr, ptr, ptr }, align 8
  %3 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %4 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %5 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %.fca.1.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 1
  %.fca.2.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 2
  %.fca.3.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 3
  %.fca.4.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 4
  %.fca.5.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 5
  %.fca.6.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 6
  %.fca.7.0.0.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 0
  %.fca.7.0.1.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 1
  %.fca.7.0.2.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 2
  %6 = load i32, ptr %0, align 4, !tbaa !4
  %7 = tail call i32 @llvm.smax.i32(i32 %6, i32 0)
  %8 = zext i32 %7 to i64
  %9 = shl nuw nsw i64 %8, 3
  %10 = tail call ptr @malloc(i64 %9)
  store ptr %10, ptr %5, align 8, !tbaa !8
  store i64 8, ptr %.fca.1.gep, align 8, !tbaa !8
  store i32 20180515, ptr %.fca.2.gep, align 8, !tbaa !8
  store i8 1, ptr %.fca.3.gep, align 4, !tbaa !8
  store i8 28, ptr %.fca.4.gep, align 1, !tbaa !8
  store i8 2, ptr %.fca.5.gep, align 2, !tbaa !8
  store i8 0, ptr %.fca.6.gep, align 1, !tbaa !8
  store i64 1, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  store i64 %8, ptr %.fca.7.0.1.gep, align 8, !tbaa !8
  store i64 8, ptr %.fca.7.0.2.gep, align 8, !tbaa !8
  %omp_global_thread_num = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %0, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %5, ptr %gep_5, align 8
  %gep_6 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 2
  store ptr %4, ptr %gep_6, align 8
  %gep_7 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 3
  store ptr %3, ptr %gep_7, align 8
  %gep_8 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 4
  store ptr %2, ptr %gep_8, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QFPomp_subroutine..omp_par, ptr nonnull %structArg)
  %.fca.0.load = load ptr, ptr %5, align 8, !tbaa !8
  %.fca.7.0.0.load = load i64, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  %11 = sub i64 1, %.fca.7.0.0.load
  %12 = getelementptr double, ptr %.fca.0.load, i64 %11
  %13 = load double, ptr %12, align 8, !tbaa !4
  %14 = load i32, ptr %0, align 4, !tbaa !4
  %15 = sext i32 %14 to i64
  %16 = sub i64 %15, %.fca.7.0.0.load
  %17 = getelementptr double, ptr %.fca.0.load, i64 %16
  %18 = load double, ptr %17, align 8, !tbaa !4
  %19 = fadd contract double %13, %18
  store double %19, ptr %1, align 8, !tbaa !4
  call void @free(ptr %.fca.0.load)
  ret void
}
*** IR Dump After LoopSimplifyPass on _QFPomp_subroutine ***
; Function Attrs: nounwind
define void @_QFPomp_subroutine(ptr %0, ptr nocapture writeonly %1, ptr nest %2) local_unnamed_addr #2 {
entry:
  %structArg = alloca { ptr, ptr, ptr, ptr, ptr }, align 8
  %3 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %4 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %5 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %.fca.1.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 1
  %.fca.2.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 2
  %.fca.3.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 3
  %.fca.4.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 4
  %.fca.5.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 5
  %.fca.6.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 6
  %.fca.7.0.0.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 0
  %.fca.7.0.1.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 1
  %.fca.7.0.2.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 2
  %6 = load i32, ptr %0, align 4, !tbaa !4
  %7 = tail call i32 @llvm.smax.i32(i32 %6, i32 0)
  %8 = zext i32 %7 to i64
  %9 = shl nuw nsw i64 %8, 3
  %10 = tail call ptr @malloc(i64 %9)
  store ptr %10, ptr %5, align 8, !tbaa !8
  store i64 8, ptr %.fca.1.gep, align 8, !tbaa !8
  store i32 20180515, ptr %.fca.2.gep, align 8, !tbaa !8
  store i8 1, ptr %.fca.3.gep, align 4, !tbaa !8
  store i8 28, ptr %.fca.4.gep, align 1, !tbaa !8
  store i8 2, ptr %.fca.5.gep, align 2, !tbaa !8
  store i8 0, ptr %.fca.6.gep, align 1, !tbaa !8
  store i64 1, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  store i64 %8, ptr %.fca.7.0.1.gep, align 8, !tbaa !8
  store i64 8, ptr %.fca.7.0.2.gep, align 8, !tbaa !8
  %omp_global_thread_num = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %0, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %5, ptr %gep_5, align 8
  %gep_6 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 2
  store ptr %4, ptr %gep_6, align 8
  %gep_7 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 3
  store ptr %3, ptr %gep_7, align 8
  %gep_8 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 4
  store ptr %2, ptr %gep_8, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QFPomp_subroutine..omp_par, ptr nonnull %structArg)
  %.fca.0.load = load ptr, ptr %5, align 8, !tbaa !8
  %.fca.7.0.0.load = load i64, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  %11 = sub i64 1, %.fca.7.0.0.load
  %12 = getelementptr double, ptr %.fca.0.load, i64 %11
  %13 = load double, ptr %12, align 8, !tbaa !4
  %14 = load i32, ptr %0, align 4, !tbaa !4
  %15 = sext i32 %14 to i64
  %16 = sub i64 %15, %.fca.7.0.0.load
  %17 = getelementptr double, ptr %.fca.0.load, i64 %16
  %18 = load double, ptr %17, align 8, !tbaa !4
  %19 = fadd contract double %13, %18
  store double %19, ptr %1, align 8, !tbaa !4
  call void @free(ptr %.fca.0.load)
  ret void
}
*** IR Dump After LCSSAPass on _QFPomp_subroutine ***
; Function Attrs: nounwind
define void @_QFPomp_subroutine(ptr %0, ptr nocapture writeonly %1, ptr nest %2) local_unnamed_addr #2 {
entry:
  %structArg = alloca { ptr, ptr, ptr, ptr, ptr }, align 8
  %3 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %4 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %5 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %.fca.1.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 1
  %.fca.2.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 2
  %.fca.3.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 3
  %.fca.4.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 4
  %.fca.5.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 5
  %.fca.6.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 6
  %.fca.7.0.0.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 0
  %.fca.7.0.1.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 1
  %.fca.7.0.2.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 2
  %6 = load i32, ptr %0, align 4, !tbaa !4
  %7 = tail call i32 @llvm.smax.i32(i32 %6, i32 0)
  %8 = zext i32 %7 to i64
  %9 = shl nuw nsw i64 %8, 3
  %10 = tail call ptr @malloc(i64 %9)
  store ptr %10, ptr %5, align 8, !tbaa !8
  store i64 8, ptr %.fca.1.gep, align 8, !tbaa !8
  store i32 20180515, ptr %.fca.2.gep, align 8, !tbaa !8
  store i8 1, ptr %.fca.3.gep, align 4, !tbaa !8
  store i8 28, ptr %.fca.4.gep, align 1, !tbaa !8
  store i8 2, ptr %.fca.5.gep, align 2, !tbaa !8
  store i8 0, ptr %.fca.6.gep, align 1, !tbaa !8
  store i64 1, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  store i64 %8, ptr %.fca.7.0.1.gep, align 8, !tbaa !8
  store i64 8, ptr %.fca.7.0.2.gep, align 8, !tbaa !8
  %omp_global_thread_num = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %0, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %5, ptr %gep_5, align 8
  %gep_6 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 2
  store ptr %4, ptr %gep_6, align 8
  %gep_7 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 3
  store ptr %3, ptr %gep_7, align 8
  %gep_8 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 4
  store ptr %2, ptr %gep_8, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QFPomp_subroutine..omp_par, ptr nonnull %structArg)
  %.fca.0.load = load ptr, ptr %5, align 8, !tbaa !8
  %.fca.7.0.0.load = load i64, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  %11 = sub i64 1, %.fca.7.0.0.load
  %12 = getelementptr double, ptr %.fca.0.load, i64 %11
  %13 = load double, ptr %12, align 8, !tbaa !4
  %14 = load i32, ptr %0, align 4, !tbaa !4
  %15 = sext i32 %14 to i64
  %16 = sub i64 %15, %.fca.7.0.0.load
  %17 = getelementptr double, ptr %.fca.0.load, i64 %16
  %18 = load double, ptr %17, align 8, !tbaa !4
  %19 = fadd contract double %13, %18
  store double %19, ptr %1, align 8, !tbaa !4
  call void @free(ptr %.fca.0.load)
  ret void
}
*** IR Dump After AlignmentFromAssumptionsPass on _QFPomp_subroutine ***
; Function Attrs: nounwind
define void @_QFPomp_subroutine(ptr %0, ptr nocapture writeonly %1, ptr nest %2) local_unnamed_addr #2 {
entry:
  %structArg = alloca { ptr, ptr, ptr, ptr, ptr }, align 8
  %3 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %4 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %5 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %.fca.1.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 1
  %.fca.2.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 2
  %.fca.3.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 3
  %.fca.4.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 4
  %.fca.5.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 5
  %.fca.6.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 6
  %.fca.7.0.0.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 0
  %.fca.7.0.1.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 1
  %.fca.7.0.2.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 2
  %6 = load i32, ptr %0, align 4, !tbaa !4
  %7 = tail call i32 @llvm.smax.i32(i32 %6, i32 0)
  %8 = zext i32 %7 to i64
  %9 = shl nuw nsw i64 %8, 3
  %10 = tail call ptr @malloc(i64 %9)
  store ptr %10, ptr %5, align 8, !tbaa !8
  store i64 8, ptr %.fca.1.gep, align 8, !tbaa !8
  store i32 20180515, ptr %.fca.2.gep, align 8, !tbaa !8
  store i8 1, ptr %.fca.3.gep, align 4, !tbaa !8
  store i8 28, ptr %.fca.4.gep, align 1, !tbaa !8
  store i8 2, ptr %.fca.5.gep, align 2, !tbaa !8
  store i8 0, ptr %.fca.6.gep, align 1, !tbaa !8
  store i64 1, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  store i64 %8, ptr %.fca.7.0.1.gep, align 8, !tbaa !8
  store i64 8, ptr %.fca.7.0.2.gep, align 8, !tbaa !8
  %omp_global_thread_num = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %0, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %5, ptr %gep_5, align 8
  %gep_6 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 2
  store ptr %4, ptr %gep_6, align 8
  %gep_7 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 3
  store ptr %3, ptr %gep_7, align 8
  %gep_8 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 4
  store ptr %2, ptr %gep_8, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QFPomp_subroutine..omp_par, ptr nonnull %structArg)
  %.fca.0.load = load ptr, ptr %5, align 8, !tbaa !8
  %.fca.7.0.0.load = load i64, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  %11 = sub i64 1, %.fca.7.0.0.load
  %12 = getelementptr double, ptr %.fca.0.load, i64 %11
  %13 = load double, ptr %12, align 8, !tbaa !4
  %14 = load i32, ptr %0, align 4, !tbaa !4
  %15 = sext i32 %14 to i64
  %16 = sub i64 %15, %.fca.7.0.0.load
  %17 = getelementptr double, ptr %.fca.0.load, i64 %16
  %18 = load double, ptr %17, align 8, !tbaa !4
  %19 = fadd contract double %13, %18
  store double %19, ptr %1, align 8, !tbaa !4
  call void @free(ptr %.fca.0.load)
  ret void
}
*** IR Dump After LoopSinkPass on _QFPomp_subroutine ***
; Function Attrs: nounwind
define void @_QFPomp_subroutine(ptr %0, ptr nocapture writeonly %1, ptr nest %2) local_unnamed_addr #2 {
entry:
  %structArg = alloca { ptr, ptr, ptr, ptr, ptr }, align 8
  %3 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %4 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %5 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %.fca.1.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 1
  %.fca.2.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 2
  %.fca.3.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 3
  %.fca.4.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 4
  %.fca.5.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 5
  %.fca.6.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 6
  %.fca.7.0.0.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 0
  %.fca.7.0.1.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 1
  %.fca.7.0.2.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 2
  %6 = load i32, ptr %0, align 4, !tbaa !4
  %7 = tail call i32 @llvm.smax.i32(i32 %6, i32 0)
  %8 = zext i32 %7 to i64
  %9 = shl nuw nsw i64 %8, 3
  %10 = tail call ptr @malloc(i64 %9)
  store ptr %10, ptr %5, align 8, !tbaa !8
  store i64 8, ptr %.fca.1.gep, align 8, !tbaa !8
  store i32 20180515, ptr %.fca.2.gep, align 8, !tbaa !8
  store i8 1, ptr %.fca.3.gep, align 4, !tbaa !8
  store i8 28, ptr %.fca.4.gep, align 1, !tbaa !8
  store i8 2, ptr %.fca.5.gep, align 2, !tbaa !8
  store i8 0, ptr %.fca.6.gep, align 1, !tbaa !8
  store i64 1, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  store i64 %8, ptr %.fca.7.0.1.gep, align 8, !tbaa !8
  store i64 8, ptr %.fca.7.0.2.gep, align 8, !tbaa !8
  %omp_global_thread_num = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %0, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %5, ptr %gep_5, align 8
  %gep_6 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 2
  store ptr %4, ptr %gep_6, align 8
  %gep_7 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 3
  store ptr %3, ptr %gep_7, align 8
  %gep_8 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 4
  store ptr %2, ptr %gep_8, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QFPomp_subroutine..omp_par, ptr nonnull %structArg)
  %.fca.0.load = load ptr, ptr %5, align 8, !tbaa !8
  %.fca.7.0.0.load = load i64, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  %11 = sub i64 1, %.fca.7.0.0.load
  %12 = getelementptr double, ptr %.fca.0.load, i64 %11
  %13 = load double, ptr %12, align 8, !tbaa !4
  %14 = load i32, ptr %0, align 4, !tbaa !4
  %15 = sext i32 %14 to i64
  %16 = sub i64 %15, %.fca.7.0.0.load
  %17 = getelementptr double, ptr %.fca.0.load, i64 %16
  %18 = load double, ptr %17, align 8, !tbaa !4
  %19 = fadd contract double %13, %18
  store double %19, ptr %1, align 8, !tbaa !4
  call void @free(ptr %.fca.0.load)
  ret void
}
*** IR Dump After InstSimplifyPass on _QFPomp_subroutine ***
; Function Attrs: nounwind
define void @_QFPomp_subroutine(ptr %0, ptr nocapture writeonly %1, ptr nest %2) local_unnamed_addr #2 {
entry:
  %structArg = alloca { ptr, ptr, ptr, ptr, ptr }, align 8
  %3 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %4 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %5 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %.fca.1.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 1
  %.fca.2.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 2
  %.fca.3.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 3
  %.fca.4.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 4
  %.fca.5.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 5
  %.fca.6.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 6
  %.fca.7.0.0.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 0
  %.fca.7.0.1.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 1
  %.fca.7.0.2.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 2
  %6 = load i32, ptr %0, align 4, !tbaa !4
  %7 = tail call i32 @llvm.smax.i32(i32 %6, i32 0)
  %8 = zext i32 %7 to i64
  %9 = shl nuw nsw i64 %8, 3
  %10 = tail call ptr @malloc(i64 %9)
  store ptr %10, ptr %5, align 8, !tbaa !8
  store i64 8, ptr %.fca.1.gep, align 8, !tbaa !8
  store i32 20180515, ptr %.fca.2.gep, align 8, !tbaa !8
  store i8 1, ptr %.fca.3.gep, align 4, !tbaa !8
  store i8 28, ptr %.fca.4.gep, align 1, !tbaa !8
  store i8 2, ptr %.fca.5.gep, align 2, !tbaa !8
  store i8 0, ptr %.fca.6.gep, align 1, !tbaa !8
  store i64 1, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  store i64 %8, ptr %.fca.7.0.1.gep, align 8, !tbaa !8
  store i64 8, ptr %.fca.7.0.2.gep, align 8, !tbaa !8
  %omp_global_thread_num = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %0, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %5, ptr %gep_5, align 8
  %gep_6 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 2
  store ptr %4, ptr %gep_6, align 8
  %gep_7 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 3
  store ptr %3, ptr %gep_7, align 8
  %gep_8 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 4
  store ptr %2, ptr %gep_8, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QFPomp_subroutine..omp_par, ptr nonnull %structArg)
  %.fca.0.load = load ptr, ptr %5, align 8, !tbaa !8
  %.fca.7.0.0.load = load i64, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  %11 = sub i64 1, %.fca.7.0.0.load
  %12 = getelementptr double, ptr %.fca.0.load, i64 %11
  %13 = load double, ptr %12, align 8, !tbaa !4
  %14 = load i32, ptr %0, align 4, !tbaa !4
  %15 = sext i32 %14 to i64
  %16 = sub i64 %15, %.fca.7.0.0.load
  %17 = getelementptr double, ptr %.fca.0.load, i64 %16
  %18 = load double, ptr %17, align 8, !tbaa !4
  %19 = fadd contract double %13, %18
  store double %19, ptr %1, align 8, !tbaa !4
  call void @free(ptr %.fca.0.load)
  ret void
}
*** IR Dump After DivRemPairsPass on _QFPomp_subroutine ***
; Function Attrs: nounwind
define void @_QFPomp_subroutine(ptr %0, ptr nocapture writeonly %1, ptr nest %2) local_unnamed_addr #2 {
entry:
  %structArg = alloca { ptr, ptr, ptr, ptr, ptr }, align 8
  %3 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %4 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %5 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %.fca.1.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 1
  %.fca.2.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 2
  %.fca.3.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 3
  %.fca.4.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 4
  %.fca.5.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 5
  %.fca.6.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 6
  %.fca.7.0.0.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 0
  %.fca.7.0.1.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 1
  %.fca.7.0.2.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 2
  %6 = load i32, ptr %0, align 4, !tbaa !4
  %7 = tail call i32 @llvm.smax.i32(i32 %6, i32 0)
  %8 = zext i32 %7 to i64
  %9 = shl nuw nsw i64 %8, 3
  %10 = tail call ptr @malloc(i64 %9)
  store ptr %10, ptr %5, align 8, !tbaa !8
  store i64 8, ptr %.fca.1.gep, align 8, !tbaa !8
  store i32 20180515, ptr %.fca.2.gep, align 8, !tbaa !8
  store i8 1, ptr %.fca.3.gep, align 4, !tbaa !8
  store i8 28, ptr %.fca.4.gep, align 1, !tbaa !8
  store i8 2, ptr %.fca.5.gep, align 2, !tbaa !8
  store i8 0, ptr %.fca.6.gep, align 1, !tbaa !8
  store i64 1, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  store i64 %8, ptr %.fca.7.0.1.gep, align 8, !tbaa !8
  store i64 8, ptr %.fca.7.0.2.gep, align 8, !tbaa !8
  %omp_global_thread_num = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %0, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %5, ptr %gep_5, align 8
  %gep_6 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 2
  store ptr %4, ptr %gep_6, align 8
  %gep_7 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 3
  store ptr %3, ptr %gep_7, align 8
  %gep_8 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 4
  store ptr %2, ptr %gep_8, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QFPomp_subroutine..omp_par, ptr nonnull %structArg)
  %.fca.0.load = load ptr, ptr %5, align 8, !tbaa !8
  %.fca.7.0.0.load = load i64, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  %11 = sub i64 1, %.fca.7.0.0.load
  %12 = getelementptr double, ptr %.fca.0.load, i64 %11
  %13 = load double, ptr %12, align 8, !tbaa !4
  %14 = load i32, ptr %0, align 4, !tbaa !4
  %15 = sext i32 %14 to i64
  %16 = sub i64 %15, %.fca.7.0.0.load
  %17 = getelementptr double, ptr %.fca.0.load, i64 %16
  %18 = load double, ptr %17, align 8, !tbaa !4
  %19 = fadd contract double %13, %18
  store double %19, ptr %1, align 8, !tbaa !4
  call void @free(ptr %.fca.0.load)
  ret void
}
*** IR Dump After TailCallElimPass on _QFPomp_subroutine ***
; Function Attrs: nounwind
define void @_QFPomp_subroutine(ptr %0, ptr nocapture writeonly %1, ptr nest %2) local_unnamed_addr #2 {
entry:
  %structArg = alloca { ptr, ptr, ptr, ptr, ptr }, align 8
  %3 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %4 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %5 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %.fca.1.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 1
  %.fca.2.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 2
  %.fca.3.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 3
  %.fca.4.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 4
  %.fca.5.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 5
  %.fca.6.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 6
  %.fca.7.0.0.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 0
  %.fca.7.0.1.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 1
  %.fca.7.0.2.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 2
  %6 = load i32, ptr %0, align 4, !tbaa !4
  %7 = tail call i32 @llvm.smax.i32(i32 %6, i32 0)
  %8 = zext i32 %7 to i64
  %9 = shl nuw nsw i64 %8, 3
  %10 = tail call ptr @malloc(i64 %9)
  store ptr %10, ptr %5, align 8, !tbaa !8
  store i64 8, ptr %.fca.1.gep, align 8, !tbaa !8
  store i32 20180515, ptr %.fca.2.gep, align 8, !tbaa !8
  store i8 1, ptr %.fca.3.gep, align 4, !tbaa !8
  store i8 28, ptr %.fca.4.gep, align 1, !tbaa !8
  store i8 2, ptr %.fca.5.gep, align 2, !tbaa !8
  store i8 0, ptr %.fca.6.gep, align 1, !tbaa !8
  store i64 1, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  store i64 %8, ptr %.fca.7.0.1.gep, align 8, !tbaa !8
  store i64 8, ptr %.fca.7.0.2.gep, align 8, !tbaa !8
  %omp_global_thread_num = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %0, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %5, ptr %gep_5, align 8
  %gep_6 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 2
  store ptr %4, ptr %gep_6, align 8
  %gep_7 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 3
  store ptr %3, ptr %gep_7, align 8
  %gep_8 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 4
  store ptr %2, ptr %gep_8, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QFPomp_subroutine..omp_par, ptr nonnull %structArg)
  %.fca.0.load = load ptr, ptr %5, align 8, !tbaa !8
  %.fca.7.0.0.load = load i64, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  %11 = sub i64 1, %.fca.7.0.0.load
  %12 = getelementptr double, ptr %.fca.0.load, i64 %11
  %13 = load double, ptr %12, align 8, !tbaa !4
  %14 = load i32, ptr %0, align 4, !tbaa !4
  %15 = sext i32 %14 to i64
  %16 = sub i64 %15, %.fca.7.0.0.load
  %17 = getelementptr double, ptr %.fca.0.load, i64 %16
  %18 = load double, ptr %17, align 8, !tbaa !4
  %19 = fadd contract double %13, %18
  store double %19, ptr %1, align 8, !tbaa !4
  call void @free(ptr %.fca.0.load)
  ret void
}
*** IR Dump After SimplifyCFGPass on _QFPomp_subroutine ***
; Function Attrs: nounwind
define void @_QFPomp_subroutine(ptr %0, ptr nocapture writeonly %1, ptr nest %2) local_unnamed_addr #2 {
entry:
  %structArg = alloca { ptr, ptr, ptr, ptr, ptr }, align 8
  %3 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %4 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %5 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %.fca.1.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 1
  %.fca.2.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 2
  %.fca.3.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 3
  %.fca.4.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 4
  %.fca.5.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 5
  %.fca.6.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 6
  %.fca.7.0.0.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 0
  %.fca.7.0.1.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 1
  %.fca.7.0.2.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 2
  %6 = load i32, ptr %0, align 4, !tbaa !4
  %7 = tail call i32 @llvm.smax.i32(i32 %6, i32 0)
  %8 = zext i32 %7 to i64
  %9 = shl nuw nsw i64 %8, 3
  %10 = tail call ptr @malloc(i64 %9)
  store ptr %10, ptr %5, align 8, !tbaa !8
  store i64 8, ptr %.fca.1.gep, align 8, !tbaa !8
  store i32 20180515, ptr %.fca.2.gep, align 8, !tbaa !8
  store i8 1, ptr %.fca.3.gep, align 4, !tbaa !8
  store i8 28, ptr %.fca.4.gep, align 1, !tbaa !8
  store i8 2, ptr %.fca.5.gep, align 2, !tbaa !8
  store i8 0, ptr %.fca.6.gep, align 1, !tbaa !8
  store i64 1, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  store i64 %8, ptr %.fca.7.0.1.gep, align 8, !tbaa !8
  store i64 8, ptr %.fca.7.0.2.gep, align 8, !tbaa !8
  %omp_global_thread_num = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %0, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %5, ptr %gep_5, align 8
  %gep_6 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 2
  store ptr %4, ptr %gep_6, align 8
  %gep_7 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 3
  store ptr %3, ptr %gep_7, align 8
  %gep_8 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 4
  store ptr %2, ptr %gep_8, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QFPomp_subroutine..omp_par, ptr nonnull %structArg)
  %.fca.0.load = load ptr, ptr %5, align 8, !tbaa !8
  %.fca.7.0.0.load = load i64, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  %11 = sub i64 1, %.fca.7.0.0.load
  %12 = getelementptr double, ptr %.fca.0.load, i64 %11
  %13 = load double, ptr %12, align 8, !tbaa !4
  %14 = load i32, ptr %0, align 4, !tbaa !4
  %15 = sext i32 %14 to i64
  %16 = sub i64 %15, %.fca.7.0.0.load
  %17 = getelementptr double, ptr %.fca.0.load, i64 %16
  %18 = load double, ptr %17, align 8, !tbaa !4
  %19 = fadd contract double %13, %18
  store double %19, ptr %1, align 8, !tbaa !4
  call void @free(ptr %.fca.0.load)
  ret void
}
*** IR Dump After Float2IntPass on _QFPomp_subroutine..omp_par ***
; Function Attrs: norecurse nounwind
define internal void @_QFPomp_subroutine..omp_par(ptr noalias nocapture readnone %tid.addr, ptr noalias nocapture readnone %zero.addr, ptr nocapture readonly %0) #3 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %gep_3 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 2
  %loadgep_4 = load ptr, ptr %gep_3, align 8
  %gep_5 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 3
  %loadgep_6 = load ptr, ptr %gep_5, align 8
  %gep_7 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 4
  %loadgep_8 = load ptr, ptr %gep_7, align 8
  %1 = tail call i32 @omp_get_thread_num()
  %2 = tail call i32 @omp_get_num_threads()
  %3 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %4 = sdiv i32 %3, %2
  %5 = mul i32 %4, %1
  %6 = add i32 %5, 1
  %7 = add i32 %2, -1
  %8 = icmp eq i32 %1, %7
  %9 = add i32 %6, %4
  %spec.select = select i1 %8, i32 %3, i32 %9
  %.unpack = load ptr, ptr %loadgep_2, align 8, !tbaa !8
  %.elt14 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  %.unpack15 = load i64, ptr %.elt14, align 8, !tbaa !8
  %.elt16 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  %.unpack17 = load i32, ptr %.elt16, align 8, !tbaa !8
  %.elt18 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  %.unpack19 = load i8, ptr %.elt18, align 4, !tbaa !8
  %.elt20 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  %.unpack21 = load i8, ptr %.elt20, align 1, !tbaa !8
  %.elt22 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  %.unpack23 = load i8, ptr %.elt22, align 2, !tbaa !8
  %.elt24 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  %.unpack25 = load i8, ptr %.elt24, align 1, !tbaa !8
  %.elt26 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  %.unpack27.unpack.unpack = load i64, ptr %.elt26, align 8, !tbaa !8
  %.unpack27.unpack.elt29 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  %.unpack27.unpack.unpack30 = load i64, ptr %.unpack27.unpack.elt29, align 8, !tbaa !8
  %.unpack27.unpack.elt31 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  %.unpack27.unpack.unpack32 = load i64, ptr %.unpack27.unpack.elt31, align 8, !tbaa !8
  store ptr %.unpack, ptr %loadgep_4, align 8, !tbaa !8
  %loadgep_4.repack34 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 1
  store i64 %.unpack15, ptr %loadgep_4.repack34, align 8, !tbaa !8
  %loadgep_4.repack36 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 2
  store i32 %.unpack17, ptr %loadgep_4.repack36, align 8, !tbaa !8
  %loadgep_4.repack38 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 3
  store i8 %.unpack19, ptr %loadgep_4.repack38, align 4, !tbaa !8
  %loadgep_4.repack40 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 4
  store i8 %.unpack21, ptr %loadgep_4.repack40, align 1, !tbaa !8
  %loadgep_4.repack42 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 5
  store i8 %.unpack23, ptr %loadgep_4.repack42, align 2, !tbaa !8
  %loadgep_4.repack44 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 6
  store i8 %.unpack25, ptr %loadgep_4.repack44, align 1, !tbaa !8
  %loadgep_4.repack46 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7
  store i64 %.unpack27.unpack.unpack, ptr %loadgep_4.repack46, align 8, !tbaa !8
  %loadgep_4.repack46.repack48 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack27.unpack.unpack30, ptr %loadgep_4.repack46.repack48, align 8, !tbaa !8
  %loadgep_4.repack46.repack50 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 2
  store i64 %.unpack27.unpack.unpack32, ptr %loadgep_4.repack46.repack50, align 8, !tbaa !8
  %10 = icmp eq i64 %.unpack27.unpack.unpack30, 0
  %11 = select i1 %10, i64 1, i64 %.unpack27.unpack.unpack
  store ptr %.unpack, ptr %loadgep_6, align 8, !tbaa !8
  %loadgep_6.repack52 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 1
  store i64 8, ptr %loadgep_6.repack52, align 8, !tbaa !8
  %loadgep_6.repack54 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 2
  store i32 20180515, ptr %loadgep_6.repack54, align 8, !tbaa !8
  %loadgep_6.repack56 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 3
  store i8 1, ptr %loadgep_6.repack56, align 4, !tbaa !8
  %loadgep_6.repack58 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 4
  store i8 28, ptr %loadgep_6.repack58, align 1, !tbaa !8
  %loadgep_6.repack60 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 5
  store i8 0, ptr %loadgep_6.repack60, align 2, !tbaa !8
  %loadgep_6.repack62 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 6
  store i8 0, ptr %loadgep_6.repack62, align 1, !tbaa !8
  %loadgep_6.repack64 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7
  store i64 %11, ptr %loadgep_6.repack64, align 8, !tbaa !8
  %loadgep_6.repack64.repack66 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack27.unpack.unpack30, ptr %loadgep_6.repack64.repack66, align 8, !tbaa !8
  %loadgep_6.repack64.repack68 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7, i64 0, i64 2
  store i64 8, ptr %loadgep_6.repack64.repack68, align 8, !tbaa !8
  %12 = load ptr, ptr %loadgep_8, align 8, !tbaa !4
  %13 = getelementptr { ptr, ptr }, ptr %loadgep_8, i64 0, i32 1
  %14 = load ptr, ptr %13, align 8, !tbaa !4
  %15 = sext i32 %6 to i64
  %16 = sext i32 %spec.select to i64
  %reass.sub9.i = sub nsw i64 %16, %15
  %17 = icmp sgt i64 %reass.sub9.i, -1
  br i1 %17, label %.lr.ph8.preheader.i, label %_QFPloop.exit

.lr.ph8.preheader.i:                              ; preds = %omp.par.entry
  %18 = add nuw nsw i64 %reass.sub9.i, 1
  br label %.lr.ph8.i

.lr.ph8.i:                                        ; preds = %.lr.ph8.i, %.lr.ph8.preheader.i
  %19 = phi i64 [ %29, %.lr.ph8.i ], [ %18, %.lr.ph8.preheader.i ]
  %20 = phi i32 [ %28, %.lr.ph8.i ], [ %6, %.lr.ph8.preheader.i ]
  %21 = load i32, ptr %12, align 4, !tbaa !4
  %22 = sitofp i32 %21 to float
  %23 = fdiv contract float 1.000000e+00, %22
  %24 = fpext float %23 to double
  %25 = sext i32 %20 to i64
  %26 = add nsw i64 %25, -1
  %27 = getelementptr double, ptr %.unpack, i64 %26
  store double %24, ptr %27, align 8, !tbaa !4
  store double %24, ptr %14, align 8, !tbaa !4
  %28 = add i32 %20, 1
  %29 = add nsw i64 %19, -1
  %30 = icmp ugt i64 %19, 1
  br i1 %30, label %.lr.ph8.i, label %_QFPloop.exit

_QFPloop.exit:                                    ; preds = %.lr.ph8.i, %omp.par.entry
  ret void
}
*** IR Dump After LowerConstantIntrinsicsPass on _QFPomp_subroutine..omp_par ***
; Function Attrs: norecurse nounwind
define internal void @_QFPomp_subroutine..omp_par(ptr noalias nocapture readnone %tid.addr, ptr noalias nocapture readnone %zero.addr, ptr nocapture readonly %0) #3 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %gep_3 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 2
  %loadgep_4 = load ptr, ptr %gep_3, align 8
  %gep_5 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 3
  %loadgep_6 = load ptr, ptr %gep_5, align 8
  %gep_7 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 4
  %loadgep_8 = load ptr, ptr %gep_7, align 8
  %1 = tail call i32 @omp_get_thread_num()
  %2 = tail call i32 @omp_get_num_threads()
  %3 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %4 = sdiv i32 %3, %2
  %5 = mul i32 %4, %1
  %6 = add i32 %5, 1
  %7 = add i32 %2, -1
  %8 = icmp eq i32 %1, %7
  %9 = add i32 %6, %4
  %spec.select = select i1 %8, i32 %3, i32 %9
  %.unpack = load ptr, ptr %loadgep_2, align 8, !tbaa !8
  %.elt14 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  %.unpack15 = load i64, ptr %.elt14, align 8, !tbaa !8
  %.elt16 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  %.unpack17 = load i32, ptr %.elt16, align 8, !tbaa !8
  %.elt18 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  %.unpack19 = load i8, ptr %.elt18, align 4, !tbaa !8
  %.elt20 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  %.unpack21 = load i8, ptr %.elt20, align 1, !tbaa !8
  %.elt22 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  %.unpack23 = load i8, ptr %.elt22, align 2, !tbaa !8
  %.elt24 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  %.unpack25 = load i8, ptr %.elt24, align 1, !tbaa !8
  %.elt26 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  %.unpack27.unpack.unpack = load i64, ptr %.elt26, align 8, !tbaa !8
  %.unpack27.unpack.elt29 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  %.unpack27.unpack.unpack30 = load i64, ptr %.unpack27.unpack.elt29, align 8, !tbaa !8
  %.unpack27.unpack.elt31 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  %.unpack27.unpack.unpack32 = load i64, ptr %.unpack27.unpack.elt31, align 8, !tbaa !8
  store ptr %.unpack, ptr %loadgep_4, align 8, !tbaa !8
  %loadgep_4.repack34 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 1
  store i64 %.unpack15, ptr %loadgep_4.repack34, align 8, !tbaa !8
  %loadgep_4.repack36 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 2
  store i32 %.unpack17, ptr %loadgep_4.repack36, align 8, !tbaa !8
  %loadgep_4.repack38 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 3
  store i8 %.unpack19, ptr %loadgep_4.repack38, align 4, !tbaa !8
  %loadgep_4.repack40 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 4
  store i8 %.unpack21, ptr %loadgep_4.repack40, align 1, !tbaa !8
  %loadgep_4.repack42 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 5
  store i8 %.unpack23, ptr %loadgep_4.repack42, align 2, !tbaa !8
  %loadgep_4.repack44 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 6
  store i8 %.unpack25, ptr %loadgep_4.repack44, align 1, !tbaa !8
  %loadgep_4.repack46 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7
  store i64 %.unpack27.unpack.unpack, ptr %loadgep_4.repack46, align 8, !tbaa !8
  %loadgep_4.repack46.repack48 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack27.unpack.unpack30, ptr %loadgep_4.repack46.repack48, align 8, !tbaa !8
  %loadgep_4.repack46.repack50 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 2
  store i64 %.unpack27.unpack.unpack32, ptr %loadgep_4.repack46.repack50, align 8, !tbaa !8
  %10 = icmp eq i64 %.unpack27.unpack.unpack30, 0
  %11 = select i1 %10, i64 1, i64 %.unpack27.unpack.unpack
  store ptr %.unpack, ptr %loadgep_6, align 8, !tbaa !8
  %loadgep_6.repack52 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 1
  store i64 8, ptr %loadgep_6.repack52, align 8, !tbaa !8
  %loadgep_6.repack54 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 2
  store i32 20180515, ptr %loadgep_6.repack54, align 8, !tbaa !8
  %loadgep_6.repack56 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 3
  store i8 1, ptr %loadgep_6.repack56, align 4, !tbaa !8
  %loadgep_6.repack58 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 4
  store i8 28, ptr %loadgep_6.repack58, align 1, !tbaa !8
  %loadgep_6.repack60 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 5
  store i8 0, ptr %loadgep_6.repack60, align 2, !tbaa !8
  %loadgep_6.repack62 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 6
  store i8 0, ptr %loadgep_6.repack62, align 1, !tbaa !8
  %loadgep_6.repack64 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7
  store i64 %11, ptr %loadgep_6.repack64, align 8, !tbaa !8
  %loadgep_6.repack64.repack66 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack27.unpack.unpack30, ptr %loadgep_6.repack64.repack66, align 8, !tbaa !8
  %loadgep_6.repack64.repack68 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7, i64 0, i64 2
  store i64 8, ptr %loadgep_6.repack64.repack68, align 8, !tbaa !8
  %12 = load ptr, ptr %loadgep_8, align 8, !tbaa !4
  %13 = getelementptr { ptr, ptr }, ptr %loadgep_8, i64 0, i32 1
  %14 = load ptr, ptr %13, align 8, !tbaa !4
  %15 = sext i32 %6 to i64
  %16 = sext i32 %spec.select to i64
  %reass.sub9.i = sub nsw i64 %16, %15
  %17 = icmp sgt i64 %reass.sub9.i, -1
  br i1 %17, label %.lr.ph8.preheader.i, label %_QFPloop.exit

.lr.ph8.preheader.i:                              ; preds = %omp.par.entry
  %18 = add nuw nsw i64 %reass.sub9.i, 1
  br label %.lr.ph8.i

.lr.ph8.i:                                        ; preds = %.lr.ph8.i, %.lr.ph8.preheader.i
  %19 = phi i64 [ %29, %.lr.ph8.i ], [ %18, %.lr.ph8.preheader.i ]
  %20 = phi i32 [ %28, %.lr.ph8.i ], [ %6, %.lr.ph8.preheader.i ]
  %21 = load i32, ptr %12, align 4, !tbaa !4
  %22 = sitofp i32 %21 to float
  %23 = fdiv contract float 1.000000e+00, %22
  %24 = fpext float %23 to double
  %25 = sext i32 %20 to i64
  %26 = add nsw i64 %25, -1
  %27 = getelementptr double, ptr %.unpack, i64 %26
  store double %24, ptr %27, align 8, !tbaa !4
  store double %24, ptr %14, align 8, !tbaa !4
  %28 = add i32 %20, 1
  %29 = add nsw i64 %19, -1
  %30 = icmp ugt i64 %19, 1
  br i1 %30, label %.lr.ph8.i, label %_QFPloop.exit

_QFPloop.exit:                                    ; preds = %.lr.ph8.i, %omp.par.entry
  ret void
}
*** IR Dump After ControlHeightReductionPass on _QFPomp_subroutine..omp_par ***
; Function Attrs: norecurse nounwind
define internal void @_QFPomp_subroutine..omp_par(ptr noalias nocapture readnone %tid.addr, ptr noalias nocapture readnone %zero.addr, ptr nocapture readonly %0) #3 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %gep_3 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 2
  %loadgep_4 = load ptr, ptr %gep_3, align 8
  %gep_5 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 3
  %loadgep_6 = load ptr, ptr %gep_5, align 8
  %gep_7 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 4
  %loadgep_8 = load ptr, ptr %gep_7, align 8
  %1 = tail call i32 @omp_get_thread_num()
  %2 = tail call i32 @omp_get_num_threads()
  %3 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %4 = sdiv i32 %3, %2
  %5 = mul i32 %4, %1
  %6 = add i32 %5, 1
  %7 = add i32 %2, -1
  %8 = icmp eq i32 %1, %7
  %9 = add i32 %6, %4
  %spec.select = select i1 %8, i32 %3, i32 %9
  %.unpack = load ptr, ptr %loadgep_2, align 8, !tbaa !8
  %.elt14 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  %.unpack15 = load i64, ptr %.elt14, align 8, !tbaa !8
  %.elt16 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  %.unpack17 = load i32, ptr %.elt16, align 8, !tbaa !8
  %.elt18 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  %.unpack19 = load i8, ptr %.elt18, align 4, !tbaa !8
  %.elt20 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  %.unpack21 = load i8, ptr %.elt20, align 1, !tbaa !8
  %.elt22 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  %.unpack23 = load i8, ptr %.elt22, align 2, !tbaa !8
  %.elt24 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  %.unpack25 = load i8, ptr %.elt24, align 1, !tbaa !8
  %.elt26 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  %.unpack27.unpack.unpack = load i64, ptr %.elt26, align 8, !tbaa !8
  %.unpack27.unpack.elt29 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  %.unpack27.unpack.unpack30 = load i64, ptr %.unpack27.unpack.elt29, align 8, !tbaa !8
  %.unpack27.unpack.elt31 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  %.unpack27.unpack.unpack32 = load i64, ptr %.unpack27.unpack.elt31, align 8, !tbaa !8
  store ptr %.unpack, ptr %loadgep_4, align 8, !tbaa !8
  %loadgep_4.repack34 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 1
  store i64 %.unpack15, ptr %loadgep_4.repack34, align 8, !tbaa !8
  %loadgep_4.repack36 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 2
  store i32 %.unpack17, ptr %loadgep_4.repack36, align 8, !tbaa !8
  %loadgep_4.repack38 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 3
  store i8 %.unpack19, ptr %loadgep_4.repack38, align 4, !tbaa !8
  %loadgep_4.repack40 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 4
  store i8 %.unpack21, ptr %loadgep_4.repack40, align 1, !tbaa !8
  %loadgep_4.repack42 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 5
  store i8 %.unpack23, ptr %loadgep_4.repack42, align 2, !tbaa !8
  %loadgep_4.repack44 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 6
  store i8 %.unpack25, ptr %loadgep_4.repack44, align 1, !tbaa !8
  %loadgep_4.repack46 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7
  store i64 %.unpack27.unpack.unpack, ptr %loadgep_4.repack46, align 8, !tbaa !8
  %loadgep_4.repack46.repack48 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack27.unpack.unpack30, ptr %loadgep_4.repack46.repack48, align 8, !tbaa !8
  %loadgep_4.repack46.repack50 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 2
  store i64 %.unpack27.unpack.unpack32, ptr %loadgep_4.repack46.repack50, align 8, !tbaa !8
  %10 = icmp eq i64 %.unpack27.unpack.unpack30, 0
  %11 = select i1 %10, i64 1, i64 %.unpack27.unpack.unpack
  store ptr %.unpack, ptr %loadgep_6, align 8, !tbaa !8
  %loadgep_6.repack52 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 1
  store i64 8, ptr %loadgep_6.repack52, align 8, !tbaa !8
  %loadgep_6.repack54 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 2
  store i32 20180515, ptr %loadgep_6.repack54, align 8, !tbaa !8
  %loadgep_6.repack56 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 3
  store i8 1, ptr %loadgep_6.repack56, align 4, !tbaa !8
  %loadgep_6.repack58 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 4
  store i8 28, ptr %loadgep_6.repack58, align 1, !tbaa !8
  %loadgep_6.repack60 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 5
  store i8 0, ptr %loadgep_6.repack60, align 2, !tbaa !8
  %loadgep_6.repack62 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 6
  store i8 0, ptr %loadgep_6.repack62, align 1, !tbaa !8
  %loadgep_6.repack64 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7
  store i64 %11, ptr %loadgep_6.repack64, align 8, !tbaa !8
  %loadgep_6.repack64.repack66 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack27.unpack.unpack30, ptr %loadgep_6.repack64.repack66, align 8, !tbaa !8
  %loadgep_6.repack64.repack68 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7, i64 0, i64 2
  store i64 8, ptr %loadgep_6.repack64.repack68, align 8, !tbaa !8
  %12 = load ptr, ptr %loadgep_8, align 8, !tbaa !4
  %13 = getelementptr { ptr, ptr }, ptr %loadgep_8, i64 0, i32 1
  %14 = load ptr, ptr %13, align 8, !tbaa !4
  %15 = sext i32 %6 to i64
  %16 = sext i32 %spec.select to i64
  %reass.sub9.i = sub nsw i64 %16, %15
  %17 = icmp sgt i64 %reass.sub9.i, -1
  br i1 %17, label %.lr.ph8.preheader.i, label %_QFPloop.exit

.lr.ph8.preheader.i:                              ; preds = %omp.par.entry
  %18 = add nuw nsw i64 %reass.sub9.i, 1
  br label %.lr.ph8.i

.lr.ph8.i:                                        ; preds = %.lr.ph8.i, %.lr.ph8.preheader.i
  %19 = phi i64 [ %29, %.lr.ph8.i ], [ %18, %.lr.ph8.preheader.i ]
  %20 = phi i32 [ %28, %.lr.ph8.i ], [ %6, %.lr.ph8.preheader.i ]
  %21 = load i32, ptr %12, align 4, !tbaa !4
  %22 = sitofp i32 %21 to float
  %23 = fdiv contract float 1.000000e+00, %22
  %24 = fpext float %23 to double
  %25 = sext i32 %20 to i64
  %26 = add nsw i64 %25, -1
  %27 = getelementptr double, ptr %.unpack, i64 %26
  store double %24, ptr %27, align 8, !tbaa !4
  store double %24, ptr %14, align 8, !tbaa !4
  %28 = add i32 %20, 1
  %29 = add nsw i64 %19, -1
  %30 = icmp ugt i64 %19, 1
  br i1 %30, label %.lr.ph8.i, label %_QFPloop.exit

_QFPloop.exit:                                    ; preds = %.lr.ph8.i, %omp.par.entry
  ret void
}
*** IR Dump After LoopSimplifyPass on _QFPomp_subroutine..omp_par ***
; Function Attrs: norecurse nounwind
define internal void @_QFPomp_subroutine..omp_par(ptr noalias nocapture readnone %tid.addr, ptr noalias nocapture readnone %zero.addr, ptr nocapture readonly %0) #3 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %gep_3 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 2
  %loadgep_4 = load ptr, ptr %gep_3, align 8
  %gep_5 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 3
  %loadgep_6 = load ptr, ptr %gep_5, align 8
  %gep_7 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 4
  %loadgep_8 = load ptr, ptr %gep_7, align 8
  %1 = tail call i32 @omp_get_thread_num()
  %2 = tail call i32 @omp_get_num_threads()
  %3 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %4 = sdiv i32 %3, %2
  %5 = mul i32 %4, %1
  %6 = add i32 %5, 1
  %7 = add i32 %2, -1
  %8 = icmp eq i32 %1, %7
  %9 = add i32 %6, %4
  %spec.select = select i1 %8, i32 %3, i32 %9
  %.unpack = load ptr, ptr %loadgep_2, align 8, !tbaa !8
  %.elt14 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  %.unpack15 = load i64, ptr %.elt14, align 8, !tbaa !8
  %.elt16 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  %.unpack17 = load i32, ptr %.elt16, align 8, !tbaa !8
  %.elt18 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  %.unpack19 = load i8, ptr %.elt18, align 4, !tbaa !8
  %.elt20 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  %.unpack21 = load i8, ptr %.elt20, align 1, !tbaa !8
  %.elt22 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  %.unpack23 = load i8, ptr %.elt22, align 2, !tbaa !8
  %.elt24 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  %.unpack25 = load i8, ptr %.elt24, align 1, !tbaa !8
  %.elt26 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  %.unpack27.unpack.unpack = load i64, ptr %.elt26, align 8, !tbaa !8
  %.unpack27.unpack.elt29 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  %.unpack27.unpack.unpack30 = load i64, ptr %.unpack27.unpack.elt29, align 8, !tbaa !8
  %.unpack27.unpack.elt31 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  %.unpack27.unpack.unpack32 = load i64, ptr %.unpack27.unpack.elt31, align 8, !tbaa !8
  store ptr %.unpack, ptr %loadgep_4, align 8, !tbaa !8
  %loadgep_4.repack34 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 1
  store i64 %.unpack15, ptr %loadgep_4.repack34, align 8, !tbaa !8
  %loadgep_4.repack36 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 2
  store i32 %.unpack17, ptr %loadgep_4.repack36, align 8, !tbaa !8
  %loadgep_4.repack38 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 3
  store i8 %.unpack19, ptr %loadgep_4.repack38, align 4, !tbaa !8
  %loadgep_4.repack40 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 4
  store i8 %.unpack21, ptr %loadgep_4.repack40, align 1, !tbaa !8
  %loadgep_4.repack42 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 5
  store i8 %.unpack23, ptr %loadgep_4.repack42, align 2, !tbaa !8
  %loadgep_4.repack44 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 6
  store i8 %.unpack25, ptr %loadgep_4.repack44, align 1, !tbaa !8
  %loadgep_4.repack46 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7
  store i64 %.unpack27.unpack.unpack, ptr %loadgep_4.repack46, align 8, !tbaa !8
  %loadgep_4.repack46.repack48 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack27.unpack.unpack30, ptr %loadgep_4.repack46.repack48, align 8, !tbaa !8
  %loadgep_4.repack46.repack50 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 2
  store i64 %.unpack27.unpack.unpack32, ptr %loadgep_4.repack46.repack50, align 8, !tbaa !8
  %10 = icmp eq i64 %.unpack27.unpack.unpack30, 0
  %11 = select i1 %10, i64 1, i64 %.unpack27.unpack.unpack
  store ptr %.unpack, ptr %loadgep_6, align 8, !tbaa !8
  %loadgep_6.repack52 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 1
  store i64 8, ptr %loadgep_6.repack52, align 8, !tbaa !8
  %loadgep_6.repack54 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 2
  store i32 20180515, ptr %loadgep_6.repack54, align 8, !tbaa !8
  %loadgep_6.repack56 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 3
  store i8 1, ptr %loadgep_6.repack56, align 4, !tbaa !8
  %loadgep_6.repack58 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 4
  store i8 28, ptr %loadgep_6.repack58, align 1, !tbaa !8
  %loadgep_6.repack60 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 5
  store i8 0, ptr %loadgep_6.repack60, align 2, !tbaa !8
  %loadgep_6.repack62 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 6
  store i8 0, ptr %loadgep_6.repack62, align 1, !tbaa !8
  %loadgep_6.repack64 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7
  store i64 %11, ptr %loadgep_6.repack64, align 8, !tbaa !8
  %loadgep_6.repack64.repack66 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack27.unpack.unpack30, ptr %loadgep_6.repack64.repack66, align 8, !tbaa !8
  %loadgep_6.repack64.repack68 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7, i64 0, i64 2
  store i64 8, ptr %loadgep_6.repack64.repack68, align 8, !tbaa !8
  %12 = load ptr, ptr %loadgep_8, align 8, !tbaa !4
  %13 = getelementptr { ptr, ptr }, ptr %loadgep_8, i64 0, i32 1
  %14 = load ptr, ptr %13, align 8, !tbaa !4
  %15 = sext i32 %6 to i64
  %16 = sext i32 %spec.select to i64
  %reass.sub9.i = sub nsw i64 %16, %15
  %17 = icmp sgt i64 %reass.sub9.i, -1
  br i1 %17, label %.lr.ph8.preheader.i, label %_QFPloop.exit

.lr.ph8.preheader.i:                              ; preds = %omp.par.entry
  %18 = add nuw nsw i64 %reass.sub9.i, 1
  br label %.lr.ph8.i

.lr.ph8.i:                                        ; preds = %.lr.ph8.i, %.lr.ph8.preheader.i
  %19 = phi i64 [ %29, %.lr.ph8.i ], [ %18, %.lr.ph8.preheader.i ]
  %20 = phi i32 [ %28, %.lr.ph8.i ], [ %6, %.lr.ph8.preheader.i ]
  %21 = load i32, ptr %12, align 4, !tbaa !4
  %22 = sitofp i32 %21 to float
  %23 = fdiv contract float 1.000000e+00, %22
  %24 = fpext float %23 to double
  %25 = sext i32 %20 to i64
  %26 = add nsw i64 %25, -1
  %27 = getelementptr double, ptr %.unpack, i64 %26
  store double %24, ptr %27, align 8, !tbaa !4
  store double %24, ptr %14, align 8, !tbaa !4
  %28 = add i32 %20, 1
  %29 = add nsw i64 %19, -1
  %30 = icmp ugt i64 %19, 1
  br i1 %30, label %.lr.ph8.i, label %_QFPloop.exit.loopexit

_QFPloop.exit.loopexit:                           ; preds = %.lr.ph8.i
  br label %_QFPloop.exit

_QFPloop.exit:                                    ; preds = %_QFPloop.exit.loopexit, %omp.par.entry
  ret void
}
*** IR Dump After LCSSAPass on _QFPomp_subroutine..omp_par ***
; Function Attrs: norecurse nounwind
define internal void @_QFPomp_subroutine..omp_par(ptr noalias nocapture readnone %tid.addr, ptr noalias nocapture readnone %zero.addr, ptr nocapture readonly %0) #3 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %gep_3 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 2
  %loadgep_4 = load ptr, ptr %gep_3, align 8
  %gep_5 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 3
  %loadgep_6 = load ptr, ptr %gep_5, align 8
  %gep_7 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 4
  %loadgep_8 = load ptr, ptr %gep_7, align 8
  %1 = tail call i32 @omp_get_thread_num()
  %2 = tail call i32 @omp_get_num_threads()
  %3 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %4 = sdiv i32 %3, %2
  %5 = mul i32 %4, %1
  %6 = add i32 %5, 1
  %7 = add i32 %2, -1
  %8 = icmp eq i32 %1, %7
  %9 = add i32 %6, %4
  %spec.select = select i1 %8, i32 %3, i32 %9
  %.unpack = load ptr, ptr %loadgep_2, align 8, !tbaa !8
  %.elt14 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  %.unpack15 = load i64, ptr %.elt14, align 8, !tbaa !8
  %.elt16 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  %.unpack17 = load i32, ptr %.elt16, align 8, !tbaa !8
  %.elt18 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  %.unpack19 = load i8, ptr %.elt18, align 4, !tbaa !8
  %.elt20 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  %.unpack21 = load i8, ptr %.elt20, align 1, !tbaa !8
  %.elt22 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  %.unpack23 = load i8, ptr %.elt22, align 2, !tbaa !8
  %.elt24 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  %.unpack25 = load i8, ptr %.elt24, align 1, !tbaa !8
  %.elt26 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  %.unpack27.unpack.unpack = load i64, ptr %.elt26, align 8, !tbaa !8
  %.unpack27.unpack.elt29 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  %.unpack27.unpack.unpack30 = load i64, ptr %.unpack27.unpack.elt29, align 8, !tbaa !8
  %.unpack27.unpack.elt31 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  %.unpack27.unpack.unpack32 = load i64, ptr %.unpack27.unpack.elt31, align 8, !tbaa !8
  store ptr %.unpack, ptr %loadgep_4, align 8, !tbaa !8
  %loadgep_4.repack34 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 1
  store i64 %.unpack15, ptr %loadgep_4.repack34, align 8, !tbaa !8
  %loadgep_4.repack36 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 2
  store i32 %.unpack17, ptr %loadgep_4.repack36, align 8, !tbaa !8
  %loadgep_4.repack38 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 3
  store i8 %.unpack19, ptr %loadgep_4.repack38, align 4, !tbaa !8
  %loadgep_4.repack40 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 4
  store i8 %.unpack21, ptr %loadgep_4.repack40, align 1, !tbaa !8
  %loadgep_4.repack42 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 5
  store i8 %.unpack23, ptr %loadgep_4.repack42, align 2, !tbaa !8
  %loadgep_4.repack44 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 6
  store i8 %.unpack25, ptr %loadgep_4.repack44, align 1, !tbaa !8
  %loadgep_4.repack46 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7
  store i64 %.unpack27.unpack.unpack, ptr %loadgep_4.repack46, align 8, !tbaa !8
  %loadgep_4.repack46.repack48 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack27.unpack.unpack30, ptr %loadgep_4.repack46.repack48, align 8, !tbaa !8
  %loadgep_4.repack46.repack50 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 2
  store i64 %.unpack27.unpack.unpack32, ptr %loadgep_4.repack46.repack50, align 8, !tbaa !8
  %10 = icmp eq i64 %.unpack27.unpack.unpack30, 0
  %11 = select i1 %10, i64 1, i64 %.unpack27.unpack.unpack
  store ptr %.unpack, ptr %loadgep_6, align 8, !tbaa !8
  %loadgep_6.repack52 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 1
  store i64 8, ptr %loadgep_6.repack52, align 8, !tbaa !8
  %loadgep_6.repack54 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 2
  store i32 20180515, ptr %loadgep_6.repack54, align 8, !tbaa !8
  %loadgep_6.repack56 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 3
  store i8 1, ptr %loadgep_6.repack56, align 4, !tbaa !8
  %loadgep_6.repack58 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 4
  store i8 28, ptr %loadgep_6.repack58, align 1, !tbaa !8
  %loadgep_6.repack60 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 5
  store i8 0, ptr %loadgep_6.repack60, align 2, !tbaa !8
  %loadgep_6.repack62 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 6
  store i8 0, ptr %loadgep_6.repack62, align 1, !tbaa !8
  %loadgep_6.repack64 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7
  store i64 %11, ptr %loadgep_6.repack64, align 8, !tbaa !8
  %loadgep_6.repack64.repack66 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack27.unpack.unpack30, ptr %loadgep_6.repack64.repack66, align 8, !tbaa !8
  %loadgep_6.repack64.repack68 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7, i64 0, i64 2
  store i64 8, ptr %loadgep_6.repack64.repack68, align 8, !tbaa !8
  %12 = load ptr, ptr %loadgep_8, align 8, !tbaa !4
  %13 = getelementptr { ptr, ptr }, ptr %loadgep_8, i64 0, i32 1
  %14 = load ptr, ptr %13, align 8, !tbaa !4
  %15 = sext i32 %6 to i64
  %16 = sext i32 %spec.select to i64
  %reass.sub9.i = sub nsw i64 %16, %15
  %17 = icmp sgt i64 %reass.sub9.i, -1
  br i1 %17, label %.lr.ph8.preheader.i, label %_QFPloop.exit

.lr.ph8.preheader.i:                              ; preds = %omp.par.entry
  %18 = add nuw nsw i64 %reass.sub9.i, 1
  br label %.lr.ph8.i

.lr.ph8.i:                                        ; preds = %.lr.ph8.i, %.lr.ph8.preheader.i
  %19 = phi i64 [ %29, %.lr.ph8.i ], [ %18, %.lr.ph8.preheader.i ]
  %20 = phi i32 [ %28, %.lr.ph8.i ], [ %6, %.lr.ph8.preheader.i ]
  %21 = load i32, ptr %12, align 4, !tbaa !4
  %22 = sitofp i32 %21 to float
  %23 = fdiv contract float 1.000000e+00, %22
  %24 = fpext float %23 to double
  %25 = sext i32 %20 to i64
  %26 = add nsw i64 %25, -1
  %27 = getelementptr double, ptr %.unpack, i64 %26
  store double %24, ptr %27, align 8, !tbaa !4
  store double %24, ptr %14, align 8, !tbaa !4
  %28 = add i32 %20, 1
  %29 = add nsw i64 %19, -1
  %30 = icmp ugt i64 %19, 1
  br i1 %30, label %.lr.ph8.i, label %_QFPloop.exit.loopexit

_QFPloop.exit.loopexit:                           ; preds = %.lr.ph8.i
  br label %_QFPloop.exit

_QFPloop.exit:                                    ; preds = %_QFPloop.exit.loopexit, %omp.par.entry
  ret void
}
*** IR Dump After LoopRotatePass on .lr.ph8.i ***

; Preheader:
.lr.ph8.preheader.i:                              ; preds = %omp.par.entry
  %18 = add nuw nsw i64 %reass.sub9.i, 1
  br label %.lr.ph8.i

; Loop:
.lr.ph8.i:                                        ; preds = %.lr.ph8.i, %.lr.ph8.preheader.i
  %19 = phi i64 [ %29, %.lr.ph8.i ], [ %18, %.lr.ph8.preheader.i ]
  %20 = phi i32 [ %28, %.lr.ph8.i ], [ %6, %.lr.ph8.preheader.i ]
  %21 = load i32, ptr %12, align 4, !tbaa !4
  %22 = sitofp i32 %21 to float
  %23 = fdiv contract float 1.000000e+00, %22
  %24 = fpext float %23 to double
  %25 = sext i32 %20 to i64
  %26 = add nsw i64 %25, -1
  %27 = getelementptr double, ptr %.unpack, i64 %26
  store double %24, ptr %27, align 8, !tbaa !4
  store double %24, ptr %14, align 8, !tbaa !4
  %28 = add i32 %20, 1
  %29 = add nsw i64 %19, -1
  %30 = icmp ugt i64 %19, 1
  br i1 %30, label %.lr.ph8.i, label %_QFPloop.exit.loopexit

; Exit blocks
_QFPloop.exit.loopexit:                           ; preds = %.lr.ph8.i
  br label %_QFPloop.exit
*** IR Dump After LoopDeletionPass on .lr.ph8.i ***

; Preheader:
.lr.ph8.preheader.i:                              ; preds = %omp.par.entry
  %18 = add nuw nsw i64 %reass.sub9.i, 1
  br label %.lr.ph8.i

; Loop:
.lr.ph8.i:                                        ; preds = %.lr.ph8.i, %.lr.ph8.preheader.i
  %19 = phi i64 [ %29, %.lr.ph8.i ], [ %18, %.lr.ph8.preheader.i ]
  %20 = phi i32 [ %28, %.lr.ph8.i ], [ %6, %.lr.ph8.preheader.i ]
  %21 = load i32, ptr %12, align 4, !tbaa !4
  %22 = sitofp i32 %21 to float
  %23 = fdiv contract float 1.000000e+00, %22
  %24 = fpext float %23 to double
  %25 = sext i32 %20 to i64
  %26 = add nsw i64 %25, -1
  %27 = getelementptr double, ptr %.unpack, i64 %26
  store double %24, ptr %27, align 8, !tbaa !4
  store double %24, ptr %14, align 8, !tbaa !4
  %28 = add i32 %20, 1
  %29 = add nsw i64 %19, -1
  %30 = icmp ugt i64 %19, 1
  br i1 %30, label %.lr.ph8.i, label %_QFPloop.exit.loopexit

; Exit blocks
_QFPloop.exit.loopexit:                           ; preds = %.lr.ph8.i
  br label %_QFPloop.exit
*** IR Dump After LoopDistributePass on _QFPomp_subroutine..omp_par ***
; Function Attrs: norecurse nounwind
define internal void @_QFPomp_subroutine..omp_par(ptr noalias nocapture readnone %tid.addr, ptr noalias nocapture readnone %zero.addr, ptr nocapture readonly %0) #3 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %gep_3 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 2
  %loadgep_4 = load ptr, ptr %gep_3, align 8
  %gep_5 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 3
  %loadgep_6 = load ptr, ptr %gep_5, align 8
  %gep_7 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 4
  %loadgep_8 = load ptr, ptr %gep_7, align 8
  %1 = tail call i32 @omp_get_thread_num()
  %2 = tail call i32 @omp_get_num_threads()
  %3 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %4 = sdiv i32 %3, %2
  %5 = mul i32 %4, %1
  %6 = add i32 %5, 1
  %7 = add i32 %2, -1
  %8 = icmp eq i32 %1, %7
  %9 = add i32 %6, %4
  %spec.select = select i1 %8, i32 %3, i32 %9
  %.unpack = load ptr, ptr %loadgep_2, align 8, !tbaa !8
  %.elt14 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  %.unpack15 = load i64, ptr %.elt14, align 8, !tbaa !8
  %.elt16 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  %.unpack17 = load i32, ptr %.elt16, align 8, !tbaa !8
  %.elt18 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  %.unpack19 = load i8, ptr %.elt18, align 4, !tbaa !8
  %.elt20 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  %.unpack21 = load i8, ptr %.elt20, align 1, !tbaa !8
  %.elt22 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  %.unpack23 = load i8, ptr %.elt22, align 2, !tbaa !8
  %.elt24 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  %.unpack25 = load i8, ptr %.elt24, align 1, !tbaa !8
  %.elt26 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  %.unpack27.unpack.unpack = load i64, ptr %.elt26, align 8, !tbaa !8
  %.unpack27.unpack.elt29 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  %.unpack27.unpack.unpack30 = load i64, ptr %.unpack27.unpack.elt29, align 8, !tbaa !8
  %.unpack27.unpack.elt31 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  %.unpack27.unpack.unpack32 = load i64, ptr %.unpack27.unpack.elt31, align 8, !tbaa !8
  store ptr %.unpack, ptr %loadgep_4, align 8, !tbaa !8
  %loadgep_4.repack34 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 1
  store i64 %.unpack15, ptr %loadgep_4.repack34, align 8, !tbaa !8
  %loadgep_4.repack36 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 2
  store i32 %.unpack17, ptr %loadgep_4.repack36, align 8, !tbaa !8
  %loadgep_4.repack38 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 3
  store i8 %.unpack19, ptr %loadgep_4.repack38, align 4, !tbaa !8
  %loadgep_4.repack40 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 4
  store i8 %.unpack21, ptr %loadgep_4.repack40, align 1, !tbaa !8
  %loadgep_4.repack42 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 5
  store i8 %.unpack23, ptr %loadgep_4.repack42, align 2, !tbaa !8
  %loadgep_4.repack44 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 6
  store i8 %.unpack25, ptr %loadgep_4.repack44, align 1, !tbaa !8
  %loadgep_4.repack46 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7
  store i64 %.unpack27.unpack.unpack, ptr %loadgep_4.repack46, align 8, !tbaa !8
  %loadgep_4.repack46.repack48 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack27.unpack.unpack30, ptr %loadgep_4.repack46.repack48, align 8, !tbaa !8
  %loadgep_4.repack46.repack50 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 2
  store i64 %.unpack27.unpack.unpack32, ptr %loadgep_4.repack46.repack50, align 8, !tbaa !8
  %10 = icmp eq i64 %.unpack27.unpack.unpack30, 0
  %11 = select i1 %10, i64 1, i64 %.unpack27.unpack.unpack
  store ptr %.unpack, ptr %loadgep_6, align 8, !tbaa !8
  %loadgep_6.repack52 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 1
  store i64 8, ptr %loadgep_6.repack52, align 8, !tbaa !8
  %loadgep_6.repack54 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 2
  store i32 20180515, ptr %loadgep_6.repack54, align 8, !tbaa !8
  %loadgep_6.repack56 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 3
  store i8 1, ptr %loadgep_6.repack56, align 4, !tbaa !8
  %loadgep_6.repack58 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 4
  store i8 28, ptr %loadgep_6.repack58, align 1, !tbaa !8
  %loadgep_6.repack60 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 5
  store i8 0, ptr %loadgep_6.repack60, align 2, !tbaa !8
  %loadgep_6.repack62 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 6
  store i8 0, ptr %loadgep_6.repack62, align 1, !tbaa !8
  %loadgep_6.repack64 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7
  store i64 %11, ptr %loadgep_6.repack64, align 8, !tbaa !8
  %loadgep_6.repack64.repack66 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack27.unpack.unpack30, ptr %loadgep_6.repack64.repack66, align 8, !tbaa !8
  %loadgep_6.repack64.repack68 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7, i64 0, i64 2
  store i64 8, ptr %loadgep_6.repack64.repack68, align 8, !tbaa !8
  %12 = load ptr, ptr %loadgep_8, align 8, !tbaa !4
  %13 = getelementptr { ptr, ptr }, ptr %loadgep_8, i64 0, i32 1
  %14 = load ptr, ptr %13, align 8, !tbaa !4
  %15 = sext i32 %6 to i64
  %16 = sext i32 %spec.select to i64
  %reass.sub9.i = sub nsw i64 %16, %15
  %17 = icmp sgt i64 %reass.sub9.i, -1
  br i1 %17, label %.lr.ph8.preheader.i, label %_QFPloop.exit

.lr.ph8.preheader.i:                              ; preds = %omp.par.entry
  %18 = add nuw nsw i64 %reass.sub9.i, 1
  br label %.lr.ph8.i

.lr.ph8.i:                                        ; preds = %.lr.ph8.i, %.lr.ph8.preheader.i
  %19 = phi i64 [ %29, %.lr.ph8.i ], [ %18, %.lr.ph8.preheader.i ]
  %20 = phi i32 [ %28, %.lr.ph8.i ], [ %6, %.lr.ph8.preheader.i ]
  %21 = load i32, ptr %12, align 4, !tbaa !4
  %22 = sitofp i32 %21 to float
  %23 = fdiv contract float 1.000000e+00, %22
  %24 = fpext float %23 to double
  %25 = sext i32 %20 to i64
  %26 = add nsw i64 %25, -1
  %27 = getelementptr double, ptr %.unpack, i64 %26
  store double %24, ptr %27, align 8, !tbaa !4
  store double %24, ptr %14, align 8, !tbaa !4
  %28 = add i32 %20, 1
  %29 = add nsw i64 %19, -1
  %30 = icmp ugt i64 %19, 1
  br i1 %30, label %.lr.ph8.i, label %_QFPloop.exit.loopexit

_QFPloop.exit.loopexit:                           ; preds = %.lr.ph8.i
  br label %_QFPloop.exit

_QFPloop.exit:                                    ; preds = %_QFPloop.exit.loopexit, %omp.par.entry
  ret void
}
*** IR Dump After InjectTLIMappings on _QFPomp_subroutine..omp_par ***
; Function Attrs: norecurse nounwind
define internal void @_QFPomp_subroutine..omp_par(ptr noalias nocapture readnone %tid.addr, ptr noalias nocapture readnone %zero.addr, ptr nocapture readonly %0) #3 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %gep_3 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 2
  %loadgep_4 = load ptr, ptr %gep_3, align 8
  %gep_5 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 3
  %loadgep_6 = load ptr, ptr %gep_5, align 8
  %gep_7 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 4
  %loadgep_8 = load ptr, ptr %gep_7, align 8
  %1 = tail call i32 @omp_get_thread_num()
  %2 = tail call i32 @omp_get_num_threads()
  %3 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %4 = sdiv i32 %3, %2
  %5 = mul i32 %4, %1
  %6 = add i32 %5, 1
  %7 = add i32 %2, -1
  %8 = icmp eq i32 %1, %7
  %9 = add i32 %6, %4
  %spec.select = select i1 %8, i32 %3, i32 %9
  %.unpack = load ptr, ptr %loadgep_2, align 8, !tbaa !8
  %.elt14 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  %.unpack15 = load i64, ptr %.elt14, align 8, !tbaa !8
  %.elt16 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  %.unpack17 = load i32, ptr %.elt16, align 8, !tbaa !8
  %.elt18 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  %.unpack19 = load i8, ptr %.elt18, align 4, !tbaa !8
  %.elt20 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  %.unpack21 = load i8, ptr %.elt20, align 1, !tbaa !8
  %.elt22 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  %.unpack23 = load i8, ptr %.elt22, align 2, !tbaa !8
  %.elt24 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  %.unpack25 = load i8, ptr %.elt24, align 1, !tbaa !8
  %.elt26 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  %.unpack27.unpack.unpack = load i64, ptr %.elt26, align 8, !tbaa !8
  %.unpack27.unpack.elt29 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  %.unpack27.unpack.unpack30 = load i64, ptr %.unpack27.unpack.elt29, align 8, !tbaa !8
  %.unpack27.unpack.elt31 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  %.unpack27.unpack.unpack32 = load i64, ptr %.unpack27.unpack.elt31, align 8, !tbaa !8
  store ptr %.unpack, ptr %loadgep_4, align 8, !tbaa !8
  %loadgep_4.repack34 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 1
  store i64 %.unpack15, ptr %loadgep_4.repack34, align 8, !tbaa !8
  %loadgep_4.repack36 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 2
  store i32 %.unpack17, ptr %loadgep_4.repack36, align 8, !tbaa !8
  %loadgep_4.repack38 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 3
  store i8 %.unpack19, ptr %loadgep_4.repack38, align 4, !tbaa !8
  %loadgep_4.repack40 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 4
  store i8 %.unpack21, ptr %loadgep_4.repack40, align 1, !tbaa !8
  %loadgep_4.repack42 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 5
  store i8 %.unpack23, ptr %loadgep_4.repack42, align 2, !tbaa !8
  %loadgep_4.repack44 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 6
  store i8 %.unpack25, ptr %loadgep_4.repack44, align 1, !tbaa !8
  %loadgep_4.repack46 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7
  store i64 %.unpack27.unpack.unpack, ptr %loadgep_4.repack46, align 8, !tbaa !8
  %loadgep_4.repack46.repack48 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack27.unpack.unpack30, ptr %loadgep_4.repack46.repack48, align 8, !tbaa !8
  %loadgep_4.repack46.repack50 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 2
  store i64 %.unpack27.unpack.unpack32, ptr %loadgep_4.repack46.repack50, align 8, !tbaa !8
  %10 = icmp eq i64 %.unpack27.unpack.unpack30, 0
  %11 = select i1 %10, i64 1, i64 %.unpack27.unpack.unpack
  store ptr %.unpack, ptr %loadgep_6, align 8, !tbaa !8
  %loadgep_6.repack52 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 1
  store i64 8, ptr %loadgep_6.repack52, align 8, !tbaa !8
  %loadgep_6.repack54 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 2
  store i32 20180515, ptr %loadgep_6.repack54, align 8, !tbaa !8
  %loadgep_6.repack56 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 3
  store i8 1, ptr %loadgep_6.repack56, align 4, !tbaa !8
  %loadgep_6.repack58 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 4
  store i8 28, ptr %loadgep_6.repack58, align 1, !tbaa !8
  %loadgep_6.repack60 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 5
  store i8 0, ptr %loadgep_6.repack60, align 2, !tbaa !8
  %loadgep_6.repack62 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 6
  store i8 0, ptr %loadgep_6.repack62, align 1, !tbaa !8
  %loadgep_6.repack64 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7
  store i64 %11, ptr %loadgep_6.repack64, align 8, !tbaa !8
  %loadgep_6.repack64.repack66 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack27.unpack.unpack30, ptr %loadgep_6.repack64.repack66, align 8, !tbaa !8
  %loadgep_6.repack64.repack68 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7, i64 0, i64 2
  store i64 8, ptr %loadgep_6.repack64.repack68, align 8, !tbaa !8
  %12 = load ptr, ptr %loadgep_8, align 8, !tbaa !4
  %13 = getelementptr { ptr, ptr }, ptr %loadgep_8, i64 0, i32 1
  %14 = load ptr, ptr %13, align 8, !tbaa !4
  %15 = sext i32 %6 to i64
  %16 = sext i32 %spec.select to i64
  %reass.sub9.i = sub nsw i64 %16, %15
  %17 = icmp sgt i64 %reass.sub9.i, -1
  br i1 %17, label %.lr.ph8.preheader.i, label %_QFPloop.exit

.lr.ph8.preheader.i:                              ; preds = %omp.par.entry
  %18 = add nuw nsw i64 %reass.sub9.i, 1
  br label %.lr.ph8.i

.lr.ph8.i:                                        ; preds = %.lr.ph8.i, %.lr.ph8.preheader.i
  %19 = phi i64 [ %29, %.lr.ph8.i ], [ %18, %.lr.ph8.preheader.i ]
  %20 = phi i32 [ %28, %.lr.ph8.i ], [ %6, %.lr.ph8.preheader.i ]
  %21 = load i32, ptr %12, align 4, !tbaa !4
  %22 = sitofp i32 %21 to float
  %23 = fdiv contract float 1.000000e+00, %22
  %24 = fpext float %23 to double
  %25 = sext i32 %20 to i64
  %26 = add nsw i64 %25, -1
  %27 = getelementptr double, ptr %.unpack, i64 %26
  store double %24, ptr %27, align 8, !tbaa !4
  store double %24, ptr %14, align 8, !tbaa !4
  %28 = add i32 %20, 1
  %29 = add nsw i64 %19, -1
  %30 = icmp ugt i64 %19, 1
  br i1 %30, label %.lr.ph8.i, label %_QFPloop.exit.loopexit

_QFPloop.exit.loopexit:                           ; preds = %.lr.ph8.i
  br label %_QFPloop.exit

_QFPloop.exit:                                    ; preds = %_QFPloop.exit.loopexit, %omp.par.entry
  ret void
}
*** IR Dump After LoopVectorizePass on _QFPomp_subroutine..omp_par ***
; Function Attrs: norecurse nounwind
define internal void @_QFPomp_subroutine..omp_par(ptr noalias nocapture readnone %tid.addr, ptr noalias nocapture readnone %zero.addr, ptr nocapture readonly %0) #3 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %gep_3 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 2
  %loadgep_4 = load ptr, ptr %gep_3, align 8
  %gep_5 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 3
  %loadgep_6 = load ptr, ptr %gep_5, align 8
  %gep_7 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 4
  %loadgep_8 = load ptr, ptr %gep_7, align 8
  %1 = tail call i32 @omp_get_thread_num()
  %2 = tail call i32 @omp_get_num_threads()
  %3 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %4 = sdiv i32 %3, %2
  %5 = mul i32 %4, %1
  %6 = add i32 %5, 1
  %7 = add i32 %2, -1
  %8 = icmp eq i32 %1, %7
  %9 = add i32 %6, %4
  %spec.select = select i1 %8, i32 %3, i32 %9
  %.unpack = load ptr, ptr %loadgep_2, align 8, !tbaa !8
  %.elt14 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  %.unpack15 = load i64, ptr %.elt14, align 8, !tbaa !8
  %.elt16 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  %.unpack17 = load i32, ptr %.elt16, align 8, !tbaa !8
  %.elt18 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  %.unpack19 = load i8, ptr %.elt18, align 4, !tbaa !8
  %.elt20 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  %.unpack21 = load i8, ptr %.elt20, align 1, !tbaa !8
  %.elt22 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  %.unpack23 = load i8, ptr %.elt22, align 2, !tbaa !8
  %.elt24 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  %.unpack25 = load i8, ptr %.elt24, align 1, !tbaa !8
  %.elt26 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  %.unpack27.unpack.unpack = load i64, ptr %.elt26, align 8, !tbaa !8
  %.unpack27.unpack.elt29 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  %.unpack27.unpack.unpack30 = load i64, ptr %.unpack27.unpack.elt29, align 8, !tbaa !8
  %.unpack27.unpack.elt31 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  %.unpack27.unpack.unpack32 = load i64, ptr %.unpack27.unpack.elt31, align 8, !tbaa !8
  store ptr %.unpack, ptr %loadgep_4, align 8, !tbaa !8
  %loadgep_4.repack34 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 1
  store i64 %.unpack15, ptr %loadgep_4.repack34, align 8, !tbaa !8
  %loadgep_4.repack36 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 2
  store i32 %.unpack17, ptr %loadgep_4.repack36, align 8, !tbaa !8
  %loadgep_4.repack38 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 3
  store i8 %.unpack19, ptr %loadgep_4.repack38, align 4, !tbaa !8
  %loadgep_4.repack40 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 4
  store i8 %.unpack21, ptr %loadgep_4.repack40, align 1, !tbaa !8
  %loadgep_4.repack42 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 5
  store i8 %.unpack23, ptr %loadgep_4.repack42, align 2, !tbaa !8
  %loadgep_4.repack44 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 6
  store i8 %.unpack25, ptr %loadgep_4.repack44, align 1, !tbaa !8
  %loadgep_4.repack46 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7
  store i64 %.unpack27.unpack.unpack, ptr %loadgep_4.repack46, align 8, !tbaa !8
  %loadgep_4.repack46.repack48 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack27.unpack.unpack30, ptr %loadgep_4.repack46.repack48, align 8, !tbaa !8
  %loadgep_4.repack46.repack50 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 2
  store i64 %.unpack27.unpack.unpack32, ptr %loadgep_4.repack46.repack50, align 8, !tbaa !8
  %10 = icmp eq i64 %.unpack27.unpack.unpack30, 0
  %11 = select i1 %10, i64 1, i64 %.unpack27.unpack.unpack
  store ptr %.unpack, ptr %loadgep_6, align 8, !tbaa !8
  %loadgep_6.repack52 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 1
  store i64 8, ptr %loadgep_6.repack52, align 8, !tbaa !8
  %loadgep_6.repack54 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 2
  store i32 20180515, ptr %loadgep_6.repack54, align 8, !tbaa !8
  %loadgep_6.repack56 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 3
  store i8 1, ptr %loadgep_6.repack56, align 4, !tbaa !8
  %loadgep_6.repack58 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 4
  store i8 28, ptr %loadgep_6.repack58, align 1, !tbaa !8
  %loadgep_6.repack60 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 5
  store i8 0, ptr %loadgep_6.repack60, align 2, !tbaa !8
  %loadgep_6.repack62 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 6
  store i8 0, ptr %loadgep_6.repack62, align 1, !tbaa !8
  %loadgep_6.repack64 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7
  store i64 %11, ptr %loadgep_6.repack64, align 8, !tbaa !8
  %loadgep_6.repack64.repack66 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack27.unpack.unpack30, ptr %loadgep_6.repack64.repack66, align 8, !tbaa !8
  %loadgep_6.repack64.repack68 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7, i64 0, i64 2
  store i64 8, ptr %loadgep_6.repack64.repack68, align 8, !tbaa !8
  %12 = load ptr, ptr %loadgep_8, align 8, !tbaa !4
  %13 = getelementptr { ptr, ptr }, ptr %loadgep_8, i64 0, i32 1
  %14 = load ptr, ptr %13, align 8, !tbaa !4
  %15 = sext i32 %6 to i64
  %16 = sext i32 %spec.select to i64
  %reass.sub9.i = sub nsw i64 %16, %15
  %17 = icmp sgt i64 %reass.sub9.i, -1
  br i1 %17, label %.lr.ph8.preheader.i, label %_QFPloop.exit

.lr.ph8.preheader.i:                              ; preds = %omp.par.entry
  %18 = add i64 %reass.sub9.i, 1
  %19 = add i64 %16, 2
  %umin82 = call i64 @llvm.umin.i64(i64 %18, i64 1)
  %20 = sub i64 %19, %umin82
  %21 = sub i64 %20, %15
  %min.iters.check = icmp ult i64 %21, 8
  br i1 %min.iters.check, label %scalar.ph, label %vector.scevcheck

vector.scevcheck:                                 ; preds = %.lr.ph8.preheader.i
  %22 = add i64 %16, 1
  %umin = call i64 @llvm.umin.i64(i64 %18, i64 1)
  %23 = sub i64 %22, %umin
  %24 = sub i64 %23, %15
  %25 = trunc i64 %24 to i32
  %26 = add i32 %6, %25
  %27 = icmp slt i32 %26, %6
  %28 = icmp ugt i64 %24, 4294967295
  %29 = or i1 %27, %28
  br i1 %29, label %scalar.ph, label %vector.memcheck

vector.memcheck:                                  ; preds = %vector.scevcheck
  %scevgep = getelementptr i8, ptr %14, i64 8
  %scevgep71 = getelementptr i8, ptr %12, i64 4
  %30 = shl nsw i64 %15, 3
  %31 = add nsw i64 %30, -8
  %scevgep72 = getelementptr i8, ptr %.unpack, i64 %31
  %32 = shl nsw i64 %16, 3
  %33 = add i64 %32, 8
  %umin73 = call i64 @llvm.umin.i64(i64 %18, i64 1)
  %34 = shl nuw nsw i64 %umin73, 3
  %35 = sub i64 %33, %34
  %scevgep74 = getelementptr i8, ptr %.unpack, i64 %35
  %bound0 = icmp ult ptr %14, %scevgep71
  %bound1 = icmp ult ptr %12, %scevgep
  %found.conflict = and i1 %bound0, %bound1
  %bound075 = icmp ult ptr %14, %scevgep74
  %bound176 = icmp ult ptr %scevgep72, %scevgep
  %found.conflict77 = and i1 %bound075, %bound176
  %conflict.rdx = or i1 %found.conflict, %found.conflict77
  %bound078 = icmp ult ptr %12, %scevgep74
  %bound179 = icmp ult ptr %scevgep72, %scevgep71
  %found.conflict80 = and i1 %bound078, %bound179
  %conflict.rdx81 = or i1 %conflict.rdx, %found.conflict80
  br i1 %conflict.rdx81, label %scalar.ph, label %vector.ph

vector.ph:                                        ; preds = %vector.memcheck
  %n.mod.vf = urem i64 %21, 2
  %n.vec = sub i64 %21, %n.mod.vf
  %ind.end = sub i64 %18, %n.vec
  %.cast = trunc i64 %n.vec to i32
  %ind.end83 = add i32 %6, %.cast
  br label %vector.body

vector.body:                                      ; preds = %vector.body, %vector.ph
  %index = phi i64 [ 0, %vector.ph ], [ %index.next, %vector.body ]
  %.cast85 = trunc i64 %index to i32
  %offset.idx = add i32 %6, %.cast85
  %36 = add i32 %offset.idx, 0
  %37 = load i32, ptr %12, align 4, !tbaa !4, !alias.scope !10, !noalias !13
  %broadcast.splatinsert = insertelement <2 x i32> poison, i32 %37, i64 0
  %broadcast.splat = shufflevector <2 x i32> %broadcast.splatinsert, <2 x i32> poison, <2 x i32> zeroinitializer
  %38 = sitofp <2 x i32> %broadcast.splat to <2 x float>
  %39 = fdiv contract <2 x float> <float 1.000000e+00, float 1.000000e+00>, %38
  %40 = fpext <2 x float> %39 to <2 x double>
  %41 = sext i32 %36 to i64
  %42 = add nsw i64 %41, -1
  %43 = getelementptr double, ptr %.unpack, i64 %42
  %44 = getelementptr double, ptr %43, i32 0
  store <2 x double> %40, ptr %44, align 8, !tbaa !4, !alias.scope !13
  %45 = extractelement <2 x double> %40, i32 1
  store double %45, ptr %14, align 8, !tbaa !4, !alias.scope !15, !noalias !17
  %index.next = add nuw i64 %index, 2
  %46 = icmp eq i64 %index.next, %n.vec
  br i1 %46, label %middle.block, label %vector.body, !llvm.loop !18

middle.block:                                     ; preds = %vector.body
  %cmp.n = icmp eq i64 %21, %n.vec
  br i1 %cmp.n, label %_QFPloop.exit.loopexit, label %scalar.ph

scalar.ph:                                        ; preds = %vector.memcheck, %vector.scevcheck, %.lr.ph8.preheader.i, %middle.block
  %bc.resume.val = phi i64 [ %ind.end, %middle.block ], [ %18, %.lr.ph8.preheader.i ], [ %18, %vector.scevcheck ], [ %18, %vector.memcheck ]
  %bc.resume.val84 = phi i32 [ %ind.end83, %middle.block ], [ %6, %.lr.ph8.preheader.i ], [ %6, %vector.scevcheck ], [ %6, %vector.memcheck ]
  br label %.lr.ph8.i

.lr.ph8.i:                                        ; preds = %.lr.ph8.i, %scalar.ph
  %47 = phi i64 [ %57, %.lr.ph8.i ], [ %bc.resume.val, %scalar.ph ]
  %48 = phi i32 [ %56, %.lr.ph8.i ], [ %bc.resume.val84, %scalar.ph ]
  %49 = load i32, ptr %12, align 4, !tbaa !4
  %50 = sitofp i32 %49 to float
  %51 = fdiv contract float 1.000000e+00, %50
  %52 = fpext float %51 to double
  %53 = sext i32 %48 to i64
  %54 = add nsw i64 %53, -1
  %55 = getelementptr double, ptr %.unpack, i64 %54
  store double %52, ptr %55, align 8, !tbaa !4
  store double %52, ptr %14, align 8, !tbaa !4
  %56 = add i32 %48, 1
  %57 = add nsw i64 %47, -1
  %58 = icmp ugt i64 %47, 1
  br i1 %58, label %.lr.ph8.i, label %_QFPloop.exit.loopexit, !llvm.loop !21

_QFPloop.exit.loopexit:                           ; preds = %middle.block, %.lr.ph8.i
  br label %_QFPloop.exit

_QFPloop.exit:                                    ; preds = %_QFPloop.exit.loopexit, %omp.par.entry
  ret void
}
*** IR Dump After LoopLoadEliminationPass on _QFPomp_subroutine..omp_par ***
; Function Attrs: norecurse nounwind
define internal void @_QFPomp_subroutine..omp_par(ptr noalias nocapture readnone %tid.addr, ptr noalias nocapture readnone %zero.addr, ptr nocapture readonly %0) #3 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %gep_3 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 2
  %loadgep_4 = load ptr, ptr %gep_3, align 8
  %gep_5 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 3
  %loadgep_6 = load ptr, ptr %gep_5, align 8
  %gep_7 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 4
  %loadgep_8 = load ptr, ptr %gep_7, align 8
  %1 = tail call i32 @omp_get_thread_num()
  %2 = tail call i32 @omp_get_num_threads()
  %3 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %4 = sdiv i32 %3, %2
  %5 = mul i32 %4, %1
  %6 = add i32 %5, 1
  %7 = add i32 %2, -1
  %8 = icmp eq i32 %1, %7
  %9 = add i32 %6, %4
  %spec.select = select i1 %8, i32 %3, i32 %9
  %.unpack = load ptr, ptr %loadgep_2, align 8, !tbaa !8
  %.elt14 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  %.unpack15 = load i64, ptr %.elt14, align 8, !tbaa !8
  %.elt16 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  %.unpack17 = load i32, ptr %.elt16, align 8, !tbaa !8
  %.elt18 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  %.unpack19 = load i8, ptr %.elt18, align 4, !tbaa !8
  %.elt20 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  %.unpack21 = load i8, ptr %.elt20, align 1, !tbaa !8
  %.elt22 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  %.unpack23 = load i8, ptr %.elt22, align 2, !tbaa !8
  %.elt24 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  %.unpack25 = load i8, ptr %.elt24, align 1, !tbaa !8
  %.elt26 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  %.unpack27.unpack.unpack = load i64, ptr %.elt26, align 8, !tbaa !8
  %.unpack27.unpack.elt29 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  %.unpack27.unpack.unpack30 = load i64, ptr %.unpack27.unpack.elt29, align 8, !tbaa !8
  %.unpack27.unpack.elt31 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  %.unpack27.unpack.unpack32 = load i64, ptr %.unpack27.unpack.elt31, align 8, !tbaa !8
  store ptr %.unpack, ptr %loadgep_4, align 8, !tbaa !8
  %loadgep_4.repack34 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 1
  store i64 %.unpack15, ptr %loadgep_4.repack34, align 8, !tbaa !8
  %loadgep_4.repack36 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 2
  store i32 %.unpack17, ptr %loadgep_4.repack36, align 8, !tbaa !8
  %loadgep_4.repack38 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 3
  store i8 %.unpack19, ptr %loadgep_4.repack38, align 4, !tbaa !8
  %loadgep_4.repack40 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 4
  store i8 %.unpack21, ptr %loadgep_4.repack40, align 1, !tbaa !8
  %loadgep_4.repack42 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 5
  store i8 %.unpack23, ptr %loadgep_4.repack42, align 2, !tbaa !8
  %loadgep_4.repack44 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 6
  store i8 %.unpack25, ptr %loadgep_4.repack44, align 1, !tbaa !8
  %loadgep_4.repack46 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7
  store i64 %.unpack27.unpack.unpack, ptr %loadgep_4.repack46, align 8, !tbaa !8
  %loadgep_4.repack46.repack48 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack27.unpack.unpack30, ptr %loadgep_4.repack46.repack48, align 8, !tbaa !8
  %loadgep_4.repack46.repack50 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 2
  store i64 %.unpack27.unpack.unpack32, ptr %loadgep_4.repack46.repack50, align 8, !tbaa !8
  %10 = icmp eq i64 %.unpack27.unpack.unpack30, 0
  %11 = select i1 %10, i64 1, i64 %.unpack27.unpack.unpack
  store ptr %.unpack, ptr %loadgep_6, align 8, !tbaa !8
  %loadgep_6.repack52 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 1
  store i64 8, ptr %loadgep_6.repack52, align 8, !tbaa !8
  %loadgep_6.repack54 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 2
  store i32 20180515, ptr %loadgep_6.repack54, align 8, !tbaa !8
  %loadgep_6.repack56 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 3
  store i8 1, ptr %loadgep_6.repack56, align 4, !tbaa !8
  %loadgep_6.repack58 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 4
  store i8 28, ptr %loadgep_6.repack58, align 1, !tbaa !8
  %loadgep_6.repack60 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 5
  store i8 0, ptr %loadgep_6.repack60, align 2, !tbaa !8
  %loadgep_6.repack62 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 6
  store i8 0, ptr %loadgep_6.repack62, align 1, !tbaa !8
  %loadgep_6.repack64 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7
  store i64 %11, ptr %loadgep_6.repack64, align 8, !tbaa !8
  %loadgep_6.repack64.repack66 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack27.unpack.unpack30, ptr %loadgep_6.repack64.repack66, align 8, !tbaa !8
  %loadgep_6.repack64.repack68 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7, i64 0, i64 2
  store i64 8, ptr %loadgep_6.repack64.repack68, align 8, !tbaa !8
  %12 = load ptr, ptr %loadgep_8, align 8, !tbaa !4
  %13 = getelementptr { ptr, ptr }, ptr %loadgep_8, i64 0, i32 1
  %14 = load ptr, ptr %13, align 8, !tbaa !4
  %15 = sext i32 %6 to i64
  %16 = sext i32 %spec.select to i64
  %reass.sub9.i = sub nsw i64 %16, %15
  %17 = icmp sgt i64 %reass.sub9.i, -1
  br i1 %17, label %.lr.ph8.preheader.i, label %_QFPloop.exit

.lr.ph8.preheader.i:                              ; preds = %omp.par.entry
  %18 = add i64 %reass.sub9.i, 1
  %19 = add i64 %16, 2
  %umin82 = call i64 @llvm.umin.i64(i64 %18, i64 1)
  %20 = sub i64 %19, %umin82
  %21 = sub i64 %20, %15
  %min.iters.check = icmp ult i64 %21, 8
  br i1 %min.iters.check, label %scalar.ph, label %vector.scevcheck

vector.scevcheck:                                 ; preds = %.lr.ph8.preheader.i
  %22 = add i64 %16, 1
  %umin = call i64 @llvm.umin.i64(i64 %18, i64 1)
  %23 = sub i64 %22, %umin
  %24 = sub i64 %23, %15
  %25 = trunc i64 %24 to i32
  %26 = add i32 %6, %25
  %27 = icmp slt i32 %26, %6
  %28 = icmp ugt i64 %24, 4294967295
  %29 = or i1 %27, %28
  br i1 %29, label %scalar.ph, label %vector.memcheck

vector.memcheck:                                  ; preds = %vector.scevcheck
  %scevgep = getelementptr i8, ptr %14, i64 8
  %scevgep71 = getelementptr i8, ptr %12, i64 4
  %30 = shl nsw i64 %15, 3
  %31 = add nsw i64 %30, -8
  %scevgep72 = getelementptr i8, ptr %.unpack, i64 %31
  %32 = shl nsw i64 %16, 3
  %33 = add i64 %32, 8
  %umin73 = call i64 @llvm.umin.i64(i64 %18, i64 1)
  %34 = shl nuw nsw i64 %umin73, 3
  %35 = sub i64 %33, %34
  %scevgep74 = getelementptr i8, ptr %.unpack, i64 %35
  %bound0 = icmp ult ptr %14, %scevgep71
  %bound1 = icmp ult ptr %12, %scevgep
  %found.conflict = and i1 %bound0, %bound1
  %bound075 = icmp ult ptr %14, %scevgep74
  %bound176 = icmp ult ptr %scevgep72, %scevgep
  %found.conflict77 = and i1 %bound075, %bound176
  %conflict.rdx = or i1 %found.conflict, %found.conflict77
  %bound078 = icmp ult ptr %12, %scevgep74
  %bound179 = icmp ult ptr %scevgep72, %scevgep71
  %found.conflict80 = and i1 %bound078, %bound179
  %conflict.rdx81 = or i1 %conflict.rdx, %found.conflict80
  br i1 %conflict.rdx81, label %scalar.ph, label %vector.ph

vector.ph:                                        ; preds = %vector.memcheck
  %n.mod.vf = urem i64 %21, 2
  %n.vec = sub i64 %21, %n.mod.vf
  %ind.end = sub i64 %18, %n.vec
  %.cast = trunc i64 %n.vec to i32
  %ind.end83 = add i32 %6, %.cast
  br label %vector.body

vector.body:                                      ; preds = %vector.body, %vector.ph
  %index = phi i64 [ 0, %vector.ph ], [ %index.next, %vector.body ]
  %.cast85 = trunc i64 %index to i32
  %offset.idx = add i32 %6, %.cast85
  %36 = add i32 %offset.idx, 0
  %37 = load i32, ptr %12, align 4, !tbaa !4, !alias.scope !10, !noalias !13
  %broadcast.splatinsert = insertelement <2 x i32> poison, i32 %37, i64 0
  %broadcast.splat = shufflevector <2 x i32> %broadcast.splatinsert, <2 x i32> poison, <2 x i32> zeroinitializer
  %38 = sitofp <2 x i32> %broadcast.splat to <2 x float>
  %39 = fdiv contract <2 x float> <float 1.000000e+00, float 1.000000e+00>, %38
  %40 = fpext <2 x float> %39 to <2 x double>
  %41 = sext i32 %36 to i64
  %42 = add nsw i64 %41, -1
  %43 = getelementptr double, ptr %.unpack, i64 %42
  %44 = getelementptr double, ptr %43, i32 0
  store <2 x double> %40, ptr %44, align 8, !tbaa !4, !alias.scope !13
  %45 = extractelement <2 x double> %40, i32 1
  store double %45, ptr %14, align 8, !tbaa !4, !alias.scope !15, !noalias !17
  %index.next = add nuw i64 %index, 2
  %46 = icmp eq i64 %index.next, %n.vec
  br i1 %46, label %middle.block, label %vector.body, !llvm.loop !18

middle.block:                                     ; preds = %vector.body
  %cmp.n = icmp eq i64 %21, %n.vec
  br i1 %cmp.n, label %_QFPloop.exit.loopexit, label %scalar.ph

scalar.ph:                                        ; preds = %vector.memcheck, %vector.scevcheck, %.lr.ph8.preheader.i, %middle.block
  %bc.resume.val = phi i64 [ %ind.end, %middle.block ], [ %18, %.lr.ph8.preheader.i ], [ %18, %vector.scevcheck ], [ %18, %vector.memcheck ]
  %bc.resume.val84 = phi i32 [ %ind.end83, %middle.block ], [ %6, %.lr.ph8.preheader.i ], [ %6, %vector.scevcheck ], [ %6, %vector.memcheck ]
  br label %.lr.ph8.i

.lr.ph8.i:                                        ; preds = %.lr.ph8.i, %scalar.ph
  %47 = phi i64 [ %57, %.lr.ph8.i ], [ %bc.resume.val, %scalar.ph ]
  %48 = phi i32 [ %56, %.lr.ph8.i ], [ %bc.resume.val84, %scalar.ph ]
  %49 = load i32, ptr %12, align 4, !tbaa !4
  %50 = sitofp i32 %49 to float
  %51 = fdiv contract float 1.000000e+00, %50
  %52 = fpext float %51 to double
  %53 = sext i32 %48 to i64
  %54 = add nsw i64 %53, -1
  %55 = getelementptr double, ptr %.unpack, i64 %54
  store double %52, ptr %55, align 8, !tbaa !4
  store double %52, ptr %14, align 8, !tbaa !4
  %56 = add i32 %48, 1
  %57 = add nsw i64 %47, -1
  %58 = icmp ugt i64 %47, 1
  br i1 %58, label %.lr.ph8.i, label %_QFPloop.exit.loopexit.loopexit, !llvm.loop !21

_QFPloop.exit.loopexit.loopexit:                  ; preds = %.lr.ph8.i
  br label %_QFPloop.exit.loopexit

_QFPloop.exit.loopexit:                           ; preds = %_QFPloop.exit.loopexit.loopexit, %middle.block
  br label %_QFPloop.exit

_QFPloop.exit:                                    ; preds = %_QFPloop.exit.loopexit, %omp.par.entry
  ret void
}
*** IR Dump After InstCombinePass on _QFPomp_subroutine..omp_par ***
; Function Attrs: norecurse nounwind
define internal void @_QFPomp_subroutine..omp_par(ptr noalias nocapture readnone %tid.addr, ptr noalias nocapture readnone %zero.addr, ptr nocapture readonly %0) #3 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %gep_3 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 2
  %loadgep_4 = load ptr, ptr %gep_3, align 8
  %gep_5 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 3
  %loadgep_6 = load ptr, ptr %gep_5, align 8
  %gep_7 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 4
  %loadgep_8 = load ptr, ptr %gep_7, align 8
  %1 = tail call i32 @omp_get_thread_num()
  %2 = tail call i32 @omp_get_num_threads()
  %3 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %4 = sdiv i32 %3, %2
  %5 = mul i32 %4, %1
  %6 = add i32 %5, 1
  %7 = add i32 %2, -1
  %8 = icmp eq i32 %1, %7
  %9 = add i32 %6, %4
  %spec.select = select i1 %8, i32 %3, i32 %9
  %.unpack = load ptr, ptr %loadgep_2, align 8, !tbaa !8
  %.elt14 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  %.unpack15 = load i64, ptr %.elt14, align 8, !tbaa !8
  %.elt16 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  %.unpack17 = load i32, ptr %.elt16, align 8, !tbaa !8
  %.elt18 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  %.unpack19 = load i8, ptr %.elt18, align 4, !tbaa !8
  %.elt20 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  %.unpack21 = load i8, ptr %.elt20, align 1, !tbaa !8
  %.elt22 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  %.unpack23 = load i8, ptr %.elt22, align 2, !tbaa !8
  %.elt24 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  %.unpack25 = load i8, ptr %.elt24, align 1, !tbaa !8
  %.elt26 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  %.unpack27.unpack.unpack = load i64, ptr %.elt26, align 8, !tbaa !8
  %.unpack27.unpack.elt29 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  %.unpack27.unpack.unpack30 = load i64, ptr %.unpack27.unpack.elt29, align 8, !tbaa !8
  %.unpack27.unpack.elt31 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  %.unpack27.unpack.unpack32 = load i64, ptr %.unpack27.unpack.elt31, align 8, !tbaa !8
  store ptr %.unpack, ptr %loadgep_4, align 8, !tbaa !8
  %loadgep_4.repack34 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 1
  store i64 %.unpack15, ptr %loadgep_4.repack34, align 8, !tbaa !8
  %loadgep_4.repack36 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 2
  store i32 %.unpack17, ptr %loadgep_4.repack36, align 8, !tbaa !8
  %loadgep_4.repack38 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 3
  store i8 %.unpack19, ptr %loadgep_4.repack38, align 4, !tbaa !8
  %loadgep_4.repack40 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 4
  store i8 %.unpack21, ptr %loadgep_4.repack40, align 1, !tbaa !8
  %loadgep_4.repack42 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 5
  store i8 %.unpack23, ptr %loadgep_4.repack42, align 2, !tbaa !8
  %loadgep_4.repack44 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 6
  store i8 %.unpack25, ptr %loadgep_4.repack44, align 1, !tbaa !8
  %loadgep_4.repack46 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7
  store i64 %.unpack27.unpack.unpack, ptr %loadgep_4.repack46, align 8, !tbaa !8
  %loadgep_4.repack46.repack48 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack27.unpack.unpack30, ptr %loadgep_4.repack46.repack48, align 8, !tbaa !8
  %loadgep_4.repack46.repack50 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 2
  store i64 %.unpack27.unpack.unpack32, ptr %loadgep_4.repack46.repack50, align 8, !tbaa !8
  %10 = icmp eq i64 %.unpack27.unpack.unpack30, 0
  %11 = select i1 %10, i64 1, i64 %.unpack27.unpack.unpack
  store ptr %.unpack, ptr %loadgep_6, align 8, !tbaa !8
  %loadgep_6.repack52 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 1
  store i64 8, ptr %loadgep_6.repack52, align 8, !tbaa !8
  %loadgep_6.repack54 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 2
  store i32 20180515, ptr %loadgep_6.repack54, align 8, !tbaa !8
  %loadgep_6.repack56 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 3
  store i8 1, ptr %loadgep_6.repack56, align 4, !tbaa !8
  %loadgep_6.repack58 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 4
  store i8 28, ptr %loadgep_6.repack58, align 1, !tbaa !8
  %loadgep_6.repack60 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 5
  store i8 0, ptr %loadgep_6.repack60, align 2, !tbaa !8
  %loadgep_6.repack62 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 6
  store i8 0, ptr %loadgep_6.repack62, align 1, !tbaa !8
  %loadgep_6.repack64 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7
  store i64 %11, ptr %loadgep_6.repack64, align 8, !tbaa !8
  %loadgep_6.repack64.repack66 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack27.unpack.unpack30, ptr %loadgep_6.repack64.repack66, align 8, !tbaa !8
  %loadgep_6.repack64.repack68 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7, i64 0, i64 2
  store i64 8, ptr %loadgep_6.repack64.repack68, align 8, !tbaa !8
  %12 = load ptr, ptr %loadgep_8, align 8, !tbaa !4
  %13 = getelementptr { ptr, ptr }, ptr %loadgep_8, i64 0, i32 1
  %14 = load ptr, ptr %13, align 8, !tbaa !4
  %15 = sext i32 %6 to i64
  %16 = sext i32 %spec.select to i64
  %reass.sub9.i = sub nsw i64 %16, %15
  %17 = icmp sgt i64 %reass.sub9.i, -1
  br i1 %17, label %.lr.ph8.preheader.i, label %_QFPloop.exit

.lr.ph8.preheader.i:                              ; preds = %omp.par.entry
  %18 = add nsw i64 %reass.sub9.i, 1
  %19 = add nsw i64 %16, 2
  %20 = icmp ne i64 %18, 0
  %umin82.neg = sext i1 %20 to i64
  %21 = add nsw i64 %19, %umin82.neg
  %22 = sub nsw i64 %21, %15
  %min.iters.check = icmp ult i64 %22, 8
  br i1 %min.iters.check, label %scalar.ph, label %vector.scevcheck

vector.scevcheck:                                 ; preds = %.lr.ph8.preheader.i
  %23 = add nsw i64 %16, 1
  %24 = icmp ne i64 %18, 0
  %umin.neg = sext i1 %24 to i64
  %25 = add nsw i64 %23, %umin.neg
  %26 = sub nsw i64 %25, %15
  %27 = trunc i64 %26 to i32
  %28 = add i32 %6, %27
  %29 = icmp slt i32 %28, %6
  %30 = icmp ugt i64 %26, 4294967295
  %31 = or i1 %29, %30
  br i1 %31, label %scalar.ph, label %vector.memcheck

vector.memcheck:                                  ; preds = %vector.scevcheck
  %scevgep = getelementptr i8, ptr %14, i64 8
  %scevgep71 = getelementptr i8, ptr %12, i64 4
  %32 = shl nsw i64 %15, 3
  %33 = add nsw i64 %32, -8
  %scevgep72 = getelementptr i8, ptr %.unpack, i64 %33
  %34 = shl nsw i64 %16, 3
  %35 = add nsw i64 %34, 8
  %.not = icmp eq i64 %18, 0
  %36 = select i1 %.not, i64 %35, i64 %34
  %scevgep74 = getelementptr i8, ptr %.unpack, i64 %36
  %bound0 = icmp ult ptr %14, %scevgep71
  %bound1 = icmp ult ptr %12, %scevgep
  %found.conflict = and i1 %bound0, %bound1
  %bound075 = icmp ult ptr %14, %scevgep74
  %bound176 = icmp ult ptr %scevgep72, %scevgep
  %found.conflict77 = and i1 %bound075, %bound176
  %conflict.rdx = or i1 %found.conflict, %found.conflict77
  %bound078 = icmp ult ptr %12, %scevgep74
  %bound179 = icmp ult ptr %scevgep72, %scevgep71
  %found.conflict80 = and i1 %bound078, %bound179
  %conflict.rdx81 = or i1 %conflict.rdx, %found.conflict80
  br i1 %conflict.rdx81, label %scalar.ph, label %vector.ph

vector.ph:                                        ; preds = %vector.memcheck
  %n.vec = and i64 %22, -2
  %ind.end = sub nsw i64 %18, %n.vec
  %.cast = trunc i64 %n.vec to i32
  %ind.end83 = add i32 %6, %.cast
  br label %vector.body

vector.body:                                      ; preds = %vector.body, %vector.ph
  %index = phi i64 [ 0, %vector.ph ], [ %index.next, %vector.body ]
  %.cast85 = trunc i64 %index to i32
  %offset.idx = add i32 %6, %.cast85
  %37 = load i32, ptr %12, align 4, !tbaa !4, !alias.scope !10, !noalias !13
  %broadcast.splatinsert = insertelement <2 x i32> poison, i32 %37, i64 0
  %38 = sitofp <2 x i32> %broadcast.splatinsert to <2 x float>
  %39 = fdiv contract <2 x float> <float 1.000000e+00, float poison>, %38
  %40 = shufflevector <2 x float> %39, <2 x float> poison, <2 x i32> zeroinitializer
  %41 = fpext <2 x float> %40 to <2 x double>
  %42 = sext i32 %offset.idx to i64
  %43 = add nsw i64 %42, -1
  %44 = getelementptr double, ptr %.unpack, i64 %43
  store <2 x double> %41, ptr %44, align 8, !tbaa !4, !alias.scope !13
  %45 = extractelement <2 x double> %41, i64 1
  store double %45, ptr %14, align 8, !tbaa !4, !alias.scope !15, !noalias !17
  %index.next = add nuw i64 %index, 2
  %46 = icmp eq i64 %index.next, %n.vec
  br i1 %46, label %middle.block, label %vector.body, !llvm.loop !18

middle.block:                                     ; preds = %vector.body
  %cmp.n = icmp eq i64 %22, %n.vec
  br i1 %cmp.n, label %_QFPloop.exit.loopexit, label %scalar.ph

scalar.ph:                                        ; preds = %vector.memcheck, %vector.scevcheck, %.lr.ph8.preheader.i, %middle.block
  %bc.resume.val = phi i64 [ %ind.end, %middle.block ], [ %18, %.lr.ph8.preheader.i ], [ %18, %vector.scevcheck ], [ %18, %vector.memcheck ]
  %bc.resume.val84 = phi i32 [ %ind.end83, %middle.block ], [ %6, %.lr.ph8.preheader.i ], [ %6, %vector.scevcheck ], [ %6, %vector.memcheck ]
  br label %.lr.ph8.i

.lr.ph8.i:                                        ; preds = %.lr.ph8.i, %scalar.ph
  %47 = phi i64 [ %57, %.lr.ph8.i ], [ %bc.resume.val, %scalar.ph ]
  %48 = phi i32 [ %56, %.lr.ph8.i ], [ %bc.resume.val84, %scalar.ph ]
  %49 = load i32, ptr %12, align 4, !tbaa !4
  %50 = sitofp i32 %49 to float
  %51 = fdiv contract float 1.000000e+00, %50
  %52 = fpext float %51 to double
  %53 = sext i32 %48 to i64
  %54 = add nsw i64 %53, -1
  %55 = getelementptr double, ptr %.unpack, i64 %54
  store double %52, ptr %55, align 8, !tbaa !4
  store double %52, ptr %14, align 8, !tbaa !4
  %56 = add i32 %48, 1
  %57 = add nsw i64 %47, -1
  %58 = icmp ugt i64 %47, 1
  br i1 %58, label %.lr.ph8.i, label %_QFPloop.exit.loopexit.loopexit, !llvm.loop !21

_QFPloop.exit.loopexit.loopexit:                  ; preds = %.lr.ph8.i
  br label %_QFPloop.exit.loopexit

_QFPloop.exit.loopexit:                           ; preds = %_QFPloop.exit.loopexit.loopexit, %middle.block
  br label %_QFPloop.exit

_QFPloop.exit:                                    ; preds = %_QFPloop.exit.loopexit, %omp.par.entry
  ret void
}
*** IR Dump After SimplifyCFGPass on _QFPomp_subroutine..omp_par ***
; Function Attrs: norecurse nounwind
define internal void @_QFPomp_subroutine..omp_par(ptr noalias nocapture readnone %tid.addr, ptr noalias nocapture readnone %zero.addr, ptr nocapture readonly %0) #3 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %gep_3 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 2
  %loadgep_4 = load ptr, ptr %gep_3, align 8
  %gep_5 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 3
  %loadgep_6 = load ptr, ptr %gep_5, align 8
  %gep_7 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 4
  %loadgep_8 = load ptr, ptr %gep_7, align 8
  %1 = tail call i32 @omp_get_thread_num()
  %2 = tail call i32 @omp_get_num_threads()
  %3 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %4 = sdiv i32 %3, %2
  %5 = mul i32 %4, %1
  %6 = add i32 %5, 1
  %7 = add i32 %2, -1
  %8 = icmp eq i32 %1, %7
  %9 = add i32 %6, %4
  %spec.select = select i1 %8, i32 %3, i32 %9
  %.unpack = load ptr, ptr %loadgep_2, align 8, !tbaa !8
  %.elt14 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  %.unpack15 = load i64, ptr %.elt14, align 8, !tbaa !8
  %.elt16 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  %.unpack17 = load i32, ptr %.elt16, align 8, !tbaa !8
  %.elt18 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  %.unpack19 = load i8, ptr %.elt18, align 4, !tbaa !8
  %.elt20 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  %.unpack21 = load i8, ptr %.elt20, align 1, !tbaa !8
  %.elt22 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  %.unpack23 = load i8, ptr %.elt22, align 2, !tbaa !8
  %.elt24 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  %.unpack25 = load i8, ptr %.elt24, align 1, !tbaa !8
  %.elt26 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  %.unpack27.unpack.unpack = load i64, ptr %.elt26, align 8, !tbaa !8
  %.unpack27.unpack.elt29 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  %.unpack27.unpack.unpack30 = load i64, ptr %.unpack27.unpack.elt29, align 8, !tbaa !8
  %.unpack27.unpack.elt31 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  %.unpack27.unpack.unpack32 = load i64, ptr %.unpack27.unpack.elt31, align 8, !tbaa !8
  store ptr %.unpack, ptr %loadgep_4, align 8, !tbaa !8
  %loadgep_4.repack34 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 1
  store i64 %.unpack15, ptr %loadgep_4.repack34, align 8, !tbaa !8
  %loadgep_4.repack36 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 2
  store i32 %.unpack17, ptr %loadgep_4.repack36, align 8, !tbaa !8
  %loadgep_4.repack38 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 3
  store i8 %.unpack19, ptr %loadgep_4.repack38, align 4, !tbaa !8
  %loadgep_4.repack40 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 4
  store i8 %.unpack21, ptr %loadgep_4.repack40, align 1, !tbaa !8
  %loadgep_4.repack42 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 5
  store i8 %.unpack23, ptr %loadgep_4.repack42, align 2, !tbaa !8
  %loadgep_4.repack44 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 6
  store i8 %.unpack25, ptr %loadgep_4.repack44, align 1, !tbaa !8
  %loadgep_4.repack46 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7
  store i64 %.unpack27.unpack.unpack, ptr %loadgep_4.repack46, align 8, !tbaa !8
  %loadgep_4.repack46.repack48 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack27.unpack.unpack30, ptr %loadgep_4.repack46.repack48, align 8, !tbaa !8
  %loadgep_4.repack46.repack50 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 2
  store i64 %.unpack27.unpack.unpack32, ptr %loadgep_4.repack46.repack50, align 8, !tbaa !8
  %10 = icmp eq i64 %.unpack27.unpack.unpack30, 0
  %11 = select i1 %10, i64 1, i64 %.unpack27.unpack.unpack
  store ptr %.unpack, ptr %loadgep_6, align 8, !tbaa !8
  %loadgep_6.repack52 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 1
  store i64 8, ptr %loadgep_6.repack52, align 8, !tbaa !8
  %loadgep_6.repack54 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 2
  store i32 20180515, ptr %loadgep_6.repack54, align 8, !tbaa !8
  %loadgep_6.repack56 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 3
  store i8 1, ptr %loadgep_6.repack56, align 4, !tbaa !8
  %loadgep_6.repack58 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 4
  store i8 28, ptr %loadgep_6.repack58, align 1, !tbaa !8
  %loadgep_6.repack60 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 5
  store i8 0, ptr %loadgep_6.repack60, align 2, !tbaa !8
  %loadgep_6.repack62 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 6
  store i8 0, ptr %loadgep_6.repack62, align 1, !tbaa !8
  %loadgep_6.repack64 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7
  store i64 %11, ptr %loadgep_6.repack64, align 8, !tbaa !8
  %loadgep_6.repack64.repack66 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack27.unpack.unpack30, ptr %loadgep_6.repack64.repack66, align 8, !tbaa !8
  %loadgep_6.repack64.repack68 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7, i64 0, i64 2
  store i64 8, ptr %loadgep_6.repack64.repack68, align 8, !tbaa !8
  %12 = load ptr, ptr %loadgep_8, align 8, !tbaa !4
  %13 = getelementptr { ptr, ptr }, ptr %loadgep_8, i64 0, i32 1
  %14 = load ptr, ptr %13, align 8, !tbaa !4
  %15 = sext i32 %6 to i64
  %16 = sext i32 %spec.select to i64
  %reass.sub9.i = sub nsw i64 %16, %15
  %17 = icmp sgt i64 %reass.sub9.i, -1
  br i1 %17, label %.lr.ph8.preheader.i, label %_QFPloop.exit

.lr.ph8.preheader.i:                              ; preds = %omp.par.entry
  %18 = add nsw i64 %reass.sub9.i, 1
  %19 = add nsw i64 %16, 2
  %20 = icmp ne i64 %18, 0
  %umin82.neg = sext i1 %20 to i64
  %21 = add nsw i64 %19, %umin82.neg
  %22 = sub nsw i64 %21, %15
  %min.iters.check = icmp ult i64 %22, 8
  br i1 %min.iters.check, label %.lr.ph8.i, label %vector.scevcheck

vector.scevcheck:                                 ; preds = %.lr.ph8.preheader.i
  %23 = add nsw i64 %16, 1
  %24 = icmp ne i64 %18, 0
  %umin.neg = sext i1 %24 to i64
  %25 = add nsw i64 %23, %umin.neg
  %26 = sub nsw i64 %25, %15
  %27 = trunc i64 %26 to i32
  %28 = add i32 %6, %27
  %29 = icmp slt i32 %28, %6
  %30 = icmp ugt i64 %26, 4294967295
  %31 = or i1 %29, %30
  br i1 %31, label %.lr.ph8.i, label %vector.memcheck

vector.memcheck:                                  ; preds = %vector.scevcheck
  %scevgep = getelementptr i8, ptr %14, i64 8
  %scevgep71 = getelementptr i8, ptr %12, i64 4
  %32 = shl nsw i64 %15, 3
  %33 = add nsw i64 %32, -8
  %scevgep72 = getelementptr i8, ptr %.unpack, i64 %33
  %34 = shl nsw i64 %16, 3
  %35 = add nsw i64 %34, 8
  %.not = icmp eq i64 %18, 0
  %36 = select i1 %.not, i64 %35, i64 %34
  %scevgep74 = getelementptr i8, ptr %.unpack, i64 %36
  %bound0 = icmp ult ptr %14, %scevgep71
  %bound1 = icmp ult ptr %12, %scevgep
  %found.conflict = and i1 %bound0, %bound1
  %bound075 = icmp ult ptr %14, %scevgep74
  %bound176 = icmp ult ptr %scevgep72, %scevgep
  %found.conflict77 = and i1 %bound075, %bound176
  %conflict.rdx = or i1 %found.conflict, %found.conflict77
  %bound078 = icmp ult ptr %12, %scevgep74
  %bound179 = icmp ult ptr %scevgep72, %scevgep71
  %found.conflict80 = and i1 %bound078, %bound179
  %conflict.rdx81 = or i1 %conflict.rdx, %found.conflict80
  br i1 %conflict.rdx81, label %.lr.ph8.i, label %vector.ph

vector.ph:                                        ; preds = %vector.memcheck
  %n.vec = and i64 %22, -2
  %ind.end = sub nsw i64 %18, %n.vec
  %.cast = trunc i64 %n.vec to i32
  %ind.end83 = add i32 %6, %.cast
  br label %vector.body

vector.body:                                      ; preds = %vector.body, %vector.ph
  %index = phi i64 [ 0, %vector.ph ], [ %index.next, %vector.body ]
  %.cast85 = trunc i64 %index to i32
  %offset.idx = add i32 %6, %.cast85
  %37 = load i32, ptr %12, align 4, !tbaa !4, !alias.scope !10, !noalias !13
  %broadcast.splatinsert = insertelement <2 x i32> poison, i32 %37, i64 0
  %38 = sitofp <2 x i32> %broadcast.splatinsert to <2 x float>
  %39 = fdiv contract <2 x float> <float 1.000000e+00, float poison>, %38
  %40 = shufflevector <2 x float> %39, <2 x float> poison, <2 x i32> zeroinitializer
  %41 = fpext <2 x float> %40 to <2 x double>
  %42 = sext i32 %offset.idx to i64
  %43 = add nsw i64 %42, -1
  %44 = getelementptr double, ptr %.unpack, i64 %43
  store <2 x double> %41, ptr %44, align 8, !tbaa !4, !alias.scope !13
  %45 = extractelement <2 x double> %41, i64 1
  store double %45, ptr %14, align 8, !tbaa !4, !alias.scope !15, !noalias !17
  %index.next = add nuw i64 %index, 2
  %46 = icmp eq i64 %index.next, %n.vec
  br i1 %46, label %middle.block, label %vector.body, !llvm.loop !18

middle.block:                                     ; preds = %vector.body
  %cmp.n = icmp eq i64 %22, %n.vec
  br i1 %cmp.n, label %_QFPloop.exit, label %.lr.ph8.i

.lr.ph8.i:                                        ; preds = %middle.block, %.lr.ph8.preheader.i, %vector.scevcheck, %vector.memcheck, %.lr.ph8.i
  %47 = phi i64 [ %57, %.lr.ph8.i ], [ %ind.end, %middle.block ], [ %18, %.lr.ph8.preheader.i ], [ %18, %vector.scevcheck ], [ %18, %vector.memcheck ]
  %48 = phi i32 [ %56, %.lr.ph8.i ], [ %ind.end83, %middle.block ], [ %6, %.lr.ph8.preheader.i ], [ %6, %vector.scevcheck ], [ %6, %vector.memcheck ]
  %49 = load i32, ptr %12, align 4, !tbaa !4
  %50 = sitofp i32 %49 to float
  %51 = fdiv contract float 1.000000e+00, %50
  %52 = fpext float %51 to double
  %53 = sext i32 %48 to i64
  %54 = add nsw i64 %53, -1
  %55 = getelementptr double, ptr %.unpack, i64 %54
  store double %52, ptr %55, align 8, !tbaa !4
  store double %52, ptr %14, align 8, !tbaa !4
  %56 = add i32 %48, 1
  %57 = add nsw i64 %47, -1
  %58 = icmp ugt i64 %47, 1
  br i1 %58, label %.lr.ph8.i, label %_QFPloop.exit, !llvm.loop !21

_QFPloop.exit:                                    ; preds = %middle.block, %.lr.ph8.i, %omp.par.entry
  ret void
}
*** IR Dump After VectorCombinePass on _QFPomp_subroutine..omp_par ***
; Function Attrs: norecurse nounwind
define internal void @_QFPomp_subroutine..omp_par(ptr noalias nocapture readnone %tid.addr, ptr noalias nocapture readnone %zero.addr, ptr nocapture readonly %0) #3 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %gep_3 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 2
  %loadgep_4 = load ptr, ptr %gep_3, align 8
  %gep_5 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 3
  %loadgep_6 = load ptr, ptr %gep_5, align 8
  %gep_7 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 4
  %loadgep_8 = load ptr, ptr %gep_7, align 8
  %1 = tail call i32 @omp_get_thread_num()
  %2 = tail call i32 @omp_get_num_threads()
  %3 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %4 = sdiv i32 %3, %2
  %5 = mul i32 %4, %1
  %6 = add i32 %5, 1
  %7 = add i32 %2, -1
  %8 = icmp eq i32 %1, %7
  %9 = add i32 %6, %4
  %spec.select = select i1 %8, i32 %3, i32 %9
  %.unpack = load ptr, ptr %loadgep_2, align 8, !tbaa !8
  %.elt14 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  %.unpack15 = load i64, ptr %.elt14, align 8, !tbaa !8
  %.elt16 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  %.unpack17 = load i32, ptr %.elt16, align 8, !tbaa !8
  %.elt18 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  %.unpack19 = load i8, ptr %.elt18, align 4, !tbaa !8
  %.elt20 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  %.unpack21 = load i8, ptr %.elt20, align 1, !tbaa !8
  %.elt22 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  %.unpack23 = load i8, ptr %.elt22, align 2, !tbaa !8
  %.elt24 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  %.unpack25 = load i8, ptr %.elt24, align 1, !tbaa !8
  %.elt26 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  %.unpack27.unpack.unpack = load i64, ptr %.elt26, align 8, !tbaa !8
  %.unpack27.unpack.elt29 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  %.unpack27.unpack.unpack30 = load i64, ptr %.unpack27.unpack.elt29, align 8, !tbaa !8
  %.unpack27.unpack.elt31 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  %.unpack27.unpack.unpack32 = load i64, ptr %.unpack27.unpack.elt31, align 8, !tbaa !8
  store ptr %.unpack, ptr %loadgep_4, align 8, !tbaa !8
  %loadgep_4.repack34 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 1
  store i64 %.unpack15, ptr %loadgep_4.repack34, align 8, !tbaa !8
  %loadgep_4.repack36 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 2
  store i32 %.unpack17, ptr %loadgep_4.repack36, align 8, !tbaa !8
  %loadgep_4.repack38 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 3
  store i8 %.unpack19, ptr %loadgep_4.repack38, align 4, !tbaa !8
  %loadgep_4.repack40 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 4
  store i8 %.unpack21, ptr %loadgep_4.repack40, align 1, !tbaa !8
  %loadgep_4.repack42 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 5
  store i8 %.unpack23, ptr %loadgep_4.repack42, align 2, !tbaa !8
  %loadgep_4.repack44 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 6
  store i8 %.unpack25, ptr %loadgep_4.repack44, align 1, !tbaa !8
  %loadgep_4.repack46 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7
  store i64 %.unpack27.unpack.unpack, ptr %loadgep_4.repack46, align 8, !tbaa !8
  %loadgep_4.repack46.repack48 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack27.unpack.unpack30, ptr %loadgep_4.repack46.repack48, align 8, !tbaa !8
  %loadgep_4.repack46.repack50 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 2
  store i64 %.unpack27.unpack.unpack32, ptr %loadgep_4.repack46.repack50, align 8, !tbaa !8
  %10 = icmp eq i64 %.unpack27.unpack.unpack30, 0
  %11 = select i1 %10, i64 1, i64 %.unpack27.unpack.unpack
  store ptr %.unpack, ptr %loadgep_6, align 8, !tbaa !8
  %loadgep_6.repack52 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 1
  store i64 8, ptr %loadgep_6.repack52, align 8, !tbaa !8
  %loadgep_6.repack54 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 2
  store i32 20180515, ptr %loadgep_6.repack54, align 8, !tbaa !8
  %loadgep_6.repack56 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 3
  store i8 1, ptr %loadgep_6.repack56, align 4, !tbaa !8
  %loadgep_6.repack58 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 4
  store i8 28, ptr %loadgep_6.repack58, align 1, !tbaa !8
  %loadgep_6.repack60 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 5
  store i8 0, ptr %loadgep_6.repack60, align 2, !tbaa !8
  %loadgep_6.repack62 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 6
  store i8 0, ptr %loadgep_6.repack62, align 1, !tbaa !8
  %loadgep_6.repack64 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7
  store i64 %11, ptr %loadgep_6.repack64, align 8, !tbaa !8
  %loadgep_6.repack64.repack66 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack27.unpack.unpack30, ptr %loadgep_6.repack64.repack66, align 8, !tbaa !8
  %loadgep_6.repack64.repack68 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7, i64 0, i64 2
  store i64 8, ptr %loadgep_6.repack64.repack68, align 8, !tbaa !8
  %12 = load ptr, ptr %loadgep_8, align 8, !tbaa !4
  %13 = getelementptr { ptr, ptr }, ptr %loadgep_8, i64 0, i32 1
  %14 = load ptr, ptr %13, align 8, !tbaa !4
  %15 = sext i32 %6 to i64
  %16 = sext i32 %spec.select to i64
  %reass.sub9.i = sub nsw i64 %16, %15
  %17 = icmp sgt i64 %reass.sub9.i, -1
  br i1 %17, label %.lr.ph8.preheader.i, label %_QFPloop.exit

.lr.ph8.preheader.i:                              ; preds = %omp.par.entry
  %18 = add nsw i64 %reass.sub9.i, 1
  %19 = add nsw i64 %16, 2
  %20 = icmp ne i64 %18, 0
  %umin82.neg = sext i1 %20 to i64
  %21 = add nsw i64 %19, %umin82.neg
  %22 = sub nsw i64 %21, %15
  %min.iters.check = icmp ult i64 %22, 8
  br i1 %min.iters.check, label %.lr.ph8.i, label %vector.scevcheck

vector.scevcheck:                                 ; preds = %.lr.ph8.preheader.i
  %23 = add nsw i64 %16, 1
  %24 = icmp ne i64 %18, 0
  %umin.neg = sext i1 %24 to i64
  %25 = add nsw i64 %23, %umin.neg
  %26 = sub nsw i64 %25, %15
  %27 = trunc i64 %26 to i32
  %28 = add i32 %6, %27
  %29 = icmp slt i32 %28, %6
  %30 = icmp ugt i64 %26, 4294967295
  %31 = or i1 %29, %30
  br i1 %31, label %.lr.ph8.i, label %vector.memcheck

vector.memcheck:                                  ; preds = %vector.scevcheck
  %scevgep = getelementptr i8, ptr %14, i64 8
  %scevgep71 = getelementptr i8, ptr %12, i64 4
  %32 = shl nsw i64 %15, 3
  %33 = add nsw i64 %32, -8
  %scevgep72 = getelementptr i8, ptr %.unpack, i64 %33
  %34 = shl nsw i64 %16, 3
  %35 = add nsw i64 %34, 8
  %.not = icmp eq i64 %18, 0
  %36 = select i1 %.not, i64 %35, i64 %34
  %scevgep74 = getelementptr i8, ptr %.unpack, i64 %36
  %bound0 = icmp ult ptr %14, %scevgep71
  %bound1 = icmp ult ptr %12, %scevgep
  %found.conflict = and i1 %bound0, %bound1
  %bound075 = icmp ult ptr %14, %scevgep74
  %bound176 = icmp ult ptr %scevgep72, %scevgep
  %found.conflict77 = and i1 %bound075, %bound176
  %conflict.rdx = or i1 %found.conflict, %found.conflict77
  %bound078 = icmp ult ptr %12, %scevgep74
  %bound179 = icmp ult ptr %scevgep72, %scevgep71
  %found.conflict80 = and i1 %bound078, %bound179
  %conflict.rdx81 = or i1 %conflict.rdx, %found.conflict80
  br i1 %conflict.rdx81, label %.lr.ph8.i, label %vector.ph

vector.ph:                                        ; preds = %vector.memcheck
  %n.vec = and i64 %22, -2
  %ind.end = sub nsw i64 %18, %n.vec
  %.cast = trunc i64 %n.vec to i32
  %ind.end83 = add i32 %6, %.cast
  br label %vector.body

vector.body:                                      ; preds = %vector.body, %vector.ph
  %index = phi i64 [ 0, %vector.ph ], [ %index.next, %vector.body ]
  %.cast85 = trunc i64 %index to i32
  %offset.idx = add i32 %6, %.cast85
  %37 = load i32, ptr %12, align 4, !tbaa !4, !alias.scope !10, !noalias !13
  %broadcast.splatinsert = insertelement <2 x i32> poison, i32 %37, i64 0
  %38 = sitofp <2 x i32> %broadcast.splatinsert to <2 x float>
  %39 = fdiv contract <2 x float> <float 1.000000e+00, float poison>, %38
  %40 = shufflevector <2 x float> %39, <2 x float> poison, <2 x i32> zeroinitializer
  %41 = fpext <2 x float> %40 to <2 x double>
  %42 = sext i32 %offset.idx to i64
  %43 = add nsw i64 %42, -1
  %44 = getelementptr double, ptr %.unpack, i64 %43
  store <2 x double> %41, ptr %44, align 8, !tbaa !4, !alias.scope !13
  %45 = extractelement <2 x double> %41, i64 1
  store double %45, ptr %14, align 8, !tbaa !4, !alias.scope !15, !noalias !17
  %index.next = add nuw i64 %index, 2
  %46 = icmp eq i64 %index.next, %n.vec
  br i1 %46, label %middle.block, label %vector.body, !llvm.loop !18

middle.block:                                     ; preds = %vector.body
  %cmp.n = icmp eq i64 %22, %n.vec
  br i1 %cmp.n, label %_QFPloop.exit, label %.lr.ph8.i

.lr.ph8.i:                                        ; preds = %middle.block, %.lr.ph8.preheader.i, %vector.scevcheck, %vector.memcheck, %.lr.ph8.i
  %47 = phi i64 [ %57, %.lr.ph8.i ], [ %ind.end, %middle.block ], [ %18, %.lr.ph8.preheader.i ], [ %18, %vector.scevcheck ], [ %18, %vector.memcheck ]
  %48 = phi i32 [ %56, %.lr.ph8.i ], [ %ind.end83, %middle.block ], [ %6, %.lr.ph8.preheader.i ], [ %6, %vector.scevcheck ], [ %6, %vector.memcheck ]
  %49 = load i32, ptr %12, align 4, !tbaa !4
  %50 = sitofp i32 %49 to float
  %51 = fdiv contract float 1.000000e+00, %50
  %52 = fpext float %51 to double
  %53 = sext i32 %48 to i64
  %54 = add nsw i64 %53, -1
  %55 = getelementptr double, ptr %.unpack, i64 %54
  store double %52, ptr %55, align 8, !tbaa !4
  store double %52, ptr %14, align 8, !tbaa !4
  %56 = add i32 %48, 1
  %57 = add nsw i64 %47, -1
  %58 = icmp ugt i64 %47, 1
  br i1 %58, label %.lr.ph8.i, label %_QFPloop.exit, !llvm.loop !21

_QFPloop.exit:                                    ; preds = %middle.block, %.lr.ph8.i, %omp.par.entry
  ret void
}
*** IR Dump After InstCombinePass on _QFPomp_subroutine..omp_par ***
; Function Attrs: norecurse nounwind
define internal void @_QFPomp_subroutine..omp_par(ptr noalias nocapture readnone %tid.addr, ptr noalias nocapture readnone %zero.addr, ptr nocapture readonly %0) #3 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %gep_3 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 2
  %loadgep_4 = load ptr, ptr %gep_3, align 8
  %gep_5 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 3
  %loadgep_6 = load ptr, ptr %gep_5, align 8
  %gep_7 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 4
  %loadgep_8 = load ptr, ptr %gep_7, align 8
  %1 = tail call i32 @omp_get_thread_num()
  %2 = tail call i32 @omp_get_num_threads()
  %3 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %4 = sdiv i32 %3, %2
  %5 = mul i32 %4, %1
  %6 = add i32 %5, 1
  %7 = add i32 %2, -1
  %8 = icmp eq i32 %1, %7
  %9 = add i32 %6, %4
  %spec.select = select i1 %8, i32 %3, i32 %9
  %.unpack = load ptr, ptr %loadgep_2, align 8, !tbaa !8
  %.elt14 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  %.unpack15 = load i64, ptr %.elt14, align 8, !tbaa !8
  %.elt16 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  %.unpack17 = load i32, ptr %.elt16, align 8, !tbaa !8
  %.elt18 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  %.unpack19 = load i8, ptr %.elt18, align 4, !tbaa !8
  %.elt20 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  %.unpack21 = load i8, ptr %.elt20, align 1, !tbaa !8
  %.elt22 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  %.unpack23 = load i8, ptr %.elt22, align 2, !tbaa !8
  %.elt24 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  %.unpack25 = load i8, ptr %.elt24, align 1, !tbaa !8
  %.elt26 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  %.unpack27.unpack.unpack = load i64, ptr %.elt26, align 8, !tbaa !8
  %.unpack27.unpack.elt29 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  %.unpack27.unpack.unpack30 = load i64, ptr %.unpack27.unpack.elt29, align 8, !tbaa !8
  %.unpack27.unpack.elt31 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  %.unpack27.unpack.unpack32 = load i64, ptr %.unpack27.unpack.elt31, align 8, !tbaa !8
  store ptr %.unpack, ptr %loadgep_4, align 8, !tbaa !8
  %loadgep_4.repack34 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 1
  store i64 %.unpack15, ptr %loadgep_4.repack34, align 8, !tbaa !8
  %loadgep_4.repack36 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 2
  store i32 %.unpack17, ptr %loadgep_4.repack36, align 8, !tbaa !8
  %loadgep_4.repack38 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 3
  store i8 %.unpack19, ptr %loadgep_4.repack38, align 4, !tbaa !8
  %loadgep_4.repack40 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 4
  store i8 %.unpack21, ptr %loadgep_4.repack40, align 1, !tbaa !8
  %loadgep_4.repack42 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 5
  store i8 %.unpack23, ptr %loadgep_4.repack42, align 2, !tbaa !8
  %loadgep_4.repack44 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 6
  store i8 %.unpack25, ptr %loadgep_4.repack44, align 1, !tbaa !8
  %loadgep_4.repack46 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7
  store i64 %.unpack27.unpack.unpack, ptr %loadgep_4.repack46, align 8, !tbaa !8
  %loadgep_4.repack46.repack48 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack27.unpack.unpack30, ptr %loadgep_4.repack46.repack48, align 8, !tbaa !8
  %loadgep_4.repack46.repack50 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 2
  store i64 %.unpack27.unpack.unpack32, ptr %loadgep_4.repack46.repack50, align 8, !tbaa !8
  %10 = icmp eq i64 %.unpack27.unpack.unpack30, 0
  %11 = select i1 %10, i64 1, i64 %.unpack27.unpack.unpack
  store ptr %.unpack, ptr %loadgep_6, align 8, !tbaa !8
  %loadgep_6.repack52 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 1
  store i64 8, ptr %loadgep_6.repack52, align 8, !tbaa !8
  %loadgep_6.repack54 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 2
  store i32 20180515, ptr %loadgep_6.repack54, align 8, !tbaa !8
  %loadgep_6.repack56 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 3
  store i8 1, ptr %loadgep_6.repack56, align 4, !tbaa !8
  %loadgep_6.repack58 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 4
  store i8 28, ptr %loadgep_6.repack58, align 1, !tbaa !8
  %loadgep_6.repack60 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 5
  store i8 0, ptr %loadgep_6.repack60, align 2, !tbaa !8
  %loadgep_6.repack62 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 6
  store i8 0, ptr %loadgep_6.repack62, align 1, !tbaa !8
  %loadgep_6.repack64 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7
  store i64 %11, ptr %loadgep_6.repack64, align 8, !tbaa !8
  %loadgep_6.repack64.repack66 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack27.unpack.unpack30, ptr %loadgep_6.repack64.repack66, align 8, !tbaa !8
  %loadgep_6.repack64.repack68 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7, i64 0, i64 2
  store i64 8, ptr %loadgep_6.repack64.repack68, align 8, !tbaa !8
  %12 = load ptr, ptr %loadgep_8, align 8, !tbaa !4
  %13 = getelementptr { ptr, ptr }, ptr %loadgep_8, i64 0, i32 1
  %14 = load ptr, ptr %13, align 8, !tbaa !4
  %15 = sext i32 %6 to i64
  %16 = sext i32 %spec.select to i64
  %reass.sub9.i = sub nsw i64 %16, %15
  %17 = icmp sgt i64 %reass.sub9.i, -1
  br i1 %17, label %.lr.ph8.preheader.i, label %_QFPloop.exit

.lr.ph8.preheader.i:                              ; preds = %omp.par.entry
  %18 = add nsw i64 %reass.sub9.i, 1
  %19 = add nsw i64 %16, 2
  %20 = icmp ne i64 %18, 0
  %umin82.neg = sext i1 %20 to i64
  %21 = add nsw i64 %19, %umin82.neg
  %22 = sub nsw i64 %21, %15
  %min.iters.check = icmp ult i64 %22, 8
  br i1 %min.iters.check, label %.lr.ph8.i, label %vector.scevcheck

vector.scevcheck:                                 ; preds = %.lr.ph8.preheader.i
  %23 = add nsw i64 %16, 1
  %24 = icmp ne i64 %18, 0
  %umin.neg = sext i1 %24 to i64
  %25 = add nsw i64 %23, %umin.neg
  %26 = sub nsw i64 %25, %15
  %27 = trunc i64 %26 to i32
  %28 = add i32 %6, %27
  %29 = icmp slt i32 %28, %6
  %30 = icmp ugt i64 %26, 4294967295
  %31 = or i1 %29, %30
  br i1 %31, label %.lr.ph8.i, label %vector.memcheck

vector.memcheck:                                  ; preds = %vector.scevcheck
  %scevgep = getelementptr i8, ptr %14, i64 8
  %scevgep71 = getelementptr i8, ptr %12, i64 4
  %32 = shl nsw i64 %15, 3
  %33 = add nsw i64 %32, -8
  %scevgep72 = getelementptr i8, ptr %.unpack, i64 %33
  %34 = shl nsw i64 %16, 3
  %35 = add nsw i64 %34, 8
  %.not = icmp eq i64 %18, 0
  %36 = select i1 %.not, i64 %35, i64 %34
  %scevgep74 = getelementptr i8, ptr %.unpack, i64 %36
  %bound0 = icmp ult ptr %14, %scevgep71
  %bound1 = icmp ult ptr %12, %scevgep
  %found.conflict = and i1 %bound0, %bound1
  %bound075 = icmp ult ptr %14, %scevgep74
  %bound176 = icmp ult ptr %scevgep72, %scevgep
  %found.conflict77 = and i1 %bound075, %bound176
  %conflict.rdx = or i1 %found.conflict, %found.conflict77
  %bound078 = icmp ult ptr %12, %scevgep74
  %bound179 = icmp ult ptr %scevgep72, %scevgep71
  %found.conflict80 = and i1 %bound078, %bound179
  %conflict.rdx81 = or i1 %conflict.rdx, %found.conflict80
  br i1 %conflict.rdx81, label %.lr.ph8.i, label %vector.ph

vector.ph:                                        ; preds = %vector.memcheck
  %n.vec = and i64 %22, -2
  %ind.end = sub nsw i64 %18, %n.vec
  %.cast = trunc i64 %n.vec to i32
  %ind.end83 = add i32 %6, %.cast
  br label %vector.body

vector.body:                                      ; preds = %vector.body, %vector.ph
  %index = phi i64 [ 0, %vector.ph ], [ %index.next, %vector.body ]
  %.cast85 = trunc i64 %index to i32
  %offset.idx = add i32 %6, %.cast85
  %37 = load i32, ptr %12, align 4, !tbaa !4, !alias.scope !10, !noalias !13
  %broadcast.splatinsert = insertelement <2 x i32> poison, i32 %37, i64 0
  %38 = sitofp <2 x i32> %broadcast.splatinsert to <2 x float>
  %39 = fdiv contract <2 x float> <float 1.000000e+00, float poison>, %38
  %40 = shufflevector <2 x float> %39, <2 x float> poison, <2 x i32> zeroinitializer
  %41 = fpext <2 x float> %40 to <2 x double>
  %42 = sext i32 %offset.idx to i64
  %43 = add nsw i64 %42, -1
  %44 = getelementptr double, ptr %.unpack, i64 %43
  store <2 x double> %41, ptr %44, align 8, !tbaa !4, !alias.scope !13
  %45 = extractelement <2 x double> %41, i64 1
  store double %45, ptr %14, align 8, !tbaa !4, !alias.scope !15, !noalias !17
  %index.next = add nuw i64 %index, 2
  %46 = icmp eq i64 %index.next, %n.vec
  br i1 %46, label %middle.block, label %vector.body, !llvm.loop !18

middle.block:                                     ; preds = %vector.body
  %cmp.n = icmp eq i64 %22, %n.vec
  br i1 %cmp.n, label %_QFPloop.exit, label %.lr.ph8.i

.lr.ph8.i:                                        ; preds = %middle.block, %.lr.ph8.preheader.i, %vector.scevcheck, %vector.memcheck, %.lr.ph8.i
  %47 = phi i64 [ %57, %.lr.ph8.i ], [ %ind.end, %middle.block ], [ %18, %.lr.ph8.preheader.i ], [ %18, %vector.scevcheck ], [ %18, %vector.memcheck ]
  %48 = phi i32 [ %56, %.lr.ph8.i ], [ %ind.end83, %middle.block ], [ %6, %.lr.ph8.preheader.i ], [ %6, %vector.scevcheck ], [ %6, %vector.memcheck ]
  %49 = load i32, ptr %12, align 4, !tbaa !4
  %50 = sitofp i32 %49 to float
  %51 = fdiv contract float 1.000000e+00, %50
  %52 = fpext float %51 to double
  %53 = sext i32 %48 to i64
  %54 = add nsw i64 %53, -1
  %55 = getelementptr double, ptr %.unpack, i64 %54
  store double %52, ptr %55, align 8, !tbaa !4
  store double %52, ptr %14, align 8, !tbaa !4
  %56 = add i32 %48, 1
  %57 = add nsw i64 %47, -1
  %58 = icmp ugt i64 %47, 1
  br i1 %58, label %.lr.ph8.i, label %_QFPloop.exit, !llvm.loop !21

_QFPloop.exit:                                    ; preds = %middle.block, %.lr.ph8.i, %omp.par.entry
  ret void
}
*** IR Dump After LoopUnrollPass on _QFPomp_subroutine..omp_par ***
; Function Attrs: norecurse nounwind
define internal void @_QFPomp_subroutine..omp_par(ptr noalias nocapture readnone %tid.addr, ptr noalias nocapture readnone %zero.addr, ptr nocapture readonly %0) #3 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %gep_3 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 2
  %loadgep_4 = load ptr, ptr %gep_3, align 8
  %gep_5 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 3
  %loadgep_6 = load ptr, ptr %gep_5, align 8
  %gep_7 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 4
  %loadgep_8 = load ptr, ptr %gep_7, align 8
  %1 = tail call i32 @omp_get_thread_num()
  %2 = tail call i32 @omp_get_num_threads()
  %3 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %4 = sdiv i32 %3, %2
  %5 = mul i32 %4, %1
  %6 = add i32 %5, 1
  %7 = add i32 %2, -1
  %8 = icmp eq i32 %1, %7
  %9 = add i32 %6, %4
  %spec.select = select i1 %8, i32 %3, i32 %9
  %.unpack = load ptr, ptr %loadgep_2, align 8, !tbaa !8
  %.elt14 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  %.unpack15 = load i64, ptr %.elt14, align 8, !tbaa !8
  %.elt16 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  %.unpack17 = load i32, ptr %.elt16, align 8, !tbaa !8
  %.elt18 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  %.unpack19 = load i8, ptr %.elt18, align 4, !tbaa !8
  %.elt20 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  %.unpack21 = load i8, ptr %.elt20, align 1, !tbaa !8
  %.elt22 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  %.unpack23 = load i8, ptr %.elt22, align 2, !tbaa !8
  %.elt24 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  %.unpack25 = load i8, ptr %.elt24, align 1, !tbaa !8
  %.elt26 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  %.unpack27.unpack.unpack = load i64, ptr %.elt26, align 8, !tbaa !8
  %.unpack27.unpack.elt29 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  %.unpack27.unpack.unpack30 = load i64, ptr %.unpack27.unpack.elt29, align 8, !tbaa !8
  %.unpack27.unpack.elt31 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  %.unpack27.unpack.unpack32 = load i64, ptr %.unpack27.unpack.elt31, align 8, !tbaa !8
  store ptr %.unpack, ptr %loadgep_4, align 8, !tbaa !8
  %loadgep_4.repack34 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 1
  store i64 %.unpack15, ptr %loadgep_4.repack34, align 8, !tbaa !8
  %loadgep_4.repack36 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 2
  store i32 %.unpack17, ptr %loadgep_4.repack36, align 8, !tbaa !8
  %loadgep_4.repack38 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 3
  store i8 %.unpack19, ptr %loadgep_4.repack38, align 4, !tbaa !8
  %loadgep_4.repack40 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 4
  store i8 %.unpack21, ptr %loadgep_4.repack40, align 1, !tbaa !8
  %loadgep_4.repack42 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 5
  store i8 %.unpack23, ptr %loadgep_4.repack42, align 2, !tbaa !8
  %loadgep_4.repack44 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 6
  store i8 %.unpack25, ptr %loadgep_4.repack44, align 1, !tbaa !8
  %loadgep_4.repack46 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7
  store i64 %.unpack27.unpack.unpack, ptr %loadgep_4.repack46, align 8, !tbaa !8
  %loadgep_4.repack46.repack48 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack27.unpack.unpack30, ptr %loadgep_4.repack46.repack48, align 8, !tbaa !8
  %loadgep_4.repack46.repack50 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 2
  store i64 %.unpack27.unpack.unpack32, ptr %loadgep_4.repack46.repack50, align 8, !tbaa !8
  %10 = icmp eq i64 %.unpack27.unpack.unpack30, 0
  %11 = select i1 %10, i64 1, i64 %.unpack27.unpack.unpack
  store ptr %.unpack, ptr %loadgep_6, align 8, !tbaa !8
  %loadgep_6.repack52 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 1
  store i64 8, ptr %loadgep_6.repack52, align 8, !tbaa !8
  %loadgep_6.repack54 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 2
  store i32 20180515, ptr %loadgep_6.repack54, align 8, !tbaa !8
  %loadgep_6.repack56 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 3
  store i8 1, ptr %loadgep_6.repack56, align 4, !tbaa !8
  %loadgep_6.repack58 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 4
  store i8 28, ptr %loadgep_6.repack58, align 1, !tbaa !8
  %loadgep_6.repack60 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 5
  store i8 0, ptr %loadgep_6.repack60, align 2, !tbaa !8
  %loadgep_6.repack62 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 6
  store i8 0, ptr %loadgep_6.repack62, align 1, !tbaa !8
  %loadgep_6.repack64 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7
  store i64 %11, ptr %loadgep_6.repack64, align 8, !tbaa !8
  %loadgep_6.repack64.repack66 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack27.unpack.unpack30, ptr %loadgep_6.repack64.repack66, align 8, !tbaa !8
  %loadgep_6.repack64.repack68 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7, i64 0, i64 2
  store i64 8, ptr %loadgep_6.repack64.repack68, align 8, !tbaa !8
  %12 = load ptr, ptr %loadgep_8, align 8, !tbaa !4
  %13 = getelementptr { ptr, ptr }, ptr %loadgep_8, i64 0, i32 1
  %14 = load ptr, ptr %13, align 8, !tbaa !4
  %15 = sext i32 %6 to i64
  %16 = sext i32 %spec.select to i64
  %reass.sub9.i = sub nsw i64 %16, %15
  %17 = icmp sgt i64 %reass.sub9.i, -1
  br i1 %17, label %.lr.ph8.preheader.i, label %_QFPloop.exit

.lr.ph8.preheader.i:                              ; preds = %omp.par.entry
  %18 = add nsw i64 %reass.sub9.i, 1
  %19 = add nsw i64 %16, 2
  %20 = icmp ne i64 %18, 0
  %umin82.neg = sext i1 %20 to i64
  %21 = add nsw i64 %19, %umin82.neg
  %22 = sub nsw i64 %21, %15
  %min.iters.check = icmp ult i64 %22, 8
  br i1 %min.iters.check, label %.lr.ph8.i.preheader, label %vector.scevcheck

vector.scevcheck:                                 ; preds = %.lr.ph8.preheader.i
  %23 = add nsw i64 %16, 1
  %24 = icmp ne i64 %18, 0
  %umin.neg = sext i1 %24 to i64
  %25 = add nsw i64 %23, %umin.neg
  %26 = sub nsw i64 %25, %15
  %27 = trunc i64 %26 to i32
  %28 = add i32 %6, %27
  %29 = icmp slt i32 %28, %6
  %30 = icmp ugt i64 %26, 4294967295
  %31 = or i1 %29, %30
  br i1 %31, label %.lr.ph8.i.preheader, label %vector.memcheck

vector.memcheck:                                  ; preds = %vector.scevcheck
  %scevgep = getelementptr i8, ptr %14, i64 8
  %scevgep71 = getelementptr i8, ptr %12, i64 4
  %32 = shl nsw i64 %15, 3
  %33 = add nsw i64 %32, -8
  %scevgep72 = getelementptr i8, ptr %.unpack, i64 %33
  %34 = shl nsw i64 %16, 3
  %35 = add nsw i64 %34, 8
  %.not = icmp eq i64 %18, 0
  %36 = select i1 %.not, i64 %35, i64 %34
  %scevgep74 = getelementptr i8, ptr %.unpack, i64 %36
  %bound0 = icmp ult ptr %14, %scevgep71
  %bound1 = icmp ult ptr %12, %scevgep
  %found.conflict = and i1 %bound0, %bound1
  %bound075 = icmp ult ptr %14, %scevgep74
  %bound176 = icmp ult ptr %scevgep72, %scevgep
  %found.conflict77 = and i1 %bound075, %bound176
  %conflict.rdx = or i1 %found.conflict, %found.conflict77
  %bound078 = icmp ult ptr %12, %scevgep74
  %bound179 = icmp ult ptr %scevgep72, %scevgep71
  %found.conflict80 = and i1 %bound078, %bound179
  %conflict.rdx81 = or i1 %conflict.rdx, %found.conflict80
  br i1 %conflict.rdx81, label %.lr.ph8.i.preheader, label %vector.ph

vector.ph:                                        ; preds = %vector.memcheck
  %n.vec = and i64 %22, -2
  %ind.end = sub nsw i64 %18, %n.vec
  %.cast = trunc i64 %n.vec to i32
  %ind.end83 = add i32 %6, %.cast
  br label %vector.body

vector.body:                                      ; preds = %vector.body, %vector.ph
  %index = phi i64 [ 0, %vector.ph ], [ %index.next, %vector.body ]
  %.cast85 = trunc i64 %index to i32
  %offset.idx = add i32 %6, %.cast85
  %37 = load i32, ptr %12, align 4, !tbaa !4, !alias.scope !10, !noalias !13
  %broadcast.splatinsert = insertelement <2 x i32> poison, i32 %37, i64 0
  %38 = sitofp <2 x i32> %broadcast.splatinsert to <2 x float>
  %39 = fdiv contract <2 x float> <float 1.000000e+00, float poison>, %38
  %40 = shufflevector <2 x float> %39, <2 x float> poison, <2 x i32> zeroinitializer
  %41 = fpext <2 x float> %40 to <2 x double>
  %42 = sext i32 %offset.idx to i64
  %43 = add nsw i64 %42, -1
  %44 = getelementptr double, ptr %.unpack, i64 %43
  store <2 x double> %41, ptr %44, align 8, !tbaa !4, !alias.scope !13
  %45 = extractelement <2 x double> %41, i64 1
  store double %45, ptr %14, align 8, !tbaa !4, !alias.scope !15, !noalias !17
  %index.next = add nuw i64 %index, 2
  %46 = icmp eq i64 %index.next, %n.vec
  br i1 %46, label %middle.block, label %vector.body, !llvm.loop !18

middle.block:                                     ; preds = %vector.body
  %cmp.n = icmp eq i64 %22, %n.vec
  br i1 %cmp.n, label %_QFPloop.exit, label %.lr.ph8.i.preheader

.lr.ph8.i.preheader:                              ; preds = %vector.memcheck, %vector.scevcheck, %.lr.ph8.preheader.i, %middle.block
  %.ph = phi i64 [ %18, %vector.memcheck ], [ %18, %vector.scevcheck ], [ %18, %.lr.ph8.preheader.i ], [ %ind.end, %middle.block ]
  %.ph86 = phi i32 [ %6, %vector.memcheck ], [ %6, %vector.scevcheck ], [ %6, %.lr.ph8.preheader.i ], [ %ind.end83, %middle.block ]
  br label %.lr.ph8.i

.lr.ph8.i:                                        ; preds = %.lr.ph8.i.preheader, %.lr.ph8.i
  %47 = phi i64 [ %57, %.lr.ph8.i ], [ %.ph, %.lr.ph8.i.preheader ]
  %48 = phi i32 [ %56, %.lr.ph8.i ], [ %.ph86, %.lr.ph8.i.preheader ]
  %49 = load i32, ptr %12, align 4, !tbaa !4
  %50 = sitofp i32 %49 to float
  %51 = fdiv contract float 1.000000e+00, %50
  %52 = fpext float %51 to double
  %53 = sext i32 %48 to i64
  %54 = add nsw i64 %53, -1
  %55 = getelementptr double, ptr %.unpack, i64 %54
  store double %52, ptr %55, align 8, !tbaa !4
  store double %52, ptr %14, align 8, !tbaa !4
  %56 = add i32 %48, 1
  %57 = add nsw i64 %47, -1
  %58 = icmp ugt i64 %47, 1
  br i1 %58, label %.lr.ph8.i, label %_QFPloop.exit.loopexit, !llvm.loop !21

_QFPloop.exit.loopexit:                           ; preds = %.lr.ph8.i
  br label %_QFPloop.exit

_QFPloop.exit:                                    ; preds = %_QFPloop.exit.loopexit, %middle.block, %omp.par.entry
  ret void
}
*** IR Dump After WarnMissedTransformationsPass on _QFPomp_subroutine..omp_par ***
; Function Attrs: norecurse nounwind
define internal void @_QFPomp_subroutine..omp_par(ptr noalias nocapture readnone %tid.addr, ptr noalias nocapture readnone %zero.addr, ptr nocapture readonly %0) #3 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %gep_3 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 2
  %loadgep_4 = load ptr, ptr %gep_3, align 8
  %gep_5 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 3
  %loadgep_6 = load ptr, ptr %gep_5, align 8
  %gep_7 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 4
  %loadgep_8 = load ptr, ptr %gep_7, align 8
  %1 = tail call i32 @omp_get_thread_num()
  %2 = tail call i32 @omp_get_num_threads()
  %3 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %4 = sdiv i32 %3, %2
  %5 = mul i32 %4, %1
  %6 = add i32 %5, 1
  %7 = add i32 %2, -1
  %8 = icmp eq i32 %1, %7
  %9 = add i32 %6, %4
  %spec.select = select i1 %8, i32 %3, i32 %9
  %.unpack = load ptr, ptr %loadgep_2, align 8, !tbaa !8
  %.elt14 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  %.unpack15 = load i64, ptr %.elt14, align 8, !tbaa !8
  %.elt16 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  %.unpack17 = load i32, ptr %.elt16, align 8, !tbaa !8
  %.elt18 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  %.unpack19 = load i8, ptr %.elt18, align 4, !tbaa !8
  %.elt20 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  %.unpack21 = load i8, ptr %.elt20, align 1, !tbaa !8
  %.elt22 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  %.unpack23 = load i8, ptr %.elt22, align 2, !tbaa !8
  %.elt24 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  %.unpack25 = load i8, ptr %.elt24, align 1, !tbaa !8
  %.elt26 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  %.unpack27.unpack.unpack = load i64, ptr %.elt26, align 8, !tbaa !8
  %.unpack27.unpack.elt29 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  %.unpack27.unpack.unpack30 = load i64, ptr %.unpack27.unpack.elt29, align 8, !tbaa !8
  %.unpack27.unpack.elt31 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  %.unpack27.unpack.unpack32 = load i64, ptr %.unpack27.unpack.elt31, align 8, !tbaa !8
  store ptr %.unpack, ptr %loadgep_4, align 8, !tbaa !8
  %loadgep_4.repack34 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 1
  store i64 %.unpack15, ptr %loadgep_4.repack34, align 8, !tbaa !8
  %loadgep_4.repack36 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 2
  store i32 %.unpack17, ptr %loadgep_4.repack36, align 8, !tbaa !8
  %loadgep_4.repack38 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 3
  store i8 %.unpack19, ptr %loadgep_4.repack38, align 4, !tbaa !8
  %loadgep_4.repack40 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 4
  store i8 %.unpack21, ptr %loadgep_4.repack40, align 1, !tbaa !8
  %loadgep_4.repack42 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 5
  store i8 %.unpack23, ptr %loadgep_4.repack42, align 2, !tbaa !8
  %loadgep_4.repack44 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 6
  store i8 %.unpack25, ptr %loadgep_4.repack44, align 1, !tbaa !8
  %loadgep_4.repack46 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7
  store i64 %.unpack27.unpack.unpack, ptr %loadgep_4.repack46, align 8, !tbaa !8
  %loadgep_4.repack46.repack48 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack27.unpack.unpack30, ptr %loadgep_4.repack46.repack48, align 8, !tbaa !8
  %loadgep_4.repack46.repack50 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 2
  store i64 %.unpack27.unpack.unpack32, ptr %loadgep_4.repack46.repack50, align 8, !tbaa !8
  %10 = icmp eq i64 %.unpack27.unpack.unpack30, 0
  %11 = select i1 %10, i64 1, i64 %.unpack27.unpack.unpack
  store ptr %.unpack, ptr %loadgep_6, align 8, !tbaa !8
  %loadgep_6.repack52 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 1
  store i64 8, ptr %loadgep_6.repack52, align 8, !tbaa !8
  %loadgep_6.repack54 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 2
  store i32 20180515, ptr %loadgep_6.repack54, align 8, !tbaa !8
  %loadgep_6.repack56 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 3
  store i8 1, ptr %loadgep_6.repack56, align 4, !tbaa !8
  %loadgep_6.repack58 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 4
  store i8 28, ptr %loadgep_6.repack58, align 1, !tbaa !8
  %loadgep_6.repack60 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 5
  store i8 0, ptr %loadgep_6.repack60, align 2, !tbaa !8
  %loadgep_6.repack62 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 6
  store i8 0, ptr %loadgep_6.repack62, align 1, !tbaa !8
  %loadgep_6.repack64 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7
  store i64 %11, ptr %loadgep_6.repack64, align 8, !tbaa !8
  %loadgep_6.repack64.repack66 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack27.unpack.unpack30, ptr %loadgep_6.repack64.repack66, align 8, !tbaa !8
  %loadgep_6.repack64.repack68 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7, i64 0, i64 2
  store i64 8, ptr %loadgep_6.repack64.repack68, align 8, !tbaa !8
  %12 = load ptr, ptr %loadgep_8, align 8, !tbaa !4
  %13 = getelementptr { ptr, ptr }, ptr %loadgep_8, i64 0, i32 1
  %14 = load ptr, ptr %13, align 8, !tbaa !4
  %15 = sext i32 %6 to i64
  %16 = sext i32 %spec.select to i64
  %reass.sub9.i = sub nsw i64 %16, %15
  %17 = icmp sgt i64 %reass.sub9.i, -1
  br i1 %17, label %.lr.ph8.preheader.i, label %_QFPloop.exit

.lr.ph8.preheader.i:                              ; preds = %omp.par.entry
  %18 = add nsw i64 %reass.sub9.i, 1
  %19 = add nsw i64 %16, 2
  %20 = icmp ne i64 %18, 0
  %umin82.neg = sext i1 %20 to i64
  %21 = add nsw i64 %19, %umin82.neg
  %22 = sub nsw i64 %21, %15
  %min.iters.check = icmp ult i64 %22, 8
  br i1 %min.iters.check, label %.lr.ph8.i.preheader, label %vector.scevcheck

vector.scevcheck:                                 ; preds = %.lr.ph8.preheader.i
  %23 = add nsw i64 %16, 1
  %24 = icmp ne i64 %18, 0
  %umin.neg = sext i1 %24 to i64
  %25 = add nsw i64 %23, %umin.neg
  %26 = sub nsw i64 %25, %15
  %27 = trunc i64 %26 to i32
  %28 = add i32 %6, %27
  %29 = icmp slt i32 %28, %6
  %30 = icmp ugt i64 %26, 4294967295
  %31 = or i1 %29, %30
  br i1 %31, label %.lr.ph8.i.preheader, label %vector.memcheck

vector.memcheck:                                  ; preds = %vector.scevcheck
  %scevgep = getelementptr i8, ptr %14, i64 8
  %scevgep71 = getelementptr i8, ptr %12, i64 4
  %32 = shl nsw i64 %15, 3
  %33 = add nsw i64 %32, -8
  %scevgep72 = getelementptr i8, ptr %.unpack, i64 %33
  %34 = shl nsw i64 %16, 3
  %35 = add nsw i64 %34, 8
  %.not = icmp eq i64 %18, 0
  %36 = select i1 %.not, i64 %35, i64 %34
  %scevgep74 = getelementptr i8, ptr %.unpack, i64 %36
  %bound0 = icmp ult ptr %14, %scevgep71
  %bound1 = icmp ult ptr %12, %scevgep
  %found.conflict = and i1 %bound0, %bound1
  %bound075 = icmp ult ptr %14, %scevgep74
  %bound176 = icmp ult ptr %scevgep72, %scevgep
  %found.conflict77 = and i1 %bound075, %bound176
  %conflict.rdx = or i1 %found.conflict, %found.conflict77
  %bound078 = icmp ult ptr %12, %scevgep74
  %bound179 = icmp ult ptr %scevgep72, %scevgep71
  %found.conflict80 = and i1 %bound078, %bound179
  %conflict.rdx81 = or i1 %conflict.rdx, %found.conflict80
  br i1 %conflict.rdx81, label %.lr.ph8.i.preheader, label %vector.ph

vector.ph:                                        ; preds = %vector.memcheck
  %n.vec = and i64 %22, -2
  %ind.end = sub nsw i64 %18, %n.vec
  %.cast = trunc i64 %n.vec to i32
  %ind.end83 = add i32 %6, %.cast
  br label %vector.body

vector.body:                                      ; preds = %vector.body, %vector.ph
  %index = phi i64 [ 0, %vector.ph ], [ %index.next, %vector.body ]
  %.cast85 = trunc i64 %index to i32
  %offset.idx = add i32 %6, %.cast85
  %37 = load i32, ptr %12, align 4, !tbaa !4, !alias.scope !10, !noalias !13
  %broadcast.splatinsert = insertelement <2 x i32> poison, i32 %37, i64 0
  %38 = sitofp <2 x i32> %broadcast.splatinsert to <2 x float>
  %39 = fdiv contract <2 x float> <float 1.000000e+00, float poison>, %38
  %40 = shufflevector <2 x float> %39, <2 x float> poison, <2 x i32> zeroinitializer
  %41 = fpext <2 x float> %40 to <2 x double>
  %42 = sext i32 %offset.idx to i64
  %43 = add nsw i64 %42, -1
  %44 = getelementptr double, ptr %.unpack, i64 %43
  store <2 x double> %41, ptr %44, align 8, !tbaa !4, !alias.scope !13
  %45 = extractelement <2 x double> %41, i64 1
  store double %45, ptr %14, align 8, !tbaa !4, !alias.scope !15, !noalias !17
  %index.next = add nuw i64 %index, 2
  %46 = icmp eq i64 %index.next, %n.vec
  br i1 %46, label %middle.block, label %vector.body, !llvm.loop !18

middle.block:                                     ; preds = %vector.body
  %cmp.n = icmp eq i64 %22, %n.vec
  br i1 %cmp.n, label %_QFPloop.exit, label %.lr.ph8.i.preheader

.lr.ph8.i.preheader:                              ; preds = %vector.memcheck, %vector.scevcheck, %.lr.ph8.preheader.i, %middle.block
  %.ph = phi i64 [ %18, %vector.memcheck ], [ %18, %vector.scevcheck ], [ %18, %.lr.ph8.preheader.i ], [ %ind.end, %middle.block ]
  %.ph86 = phi i32 [ %6, %vector.memcheck ], [ %6, %vector.scevcheck ], [ %6, %.lr.ph8.preheader.i ], [ %ind.end83, %middle.block ]
  br label %.lr.ph8.i

.lr.ph8.i:                                        ; preds = %.lr.ph8.i.preheader, %.lr.ph8.i
  %47 = phi i64 [ %57, %.lr.ph8.i ], [ %.ph, %.lr.ph8.i.preheader ]
  %48 = phi i32 [ %56, %.lr.ph8.i ], [ %.ph86, %.lr.ph8.i.preheader ]
  %49 = load i32, ptr %12, align 4, !tbaa !4
  %50 = sitofp i32 %49 to float
  %51 = fdiv contract float 1.000000e+00, %50
  %52 = fpext float %51 to double
  %53 = sext i32 %48 to i64
  %54 = add nsw i64 %53, -1
  %55 = getelementptr double, ptr %.unpack, i64 %54
  store double %52, ptr %55, align 8, !tbaa !4
  store double %52, ptr %14, align 8, !tbaa !4
  %56 = add i32 %48, 1
  %57 = add nsw i64 %47, -1
  %58 = icmp ugt i64 %47, 1
  br i1 %58, label %.lr.ph8.i, label %_QFPloop.exit.loopexit, !llvm.loop !21

_QFPloop.exit.loopexit:                           ; preds = %.lr.ph8.i
  br label %_QFPloop.exit

_QFPloop.exit:                                    ; preds = %_QFPloop.exit.loopexit, %middle.block, %omp.par.entry
  ret void
}
*** IR Dump After SROAPass on _QFPomp_subroutine..omp_par ***
; Function Attrs: norecurse nounwind
define internal void @_QFPomp_subroutine..omp_par(ptr noalias nocapture readnone %tid.addr, ptr noalias nocapture readnone %zero.addr, ptr nocapture readonly %0) #3 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %gep_3 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 2
  %loadgep_4 = load ptr, ptr %gep_3, align 8
  %gep_5 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 3
  %loadgep_6 = load ptr, ptr %gep_5, align 8
  %gep_7 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 4
  %loadgep_8 = load ptr, ptr %gep_7, align 8
  %1 = tail call i32 @omp_get_thread_num()
  %2 = tail call i32 @omp_get_num_threads()
  %3 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %4 = sdiv i32 %3, %2
  %5 = mul i32 %4, %1
  %6 = add i32 %5, 1
  %7 = add i32 %2, -1
  %8 = icmp eq i32 %1, %7
  %9 = add i32 %6, %4
  %spec.select = select i1 %8, i32 %3, i32 %9
  %.unpack = load ptr, ptr %loadgep_2, align 8, !tbaa !8
  %.elt14 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  %.unpack15 = load i64, ptr %.elt14, align 8, !tbaa !8
  %.elt16 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  %.unpack17 = load i32, ptr %.elt16, align 8, !tbaa !8
  %.elt18 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  %.unpack19 = load i8, ptr %.elt18, align 4, !tbaa !8
  %.elt20 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  %.unpack21 = load i8, ptr %.elt20, align 1, !tbaa !8
  %.elt22 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  %.unpack23 = load i8, ptr %.elt22, align 2, !tbaa !8
  %.elt24 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  %.unpack25 = load i8, ptr %.elt24, align 1, !tbaa !8
  %.elt26 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  %.unpack27.unpack.unpack = load i64, ptr %.elt26, align 8, !tbaa !8
  %.unpack27.unpack.elt29 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  %.unpack27.unpack.unpack30 = load i64, ptr %.unpack27.unpack.elt29, align 8, !tbaa !8
  %.unpack27.unpack.elt31 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  %.unpack27.unpack.unpack32 = load i64, ptr %.unpack27.unpack.elt31, align 8, !tbaa !8
  store ptr %.unpack, ptr %loadgep_4, align 8, !tbaa !8
  %loadgep_4.repack34 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 1
  store i64 %.unpack15, ptr %loadgep_4.repack34, align 8, !tbaa !8
  %loadgep_4.repack36 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 2
  store i32 %.unpack17, ptr %loadgep_4.repack36, align 8, !tbaa !8
  %loadgep_4.repack38 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 3
  store i8 %.unpack19, ptr %loadgep_4.repack38, align 4, !tbaa !8
  %loadgep_4.repack40 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 4
  store i8 %.unpack21, ptr %loadgep_4.repack40, align 1, !tbaa !8
  %loadgep_4.repack42 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 5
  store i8 %.unpack23, ptr %loadgep_4.repack42, align 2, !tbaa !8
  %loadgep_4.repack44 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 6
  store i8 %.unpack25, ptr %loadgep_4.repack44, align 1, !tbaa !8
  %loadgep_4.repack46 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7
  store i64 %.unpack27.unpack.unpack, ptr %loadgep_4.repack46, align 8, !tbaa !8
  %loadgep_4.repack46.repack48 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack27.unpack.unpack30, ptr %loadgep_4.repack46.repack48, align 8, !tbaa !8
  %loadgep_4.repack46.repack50 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 2
  store i64 %.unpack27.unpack.unpack32, ptr %loadgep_4.repack46.repack50, align 8, !tbaa !8
  %10 = icmp eq i64 %.unpack27.unpack.unpack30, 0
  %11 = select i1 %10, i64 1, i64 %.unpack27.unpack.unpack
  store ptr %.unpack, ptr %loadgep_6, align 8, !tbaa !8
  %loadgep_6.repack52 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 1
  store i64 8, ptr %loadgep_6.repack52, align 8, !tbaa !8
  %loadgep_6.repack54 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 2
  store i32 20180515, ptr %loadgep_6.repack54, align 8, !tbaa !8
  %loadgep_6.repack56 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 3
  store i8 1, ptr %loadgep_6.repack56, align 4, !tbaa !8
  %loadgep_6.repack58 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 4
  store i8 28, ptr %loadgep_6.repack58, align 1, !tbaa !8
  %loadgep_6.repack60 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 5
  store i8 0, ptr %loadgep_6.repack60, align 2, !tbaa !8
  %loadgep_6.repack62 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 6
  store i8 0, ptr %loadgep_6.repack62, align 1, !tbaa !8
  %loadgep_6.repack64 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7
  store i64 %11, ptr %loadgep_6.repack64, align 8, !tbaa !8
  %loadgep_6.repack64.repack66 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack27.unpack.unpack30, ptr %loadgep_6.repack64.repack66, align 8, !tbaa !8
  %loadgep_6.repack64.repack68 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7, i64 0, i64 2
  store i64 8, ptr %loadgep_6.repack64.repack68, align 8, !tbaa !8
  %12 = load ptr, ptr %loadgep_8, align 8, !tbaa !4
  %13 = getelementptr { ptr, ptr }, ptr %loadgep_8, i64 0, i32 1
  %14 = load ptr, ptr %13, align 8, !tbaa !4
  %15 = sext i32 %6 to i64
  %16 = sext i32 %spec.select to i64
  %reass.sub9.i = sub nsw i64 %16, %15
  %17 = icmp sgt i64 %reass.sub9.i, -1
  br i1 %17, label %.lr.ph8.preheader.i, label %_QFPloop.exit

.lr.ph8.preheader.i:                              ; preds = %omp.par.entry
  %18 = add nsw i64 %reass.sub9.i, 1
  %19 = add nsw i64 %16, 2
  %20 = icmp ne i64 %18, 0
  %umin82.neg = sext i1 %20 to i64
  %21 = add nsw i64 %19, %umin82.neg
  %22 = sub nsw i64 %21, %15
  %min.iters.check = icmp ult i64 %22, 8
  br i1 %min.iters.check, label %.lr.ph8.i.preheader, label %vector.scevcheck

vector.scevcheck:                                 ; preds = %.lr.ph8.preheader.i
  %23 = add nsw i64 %16, 1
  %24 = icmp ne i64 %18, 0
  %umin.neg = sext i1 %24 to i64
  %25 = add nsw i64 %23, %umin.neg
  %26 = sub nsw i64 %25, %15
  %27 = trunc i64 %26 to i32
  %28 = add i32 %6, %27
  %29 = icmp slt i32 %28, %6
  %30 = icmp ugt i64 %26, 4294967295
  %31 = or i1 %29, %30
  br i1 %31, label %.lr.ph8.i.preheader, label %vector.memcheck

vector.memcheck:                                  ; preds = %vector.scevcheck
  %scevgep = getelementptr i8, ptr %14, i64 8
  %scevgep71 = getelementptr i8, ptr %12, i64 4
  %32 = shl nsw i64 %15, 3
  %33 = add nsw i64 %32, -8
  %scevgep72 = getelementptr i8, ptr %.unpack, i64 %33
  %34 = shl nsw i64 %16, 3
  %35 = add nsw i64 %34, 8
  %.not = icmp eq i64 %18, 0
  %36 = select i1 %.not, i64 %35, i64 %34
  %scevgep74 = getelementptr i8, ptr %.unpack, i64 %36
  %bound0 = icmp ult ptr %14, %scevgep71
  %bound1 = icmp ult ptr %12, %scevgep
  %found.conflict = and i1 %bound0, %bound1
  %bound075 = icmp ult ptr %14, %scevgep74
  %bound176 = icmp ult ptr %scevgep72, %scevgep
  %found.conflict77 = and i1 %bound075, %bound176
  %conflict.rdx = or i1 %found.conflict, %found.conflict77
  %bound078 = icmp ult ptr %12, %scevgep74
  %bound179 = icmp ult ptr %scevgep72, %scevgep71
  %found.conflict80 = and i1 %bound078, %bound179
  %conflict.rdx81 = or i1 %conflict.rdx, %found.conflict80
  br i1 %conflict.rdx81, label %.lr.ph8.i.preheader, label %vector.ph

vector.ph:                                        ; preds = %vector.memcheck
  %n.vec = and i64 %22, -2
  %ind.end = sub nsw i64 %18, %n.vec
  %.cast = trunc i64 %n.vec to i32
  %ind.end83 = add i32 %6, %.cast
  br label %vector.body

vector.body:                                      ; preds = %vector.body, %vector.ph
  %index = phi i64 [ 0, %vector.ph ], [ %index.next, %vector.body ]
  %.cast85 = trunc i64 %index to i32
  %offset.idx = add i32 %6, %.cast85
  %37 = load i32, ptr %12, align 4, !tbaa !4, !alias.scope !10, !noalias !13
  %broadcast.splatinsert = insertelement <2 x i32> poison, i32 %37, i64 0
  %38 = sitofp <2 x i32> %broadcast.splatinsert to <2 x float>
  %39 = fdiv contract <2 x float> <float 1.000000e+00, float poison>, %38
  %40 = shufflevector <2 x float> %39, <2 x float> poison, <2 x i32> zeroinitializer
  %41 = fpext <2 x float> %40 to <2 x double>
  %42 = sext i32 %offset.idx to i64
  %43 = add nsw i64 %42, -1
  %44 = getelementptr double, ptr %.unpack, i64 %43
  store <2 x double> %41, ptr %44, align 8, !tbaa !4, !alias.scope !13
  %45 = extractelement <2 x double> %41, i64 1
  store double %45, ptr %14, align 8, !tbaa !4, !alias.scope !15, !noalias !17
  %index.next = add nuw i64 %index, 2
  %46 = icmp eq i64 %index.next, %n.vec
  br i1 %46, label %middle.block, label %vector.body, !llvm.loop !18

middle.block:                                     ; preds = %vector.body
  %cmp.n = icmp eq i64 %22, %n.vec
  br i1 %cmp.n, label %_QFPloop.exit, label %.lr.ph8.i.preheader

.lr.ph8.i.preheader:                              ; preds = %vector.memcheck, %vector.scevcheck, %.lr.ph8.preheader.i, %middle.block
  %.ph = phi i64 [ %18, %vector.memcheck ], [ %18, %vector.scevcheck ], [ %18, %.lr.ph8.preheader.i ], [ %ind.end, %middle.block ]
  %.ph86 = phi i32 [ %6, %vector.memcheck ], [ %6, %vector.scevcheck ], [ %6, %.lr.ph8.preheader.i ], [ %ind.end83, %middle.block ]
  br label %.lr.ph8.i

.lr.ph8.i:                                        ; preds = %.lr.ph8.i.preheader, %.lr.ph8.i
  %47 = phi i64 [ %57, %.lr.ph8.i ], [ %.ph, %.lr.ph8.i.preheader ]
  %48 = phi i32 [ %56, %.lr.ph8.i ], [ %.ph86, %.lr.ph8.i.preheader ]
  %49 = load i32, ptr %12, align 4, !tbaa !4
  %50 = sitofp i32 %49 to float
  %51 = fdiv contract float 1.000000e+00, %50
  %52 = fpext float %51 to double
  %53 = sext i32 %48 to i64
  %54 = add nsw i64 %53, -1
  %55 = getelementptr double, ptr %.unpack, i64 %54
  store double %52, ptr %55, align 8, !tbaa !4
  store double %52, ptr %14, align 8, !tbaa !4
  %56 = add i32 %48, 1
  %57 = add nsw i64 %47, -1
  %58 = icmp ugt i64 %47, 1
  br i1 %58, label %.lr.ph8.i, label %_QFPloop.exit.loopexit, !llvm.loop !21

_QFPloop.exit.loopexit:                           ; preds = %.lr.ph8.i
  br label %_QFPloop.exit

_QFPloop.exit:                                    ; preds = %_QFPloop.exit.loopexit, %middle.block, %omp.par.entry
  ret void
}
*** IR Dump After InstCombinePass on _QFPomp_subroutine..omp_par ***
; Function Attrs: norecurse nounwind
define internal void @_QFPomp_subroutine..omp_par(ptr noalias nocapture readnone %tid.addr, ptr noalias nocapture readnone %zero.addr, ptr nocapture readonly %0) #3 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %gep_3 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 2
  %loadgep_4 = load ptr, ptr %gep_3, align 8
  %gep_5 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 3
  %loadgep_6 = load ptr, ptr %gep_5, align 8
  %gep_7 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 4
  %loadgep_8 = load ptr, ptr %gep_7, align 8
  %1 = tail call i32 @omp_get_thread_num()
  %2 = tail call i32 @omp_get_num_threads()
  %3 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %4 = sdiv i32 %3, %2
  %5 = mul i32 %4, %1
  %6 = add i32 %5, 1
  %7 = add i32 %2, -1
  %8 = icmp eq i32 %1, %7
  %9 = add i32 %6, %4
  %spec.select = select i1 %8, i32 %3, i32 %9
  %.unpack = load ptr, ptr %loadgep_2, align 8, !tbaa !8
  %.elt14 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  %.unpack15 = load i64, ptr %.elt14, align 8, !tbaa !8
  %.elt16 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  %.unpack17 = load i32, ptr %.elt16, align 8, !tbaa !8
  %.elt18 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  %.unpack19 = load i8, ptr %.elt18, align 4, !tbaa !8
  %.elt20 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  %.unpack21 = load i8, ptr %.elt20, align 1, !tbaa !8
  %.elt22 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  %.unpack23 = load i8, ptr %.elt22, align 2, !tbaa !8
  %.elt24 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  %.unpack25 = load i8, ptr %.elt24, align 1, !tbaa !8
  %.elt26 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  %.unpack27.unpack.unpack = load i64, ptr %.elt26, align 8, !tbaa !8
  %.unpack27.unpack.elt29 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  %.unpack27.unpack.unpack30 = load i64, ptr %.unpack27.unpack.elt29, align 8, !tbaa !8
  %.unpack27.unpack.elt31 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  %.unpack27.unpack.unpack32 = load i64, ptr %.unpack27.unpack.elt31, align 8, !tbaa !8
  store ptr %.unpack, ptr %loadgep_4, align 8, !tbaa !8
  %loadgep_4.repack34 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 1
  store i64 %.unpack15, ptr %loadgep_4.repack34, align 8, !tbaa !8
  %loadgep_4.repack36 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 2
  store i32 %.unpack17, ptr %loadgep_4.repack36, align 8, !tbaa !8
  %loadgep_4.repack38 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 3
  store i8 %.unpack19, ptr %loadgep_4.repack38, align 4, !tbaa !8
  %loadgep_4.repack40 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 4
  store i8 %.unpack21, ptr %loadgep_4.repack40, align 1, !tbaa !8
  %loadgep_4.repack42 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 5
  store i8 %.unpack23, ptr %loadgep_4.repack42, align 2, !tbaa !8
  %loadgep_4.repack44 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 6
  store i8 %.unpack25, ptr %loadgep_4.repack44, align 1, !tbaa !8
  %loadgep_4.repack46 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7
  store i64 %.unpack27.unpack.unpack, ptr %loadgep_4.repack46, align 8, !tbaa !8
  %loadgep_4.repack46.repack48 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack27.unpack.unpack30, ptr %loadgep_4.repack46.repack48, align 8, !tbaa !8
  %loadgep_4.repack46.repack50 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 2
  store i64 %.unpack27.unpack.unpack32, ptr %loadgep_4.repack46.repack50, align 8, !tbaa !8
  %10 = icmp eq i64 %.unpack27.unpack.unpack30, 0
  %11 = select i1 %10, i64 1, i64 %.unpack27.unpack.unpack
  store ptr %.unpack, ptr %loadgep_6, align 8, !tbaa !8
  %loadgep_6.repack52 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 1
  store i64 8, ptr %loadgep_6.repack52, align 8, !tbaa !8
  %loadgep_6.repack54 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 2
  store i32 20180515, ptr %loadgep_6.repack54, align 8, !tbaa !8
  %loadgep_6.repack56 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 3
  store i8 1, ptr %loadgep_6.repack56, align 4, !tbaa !8
  %loadgep_6.repack58 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 4
  store i8 28, ptr %loadgep_6.repack58, align 1, !tbaa !8
  %loadgep_6.repack60 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 5
  store i8 0, ptr %loadgep_6.repack60, align 2, !tbaa !8
  %loadgep_6.repack62 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 6
  store i8 0, ptr %loadgep_6.repack62, align 1, !tbaa !8
  %loadgep_6.repack64 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7
  store i64 %11, ptr %loadgep_6.repack64, align 8, !tbaa !8
  %loadgep_6.repack64.repack66 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack27.unpack.unpack30, ptr %loadgep_6.repack64.repack66, align 8, !tbaa !8
  %loadgep_6.repack64.repack68 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7, i64 0, i64 2
  store i64 8, ptr %loadgep_6.repack64.repack68, align 8, !tbaa !8
  %12 = load ptr, ptr %loadgep_8, align 8, !tbaa !4
  %13 = getelementptr { ptr, ptr }, ptr %loadgep_8, i64 0, i32 1
  %14 = load ptr, ptr %13, align 8, !tbaa !4
  %15 = sext i32 %6 to i64
  %16 = sext i32 %spec.select to i64
  %reass.sub9.i = sub nsw i64 %16, %15
  %17 = icmp sgt i64 %reass.sub9.i, -1
  br i1 %17, label %.lr.ph8.preheader.i, label %_QFPloop.exit

.lr.ph8.preheader.i:                              ; preds = %omp.par.entry
  %18 = add nsw i64 %reass.sub9.i, 1
  %19 = add nsw i64 %16, 2
  %20 = icmp ne i64 %18, 0
  %umin82.neg = sext i1 %20 to i64
  %21 = add nsw i64 %19, %umin82.neg
  %22 = sub nsw i64 %21, %15
  %min.iters.check = icmp ult i64 %22, 8
  br i1 %min.iters.check, label %.lr.ph8.i.preheader, label %vector.scevcheck

vector.scevcheck:                                 ; preds = %.lr.ph8.preheader.i
  %23 = add nsw i64 %16, 1
  %24 = icmp ne i64 %18, 0
  %umin.neg = sext i1 %24 to i64
  %25 = add nsw i64 %23, %umin.neg
  %26 = sub nsw i64 %25, %15
  %27 = trunc i64 %26 to i32
  %28 = add i32 %6, %27
  %29 = icmp slt i32 %28, %6
  %30 = icmp ugt i64 %26, 4294967295
  %31 = or i1 %29, %30
  br i1 %31, label %.lr.ph8.i.preheader, label %vector.memcheck

vector.memcheck:                                  ; preds = %vector.scevcheck
  %scevgep = getelementptr i8, ptr %14, i64 8
  %scevgep71 = getelementptr i8, ptr %12, i64 4
  %32 = shl nsw i64 %15, 3
  %33 = add nsw i64 %32, -8
  %scevgep72 = getelementptr i8, ptr %.unpack, i64 %33
  %34 = shl nsw i64 %16, 3
  %35 = add nsw i64 %34, 8
  %.not = icmp eq i64 %18, 0
  %36 = select i1 %.not, i64 %35, i64 %34
  %scevgep74 = getelementptr i8, ptr %.unpack, i64 %36
  %bound0 = icmp ult ptr %14, %scevgep71
  %bound1 = icmp ult ptr %12, %scevgep
  %found.conflict = and i1 %bound0, %bound1
  %bound075 = icmp ult ptr %14, %scevgep74
  %bound176 = icmp ult ptr %scevgep72, %scevgep
  %found.conflict77 = and i1 %bound075, %bound176
  %conflict.rdx = or i1 %found.conflict, %found.conflict77
  %bound078 = icmp ult ptr %12, %scevgep74
  %bound179 = icmp ult ptr %scevgep72, %scevgep71
  %found.conflict80 = and i1 %bound078, %bound179
  %conflict.rdx81 = or i1 %conflict.rdx, %found.conflict80
  br i1 %conflict.rdx81, label %.lr.ph8.i.preheader, label %vector.ph

vector.ph:                                        ; preds = %vector.memcheck
  %n.vec = and i64 %22, -2
  %ind.end = sub nsw i64 %18, %n.vec
  %.cast = trunc i64 %n.vec to i32
  %ind.end83 = add i32 %6, %.cast
  br label %vector.body

vector.body:                                      ; preds = %vector.body, %vector.ph
  %index = phi i64 [ 0, %vector.ph ], [ %index.next, %vector.body ]
  %.cast85 = trunc i64 %index to i32
  %offset.idx = add i32 %6, %.cast85
  %37 = load i32, ptr %12, align 4, !tbaa !4, !alias.scope !10, !noalias !13
  %broadcast.splatinsert = insertelement <2 x i32> poison, i32 %37, i64 0
  %38 = sitofp <2 x i32> %broadcast.splatinsert to <2 x float>
  %39 = fdiv contract <2 x float> <float 1.000000e+00, float poison>, %38
  %40 = shufflevector <2 x float> %39, <2 x float> poison, <2 x i32> zeroinitializer
  %41 = fpext <2 x float> %40 to <2 x double>
  %42 = sext i32 %offset.idx to i64
  %43 = add nsw i64 %42, -1
  %44 = getelementptr double, ptr %.unpack, i64 %43
  store <2 x double> %41, ptr %44, align 8, !tbaa !4, !alias.scope !13
  %45 = extractelement <2 x double> %41, i64 1
  store double %45, ptr %14, align 8, !tbaa !4, !alias.scope !15, !noalias !17
  %index.next = add nuw i64 %index, 2
  %46 = icmp eq i64 %index.next, %n.vec
  br i1 %46, label %middle.block, label %vector.body, !llvm.loop !18

middle.block:                                     ; preds = %vector.body
  %cmp.n = icmp eq i64 %22, %n.vec
  br i1 %cmp.n, label %_QFPloop.exit, label %.lr.ph8.i.preheader

.lr.ph8.i.preheader:                              ; preds = %vector.memcheck, %vector.scevcheck, %.lr.ph8.preheader.i, %middle.block
  %.ph = phi i64 [ %18, %vector.memcheck ], [ %18, %vector.scevcheck ], [ %18, %.lr.ph8.preheader.i ], [ %ind.end, %middle.block ]
  %.ph86 = phi i32 [ %6, %vector.memcheck ], [ %6, %vector.scevcheck ], [ %6, %.lr.ph8.preheader.i ], [ %ind.end83, %middle.block ]
  br label %.lr.ph8.i

.lr.ph8.i:                                        ; preds = %.lr.ph8.i.preheader, %.lr.ph8.i
  %47 = phi i64 [ %57, %.lr.ph8.i ], [ %.ph, %.lr.ph8.i.preheader ]
  %48 = phi i32 [ %56, %.lr.ph8.i ], [ %.ph86, %.lr.ph8.i.preheader ]
  %49 = load i32, ptr %12, align 4, !tbaa !4
  %50 = sitofp i32 %49 to float
  %51 = fdiv contract float 1.000000e+00, %50
  %52 = fpext float %51 to double
  %53 = sext i32 %48 to i64
  %54 = add nsw i64 %53, -1
  %55 = getelementptr double, ptr %.unpack, i64 %54
  store double %52, ptr %55, align 8, !tbaa !4
  store double %52, ptr %14, align 8, !tbaa !4
  %56 = add i32 %48, 1
  %57 = add nsw i64 %47, -1
  %58 = icmp ugt i64 %47, 1
  br i1 %58, label %.lr.ph8.i, label %_QFPloop.exit.loopexit, !llvm.loop !21

_QFPloop.exit.loopexit:                           ; preds = %.lr.ph8.i
  br label %_QFPloop.exit

_QFPloop.exit:                                    ; preds = %_QFPloop.exit.loopexit, %middle.block, %omp.par.entry
  ret void
}
*** IR Dump After LoopSimplifyPass on _QFPomp_subroutine..omp_par ***
; Function Attrs: norecurse nounwind
define internal void @_QFPomp_subroutine..omp_par(ptr noalias nocapture readnone %tid.addr, ptr noalias nocapture readnone %zero.addr, ptr nocapture readonly %0) #3 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %gep_3 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 2
  %loadgep_4 = load ptr, ptr %gep_3, align 8
  %gep_5 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 3
  %loadgep_6 = load ptr, ptr %gep_5, align 8
  %gep_7 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 4
  %loadgep_8 = load ptr, ptr %gep_7, align 8
  %1 = tail call i32 @omp_get_thread_num()
  %2 = tail call i32 @omp_get_num_threads()
  %3 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %4 = sdiv i32 %3, %2
  %5 = mul i32 %4, %1
  %6 = add i32 %5, 1
  %7 = add i32 %2, -1
  %8 = icmp eq i32 %1, %7
  %9 = add i32 %6, %4
  %spec.select = select i1 %8, i32 %3, i32 %9
  %.unpack = load ptr, ptr %loadgep_2, align 8, !tbaa !8
  %.elt14 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  %.unpack15 = load i64, ptr %.elt14, align 8, !tbaa !8
  %.elt16 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  %.unpack17 = load i32, ptr %.elt16, align 8, !tbaa !8
  %.elt18 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  %.unpack19 = load i8, ptr %.elt18, align 4, !tbaa !8
  %.elt20 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  %.unpack21 = load i8, ptr %.elt20, align 1, !tbaa !8
  %.elt22 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  %.unpack23 = load i8, ptr %.elt22, align 2, !tbaa !8
  %.elt24 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  %.unpack25 = load i8, ptr %.elt24, align 1, !tbaa !8
  %.elt26 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  %.unpack27.unpack.unpack = load i64, ptr %.elt26, align 8, !tbaa !8
  %.unpack27.unpack.elt29 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  %.unpack27.unpack.unpack30 = load i64, ptr %.unpack27.unpack.elt29, align 8, !tbaa !8
  %.unpack27.unpack.elt31 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  %.unpack27.unpack.unpack32 = load i64, ptr %.unpack27.unpack.elt31, align 8, !tbaa !8
  store ptr %.unpack, ptr %loadgep_4, align 8, !tbaa !8
  %loadgep_4.repack34 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 1
  store i64 %.unpack15, ptr %loadgep_4.repack34, align 8, !tbaa !8
  %loadgep_4.repack36 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 2
  store i32 %.unpack17, ptr %loadgep_4.repack36, align 8, !tbaa !8
  %loadgep_4.repack38 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 3
  store i8 %.unpack19, ptr %loadgep_4.repack38, align 4, !tbaa !8
  %loadgep_4.repack40 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 4
  store i8 %.unpack21, ptr %loadgep_4.repack40, align 1, !tbaa !8
  %loadgep_4.repack42 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 5
  store i8 %.unpack23, ptr %loadgep_4.repack42, align 2, !tbaa !8
  %loadgep_4.repack44 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 6
  store i8 %.unpack25, ptr %loadgep_4.repack44, align 1, !tbaa !8
  %loadgep_4.repack46 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7
  store i64 %.unpack27.unpack.unpack, ptr %loadgep_4.repack46, align 8, !tbaa !8
  %loadgep_4.repack46.repack48 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack27.unpack.unpack30, ptr %loadgep_4.repack46.repack48, align 8, !tbaa !8
  %loadgep_4.repack46.repack50 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 2
  store i64 %.unpack27.unpack.unpack32, ptr %loadgep_4.repack46.repack50, align 8, !tbaa !8
  %10 = icmp eq i64 %.unpack27.unpack.unpack30, 0
  %11 = select i1 %10, i64 1, i64 %.unpack27.unpack.unpack
  store ptr %.unpack, ptr %loadgep_6, align 8, !tbaa !8
  %loadgep_6.repack52 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 1
  store i64 8, ptr %loadgep_6.repack52, align 8, !tbaa !8
  %loadgep_6.repack54 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 2
  store i32 20180515, ptr %loadgep_6.repack54, align 8, !tbaa !8
  %loadgep_6.repack56 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 3
  store i8 1, ptr %loadgep_6.repack56, align 4, !tbaa !8
  %loadgep_6.repack58 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 4
  store i8 28, ptr %loadgep_6.repack58, align 1, !tbaa !8
  %loadgep_6.repack60 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 5
  store i8 0, ptr %loadgep_6.repack60, align 2, !tbaa !8
  %loadgep_6.repack62 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 6
  store i8 0, ptr %loadgep_6.repack62, align 1, !tbaa !8
  %loadgep_6.repack64 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7
  store i64 %11, ptr %loadgep_6.repack64, align 8, !tbaa !8
  %loadgep_6.repack64.repack66 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack27.unpack.unpack30, ptr %loadgep_6.repack64.repack66, align 8, !tbaa !8
  %loadgep_6.repack64.repack68 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7, i64 0, i64 2
  store i64 8, ptr %loadgep_6.repack64.repack68, align 8, !tbaa !8
  %12 = load ptr, ptr %loadgep_8, align 8, !tbaa !4
  %13 = getelementptr { ptr, ptr }, ptr %loadgep_8, i64 0, i32 1
  %14 = load ptr, ptr %13, align 8, !tbaa !4
  %15 = sext i32 %6 to i64
  %16 = sext i32 %spec.select to i64
  %reass.sub9.i = sub nsw i64 %16, %15
  %17 = icmp sgt i64 %reass.sub9.i, -1
  br i1 %17, label %.lr.ph8.preheader.i, label %_QFPloop.exit

.lr.ph8.preheader.i:                              ; preds = %omp.par.entry
  %18 = add nsw i64 %reass.sub9.i, 1
  %19 = add nsw i64 %16, 2
  %20 = icmp ne i64 %18, 0
  %umin82.neg = sext i1 %20 to i64
  %21 = add nsw i64 %19, %umin82.neg
  %22 = sub nsw i64 %21, %15
  %min.iters.check = icmp ult i64 %22, 8
  br i1 %min.iters.check, label %.lr.ph8.i.preheader, label %vector.scevcheck

vector.scevcheck:                                 ; preds = %.lr.ph8.preheader.i
  %23 = add nsw i64 %16, 1
  %24 = icmp ne i64 %18, 0
  %umin.neg = sext i1 %24 to i64
  %25 = add nsw i64 %23, %umin.neg
  %26 = sub nsw i64 %25, %15
  %27 = trunc i64 %26 to i32
  %28 = add i32 %6, %27
  %29 = icmp slt i32 %28, %6
  %30 = icmp ugt i64 %26, 4294967295
  %31 = or i1 %29, %30
  br i1 %31, label %.lr.ph8.i.preheader, label %vector.memcheck

vector.memcheck:                                  ; preds = %vector.scevcheck
  %scevgep = getelementptr i8, ptr %14, i64 8
  %scevgep71 = getelementptr i8, ptr %12, i64 4
  %32 = shl nsw i64 %15, 3
  %33 = add nsw i64 %32, -8
  %scevgep72 = getelementptr i8, ptr %.unpack, i64 %33
  %34 = shl nsw i64 %16, 3
  %35 = add nsw i64 %34, 8
  %.not = icmp eq i64 %18, 0
  %36 = select i1 %.not, i64 %35, i64 %34
  %scevgep74 = getelementptr i8, ptr %.unpack, i64 %36
  %bound0 = icmp ult ptr %14, %scevgep71
  %bound1 = icmp ult ptr %12, %scevgep
  %found.conflict = and i1 %bound0, %bound1
  %bound075 = icmp ult ptr %14, %scevgep74
  %bound176 = icmp ult ptr %scevgep72, %scevgep
  %found.conflict77 = and i1 %bound075, %bound176
  %conflict.rdx = or i1 %found.conflict, %found.conflict77
  %bound078 = icmp ult ptr %12, %scevgep74
  %bound179 = icmp ult ptr %scevgep72, %scevgep71
  %found.conflict80 = and i1 %bound078, %bound179
  %conflict.rdx81 = or i1 %conflict.rdx, %found.conflict80
  br i1 %conflict.rdx81, label %.lr.ph8.i.preheader, label %vector.ph

vector.ph:                                        ; preds = %vector.memcheck
  %n.vec = and i64 %22, -2
  %ind.end = sub nsw i64 %18, %n.vec
  %.cast = trunc i64 %n.vec to i32
  %ind.end83 = add i32 %6, %.cast
  br label %vector.body

vector.body:                                      ; preds = %vector.body, %vector.ph
  %index = phi i64 [ 0, %vector.ph ], [ %index.next, %vector.body ]
  %.cast85 = trunc i64 %index to i32
  %offset.idx = add i32 %6, %.cast85
  %37 = load i32, ptr %12, align 4, !tbaa !4, !alias.scope !10, !noalias !13
  %broadcast.splatinsert = insertelement <2 x i32> poison, i32 %37, i64 0
  %38 = sitofp <2 x i32> %broadcast.splatinsert to <2 x float>
  %39 = fdiv contract <2 x float> <float 1.000000e+00, float poison>, %38
  %40 = shufflevector <2 x float> %39, <2 x float> poison, <2 x i32> zeroinitializer
  %41 = fpext <2 x float> %40 to <2 x double>
  %42 = sext i32 %offset.idx to i64
  %43 = add nsw i64 %42, -1
  %44 = getelementptr double, ptr %.unpack, i64 %43
  store <2 x double> %41, ptr %44, align 8, !tbaa !4, !alias.scope !13
  %45 = extractelement <2 x double> %41, i64 1
  store double %45, ptr %14, align 8, !tbaa !4, !alias.scope !15, !noalias !17
  %index.next = add nuw i64 %index, 2
  %46 = icmp eq i64 %index.next, %n.vec
  br i1 %46, label %middle.block, label %vector.body, !llvm.loop !18

middle.block:                                     ; preds = %vector.body
  %cmp.n = icmp eq i64 %22, %n.vec
  br i1 %cmp.n, label %_QFPloop.exit, label %.lr.ph8.i.preheader

.lr.ph8.i.preheader:                              ; preds = %vector.memcheck, %vector.scevcheck, %.lr.ph8.preheader.i, %middle.block
  %.ph = phi i64 [ %18, %vector.memcheck ], [ %18, %vector.scevcheck ], [ %18, %.lr.ph8.preheader.i ], [ %ind.end, %middle.block ]
  %.ph86 = phi i32 [ %6, %vector.memcheck ], [ %6, %vector.scevcheck ], [ %6, %.lr.ph8.preheader.i ], [ %ind.end83, %middle.block ]
  br label %.lr.ph8.i

.lr.ph8.i:                                        ; preds = %.lr.ph8.i.preheader, %.lr.ph8.i
  %47 = phi i64 [ %57, %.lr.ph8.i ], [ %.ph, %.lr.ph8.i.preheader ]
  %48 = phi i32 [ %56, %.lr.ph8.i ], [ %.ph86, %.lr.ph8.i.preheader ]
  %49 = load i32, ptr %12, align 4, !tbaa !4
  %50 = sitofp i32 %49 to float
  %51 = fdiv contract float 1.000000e+00, %50
  %52 = fpext float %51 to double
  %53 = sext i32 %48 to i64
  %54 = add nsw i64 %53, -1
  %55 = getelementptr double, ptr %.unpack, i64 %54
  store double %52, ptr %55, align 8, !tbaa !4
  store double %52, ptr %14, align 8, !tbaa !4
  %56 = add i32 %48, 1
  %57 = add nsw i64 %47, -1
  %58 = icmp ugt i64 %47, 1
  br i1 %58, label %.lr.ph8.i, label %_QFPloop.exit.loopexit, !llvm.loop !21

_QFPloop.exit.loopexit:                           ; preds = %.lr.ph8.i
  br label %_QFPloop.exit

_QFPloop.exit:                                    ; preds = %_QFPloop.exit.loopexit, %middle.block, %omp.par.entry
  ret void
}
*** IR Dump After LCSSAPass on _QFPomp_subroutine..omp_par ***
; Function Attrs: norecurse nounwind
define internal void @_QFPomp_subroutine..omp_par(ptr noalias nocapture readnone %tid.addr, ptr noalias nocapture readnone %zero.addr, ptr nocapture readonly %0) #3 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %gep_3 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 2
  %loadgep_4 = load ptr, ptr %gep_3, align 8
  %gep_5 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 3
  %loadgep_6 = load ptr, ptr %gep_5, align 8
  %gep_7 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 4
  %loadgep_8 = load ptr, ptr %gep_7, align 8
  %1 = tail call i32 @omp_get_thread_num()
  %2 = tail call i32 @omp_get_num_threads()
  %3 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %4 = sdiv i32 %3, %2
  %5 = mul i32 %4, %1
  %6 = add i32 %5, 1
  %7 = add i32 %2, -1
  %8 = icmp eq i32 %1, %7
  %9 = add i32 %6, %4
  %spec.select = select i1 %8, i32 %3, i32 %9
  %.unpack = load ptr, ptr %loadgep_2, align 8, !tbaa !8
  %.elt14 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  %.unpack15 = load i64, ptr %.elt14, align 8, !tbaa !8
  %.elt16 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  %.unpack17 = load i32, ptr %.elt16, align 8, !tbaa !8
  %.elt18 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  %.unpack19 = load i8, ptr %.elt18, align 4, !tbaa !8
  %.elt20 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  %.unpack21 = load i8, ptr %.elt20, align 1, !tbaa !8
  %.elt22 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  %.unpack23 = load i8, ptr %.elt22, align 2, !tbaa !8
  %.elt24 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  %.unpack25 = load i8, ptr %.elt24, align 1, !tbaa !8
  %.elt26 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  %.unpack27.unpack.unpack = load i64, ptr %.elt26, align 8, !tbaa !8
  %.unpack27.unpack.elt29 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  %.unpack27.unpack.unpack30 = load i64, ptr %.unpack27.unpack.elt29, align 8, !tbaa !8
  %.unpack27.unpack.elt31 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  %.unpack27.unpack.unpack32 = load i64, ptr %.unpack27.unpack.elt31, align 8, !tbaa !8
  store ptr %.unpack, ptr %loadgep_4, align 8, !tbaa !8
  %loadgep_4.repack34 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 1
  store i64 %.unpack15, ptr %loadgep_4.repack34, align 8, !tbaa !8
  %loadgep_4.repack36 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 2
  store i32 %.unpack17, ptr %loadgep_4.repack36, align 8, !tbaa !8
  %loadgep_4.repack38 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 3
  store i8 %.unpack19, ptr %loadgep_4.repack38, align 4, !tbaa !8
  %loadgep_4.repack40 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 4
  store i8 %.unpack21, ptr %loadgep_4.repack40, align 1, !tbaa !8
  %loadgep_4.repack42 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 5
  store i8 %.unpack23, ptr %loadgep_4.repack42, align 2, !tbaa !8
  %loadgep_4.repack44 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 6
  store i8 %.unpack25, ptr %loadgep_4.repack44, align 1, !tbaa !8
  %loadgep_4.repack46 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7
  store i64 %.unpack27.unpack.unpack, ptr %loadgep_4.repack46, align 8, !tbaa !8
  %loadgep_4.repack46.repack48 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack27.unpack.unpack30, ptr %loadgep_4.repack46.repack48, align 8, !tbaa !8
  %loadgep_4.repack46.repack50 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 2
  store i64 %.unpack27.unpack.unpack32, ptr %loadgep_4.repack46.repack50, align 8, !tbaa !8
  %10 = icmp eq i64 %.unpack27.unpack.unpack30, 0
  %11 = select i1 %10, i64 1, i64 %.unpack27.unpack.unpack
  store ptr %.unpack, ptr %loadgep_6, align 8, !tbaa !8
  %loadgep_6.repack52 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 1
  store i64 8, ptr %loadgep_6.repack52, align 8, !tbaa !8
  %loadgep_6.repack54 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 2
  store i32 20180515, ptr %loadgep_6.repack54, align 8, !tbaa !8
  %loadgep_6.repack56 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 3
  store i8 1, ptr %loadgep_6.repack56, align 4, !tbaa !8
  %loadgep_6.repack58 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 4
  store i8 28, ptr %loadgep_6.repack58, align 1, !tbaa !8
  %loadgep_6.repack60 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 5
  store i8 0, ptr %loadgep_6.repack60, align 2, !tbaa !8
  %loadgep_6.repack62 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 6
  store i8 0, ptr %loadgep_6.repack62, align 1, !tbaa !8
  %loadgep_6.repack64 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7
  store i64 %11, ptr %loadgep_6.repack64, align 8, !tbaa !8
  %loadgep_6.repack64.repack66 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack27.unpack.unpack30, ptr %loadgep_6.repack64.repack66, align 8, !tbaa !8
  %loadgep_6.repack64.repack68 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7, i64 0, i64 2
  store i64 8, ptr %loadgep_6.repack64.repack68, align 8, !tbaa !8
  %12 = load ptr, ptr %loadgep_8, align 8, !tbaa !4
  %13 = getelementptr { ptr, ptr }, ptr %loadgep_8, i64 0, i32 1
  %14 = load ptr, ptr %13, align 8, !tbaa !4
  %15 = sext i32 %6 to i64
  %16 = sext i32 %spec.select to i64
  %reass.sub9.i = sub nsw i64 %16, %15
  %17 = icmp sgt i64 %reass.sub9.i, -1
  br i1 %17, label %.lr.ph8.preheader.i, label %_QFPloop.exit

.lr.ph8.preheader.i:                              ; preds = %omp.par.entry
  %18 = add nsw i64 %reass.sub9.i, 1
  %19 = add nsw i64 %16, 2
  %20 = icmp ne i64 %18, 0
  %umin82.neg = sext i1 %20 to i64
  %21 = add nsw i64 %19, %umin82.neg
  %22 = sub nsw i64 %21, %15
  %min.iters.check = icmp ult i64 %22, 8
  br i1 %min.iters.check, label %.lr.ph8.i.preheader, label %vector.scevcheck

vector.scevcheck:                                 ; preds = %.lr.ph8.preheader.i
  %23 = add nsw i64 %16, 1
  %24 = icmp ne i64 %18, 0
  %umin.neg = sext i1 %24 to i64
  %25 = add nsw i64 %23, %umin.neg
  %26 = sub nsw i64 %25, %15
  %27 = trunc i64 %26 to i32
  %28 = add i32 %6, %27
  %29 = icmp slt i32 %28, %6
  %30 = icmp ugt i64 %26, 4294967295
  %31 = or i1 %29, %30
  br i1 %31, label %.lr.ph8.i.preheader, label %vector.memcheck

vector.memcheck:                                  ; preds = %vector.scevcheck
  %scevgep = getelementptr i8, ptr %14, i64 8
  %scevgep71 = getelementptr i8, ptr %12, i64 4
  %32 = shl nsw i64 %15, 3
  %33 = add nsw i64 %32, -8
  %scevgep72 = getelementptr i8, ptr %.unpack, i64 %33
  %34 = shl nsw i64 %16, 3
  %35 = add nsw i64 %34, 8
  %.not = icmp eq i64 %18, 0
  %36 = select i1 %.not, i64 %35, i64 %34
  %scevgep74 = getelementptr i8, ptr %.unpack, i64 %36
  %bound0 = icmp ult ptr %14, %scevgep71
  %bound1 = icmp ult ptr %12, %scevgep
  %found.conflict = and i1 %bound0, %bound1
  %bound075 = icmp ult ptr %14, %scevgep74
  %bound176 = icmp ult ptr %scevgep72, %scevgep
  %found.conflict77 = and i1 %bound075, %bound176
  %conflict.rdx = or i1 %found.conflict, %found.conflict77
  %bound078 = icmp ult ptr %12, %scevgep74
  %bound179 = icmp ult ptr %scevgep72, %scevgep71
  %found.conflict80 = and i1 %bound078, %bound179
  %conflict.rdx81 = or i1 %conflict.rdx, %found.conflict80
  br i1 %conflict.rdx81, label %.lr.ph8.i.preheader, label %vector.ph

vector.ph:                                        ; preds = %vector.memcheck
  %n.vec = and i64 %22, -2
  %ind.end = sub nsw i64 %18, %n.vec
  %.cast = trunc i64 %n.vec to i32
  %ind.end83 = add i32 %6, %.cast
  br label %vector.body

vector.body:                                      ; preds = %vector.body, %vector.ph
  %index = phi i64 [ 0, %vector.ph ], [ %index.next, %vector.body ]
  %.cast85 = trunc i64 %index to i32
  %offset.idx = add i32 %6, %.cast85
  %37 = load i32, ptr %12, align 4, !tbaa !4, !alias.scope !10, !noalias !13
  %broadcast.splatinsert = insertelement <2 x i32> poison, i32 %37, i64 0
  %38 = sitofp <2 x i32> %broadcast.splatinsert to <2 x float>
  %39 = fdiv contract <2 x float> <float 1.000000e+00, float poison>, %38
  %40 = shufflevector <2 x float> %39, <2 x float> poison, <2 x i32> zeroinitializer
  %41 = fpext <2 x float> %40 to <2 x double>
  %42 = sext i32 %offset.idx to i64
  %43 = add nsw i64 %42, -1
  %44 = getelementptr double, ptr %.unpack, i64 %43
  store <2 x double> %41, ptr %44, align 8, !tbaa !4, !alias.scope !13
  %45 = extractelement <2 x double> %41, i64 1
  store double %45, ptr %14, align 8, !tbaa !4, !alias.scope !15, !noalias !17
  %index.next = add nuw i64 %index, 2
  %46 = icmp eq i64 %index.next, %n.vec
  br i1 %46, label %middle.block, label %vector.body, !llvm.loop !18

middle.block:                                     ; preds = %vector.body
  %cmp.n = icmp eq i64 %22, %n.vec
  br i1 %cmp.n, label %_QFPloop.exit, label %.lr.ph8.i.preheader

.lr.ph8.i.preheader:                              ; preds = %vector.memcheck, %vector.scevcheck, %.lr.ph8.preheader.i, %middle.block
  %.ph = phi i64 [ %18, %vector.memcheck ], [ %18, %vector.scevcheck ], [ %18, %.lr.ph8.preheader.i ], [ %ind.end, %middle.block ]
  %.ph86 = phi i32 [ %6, %vector.memcheck ], [ %6, %vector.scevcheck ], [ %6, %.lr.ph8.preheader.i ], [ %ind.end83, %middle.block ]
  br label %.lr.ph8.i

.lr.ph8.i:                                        ; preds = %.lr.ph8.i.preheader, %.lr.ph8.i
  %47 = phi i64 [ %57, %.lr.ph8.i ], [ %.ph, %.lr.ph8.i.preheader ]
  %48 = phi i32 [ %56, %.lr.ph8.i ], [ %.ph86, %.lr.ph8.i.preheader ]
  %49 = load i32, ptr %12, align 4, !tbaa !4
  %50 = sitofp i32 %49 to float
  %51 = fdiv contract float 1.000000e+00, %50
  %52 = fpext float %51 to double
  %53 = sext i32 %48 to i64
  %54 = add nsw i64 %53, -1
  %55 = getelementptr double, ptr %.unpack, i64 %54
  store double %52, ptr %55, align 8, !tbaa !4
  store double %52, ptr %14, align 8, !tbaa !4
  %56 = add i32 %48, 1
  %57 = add nsw i64 %47, -1
  %58 = icmp ugt i64 %47, 1
  br i1 %58, label %.lr.ph8.i, label %_QFPloop.exit.loopexit, !llvm.loop !21

_QFPloop.exit.loopexit:                           ; preds = %.lr.ph8.i
  br label %_QFPloop.exit

_QFPloop.exit:                                    ; preds = %_QFPloop.exit.loopexit, %middle.block, %omp.par.entry
  ret void
}
*** IR Dump After LICMPass on vector.body ***

; Preheader:
vector.ph:                                        ; preds = %vector.memcheck
  %n.vec = and i64 %22, -2
  %ind.end = sub nsw i64 %18, %n.vec
  %.cast = trunc i64 %n.vec to i32
  %ind.end83 = add i32 %6, %.cast
  %37 = load i32, ptr %12, align 4, !tbaa !4, !alias.scope !10, !noalias !13
  %broadcast.splatinsert = insertelement <2 x i32> poison, i32 %37, i64 0
  %38 = sitofp <2 x i32> %broadcast.splatinsert to <2 x float>
  %39 = fdiv contract <2 x float> <float 1.000000e+00, float poison>, %38
  %40 = shufflevector <2 x float> %39, <2 x float> poison, <2 x i32> zeroinitializer
  %41 = fpext <2 x float> %40 to <2 x double>
  %42 = extractelement <2 x double> %41, i64 1
  store double %42, ptr %14, align 8, !tbaa !4, !alias.scope !15, !noalias !17
  br label %vector.body

; Loop:
vector.body:                                      ; preds = %vector.body, %vector.ph
  %index = phi i64 [ 0, %vector.ph ], [ %index.next, %vector.body ]
  %.cast85 = trunc i64 %index to i32
  %offset.idx = add i32 %6, %.cast85
  %43 = sext i32 %offset.idx to i64
  %44 = add nsw i64 %43, -1
  %45 = getelementptr double, ptr %.unpack, i64 %44
  store <2 x double> %41, ptr %45, align 8, !tbaa !4, !alias.scope !13
  %index.next = add nuw i64 %index, 2
  %46 = icmp eq i64 %index.next, %n.vec
  br i1 %46, label %middle.block, label %vector.body, !llvm.loop !18

; Exit blocks
middle.block:                                     ; preds = %vector.body
  %cmp.n = icmp eq i64 %22, %n.vec
  br i1 %cmp.n, label %_QFPloop.exit, label %.lr.ph8.i.preheader
*** IR Dump After LICMPass on .lr.ph8.i ***

; Preheader:
.lr.ph8.i.preheader:                              ; preds = %vector.memcheck, %vector.scevcheck, %.lr.ph8.preheader.i, %middle.block
  %.ph = phi i64 [ %18, %vector.memcheck ], [ %18, %vector.scevcheck ], [ %18, %.lr.ph8.preheader.i ], [ %ind.end, %middle.block ]
  %.ph86 = phi i32 [ %6, %vector.memcheck ], [ %6, %vector.scevcheck ], [ %6, %.lr.ph8.preheader.i ], [ %ind.end83, %middle.block ]
  br label %.lr.ph8.i

; Loop:
.lr.ph8.i:                                        ; preds = %.lr.ph8.i.preheader, %.lr.ph8.i
  %47 = phi i64 [ %57, %.lr.ph8.i ], [ %.ph, %.lr.ph8.i.preheader ]
  %48 = phi i32 [ %56, %.lr.ph8.i ], [ %.ph86, %.lr.ph8.i.preheader ]
  %49 = load i32, ptr %12, align 4, !tbaa !4
  %50 = sitofp i32 %49 to float
  %51 = fdiv contract float 1.000000e+00, %50
  %52 = fpext float %51 to double
  %53 = sext i32 %48 to i64
  %54 = add nsw i64 %53, -1
  %55 = getelementptr double, ptr %.unpack, i64 %54
  store double %52, ptr %55, align 8, !tbaa !4
  store double %52, ptr %14, align 8, !tbaa !4
  %56 = add i32 %48, 1
  %57 = add nsw i64 %47, -1
  %58 = icmp ugt i64 %47, 1
  br i1 %58, label %.lr.ph8.i, label %_QFPloop.exit.loopexit, !llvm.loop !21

; Exit blocks
_QFPloop.exit.loopexit:                           ; preds = %.lr.ph8.i
  br label %_QFPloop.exit
*** IR Dump After AlignmentFromAssumptionsPass on _QFPomp_subroutine..omp_par ***
; Function Attrs: norecurse nounwind
define internal void @_QFPomp_subroutine..omp_par(ptr noalias nocapture readnone %tid.addr, ptr noalias nocapture readnone %zero.addr, ptr nocapture readonly %0) #3 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %gep_3 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 2
  %loadgep_4 = load ptr, ptr %gep_3, align 8
  %gep_5 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 3
  %loadgep_6 = load ptr, ptr %gep_5, align 8
  %gep_7 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 4
  %loadgep_8 = load ptr, ptr %gep_7, align 8
  %1 = tail call i32 @omp_get_thread_num()
  %2 = tail call i32 @omp_get_num_threads()
  %3 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %4 = sdiv i32 %3, %2
  %5 = mul i32 %4, %1
  %6 = add i32 %5, 1
  %7 = add i32 %2, -1
  %8 = icmp eq i32 %1, %7
  %9 = add i32 %6, %4
  %spec.select = select i1 %8, i32 %3, i32 %9
  %.unpack = load ptr, ptr %loadgep_2, align 8, !tbaa !8
  %.elt14 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  %.unpack15 = load i64, ptr %.elt14, align 8, !tbaa !8
  %.elt16 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  %.unpack17 = load i32, ptr %.elt16, align 8, !tbaa !8
  %.elt18 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  %.unpack19 = load i8, ptr %.elt18, align 4, !tbaa !8
  %.elt20 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  %.unpack21 = load i8, ptr %.elt20, align 1, !tbaa !8
  %.elt22 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  %.unpack23 = load i8, ptr %.elt22, align 2, !tbaa !8
  %.elt24 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  %.unpack25 = load i8, ptr %.elt24, align 1, !tbaa !8
  %.elt26 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  %.unpack27.unpack.unpack = load i64, ptr %.elt26, align 8, !tbaa !8
  %.unpack27.unpack.elt29 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  %.unpack27.unpack.unpack30 = load i64, ptr %.unpack27.unpack.elt29, align 8, !tbaa !8
  %.unpack27.unpack.elt31 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  %.unpack27.unpack.unpack32 = load i64, ptr %.unpack27.unpack.elt31, align 8, !tbaa !8
  store ptr %.unpack, ptr %loadgep_4, align 8, !tbaa !8
  %loadgep_4.repack34 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 1
  store i64 %.unpack15, ptr %loadgep_4.repack34, align 8, !tbaa !8
  %loadgep_4.repack36 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 2
  store i32 %.unpack17, ptr %loadgep_4.repack36, align 8, !tbaa !8
  %loadgep_4.repack38 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 3
  store i8 %.unpack19, ptr %loadgep_4.repack38, align 4, !tbaa !8
  %loadgep_4.repack40 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 4
  store i8 %.unpack21, ptr %loadgep_4.repack40, align 1, !tbaa !8
  %loadgep_4.repack42 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 5
  store i8 %.unpack23, ptr %loadgep_4.repack42, align 2, !tbaa !8
  %loadgep_4.repack44 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 6
  store i8 %.unpack25, ptr %loadgep_4.repack44, align 1, !tbaa !8
  %loadgep_4.repack46 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7
  store i64 %.unpack27.unpack.unpack, ptr %loadgep_4.repack46, align 8, !tbaa !8
  %loadgep_4.repack46.repack48 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack27.unpack.unpack30, ptr %loadgep_4.repack46.repack48, align 8, !tbaa !8
  %loadgep_4.repack46.repack50 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 2
  store i64 %.unpack27.unpack.unpack32, ptr %loadgep_4.repack46.repack50, align 8, !tbaa !8
  %10 = icmp eq i64 %.unpack27.unpack.unpack30, 0
  %11 = select i1 %10, i64 1, i64 %.unpack27.unpack.unpack
  store ptr %.unpack, ptr %loadgep_6, align 8, !tbaa !8
  %loadgep_6.repack52 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 1
  store i64 8, ptr %loadgep_6.repack52, align 8, !tbaa !8
  %loadgep_6.repack54 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 2
  store i32 20180515, ptr %loadgep_6.repack54, align 8, !tbaa !8
  %loadgep_6.repack56 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 3
  store i8 1, ptr %loadgep_6.repack56, align 4, !tbaa !8
  %loadgep_6.repack58 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 4
  store i8 28, ptr %loadgep_6.repack58, align 1, !tbaa !8
  %loadgep_6.repack60 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 5
  store i8 0, ptr %loadgep_6.repack60, align 2, !tbaa !8
  %loadgep_6.repack62 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 6
  store i8 0, ptr %loadgep_6.repack62, align 1, !tbaa !8
  %loadgep_6.repack64 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7
  store i64 %11, ptr %loadgep_6.repack64, align 8, !tbaa !8
  %loadgep_6.repack64.repack66 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack27.unpack.unpack30, ptr %loadgep_6.repack64.repack66, align 8, !tbaa !8
  %loadgep_6.repack64.repack68 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7, i64 0, i64 2
  store i64 8, ptr %loadgep_6.repack64.repack68, align 8, !tbaa !8
  %12 = load ptr, ptr %loadgep_8, align 8, !tbaa !4
  %13 = getelementptr { ptr, ptr }, ptr %loadgep_8, i64 0, i32 1
  %14 = load ptr, ptr %13, align 8, !tbaa !4
  %15 = sext i32 %6 to i64
  %16 = sext i32 %spec.select to i64
  %reass.sub9.i = sub nsw i64 %16, %15
  %17 = icmp sgt i64 %reass.sub9.i, -1
  br i1 %17, label %.lr.ph8.preheader.i, label %_QFPloop.exit

.lr.ph8.preheader.i:                              ; preds = %omp.par.entry
  %18 = add nsw i64 %reass.sub9.i, 1
  %19 = add nsw i64 %16, 2
  %20 = icmp ne i64 %18, 0
  %umin82.neg = sext i1 %20 to i64
  %21 = add nsw i64 %19, %umin82.neg
  %22 = sub nsw i64 %21, %15
  %min.iters.check = icmp ult i64 %22, 8
  br i1 %min.iters.check, label %.lr.ph8.i.preheader, label %vector.scevcheck

vector.scevcheck:                                 ; preds = %.lr.ph8.preheader.i
  %23 = add nsw i64 %16, 1
  %24 = icmp ne i64 %18, 0
  %umin.neg = sext i1 %24 to i64
  %25 = add nsw i64 %23, %umin.neg
  %26 = sub nsw i64 %25, %15
  %27 = trunc i64 %26 to i32
  %28 = add i32 %6, %27
  %29 = icmp slt i32 %28, %6
  %30 = icmp ugt i64 %26, 4294967295
  %31 = or i1 %29, %30
  br i1 %31, label %.lr.ph8.i.preheader, label %vector.memcheck

vector.memcheck:                                  ; preds = %vector.scevcheck
  %scevgep = getelementptr i8, ptr %14, i64 8
  %scevgep71 = getelementptr i8, ptr %12, i64 4
  %32 = shl nsw i64 %15, 3
  %33 = add nsw i64 %32, -8
  %scevgep72 = getelementptr i8, ptr %.unpack, i64 %33
  %34 = shl nsw i64 %16, 3
  %35 = add nsw i64 %34, 8
  %.not = icmp eq i64 %18, 0
  %36 = select i1 %.not, i64 %35, i64 %34
  %scevgep74 = getelementptr i8, ptr %.unpack, i64 %36
  %bound0 = icmp ult ptr %14, %scevgep71
  %bound1 = icmp ult ptr %12, %scevgep
  %found.conflict = and i1 %bound0, %bound1
  %bound075 = icmp ult ptr %14, %scevgep74
  %bound176 = icmp ult ptr %scevgep72, %scevgep
  %found.conflict77 = and i1 %bound075, %bound176
  %conflict.rdx = or i1 %found.conflict, %found.conflict77
  %bound078 = icmp ult ptr %12, %scevgep74
  %bound179 = icmp ult ptr %scevgep72, %scevgep71
  %found.conflict80 = and i1 %bound078, %bound179
  %conflict.rdx81 = or i1 %conflict.rdx, %found.conflict80
  br i1 %conflict.rdx81, label %.lr.ph8.i.preheader, label %vector.ph

vector.ph:                                        ; preds = %vector.memcheck
  %n.vec = and i64 %22, -2
  %ind.end = sub nsw i64 %18, %n.vec
  %.cast = trunc i64 %n.vec to i32
  %ind.end83 = add i32 %6, %.cast
  %37 = load i32, ptr %12, align 4, !tbaa !4, !alias.scope !10, !noalias !13
  %broadcast.splatinsert = insertelement <2 x i32> poison, i32 %37, i64 0
  %38 = sitofp <2 x i32> %broadcast.splatinsert to <2 x float>
  %39 = fdiv contract <2 x float> <float 1.000000e+00, float poison>, %38
  %40 = shufflevector <2 x float> %39, <2 x float> poison, <2 x i32> zeroinitializer
  %41 = fpext <2 x float> %40 to <2 x double>
  %42 = extractelement <2 x double> %41, i64 1
  store double %42, ptr %14, align 8, !tbaa !4, !alias.scope !15, !noalias !17
  br label %vector.body

vector.body:                                      ; preds = %vector.body, %vector.ph
  %index = phi i64 [ 0, %vector.ph ], [ %index.next, %vector.body ]
  %.cast85 = trunc i64 %index to i32
  %offset.idx = add i32 %6, %.cast85
  %43 = sext i32 %offset.idx to i64
  %44 = add nsw i64 %43, -1
  %45 = getelementptr double, ptr %.unpack, i64 %44
  store <2 x double> %41, ptr %45, align 8, !tbaa !4, !alias.scope !13
  %index.next = add nuw i64 %index, 2
  %46 = icmp eq i64 %index.next, %n.vec
  br i1 %46, label %middle.block, label %vector.body, !llvm.loop !18

middle.block:                                     ; preds = %vector.body
  %cmp.n = icmp eq i64 %22, %n.vec
  br i1 %cmp.n, label %_QFPloop.exit, label %.lr.ph8.i.preheader

.lr.ph8.i.preheader:                              ; preds = %vector.memcheck, %vector.scevcheck, %.lr.ph8.preheader.i, %middle.block
  %.ph = phi i64 [ %18, %vector.memcheck ], [ %18, %vector.scevcheck ], [ %18, %.lr.ph8.preheader.i ], [ %ind.end, %middle.block ]
  %.ph86 = phi i32 [ %6, %vector.memcheck ], [ %6, %vector.scevcheck ], [ %6, %.lr.ph8.preheader.i ], [ %ind.end83, %middle.block ]
  br label %.lr.ph8.i

.lr.ph8.i:                                        ; preds = %.lr.ph8.i.preheader, %.lr.ph8.i
  %47 = phi i64 [ %57, %.lr.ph8.i ], [ %.ph, %.lr.ph8.i.preheader ]
  %48 = phi i32 [ %56, %.lr.ph8.i ], [ %.ph86, %.lr.ph8.i.preheader ]
  %49 = load i32, ptr %12, align 4, !tbaa !4
  %50 = sitofp i32 %49 to float
  %51 = fdiv contract float 1.000000e+00, %50
  %52 = fpext float %51 to double
  %53 = sext i32 %48 to i64
  %54 = add nsw i64 %53, -1
  %55 = getelementptr double, ptr %.unpack, i64 %54
  store double %52, ptr %55, align 8, !tbaa !4
  store double %52, ptr %14, align 8, !tbaa !4
  %56 = add i32 %48, 1
  %57 = add nsw i64 %47, -1
  %58 = icmp ugt i64 %47, 1
  br i1 %58, label %.lr.ph8.i, label %_QFPloop.exit.loopexit, !llvm.loop !21

_QFPloop.exit.loopexit:                           ; preds = %.lr.ph8.i
  br label %_QFPloop.exit

_QFPloop.exit:                                    ; preds = %_QFPloop.exit.loopexit, %middle.block, %omp.par.entry
  ret void
}
*** IR Dump After LoopSinkPass on _QFPomp_subroutine..omp_par ***
; Function Attrs: norecurse nounwind
define internal void @_QFPomp_subroutine..omp_par(ptr noalias nocapture readnone %tid.addr, ptr noalias nocapture readnone %zero.addr, ptr nocapture readonly %0) #3 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %gep_3 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 2
  %loadgep_4 = load ptr, ptr %gep_3, align 8
  %gep_5 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 3
  %loadgep_6 = load ptr, ptr %gep_5, align 8
  %gep_7 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 4
  %loadgep_8 = load ptr, ptr %gep_7, align 8
  %1 = tail call i32 @omp_get_thread_num()
  %2 = tail call i32 @omp_get_num_threads()
  %3 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %4 = sdiv i32 %3, %2
  %5 = mul i32 %4, %1
  %6 = add i32 %5, 1
  %7 = add i32 %2, -1
  %8 = icmp eq i32 %1, %7
  %9 = add i32 %6, %4
  %spec.select = select i1 %8, i32 %3, i32 %9
  %.unpack = load ptr, ptr %loadgep_2, align 8, !tbaa !8
  %.elt14 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  %.unpack15 = load i64, ptr %.elt14, align 8, !tbaa !8
  %.elt16 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  %.unpack17 = load i32, ptr %.elt16, align 8, !tbaa !8
  %.elt18 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  %.unpack19 = load i8, ptr %.elt18, align 4, !tbaa !8
  %.elt20 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  %.unpack21 = load i8, ptr %.elt20, align 1, !tbaa !8
  %.elt22 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  %.unpack23 = load i8, ptr %.elt22, align 2, !tbaa !8
  %.elt24 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  %.unpack25 = load i8, ptr %.elt24, align 1, !tbaa !8
  %.elt26 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  %.unpack27.unpack.unpack = load i64, ptr %.elt26, align 8, !tbaa !8
  %.unpack27.unpack.elt29 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  %.unpack27.unpack.unpack30 = load i64, ptr %.unpack27.unpack.elt29, align 8, !tbaa !8
  %.unpack27.unpack.elt31 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  %.unpack27.unpack.unpack32 = load i64, ptr %.unpack27.unpack.elt31, align 8, !tbaa !8
  store ptr %.unpack, ptr %loadgep_4, align 8, !tbaa !8
  %loadgep_4.repack34 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 1
  store i64 %.unpack15, ptr %loadgep_4.repack34, align 8, !tbaa !8
  %loadgep_4.repack36 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 2
  store i32 %.unpack17, ptr %loadgep_4.repack36, align 8, !tbaa !8
  %loadgep_4.repack38 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 3
  store i8 %.unpack19, ptr %loadgep_4.repack38, align 4, !tbaa !8
  %loadgep_4.repack40 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 4
  store i8 %.unpack21, ptr %loadgep_4.repack40, align 1, !tbaa !8
  %loadgep_4.repack42 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 5
  store i8 %.unpack23, ptr %loadgep_4.repack42, align 2, !tbaa !8
  %loadgep_4.repack44 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 6
  store i8 %.unpack25, ptr %loadgep_4.repack44, align 1, !tbaa !8
  %loadgep_4.repack46 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7
  store i64 %.unpack27.unpack.unpack, ptr %loadgep_4.repack46, align 8, !tbaa !8
  %loadgep_4.repack46.repack48 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack27.unpack.unpack30, ptr %loadgep_4.repack46.repack48, align 8, !tbaa !8
  %loadgep_4.repack46.repack50 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 2
  store i64 %.unpack27.unpack.unpack32, ptr %loadgep_4.repack46.repack50, align 8, !tbaa !8
  %10 = icmp eq i64 %.unpack27.unpack.unpack30, 0
  %11 = select i1 %10, i64 1, i64 %.unpack27.unpack.unpack
  store ptr %.unpack, ptr %loadgep_6, align 8, !tbaa !8
  %loadgep_6.repack52 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 1
  store i64 8, ptr %loadgep_6.repack52, align 8, !tbaa !8
  %loadgep_6.repack54 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 2
  store i32 20180515, ptr %loadgep_6.repack54, align 8, !tbaa !8
  %loadgep_6.repack56 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 3
  store i8 1, ptr %loadgep_6.repack56, align 4, !tbaa !8
  %loadgep_6.repack58 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 4
  store i8 28, ptr %loadgep_6.repack58, align 1, !tbaa !8
  %loadgep_6.repack60 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 5
  store i8 0, ptr %loadgep_6.repack60, align 2, !tbaa !8
  %loadgep_6.repack62 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 6
  store i8 0, ptr %loadgep_6.repack62, align 1, !tbaa !8
  %loadgep_6.repack64 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7
  store i64 %11, ptr %loadgep_6.repack64, align 8, !tbaa !8
  %loadgep_6.repack64.repack66 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack27.unpack.unpack30, ptr %loadgep_6.repack64.repack66, align 8, !tbaa !8
  %loadgep_6.repack64.repack68 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7, i64 0, i64 2
  store i64 8, ptr %loadgep_6.repack64.repack68, align 8, !tbaa !8
  %12 = load ptr, ptr %loadgep_8, align 8, !tbaa !4
  %13 = getelementptr { ptr, ptr }, ptr %loadgep_8, i64 0, i32 1
  %14 = load ptr, ptr %13, align 8, !tbaa !4
  %15 = sext i32 %6 to i64
  %16 = sext i32 %spec.select to i64
  %reass.sub9.i = sub nsw i64 %16, %15
  %17 = icmp sgt i64 %reass.sub9.i, -1
  br i1 %17, label %.lr.ph8.preheader.i, label %_QFPloop.exit

.lr.ph8.preheader.i:                              ; preds = %omp.par.entry
  %18 = add nsw i64 %reass.sub9.i, 1
  %19 = add nsw i64 %16, 2
  %20 = icmp ne i64 %18, 0
  %umin82.neg = sext i1 %20 to i64
  %21 = add nsw i64 %19, %umin82.neg
  %22 = sub nsw i64 %21, %15
  %min.iters.check = icmp ult i64 %22, 8
  br i1 %min.iters.check, label %.lr.ph8.i.preheader, label %vector.scevcheck

vector.scevcheck:                                 ; preds = %.lr.ph8.preheader.i
  %23 = add nsw i64 %16, 1
  %24 = icmp ne i64 %18, 0
  %umin.neg = sext i1 %24 to i64
  %25 = add nsw i64 %23, %umin.neg
  %26 = sub nsw i64 %25, %15
  %27 = trunc i64 %26 to i32
  %28 = add i32 %6, %27
  %29 = icmp slt i32 %28, %6
  %30 = icmp ugt i64 %26, 4294967295
  %31 = or i1 %29, %30
  br i1 %31, label %.lr.ph8.i.preheader, label %vector.memcheck

vector.memcheck:                                  ; preds = %vector.scevcheck
  %scevgep = getelementptr i8, ptr %14, i64 8
  %scevgep71 = getelementptr i8, ptr %12, i64 4
  %32 = shl nsw i64 %15, 3
  %33 = add nsw i64 %32, -8
  %scevgep72 = getelementptr i8, ptr %.unpack, i64 %33
  %34 = shl nsw i64 %16, 3
  %35 = add nsw i64 %34, 8
  %.not = icmp eq i64 %18, 0
  %36 = select i1 %.not, i64 %35, i64 %34
  %scevgep74 = getelementptr i8, ptr %.unpack, i64 %36
  %bound0 = icmp ult ptr %14, %scevgep71
  %bound1 = icmp ult ptr %12, %scevgep
  %found.conflict = and i1 %bound0, %bound1
  %bound075 = icmp ult ptr %14, %scevgep74
  %bound176 = icmp ult ptr %scevgep72, %scevgep
  %found.conflict77 = and i1 %bound075, %bound176
  %conflict.rdx = or i1 %found.conflict, %found.conflict77
  %bound078 = icmp ult ptr %12, %scevgep74
  %bound179 = icmp ult ptr %scevgep72, %scevgep71
  %found.conflict80 = and i1 %bound078, %bound179
  %conflict.rdx81 = or i1 %conflict.rdx, %found.conflict80
  br i1 %conflict.rdx81, label %.lr.ph8.i.preheader, label %vector.ph

vector.ph:                                        ; preds = %vector.memcheck
  %n.vec = and i64 %22, -2
  %ind.end = sub nsw i64 %18, %n.vec
  %.cast = trunc i64 %n.vec to i32
  %ind.end83 = add i32 %6, %.cast
  %37 = load i32, ptr %12, align 4, !tbaa !4, !alias.scope !10, !noalias !13
  %broadcast.splatinsert = insertelement <2 x i32> poison, i32 %37, i64 0
  %38 = sitofp <2 x i32> %broadcast.splatinsert to <2 x float>
  %39 = fdiv contract <2 x float> <float 1.000000e+00, float poison>, %38
  %40 = shufflevector <2 x float> %39, <2 x float> poison, <2 x i32> zeroinitializer
  %41 = fpext <2 x float> %40 to <2 x double>
  %42 = extractelement <2 x double> %41, i64 1
  store double %42, ptr %14, align 8, !tbaa !4, !alias.scope !15, !noalias !17
  br label %vector.body

vector.body:                                      ; preds = %vector.body, %vector.ph
  %index = phi i64 [ 0, %vector.ph ], [ %index.next, %vector.body ]
  %.cast85 = trunc i64 %index to i32
  %offset.idx = add i32 %6, %.cast85
  %43 = sext i32 %offset.idx to i64
  %44 = add nsw i64 %43, -1
  %45 = getelementptr double, ptr %.unpack, i64 %44
  store <2 x double> %41, ptr %45, align 8, !tbaa !4, !alias.scope !13
  %index.next = add nuw i64 %index, 2
  %46 = icmp eq i64 %index.next, %n.vec
  br i1 %46, label %middle.block, label %vector.body, !llvm.loop !18

middle.block:                                     ; preds = %vector.body
  %cmp.n = icmp eq i64 %22, %n.vec
  br i1 %cmp.n, label %_QFPloop.exit, label %.lr.ph8.i.preheader

.lr.ph8.i.preheader:                              ; preds = %vector.memcheck, %vector.scevcheck, %.lr.ph8.preheader.i, %middle.block
  %.ph = phi i64 [ %18, %vector.memcheck ], [ %18, %vector.scevcheck ], [ %18, %.lr.ph8.preheader.i ], [ %ind.end, %middle.block ]
  %.ph86 = phi i32 [ %6, %vector.memcheck ], [ %6, %vector.scevcheck ], [ %6, %.lr.ph8.preheader.i ], [ %ind.end83, %middle.block ]
  br label %.lr.ph8.i

.lr.ph8.i:                                        ; preds = %.lr.ph8.i.preheader, %.lr.ph8.i
  %47 = phi i64 [ %57, %.lr.ph8.i ], [ %.ph, %.lr.ph8.i.preheader ]
  %48 = phi i32 [ %56, %.lr.ph8.i ], [ %.ph86, %.lr.ph8.i.preheader ]
  %49 = load i32, ptr %12, align 4, !tbaa !4
  %50 = sitofp i32 %49 to float
  %51 = fdiv contract float 1.000000e+00, %50
  %52 = fpext float %51 to double
  %53 = sext i32 %48 to i64
  %54 = add nsw i64 %53, -1
  %55 = getelementptr double, ptr %.unpack, i64 %54
  store double %52, ptr %55, align 8, !tbaa !4
  store double %52, ptr %14, align 8, !tbaa !4
  %56 = add i32 %48, 1
  %57 = add nsw i64 %47, -1
  %58 = icmp ugt i64 %47, 1
  br i1 %58, label %.lr.ph8.i, label %_QFPloop.exit.loopexit, !llvm.loop !21

_QFPloop.exit.loopexit:                           ; preds = %.lr.ph8.i
  br label %_QFPloop.exit

_QFPloop.exit:                                    ; preds = %_QFPloop.exit.loopexit, %middle.block, %omp.par.entry
  ret void
}
*** IR Dump After InstSimplifyPass on _QFPomp_subroutine..omp_par ***
; Function Attrs: norecurse nounwind
define internal void @_QFPomp_subroutine..omp_par(ptr noalias nocapture readnone %tid.addr, ptr noalias nocapture readnone %zero.addr, ptr nocapture readonly %0) #3 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %gep_3 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 2
  %loadgep_4 = load ptr, ptr %gep_3, align 8
  %gep_5 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 3
  %loadgep_6 = load ptr, ptr %gep_5, align 8
  %gep_7 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 4
  %loadgep_8 = load ptr, ptr %gep_7, align 8
  %1 = tail call i32 @omp_get_thread_num()
  %2 = tail call i32 @omp_get_num_threads()
  %3 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %4 = sdiv i32 %3, %2
  %5 = mul i32 %4, %1
  %6 = add i32 %5, 1
  %7 = add i32 %2, -1
  %8 = icmp eq i32 %1, %7
  %9 = add i32 %6, %4
  %spec.select = select i1 %8, i32 %3, i32 %9
  %.unpack = load ptr, ptr %loadgep_2, align 8, !tbaa !8
  %.elt14 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  %.unpack15 = load i64, ptr %.elt14, align 8, !tbaa !8
  %.elt16 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  %.unpack17 = load i32, ptr %.elt16, align 8, !tbaa !8
  %.elt18 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  %.unpack19 = load i8, ptr %.elt18, align 4, !tbaa !8
  %.elt20 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  %.unpack21 = load i8, ptr %.elt20, align 1, !tbaa !8
  %.elt22 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  %.unpack23 = load i8, ptr %.elt22, align 2, !tbaa !8
  %.elt24 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  %.unpack25 = load i8, ptr %.elt24, align 1, !tbaa !8
  %.elt26 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  %.unpack27.unpack.unpack = load i64, ptr %.elt26, align 8, !tbaa !8
  %.unpack27.unpack.elt29 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  %.unpack27.unpack.unpack30 = load i64, ptr %.unpack27.unpack.elt29, align 8, !tbaa !8
  %.unpack27.unpack.elt31 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  %.unpack27.unpack.unpack32 = load i64, ptr %.unpack27.unpack.elt31, align 8, !tbaa !8
  store ptr %.unpack, ptr %loadgep_4, align 8, !tbaa !8
  %loadgep_4.repack34 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 1
  store i64 %.unpack15, ptr %loadgep_4.repack34, align 8, !tbaa !8
  %loadgep_4.repack36 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 2
  store i32 %.unpack17, ptr %loadgep_4.repack36, align 8, !tbaa !8
  %loadgep_4.repack38 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 3
  store i8 %.unpack19, ptr %loadgep_4.repack38, align 4, !tbaa !8
  %loadgep_4.repack40 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 4
  store i8 %.unpack21, ptr %loadgep_4.repack40, align 1, !tbaa !8
  %loadgep_4.repack42 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 5
  store i8 %.unpack23, ptr %loadgep_4.repack42, align 2, !tbaa !8
  %loadgep_4.repack44 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 6
  store i8 %.unpack25, ptr %loadgep_4.repack44, align 1, !tbaa !8
  %loadgep_4.repack46 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7
  store i64 %.unpack27.unpack.unpack, ptr %loadgep_4.repack46, align 8, !tbaa !8
  %loadgep_4.repack46.repack48 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack27.unpack.unpack30, ptr %loadgep_4.repack46.repack48, align 8, !tbaa !8
  %loadgep_4.repack46.repack50 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 2
  store i64 %.unpack27.unpack.unpack32, ptr %loadgep_4.repack46.repack50, align 8, !tbaa !8
  %10 = icmp eq i64 %.unpack27.unpack.unpack30, 0
  %11 = select i1 %10, i64 1, i64 %.unpack27.unpack.unpack
  store ptr %.unpack, ptr %loadgep_6, align 8, !tbaa !8
  %loadgep_6.repack52 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 1
  store i64 8, ptr %loadgep_6.repack52, align 8, !tbaa !8
  %loadgep_6.repack54 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 2
  store i32 20180515, ptr %loadgep_6.repack54, align 8, !tbaa !8
  %loadgep_6.repack56 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 3
  store i8 1, ptr %loadgep_6.repack56, align 4, !tbaa !8
  %loadgep_6.repack58 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 4
  store i8 28, ptr %loadgep_6.repack58, align 1, !tbaa !8
  %loadgep_6.repack60 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 5
  store i8 0, ptr %loadgep_6.repack60, align 2, !tbaa !8
  %loadgep_6.repack62 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 6
  store i8 0, ptr %loadgep_6.repack62, align 1, !tbaa !8
  %loadgep_6.repack64 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7
  store i64 %11, ptr %loadgep_6.repack64, align 8, !tbaa !8
  %loadgep_6.repack64.repack66 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack27.unpack.unpack30, ptr %loadgep_6.repack64.repack66, align 8, !tbaa !8
  %loadgep_6.repack64.repack68 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7, i64 0, i64 2
  store i64 8, ptr %loadgep_6.repack64.repack68, align 8, !tbaa !8
  %12 = load ptr, ptr %loadgep_8, align 8, !tbaa !4
  %13 = getelementptr { ptr, ptr }, ptr %loadgep_8, i64 0, i32 1
  %14 = load ptr, ptr %13, align 8, !tbaa !4
  %15 = sext i32 %6 to i64
  %16 = sext i32 %spec.select to i64
  %reass.sub9.i = sub nsw i64 %16, %15
  %17 = icmp sgt i64 %reass.sub9.i, -1
  br i1 %17, label %.lr.ph8.preheader.i, label %_QFPloop.exit

.lr.ph8.preheader.i:                              ; preds = %omp.par.entry
  %18 = add nsw i64 %reass.sub9.i, 1
  %19 = add nsw i64 %16, 2
  %20 = icmp ne i64 %18, 0
  %umin82.neg = sext i1 %20 to i64
  %21 = add nsw i64 %19, %umin82.neg
  %22 = sub nsw i64 %21, %15
  %min.iters.check = icmp ult i64 %22, 8
  br i1 %min.iters.check, label %.lr.ph8.i.preheader, label %vector.scevcheck

vector.scevcheck:                                 ; preds = %.lr.ph8.preheader.i
  %23 = add nsw i64 %16, 1
  %24 = icmp ne i64 %18, 0
  %umin.neg = sext i1 %24 to i64
  %25 = add nsw i64 %23, %umin.neg
  %26 = sub nsw i64 %25, %15
  %27 = trunc i64 %26 to i32
  %28 = add i32 %6, %27
  %29 = icmp slt i32 %28, %6
  %30 = icmp ugt i64 %26, 4294967295
  %31 = or i1 %29, %30
  br i1 %31, label %.lr.ph8.i.preheader, label %vector.memcheck

vector.memcheck:                                  ; preds = %vector.scevcheck
  %scevgep = getelementptr i8, ptr %14, i64 8
  %scevgep71 = getelementptr i8, ptr %12, i64 4
  %32 = shl nsw i64 %15, 3
  %33 = add nsw i64 %32, -8
  %scevgep72 = getelementptr i8, ptr %.unpack, i64 %33
  %34 = shl nsw i64 %16, 3
  %35 = add nsw i64 %34, 8
  %.not = icmp eq i64 %18, 0
  %36 = select i1 %.not, i64 %35, i64 %34
  %scevgep74 = getelementptr i8, ptr %.unpack, i64 %36
  %bound0 = icmp ult ptr %14, %scevgep71
  %bound1 = icmp ult ptr %12, %scevgep
  %found.conflict = and i1 %bound0, %bound1
  %bound075 = icmp ult ptr %14, %scevgep74
  %bound176 = icmp ult ptr %scevgep72, %scevgep
  %found.conflict77 = and i1 %bound075, %bound176
  %conflict.rdx = or i1 %found.conflict, %found.conflict77
  %bound078 = icmp ult ptr %12, %scevgep74
  %bound179 = icmp ult ptr %scevgep72, %scevgep71
  %found.conflict80 = and i1 %bound078, %bound179
  %conflict.rdx81 = or i1 %conflict.rdx, %found.conflict80
  br i1 %conflict.rdx81, label %.lr.ph8.i.preheader, label %vector.ph

vector.ph:                                        ; preds = %vector.memcheck
  %n.vec = and i64 %22, -2
  %ind.end = sub nsw i64 %18, %n.vec
  %.cast = trunc i64 %n.vec to i32
  %ind.end83 = add i32 %6, %.cast
  %37 = load i32, ptr %12, align 4, !tbaa !4, !alias.scope !10, !noalias !13
  %broadcast.splatinsert = insertelement <2 x i32> poison, i32 %37, i64 0
  %38 = sitofp <2 x i32> %broadcast.splatinsert to <2 x float>
  %39 = fdiv contract <2 x float> <float 1.000000e+00, float poison>, %38
  %40 = shufflevector <2 x float> %39, <2 x float> poison, <2 x i32> zeroinitializer
  %41 = fpext <2 x float> %40 to <2 x double>
  %42 = extractelement <2 x double> %41, i64 1
  store double %42, ptr %14, align 8, !tbaa !4, !alias.scope !15, !noalias !17
  br label %vector.body

vector.body:                                      ; preds = %vector.body, %vector.ph
  %index = phi i64 [ 0, %vector.ph ], [ %index.next, %vector.body ]
  %.cast85 = trunc i64 %index to i32
  %offset.idx = add i32 %6, %.cast85
  %43 = sext i32 %offset.idx to i64
  %44 = add nsw i64 %43, -1
  %45 = getelementptr double, ptr %.unpack, i64 %44
  store <2 x double> %41, ptr %45, align 8, !tbaa !4, !alias.scope !13
  %index.next = add nuw i64 %index, 2
  %46 = icmp eq i64 %index.next, %n.vec
  br i1 %46, label %middle.block, label %vector.body, !llvm.loop !18

middle.block:                                     ; preds = %vector.body
  %cmp.n = icmp eq i64 %22, %n.vec
  br i1 %cmp.n, label %_QFPloop.exit, label %.lr.ph8.i.preheader

.lr.ph8.i.preheader:                              ; preds = %vector.memcheck, %vector.scevcheck, %.lr.ph8.preheader.i, %middle.block
  %.ph = phi i64 [ %18, %vector.memcheck ], [ %18, %vector.scevcheck ], [ %18, %.lr.ph8.preheader.i ], [ %ind.end, %middle.block ]
  %.ph86 = phi i32 [ %6, %vector.memcheck ], [ %6, %vector.scevcheck ], [ %6, %.lr.ph8.preheader.i ], [ %ind.end83, %middle.block ]
  br label %.lr.ph8.i

.lr.ph8.i:                                        ; preds = %.lr.ph8.i.preheader, %.lr.ph8.i
  %47 = phi i64 [ %57, %.lr.ph8.i ], [ %.ph, %.lr.ph8.i.preheader ]
  %48 = phi i32 [ %56, %.lr.ph8.i ], [ %.ph86, %.lr.ph8.i.preheader ]
  %49 = load i32, ptr %12, align 4, !tbaa !4
  %50 = sitofp i32 %49 to float
  %51 = fdiv contract float 1.000000e+00, %50
  %52 = fpext float %51 to double
  %53 = sext i32 %48 to i64
  %54 = add nsw i64 %53, -1
  %55 = getelementptr double, ptr %.unpack, i64 %54
  store double %52, ptr %55, align 8, !tbaa !4
  store double %52, ptr %14, align 8, !tbaa !4
  %56 = add i32 %48, 1
  %57 = add nsw i64 %47, -1
  %58 = icmp ugt i64 %47, 1
  br i1 %58, label %.lr.ph8.i, label %_QFPloop.exit.loopexit, !llvm.loop !21

_QFPloop.exit.loopexit:                           ; preds = %.lr.ph8.i
  br label %_QFPloop.exit

_QFPloop.exit:                                    ; preds = %_QFPloop.exit.loopexit, %middle.block, %omp.par.entry
  ret void
}
*** IR Dump After DivRemPairsPass on _QFPomp_subroutine..omp_par ***
; Function Attrs: norecurse nounwind
define internal void @_QFPomp_subroutine..omp_par(ptr noalias nocapture readnone %tid.addr, ptr noalias nocapture readnone %zero.addr, ptr nocapture readonly %0) #3 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %gep_3 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 2
  %loadgep_4 = load ptr, ptr %gep_3, align 8
  %gep_5 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 3
  %loadgep_6 = load ptr, ptr %gep_5, align 8
  %gep_7 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 4
  %loadgep_8 = load ptr, ptr %gep_7, align 8
  %1 = tail call i32 @omp_get_thread_num()
  %2 = tail call i32 @omp_get_num_threads()
  %3 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %4 = sdiv i32 %3, %2
  %5 = mul i32 %4, %1
  %6 = add i32 %5, 1
  %7 = add i32 %2, -1
  %8 = icmp eq i32 %1, %7
  %9 = add i32 %6, %4
  %spec.select = select i1 %8, i32 %3, i32 %9
  %.unpack = load ptr, ptr %loadgep_2, align 8, !tbaa !8
  %.elt14 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  %.unpack15 = load i64, ptr %.elt14, align 8, !tbaa !8
  %.elt16 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  %.unpack17 = load i32, ptr %.elt16, align 8, !tbaa !8
  %.elt18 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  %.unpack19 = load i8, ptr %.elt18, align 4, !tbaa !8
  %.elt20 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  %.unpack21 = load i8, ptr %.elt20, align 1, !tbaa !8
  %.elt22 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  %.unpack23 = load i8, ptr %.elt22, align 2, !tbaa !8
  %.elt24 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  %.unpack25 = load i8, ptr %.elt24, align 1, !tbaa !8
  %.elt26 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  %.unpack27.unpack.unpack = load i64, ptr %.elt26, align 8, !tbaa !8
  %.unpack27.unpack.elt29 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  %.unpack27.unpack.unpack30 = load i64, ptr %.unpack27.unpack.elt29, align 8, !tbaa !8
  %.unpack27.unpack.elt31 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  %.unpack27.unpack.unpack32 = load i64, ptr %.unpack27.unpack.elt31, align 8, !tbaa !8
  store ptr %.unpack, ptr %loadgep_4, align 8, !tbaa !8
  %loadgep_4.repack34 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 1
  store i64 %.unpack15, ptr %loadgep_4.repack34, align 8, !tbaa !8
  %loadgep_4.repack36 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 2
  store i32 %.unpack17, ptr %loadgep_4.repack36, align 8, !tbaa !8
  %loadgep_4.repack38 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 3
  store i8 %.unpack19, ptr %loadgep_4.repack38, align 4, !tbaa !8
  %loadgep_4.repack40 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 4
  store i8 %.unpack21, ptr %loadgep_4.repack40, align 1, !tbaa !8
  %loadgep_4.repack42 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 5
  store i8 %.unpack23, ptr %loadgep_4.repack42, align 2, !tbaa !8
  %loadgep_4.repack44 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 6
  store i8 %.unpack25, ptr %loadgep_4.repack44, align 1, !tbaa !8
  %loadgep_4.repack46 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7
  store i64 %.unpack27.unpack.unpack, ptr %loadgep_4.repack46, align 8, !tbaa !8
  %loadgep_4.repack46.repack48 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack27.unpack.unpack30, ptr %loadgep_4.repack46.repack48, align 8, !tbaa !8
  %loadgep_4.repack46.repack50 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 2
  store i64 %.unpack27.unpack.unpack32, ptr %loadgep_4.repack46.repack50, align 8, !tbaa !8
  %10 = icmp eq i64 %.unpack27.unpack.unpack30, 0
  %11 = select i1 %10, i64 1, i64 %.unpack27.unpack.unpack
  store ptr %.unpack, ptr %loadgep_6, align 8, !tbaa !8
  %loadgep_6.repack52 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 1
  store i64 8, ptr %loadgep_6.repack52, align 8, !tbaa !8
  %loadgep_6.repack54 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 2
  store i32 20180515, ptr %loadgep_6.repack54, align 8, !tbaa !8
  %loadgep_6.repack56 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 3
  store i8 1, ptr %loadgep_6.repack56, align 4, !tbaa !8
  %loadgep_6.repack58 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 4
  store i8 28, ptr %loadgep_6.repack58, align 1, !tbaa !8
  %loadgep_6.repack60 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 5
  store i8 0, ptr %loadgep_6.repack60, align 2, !tbaa !8
  %loadgep_6.repack62 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 6
  store i8 0, ptr %loadgep_6.repack62, align 1, !tbaa !8
  %loadgep_6.repack64 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7
  store i64 %11, ptr %loadgep_6.repack64, align 8, !tbaa !8
  %loadgep_6.repack64.repack66 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack27.unpack.unpack30, ptr %loadgep_6.repack64.repack66, align 8, !tbaa !8
  %loadgep_6.repack64.repack68 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7, i64 0, i64 2
  store i64 8, ptr %loadgep_6.repack64.repack68, align 8, !tbaa !8
  %12 = load ptr, ptr %loadgep_8, align 8, !tbaa !4
  %13 = getelementptr { ptr, ptr }, ptr %loadgep_8, i64 0, i32 1
  %14 = load ptr, ptr %13, align 8, !tbaa !4
  %15 = sext i32 %6 to i64
  %16 = sext i32 %spec.select to i64
  %reass.sub9.i = sub nsw i64 %16, %15
  %17 = icmp sgt i64 %reass.sub9.i, -1
  br i1 %17, label %.lr.ph8.preheader.i, label %_QFPloop.exit

.lr.ph8.preheader.i:                              ; preds = %omp.par.entry
  %18 = add nsw i64 %reass.sub9.i, 1
  %19 = add nsw i64 %16, 2
  %20 = icmp ne i64 %18, 0
  %umin82.neg = sext i1 %20 to i64
  %21 = add nsw i64 %19, %umin82.neg
  %22 = sub nsw i64 %21, %15
  %min.iters.check = icmp ult i64 %22, 8
  br i1 %min.iters.check, label %.lr.ph8.i.preheader, label %vector.scevcheck

vector.scevcheck:                                 ; preds = %.lr.ph8.preheader.i
  %23 = add nsw i64 %16, 1
  %24 = icmp ne i64 %18, 0
  %umin.neg = sext i1 %24 to i64
  %25 = add nsw i64 %23, %umin.neg
  %26 = sub nsw i64 %25, %15
  %27 = trunc i64 %26 to i32
  %28 = add i32 %6, %27
  %29 = icmp slt i32 %28, %6
  %30 = icmp ugt i64 %26, 4294967295
  %31 = or i1 %29, %30
  br i1 %31, label %.lr.ph8.i.preheader, label %vector.memcheck

vector.memcheck:                                  ; preds = %vector.scevcheck
  %scevgep = getelementptr i8, ptr %14, i64 8
  %scevgep71 = getelementptr i8, ptr %12, i64 4
  %32 = shl nsw i64 %15, 3
  %33 = add nsw i64 %32, -8
  %scevgep72 = getelementptr i8, ptr %.unpack, i64 %33
  %34 = shl nsw i64 %16, 3
  %35 = add nsw i64 %34, 8
  %.not = icmp eq i64 %18, 0
  %36 = select i1 %.not, i64 %35, i64 %34
  %scevgep74 = getelementptr i8, ptr %.unpack, i64 %36
  %bound0 = icmp ult ptr %14, %scevgep71
  %bound1 = icmp ult ptr %12, %scevgep
  %found.conflict = and i1 %bound0, %bound1
  %bound075 = icmp ult ptr %14, %scevgep74
  %bound176 = icmp ult ptr %scevgep72, %scevgep
  %found.conflict77 = and i1 %bound075, %bound176
  %conflict.rdx = or i1 %found.conflict, %found.conflict77
  %bound078 = icmp ult ptr %12, %scevgep74
  %bound179 = icmp ult ptr %scevgep72, %scevgep71
  %found.conflict80 = and i1 %bound078, %bound179
  %conflict.rdx81 = or i1 %conflict.rdx, %found.conflict80
  br i1 %conflict.rdx81, label %.lr.ph8.i.preheader, label %vector.ph

vector.ph:                                        ; preds = %vector.memcheck
  %n.vec = and i64 %22, -2
  %ind.end = sub nsw i64 %18, %n.vec
  %.cast = trunc i64 %n.vec to i32
  %ind.end83 = add i32 %6, %.cast
  %37 = load i32, ptr %12, align 4, !tbaa !4, !alias.scope !10, !noalias !13
  %broadcast.splatinsert = insertelement <2 x i32> poison, i32 %37, i64 0
  %38 = sitofp <2 x i32> %broadcast.splatinsert to <2 x float>
  %39 = fdiv contract <2 x float> <float 1.000000e+00, float poison>, %38
  %40 = shufflevector <2 x float> %39, <2 x float> poison, <2 x i32> zeroinitializer
  %41 = fpext <2 x float> %40 to <2 x double>
  %42 = extractelement <2 x double> %41, i64 1
  store double %42, ptr %14, align 8, !tbaa !4, !alias.scope !15, !noalias !17
  br label %vector.body

vector.body:                                      ; preds = %vector.body, %vector.ph
  %index = phi i64 [ 0, %vector.ph ], [ %index.next, %vector.body ]
  %.cast85 = trunc i64 %index to i32
  %offset.idx = add i32 %6, %.cast85
  %43 = sext i32 %offset.idx to i64
  %44 = add nsw i64 %43, -1
  %45 = getelementptr double, ptr %.unpack, i64 %44
  store <2 x double> %41, ptr %45, align 8, !tbaa !4, !alias.scope !13
  %index.next = add nuw i64 %index, 2
  %46 = icmp eq i64 %index.next, %n.vec
  br i1 %46, label %middle.block, label %vector.body, !llvm.loop !18

middle.block:                                     ; preds = %vector.body
  %cmp.n = icmp eq i64 %22, %n.vec
  br i1 %cmp.n, label %_QFPloop.exit, label %.lr.ph8.i.preheader

.lr.ph8.i.preheader:                              ; preds = %vector.memcheck, %vector.scevcheck, %.lr.ph8.preheader.i, %middle.block
  %.ph = phi i64 [ %18, %vector.memcheck ], [ %18, %vector.scevcheck ], [ %18, %.lr.ph8.preheader.i ], [ %ind.end, %middle.block ]
  %.ph86 = phi i32 [ %6, %vector.memcheck ], [ %6, %vector.scevcheck ], [ %6, %.lr.ph8.preheader.i ], [ %ind.end83, %middle.block ]
  br label %.lr.ph8.i

.lr.ph8.i:                                        ; preds = %.lr.ph8.i.preheader, %.lr.ph8.i
  %47 = phi i64 [ %57, %.lr.ph8.i ], [ %.ph, %.lr.ph8.i.preheader ]
  %48 = phi i32 [ %56, %.lr.ph8.i ], [ %.ph86, %.lr.ph8.i.preheader ]
  %49 = load i32, ptr %12, align 4, !tbaa !4
  %50 = sitofp i32 %49 to float
  %51 = fdiv contract float 1.000000e+00, %50
  %52 = fpext float %51 to double
  %53 = sext i32 %48 to i64
  %54 = add nsw i64 %53, -1
  %55 = getelementptr double, ptr %.unpack, i64 %54
  store double %52, ptr %55, align 8, !tbaa !4
  store double %52, ptr %14, align 8, !tbaa !4
  %56 = add i32 %48, 1
  %57 = add nsw i64 %47, -1
  %58 = icmp ugt i64 %47, 1
  br i1 %58, label %.lr.ph8.i, label %_QFPloop.exit.loopexit, !llvm.loop !21

_QFPloop.exit.loopexit:                           ; preds = %.lr.ph8.i
  br label %_QFPloop.exit

_QFPloop.exit:                                    ; preds = %_QFPloop.exit.loopexit, %middle.block, %omp.par.entry
  ret void
}
*** IR Dump After TailCallElimPass on _QFPomp_subroutine..omp_par ***
; Function Attrs: norecurse nounwind
define internal void @_QFPomp_subroutine..omp_par(ptr noalias nocapture readnone %tid.addr, ptr noalias nocapture readnone %zero.addr, ptr nocapture readonly %0) #3 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %gep_3 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 2
  %loadgep_4 = load ptr, ptr %gep_3, align 8
  %gep_5 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 3
  %loadgep_6 = load ptr, ptr %gep_5, align 8
  %gep_7 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 4
  %loadgep_8 = load ptr, ptr %gep_7, align 8
  %1 = tail call i32 @omp_get_thread_num()
  %2 = tail call i32 @omp_get_num_threads()
  %3 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %4 = sdiv i32 %3, %2
  %5 = mul i32 %4, %1
  %6 = add i32 %5, 1
  %7 = add i32 %2, -1
  %8 = icmp eq i32 %1, %7
  %9 = add i32 %6, %4
  %spec.select = select i1 %8, i32 %3, i32 %9
  %.unpack = load ptr, ptr %loadgep_2, align 8, !tbaa !8
  %.elt14 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  %.unpack15 = load i64, ptr %.elt14, align 8, !tbaa !8
  %.elt16 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  %.unpack17 = load i32, ptr %.elt16, align 8, !tbaa !8
  %.elt18 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  %.unpack19 = load i8, ptr %.elt18, align 4, !tbaa !8
  %.elt20 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  %.unpack21 = load i8, ptr %.elt20, align 1, !tbaa !8
  %.elt22 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  %.unpack23 = load i8, ptr %.elt22, align 2, !tbaa !8
  %.elt24 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  %.unpack25 = load i8, ptr %.elt24, align 1, !tbaa !8
  %.elt26 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  %.unpack27.unpack.unpack = load i64, ptr %.elt26, align 8, !tbaa !8
  %.unpack27.unpack.elt29 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  %.unpack27.unpack.unpack30 = load i64, ptr %.unpack27.unpack.elt29, align 8, !tbaa !8
  %.unpack27.unpack.elt31 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  %.unpack27.unpack.unpack32 = load i64, ptr %.unpack27.unpack.elt31, align 8, !tbaa !8
  store ptr %.unpack, ptr %loadgep_4, align 8, !tbaa !8
  %loadgep_4.repack34 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 1
  store i64 %.unpack15, ptr %loadgep_4.repack34, align 8, !tbaa !8
  %loadgep_4.repack36 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 2
  store i32 %.unpack17, ptr %loadgep_4.repack36, align 8, !tbaa !8
  %loadgep_4.repack38 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 3
  store i8 %.unpack19, ptr %loadgep_4.repack38, align 4, !tbaa !8
  %loadgep_4.repack40 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 4
  store i8 %.unpack21, ptr %loadgep_4.repack40, align 1, !tbaa !8
  %loadgep_4.repack42 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 5
  store i8 %.unpack23, ptr %loadgep_4.repack42, align 2, !tbaa !8
  %loadgep_4.repack44 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 6
  store i8 %.unpack25, ptr %loadgep_4.repack44, align 1, !tbaa !8
  %loadgep_4.repack46 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7
  store i64 %.unpack27.unpack.unpack, ptr %loadgep_4.repack46, align 8, !tbaa !8
  %loadgep_4.repack46.repack48 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack27.unpack.unpack30, ptr %loadgep_4.repack46.repack48, align 8, !tbaa !8
  %loadgep_4.repack46.repack50 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 2
  store i64 %.unpack27.unpack.unpack32, ptr %loadgep_4.repack46.repack50, align 8, !tbaa !8
  %10 = icmp eq i64 %.unpack27.unpack.unpack30, 0
  %11 = select i1 %10, i64 1, i64 %.unpack27.unpack.unpack
  store ptr %.unpack, ptr %loadgep_6, align 8, !tbaa !8
  %loadgep_6.repack52 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 1
  store i64 8, ptr %loadgep_6.repack52, align 8, !tbaa !8
  %loadgep_6.repack54 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 2
  store i32 20180515, ptr %loadgep_6.repack54, align 8, !tbaa !8
  %loadgep_6.repack56 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 3
  store i8 1, ptr %loadgep_6.repack56, align 4, !tbaa !8
  %loadgep_6.repack58 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 4
  store i8 28, ptr %loadgep_6.repack58, align 1, !tbaa !8
  %loadgep_6.repack60 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 5
  store i8 0, ptr %loadgep_6.repack60, align 2, !tbaa !8
  %loadgep_6.repack62 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 6
  store i8 0, ptr %loadgep_6.repack62, align 1, !tbaa !8
  %loadgep_6.repack64 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7
  store i64 %11, ptr %loadgep_6.repack64, align 8, !tbaa !8
  %loadgep_6.repack64.repack66 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack27.unpack.unpack30, ptr %loadgep_6.repack64.repack66, align 8, !tbaa !8
  %loadgep_6.repack64.repack68 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7, i64 0, i64 2
  store i64 8, ptr %loadgep_6.repack64.repack68, align 8, !tbaa !8
  %12 = load ptr, ptr %loadgep_8, align 8, !tbaa !4
  %13 = getelementptr { ptr, ptr }, ptr %loadgep_8, i64 0, i32 1
  %14 = load ptr, ptr %13, align 8, !tbaa !4
  %15 = sext i32 %6 to i64
  %16 = sext i32 %spec.select to i64
  %reass.sub9.i = sub nsw i64 %16, %15
  %17 = icmp sgt i64 %reass.sub9.i, -1
  br i1 %17, label %.lr.ph8.preheader.i, label %_QFPloop.exit

.lr.ph8.preheader.i:                              ; preds = %omp.par.entry
  %18 = add nsw i64 %reass.sub9.i, 1
  %19 = add nsw i64 %16, 2
  %20 = icmp ne i64 %18, 0
  %umin82.neg = sext i1 %20 to i64
  %21 = add nsw i64 %19, %umin82.neg
  %22 = sub nsw i64 %21, %15
  %min.iters.check = icmp ult i64 %22, 8
  br i1 %min.iters.check, label %.lr.ph8.i.preheader, label %vector.scevcheck

vector.scevcheck:                                 ; preds = %.lr.ph8.preheader.i
  %23 = add nsw i64 %16, 1
  %24 = icmp ne i64 %18, 0
  %umin.neg = sext i1 %24 to i64
  %25 = add nsw i64 %23, %umin.neg
  %26 = sub nsw i64 %25, %15
  %27 = trunc i64 %26 to i32
  %28 = add i32 %6, %27
  %29 = icmp slt i32 %28, %6
  %30 = icmp ugt i64 %26, 4294967295
  %31 = or i1 %29, %30
  br i1 %31, label %.lr.ph8.i.preheader, label %vector.memcheck

vector.memcheck:                                  ; preds = %vector.scevcheck
  %scevgep = getelementptr i8, ptr %14, i64 8
  %scevgep71 = getelementptr i8, ptr %12, i64 4
  %32 = shl nsw i64 %15, 3
  %33 = add nsw i64 %32, -8
  %scevgep72 = getelementptr i8, ptr %.unpack, i64 %33
  %34 = shl nsw i64 %16, 3
  %35 = add nsw i64 %34, 8
  %.not = icmp eq i64 %18, 0
  %36 = select i1 %.not, i64 %35, i64 %34
  %scevgep74 = getelementptr i8, ptr %.unpack, i64 %36
  %bound0 = icmp ult ptr %14, %scevgep71
  %bound1 = icmp ult ptr %12, %scevgep
  %found.conflict = and i1 %bound0, %bound1
  %bound075 = icmp ult ptr %14, %scevgep74
  %bound176 = icmp ult ptr %scevgep72, %scevgep
  %found.conflict77 = and i1 %bound075, %bound176
  %conflict.rdx = or i1 %found.conflict, %found.conflict77
  %bound078 = icmp ult ptr %12, %scevgep74
  %bound179 = icmp ult ptr %scevgep72, %scevgep71
  %found.conflict80 = and i1 %bound078, %bound179
  %conflict.rdx81 = or i1 %conflict.rdx, %found.conflict80
  br i1 %conflict.rdx81, label %.lr.ph8.i.preheader, label %vector.ph

vector.ph:                                        ; preds = %vector.memcheck
  %n.vec = and i64 %22, -2
  %ind.end = sub nsw i64 %18, %n.vec
  %.cast = trunc i64 %n.vec to i32
  %ind.end83 = add i32 %6, %.cast
  %37 = load i32, ptr %12, align 4, !tbaa !4, !alias.scope !10, !noalias !13
  %broadcast.splatinsert = insertelement <2 x i32> poison, i32 %37, i64 0
  %38 = sitofp <2 x i32> %broadcast.splatinsert to <2 x float>
  %39 = fdiv contract <2 x float> <float 1.000000e+00, float poison>, %38
  %40 = shufflevector <2 x float> %39, <2 x float> poison, <2 x i32> zeroinitializer
  %41 = fpext <2 x float> %40 to <2 x double>
  %42 = extractelement <2 x double> %41, i64 1
  store double %42, ptr %14, align 8, !tbaa !4, !alias.scope !15, !noalias !17
  br label %vector.body

vector.body:                                      ; preds = %vector.body, %vector.ph
  %index = phi i64 [ 0, %vector.ph ], [ %index.next, %vector.body ]
  %.cast85 = trunc i64 %index to i32
  %offset.idx = add i32 %6, %.cast85
  %43 = sext i32 %offset.idx to i64
  %44 = add nsw i64 %43, -1
  %45 = getelementptr double, ptr %.unpack, i64 %44
  store <2 x double> %41, ptr %45, align 8, !tbaa !4, !alias.scope !13
  %index.next = add nuw i64 %index, 2
  %46 = icmp eq i64 %index.next, %n.vec
  br i1 %46, label %middle.block, label %vector.body, !llvm.loop !18

middle.block:                                     ; preds = %vector.body
  %cmp.n = icmp eq i64 %22, %n.vec
  br i1 %cmp.n, label %_QFPloop.exit, label %.lr.ph8.i.preheader

.lr.ph8.i.preheader:                              ; preds = %vector.memcheck, %vector.scevcheck, %.lr.ph8.preheader.i, %middle.block
  %.ph = phi i64 [ %18, %vector.memcheck ], [ %18, %vector.scevcheck ], [ %18, %.lr.ph8.preheader.i ], [ %ind.end, %middle.block ]
  %.ph86 = phi i32 [ %6, %vector.memcheck ], [ %6, %vector.scevcheck ], [ %6, %.lr.ph8.preheader.i ], [ %ind.end83, %middle.block ]
  br label %.lr.ph8.i

.lr.ph8.i:                                        ; preds = %.lr.ph8.i.preheader, %.lr.ph8.i
  %47 = phi i64 [ %57, %.lr.ph8.i ], [ %.ph, %.lr.ph8.i.preheader ]
  %48 = phi i32 [ %56, %.lr.ph8.i ], [ %.ph86, %.lr.ph8.i.preheader ]
  %49 = load i32, ptr %12, align 4, !tbaa !4
  %50 = sitofp i32 %49 to float
  %51 = fdiv contract float 1.000000e+00, %50
  %52 = fpext float %51 to double
  %53 = sext i32 %48 to i64
  %54 = add nsw i64 %53, -1
  %55 = getelementptr double, ptr %.unpack, i64 %54
  store double %52, ptr %55, align 8, !tbaa !4
  store double %52, ptr %14, align 8, !tbaa !4
  %56 = add i32 %48, 1
  %57 = add nsw i64 %47, -1
  %58 = icmp ugt i64 %47, 1
  br i1 %58, label %.lr.ph8.i, label %_QFPloop.exit.loopexit, !llvm.loop !21

_QFPloop.exit.loopexit:                           ; preds = %.lr.ph8.i
  br label %_QFPloop.exit

_QFPloop.exit:                                    ; preds = %_QFPloop.exit.loopexit, %middle.block, %omp.par.entry
  ret void
}
*** IR Dump After SimplifyCFGPass on _QFPomp_subroutine..omp_par ***
; Function Attrs: norecurse nounwind
define internal void @_QFPomp_subroutine..omp_par(ptr noalias nocapture readnone %tid.addr, ptr noalias nocapture readnone %zero.addr, ptr nocapture readonly %0) #3 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %gep_3 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 2
  %loadgep_4 = load ptr, ptr %gep_3, align 8
  %gep_5 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 3
  %loadgep_6 = load ptr, ptr %gep_5, align 8
  %gep_7 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 4
  %loadgep_8 = load ptr, ptr %gep_7, align 8
  %1 = tail call i32 @omp_get_thread_num()
  %2 = tail call i32 @omp_get_num_threads()
  %3 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %4 = sdiv i32 %3, %2
  %5 = mul i32 %4, %1
  %6 = add i32 %5, 1
  %7 = add i32 %2, -1
  %8 = icmp eq i32 %1, %7
  %9 = add i32 %6, %4
  %spec.select = select i1 %8, i32 %3, i32 %9
  %.unpack = load ptr, ptr %loadgep_2, align 8, !tbaa !8
  %.elt14 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  %.unpack15 = load i64, ptr %.elt14, align 8, !tbaa !8
  %.elt16 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  %.unpack17 = load i32, ptr %.elt16, align 8, !tbaa !8
  %.elt18 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  %.unpack19 = load i8, ptr %.elt18, align 4, !tbaa !8
  %.elt20 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  %.unpack21 = load i8, ptr %.elt20, align 1, !tbaa !8
  %.elt22 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  %.unpack23 = load i8, ptr %.elt22, align 2, !tbaa !8
  %.elt24 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  %.unpack25 = load i8, ptr %.elt24, align 1, !tbaa !8
  %.elt26 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  %.unpack27.unpack.unpack = load i64, ptr %.elt26, align 8, !tbaa !8
  %.unpack27.unpack.elt29 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  %.unpack27.unpack.unpack30 = load i64, ptr %.unpack27.unpack.elt29, align 8, !tbaa !8
  %.unpack27.unpack.elt31 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  %.unpack27.unpack.unpack32 = load i64, ptr %.unpack27.unpack.elt31, align 8, !tbaa !8
  store ptr %.unpack, ptr %loadgep_4, align 8, !tbaa !8
  %loadgep_4.repack34 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 1
  store i64 %.unpack15, ptr %loadgep_4.repack34, align 8, !tbaa !8
  %loadgep_4.repack36 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 2
  store i32 %.unpack17, ptr %loadgep_4.repack36, align 8, !tbaa !8
  %loadgep_4.repack38 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 3
  store i8 %.unpack19, ptr %loadgep_4.repack38, align 4, !tbaa !8
  %loadgep_4.repack40 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 4
  store i8 %.unpack21, ptr %loadgep_4.repack40, align 1, !tbaa !8
  %loadgep_4.repack42 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 5
  store i8 %.unpack23, ptr %loadgep_4.repack42, align 2, !tbaa !8
  %loadgep_4.repack44 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 6
  store i8 %.unpack25, ptr %loadgep_4.repack44, align 1, !tbaa !8
  %loadgep_4.repack46 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7
  store i64 %.unpack27.unpack.unpack, ptr %loadgep_4.repack46, align 8, !tbaa !8
  %loadgep_4.repack46.repack48 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack27.unpack.unpack30, ptr %loadgep_4.repack46.repack48, align 8, !tbaa !8
  %loadgep_4.repack46.repack50 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 2
  store i64 %.unpack27.unpack.unpack32, ptr %loadgep_4.repack46.repack50, align 8, !tbaa !8
  %10 = icmp eq i64 %.unpack27.unpack.unpack30, 0
  %11 = select i1 %10, i64 1, i64 %.unpack27.unpack.unpack
  store ptr %.unpack, ptr %loadgep_6, align 8, !tbaa !8
  %loadgep_6.repack52 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 1
  store i64 8, ptr %loadgep_6.repack52, align 8, !tbaa !8
  %loadgep_6.repack54 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 2
  store i32 20180515, ptr %loadgep_6.repack54, align 8, !tbaa !8
  %loadgep_6.repack56 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 3
  store i8 1, ptr %loadgep_6.repack56, align 4, !tbaa !8
  %loadgep_6.repack58 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 4
  store i8 28, ptr %loadgep_6.repack58, align 1, !tbaa !8
  %loadgep_6.repack60 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 5
  store i8 0, ptr %loadgep_6.repack60, align 2, !tbaa !8
  %loadgep_6.repack62 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 6
  store i8 0, ptr %loadgep_6.repack62, align 1, !tbaa !8
  %loadgep_6.repack64 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7
  store i64 %11, ptr %loadgep_6.repack64, align 8, !tbaa !8
  %loadgep_6.repack64.repack66 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack27.unpack.unpack30, ptr %loadgep_6.repack64.repack66, align 8, !tbaa !8
  %loadgep_6.repack64.repack68 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7, i64 0, i64 2
  store i64 8, ptr %loadgep_6.repack64.repack68, align 8, !tbaa !8
  %12 = load ptr, ptr %loadgep_8, align 8, !tbaa !4
  %13 = getelementptr { ptr, ptr }, ptr %loadgep_8, i64 0, i32 1
  %14 = load ptr, ptr %13, align 8, !tbaa !4
  %15 = sext i32 %6 to i64
  %16 = sext i32 %spec.select to i64
  %reass.sub9.i = sub nsw i64 %16, %15
  %17 = icmp sgt i64 %reass.sub9.i, -1
  br i1 %17, label %.lr.ph8.preheader.i, label %_QFPloop.exit

.lr.ph8.preheader.i:                              ; preds = %omp.par.entry
  %18 = add nsw i64 %reass.sub9.i, 1
  %19 = add nsw i64 %16, 2
  %20 = icmp ne i64 %18, 0
  %umin82.neg = sext i1 %20 to i64
  %21 = add nsw i64 %19, %umin82.neg
  %22 = sub nsw i64 %21, %15
  %min.iters.check = icmp ult i64 %22, 8
  br i1 %min.iters.check, label %.lr.ph8.i.preheader, label %vector.scevcheck

vector.scevcheck:                                 ; preds = %.lr.ph8.preheader.i
  %23 = add nsw i64 %16, 1
  %24 = icmp ne i64 %18, 0
  %umin.neg = sext i1 %24 to i64
  %25 = add nsw i64 %23, %umin.neg
  %26 = sub nsw i64 %25, %15
  %27 = trunc i64 %26 to i32
  %28 = add i32 %6, %27
  %29 = icmp slt i32 %28, %6
  %30 = icmp ugt i64 %26, 4294967295
  %31 = or i1 %29, %30
  br i1 %31, label %.lr.ph8.i.preheader, label %vector.memcheck

vector.memcheck:                                  ; preds = %vector.scevcheck
  %scevgep = getelementptr i8, ptr %14, i64 8
  %scevgep71 = getelementptr i8, ptr %12, i64 4
  %32 = shl nsw i64 %15, 3
  %33 = add nsw i64 %32, -8
  %scevgep72 = getelementptr i8, ptr %.unpack, i64 %33
  %34 = shl nsw i64 %16, 3
  %35 = add nsw i64 %34, 8
  %.not = icmp eq i64 %18, 0
  %36 = select i1 %.not, i64 %35, i64 %34
  %scevgep74 = getelementptr i8, ptr %.unpack, i64 %36
  %bound0 = icmp ult ptr %14, %scevgep71
  %bound1 = icmp ult ptr %12, %scevgep
  %found.conflict = and i1 %bound0, %bound1
  %bound075 = icmp ult ptr %14, %scevgep74
  %bound176 = icmp ult ptr %scevgep72, %scevgep
  %found.conflict77 = and i1 %bound075, %bound176
  %conflict.rdx = or i1 %found.conflict, %found.conflict77
  %bound078 = icmp ult ptr %12, %scevgep74
  %bound179 = icmp ult ptr %scevgep72, %scevgep71
  %found.conflict80 = and i1 %bound078, %bound179
  %conflict.rdx81 = or i1 %conflict.rdx, %found.conflict80
  br i1 %conflict.rdx81, label %.lr.ph8.i.preheader, label %vector.ph

vector.ph:                                        ; preds = %vector.memcheck
  %n.vec = and i64 %22, -2
  %ind.end = sub nsw i64 %18, %n.vec
  %.cast = trunc i64 %n.vec to i32
  %ind.end83 = add i32 %6, %.cast
  %37 = load i32, ptr %12, align 4, !tbaa !4, !alias.scope !10, !noalias !13
  %broadcast.splatinsert = insertelement <2 x i32> poison, i32 %37, i64 0
  %38 = sitofp <2 x i32> %broadcast.splatinsert to <2 x float>
  %39 = fdiv contract <2 x float> <float 1.000000e+00, float poison>, %38
  %40 = shufflevector <2 x float> %39, <2 x float> poison, <2 x i32> zeroinitializer
  %41 = fpext <2 x float> %40 to <2 x double>
  %42 = extractelement <2 x double> %41, i64 1
  store double %42, ptr %14, align 8, !tbaa !4, !alias.scope !15, !noalias !17
  br label %vector.body

vector.body:                                      ; preds = %vector.body, %vector.ph
  %index = phi i64 [ 0, %vector.ph ], [ %index.next, %vector.body ]
  %.cast85 = trunc i64 %index to i32
  %offset.idx = add i32 %6, %.cast85
  %43 = sext i32 %offset.idx to i64
  %44 = add nsw i64 %43, -1
  %45 = getelementptr double, ptr %.unpack, i64 %44
  store <2 x double> %41, ptr %45, align 8, !tbaa !4, !alias.scope !13
  %index.next = add nuw i64 %index, 2
  %46 = icmp eq i64 %index.next, %n.vec
  br i1 %46, label %middle.block, label %vector.body, !llvm.loop !18

middle.block:                                     ; preds = %vector.body
  %cmp.n = icmp eq i64 %22, %n.vec
  br i1 %cmp.n, label %_QFPloop.exit, label %.lr.ph8.i.preheader

.lr.ph8.i.preheader:                              ; preds = %vector.memcheck, %vector.scevcheck, %.lr.ph8.preheader.i, %middle.block
  %.ph = phi i64 [ %18, %vector.memcheck ], [ %18, %vector.scevcheck ], [ %18, %.lr.ph8.preheader.i ], [ %ind.end, %middle.block ]
  %.ph86 = phi i32 [ %6, %vector.memcheck ], [ %6, %vector.scevcheck ], [ %6, %.lr.ph8.preheader.i ], [ %ind.end83, %middle.block ]
  br label %.lr.ph8.i

.lr.ph8.i:                                        ; preds = %.lr.ph8.i.preheader, %.lr.ph8.i
  %47 = phi i64 [ %57, %.lr.ph8.i ], [ %.ph, %.lr.ph8.i.preheader ]
  %48 = phi i32 [ %56, %.lr.ph8.i ], [ %.ph86, %.lr.ph8.i.preheader ]
  %49 = load i32, ptr %12, align 4, !tbaa !4
  %50 = sitofp i32 %49 to float
  %51 = fdiv contract float 1.000000e+00, %50
  %52 = fpext float %51 to double
  %53 = sext i32 %48 to i64
  %54 = add nsw i64 %53, -1
  %55 = getelementptr double, ptr %.unpack, i64 %54
  store double %52, ptr %55, align 8, !tbaa !4
  store double %52, ptr %14, align 8, !tbaa !4
  %56 = add i32 %48, 1
  %57 = add nsw i64 %47, -1
  %58 = icmp ugt i64 %47, 1
  br i1 %58, label %.lr.ph8.i, label %_QFPloop.exit, !llvm.loop !21

_QFPloop.exit:                                    ; preds = %.lr.ph8.i, %middle.block, %omp.par.entry
  ret void
}
*** IR Dump After Float2IntPass on _QFPloop ***
; Function Attrs: nofree norecurse nosync nounwind memory(readwrite, inaccessiblemem: none)
define void @_QFPloop(ptr nocapture readonly %0, ptr nocapture readonly %1, ptr nocapture readonly %2, ptr nest nocapture readonly %3) local_unnamed_addr #4 {
  %5 = load ptr, ptr %3, align 8, !tbaa !4
  %6 = getelementptr { ptr, ptr }, ptr %3, i64 0, i32 1
  %7 = load ptr, ptr %6, align 8, !tbaa !4
  %8 = load i32, ptr %0, align 4, !tbaa !4
  %9 = sext i32 %8 to i64
  %10 = load i32, ptr %1, align 4, !tbaa !4
  %11 = sext i32 %10 to i64
  %12 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %2, i64 0, i32 7, i64 0, i64 2
  %13 = load i64, ptr %12, align 8, !tbaa !8
  %14 = icmp eq i64 %13, 8
  br i1 %14, label %15, label %31

15:                                               ; preds = %4
  %16 = load ptr, ptr %2, align 8, !tbaa !8
  %reass.sub9 = sub nsw i64 %11, %9
  %17 = icmp sgt i64 %reass.sub9, -1
  br i1 %17, label %.lr.ph8.preheader, label %.loopexit

.lr.ph8.preheader:                                ; preds = %15
  %18 = add nuw nsw i64 %reass.sub9, 1
  br label %.lr.ph8

.lr.ph8:                                          ; preds = %.lr.ph8.preheader, %.lr.ph8
  %19 = phi i64 [ %29, %.lr.ph8 ], [ %18, %.lr.ph8.preheader ]
  %20 = phi i32 [ %28, %.lr.ph8 ], [ %8, %.lr.ph8.preheader ]
  %21 = load i32, ptr %5, align 4, !tbaa !4
  %22 = sitofp i32 %21 to float
  %23 = fdiv contract float 1.000000e+00, %22
  %24 = fpext float %23 to double
  %25 = sext i32 %20 to i64
  %26 = add nsw i64 %25, -1
  %27 = getelementptr double, ptr %16, i64 %26
  store double %24, ptr %27, align 8, !tbaa !4
  store double %24, ptr %7, align 8, !tbaa !4
  %28 = add i32 %20, 1
  %29 = add nsw i64 %19, -1
  %30 = icmp ugt i64 %19, 1
  br i1 %30, label %.lr.ph8, label %.loopexit

31:                                               ; preds = %4
  %reass.sub = sub nsw i64 %11, %9
  %32 = icmp sgt i64 %reass.sub, -1
  br i1 %32, label %.lr.ph, label %.loopexit

.lr.ph:                                           ; preds = %31
  %33 = add nuw nsw i64 %reass.sub, 1
  %34 = load ptr, ptr %2, align 8, !tbaa !8
  br label %35

35:                                               ; preds = %.lr.ph, %35
  %36 = phi i64 [ %33, %.lr.ph ], [ %47, %35 ]
  %37 = phi i32 [ %8, %.lr.ph ], [ %46, %35 ]
  %38 = load i32, ptr %5, align 4, !tbaa !4
  %39 = sitofp i32 %38 to float
  %40 = fdiv contract float 1.000000e+00, %39
  %41 = fpext float %40 to double
  %42 = sext i32 %37 to i64
  %43 = add nsw i64 %42, -1
  %44 = mul i64 %43, %13
  %45 = getelementptr i8, ptr %34, i64 %44
  store double %41, ptr %45, align 8, !tbaa !4
  store double %41, ptr %7, align 8, !tbaa !4
  %46 = add i32 %37, 1
  %47 = add nsw i64 %36, -1
  %48 = icmp ugt i64 %36, 1
  br i1 %48, label %35, label %.loopexit

.loopexit:                                        ; preds = %35, %.lr.ph8, %31, %15
  ret void
}
*** IR Dump After LowerConstantIntrinsicsPass on _QFPloop ***
; Function Attrs: nofree norecurse nosync nounwind memory(readwrite, inaccessiblemem: none)
define void @_QFPloop(ptr nocapture readonly %0, ptr nocapture readonly %1, ptr nocapture readonly %2, ptr nest nocapture readonly %3) local_unnamed_addr #4 {
  %5 = load ptr, ptr %3, align 8, !tbaa !4
  %6 = getelementptr { ptr, ptr }, ptr %3, i64 0, i32 1
  %7 = load ptr, ptr %6, align 8, !tbaa !4
  %8 = load i32, ptr %0, align 4, !tbaa !4
  %9 = sext i32 %8 to i64
  %10 = load i32, ptr %1, align 4, !tbaa !4
  %11 = sext i32 %10 to i64
  %12 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %2, i64 0, i32 7, i64 0, i64 2
  %13 = load i64, ptr %12, align 8, !tbaa !8
  %14 = icmp eq i64 %13, 8
  br i1 %14, label %15, label %31

15:                                               ; preds = %4
  %16 = load ptr, ptr %2, align 8, !tbaa !8
  %reass.sub9 = sub nsw i64 %11, %9
  %17 = icmp sgt i64 %reass.sub9, -1
  br i1 %17, label %.lr.ph8.preheader, label %.loopexit

.lr.ph8.preheader:                                ; preds = %15
  %18 = add nuw nsw i64 %reass.sub9, 1
  br label %.lr.ph8

.lr.ph8:                                          ; preds = %.lr.ph8.preheader, %.lr.ph8
  %19 = phi i64 [ %29, %.lr.ph8 ], [ %18, %.lr.ph8.preheader ]
  %20 = phi i32 [ %28, %.lr.ph8 ], [ %8, %.lr.ph8.preheader ]
  %21 = load i32, ptr %5, align 4, !tbaa !4
  %22 = sitofp i32 %21 to float
  %23 = fdiv contract float 1.000000e+00, %22
  %24 = fpext float %23 to double
  %25 = sext i32 %20 to i64
  %26 = add nsw i64 %25, -1
  %27 = getelementptr double, ptr %16, i64 %26
  store double %24, ptr %27, align 8, !tbaa !4
  store double %24, ptr %7, align 8, !tbaa !4
  %28 = add i32 %20, 1
  %29 = add nsw i64 %19, -1
  %30 = icmp ugt i64 %19, 1
  br i1 %30, label %.lr.ph8, label %.loopexit

31:                                               ; preds = %4
  %reass.sub = sub nsw i64 %11, %9
  %32 = icmp sgt i64 %reass.sub, -1
  br i1 %32, label %.lr.ph, label %.loopexit

.lr.ph:                                           ; preds = %31
  %33 = add nuw nsw i64 %reass.sub, 1
  %34 = load ptr, ptr %2, align 8, !tbaa !8
  br label %35

35:                                               ; preds = %.lr.ph, %35
  %36 = phi i64 [ %33, %.lr.ph ], [ %47, %35 ]
  %37 = phi i32 [ %8, %.lr.ph ], [ %46, %35 ]
  %38 = load i32, ptr %5, align 4, !tbaa !4
  %39 = sitofp i32 %38 to float
  %40 = fdiv contract float 1.000000e+00, %39
  %41 = fpext float %40 to double
  %42 = sext i32 %37 to i64
  %43 = add nsw i64 %42, -1
  %44 = mul i64 %43, %13
  %45 = getelementptr i8, ptr %34, i64 %44
  store double %41, ptr %45, align 8, !tbaa !4
  store double %41, ptr %7, align 8, !tbaa !4
  %46 = add i32 %37, 1
  %47 = add nsw i64 %36, -1
  %48 = icmp ugt i64 %36, 1
  br i1 %48, label %35, label %.loopexit

.loopexit:                                        ; preds = %35, %.lr.ph8, %31, %15
  ret void
}
*** IR Dump After ControlHeightReductionPass on _QFPloop ***
; Function Attrs: nofree norecurse nosync nounwind memory(readwrite, inaccessiblemem: none)
define void @_QFPloop(ptr nocapture readonly %0, ptr nocapture readonly %1, ptr nocapture readonly %2, ptr nest nocapture readonly %3) local_unnamed_addr #4 {
  %5 = load ptr, ptr %3, align 8, !tbaa !4
  %6 = getelementptr { ptr, ptr }, ptr %3, i64 0, i32 1
  %7 = load ptr, ptr %6, align 8, !tbaa !4
  %8 = load i32, ptr %0, align 4, !tbaa !4
  %9 = sext i32 %8 to i64
  %10 = load i32, ptr %1, align 4, !tbaa !4
  %11 = sext i32 %10 to i64
  %12 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %2, i64 0, i32 7, i64 0, i64 2
  %13 = load i64, ptr %12, align 8, !tbaa !8
  %14 = icmp eq i64 %13, 8
  br i1 %14, label %15, label %31

15:                                               ; preds = %4
  %16 = load ptr, ptr %2, align 8, !tbaa !8
  %reass.sub9 = sub nsw i64 %11, %9
  %17 = icmp sgt i64 %reass.sub9, -1
  br i1 %17, label %.lr.ph8.preheader, label %.loopexit

.lr.ph8.preheader:                                ; preds = %15
  %18 = add nuw nsw i64 %reass.sub9, 1
  br label %.lr.ph8

.lr.ph8:                                          ; preds = %.lr.ph8.preheader, %.lr.ph8
  %19 = phi i64 [ %29, %.lr.ph8 ], [ %18, %.lr.ph8.preheader ]
  %20 = phi i32 [ %28, %.lr.ph8 ], [ %8, %.lr.ph8.preheader ]
  %21 = load i32, ptr %5, align 4, !tbaa !4
  %22 = sitofp i32 %21 to float
  %23 = fdiv contract float 1.000000e+00, %22
  %24 = fpext float %23 to double
  %25 = sext i32 %20 to i64
  %26 = add nsw i64 %25, -1
  %27 = getelementptr double, ptr %16, i64 %26
  store double %24, ptr %27, align 8, !tbaa !4
  store double %24, ptr %7, align 8, !tbaa !4
  %28 = add i32 %20, 1
  %29 = add nsw i64 %19, -1
  %30 = icmp ugt i64 %19, 1
  br i1 %30, label %.lr.ph8, label %.loopexit

31:                                               ; preds = %4
  %reass.sub = sub nsw i64 %11, %9
  %32 = icmp sgt i64 %reass.sub, -1
  br i1 %32, label %.lr.ph, label %.loopexit

.lr.ph:                                           ; preds = %31
  %33 = add nuw nsw i64 %reass.sub, 1
  %34 = load ptr, ptr %2, align 8, !tbaa !8
  br label %35

35:                                               ; preds = %.lr.ph, %35
  %36 = phi i64 [ %33, %.lr.ph ], [ %47, %35 ]
  %37 = phi i32 [ %8, %.lr.ph ], [ %46, %35 ]
  %38 = load i32, ptr %5, align 4, !tbaa !4
  %39 = sitofp i32 %38 to float
  %40 = fdiv contract float 1.000000e+00, %39
  %41 = fpext float %40 to double
  %42 = sext i32 %37 to i64
  %43 = add nsw i64 %42, -1
  %44 = mul i64 %43, %13
  %45 = getelementptr i8, ptr %34, i64 %44
  store double %41, ptr %45, align 8, !tbaa !4
  store double %41, ptr %7, align 8, !tbaa !4
  %46 = add i32 %37, 1
  %47 = add nsw i64 %36, -1
  %48 = icmp ugt i64 %36, 1
  br i1 %48, label %35, label %.loopexit

.loopexit:                                        ; preds = %35, %.lr.ph8, %31, %15
  ret void
}
*** IR Dump After LoopSimplifyPass on _QFPloop ***
; Function Attrs: nofree norecurse nosync nounwind memory(readwrite, inaccessiblemem: none)
define void @_QFPloop(ptr nocapture readonly %0, ptr nocapture readonly %1, ptr nocapture readonly %2, ptr nest nocapture readonly %3) local_unnamed_addr #4 {
  %5 = load ptr, ptr %3, align 8, !tbaa !4
  %6 = getelementptr { ptr, ptr }, ptr %3, i64 0, i32 1
  %7 = load ptr, ptr %6, align 8, !tbaa !4
  %8 = load i32, ptr %0, align 4, !tbaa !4
  %9 = sext i32 %8 to i64
  %10 = load i32, ptr %1, align 4, !tbaa !4
  %11 = sext i32 %10 to i64
  %12 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %2, i64 0, i32 7, i64 0, i64 2
  %13 = load i64, ptr %12, align 8, !tbaa !8
  %14 = icmp eq i64 %13, 8
  br i1 %14, label %15, label %31

15:                                               ; preds = %4
  %16 = load ptr, ptr %2, align 8, !tbaa !8
  %reass.sub9 = sub nsw i64 %11, %9
  %17 = icmp sgt i64 %reass.sub9, -1
  br i1 %17, label %.lr.ph8.preheader, label %.loopexit

.lr.ph8.preheader:                                ; preds = %15
  %18 = add nuw nsw i64 %reass.sub9, 1
  br label %.lr.ph8

.lr.ph8:                                          ; preds = %.lr.ph8.preheader, %.lr.ph8
  %19 = phi i64 [ %29, %.lr.ph8 ], [ %18, %.lr.ph8.preheader ]
  %20 = phi i32 [ %28, %.lr.ph8 ], [ %8, %.lr.ph8.preheader ]
  %21 = load i32, ptr %5, align 4, !tbaa !4
  %22 = sitofp i32 %21 to float
  %23 = fdiv contract float 1.000000e+00, %22
  %24 = fpext float %23 to double
  %25 = sext i32 %20 to i64
  %26 = add nsw i64 %25, -1
  %27 = getelementptr double, ptr %16, i64 %26
  store double %24, ptr %27, align 8, !tbaa !4
  store double %24, ptr %7, align 8, !tbaa !4
  %28 = add i32 %20, 1
  %29 = add nsw i64 %19, -1
  %30 = icmp ugt i64 %19, 1
  br i1 %30, label %.lr.ph8, label %.loopexit.loopexit

31:                                               ; preds = %4
  %reass.sub = sub nsw i64 %11, %9
  %32 = icmp sgt i64 %reass.sub, -1
  br i1 %32, label %.lr.ph, label %.loopexit

.lr.ph:                                           ; preds = %31
  %33 = add nuw nsw i64 %reass.sub, 1
  %34 = load ptr, ptr %2, align 8, !tbaa !8
  br label %35

35:                                               ; preds = %.lr.ph, %35
  %36 = phi i64 [ %33, %.lr.ph ], [ %47, %35 ]
  %37 = phi i32 [ %8, %.lr.ph ], [ %46, %35 ]
  %38 = load i32, ptr %5, align 4, !tbaa !4
  %39 = sitofp i32 %38 to float
  %40 = fdiv contract float 1.000000e+00, %39
  %41 = fpext float %40 to double
  %42 = sext i32 %37 to i64
  %43 = add nsw i64 %42, -1
  %44 = mul i64 %43, %13
  %45 = getelementptr i8, ptr %34, i64 %44
  store double %41, ptr %45, align 8, !tbaa !4
  store double %41, ptr %7, align 8, !tbaa !4
  %46 = add i32 %37, 1
  %47 = add nsw i64 %36, -1
  %48 = icmp ugt i64 %36, 1
  br i1 %48, label %35, label %.loopexit.loopexit12

.loopexit.loopexit:                               ; preds = %.lr.ph8
  br label %.loopexit

.loopexit.loopexit12:                             ; preds = %35
  br label %.loopexit

.loopexit:                                        ; preds = %.loopexit.loopexit12, %.loopexit.loopexit, %31, %15
  ret void
}
*** IR Dump After LCSSAPass on _QFPloop ***
; Function Attrs: nofree norecurse nosync nounwind memory(readwrite, inaccessiblemem: none)
define void @_QFPloop(ptr nocapture readonly %0, ptr nocapture readonly %1, ptr nocapture readonly %2, ptr nest nocapture readonly %3) local_unnamed_addr #4 {
  %5 = load ptr, ptr %3, align 8, !tbaa !4
  %6 = getelementptr { ptr, ptr }, ptr %3, i64 0, i32 1
  %7 = load ptr, ptr %6, align 8, !tbaa !4
  %8 = load i32, ptr %0, align 4, !tbaa !4
  %9 = sext i32 %8 to i64
  %10 = load i32, ptr %1, align 4, !tbaa !4
  %11 = sext i32 %10 to i64
  %12 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %2, i64 0, i32 7, i64 0, i64 2
  %13 = load i64, ptr %12, align 8, !tbaa !8
  %14 = icmp eq i64 %13, 8
  br i1 %14, label %15, label %31

15:                                               ; preds = %4
  %16 = load ptr, ptr %2, align 8, !tbaa !8
  %reass.sub9 = sub nsw i64 %11, %9
  %17 = icmp sgt i64 %reass.sub9, -1
  br i1 %17, label %.lr.ph8.preheader, label %.loopexit

.lr.ph8.preheader:                                ; preds = %15
  %18 = add nuw nsw i64 %reass.sub9, 1
  br label %.lr.ph8

.lr.ph8:                                          ; preds = %.lr.ph8.preheader, %.lr.ph8
  %19 = phi i64 [ %29, %.lr.ph8 ], [ %18, %.lr.ph8.preheader ]
  %20 = phi i32 [ %28, %.lr.ph8 ], [ %8, %.lr.ph8.preheader ]
  %21 = load i32, ptr %5, align 4, !tbaa !4
  %22 = sitofp i32 %21 to float
  %23 = fdiv contract float 1.000000e+00, %22
  %24 = fpext float %23 to double
  %25 = sext i32 %20 to i64
  %26 = add nsw i64 %25, -1
  %27 = getelementptr double, ptr %16, i64 %26
  store double %24, ptr %27, align 8, !tbaa !4
  store double %24, ptr %7, align 8, !tbaa !4
  %28 = add i32 %20, 1
  %29 = add nsw i64 %19, -1
  %30 = icmp ugt i64 %19, 1
  br i1 %30, label %.lr.ph8, label %.loopexit.loopexit

31:                                               ; preds = %4
  %reass.sub = sub nsw i64 %11, %9
  %32 = icmp sgt i64 %reass.sub, -1
  br i1 %32, label %.lr.ph, label %.loopexit

.lr.ph:                                           ; preds = %31
  %33 = add nuw nsw i64 %reass.sub, 1
  %34 = load ptr, ptr %2, align 8, !tbaa !8
  br label %35

35:                                               ; preds = %.lr.ph, %35
  %36 = phi i64 [ %33, %.lr.ph ], [ %47, %35 ]
  %37 = phi i32 [ %8, %.lr.ph ], [ %46, %35 ]
  %38 = load i32, ptr %5, align 4, !tbaa !4
  %39 = sitofp i32 %38 to float
  %40 = fdiv contract float 1.000000e+00, %39
  %41 = fpext float %40 to double
  %42 = sext i32 %37 to i64
  %43 = add nsw i64 %42, -1
  %44 = mul i64 %43, %13
  %45 = getelementptr i8, ptr %34, i64 %44
  store double %41, ptr %45, align 8, !tbaa !4
  store double %41, ptr %7, align 8, !tbaa !4
  %46 = add i32 %37, 1
  %47 = add nsw i64 %36, -1
  %48 = icmp ugt i64 %36, 1
  br i1 %48, label %35, label %.loopexit.loopexit12

.loopexit.loopexit:                               ; preds = %.lr.ph8
  br label %.loopexit

.loopexit.loopexit12:                             ; preds = %35
  br label %.loopexit

.loopexit:                                        ; preds = %.loopexit.loopexit12, %.loopexit.loopexit, %31, %15
  ret void
}
*** IR Dump After LoopRotatePass on <unnamed loop> ***

; Preheader:
.lr.ph:                                           ; preds = %31
  %33 = add nuw nsw i64 %reass.sub, 1
  %34 = load ptr, ptr %2, align 8, !tbaa !8
  br label %35

; Loop:
35:                                               ; preds = %.lr.ph, %35
  %36 = phi i64 [ %33, %.lr.ph ], [ %47, %35 ]
  %37 = phi i32 [ %8, %.lr.ph ], [ %46, %35 ]
  %38 = load i32, ptr %5, align 4, !tbaa !4
  %39 = sitofp i32 %38 to float
  %40 = fdiv contract float 1.000000e+00, %39
  %41 = fpext float %40 to double
  %42 = sext i32 %37 to i64
  %43 = add nsw i64 %42, -1
  %44 = mul i64 %43, %13
  %45 = getelementptr i8, ptr %34, i64 %44
  store double %41, ptr %45, align 8, !tbaa !4
  store double %41, ptr %7, align 8, !tbaa !4
  %46 = add i32 %37, 1
  %47 = add nsw i64 %36, -1
  %48 = icmp ugt i64 %36, 1
  br i1 %48, label %35, label %.loopexit.loopexit12

; Exit blocks
.loopexit.loopexit12:                             ; preds = %35
  br label %.loopexit
*** IR Dump After LoopDeletionPass on <unnamed loop> ***

; Preheader:
.lr.ph:                                           ; preds = %31
  %33 = add nuw nsw i64 %reass.sub, 1
  %34 = load ptr, ptr %2, align 8, !tbaa !8
  br label %35

; Loop:
35:                                               ; preds = %.lr.ph, %35
  %36 = phi i64 [ %33, %.lr.ph ], [ %47, %35 ]
  %37 = phi i32 [ %8, %.lr.ph ], [ %46, %35 ]
  %38 = load i32, ptr %5, align 4, !tbaa !4
  %39 = sitofp i32 %38 to float
  %40 = fdiv contract float 1.000000e+00, %39
  %41 = fpext float %40 to double
  %42 = sext i32 %37 to i64
  %43 = add nsw i64 %42, -1
  %44 = mul i64 %43, %13
  %45 = getelementptr i8, ptr %34, i64 %44
  store double %41, ptr %45, align 8, !tbaa !4
  store double %41, ptr %7, align 8, !tbaa !4
  %46 = add i32 %37, 1
  %47 = add nsw i64 %36, -1
  %48 = icmp ugt i64 %36, 1
  br i1 %48, label %35, label %.loopexit.loopexit12

; Exit blocks
.loopexit.loopexit12:                             ; preds = %35
  br label %.loopexit
*** IR Dump After LoopRotatePass on .lr.ph8 ***

; Preheader:
.lr.ph8.preheader:                                ; preds = %15
  %18 = add nuw nsw i64 %reass.sub9, 1
  br label %.lr.ph8

; Loop:
.lr.ph8:                                          ; preds = %.lr.ph8.preheader, %.lr.ph8
  %19 = phi i64 [ %29, %.lr.ph8 ], [ %18, %.lr.ph8.preheader ]
  %20 = phi i32 [ %28, %.lr.ph8 ], [ %8, %.lr.ph8.preheader ]
  %21 = load i32, ptr %5, align 4, !tbaa !4
  %22 = sitofp i32 %21 to float
  %23 = fdiv contract float 1.000000e+00, %22
  %24 = fpext float %23 to double
  %25 = sext i32 %20 to i64
  %26 = add nsw i64 %25, -1
  %27 = getelementptr double, ptr %16, i64 %26
  store double %24, ptr %27, align 8, !tbaa !4
  store double %24, ptr %7, align 8, !tbaa !4
  %28 = add i32 %20, 1
  %29 = add nsw i64 %19, -1
  %30 = icmp ugt i64 %19, 1
  br i1 %30, label %.lr.ph8, label %.loopexit.loopexit

; Exit blocks
.loopexit.loopexit:                               ; preds = %.lr.ph8
  br label %.loopexit
*** IR Dump After LoopDeletionPass on .lr.ph8 ***

; Preheader:
.lr.ph8.preheader:                                ; preds = %15
  %18 = add nuw nsw i64 %reass.sub9, 1
  br label %.lr.ph8

; Loop:
.lr.ph8:                                          ; preds = %.lr.ph8.preheader, %.lr.ph8
  %19 = phi i64 [ %29, %.lr.ph8 ], [ %18, %.lr.ph8.preheader ]
  %20 = phi i32 [ %28, %.lr.ph8 ], [ %8, %.lr.ph8.preheader ]
  %21 = load i32, ptr %5, align 4, !tbaa !4
  %22 = sitofp i32 %21 to float
  %23 = fdiv contract float 1.000000e+00, %22
  %24 = fpext float %23 to double
  %25 = sext i32 %20 to i64
  %26 = add nsw i64 %25, -1
  %27 = getelementptr double, ptr %16, i64 %26
  store double %24, ptr %27, align 8, !tbaa !4
  store double %24, ptr %7, align 8, !tbaa !4
  %28 = add i32 %20, 1
  %29 = add nsw i64 %19, -1
  %30 = icmp ugt i64 %19, 1
  br i1 %30, label %.lr.ph8, label %.loopexit.loopexit

; Exit blocks
.loopexit.loopexit:                               ; preds = %.lr.ph8
  br label %.loopexit
*** IR Dump After LoopDistributePass on _QFPloop ***
; Function Attrs: nofree norecurse nosync nounwind memory(readwrite, inaccessiblemem: none)
define void @_QFPloop(ptr nocapture readonly %0, ptr nocapture readonly %1, ptr nocapture readonly %2, ptr nest nocapture readonly %3) local_unnamed_addr #4 {
  %5 = load ptr, ptr %3, align 8, !tbaa !4
  %6 = getelementptr { ptr, ptr }, ptr %3, i64 0, i32 1
  %7 = load ptr, ptr %6, align 8, !tbaa !4
  %8 = load i32, ptr %0, align 4, !tbaa !4
  %9 = sext i32 %8 to i64
  %10 = load i32, ptr %1, align 4, !tbaa !4
  %11 = sext i32 %10 to i64
  %12 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %2, i64 0, i32 7, i64 0, i64 2
  %13 = load i64, ptr %12, align 8, !tbaa !8
  %14 = icmp eq i64 %13, 8
  br i1 %14, label %15, label %31

15:                                               ; preds = %4
  %16 = load ptr, ptr %2, align 8, !tbaa !8
  %reass.sub9 = sub nsw i64 %11, %9
  %17 = icmp sgt i64 %reass.sub9, -1
  br i1 %17, label %.lr.ph8.preheader, label %.loopexit

.lr.ph8.preheader:                                ; preds = %15
  %18 = add nuw nsw i64 %reass.sub9, 1
  br label %.lr.ph8

.lr.ph8:                                          ; preds = %.lr.ph8.preheader, %.lr.ph8
  %19 = phi i64 [ %29, %.lr.ph8 ], [ %18, %.lr.ph8.preheader ]
  %20 = phi i32 [ %28, %.lr.ph8 ], [ %8, %.lr.ph8.preheader ]
  %21 = load i32, ptr %5, align 4, !tbaa !4
  %22 = sitofp i32 %21 to float
  %23 = fdiv contract float 1.000000e+00, %22
  %24 = fpext float %23 to double
  %25 = sext i32 %20 to i64
  %26 = add nsw i64 %25, -1
  %27 = getelementptr double, ptr %16, i64 %26
  store double %24, ptr %27, align 8, !tbaa !4
  store double %24, ptr %7, align 8, !tbaa !4
  %28 = add i32 %20, 1
  %29 = add nsw i64 %19, -1
  %30 = icmp ugt i64 %19, 1
  br i1 %30, label %.lr.ph8, label %.loopexit.loopexit

31:                                               ; preds = %4
  %reass.sub = sub nsw i64 %11, %9
  %32 = icmp sgt i64 %reass.sub, -1
  br i1 %32, label %.lr.ph, label %.loopexit

.lr.ph:                                           ; preds = %31
  %33 = add nuw nsw i64 %reass.sub, 1
  %34 = load ptr, ptr %2, align 8, !tbaa !8
  br label %35

35:                                               ; preds = %.lr.ph, %35
  %36 = phi i64 [ %33, %.lr.ph ], [ %47, %35 ]
  %37 = phi i32 [ %8, %.lr.ph ], [ %46, %35 ]
  %38 = load i32, ptr %5, align 4, !tbaa !4
  %39 = sitofp i32 %38 to float
  %40 = fdiv contract float 1.000000e+00, %39
  %41 = fpext float %40 to double
  %42 = sext i32 %37 to i64
  %43 = add nsw i64 %42, -1
  %44 = mul i64 %43, %13
  %45 = getelementptr i8, ptr %34, i64 %44
  store double %41, ptr %45, align 8, !tbaa !4
  store double %41, ptr %7, align 8, !tbaa !4
  %46 = add i32 %37, 1
  %47 = add nsw i64 %36, -1
  %48 = icmp ugt i64 %36, 1
  br i1 %48, label %35, label %.loopexit.loopexit12

.loopexit.loopexit:                               ; preds = %.lr.ph8
  br label %.loopexit

.loopexit.loopexit12:                             ; preds = %35
  br label %.loopexit

.loopexit:                                        ; preds = %.loopexit.loopexit12, %.loopexit.loopexit, %31, %15
  ret void
}
*** IR Dump After InjectTLIMappings on _QFPloop ***
; Function Attrs: nofree norecurse nosync nounwind memory(readwrite, inaccessiblemem: none)
define void @_QFPloop(ptr nocapture readonly %0, ptr nocapture readonly %1, ptr nocapture readonly %2, ptr nest nocapture readonly %3) local_unnamed_addr #4 {
  %5 = load ptr, ptr %3, align 8, !tbaa !4
  %6 = getelementptr { ptr, ptr }, ptr %3, i64 0, i32 1
  %7 = load ptr, ptr %6, align 8, !tbaa !4
  %8 = load i32, ptr %0, align 4, !tbaa !4
  %9 = sext i32 %8 to i64
  %10 = load i32, ptr %1, align 4, !tbaa !4
  %11 = sext i32 %10 to i64
  %12 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %2, i64 0, i32 7, i64 0, i64 2
  %13 = load i64, ptr %12, align 8, !tbaa !8
  %14 = icmp eq i64 %13, 8
  br i1 %14, label %15, label %31

15:                                               ; preds = %4
  %16 = load ptr, ptr %2, align 8, !tbaa !8
  %reass.sub9 = sub nsw i64 %11, %9
  %17 = icmp sgt i64 %reass.sub9, -1
  br i1 %17, label %.lr.ph8.preheader, label %.loopexit

.lr.ph8.preheader:                                ; preds = %15
  %18 = add nuw nsw i64 %reass.sub9, 1
  br label %.lr.ph8

.lr.ph8:                                          ; preds = %.lr.ph8.preheader, %.lr.ph8
  %19 = phi i64 [ %29, %.lr.ph8 ], [ %18, %.lr.ph8.preheader ]
  %20 = phi i32 [ %28, %.lr.ph8 ], [ %8, %.lr.ph8.preheader ]
  %21 = load i32, ptr %5, align 4, !tbaa !4
  %22 = sitofp i32 %21 to float
  %23 = fdiv contract float 1.000000e+00, %22
  %24 = fpext float %23 to double
  %25 = sext i32 %20 to i64
  %26 = add nsw i64 %25, -1
  %27 = getelementptr double, ptr %16, i64 %26
  store double %24, ptr %27, align 8, !tbaa !4
  store double %24, ptr %7, align 8, !tbaa !4
  %28 = add i32 %20, 1
  %29 = add nsw i64 %19, -1
  %30 = icmp ugt i64 %19, 1
  br i1 %30, label %.lr.ph8, label %.loopexit.loopexit

31:                                               ; preds = %4
  %reass.sub = sub nsw i64 %11, %9
  %32 = icmp sgt i64 %reass.sub, -1
  br i1 %32, label %.lr.ph, label %.loopexit

.lr.ph:                                           ; preds = %31
  %33 = add nuw nsw i64 %reass.sub, 1
  %34 = load ptr, ptr %2, align 8, !tbaa !8
  br label %35

35:                                               ; preds = %.lr.ph, %35
  %36 = phi i64 [ %33, %.lr.ph ], [ %47, %35 ]
  %37 = phi i32 [ %8, %.lr.ph ], [ %46, %35 ]
  %38 = load i32, ptr %5, align 4, !tbaa !4
  %39 = sitofp i32 %38 to float
  %40 = fdiv contract float 1.000000e+00, %39
  %41 = fpext float %40 to double
  %42 = sext i32 %37 to i64
  %43 = add nsw i64 %42, -1
  %44 = mul i64 %43, %13
  %45 = getelementptr i8, ptr %34, i64 %44
  store double %41, ptr %45, align 8, !tbaa !4
  store double %41, ptr %7, align 8, !tbaa !4
  %46 = add i32 %37, 1
  %47 = add nsw i64 %36, -1
  %48 = icmp ugt i64 %36, 1
  br i1 %48, label %35, label %.loopexit.loopexit12

.loopexit.loopexit:                               ; preds = %.lr.ph8
  br label %.loopexit

.loopexit.loopexit12:                             ; preds = %35
  br label %.loopexit

.loopexit:                                        ; preds = %.loopexit.loopexit12, %.loopexit.loopexit, %31, %15
  ret void
}
*** IR Dump After LoopVectorizePass on _QFPloop ***
; Function Attrs: nofree norecurse nosync nounwind memory(readwrite, inaccessiblemem: none)
define void @_QFPloop(ptr nocapture readonly %0, ptr nocapture readonly %1, ptr nocapture readonly %2, ptr nest nocapture readonly %3) local_unnamed_addr #4 {
  %5 = load ptr, ptr %3, align 8, !tbaa !4
  %6 = getelementptr { ptr, ptr }, ptr %3, i64 0, i32 1
  %7 = load ptr, ptr %6, align 8, !tbaa !4
  %8 = load i32, ptr %0, align 4, !tbaa !4
  %9 = sext i32 %8 to i64
  %10 = load i32, ptr %1, align 4, !tbaa !4
  %11 = sext i32 %10 to i64
  %12 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %2, i64 0, i32 7, i64 0, i64 2
  %13 = load i64, ptr %12, align 8, !tbaa !8
  %14 = icmp eq i64 %13, 8
  br i1 %14, label %15, label %59

15:                                               ; preds = %4
  %16 = load ptr, ptr %2, align 8, !tbaa !8
  %reass.sub9 = sub nsw i64 %11, %9
  %17 = icmp sgt i64 %reass.sub9, -1
  br i1 %17, label %.lr.ph8.preheader, label %.loopexit

.lr.ph8.preheader:                                ; preds = %15
  %18 = add i64 %reass.sub9, 1
  %19 = add i64 %11, 2
  %umin24 = call i64 @llvm.umin.i64(i64 %18, i64 1)
  %20 = sub i64 %19, %umin24
  %21 = sub i64 %20, %9
  %min.iters.check = icmp ult i64 %21, 8
  br i1 %min.iters.check, label %scalar.ph, label %vector.scevcheck

vector.scevcheck:                                 ; preds = %.lr.ph8.preheader
  %22 = add i64 %11, 1
  %umin = call i64 @llvm.umin.i64(i64 %18, i64 1)
  %23 = sub i64 %22, %umin
  %24 = sub i64 %23, %9
  %25 = trunc i64 %24 to i32
  %26 = add i32 %8, %25
  %27 = icmp slt i32 %26, %8
  %28 = icmp ugt i64 %24, 4294967295
  %29 = or i1 %27, %28
  br i1 %29, label %scalar.ph, label %vector.memcheck

vector.memcheck:                                  ; preds = %vector.scevcheck
  %scevgep = getelementptr i8, ptr %7, i64 8
  %scevgep13 = getelementptr i8, ptr %5, i64 4
  %30 = shl nsw i64 %9, 3
  %31 = add nsw i64 %30, -8
  %scevgep14 = getelementptr i8, ptr %16, i64 %31
  %32 = shl nsw i64 %11, 3
  %33 = add i64 %32, 8
  %umin15 = call i64 @llvm.umin.i64(i64 %18, i64 1)
  %34 = shl nuw nsw i64 %umin15, 3
  %35 = sub i64 %33, %34
  %scevgep16 = getelementptr i8, ptr %16, i64 %35
  %bound0 = icmp ult ptr %7, %scevgep13
  %bound1 = icmp ult ptr %5, %scevgep
  %found.conflict = and i1 %bound0, %bound1
  %bound017 = icmp ult ptr %7, %scevgep16
  %bound118 = icmp ult ptr %scevgep14, %scevgep
  %found.conflict19 = and i1 %bound017, %bound118
  %conflict.rdx = or i1 %found.conflict, %found.conflict19
  %bound020 = icmp ult ptr %5, %scevgep16
  %bound121 = icmp ult ptr %scevgep14, %scevgep13
  %found.conflict22 = and i1 %bound020, %bound121
  %conflict.rdx23 = or i1 %conflict.rdx, %found.conflict22
  br i1 %conflict.rdx23, label %scalar.ph, label %vector.ph

vector.ph:                                        ; preds = %vector.memcheck
  %n.mod.vf = urem i64 %21, 2
  %n.vec = sub i64 %21, %n.mod.vf
  %ind.end = sub i64 %18, %n.vec
  %.cast = trunc i64 %n.vec to i32
  %ind.end25 = add i32 %8, %.cast
  br label %vector.body

vector.body:                                      ; preds = %vector.body, %vector.ph
  %index = phi i64 [ 0, %vector.ph ], [ %index.next, %vector.body ]
  %.cast27 = trunc i64 %index to i32
  %offset.idx = add i32 %8, %.cast27
  %36 = add i32 %offset.idx, 0
  %37 = load i32, ptr %5, align 4, !tbaa !4, !alias.scope !22, !noalias !25
  %broadcast.splatinsert = insertelement <2 x i32> poison, i32 %37, i64 0
  %broadcast.splat = shufflevector <2 x i32> %broadcast.splatinsert, <2 x i32> poison, <2 x i32> zeroinitializer
  %38 = sitofp <2 x i32> %broadcast.splat to <2 x float>
  %39 = fdiv contract <2 x float> <float 1.000000e+00, float 1.000000e+00>, %38
  %40 = fpext <2 x float> %39 to <2 x double>
  %41 = sext i32 %36 to i64
  %42 = add nsw i64 %41, -1
  %43 = getelementptr double, ptr %16, i64 %42
  %44 = getelementptr double, ptr %43, i32 0
  store <2 x double> %40, ptr %44, align 8, !tbaa !4, !alias.scope !25
  %45 = extractelement <2 x double> %40, i32 1
  store double %45, ptr %7, align 8, !tbaa !4, !alias.scope !27, !noalias !29
  %index.next = add nuw i64 %index, 2
  %46 = icmp eq i64 %index.next, %n.vec
  br i1 %46, label %middle.block, label %vector.body, !llvm.loop !30

middle.block:                                     ; preds = %vector.body
  %cmp.n = icmp eq i64 %21, %n.vec
  br i1 %cmp.n, label %.loopexit.loopexit, label %scalar.ph

scalar.ph:                                        ; preds = %vector.memcheck, %vector.scevcheck, %.lr.ph8.preheader, %middle.block
  %bc.resume.val = phi i64 [ %ind.end, %middle.block ], [ %18, %.lr.ph8.preheader ], [ %18, %vector.scevcheck ], [ %18, %vector.memcheck ]
  %bc.resume.val26 = phi i32 [ %ind.end25, %middle.block ], [ %8, %.lr.ph8.preheader ], [ %8, %vector.scevcheck ], [ %8, %vector.memcheck ]
  br label %.lr.ph8

.lr.ph8:                                          ; preds = %scalar.ph, %.lr.ph8
  %47 = phi i64 [ %57, %.lr.ph8 ], [ %bc.resume.val, %scalar.ph ]
  %48 = phi i32 [ %56, %.lr.ph8 ], [ %bc.resume.val26, %scalar.ph ]
  %49 = load i32, ptr %5, align 4, !tbaa !4
  %50 = sitofp i32 %49 to float
  %51 = fdiv contract float 1.000000e+00, %50
  %52 = fpext float %51 to double
  %53 = sext i32 %48 to i64
  %54 = add nsw i64 %53, -1
  %55 = getelementptr double, ptr %16, i64 %54
  store double %52, ptr %55, align 8, !tbaa !4
  store double %52, ptr %7, align 8, !tbaa !4
  %56 = add i32 %48, 1
  %57 = add nsw i64 %47, -1
  %58 = icmp ugt i64 %47, 1
  br i1 %58, label %.lr.ph8, label %.loopexit.loopexit, !llvm.loop !31

59:                                               ; preds = %4
  %reass.sub = sub nsw i64 %11, %9
  %60 = icmp sgt i64 %reass.sub, -1
  br i1 %60, label %.lr.ph, label %.loopexit

.lr.ph:                                           ; preds = %59
  %61 = add nuw nsw i64 %reass.sub, 1
  %62 = load ptr, ptr %2, align 8, !tbaa !8
  br label %63

63:                                               ; preds = %.lr.ph, %63
  %64 = phi i64 [ %61, %.lr.ph ], [ %75, %63 ]
  %65 = phi i32 [ %8, %.lr.ph ], [ %74, %63 ]
  %66 = load i32, ptr %5, align 4, !tbaa !4
  %67 = sitofp i32 %66 to float
  %68 = fdiv contract float 1.000000e+00, %67
  %69 = fpext float %68 to double
  %70 = sext i32 %65 to i64
  %71 = add nsw i64 %70, -1
  %72 = mul i64 %71, %13
  %73 = getelementptr i8, ptr %62, i64 %72
  store double %69, ptr %73, align 8, !tbaa !4
  store double %69, ptr %7, align 8, !tbaa !4
  %74 = add i32 %65, 1
  %75 = add nsw i64 %64, -1
  %76 = icmp ugt i64 %64, 1
  br i1 %76, label %63, label %.loopexit.loopexit12

.loopexit.loopexit:                               ; preds = %middle.block, %.lr.ph8
  br label %.loopexit

.loopexit.loopexit12:                             ; preds = %63
  br label %.loopexit

.loopexit:                                        ; preds = %.loopexit.loopexit12, %.loopexit.loopexit, %59, %15
  ret void
}
*** IR Dump After LoopLoadEliminationPass on _QFPloop ***
; Function Attrs: nofree norecurse nosync nounwind memory(readwrite, inaccessiblemem: none)
define void @_QFPloop(ptr nocapture readonly %0, ptr nocapture readonly %1, ptr nocapture readonly %2, ptr nest nocapture readonly %3) local_unnamed_addr #4 {
  %5 = load ptr, ptr %3, align 8, !tbaa !4
  %6 = getelementptr { ptr, ptr }, ptr %3, i64 0, i32 1
  %7 = load ptr, ptr %6, align 8, !tbaa !4
  %8 = load i32, ptr %0, align 4, !tbaa !4
  %9 = sext i32 %8 to i64
  %10 = load i32, ptr %1, align 4, !tbaa !4
  %11 = sext i32 %10 to i64
  %12 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %2, i64 0, i32 7, i64 0, i64 2
  %13 = load i64, ptr %12, align 8, !tbaa !8
  %14 = icmp eq i64 %13, 8
  br i1 %14, label %15, label %59

15:                                               ; preds = %4
  %16 = load ptr, ptr %2, align 8, !tbaa !8
  %reass.sub9 = sub nsw i64 %11, %9
  %17 = icmp sgt i64 %reass.sub9, -1
  br i1 %17, label %.lr.ph8.preheader, label %.loopexit

.lr.ph8.preheader:                                ; preds = %15
  %18 = add i64 %reass.sub9, 1
  %19 = add i64 %11, 2
  %umin24 = call i64 @llvm.umin.i64(i64 %18, i64 1)
  %20 = sub i64 %19, %umin24
  %21 = sub i64 %20, %9
  %min.iters.check = icmp ult i64 %21, 8
  br i1 %min.iters.check, label %scalar.ph, label %vector.scevcheck

vector.scevcheck:                                 ; preds = %.lr.ph8.preheader
  %22 = add i64 %11, 1
  %umin = call i64 @llvm.umin.i64(i64 %18, i64 1)
  %23 = sub i64 %22, %umin
  %24 = sub i64 %23, %9
  %25 = trunc i64 %24 to i32
  %26 = add i32 %8, %25
  %27 = icmp slt i32 %26, %8
  %28 = icmp ugt i64 %24, 4294967295
  %29 = or i1 %27, %28
  br i1 %29, label %scalar.ph, label %vector.memcheck

vector.memcheck:                                  ; preds = %vector.scevcheck
  %scevgep = getelementptr i8, ptr %7, i64 8
  %scevgep13 = getelementptr i8, ptr %5, i64 4
  %30 = shl nsw i64 %9, 3
  %31 = add nsw i64 %30, -8
  %scevgep14 = getelementptr i8, ptr %16, i64 %31
  %32 = shl nsw i64 %11, 3
  %33 = add i64 %32, 8
  %umin15 = call i64 @llvm.umin.i64(i64 %18, i64 1)
  %34 = shl nuw nsw i64 %umin15, 3
  %35 = sub i64 %33, %34
  %scevgep16 = getelementptr i8, ptr %16, i64 %35
  %bound0 = icmp ult ptr %7, %scevgep13
  %bound1 = icmp ult ptr %5, %scevgep
  %found.conflict = and i1 %bound0, %bound1
  %bound017 = icmp ult ptr %7, %scevgep16
  %bound118 = icmp ult ptr %scevgep14, %scevgep
  %found.conflict19 = and i1 %bound017, %bound118
  %conflict.rdx = or i1 %found.conflict, %found.conflict19
  %bound020 = icmp ult ptr %5, %scevgep16
  %bound121 = icmp ult ptr %scevgep14, %scevgep13
  %found.conflict22 = and i1 %bound020, %bound121
  %conflict.rdx23 = or i1 %conflict.rdx, %found.conflict22
  br i1 %conflict.rdx23, label %scalar.ph, label %vector.ph

vector.ph:                                        ; preds = %vector.memcheck
  %n.mod.vf = urem i64 %21, 2
  %n.vec = sub i64 %21, %n.mod.vf
  %ind.end = sub i64 %18, %n.vec
  %.cast = trunc i64 %n.vec to i32
  %ind.end25 = add i32 %8, %.cast
  br label %vector.body

vector.body:                                      ; preds = %vector.body, %vector.ph
  %index = phi i64 [ 0, %vector.ph ], [ %index.next, %vector.body ]
  %.cast27 = trunc i64 %index to i32
  %offset.idx = add i32 %8, %.cast27
  %36 = add i32 %offset.idx, 0
  %37 = load i32, ptr %5, align 4, !tbaa !4, !alias.scope !22, !noalias !25
  %broadcast.splatinsert = insertelement <2 x i32> poison, i32 %37, i64 0
  %broadcast.splat = shufflevector <2 x i32> %broadcast.splatinsert, <2 x i32> poison, <2 x i32> zeroinitializer
  %38 = sitofp <2 x i32> %broadcast.splat to <2 x float>
  %39 = fdiv contract <2 x float> <float 1.000000e+00, float 1.000000e+00>, %38
  %40 = fpext <2 x float> %39 to <2 x double>
  %41 = sext i32 %36 to i64
  %42 = add nsw i64 %41, -1
  %43 = getelementptr double, ptr %16, i64 %42
  %44 = getelementptr double, ptr %43, i32 0
  store <2 x double> %40, ptr %44, align 8, !tbaa !4, !alias.scope !25
  %45 = extractelement <2 x double> %40, i32 1
  store double %45, ptr %7, align 8, !tbaa !4, !alias.scope !27, !noalias !29
  %index.next = add nuw i64 %index, 2
  %46 = icmp eq i64 %index.next, %n.vec
  br i1 %46, label %middle.block, label %vector.body, !llvm.loop !30

middle.block:                                     ; preds = %vector.body
  %cmp.n = icmp eq i64 %21, %n.vec
  br i1 %cmp.n, label %.loopexit.loopexit, label %scalar.ph

scalar.ph:                                        ; preds = %vector.memcheck, %vector.scevcheck, %.lr.ph8.preheader, %middle.block
  %bc.resume.val = phi i64 [ %ind.end, %middle.block ], [ %18, %.lr.ph8.preheader ], [ %18, %vector.scevcheck ], [ %18, %vector.memcheck ]
  %bc.resume.val26 = phi i32 [ %ind.end25, %middle.block ], [ %8, %.lr.ph8.preheader ], [ %8, %vector.scevcheck ], [ %8, %vector.memcheck ]
  br label %.lr.ph8

.lr.ph8:                                          ; preds = %scalar.ph, %.lr.ph8
  %47 = phi i64 [ %57, %.lr.ph8 ], [ %bc.resume.val, %scalar.ph ]
  %48 = phi i32 [ %56, %.lr.ph8 ], [ %bc.resume.val26, %scalar.ph ]
  %49 = load i32, ptr %5, align 4, !tbaa !4
  %50 = sitofp i32 %49 to float
  %51 = fdiv contract float 1.000000e+00, %50
  %52 = fpext float %51 to double
  %53 = sext i32 %48 to i64
  %54 = add nsw i64 %53, -1
  %55 = getelementptr double, ptr %16, i64 %54
  store double %52, ptr %55, align 8, !tbaa !4
  store double %52, ptr %7, align 8, !tbaa !4
  %56 = add i32 %48, 1
  %57 = add nsw i64 %47, -1
  %58 = icmp ugt i64 %47, 1
  br i1 %58, label %.lr.ph8, label %.loopexit.loopexit.loopexit, !llvm.loop !31

59:                                               ; preds = %4
  %reass.sub = sub nsw i64 %11, %9
  %60 = icmp sgt i64 %reass.sub, -1
  br i1 %60, label %.lr.ph, label %.loopexit

.lr.ph:                                           ; preds = %59
  %61 = add nuw nsw i64 %reass.sub, 1
  %62 = load ptr, ptr %2, align 8, !tbaa !8
  br label %63

63:                                               ; preds = %.lr.ph, %63
  %64 = phi i64 [ %61, %.lr.ph ], [ %75, %63 ]
  %65 = phi i32 [ %8, %.lr.ph ], [ %74, %63 ]
  %66 = load i32, ptr %5, align 4, !tbaa !4
  %67 = sitofp i32 %66 to float
  %68 = fdiv contract float 1.000000e+00, %67
  %69 = fpext float %68 to double
  %70 = sext i32 %65 to i64
  %71 = add nsw i64 %70, -1
  %72 = mul i64 %71, %13
  %73 = getelementptr i8, ptr %62, i64 %72
  store double %69, ptr %73, align 8, !tbaa !4
  store double %69, ptr %7, align 8, !tbaa !4
  %74 = add i32 %65, 1
  %75 = add nsw i64 %64, -1
  %76 = icmp ugt i64 %64, 1
  br i1 %76, label %63, label %.loopexit.loopexit12

.loopexit.loopexit.loopexit:                      ; preds = %.lr.ph8
  br label %.loopexit.loopexit

.loopexit.loopexit:                               ; preds = %.loopexit.loopexit.loopexit, %middle.block
  br label %.loopexit

.loopexit.loopexit12:                             ; preds = %63
  br label %.loopexit

.loopexit:                                        ; preds = %.loopexit.loopexit12, %.loopexit.loopexit, %59, %15
  ret void
}
*** IR Dump After InstCombinePass on _QFPloop ***
; Function Attrs: nofree norecurse nosync nounwind memory(readwrite, inaccessiblemem: none)
define void @_QFPloop(ptr nocapture readonly %0, ptr nocapture readonly %1, ptr nocapture readonly %2, ptr nest nocapture readonly %3) local_unnamed_addr #4 {
  %5 = load ptr, ptr %3, align 8, !tbaa !4
  %6 = getelementptr { ptr, ptr }, ptr %3, i64 0, i32 1
  %7 = load ptr, ptr %6, align 8, !tbaa !4
  %8 = load i32, ptr %0, align 4, !tbaa !4
  %9 = sext i32 %8 to i64
  %10 = load i32, ptr %1, align 4, !tbaa !4
  %11 = sext i32 %10 to i64
  %12 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %2, i64 0, i32 7, i64 0, i64 2
  %13 = load i64, ptr %12, align 8, !tbaa !8
  %14 = icmp eq i64 %13, 8
  br i1 %14, label %15, label %59

15:                                               ; preds = %4
  %16 = load ptr, ptr %2, align 8, !tbaa !8
  %reass.sub9 = sub nsw i64 %11, %9
  %17 = icmp sgt i64 %reass.sub9, -1
  br i1 %17, label %.lr.ph8.preheader, label %.loopexit

.lr.ph8.preheader:                                ; preds = %15
  %18 = add nsw i64 %reass.sub9, 1
  %19 = add nsw i64 %11, 2
  %20 = icmp ne i64 %18, 0
  %umin24.neg = sext i1 %20 to i64
  %21 = add nsw i64 %19, %umin24.neg
  %22 = sub nsw i64 %21, %9
  %min.iters.check = icmp ult i64 %22, 8
  br i1 %min.iters.check, label %scalar.ph, label %vector.scevcheck

vector.scevcheck:                                 ; preds = %.lr.ph8.preheader
  %23 = add nsw i64 %11, 1
  %24 = icmp ne i64 %18, 0
  %umin.neg = sext i1 %24 to i64
  %25 = add nsw i64 %23, %umin.neg
  %26 = sub nsw i64 %25, %9
  %27 = trunc i64 %26 to i32
  %28 = add i32 %8, %27
  %29 = icmp slt i32 %28, %8
  %30 = icmp ugt i64 %26, 4294967295
  %31 = or i1 %29, %30
  br i1 %31, label %scalar.ph, label %vector.memcheck

vector.memcheck:                                  ; preds = %vector.scevcheck
  %scevgep = getelementptr i8, ptr %7, i64 8
  %scevgep13 = getelementptr i8, ptr %5, i64 4
  %32 = shl nsw i64 %9, 3
  %33 = add nsw i64 %32, -8
  %scevgep14 = getelementptr i8, ptr %16, i64 %33
  %34 = shl nsw i64 %11, 3
  %35 = add nsw i64 %34, 8
  %.not = icmp eq i64 %18, 0
  %36 = select i1 %.not, i64 %35, i64 %34
  %scevgep16 = getelementptr i8, ptr %16, i64 %36
  %bound0 = icmp ult ptr %7, %scevgep13
  %bound1 = icmp ult ptr %5, %scevgep
  %found.conflict = and i1 %bound0, %bound1
  %bound017 = icmp ult ptr %7, %scevgep16
  %bound118 = icmp ult ptr %scevgep14, %scevgep
  %found.conflict19 = and i1 %bound017, %bound118
  %conflict.rdx = or i1 %found.conflict, %found.conflict19
  %bound020 = icmp ult ptr %5, %scevgep16
  %bound121 = icmp ult ptr %scevgep14, %scevgep13
  %found.conflict22 = and i1 %bound020, %bound121
  %conflict.rdx23 = or i1 %conflict.rdx, %found.conflict22
  br i1 %conflict.rdx23, label %scalar.ph, label %vector.ph

vector.ph:                                        ; preds = %vector.memcheck
  %n.vec = and i64 %22, -2
  %ind.end = sub nsw i64 %18, %n.vec
  %.cast = trunc i64 %n.vec to i32
  %ind.end25 = add i32 %8, %.cast
  br label %vector.body

vector.body:                                      ; preds = %vector.body, %vector.ph
  %index = phi i64 [ 0, %vector.ph ], [ %index.next, %vector.body ]
  %.cast27 = trunc i64 %index to i32
  %offset.idx = add i32 %8, %.cast27
  %37 = load i32, ptr %5, align 4, !tbaa !4, !alias.scope !22, !noalias !25
  %broadcast.splatinsert = insertelement <2 x i32> poison, i32 %37, i64 0
  %38 = sitofp <2 x i32> %broadcast.splatinsert to <2 x float>
  %39 = fdiv contract <2 x float> <float 1.000000e+00, float poison>, %38
  %40 = shufflevector <2 x float> %39, <2 x float> poison, <2 x i32> zeroinitializer
  %41 = fpext <2 x float> %40 to <2 x double>
  %42 = sext i32 %offset.idx to i64
  %43 = add nsw i64 %42, -1
  %44 = getelementptr double, ptr %16, i64 %43
  store <2 x double> %41, ptr %44, align 8, !tbaa !4, !alias.scope !25
  %45 = extractelement <2 x double> %41, i64 1
  store double %45, ptr %7, align 8, !tbaa !4, !alias.scope !27, !noalias !29
  %index.next = add nuw i64 %index, 2
  %46 = icmp eq i64 %index.next, %n.vec
  br i1 %46, label %middle.block, label %vector.body, !llvm.loop !30

middle.block:                                     ; preds = %vector.body
  %cmp.n = icmp eq i64 %22, %n.vec
  br i1 %cmp.n, label %.loopexit.loopexit, label %scalar.ph

scalar.ph:                                        ; preds = %vector.memcheck, %vector.scevcheck, %.lr.ph8.preheader, %middle.block
  %bc.resume.val = phi i64 [ %ind.end, %middle.block ], [ %18, %.lr.ph8.preheader ], [ %18, %vector.scevcheck ], [ %18, %vector.memcheck ]
  %bc.resume.val26 = phi i32 [ %ind.end25, %middle.block ], [ %8, %.lr.ph8.preheader ], [ %8, %vector.scevcheck ], [ %8, %vector.memcheck ]
  br label %.lr.ph8

.lr.ph8:                                          ; preds = %scalar.ph, %.lr.ph8
  %47 = phi i64 [ %57, %.lr.ph8 ], [ %bc.resume.val, %scalar.ph ]
  %48 = phi i32 [ %56, %.lr.ph8 ], [ %bc.resume.val26, %scalar.ph ]
  %49 = load i32, ptr %5, align 4, !tbaa !4
  %50 = sitofp i32 %49 to float
  %51 = fdiv contract float 1.000000e+00, %50
  %52 = fpext float %51 to double
  %53 = sext i32 %48 to i64
  %54 = add nsw i64 %53, -1
  %55 = getelementptr double, ptr %16, i64 %54
  store double %52, ptr %55, align 8, !tbaa !4
  store double %52, ptr %7, align 8, !tbaa !4
  %56 = add i32 %48, 1
  %57 = add nsw i64 %47, -1
  %58 = icmp ugt i64 %47, 1
  br i1 %58, label %.lr.ph8, label %.loopexit.loopexit.loopexit, !llvm.loop !31

59:                                               ; preds = %4
  %reass.sub = sub nsw i64 %11, %9
  %60 = icmp sgt i64 %reass.sub, -1
  br i1 %60, label %.lr.ph, label %.loopexit

.lr.ph:                                           ; preds = %59
  %61 = add nuw nsw i64 %reass.sub, 1
  %62 = load ptr, ptr %2, align 8, !tbaa !8
  br label %63

63:                                               ; preds = %.lr.ph, %63
  %64 = phi i64 [ %61, %.lr.ph ], [ %75, %63 ]
  %65 = phi i32 [ %8, %.lr.ph ], [ %74, %63 ]
  %66 = load i32, ptr %5, align 4, !tbaa !4
  %67 = sitofp i32 %66 to float
  %68 = fdiv contract float 1.000000e+00, %67
  %69 = fpext float %68 to double
  %70 = sext i32 %65 to i64
  %71 = add nsw i64 %70, -1
  %72 = mul i64 %71, %13
  %73 = getelementptr i8, ptr %62, i64 %72
  store double %69, ptr %73, align 8, !tbaa !4
  store double %69, ptr %7, align 8, !tbaa !4
  %74 = add i32 %65, 1
  %75 = add nsw i64 %64, -1
  %76 = icmp ugt i64 %64, 1
  br i1 %76, label %63, label %.loopexit.loopexit12

.loopexit.loopexit.loopexit:                      ; preds = %.lr.ph8
  br label %.loopexit.loopexit

.loopexit.loopexit:                               ; preds = %.loopexit.loopexit.loopexit, %middle.block
  br label %.loopexit

.loopexit.loopexit12:                             ; preds = %63
  br label %.loopexit

.loopexit:                                        ; preds = %.loopexit.loopexit12, %.loopexit.loopexit, %59, %15
  ret void
}
*** IR Dump After SimplifyCFGPass on _QFPloop ***
; Function Attrs: nofree norecurse nosync nounwind memory(readwrite, inaccessiblemem: none)
define void @_QFPloop(ptr nocapture readonly %0, ptr nocapture readonly %1, ptr nocapture readonly %2, ptr nest nocapture readonly %3) local_unnamed_addr #4 {
  %5 = load ptr, ptr %3, align 8, !tbaa !4
  %6 = getelementptr { ptr, ptr }, ptr %3, i64 0, i32 1
  %7 = load ptr, ptr %6, align 8, !tbaa !4
  %8 = load i32, ptr %0, align 4, !tbaa !4
  %9 = sext i32 %8 to i64
  %10 = load i32, ptr %1, align 4, !tbaa !4
  %11 = sext i32 %10 to i64
  %12 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %2, i64 0, i32 7, i64 0, i64 2
  %13 = load i64, ptr %12, align 8, !tbaa !8
  %14 = icmp eq i64 %13, 8
  br i1 %14, label %15, label %59

15:                                               ; preds = %4
  %16 = load ptr, ptr %2, align 8, !tbaa !8
  %reass.sub9 = sub nsw i64 %11, %9
  %17 = icmp sgt i64 %reass.sub9, -1
  br i1 %17, label %.lr.ph8.preheader, label %.loopexit

.lr.ph8.preheader:                                ; preds = %15
  %18 = add nsw i64 %reass.sub9, 1
  %19 = add nsw i64 %11, 2
  %20 = icmp ne i64 %18, 0
  %umin24.neg = sext i1 %20 to i64
  %21 = add nsw i64 %19, %umin24.neg
  %22 = sub nsw i64 %21, %9
  %min.iters.check = icmp ult i64 %22, 8
  br i1 %min.iters.check, label %.lr.ph8, label %vector.scevcheck

vector.scevcheck:                                 ; preds = %.lr.ph8.preheader
  %23 = add nsw i64 %11, 1
  %24 = icmp ne i64 %18, 0
  %umin.neg = sext i1 %24 to i64
  %25 = add nsw i64 %23, %umin.neg
  %26 = sub nsw i64 %25, %9
  %27 = trunc i64 %26 to i32
  %28 = add i32 %8, %27
  %29 = icmp slt i32 %28, %8
  %30 = icmp ugt i64 %26, 4294967295
  %31 = or i1 %29, %30
  br i1 %31, label %.lr.ph8, label %vector.memcheck

vector.memcheck:                                  ; preds = %vector.scevcheck
  %scevgep = getelementptr i8, ptr %7, i64 8
  %scevgep13 = getelementptr i8, ptr %5, i64 4
  %32 = shl nsw i64 %9, 3
  %33 = add nsw i64 %32, -8
  %scevgep14 = getelementptr i8, ptr %16, i64 %33
  %34 = shl nsw i64 %11, 3
  %35 = add nsw i64 %34, 8
  %.not = icmp eq i64 %18, 0
  %36 = select i1 %.not, i64 %35, i64 %34
  %scevgep16 = getelementptr i8, ptr %16, i64 %36
  %bound0 = icmp ult ptr %7, %scevgep13
  %bound1 = icmp ult ptr %5, %scevgep
  %found.conflict = and i1 %bound0, %bound1
  %bound017 = icmp ult ptr %7, %scevgep16
  %bound118 = icmp ult ptr %scevgep14, %scevgep
  %found.conflict19 = and i1 %bound017, %bound118
  %conflict.rdx = or i1 %found.conflict, %found.conflict19
  %bound020 = icmp ult ptr %5, %scevgep16
  %bound121 = icmp ult ptr %scevgep14, %scevgep13
  %found.conflict22 = and i1 %bound020, %bound121
  %conflict.rdx23 = or i1 %conflict.rdx, %found.conflict22
  br i1 %conflict.rdx23, label %.lr.ph8, label %vector.ph

vector.ph:                                        ; preds = %vector.memcheck
  %n.vec = and i64 %22, -2
  %ind.end = sub nsw i64 %18, %n.vec
  %.cast = trunc i64 %n.vec to i32
  %ind.end25 = add i32 %8, %.cast
  br label %vector.body

vector.body:                                      ; preds = %vector.body, %vector.ph
  %index = phi i64 [ 0, %vector.ph ], [ %index.next, %vector.body ]
  %.cast27 = trunc i64 %index to i32
  %offset.idx = add i32 %8, %.cast27
  %37 = load i32, ptr %5, align 4, !tbaa !4, !alias.scope !22, !noalias !25
  %broadcast.splatinsert = insertelement <2 x i32> poison, i32 %37, i64 0
  %38 = sitofp <2 x i32> %broadcast.splatinsert to <2 x float>
  %39 = fdiv contract <2 x float> <float 1.000000e+00, float poison>, %38
  %40 = shufflevector <2 x float> %39, <2 x float> poison, <2 x i32> zeroinitializer
  %41 = fpext <2 x float> %40 to <2 x double>
  %42 = sext i32 %offset.idx to i64
  %43 = add nsw i64 %42, -1
  %44 = getelementptr double, ptr %16, i64 %43
  store <2 x double> %41, ptr %44, align 8, !tbaa !4, !alias.scope !25
  %45 = extractelement <2 x double> %41, i64 1
  store double %45, ptr %7, align 8, !tbaa !4, !alias.scope !27, !noalias !29
  %index.next = add nuw i64 %index, 2
  %46 = icmp eq i64 %index.next, %n.vec
  br i1 %46, label %middle.block, label %vector.body, !llvm.loop !30

middle.block:                                     ; preds = %vector.body
  %cmp.n = icmp eq i64 %22, %n.vec
  br i1 %cmp.n, label %.loopexit, label %.lr.ph8

.lr.ph8:                                          ; preds = %middle.block, %.lr.ph8.preheader, %vector.scevcheck, %vector.memcheck, %.lr.ph8
  %47 = phi i64 [ %57, %.lr.ph8 ], [ %ind.end, %middle.block ], [ %18, %.lr.ph8.preheader ], [ %18, %vector.scevcheck ], [ %18, %vector.memcheck ]
  %48 = phi i32 [ %56, %.lr.ph8 ], [ %ind.end25, %middle.block ], [ %8, %.lr.ph8.preheader ], [ %8, %vector.scevcheck ], [ %8, %vector.memcheck ]
  %49 = load i32, ptr %5, align 4, !tbaa !4
  %50 = sitofp i32 %49 to float
  %51 = fdiv contract float 1.000000e+00, %50
  %52 = fpext float %51 to double
  %53 = sext i32 %48 to i64
  %54 = add nsw i64 %53, -1
  %55 = getelementptr double, ptr %16, i64 %54
  store double %52, ptr %55, align 8, !tbaa !4
  store double %52, ptr %7, align 8, !tbaa !4
  %56 = add i32 %48, 1
  %57 = add nsw i64 %47, -1
  %58 = icmp ugt i64 %47, 1
  br i1 %58, label %.lr.ph8, label %.loopexit, !llvm.loop !31

59:                                               ; preds = %4
  %reass.sub = sub nsw i64 %11, %9
  %60 = icmp sgt i64 %reass.sub, -1
  br i1 %60, label %.lr.ph, label %.loopexit

.lr.ph:                                           ; preds = %59
  %61 = add nuw nsw i64 %reass.sub, 1
  %62 = load ptr, ptr %2, align 8, !tbaa !8
  br label %63

63:                                               ; preds = %.lr.ph, %63
  %64 = phi i64 [ %61, %.lr.ph ], [ %75, %63 ]
  %65 = phi i32 [ %8, %.lr.ph ], [ %74, %63 ]
  %66 = load i32, ptr %5, align 4, !tbaa !4
  %67 = sitofp i32 %66 to float
  %68 = fdiv contract float 1.000000e+00, %67
  %69 = fpext float %68 to double
  %70 = sext i32 %65 to i64
  %71 = add nsw i64 %70, -1
  %72 = mul i64 %71, %13
  %73 = getelementptr i8, ptr %62, i64 %72
  store double %69, ptr %73, align 8, !tbaa !4
  store double %69, ptr %7, align 8, !tbaa !4
  %74 = add i32 %65, 1
  %75 = add nsw i64 %64, -1
  %76 = icmp ugt i64 %64, 1
  br i1 %76, label %63, label %.loopexit

.loopexit:                                        ; preds = %63, %middle.block, %.lr.ph8, %59, %15
  ret void
}
*** IR Dump After VectorCombinePass on _QFPloop ***
; Function Attrs: nofree norecurse nosync nounwind memory(readwrite, inaccessiblemem: none)
define void @_QFPloop(ptr nocapture readonly %0, ptr nocapture readonly %1, ptr nocapture readonly %2, ptr nest nocapture readonly %3) local_unnamed_addr #4 {
  %5 = load ptr, ptr %3, align 8, !tbaa !4
  %6 = getelementptr { ptr, ptr }, ptr %3, i64 0, i32 1
  %7 = load ptr, ptr %6, align 8, !tbaa !4
  %8 = load i32, ptr %0, align 4, !tbaa !4
  %9 = sext i32 %8 to i64
  %10 = load i32, ptr %1, align 4, !tbaa !4
  %11 = sext i32 %10 to i64
  %12 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %2, i64 0, i32 7, i64 0, i64 2
  %13 = load i64, ptr %12, align 8, !tbaa !8
  %14 = icmp eq i64 %13, 8
  br i1 %14, label %15, label %59

15:                                               ; preds = %4
  %16 = load ptr, ptr %2, align 8, !tbaa !8
  %reass.sub9 = sub nsw i64 %11, %9
  %17 = icmp sgt i64 %reass.sub9, -1
  br i1 %17, label %.lr.ph8.preheader, label %.loopexit

.lr.ph8.preheader:                                ; preds = %15
  %18 = add nsw i64 %reass.sub9, 1
  %19 = add nsw i64 %11, 2
  %20 = icmp ne i64 %18, 0
  %umin24.neg = sext i1 %20 to i64
  %21 = add nsw i64 %19, %umin24.neg
  %22 = sub nsw i64 %21, %9
  %min.iters.check = icmp ult i64 %22, 8
  br i1 %min.iters.check, label %.lr.ph8, label %vector.scevcheck

vector.scevcheck:                                 ; preds = %.lr.ph8.preheader
  %23 = add nsw i64 %11, 1
  %24 = icmp ne i64 %18, 0
  %umin.neg = sext i1 %24 to i64
  %25 = add nsw i64 %23, %umin.neg
  %26 = sub nsw i64 %25, %9
  %27 = trunc i64 %26 to i32
  %28 = add i32 %8, %27
  %29 = icmp slt i32 %28, %8
  %30 = icmp ugt i64 %26, 4294967295
  %31 = or i1 %29, %30
  br i1 %31, label %.lr.ph8, label %vector.memcheck

vector.memcheck:                                  ; preds = %vector.scevcheck
  %scevgep = getelementptr i8, ptr %7, i64 8
  %scevgep13 = getelementptr i8, ptr %5, i64 4
  %32 = shl nsw i64 %9, 3
  %33 = add nsw i64 %32, -8
  %scevgep14 = getelementptr i8, ptr %16, i64 %33
  %34 = shl nsw i64 %11, 3
  %35 = add nsw i64 %34, 8
  %.not = icmp eq i64 %18, 0
  %36 = select i1 %.not, i64 %35, i64 %34
  %scevgep16 = getelementptr i8, ptr %16, i64 %36
  %bound0 = icmp ult ptr %7, %scevgep13
  %bound1 = icmp ult ptr %5, %scevgep
  %found.conflict = and i1 %bound0, %bound1
  %bound017 = icmp ult ptr %7, %scevgep16
  %bound118 = icmp ult ptr %scevgep14, %scevgep
  %found.conflict19 = and i1 %bound017, %bound118
  %conflict.rdx = or i1 %found.conflict, %found.conflict19
  %bound020 = icmp ult ptr %5, %scevgep16
  %bound121 = icmp ult ptr %scevgep14, %scevgep13
  %found.conflict22 = and i1 %bound020, %bound121
  %conflict.rdx23 = or i1 %conflict.rdx, %found.conflict22
  br i1 %conflict.rdx23, label %.lr.ph8, label %vector.ph

vector.ph:                                        ; preds = %vector.memcheck
  %n.vec = and i64 %22, -2
  %ind.end = sub nsw i64 %18, %n.vec
  %.cast = trunc i64 %n.vec to i32
  %ind.end25 = add i32 %8, %.cast
  br label %vector.body

vector.body:                                      ; preds = %vector.body, %vector.ph
  %index = phi i64 [ 0, %vector.ph ], [ %index.next, %vector.body ]
  %.cast27 = trunc i64 %index to i32
  %offset.idx = add i32 %8, %.cast27
  %37 = load i32, ptr %5, align 4, !tbaa !4, !alias.scope !22, !noalias !25
  %broadcast.splatinsert = insertelement <2 x i32> poison, i32 %37, i64 0
  %38 = sitofp <2 x i32> %broadcast.splatinsert to <2 x float>
  %39 = fdiv contract <2 x float> <float 1.000000e+00, float poison>, %38
  %40 = shufflevector <2 x float> %39, <2 x float> poison, <2 x i32> zeroinitializer
  %41 = fpext <2 x float> %40 to <2 x double>
  %42 = sext i32 %offset.idx to i64
  %43 = add nsw i64 %42, -1
  %44 = getelementptr double, ptr %16, i64 %43
  store <2 x double> %41, ptr %44, align 8, !tbaa !4, !alias.scope !25
  %45 = extractelement <2 x double> %41, i64 1
  store double %45, ptr %7, align 8, !tbaa !4, !alias.scope !27, !noalias !29
  %index.next = add nuw i64 %index, 2
  %46 = icmp eq i64 %index.next, %n.vec
  br i1 %46, label %middle.block, label %vector.body, !llvm.loop !30

middle.block:                                     ; preds = %vector.body
  %cmp.n = icmp eq i64 %22, %n.vec
  br i1 %cmp.n, label %.loopexit, label %.lr.ph8

.lr.ph8:                                          ; preds = %middle.block, %.lr.ph8.preheader, %vector.scevcheck, %vector.memcheck, %.lr.ph8
  %47 = phi i64 [ %57, %.lr.ph8 ], [ %ind.end, %middle.block ], [ %18, %.lr.ph8.preheader ], [ %18, %vector.scevcheck ], [ %18, %vector.memcheck ]
  %48 = phi i32 [ %56, %.lr.ph8 ], [ %ind.end25, %middle.block ], [ %8, %.lr.ph8.preheader ], [ %8, %vector.scevcheck ], [ %8, %vector.memcheck ]
  %49 = load i32, ptr %5, align 4, !tbaa !4
  %50 = sitofp i32 %49 to float
  %51 = fdiv contract float 1.000000e+00, %50
  %52 = fpext float %51 to double
  %53 = sext i32 %48 to i64
  %54 = add nsw i64 %53, -1
  %55 = getelementptr double, ptr %16, i64 %54
  store double %52, ptr %55, align 8, !tbaa !4
  store double %52, ptr %7, align 8, !tbaa !4
  %56 = add i32 %48, 1
  %57 = add nsw i64 %47, -1
  %58 = icmp ugt i64 %47, 1
  br i1 %58, label %.lr.ph8, label %.loopexit, !llvm.loop !31

59:                                               ; preds = %4
  %reass.sub = sub nsw i64 %11, %9
  %60 = icmp sgt i64 %reass.sub, -1
  br i1 %60, label %.lr.ph, label %.loopexit

.lr.ph:                                           ; preds = %59
  %61 = add nuw nsw i64 %reass.sub, 1
  %62 = load ptr, ptr %2, align 8, !tbaa !8
  br label %63

63:                                               ; preds = %.lr.ph, %63
  %64 = phi i64 [ %61, %.lr.ph ], [ %75, %63 ]
  %65 = phi i32 [ %8, %.lr.ph ], [ %74, %63 ]
  %66 = load i32, ptr %5, align 4, !tbaa !4
  %67 = sitofp i32 %66 to float
  %68 = fdiv contract float 1.000000e+00, %67
  %69 = fpext float %68 to double
  %70 = sext i32 %65 to i64
  %71 = add nsw i64 %70, -1
  %72 = mul i64 %71, %13
  %73 = getelementptr i8, ptr %62, i64 %72
  store double %69, ptr %73, align 8, !tbaa !4
  store double %69, ptr %7, align 8, !tbaa !4
  %74 = add i32 %65, 1
  %75 = add nsw i64 %64, -1
  %76 = icmp ugt i64 %64, 1
  br i1 %76, label %63, label %.loopexit

.loopexit:                                        ; preds = %63, %middle.block, %.lr.ph8, %59, %15
  ret void
}
*** IR Dump After InstCombinePass on _QFPloop ***
; Function Attrs: nofree norecurse nosync nounwind memory(readwrite, inaccessiblemem: none)
define void @_QFPloop(ptr nocapture readonly %0, ptr nocapture readonly %1, ptr nocapture readonly %2, ptr nest nocapture readonly %3) local_unnamed_addr #4 {
  %5 = load ptr, ptr %3, align 8, !tbaa !4
  %6 = getelementptr { ptr, ptr }, ptr %3, i64 0, i32 1
  %7 = load ptr, ptr %6, align 8, !tbaa !4
  %8 = load i32, ptr %0, align 4, !tbaa !4
  %9 = sext i32 %8 to i64
  %10 = load i32, ptr %1, align 4, !tbaa !4
  %11 = sext i32 %10 to i64
  %12 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %2, i64 0, i32 7, i64 0, i64 2
  %13 = load i64, ptr %12, align 8, !tbaa !8
  %14 = icmp eq i64 %13, 8
  br i1 %14, label %15, label %59

15:                                               ; preds = %4
  %16 = load ptr, ptr %2, align 8, !tbaa !8
  %reass.sub9 = sub nsw i64 %11, %9
  %17 = icmp sgt i64 %reass.sub9, -1
  br i1 %17, label %.lr.ph8.preheader, label %.loopexit

.lr.ph8.preheader:                                ; preds = %15
  %18 = add nsw i64 %reass.sub9, 1
  %19 = add nsw i64 %11, 2
  %20 = icmp ne i64 %18, 0
  %umin24.neg = sext i1 %20 to i64
  %21 = add nsw i64 %19, %umin24.neg
  %22 = sub nsw i64 %21, %9
  %min.iters.check = icmp ult i64 %22, 8
  br i1 %min.iters.check, label %.lr.ph8, label %vector.scevcheck

vector.scevcheck:                                 ; preds = %.lr.ph8.preheader
  %23 = add nsw i64 %11, 1
  %24 = icmp ne i64 %18, 0
  %umin.neg = sext i1 %24 to i64
  %25 = add nsw i64 %23, %umin.neg
  %26 = sub nsw i64 %25, %9
  %27 = trunc i64 %26 to i32
  %28 = add i32 %8, %27
  %29 = icmp slt i32 %28, %8
  %30 = icmp ugt i64 %26, 4294967295
  %31 = or i1 %29, %30
  br i1 %31, label %.lr.ph8, label %vector.memcheck

vector.memcheck:                                  ; preds = %vector.scevcheck
  %scevgep = getelementptr i8, ptr %7, i64 8
  %scevgep13 = getelementptr i8, ptr %5, i64 4
  %32 = shl nsw i64 %9, 3
  %33 = add nsw i64 %32, -8
  %scevgep14 = getelementptr i8, ptr %16, i64 %33
  %34 = shl nsw i64 %11, 3
  %35 = add nsw i64 %34, 8
  %.not = icmp eq i64 %18, 0
  %36 = select i1 %.not, i64 %35, i64 %34
  %scevgep16 = getelementptr i8, ptr %16, i64 %36
  %bound0 = icmp ult ptr %7, %scevgep13
  %bound1 = icmp ult ptr %5, %scevgep
  %found.conflict = and i1 %bound0, %bound1
  %bound017 = icmp ult ptr %7, %scevgep16
  %bound118 = icmp ult ptr %scevgep14, %scevgep
  %found.conflict19 = and i1 %bound017, %bound118
  %conflict.rdx = or i1 %found.conflict, %found.conflict19
  %bound020 = icmp ult ptr %5, %scevgep16
  %bound121 = icmp ult ptr %scevgep14, %scevgep13
  %found.conflict22 = and i1 %bound020, %bound121
  %conflict.rdx23 = or i1 %conflict.rdx, %found.conflict22
  br i1 %conflict.rdx23, label %.lr.ph8, label %vector.ph

vector.ph:                                        ; preds = %vector.memcheck
  %n.vec = and i64 %22, -2
  %ind.end = sub nsw i64 %18, %n.vec
  %.cast = trunc i64 %n.vec to i32
  %ind.end25 = add i32 %8, %.cast
  br label %vector.body

vector.body:                                      ; preds = %vector.body, %vector.ph
  %index = phi i64 [ 0, %vector.ph ], [ %index.next, %vector.body ]
  %.cast27 = trunc i64 %index to i32
  %offset.idx = add i32 %8, %.cast27
  %37 = load i32, ptr %5, align 4, !tbaa !4, !alias.scope !22, !noalias !25
  %broadcast.splatinsert = insertelement <2 x i32> poison, i32 %37, i64 0
  %38 = sitofp <2 x i32> %broadcast.splatinsert to <2 x float>
  %39 = fdiv contract <2 x float> <float 1.000000e+00, float poison>, %38
  %40 = shufflevector <2 x float> %39, <2 x float> poison, <2 x i32> zeroinitializer
  %41 = fpext <2 x float> %40 to <2 x double>
  %42 = sext i32 %offset.idx to i64
  %43 = add nsw i64 %42, -1
  %44 = getelementptr double, ptr %16, i64 %43
  store <2 x double> %41, ptr %44, align 8, !tbaa !4, !alias.scope !25
  %45 = extractelement <2 x double> %41, i64 1
  store double %45, ptr %7, align 8, !tbaa !4, !alias.scope !27, !noalias !29
  %index.next = add nuw i64 %index, 2
  %46 = icmp eq i64 %index.next, %n.vec
  br i1 %46, label %middle.block, label %vector.body, !llvm.loop !30

middle.block:                                     ; preds = %vector.body
  %cmp.n = icmp eq i64 %22, %n.vec
  br i1 %cmp.n, label %.loopexit, label %.lr.ph8

.lr.ph8:                                          ; preds = %middle.block, %.lr.ph8.preheader, %vector.scevcheck, %vector.memcheck, %.lr.ph8
  %47 = phi i64 [ %57, %.lr.ph8 ], [ %ind.end, %middle.block ], [ %18, %.lr.ph8.preheader ], [ %18, %vector.scevcheck ], [ %18, %vector.memcheck ]
  %48 = phi i32 [ %56, %.lr.ph8 ], [ %ind.end25, %middle.block ], [ %8, %.lr.ph8.preheader ], [ %8, %vector.scevcheck ], [ %8, %vector.memcheck ]
  %49 = load i32, ptr %5, align 4, !tbaa !4
  %50 = sitofp i32 %49 to float
  %51 = fdiv contract float 1.000000e+00, %50
  %52 = fpext float %51 to double
  %53 = sext i32 %48 to i64
  %54 = add nsw i64 %53, -1
  %55 = getelementptr double, ptr %16, i64 %54
  store double %52, ptr %55, align 8, !tbaa !4
  store double %52, ptr %7, align 8, !tbaa !4
  %56 = add i32 %48, 1
  %57 = add nsw i64 %47, -1
  %58 = icmp ugt i64 %47, 1
  br i1 %58, label %.lr.ph8, label %.loopexit, !llvm.loop !31

59:                                               ; preds = %4
  %reass.sub = sub nsw i64 %11, %9
  %60 = icmp sgt i64 %reass.sub, -1
  br i1 %60, label %.lr.ph, label %.loopexit

.lr.ph:                                           ; preds = %59
  %61 = add nuw nsw i64 %reass.sub, 1
  %62 = load ptr, ptr %2, align 8, !tbaa !8
  br label %63

63:                                               ; preds = %.lr.ph, %63
  %64 = phi i64 [ %61, %.lr.ph ], [ %75, %63 ]
  %65 = phi i32 [ %8, %.lr.ph ], [ %74, %63 ]
  %66 = load i32, ptr %5, align 4, !tbaa !4
  %67 = sitofp i32 %66 to float
  %68 = fdiv contract float 1.000000e+00, %67
  %69 = fpext float %68 to double
  %70 = sext i32 %65 to i64
  %71 = add nsw i64 %70, -1
  %72 = mul i64 %71, %13
  %73 = getelementptr i8, ptr %62, i64 %72
  store double %69, ptr %73, align 8, !tbaa !4
  store double %69, ptr %7, align 8, !tbaa !4
  %74 = add i32 %65, 1
  %75 = add nsw i64 %64, -1
  %76 = icmp ugt i64 %64, 1
  br i1 %76, label %63, label %.loopexit

.loopexit:                                        ; preds = %63, %middle.block, %.lr.ph8, %59, %15
  ret void
}
*** IR Dump After LoopUnrollPass on _QFPloop ***
; Function Attrs: nofree norecurse nosync nounwind memory(readwrite, inaccessiblemem: none)
define void @_QFPloop(ptr nocapture readonly %0, ptr nocapture readonly %1, ptr nocapture readonly %2, ptr nest nocapture readonly %3) local_unnamed_addr #4 {
  %5 = load ptr, ptr %3, align 8, !tbaa !4
  %6 = getelementptr { ptr, ptr }, ptr %3, i64 0, i32 1
  %7 = load ptr, ptr %6, align 8, !tbaa !4
  %8 = load i32, ptr %0, align 4, !tbaa !4
  %9 = sext i32 %8 to i64
  %10 = load i32, ptr %1, align 4, !tbaa !4
  %11 = sext i32 %10 to i64
  %12 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %2, i64 0, i32 7, i64 0, i64 2
  %13 = load i64, ptr %12, align 8, !tbaa !8
  %14 = icmp eq i64 %13, 8
  br i1 %14, label %15, label %59

15:                                               ; preds = %4
  %16 = load ptr, ptr %2, align 8, !tbaa !8
  %reass.sub9 = sub nsw i64 %11, %9
  %17 = icmp sgt i64 %reass.sub9, -1
  br i1 %17, label %.lr.ph8.preheader, label %.loopexit

.lr.ph8.preheader:                                ; preds = %15
  %18 = add nsw i64 %reass.sub9, 1
  %19 = add nsw i64 %11, 2
  %20 = icmp ne i64 %18, 0
  %umin24.neg = sext i1 %20 to i64
  %21 = add nsw i64 %19, %umin24.neg
  %22 = sub nsw i64 %21, %9
  %min.iters.check = icmp ult i64 %22, 8
  br i1 %min.iters.check, label %.lr.ph8.preheader28, label %vector.scevcheck

vector.scevcheck:                                 ; preds = %.lr.ph8.preheader
  %23 = add nsw i64 %11, 1
  %24 = icmp ne i64 %18, 0
  %umin.neg = sext i1 %24 to i64
  %25 = add nsw i64 %23, %umin.neg
  %26 = sub nsw i64 %25, %9
  %27 = trunc i64 %26 to i32
  %28 = add i32 %8, %27
  %29 = icmp slt i32 %28, %8
  %30 = icmp ugt i64 %26, 4294967295
  %31 = or i1 %29, %30
  br i1 %31, label %.lr.ph8.preheader28, label %vector.memcheck

vector.memcheck:                                  ; preds = %vector.scevcheck
  %scevgep = getelementptr i8, ptr %7, i64 8
  %scevgep13 = getelementptr i8, ptr %5, i64 4
  %32 = shl nsw i64 %9, 3
  %33 = add nsw i64 %32, -8
  %scevgep14 = getelementptr i8, ptr %16, i64 %33
  %34 = shl nsw i64 %11, 3
  %35 = add nsw i64 %34, 8
  %.not = icmp eq i64 %18, 0
  %36 = select i1 %.not, i64 %35, i64 %34
  %scevgep16 = getelementptr i8, ptr %16, i64 %36
  %bound0 = icmp ult ptr %7, %scevgep13
  %bound1 = icmp ult ptr %5, %scevgep
  %found.conflict = and i1 %bound0, %bound1
  %bound017 = icmp ult ptr %7, %scevgep16
  %bound118 = icmp ult ptr %scevgep14, %scevgep
  %found.conflict19 = and i1 %bound017, %bound118
  %conflict.rdx = or i1 %found.conflict, %found.conflict19
  %bound020 = icmp ult ptr %5, %scevgep16
  %bound121 = icmp ult ptr %scevgep14, %scevgep13
  %found.conflict22 = and i1 %bound020, %bound121
  %conflict.rdx23 = or i1 %conflict.rdx, %found.conflict22
  br i1 %conflict.rdx23, label %.lr.ph8.preheader28, label %vector.ph

vector.ph:                                        ; preds = %vector.memcheck
  %n.vec = and i64 %22, -2
  %ind.end = sub nsw i64 %18, %n.vec
  %.cast = trunc i64 %n.vec to i32
  %ind.end25 = add i32 %8, %.cast
  br label %vector.body

vector.body:                                      ; preds = %vector.body, %vector.ph
  %index = phi i64 [ 0, %vector.ph ], [ %index.next, %vector.body ]
  %.cast27 = trunc i64 %index to i32
  %offset.idx = add i32 %8, %.cast27
  %37 = load i32, ptr %5, align 4, !tbaa !4, !alias.scope !22, !noalias !25
  %broadcast.splatinsert = insertelement <2 x i32> poison, i32 %37, i64 0
  %38 = sitofp <2 x i32> %broadcast.splatinsert to <2 x float>
  %39 = fdiv contract <2 x float> <float 1.000000e+00, float poison>, %38
  %40 = shufflevector <2 x float> %39, <2 x float> poison, <2 x i32> zeroinitializer
  %41 = fpext <2 x float> %40 to <2 x double>
  %42 = sext i32 %offset.idx to i64
  %43 = add nsw i64 %42, -1
  %44 = getelementptr double, ptr %16, i64 %43
  store <2 x double> %41, ptr %44, align 8, !tbaa !4, !alias.scope !25
  %45 = extractelement <2 x double> %41, i64 1
  store double %45, ptr %7, align 8, !tbaa !4, !alias.scope !27, !noalias !29
  %index.next = add nuw i64 %index, 2
  %46 = icmp eq i64 %index.next, %n.vec
  br i1 %46, label %middle.block, label %vector.body, !llvm.loop !30

middle.block:                                     ; preds = %vector.body
  %cmp.n = icmp eq i64 %22, %n.vec
  br i1 %cmp.n, label %.loopexit, label %.lr.ph8.preheader28

.lr.ph8.preheader28:                              ; preds = %vector.memcheck, %vector.scevcheck, %.lr.ph8.preheader, %middle.block
  %.ph = phi i64 [ %18, %vector.memcheck ], [ %18, %vector.scevcheck ], [ %18, %.lr.ph8.preheader ], [ %ind.end, %middle.block ]
  %.ph29 = phi i32 [ %8, %vector.memcheck ], [ %8, %vector.scevcheck ], [ %8, %.lr.ph8.preheader ], [ %ind.end25, %middle.block ]
  br label %.lr.ph8

.lr.ph8:                                          ; preds = %.lr.ph8.preheader28, %.lr.ph8
  %47 = phi i64 [ %57, %.lr.ph8 ], [ %.ph, %.lr.ph8.preheader28 ]
  %48 = phi i32 [ %56, %.lr.ph8 ], [ %.ph29, %.lr.ph8.preheader28 ]
  %49 = load i32, ptr %5, align 4, !tbaa !4
  %50 = sitofp i32 %49 to float
  %51 = fdiv contract float 1.000000e+00, %50
  %52 = fpext float %51 to double
  %53 = sext i32 %48 to i64
  %54 = add nsw i64 %53, -1
  %55 = getelementptr double, ptr %16, i64 %54
  store double %52, ptr %55, align 8, !tbaa !4
  store double %52, ptr %7, align 8, !tbaa !4
  %56 = add i32 %48, 1
  %57 = add nsw i64 %47, -1
  %58 = icmp ugt i64 %47, 1
  br i1 %58, label %.lr.ph8, label %.loopexit.loopexit, !llvm.loop !31

59:                                               ; preds = %4
  %reass.sub = sub nsw i64 %11, %9
  %60 = icmp sgt i64 %reass.sub, -1
  br i1 %60, label %.lr.ph, label %.loopexit

.lr.ph:                                           ; preds = %59
  %61 = add nuw nsw i64 %reass.sub, 1
  %62 = load ptr, ptr %2, align 8, !tbaa !8
  br label %63

63:                                               ; preds = %.lr.ph, %63
  %64 = phi i64 [ %61, %.lr.ph ], [ %75, %63 ]
  %65 = phi i32 [ %8, %.lr.ph ], [ %74, %63 ]
  %66 = load i32, ptr %5, align 4, !tbaa !4
  %67 = sitofp i32 %66 to float
  %68 = fdiv contract float 1.000000e+00, %67
  %69 = fpext float %68 to double
  %70 = sext i32 %65 to i64
  %71 = add nsw i64 %70, -1
  %72 = mul i64 %71, %13
  %73 = getelementptr i8, ptr %62, i64 %72
  store double %69, ptr %73, align 8, !tbaa !4
  store double %69, ptr %7, align 8, !tbaa !4
  %74 = add i32 %65, 1
  %75 = add nsw i64 %64, -1
  %76 = icmp ugt i64 %64, 1
  br i1 %76, label %63, label %.loopexit.loopexit30

.loopexit.loopexit:                               ; preds = %.lr.ph8
  br label %.loopexit

.loopexit.loopexit30:                             ; preds = %63
  br label %.loopexit

.loopexit:                                        ; preds = %.loopexit.loopexit30, %.loopexit.loopexit, %middle.block, %59, %15
  ret void
}
*** IR Dump After WarnMissedTransformationsPass on _QFPloop ***
; Function Attrs: nofree norecurse nosync nounwind memory(readwrite, inaccessiblemem: none)
define void @_QFPloop(ptr nocapture readonly %0, ptr nocapture readonly %1, ptr nocapture readonly %2, ptr nest nocapture readonly %3) local_unnamed_addr #4 {
  %5 = load ptr, ptr %3, align 8, !tbaa !4
  %6 = getelementptr { ptr, ptr }, ptr %3, i64 0, i32 1
  %7 = load ptr, ptr %6, align 8, !tbaa !4
  %8 = load i32, ptr %0, align 4, !tbaa !4
  %9 = sext i32 %8 to i64
  %10 = load i32, ptr %1, align 4, !tbaa !4
  %11 = sext i32 %10 to i64
  %12 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %2, i64 0, i32 7, i64 0, i64 2
  %13 = load i64, ptr %12, align 8, !tbaa !8
  %14 = icmp eq i64 %13, 8
  br i1 %14, label %15, label %59

15:                                               ; preds = %4
  %16 = load ptr, ptr %2, align 8, !tbaa !8
  %reass.sub9 = sub nsw i64 %11, %9
  %17 = icmp sgt i64 %reass.sub9, -1
  br i1 %17, label %.lr.ph8.preheader, label %.loopexit

.lr.ph8.preheader:                                ; preds = %15
  %18 = add nsw i64 %reass.sub9, 1
  %19 = add nsw i64 %11, 2
  %20 = icmp ne i64 %18, 0
  %umin24.neg = sext i1 %20 to i64
  %21 = add nsw i64 %19, %umin24.neg
  %22 = sub nsw i64 %21, %9
  %min.iters.check = icmp ult i64 %22, 8
  br i1 %min.iters.check, label %.lr.ph8.preheader28, label %vector.scevcheck

vector.scevcheck:                                 ; preds = %.lr.ph8.preheader
  %23 = add nsw i64 %11, 1
  %24 = icmp ne i64 %18, 0
  %umin.neg = sext i1 %24 to i64
  %25 = add nsw i64 %23, %umin.neg
  %26 = sub nsw i64 %25, %9
  %27 = trunc i64 %26 to i32
  %28 = add i32 %8, %27
  %29 = icmp slt i32 %28, %8
  %30 = icmp ugt i64 %26, 4294967295
  %31 = or i1 %29, %30
  br i1 %31, label %.lr.ph8.preheader28, label %vector.memcheck

vector.memcheck:                                  ; preds = %vector.scevcheck
  %scevgep = getelementptr i8, ptr %7, i64 8
  %scevgep13 = getelementptr i8, ptr %5, i64 4
  %32 = shl nsw i64 %9, 3
  %33 = add nsw i64 %32, -8
  %scevgep14 = getelementptr i8, ptr %16, i64 %33
  %34 = shl nsw i64 %11, 3
  %35 = add nsw i64 %34, 8
  %.not = icmp eq i64 %18, 0
  %36 = select i1 %.not, i64 %35, i64 %34
  %scevgep16 = getelementptr i8, ptr %16, i64 %36
  %bound0 = icmp ult ptr %7, %scevgep13
  %bound1 = icmp ult ptr %5, %scevgep
  %found.conflict = and i1 %bound0, %bound1
  %bound017 = icmp ult ptr %7, %scevgep16
  %bound118 = icmp ult ptr %scevgep14, %scevgep
  %found.conflict19 = and i1 %bound017, %bound118
  %conflict.rdx = or i1 %found.conflict, %found.conflict19
  %bound020 = icmp ult ptr %5, %scevgep16
  %bound121 = icmp ult ptr %scevgep14, %scevgep13
  %found.conflict22 = and i1 %bound020, %bound121
  %conflict.rdx23 = or i1 %conflict.rdx, %found.conflict22
  br i1 %conflict.rdx23, label %.lr.ph8.preheader28, label %vector.ph

vector.ph:                                        ; preds = %vector.memcheck
  %n.vec = and i64 %22, -2
  %ind.end = sub nsw i64 %18, %n.vec
  %.cast = trunc i64 %n.vec to i32
  %ind.end25 = add i32 %8, %.cast
  br label %vector.body

vector.body:                                      ; preds = %vector.body, %vector.ph
  %index = phi i64 [ 0, %vector.ph ], [ %index.next, %vector.body ]
  %.cast27 = trunc i64 %index to i32
  %offset.idx = add i32 %8, %.cast27
  %37 = load i32, ptr %5, align 4, !tbaa !4, !alias.scope !22, !noalias !25
  %broadcast.splatinsert = insertelement <2 x i32> poison, i32 %37, i64 0
  %38 = sitofp <2 x i32> %broadcast.splatinsert to <2 x float>
  %39 = fdiv contract <2 x float> <float 1.000000e+00, float poison>, %38
  %40 = shufflevector <2 x float> %39, <2 x float> poison, <2 x i32> zeroinitializer
  %41 = fpext <2 x float> %40 to <2 x double>
  %42 = sext i32 %offset.idx to i64
  %43 = add nsw i64 %42, -1
  %44 = getelementptr double, ptr %16, i64 %43
  store <2 x double> %41, ptr %44, align 8, !tbaa !4, !alias.scope !25
  %45 = extractelement <2 x double> %41, i64 1
  store double %45, ptr %7, align 8, !tbaa !4, !alias.scope !27, !noalias !29
  %index.next = add nuw i64 %index, 2
  %46 = icmp eq i64 %index.next, %n.vec
  br i1 %46, label %middle.block, label %vector.body, !llvm.loop !30

middle.block:                                     ; preds = %vector.body
  %cmp.n = icmp eq i64 %22, %n.vec
  br i1 %cmp.n, label %.loopexit, label %.lr.ph8.preheader28

.lr.ph8.preheader28:                              ; preds = %vector.memcheck, %vector.scevcheck, %.lr.ph8.preheader, %middle.block
  %.ph = phi i64 [ %18, %vector.memcheck ], [ %18, %vector.scevcheck ], [ %18, %.lr.ph8.preheader ], [ %ind.end, %middle.block ]
  %.ph29 = phi i32 [ %8, %vector.memcheck ], [ %8, %vector.scevcheck ], [ %8, %.lr.ph8.preheader ], [ %ind.end25, %middle.block ]
  br label %.lr.ph8

.lr.ph8:                                          ; preds = %.lr.ph8.preheader28, %.lr.ph8
  %47 = phi i64 [ %57, %.lr.ph8 ], [ %.ph, %.lr.ph8.preheader28 ]
  %48 = phi i32 [ %56, %.lr.ph8 ], [ %.ph29, %.lr.ph8.preheader28 ]
  %49 = load i32, ptr %5, align 4, !tbaa !4
  %50 = sitofp i32 %49 to float
  %51 = fdiv contract float 1.000000e+00, %50
  %52 = fpext float %51 to double
  %53 = sext i32 %48 to i64
  %54 = add nsw i64 %53, -1
  %55 = getelementptr double, ptr %16, i64 %54
  store double %52, ptr %55, align 8, !tbaa !4
  store double %52, ptr %7, align 8, !tbaa !4
  %56 = add i32 %48, 1
  %57 = add nsw i64 %47, -1
  %58 = icmp ugt i64 %47, 1
  br i1 %58, label %.lr.ph8, label %.loopexit.loopexit, !llvm.loop !31

59:                                               ; preds = %4
  %reass.sub = sub nsw i64 %11, %9
  %60 = icmp sgt i64 %reass.sub, -1
  br i1 %60, label %.lr.ph, label %.loopexit

.lr.ph:                                           ; preds = %59
  %61 = add nuw nsw i64 %reass.sub, 1
  %62 = load ptr, ptr %2, align 8, !tbaa !8
  br label %63

63:                                               ; preds = %.lr.ph, %63
  %64 = phi i64 [ %61, %.lr.ph ], [ %75, %63 ]
  %65 = phi i32 [ %8, %.lr.ph ], [ %74, %63 ]
  %66 = load i32, ptr %5, align 4, !tbaa !4
  %67 = sitofp i32 %66 to float
  %68 = fdiv contract float 1.000000e+00, %67
  %69 = fpext float %68 to double
  %70 = sext i32 %65 to i64
  %71 = add nsw i64 %70, -1
  %72 = mul i64 %71, %13
  %73 = getelementptr i8, ptr %62, i64 %72
  store double %69, ptr %73, align 8, !tbaa !4
  store double %69, ptr %7, align 8, !tbaa !4
  %74 = add i32 %65, 1
  %75 = add nsw i64 %64, -1
  %76 = icmp ugt i64 %64, 1
  br i1 %76, label %63, label %.loopexit.loopexit30

.loopexit.loopexit:                               ; preds = %.lr.ph8
  br label %.loopexit

.loopexit.loopexit30:                             ; preds = %63
  br label %.loopexit

.loopexit:                                        ; preds = %.loopexit.loopexit30, %.loopexit.loopexit, %middle.block, %59, %15
  ret void
}
*** IR Dump After SROAPass on _QFPloop ***
; Function Attrs: nofree norecurse nosync nounwind memory(readwrite, inaccessiblemem: none)
define void @_QFPloop(ptr nocapture readonly %0, ptr nocapture readonly %1, ptr nocapture readonly %2, ptr nest nocapture readonly %3) local_unnamed_addr #4 {
  %5 = load ptr, ptr %3, align 8, !tbaa !4
  %6 = getelementptr { ptr, ptr }, ptr %3, i64 0, i32 1
  %7 = load ptr, ptr %6, align 8, !tbaa !4
  %8 = load i32, ptr %0, align 4, !tbaa !4
  %9 = sext i32 %8 to i64
  %10 = load i32, ptr %1, align 4, !tbaa !4
  %11 = sext i32 %10 to i64
  %12 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %2, i64 0, i32 7, i64 0, i64 2
  %13 = load i64, ptr %12, align 8, !tbaa !8
  %14 = icmp eq i64 %13, 8
  br i1 %14, label %15, label %59

15:                                               ; preds = %4
  %16 = load ptr, ptr %2, align 8, !tbaa !8
  %reass.sub9 = sub nsw i64 %11, %9
  %17 = icmp sgt i64 %reass.sub9, -1
  br i1 %17, label %.lr.ph8.preheader, label %.loopexit

.lr.ph8.preheader:                                ; preds = %15
  %18 = add nsw i64 %reass.sub9, 1
  %19 = add nsw i64 %11, 2
  %20 = icmp ne i64 %18, 0
  %umin24.neg = sext i1 %20 to i64
  %21 = add nsw i64 %19, %umin24.neg
  %22 = sub nsw i64 %21, %9
  %min.iters.check = icmp ult i64 %22, 8
  br i1 %min.iters.check, label %.lr.ph8.preheader28, label %vector.scevcheck

vector.scevcheck:                                 ; preds = %.lr.ph8.preheader
  %23 = add nsw i64 %11, 1
  %24 = icmp ne i64 %18, 0
  %umin.neg = sext i1 %24 to i64
  %25 = add nsw i64 %23, %umin.neg
  %26 = sub nsw i64 %25, %9
  %27 = trunc i64 %26 to i32
  %28 = add i32 %8, %27
  %29 = icmp slt i32 %28, %8
  %30 = icmp ugt i64 %26, 4294967295
  %31 = or i1 %29, %30
  br i1 %31, label %.lr.ph8.preheader28, label %vector.memcheck

vector.memcheck:                                  ; preds = %vector.scevcheck
  %scevgep = getelementptr i8, ptr %7, i64 8
  %scevgep13 = getelementptr i8, ptr %5, i64 4
  %32 = shl nsw i64 %9, 3
  %33 = add nsw i64 %32, -8
  %scevgep14 = getelementptr i8, ptr %16, i64 %33
  %34 = shl nsw i64 %11, 3
  %35 = add nsw i64 %34, 8
  %.not = icmp eq i64 %18, 0
  %36 = select i1 %.not, i64 %35, i64 %34
  %scevgep16 = getelementptr i8, ptr %16, i64 %36
  %bound0 = icmp ult ptr %7, %scevgep13
  %bound1 = icmp ult ptr %5, %scevgep
  %found.conflict = and i1 %bound0, %bound1
  %bound017 = icmp ult ptr %7, %scevgep16
  %bound118 = icmp ult ptr %scevgep14, %scevgep
  %found.conflict19 = and i1 %bound017, %bound118
  %conflict.rdx = or i1 %found.conflict, %found.conflict19
  %bound020 = icmp ult ptr %5, %scevgep16
  %bound121 = icmp ult ptr %scevgep14, %scevgep13
  %found.conflict22 = and i1 %bound020, %bound121
  %conflict.rdx23 = or i1 %conflict.rdx, %found.conflict22
  br i1 %conflict.rdx23, label %.lr.ph8.preheader28, label %vector.ph

vector.ph:                                        ; preds = %vector.memcheck
  %n.vec = and i64 %22, -2
  %ind.end = sub nsw i64 %18, %n.vec
  %.cast = trunc i64 %n.vec to i32
  %ind.end25 = add i32 %8, %.cast
  br label %vector.body

vector.body:                                      ; preds = %vector.body, %vector.ph
  %index = phi i64 [ 0, %vector.ph ], [ %index.next, %vector.body ]
  %.cast27 = trunc i64 %index to i32
  %offset.idx = add i32 %8, %.cast27
  %37 = load i32, ptr %5, align 4, !tbaa !4, !alias.scope !22, !noalias !25
  %broadcast.splatinsert = insertelement <2 x i32> poison, i32 %37, i64 0
  %38 = sitofp <2 x i32> %broadcast.splatinsert to <2 x float>
  %39 = fdiv contract <2 x float> <float 1.000000e+00, float poison>, %38
  %40 = shufflevector <2 x float> %39, <2 x float> poison, <2 x i32> zeroinitializer
  %41 = fpext <2 x float> %40 to <2 x double>
  %42 = sext i32 %offset.idx to i64
  %43 = add nsw i64 %42, -1
  %44 = getelementptr double, ptr %16, i64 %43
  store <2 x double> %41, ptr %44, align 8, !tbaa !4, !alias.scope !25
  %45 = extractelement <2 x double> %41, i64 1
  store double %45, ptr %7, align 8, !tbaa !4, !alias.scope !27, !noalias !29
  %index.next = add nuw i64 %index, 2
  %46 = icmp eq i64 %index.next, %n.vec
  br i1 %46, label %middle.block, label %vector.body, !llvm.loop !30

middle.block:                                     ; preds = %vector.body
  %cmp.n = icmp eq i64 %22, %n.vec
  br i1 %cmp.n, label %.loopexit, label %.lr.ph8.preheader28

.lr.ph8.preheader28:                              ; preds = %vector.memcheck, %vector.scevcheck, %.lr.ph8.preheader, %middle.block
  %.ph = phi i64 [ %18, %vector.memcheck ], [ %18, %vector.scevcheck ], [ %18, %.lr.ph8.preheader ], [ %ind.end, %middle.block ]
  %.ph29 = phi i32 [ %8, %vector.memcheck ], [ %8, %vector.scevcheck ], [ %8, %.lr.ph8.preheader ], [ %ind.end25, %middle.block ]
  br label %.lr.ph8

.lr.ph8:                                          ; preds = %.lr.ph8.preheader28, %.lr.ph8
  %47 = phi i64 [ %57, %.lr.ph8 ], [ %.ph, %.lr.ph8.preheader28 ]
  %48 = phi i32 [ %56, %.lr.ph8 ], [ %.ph29, %.lr.ph8.preheader28 ]
  %49 = load i32, ptr %5, align 4, !tbaa !4
  %50 = sitofp i32 %49 to float
  %51 = fdiv contract float 1.000000e+00, %50
  %52 = fpext float %51 to double
  %53 = sext i32 %48 to i64
  %54 = add nsw i64 %53, -1
  %55 = getelementptr double, ptr %16, i64 %54
  store double %52, ptr %55, align 8, !tbaa !4
  store double %52, ptr %7, align 8, !tbaa !4
  %56 = add i32 %48, 1
  %57 = add nsw i64 %47, -1
  %58 = icmp ugt i64 %47, 1
  br i1 %58, label %.lr.ph8, label %.loopexit.loopexit, !llvm.loop !31

59:                                               ; preds = %4
  %reass.sub = sub nsw i64 %11, %9
  %60 = icmp sgt i64 %reass.sub, -1
  br i1 %60, label %.lr.ph, label %.loopexit

.lr.ph:                                           ; preds = %59
  %61 = add nuw nsw i64 %reass.sub, 1
  %62 = load ptr, ptr %2, align 8, !tbaa !8
  br label %63

63:                                               ; preds = %.lr.ph, %63
  %64 = phi i64 [ %61, %.lr.ph ], [ %75, %63 ]
  %65 = phi i32 [ %8, %.lr.ph ], [ %74, %63 ]
  %66 = load i32, ptr %5, align 4, !tbaa !4
  %67 = sitofp i32 %66 to float
  %68 = fdiv contract float 1.000000e+00, %67
  %69 = fpext float %68 to double
  %70 = sext i32 %65 to i64
  %71 = add nsw i64 %70, -1
  %72 = mul i64 %71, %13
  %73 = getelementptr i8, ptr %62, i64 %72
  store double %69, ptr %73, align 8, !tbaa !4
  store double %69, ptr %7, align 8, !tbaa !4
  %74 = add i32 %65, 1
  %75 = add nsw i64 %64, -1
  %76 = icmp ugt i64 %64, 1
  br i1 %76, label %63, label %.loopexit.loopexit30

.loopexit.loopexit:                               ; preds = %.lr.ph8
  br label %.loopexit

.loopexit.loopexit30:                             ; preds = %63
  br label %.loopexit

.loopexit:                                        ; preds = %.loopexit.loopexit30, %.loopexit.loopexit, %middle.block, %59, %15
  ret void
}
*** IR Dump After InstCombinePass on _QFPloop ***
; Function Attrs: nofree norecurse nosync nounwind memory(readwrite, inaccessiblemem: none)
define void @_QFPloop(ptr nocapture readonly %0, ptr nocapture readonly %1, ptr nocapture readonly %2, ptr nest nocapture readonly %3) local_unnamed_addr #4 {
  %5 = load ptr, ptr %3, align 8, !tbaa !4
  %6 = getelementptr { ptr, ptr }, ptr %3, i64 0, i32 1
  %7 = load ptr, ptr %6, align 8, !tbaa !4
  %8 = load i32, ptr %0, align 4, !tbaa !4
  %9 = sext i32 %8 to i64
  %10 = load i32, ptr %1, align 4, !tbaa !4
  %11 = sext i32 %10 to i64
  %12 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %2, i64 0, i32 7, i64 0, i64 2
  %13 = load i64, ptr %12, align 8, !tbaa !8
  %14 = icmp eq i64 %13, 8
  br i1 %14, label %15, label %59

15:                                               ; preds = %4
  %16 = load ptr, ptr %2, align 8, !tbaa !8
  %reass.sub9 = sub nsw i64 %11, %9
  %17 = icmp sgt i64 %reass.sub9, -1
  br i1 %17, label %.lr.ph8.preheader, label %.loopexit

.lr.ph8.preheader:                                ; preds = %15
  %18 = add nsw i64 %reass.sub9, 1
  %19 = add nsw i64 %11, 2
  %20 = icmp ne i64 %18, 0
  %umin24.neg = sext i1 %20 to i64
  %21 = add nsw i64 %19, %umin24.neg
  %22 = sub nsw i64 %21, %9
  %min.iters.check = icmp ult i64 %22, 8
  br i1 %min.iters.check, label %.lr.ph8.preheader28, label %vector.scevcheck

vector.scevcheck:                                 ; preds = %.lr.ph8.preheader
  %23 = add nsw i64 %11, 1
  %24 = icmp ne i64 %18, 0
  %umin.neg = sext i1 %24 to i64
  %25 = add nsw i64 %23, %umin.neg
  %26 = sub nsw i64 %25, %9
  %27 = trunc i64 %26 to i32
  %28 = add i32 %8, %27
  %29 = icmp slt i32 %28, %8
  %30 = icmp ugt i64 %26, 4294967295
  %31 = or i1 %29, %30
  br i1 %31, label %.lr.ph8.preheader28, label %vector.memcheck

vector.memcheck:                                  ; preds = %vector.scevcheck
  %scevgep = getelementptr i8, ptr %7, i64 8
  %scevgep13 = getelementptr i8, ptr %5, i64 4
  %32 = shl nsw i64 %9, 3
  %33 = add nsw i64 %32, -8
  %scevgep14 = getelementptr i8, ptr %16, i64 %33
  %34 = shl nsw i64 %11, 3
  %35 = add nsw i64 %34, 8
  %.not = icmp eq i64 %18, 0
  %36 = select i1 %.not, i64 %35, i64 %34
  %scevgep16 = getelementptr i8, ptr %16, i64 %36
  %bound0 = icmp ult ptr %7, %scevgep13
  %bound1 = icmp ult ptr %5, %scevgep
  %found.conflict = and i1 %bound0, %bound1
  %bound017 = icmp ult ptr %7, %scevgep16
  %bound118 = icmp ult ptr %scevgep14, %scevgep
  %found.conflict19 = and i1 %bound017, %bound118
  %conflict.rdx = or i1 %found.conflict, %found.conflict19
  %bound020 = icmp ult ptr %5, %scevgep16
  %bound121 = icmp ult ptr %scevgep14, %scevgep13
  %found.conflict22 = and i1 %bound020, %bound121
  %conflict.rdx23 = or i1 %conflict.rdx, %found.conflict22
  br i1 %conflict.rdx23, label %.lr.ph8.preheader28, label %vector.ph

vector.ph:                                        ; preds = %vector.memcheck
  %n.vec = and i64 %22, -2
  %ind.end = sub nsw i64 %18, %n.vec
  %.cast = trunc i64 %n.vec to i32
  %ind.end25 = add i32 %8, %.cast
  br label %vector.body

vector.body:                                      ; preds = %vector.body, %vector.ph
  %index = phi i64 [ 0, %vector.ph ], [ %index.next, %vector.body ]
  %.cast27 = trunc i64 %index to i32
  %offset.idx = add i32 %8, %.cast27
  %37 = load i32, ptr %5, align 4, !tbaa !4, !alias.scope !22, !noalias !25
  %broadcast.splatinsert = insertelement <2 x i32> poison, i32 %37, i64 0
  %38 = sitofp <2 x i32> %broadcast.splatinsert to <2 x float>
  %39 = fdiv contract <2 x float> <float 1.000000e+00, float poison>, %38
  %40 = shufflevector <2 x float> %39, <2 x float> poison, <2 x i32> zeroinitializer
  %41 = fpext <2 x float> %40 to <2 x double>
  %42 = sext i32 %offset.idx to i64
  %43 = add nsw i64 %42, -1
  %44 = getelementptr double, ptr %16, i64 %43
  store <2 x double> %41, ptr %44, align 8, !tbaa !4, !alias.scope !25
  %45 = extractelement <2 x double> %41, i64 1
  store double %45, ptr %7, align 8, !tbaa !4, !alias.scope !27, !noalias !29
  %index.next = add nuw i64 %index, 2
  %46 = icmp eq i64 %index.next, %n.vec
  br i1 %46, label %middle.block, label %vector.body, !llvm.loop !30

middle.block:                                     ; preds = %vector.body
  %cmp.n = icmp eq i64 %22, %n.vec
  br i1 %cmp.n, label %.loopexit, label %.lr.ph8.preheader28

.lr.ph8.preheader28:                              ; preds = %vector.memcheck, %vector.scevcheck, %.lr.ph8.preheader, %middle.block
  %.ph = phi i64 [ %18, %vector.memcheck ], [ %18, %vector.scevcheck ], [ %18, %.lr.ph8.preheader ], [ %ind.end, %middle.block ]
  %.ph29 = phi i32 [ %8, %vector.memcheck ], [ %8, %vector.scevcheck ], [ %8, %.lr.ph8.preheader ], [ %ind.end25, %middle.block ]
  br label %.lr.ph8

.lr.ph8:                                          ; preds = %.lr.ph8.preheader28, %.lr.ph8
  %47 = phi i64 [ %57, %.lr.ph8 ], [ %.ph, %.lr.ph8.preheader28 ]
  %48 = phi i32 [ %56, %.lr.ph8 ], [ %.ph29, %.lr.ph8.preheader28 ]
  %49 = load i32, ptr %5, align 4, !tbaa !4
  %50 = sitofp i32 %49 to float
  %51 = fdiv contract float 1.000000e+00, %50
  %52 = fpext float %51 to double
  %53 = sext i32 %48 to i64
  %54 = add nsw i64 %53, -1
  %55 = getelementptr double, ptr %16, i64 %54
  store double %52, ptr %55, align 8, !tbaa !4
  store double %52, ptr %7, align 8, !tbaa !4
  %56 = add i32 %48, 1
  %57 = add nsw i64 %47, -1
  %58 = icmp ugt i64 %47, 1
  br i1 %58, label %.lr.ph8, label %.loopexit.loopexit, !llvm.loop !31

59:                                               ; preds = %4
  %reass.sub = sub nsw i64 %11, %9
  %60 = icmp sgt i64 %reass.sub, -1
  br i1 %60, label %.lr.ph, label %.loopexit

.lr.ph:                                           ; preds = %59
  %61 = add nuw nsw i64 %reass.sub, 1
  %62 = load ptr, ptr %2, align 8, !tbaa !8
  br label %63

63:                                               ; preds = %.lr.ph, %63
  %64 = phi i64 [ %61, %.lr.ph ], [ %75, %63 ]
  %65 = phi i32 [ %8, %.lr.ph ], [ %74, %63 ]
  %66 = load i32, ptr %5, align 4, !tbaa !4
  %67 = sitofp i32 %66 to float
  %68 = fdiv contract float 1.000000e+00, %67
  %69 = fpext float %68 to double
  %70 = sext i32 %65 to i64
  %71 = add nsw i64 %70, -1
  %72 = mul i64 %71, %13
  %73 = getelementptr i8, ptr %62, i64 %72
  store double %69, ptr %73, align 8, !tbaa !4
  store double %69, ptr %7, align 8, !tbaa !4
  %74 = add i32 %65, 1
  %75 = add nsw i64 %64, -1
  %76 = icmp ugt i64 %64, 1
  br i1 %76, label %63, label %.loopexit.loopexit30

.loopexit.loopexit:                               ; preds = %.lr.ph8
  br label %.loopexit

.loopexit.loopexit30:                             ; preds = %63
  br label %.loopexit

.loopexit:                                        ; preds = %.loopexit.loopexit30, %.loopexit.loopexit, %middle.block, %59, %15
  ret void
}
*** IR Dump After LoopSimplifyPass on _QFPloop ***
; Function Attrs: nofree norecurse nosync nounwind memory(readwrite, inaccessiblemem: none)
define void @_QFPloop(ptr nocapture readonly %0, ptr nocapture readonly %1, ptr nocapture readonly %2, ptr nest nocapture readonly %3) local_unnamed_addr #4 {
  %5 = load ptr, ptr %3, align 8, !tbaa !4
  %6 = getelementptr { ptr, ptr }, ptr %3, i64 0, i32 1
  %7 = load ptr, ptr %6, align 8, !tbaa !4
  %8 = load i32, ptr %0, align 4, !tbaa !4
  %9 = sext i32 %8 to i64
  %10 = load i32, ptr %1, align 4, !tbaa !4
  %11 = sext i32 %10 to i64
  %12 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %2, i64 0, i32 7, i64 0, i64 2
  %13 = load i64, ptr %12, align 8, !tbaa !8
  %14 = icmp eq i64 %13, 8
  br i1 %14, label %15, label %59

15:                                               ; preds = %4
  %16 = load ptr, ptr %2, align 8, !tbaa !8
  %reass.sub9 = sub nsw i64 %11, %9
  %17 = icmp sgt i64 %reass.sub9, -1
  br i1 %17, label %.lr.ph8.preheader, label %.loopexit

.lr.ph8.preheader:                                ; preds = %15
  %18 = add nsw i64 %reass.sub9, 1
  %19 = add nsw i64 %11, 2
  %20 = icmp ne i64 %18, 0
  %umin24.neg = sext i1 %20 to i64
  %21 = add nsw i64 %19, %umin24.neg
  %22 = sub nsw i64 %21, %9
  %min.iters.check = icmp ult i64 %22, 8
  br i1 %min.iters.check, label %.lr.ph8.preheader28, label %vector.scevcheck

vector.scevcheck:                                 ; preds = %.lr.ph8.preheader
  %23 = add nsw i64 %11, 1
  %24 = icmp ne i64 %18, 0
  %umin.neg = sext i1 %24 to i64
  %25 = add nsw i64 %23, %umin.neg
  %26 = sub nsw i64 %25, %9
  %27 = trunc i64 %26 to i32
  %28 = add i32 %8, %27
  %29 = icmp slt i32 %28, %8
  %30 = icmp ugt i64 %26, 4294967295
  %31 = or i1 %29, %30
  br i1 %31, label %.lr.ph8.preheader28, label %vector.memcheck

vector.memcheck:                                  ; preds = %vector.scevcheck
  %scevgep = getelementptr i8, ptr %7, i64 8
  %scevgep13 = getelementptr i8, ptr %5, i64 4
  %32 = shl nsw i64 %9, 3
  %33 = add nsw i64 %32, -8
  %scevgep14 = getelementptr i8, ptr %16, i64 %33
  %34 = shl nsw i64 %11, 3
  %35 = add nsw i64 %34, 8
  %.not = icmp eq i64 %18, 0
  %36 = select i1 %.not, i64 %35, i64 %34
  %scevgep16 = getelementptr i8, ptr %16, i64 %36
  %bound0 = icmp ult ptr %7, %scevgep13
  %bound1 = icmp ult ptr %5, %scevgep
  %found.conflict = and i1 %bound0, %bound1
  %bound017 = icmp ult ptr %7, %scevgep16
  %bound118 = icmp ult ptr %scevgep14, %scevgep
  %found.conflict19 = and i1 %bound017, %bound118
  %conflict.rdx = or i1 %found.conflict, %found.conflict19
  %bound020 = icmp ult ptr %5, %scevgep16
  %bound121 = icmp ult ptr %scevgep14, %scevgep13
  %found.conflict22 = and i1 %bound020, %bound121
  %conflict.rdx23 = or i1 %conflict.rdx, %found.conflict22
  br i1 %conflict.rdx23, label %.lr.ph8.preheader28, label %vector.ph

vector.ph:                                        ; preds = %vector.memcheck
  %n.vec = and i64 %22, -2
  %ind.end = sub nsw i64 %18, %n.vec
  %.cast = trunc i64 %n.vec to i32
  %ind.end25 = add i32 %8, %.cast
  br label %vector.body

vector.body:                                      ; preds = %vector.body, %vector.ph
  %index = phi i64 [ 0, %vector.ph ], [ %index.next, %vector.body ]
  %.cast27 = trunc i64 %index to i32
  %offset.idx = add i32 %8, %.cast27
  %37 = load i32, ptr %5, align 4, !tbaa !4, !alias.scope !22, !noalias !25
  %broadcast.splatinsert = insertelement <2 x i32> poison, i32 %37, i64 0
  %38 = sitofp <2 x i32> %broadcast.splatinsert to <2 x float>
  %39 = fdiv contract <2 x float> <float 1.000000e+00, float poison>, %38
  %40 = shufflevector <2 x float> %39, <2 x float> poison, <2 x i32> zeroinitializer
  %41 = fpext <2 x float> %40 to <2 x double>
  %42 = sext i32 %offset.idx to i64
  %43 = add nsw i64 %42, -1
  %44 = getelementptr double, ptr %16, i64 %43
  store <2 x double> %41, ptr %44, align 8, !tbaa !4, !alias.scope !25
  %45 = extractelement <2 x double> %41, i64 1
  store double %45, ptr %7, align 8, !tbaa !4, !alias.scope !27, !noalias !29
  %index.next = add nuw i64 %index, 2
  %46 = icmp eq i64 %index.next, %n.vec
  br i1 %46, label %middle.block, label %vector.body, !llvm.loop !30

middle.block:                                     ; preds = %vector.body
  %cmp.n = icmp eq i64 %22, %n.vec
  br i1 %cmp.n, label %.loopexit, label %.lr.ph8.preheader28

.lr.ph8.preheader28:                              ; preds = %vector.memcheck, %vector.scevcheck, %.lr.ph8.preheader, %middle.block
  %.ph = phi i64 [ %18, %vector.memcheck ], [ %18, %vector.scevcheck ], [ %18, %.lr.ph8.preheader ], [ %ind.end, %middle.block ]
  %.ph29 = phi i32 [ %8, %vector.memcheck ], [ %8, %vector.scevcheck ], [ %8, %.lr.ph8.preheader ], [ %ind.end25, %middle.block ]
  br label %.lr.ph8

.lr.ph8:                                          ; preds = %.lr.ph8.preheader28, %.lr.ph8
  %47 = phi i64 [ %57, %.lr.ph8 ], [ %.ph, %.lr.ph8.preheader28 ]
  %48 = phi i32 [ %56, %.lr.ph8 ], [ %.ph29, %.lr.ph8.preheader28 ]
  %49 = load i32, ptr %5, align 4, !tbaa !4
  %50 = sitofp i32 %49 to float
  %51 = fdiv contract float 1.000000e+00, %50
  %52 = fpext float %51 to double
  %53 = sext i32 %48 to i64
  %54 = add nsw i64 %53, -1
  %55 = getelementptr double, ptr %16, i64 %54
  store double %52, ptr %55, align 8, !tbaa !4
  store double %52, ptr %7, align 8, !tbaa !4
  %56 = add i32 %48, 1
  %57 = add nsw i64 %47, -1
  %58 = icmp ugt i64 %47, 1
  br i1 %58, label %.lr.ph8, label %.loopexit.loopexit, !llvm.loop !31

59:                                               ; preds = %4
  %reass.sub = sub nsw i64 %11, %9
  %60 = icmp sgt i64 %reass.sub, -1
  br i1 %60, label %.lr.ph, label %.loopexit

.lr.ph:                                           ; preds = %59
  %61 = add nuw nsw i64 %reass.sub, 1
  %62 = load ptr, ptr %2, align 8, !tbaa !8
  br label %63

63:                                               ; preds = %.lr.ph, %63
  %64 = phi i64 [ %61, %.lr.ph ], [ %75, %63 ]
  %65 = phi i32 [ %8, %.lr.ph ], [ %74, %63 ]
  %66 = load i32, ptr %5, align 4, !tbaa !4
  %67 = sitofp i32 %66 to float
  %68 = fdiv contract float 1.000000e+00, %67
  %69 = fpext float %68 to double
  %70 = sext i32 %65 to i64
  %71 = add nsw i64 %70, -1
  %72 = mul i64 %71, %13
  %73 = getelementptr i8, ptr %62, i64 %72
  store double %69, ptr %73, align 8, !tbaa !4
  store double %69, ptr %7, align 8, !tbaa !4
  %74 = add i32 %65, 1
  %75 = add nsw i64 %64, -1
  %76 = icmp ugt i64 %64, 1
  br i1 %76, label %63, label %.loopexit.loopexit30

.loopexit.loopexit:                               ; preds = %.lr.ph8
  br label %.loopexit

.loopexit.loopexit30:                             ; preds = %63
  br label %.loopexit

.loopexit:                                        ; preds = %.loopexit.loopexit30, %.loopexit.loopexit, %middle.block, %59, %15
  ret void
}
*** IR Dump After LCSSAPass on _QFPloop ***
; Function Attrs: nofree norecurse nosync nounwind memory(readwrite, inaccessiblemem: none)
define void @_QFPloop(ptr nocapture readonly %0, ptr nocapture readonly %1, ptr nocapture readonly %2, ptr nest nocapture readonly %3) local_unnamed_addr #4 {
  %5 = load ptr, ptr %3, align 8, !tbaa !4
  %6 = getelementptr { ptr, ptr }, ptr %3, i64 0, i32 1
  %7 = load ptr, ptr %6, align 8, !tbaa !4
  %8 = load i32, ptr %0, align 4, !tbaa !4
  %9 = sext i32 %8 to i64
  %10 = load i32, ptr %1, align 4, !tbaa !4
  %11 = sext i32 %10 to i64
  %12 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %2, i64 0, i32 7, i64 0, i64 2
  %13 = load i64, ptr %12, align 8, !tbaa !8
  %14 = icmp eq i64 %13, 8
  br i1 %14, label %15, label %59

15:                                               ; preds = %4
  %16 = load ptr, ptr %2, align 8, !tbaa !8
  %reass.sub9 = sub nsw i64 %11, %9
  %17 = icmp sgt i64 %reass.sub9, -1
  br i1 %17, label %.lr.ph8.preheader, label %.loopexit

.lr.ph8.preheader:                                ; preds = %15
  %18 = add nsw i64 %reass.sub9, 1
  %19 = add nsw i64 %11, 2
  %20 = icmp ne i64 %18, 0
  %umin24.neg = sext i1 %20 to i64
  %21 = add nsw i64 %19, %umin24.neg
  %22 = sub nsw i64 %21, %9
  %min.iters.check = icmp ult i64 %22, 8
  br i1 %min.iters.check, label %.lr.ph8.preheader28, label %vector.scevcheck

vector.scevcheck:                                 ; preds = %.lr.ph8.preheader
  %23 = add nsw i64 %11, 1
  %24 = icmp ne i64 %18, 0
  %umin.neg = sext i1 %24 to i64
  %25 = add nsw i64 %23, %umin.neg
  %26 = sub nsw i64 %25, %9
  %27 = trunc i64 %26 to i32
  %28 = add i32 %8, %27
  %29 = icmp slt i32 %28, %8
  %30 = icmp ugt i64 %26, 4294967295
  %31 = or i1 %29, %30
  br i1 %31, label %.lr.ph8.preheader28, label %vector.memcheck

vector.memcheck:                                  ; preds = %vector.scevcheck
  %scevgep = getelementptr i8, ptr %7, i64 8
  %scevgep13 = getelementptr i8, ptr %5, i64 4
  %32 = shl nsw i64 %9, 3
  %33 = add nsw i64 %32, -8
  %scevgep14 = getelementptr i8, ptr %16, i64 %33
  %34 = shl nsw i64 %11, 3
  %35 = add nsw i64 %34, 8
  %.not = icmp eq i64 %18, 0
  %36 = select i1 %.not, i64 %35, i64 %34
  %scevgep16 = getelementptr i8, ptr %16, i64 %36
  %bound0 = icmp ult ptr %7, %scevgep13
  %bound1 = icmp ult ptr %5, %scevgep
  %found.conflict = and i1 %bound0, %bound1
  %bound017 = icmp ult ptr %7, %scevgep16
  %bound118 = icmp ult ptr %scevgep14, %scevgep
  %found.conflict19 = and i1 %bound017, %bound118
  %conflict.rdx = or i1 %found.conflict, %found.conflict19
  %bound020 = icmp ult ptr %5, %scevgep16
  %bound121 = icmp ult ptr %scevgep14, %scevgep13
  %found.conflict22 = and i1 %bound020, %bound121
  %conflict.rdx23 = or i1 %conflict.rdx, %found.conflict22
  br i1 %conflict.rdx23, label %.lr.ph8.preheader28, label %vector.ph

vector.ph:                                        ; preds = %vector.memcheck
  %n.vec = and i64 %22, -2
  %ind.end = sub nsw i64 %18, %n.vec
  %.cast = trunc i64 %n.vec to i32
  %ind.end25 = add i32 %8, %.cast
  br label %vector.body

vector.body:                                      ; preds = %vector.body, %vector.ph
  %index = phi i64 [ 0, %vector.ph ], [ %index.next, %vector.body ]
  %.cast27 = trunc i64 %index to i32
  %offset.idx = add i32 %8, %.cast27
  %37 = load i32, ptr %5, align 4, !tbaa !4, !alias.scope !22, !noalias !25
  %broadcast.splatinsert = insertelement <2 x i32> poison, i32 %37, i64 0
  %38 = sitofp <2 x i32> %broadcast.splatinsert to <2 x float>
  %39 = fdiv contract <2 x float> <float 1.000000e+00, float poison>, %38
  %40 = shufflevector <2 x float> %39, <2 x float> poison, <2 x i32> zeroinitializer
  %41 = fpext <2 x float> %40 to <2 x double>
  %42 = sext i32 %offset.idx to i64
  %43 = add nsw i64 %42, -1
  %44 = getelementptr double, ptr %16, i64 %43
  store <2 x double> %41, ptr %44, align 8, !tbaa !4, !alias.scope !25
  %45 = extractelement <2 x double> %41, i64 1
  store double %45, ptr %7, align 8, !tbaa !4, !alias.scope !27, !noalias !29
  %index.next = add nuw i64 %index, 2
  %46 = icmp eq i64 %index.next, %n.vec
  br i1 %46, label %middle.block, label %vector.body, !llvm.loop !30

middle.block:                                     ; preds = %vector.body
  %cmp.n = icmp eq i64 %22, %n.vec
  br i1 %cmp.n, label %.loopexit, label %.lr.ph8.preheader28

.lr.ph8.preheader28:                              ; preds = %vector.memcheck, %vector.scevcheck, %.lr.ph8.preheader, %middle.block
  %.ph = phi i64 [ %18, %vector.memcheck ], [ %18, %vector.scevcheck ], [ %18, %.lr.ph8.preheader ], [ %ind.end, %middle.block ]
  %.ph29 = phi i32 [ %8, %vector.memcheck ], [ %8, %vector.scevcheck ], [ %8, %.lr.ph8.preheader ], [ %ind.end25, %middle.block ]
  br label %.lr.ph8

.lr.ph8:                                          ; preds = %.lr.ph8.preheader28, %.lr.ph8
  %47 = phi i64 [ %57, %.lr.ph8 ], [ %.ph, %.lr.ph8.preheader28 ]
  %48 = phi i32 [ %56, %.lr.ph8 ], [ %.ph29, %.lr.ph8.preheader28 ]
  %49 = load i32, ptr %5, align 4, !tbaa !4
  %50 = sitofp i32 %49 to float
  %51 = fdiv contract float 1.000000e+00, %50
  %52 = fpext float %51 to double
  %53 = sext i32 %48 to i64
  %54 = add nsw i64 %53, -1
  %55 = getelementptr double, ptr %16, i64 %54
  store double %52, ptr %55, align 8, !tbaa !4
  store double %52, ptr %7, align 8, !tbaa !4
  %56 = add i32 %48, 1
  %57 = add nsw i64 %47, -1
  %58 = icmp ugt i64 %47, 1
  br i1 %58, label %.lr.ph8, label %.loopexit.loopexit, !llvm.loop !31

59:                                               ; preds = %4
  %reass.sub = sub nsw i64 %11, %9
  %60 = icmp sgt i64 %reass.sub, -1
  br i1 %60, label %.lr.ph, label %.loopexit

.lr.ph:                                           ; preds = %59
  %61 = add nuw nsw i64 %reass.sub, 1
  %62 = load ptr, ptr %2, align 8, !tbaa !8
  br label %63

63:                                               ; preds = %.lr.ph, %63
  %64 = phi i64 [ %61, %.lr.ph ], [ %75, %63 ]
  %65 = phi i32 [ %8, %.lr.ph ], [ %74, %63 ]
  %66 = load i32, ptr %5, align 4, !tbaa !4
  %67 = sitofp i32 %66 to float
  %68 = fdiv contract float 1.000000e+00, %67
  %69 = fpext float %68 to double
  %70 = sext i32 %65 to i64
  %71 = add nsw i64 %70, -1
  %72 = mul i64 %71, %13
  %73 = getelementptr i8, ptr %62, i64 %72
  store double %69, ptr %73, align 8, !tbaa !4
  store double %69, ptr %7, align 8, !tbaa !4
  %74 = add i32 %65, 1
  %75 = add nsw i64 %64, -1
  %76 = icmp ugt i64 %64, 1
  br i1 %76, label %63, label %.loopexit.loopexit30

.loopexit.loopexit:                               ; preds = %.lr.ph8
  br label %.loopexit

.loopexit.loopexit30:                             ; preds = %63
  br label %.loopexit

.loopexit:                                        ; preds = %.loopexit.loopexit30, %.loopexit.loopexit, %middle.block, %59, %15
  ret void
}
*** IR Dump After LICMPass on <unnamed loop> ***

; Preheader:
.lr.ph:                                           ; preds = %59
  %61 = add nuw nsw i64 %reass.sub, 1
  %62 = load ptr, ptr %2, align 8, !tbaa !8
  br label %63

; Loop:
63:                                               ; preds = %.lr.ph, %63
  %64 = phi i64 [ %61, %.lr.ph ], [ %75, %63 ]
  %65 = phi i32 [ %8, %.lr.ph ], [ %74, %63 ]
  %66 = load i32, ptr %5, align 4, !tbaa !4
  %67 = sitofp i32 %66 to float
  %68 = fdiv contract float 1.000000e+00, %67
  %69 = fpext float %68 to double
  %70 = sext i32 %65 to i64
  %71 = add nsw i64 %70, -1
  %72 = mul i64 %71, %13
  %73 = getelementptr i8, ptr %62, i64 %72
  store double %69, ptr %73, align 8, !tbaa !4
  store double %69, ptr %7, align 8, !tbaa !4
  %74 = add i32 %65, 1
  %75 = add nsw i64 %64, -1
  %76 = icmp ugt i64 %64, 1
  br i1 %76, label %63, label %.loopexit.loopexit30

; Exit blocks
.loopexit.loopexit30:                             ; preds = %63
  br label %.loopexit
*** IR Dump After LICMPass on vector.body ***

; Preheader:
vector.ph:                                        ; preds = %vector.memcheck
  %n.vec = and i64 %22, -2
  %ind.end = sub nsw i64 %18, %n.vec
  %.cast = trunc i64 %n.vec to i32
  %ind.end25 = add i32 %8, %.cast
  %37 = load i32, ptr %5, align 4, !tbaa !4, !alias.scope !10, !noalias !13
  %broadcast.splatinsert = insertelement <2 x i32> poison, i32 %37, i64 0
  %38 = sitofp <2 x i32> %broadcast.splatinsert to <2 x float>
  %39 = fdiv contract <2 x float> <float 1.000000e+00, float poison>, %38
  %40 = shufflevector <2 x float> %39, <2 x float> poison, <2 x i32> zeroinitializer
  %41 = fpext <2 x float> %40 to <2 x double>
  %42 = extractelement <2 x double> %41, i64 1
  store double %42, ptr %7, align 8, !tbaa !4, !alias.scope !15, !noalias !17
  br label %vector.body

; Loop:
vector.body:                                      ; preds = %vector.body, %vector.ph
  %index = phi i64 [ 0, %vector.ph ], [ %index.next, %vector.body ]
  %.cast27 = trunc i64 %index to i32
  %offset.idx = add i32 %8, %.cast27
  %43 = sext i32 %offset.idx to i64
  %44 = add nsw i64 %43, -1
  %45 = getelementptr double, ptr %16, i64 %44
  store <2 x double> %41, ptr %45, align 8, !tbaa !4, !alias.scope !13
  %index.next = add nuw i64 %index, 2
  %46 = icmp eq i64 %index.next, %n.vec
  br i1 %46, label %middle.block, label %vector.body, !llvm.loop !18

; Exit blocks
middle.block:                                     ; preds = %vector.body
  %cmp.n = icmp eq i64 %22, %n.vec
  br i1 %cmp.n, label %.loopexit, label %.lr.ph8.preheader28
*** IR Dump After LICMPass on .lr.ph8 ***

; Preheader:
.lr.ph8.preheader28:                              ; preds = %vector.memcheck, %vector.scevcheck, %.lr.ph8.preheader, %middle.block
  %.ph = phi i64 [ %18, %vector.memcheck ], [ %18, %vector.scevcheck ], [ %18, %.lr.ph8.preheader ], [ %ind.end, %middle.block ]
  %.ph29 = phi i32 [ %8, %vector.memcheck ], [ %8, %vector.scevcheck ], [ %8, %.lr.ph8.preheader ], [ %ind.end25, %middle.block ]
  br label %.lr.ph8

; Loop:
.lr.ph8:                                          ; preds = %.lr.ph8.preheader28, %.lr.ph8
  %47 = phi i64 [ %57, %.lr.ph8 ], [ %.ph, %.lr.ph8.preheader28 ]
  %48 = phi i32 [ %56, %.lr.ph8 ], [ %.ph29, %.lr.ph8.preheader28 ]
  %49 = load i32, ptr %5, align 4, !tbaa !4
  %50 = sitofp i32 %49 to float
  %51 = fdiv contract float 1.000000e+00, %50
  %52 = fpext float %51 to double
  %53 = sext i32 %48 to i64
  %54 = add nsw i64 %53, -1
  %55 = getelementptr double, ptr %16, i64 %54
  store double %52, ptr %55, align 8, !tbaa !4
  store double %52, ptr %7, align 8, !tbaa !4
  %56 = add i32 %48, 1
  %57 = add nsw i64 %47, -1
  %58 = icmp ugt i64 %47, 1
  br i1 %58, label %.lr.ph8, label %.loopexit.loopexit, !llvm.loop !21

; Exit blocks
.loopexit.loopexit:                               ; preds = %.lr.ph8
  br label %.loopexit
*** IR Dump After AlignmentFromAssumptionsPass on _QFPloop ***
; Function Attrs: nofree norecurse nosync nounwind memory(readwrite, inaccessiblemem: none)
define void @_QFPloop(ptr nocapture readonly %0, ptr nocapture readonly %1, ptr nocapture readonly %2, ptr nest nocapture readonly %3) local_unnamed_addr #4 {
  %5 = load ptr, ptr %3, align 8, !tbaa !4
  %6 = getelementptr { ptr, ptr }, ptr %3, i64 0, i32 1
  %7 = load ptr, ptr %6, align 8, !tbaa !4
  %8 = load i32, ptr %0, align 4, !tbaa !4
  %9 = sext i32 %8 to i64
  %10 = load i32, ptr %1, align 4, !tbaa !4
  %11 = sext i32 %10 to i64
  %12 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %2, i64 0, i32 7, i64 0, i64 2
  %13 = load i64, ptr %12, align 8, !tbaa !8
  %14 = icmp eq i64 %13, 8
  br i1 %14, label %15, label %59

15:                                               ; preds = %4
  %16 = load ptr, ptr %2, align 8, !tbaa !8
  %reass.sub9 = sub nsw i64 %11, %9
  %17 = icmp sgt i64 %reass.sub9, -1
  br i1 %17, label %.lr.ph8.preheader, label %.loopexit

.lr.ph8.preheader:                                ; preds = %15
  %18 = add nsw i64 %reass.sub9, 1
  %19 = add nsw i64 %11, 2
  %20 = icmp ne i64 %18, 0
  %umin24.neg = sext i1 %20 to i64
  %21 = add nsw i64 %19, %umin24.neg
  %22 = sub nsw i64 %21, %9
  %min.iters.check = icmp ult i64 %22, 8
  br i1 %min.iters.check, label %.lr.ph8.preheader28, label %vector.scevcheck

vector.scevcheck:                                 ; preds = %.lr.ph8.preheader
  %23 = add nsw i64 %11, 1
  %24 = icmp ne i64 %18, 0
  %umin.neg = sext i1 %24 to i64
  %25 = add nsw i64 %23, %umin.neg
  %26 = sub nsw i64 %25, %9
  %27 = trunc i64 %26 to i32
  %28 = add i32 %8, %27
  %29 = icmp slt i32 %28, %8
  %30 = icmp ugt i64 %26, 4294967295
  %31 = or i1 %29, %30
  br i1 %31, label %.lr.ph8.preheader28, label %vector.memcheck

vector.memcheck:                                  ; preds = %vector.scevcheck
  %scevgep = getelementptr i8, ptr %7, i64 8
  %scevgep13 = getelementptr i8, ptr %5, i64 4
  %32 = shl nsw i64 %9, 3
  %33 = add nsw i64 %32, -8
  %scevgep14 = getelementptr i8, ptr %16, i64 %33
  %34 = shl nsw i64 %11, 3
  %35 = add nsw i64 %34, 8
  %.not = icmp eq i64 %18, 0
  %36 = select i1 %.not, i64 %35, i64 %34
  %scevgep16 = getelementptr i8, ptr %16, i64 %36
  %bound0 = icmp ult ptr %7, %scevgep13
  %bound1 = icmp ult ptr %5, %scevgep
  %found.conflict = and i1 %bound0, %bound1
  %bound017 = icmp ult ptr %7, %scevgep16
  %bound118 = icmp ult ptr %scevgep14, %scevgep
  %found.conflict19 = and i1 %bound017, %bound118
  %conflict.rdx = or i1 %found.conflict, %found.conflict19
  %bound020 = icmp ult ptr %5, %scevgep16
  %bound121 = icmp ult ptr %scevgep14, %scevgep13
  %found.conflict22 = and i1 %bound020, %bound121
  %conflict.rdx23 = or i1 %conflict.rdx, %found.conflict22
  br i1 %conflict.rdx23, label %.lr.ph8.preheader28, label %vector.ph

vector.ph:                                        ; preds = %vector.memcheck
  %n.vec = and i64 %22, -2
  %ind.end = sub nsw i64 %18, %n.vec
  %.cast = trunc i64 %n.vec to i32
  %ind.end25 = add i32 %8, %.cast
  %37 = load i32, ptr %5, align 4, !tbaa !4, !alias.scope !22, !noalias !25
  %broadcast.splatinsert = insertelement <2 x i32> poison, i32 %37, i64 0
  %38 = sitofp <2 x i32> %broadcast.splatinsert to <2 x float>
  %39 = fdiv contract <2 x float> <float 1.000000e+00, float poison>, %38
  %40 = shufflevector <2 x float> %39, <2 x float> poison, <2 x i32> zeroinitializer
  %41 = fpext <2 x float> %40 to <2 x double>
  %42 = extractelement <2 x double> %41, i64 1
  store double %42, ptr %7, align 8, !tbaa !4, !alias.scope !27, !noalias !29
  br label %vector.body

vector.body:                                      ; preds = %vector.body, %vector.ph
  %index = phi i64 [ 0, %vector.ph ], [ %index.next, %vector.body ]
  %.cast27 = trunc i64 %index to i32
  %offset.idx = add i32 %8, %.cast27
  %43 = sext i32 %offset.idx to i64
  %44 = add nsw i64 %43, -1
  %45 = getelementptr double, ptr %16, i64 %44
  store <2 x double> %41, ptr %45, align 8, !tbaa !4, !alias.scope !25
  %index.next = add nuw i64 %index, 2
  %46 = icmp eq i64 %index.next, %n.vec
  br i1 %46, label %middle.block, label %vector.body, !llvm.loop !30

middle.block:                                     ; preds = %vector.body
  %cmp.n = icmp eq i64 %22, %n.vec
  br i1 %cmp.n, label %.loopexit, label %.lr.ph8.preheader28

.lr.ph8.preheader28:                              ; preds = %vector.memcheck, %vector.scevcheck, %.lr.ph8.preheader, %middle.block
  %.ph = phi i64 [ %18, %vector.memcheck ], [ %18, %vector.scevcheck ], [ %18, %.lr.ph8.preheader ], [ %ind.end, %middle.block ]
  %.ph29 = phi i32 [ %8, %vector.memcheck ], [ %8, %vector.scevcheck ], [ %8, %.lr.ph8.preheader ], [ %ind.end25, %middle.block ]
  br label %.lr.ph8

.lr.ph8:                                          ; preds = %.lr.ph8.preheader28, %.lr.ph8
  %47 = phi i64 [ %57, %.lr.ph8 ], [ %.ph, %.lr.ph8.preheader28 ]
  %48 = phi i32 [ %56, %.lr.ph8 ], [ %.ph29, %.lr.ph8.preheader28 ]
  %49 = load i32, ptr %5, align 4, !tbaa !4
  %50 = sitofp i32 %49 to float
  %51 = fdiv contract float 1.000000e+00, %50
  %52 = fpext float %51 to double
  %53 = sext i32 %48 to i64
  %54 = add nsw i64 %53, -1
  %55 = getelementptr double, ptr %16, i64 %54
  store double %52, ptr %55, align 8, !tbaa !4
  store double %52, ptr %7, align 8, !tbaa !4
  %56 = add i32 %48, 1
  %57 = add nsw i64 %47, -1
  %58 = icmp ugt i64 %47, 1
  br i1 %58, label %.lr.ph8, label %.loopexit.loopexit, !llvm.loop !31

59:                                               ; preds = %4
  %reass.sub = sub nsw i64 %11, %9
  %60 = icmp sgt i64 %reass.sub, -1
  br i1 %60, label %.lr.ph, label %.loopexit

.lr.ph:                                           ; preds = %59
  %61 = add nuw nsw i64 %reass.sub, 1
  %62 = load ptr, ptr %2, align 8, !tbaa !8
  br label %63

63:                                               ; preds = %.lr.ph, %63
  %64 = phi i64 [ %61, %.lr.ph ], [ %75, %63 ]
  %65 = phi i32 [ %8, %.lr.ph ], [ %74, %63 ]
  %66 = load i32, ptr %5, align 4, !tbaa !4
  %67 = sitofp i32 %66 to float
  %68 = fdiv contract float 1.000000e+00, %67
  %69 = fpext float %68 to double
  %70 = sext i32 %65 to i64
  %71 = add nsw i64 %70, -1
  %72 = mul i64 %71, %13
  %73 = getelementptr i8, ptr %62, i64 %72
  store double %69, ptr %73, align 8, !tbaa !4
  store double %69, ptr %7, align 8, !tbaa !4
  %74 = add i32 %65, 1
  %75 = add nsw i64 %64, -1
  %76 = icmp ugt i64 %64, 1
  br i1 %76, label %63, label %.loopexit.loopexit30

.loopexit.loopexit:                               ; preds = %.lr.ph8
  br label %.loopexit

.loopexit.loopexit30:                             ; preds = %63
  br label %.loopexit

.loopexit:                                        ; preds = %.loopexit.loopexit30, %.loopexit.loopexit, %middle.block, %59, %15
  ret void
}
*** IR Dump After LoopSinkPass on _QFPloop ***
; Function Attrs: nofree norecurse nosync nounwind memory(readwrite, inaccessiblemem: none)
define void @_QFPloop(ptr nocapture readonly %0, ptr nocapture readonly %1, ptr nocapture readonly %2, ptr nest nocapture readonly %3) local_unnamed_addr #4 {
  %5 = load ptr, ptr %3, align 8, !tbaa !4
  %6 = getelementptr { ptr, ptr }, ptr %3, i64 0, i32 1
  %7 = load ptr, ptr %6, align 8, !tbaa !4
  %8 = load i32, ptr %0, align 4, !tbaa !4
  %9 = sext i32 %8 to i64
  %10 = load i32, ptr %1, align 4, !tbaa !4
  %11 = sext i32 %10 to i64
  %12 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %2, i64 0, i32 7, i64 0, i64 2
  %13 = load i64, ptr %12, align 8, !tbaa !8
  %14 = icmp eq i64 %13, 8
  br i1 %14, label %15, label %59

15:                                               ; preds = %4
  %16 = load ptr, ptr %2, align 8, !tbaa !8
  %reass.sub9 = sub nsw i64 %11, %9
  %17 = icmp sgt i64 %reass.sub9, -1
  br i1 %17, label %.lr.ph8.preheader, label %.loopexit

.lr.ph8.preheader:                                ; preds = %15
  %18 = add nsw i64 %reass.sub9, 1
  %19 = add nsw i64 %11, 2
  %20 = icmp ne i64 %18, 0
  %umin24.neg = sext i1 %20 to i64
  %21 = add nsw i64 %19, %umin24.neg
  %22 = sub nsw i64 %21, %9
  %min.iters.check = icmp ult i64 %22, 8
  br i1 %min.iters.check, label %.lr.ph8.preheader28, label %vector.scevcheck

vector.scevcheck:                                 ; preds = %.lr.ph8.preheader
  %23 = add nsw i64 %11, 1
  %24 = icmp ne i64 %18, 0
  %umin.neg = sext i1 %24 to i64
  %25 = add nsw i64 %23, %umin.neg
  %26 = sub nsw i64 %25, %9
  %27 = trunc i64 %26 to i32
  %28 = add i32 %8, %27
  %29 = icmp slt i32 %28, %8
  %30 = icmp ugt i64 %26, 4294967295
  %31 = or i1 %29, %30
  br i1 %31, label %.lr.ph8.preheader28, label %vector.memcheck

vector.memcheck:                                  ; preds = %vector.scevcheck
  %scevgep = getelementptr i8, ptr %7, i64 8
  %scevgep13 = getelementptr i8, ptr %5, i64 4
  %32 = shl nsw i64 %9, 3
  %33 = add nsw i64 %32, -8
  %scevgep14 = getelementptr i8, ptr %16, i64 %33
  %34 = shl nsw i64 %11, 3
  %35 = add nsw i64 %34, 8
  %.not = icmp eq i64 %18, 0
  %36 = select i1 %.not, i64 %35, i64 %34
  %scevgep16 = getelementptr i8, ptr %16, i64 %36
  %bound0 = icmp ult ptr %7, %scevgep13
  %bound1 = icmp ult ptr %5, %scevgep
  %found.conflict = and i1 %bound0, %bound1
  %bound017 = icmp ult ptr %7, %scevgep16
  %bound118 = icmp ult ptr %scevgep14, %scevgep
  %found.conflict19 = and i1 %bound017, %bound118
  %conflict.rdx = or i1 %found.conflict, %found.conflict19
  %bound020 = icmp ult ptr %5, %scevgep16
  %bound121 = icmp ult ptr %scevgep14, %scevgep13
  %found.conflict22 = and i1 %bound020, %bound121
  %conflict.rdx23 = or i1 %conflict.rdx, %found.conflict22
  br i1 %conflict.rdx23, label %.lr.ph8.preheader28, label %vector.ph

vector.ph:                                        ; preds = %vector.memcheck
  %n.vec = and i64 %22, -2
  %ind.end = sub nsw i64 %18, %n.vec
  %.cast = trunc i64 %n.vec to i32
  %ind.end25 = add i32 %8, %.cast
  %37 = load i32, ptr %5, align 4, !tbaa !4, !alias.scope !22, !noalias !25
  %broadcast.splatinsert = insertelement <2 x i32> poison, i32 %37, i64 0
  %38 = sitofp <2 x i32> %broadcast.splatinsert to <2 x float>
  %39 = fdiv contract <2 x float> <float 1.000000e+00, float poison>, %38
  %40 = shufflevector <2 x float> %39, <2 x float> poison, <2 x i32> zeroinitializer
  %41 = fpext <2 x float> %40 to <2 x double>
  %42 = extractelement <2 x double> %41, i64 1
  store double %42, ptr %7, align 8, !tbaa !4, !alias.scope !27, !noalias !29
  br label %vector.body

vector.body:                                      ; preds = %vector.body, %vector.ph
  %index = phi i64 [ 0, %vector.ph ], [ %index.next, %vector.body ]
  %.cast27 = trunc i64 %index to i32
  %offset.idx = add i32 %8, %.cast27
  %43 = sext i32 %offset.idx to i64
  %44 = add nsw i64 %43, -1
  %45 = getelementptr double, ptr %16, i64 %44
  store <2 x double> %41, ptr %45, align 8, !tbaa !4, !alias.scope !25
  %index.next = add nuw i64 %index, 2
  %46 = icmp eq i64 %index.next, %n.vec
  br i1 %46, label %middle.block, label %vector.body, !llvm.loop !30

middle.block:                                     ; preds = %vector.body
  %cmp.n = icmp eq i64 %22, %n.vec
  br i1 %cmp.n, label %.loopexit, label %.lr.ph8.preheader28

.lr.ph8.preheader28:                              ; preds = %vector.memcheck, %vector.scevcheck, %.lr.ph8.preheader, %middle.block
  %.ph = phi i64 [ %18, %vector.memcheck ], [ %18, %vector.scevcheck ], [ %18, %.lr.ph8.preheader ], [ %ind.end, %middle.block ]
  %.ph29 = phi i32 [ %8, %vector.memcheck ], [ %8, %vector.scevcheck ], [ %8, %.lr.ph8.preheader ], [ %ind.end25, %middle.block ]
  br label %.lr.ph8

.lr.ph8:                                          ; preds = %.lr.ph8.preheader28, %.lr.ph8
  %47 = phi i64 [ %57, %.lr.ph8 ], [ %.ph, %.lr.ph8.preheader28 ]
  %48 = phi i32 [ %56, %.lr.ph8 ], [ %.ph29, %.lr.ph8.preheader28 ]
  %49 = load i32, ptr %5, align 4, !tbaa !4
  %50 = sitofp i32 %49 to float
  %51 = fdiv contract float 1.000000e+00, %50
  %52 = fpext float %51 to double
  %53 = sext i32 %48 to i64
  %54 = add nsw i64 %53, -1
  %55 = getelementptr double, ptr %16, i64 %54
  store double %52, ptr %55, align 8, !tbaa !4
  store double %52, ptr %7, align 8, !tbaa !4
  %56 = add i32 %48, 1
  %57 = add nsw i64 %47, -1
  %58 = icmp ugt i64 %47, 1
  br i1 %58, label %.lr.ph8, label %.loopexit.loopexit, !llvm.loop !31

59:                                               ; preds = %4
  %reass.sub = sub nsw i64 %11, %9
  %60 = icmp sgt i64 %reass.sub, -1
  br i1 %60, label %.lr.ph, label %.loopexit

.lr.ph:                                           ; preds = %59
  %61 = add nuw nsw i64 %reass.sub, 1
  %62 = load ptr, ptr %2, align 8, !tbaa !8
  br label %63

63:                                               ; preds = %.lr.ph, %63
  %64 = phi i64 [ %61, %.lr.ph ], [ %75, %63 ]
  %65 = phi i32 [ %8, %.lr.ph ], [ %74, %63 ]
  %66 = load i32, ptr %5, align 4, !tbaa !4
  %67 = sitofp i32 %66 to float
  %68 = fdiv contract float 1.000000e+00, %67
  %69 = fpext float %68 to double
  %70 = sext i32 %65 to i64
  %71 = add nsw i64 %70, -1
  %72 = mul i64 %71, %13
  %73 = getelementptr i8, ptr %62, i64 %72
  store double %69, ptr %73, align 8, !tbaa !4
  store double %69, ptr %7, align 8, !tbaa !4
  %74 = add i32 %65, 1
  %75 = add nsw i64 %64, -1
  %76 = icmp ugt i64 %64, 1
  br i1 %76, label %63, label %.loopexit.loopexit30

.loopexit.loopexit:                               ; preds = %.lr.ph8
  br label %.loopexit

.loopexit.loopexit30:                             ; preds = %63
  br label %.loopexit

.loopexit:                                        ; preds = %.loopexit.loopexit30, %.loopexit.loopexit, %middle.block, %59, %15
  ret void
}
*** IR Dump After InstSimplifyPass on _QFPloop ***
; Function Attrs: nofree norecurse nosync nounwind memory(readwrite, inaccessiblemem: none)
define void @_QFPloop(ptr nocapture readonly %0, ptr nocapture readonly %1, ptr nocapture readonly %2, ptr nest nocapture readonly %3) local_unnamed_addr #4 {
  %5 = load ptr, ptr %3, align 8, !tbaa !4
  %6 = getelementptr { ptr, ptr }, ptr %3, i64 0, i32 1
  %7 = load ptr, ptr %6, align 8, !tbaa !4
  %8 = load i32, ptr %0, align 4, !tbaa !4
  %9 = sext i32 %8 to i64
  %10 = load i32, ptr %1, align 4, !tbaa !4
  %11 = sext i32 %10 to i64
  %12 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %2, i64 0, i32 7, i64 0, i64 2
  %13 = load i64, ptr %12, align 8, !tbaa !8
  %14 = icmp eq i64 %13, 8
  br i1 %14, label %15, label %59

15:                                               ; preds = %4
  %16 = load ptr, ptr %2, align 8, !tbaa !8
  %reass.sub9 = sub nsw i64 %11, %9
  %17 = icmp sgt i64 %reass.sub9, -1
  br i1 %17, label %.lr.ph8.preheader, label %.loopexit

.lr.ph8.preheader:                                ; preds = %15
  %18 = add nsw i64 %reass.sub9, 1
  %19 = add nsw i64 %11, 2
  %20 = icmp ne i64 %18, 0
  %umin24.neg = sext i1 %20 to i64
  %21 = add nsw i64 %19, %umin24.neg
  %22 = sub nsw i64 %21, %9
  %min.iters.check = icmp ult i64 %22, 8
  br i1 %min.iters.check, label %.lr.ph8.preheader28, label %vector.scevcheck

vector.scevcheck:                                 ; preds = %.lr.ph8.preheader
  %23 = add nsw i64 %11, 1
  %24 = icmp ne i64 %18, 0
  %umin.neg = sext i1 %24 to i64
  %25 = add nsw i64 %23, %umin.neg
  %26 = sub nsw i64 %25, %9
  %27 = trunc i64 %26 to i32
  %28 = add i32 %8, %27
  %29 = icmp slt i32 %28, %8
  %30 = icmp ugt i64 %26, 4294967295
  %31 = or i1 %29, %30
  br i1 %31, label %.lr.ph8.preheader28, label %vector.memcheck

vector.memcheck:                                  ; preds = %vector.scevcheck
  %scevgep = getelementptr i8, ptr %7, i64 8
  %scevgep13 = getelementptr i8, ptr %5, i64 4
  %32 = shl nsw i64 %9, 3
  %33 = add nsw i64 %32, -8
  %scevgep14 = getelementptr i8, ptr %16, i64 %33
  %34 = shl nsw i64 %11, 3
  %35 = add nsw i64 %34, 8
  %.not = icmp eq i64 %18, 0
  %36 = select i1 %.not, i64 %35, i64 %34
  %scevgep16 = getelementptr i8, ptr %16, i64 %36
  %bound0 = icmp ult ptr %7, %scevgep13
  %bound1 = icmp ult ptr %5, %scevgep
  %found.conflict = and i1 %bound0, %bound1
  %bound017 = icmp ult ptr %7, %scevgep16
  %bound118 = icmp ult ptr %scevgep14, %scevgep
  %found.conflict19 = and i1 %bound017, %bound118
  %conflict.rdx = or i1 %found.conflict, %found.conflict19
  %bound020 = icmp ult ptr %5, %scevgep16
  %bound121 = icmp ult ptr %scevgep14, %scevgep13
  %found.conflict22 = and i1 %bound020, %bound121
  %conflict.rdx23 = or i1 %conflict.rdx, %found.conflict22
  br i1 %conflict.rdx23, label %.lr.ph8.preheader28, label %vector.ph

vector.ph:                                        ; preds = %vector.memcheck
  %n.vec = and i64 %22, -2
  %ind.end = sub nsw i64 %18, %n.vec
  %.cast = trunc i64 %n.vec to i32
  %ind.end25 = add i32 %8, %.cast
  %37 = load i32, ptr %5, align 4, !tbaa !4, !alias.scope !22, !noalias !25
  %broadcast.splatinsert = insertelement <2 x i32> poison, i32 %37, i64 0
  %38 = sitofp <2 x i32> %broadcast.splatinsert to <2 x float>
  %39 = fdiv contract <2 x float> <float 1.000000e+00, float poison>, %38
  %40 = shufflevector <2 x float> %39, <2 x float> poison, <2 x i32> zeroinitializer
  %41 = fpext <2 x float> %40 to <2 x double>
  %42 = extractelement <2 x double> %41, i64 1
  store double %42, ptr %7, align 8, !tbaa !4, !alias.scope !27, !noalias !29
  br label %vector.body

vector.body:                                      ; preds = %vector.body, %vector.ph
  %index = phi i64 [ 0, %vector.ph ], [ %index.next, %vector.body ]
  %.cast27 = trunc i64 %index to i32
  %offset.idx = add i32 %8, %.cast27
  %43 = sext i32 %offset.idx to i64
  %44 = add nsw i64 %43, -1
  %45 = getelementptr double, ptr %16, i64 %44
  store <2 x double> %41, ptr %45, align 8, !tbaa !4, !alias.scope !25
  %index.next = add nuw i64 %index, 2
  %46 = icmp eq i64 %index.next, %n.vec
  br i1 %46, label %middle.block, label %vector.body, !llvm.loop !30

middle.block:                                     ; preds = %vector.body
  %cmp.n = icmp eq i64 %22, %n.vec
  br i1 %cmp.n, label %.loopexit, label %.lr.ph8.preheader28

.lr.ph8.preheader28:                              ; preds = %vector.memcheck, %vector.scevcheck, %.lr.ph8.preheader, %middle.block
  %.ph = phi i64 [ %18, %vector.memcheck ], [ %18, %vector.scevcheck ], [ %18, %.lr.ph8.preheader ], [ %ind.end, %middle.block ]
  %.ph29 = phi i32 [ %8, %vector.memcheck ], [ %8, %vector.scevcheck ], [ %8, %.lr.ph8.preheader ], [ %ind.end25, %middle.block ]
  br label %.lr.ph8

.lr.ph8:                                          ; preds = %.lr.ph8.preheader28, %.lr.ph8
  %47 = phi i64 [ %57, %.lr.ph8 ], [ %.ph, %.lr.ph8.preheader28 ]
  %48 = phi i32 [ %56, %.lr.ph8 ], [ %.ph29, %.lr.ph8.preheader28 ]
  %49 = load i32, ptr %5, align 4, !tbaa !4
  %50 = sitofp i32 %49 to float
  %51 = fdiv contract float 1.000000e+00, %50
  %52 = fpext float %51 to double
  %53 = sext i32 %48 to i64
  %54 = add nsw i64 %53, -1
  %55 = getelementptr double, ptr %16, i64 %54
  store double %52, ptr %55, align 8, !tbaa !4
  store double %52, ptr %7, align 8, !tbaa !4
  %56 = add i32 %48, 1
  %57 = add nsw i64 %47, -1
  %58 = icmp ugt i64 %47, 1
  br i1 %58, label %.lr.ph8, label %.loopexit.loopexit, !llvm.loop !31

59:                                               ; preds = %4
  %reass.sub = sub nsw i64 %11, %9
  %60 = icmp sgt i64 %reass.sub, -1
  br i1 %60, label %.lr.ph, label %.loopexit

.lr.ph:                                           ; preds = %59
  %61 = add nuw nsw i64 %reass.sub, 1
  %62 = load ptr, ptr %2, align 8, !tbaa !8
  br label %63

63:                                               ; preds = %.lr.ph, %63
  %64 = phi i64 [ %61, %.lr.ph ], [ %75, %63 ]
  %65 = phi i32 [ %8, %.lr.ph ], [ %74, %63 ]
  %66 = load i32, ptr %5, align 4, !tbaa !4
  %67 = sitofp i32 %66 to float
  %68 = fdiv contract float 1.000000e+00, %67
  %69 = fpext float %68 to double
  %70 = sext i32 %65 to i64
  %71 = add nsw i64 %70, -1
  %72 = mul i64 %71, %13
  %73 = getelementptr i8, ptr %62, i64 %72
  store double %69, ptr %73, align 8, !tbaa !4
  store double %69, ptr %7, align 8, !tbaa !4
  %74 = add i32 %65, 1
  %75 = add nsw i64 %64, -1
  %76 = icmp ugt i64 %64, 1
  br i1 %76, label %63, label %.loopexit.loopexit30

.loopexit.loopexit:                               ; preds = %.lr.ph8
  br label %.loopexit

.loopexit.loopexit30:                             ; preds = %63
  br label %.loopexit

.loopexit:                                        ; preds = %.loopexit.loopexit30, %.loopexit.loopexit, %middle.block, %59, %15
  ret void
}
*** IR Dump After DivRemPairsPass on _QFPloop ***
; Function Attrs: nofree norecurse nosync nounwind memory(readwrite, inaccessiblemem: none)
define void @_QFPloop(ptr nocapture readonly %0, ptr nocapture readonly %1, ptr nocapture readonly %2, ptr nest nocapture readonly %3) local_unnamed_addr #4 {
  %5 = load ptr, ptr %3, align 8, !tbaa !4
  %6 = getelementptr { ptr, ptr }, ptr %3, i64 0, i32 1
  %7 = load ptr, ptr %6, align 8, !tbaa !4
  %8 = load i32, ptr %0, align 4, !tbaa !4
  %9 = sext i32 %8 to i64
  %10 = load i32, ptr %1, align 4, !tbaa !4
  %11 = sext i32 %10 to i64
  %12 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %2, i64 0, i32 7, i64 0, i64 2
  %13 = load i64, ptr %12, align 8, !tbaa !8
  %14 = icmp eq i64 %13, 8
  br i1 %14, label %15, label %59

15:                                               ; preds = %4
  %16 = load ptr, ptr %2, align 8, !tbaa !8
  %reass.sub9 = sub nsw i64 %11, %9
  %17 = icmp sgt i64 %reass.sub9, -1
  br i1 %17, label %.lr.ph8.preheader, label %.loopexit

.lr.ph8.preheader:                                ; preds = %15
  %18 = add nsw i64 %reass.sub9, 1
  %19 = add nsw i64 %11, 2
  %20 = icmp ne i64 %18, 0
  %umin24.neg = sext i1 %20 to i64
  %21 = add nsw i64 %19, %umin24.neg
  %22 = sub nsw i64 %21, %9
  %min.iters.check = icmp ult i64 %22, 8
  br i1 %min.iters.check, label %.lr.ph8.preheader28, label %vector.scevcheck

vector.scevcheck:                                 ; preds = %.lr.ph8.preheader
  %23 = add nsw i64 %11, 1
  %24 = icmp ne i64 %18, 0
  %umin.neg = sext i1 %24 to i64
  %25 = add nsw i64 %23, %umin.neg
  %26 = sub nsw i64 %25, %9
  %27 = trunc i64 %26 to i32
  %28 = add i32 %8, %27
  %29 = icmp slt i32 %28, %8
  %30 = icmp ugt i64 %26, 4294967295
  %31 = or i1 %29, %30
  br i1 %31, label %.lr.ph8.preheader28, label %vector.memcheck

vector.memcheck:                                  ; preds = %vector.scevcheck
  %scevgep = getelementptr i8, ptr %7, i64 8
  %scevgep13 = getelementptr i8, ptr %5, i64 4
  %32 = shl nsw i64 %9, 3
  %33 = add nsw i64 %32, -8
  %scevgep14 = getelementptr i8, ptr %16, i64 %33
  %34 = shl nsw i64 %11, 3
  %35 = add nsw i64 %34, 8
  %.not = icmp eq i64 %18, 0
  %36 = select i1 %.not, i64 %35, i64 %34
  %scevgep16 = getelementptr i8, ptr %16, i64 %36
  %bound0 = icmp ult ptr %7, %scevgep13
  %bound1 = icmp ult ptr %5, %scevgep
  %found.conflict = and i1 %bound0, %bound1
  %bound017 = icmp ult ptr %7, %scevgep16
  %bound118 = icmp ult ptr %scevgep14, %scevgep
  %found.conflict19 = and i1 %bound017, %bound118
  %conflict.rdx = or i1 %found.conflict, %found.conflict19
  %bound020 = icmp ult ptr %5, %scevgep16
  %bound121 = icmp ult ptr %scevgep14, %scevgep13
  %found.conflict22 = and i1 %bound020, %bound121
  %conflict.rdx23 = or i1 %conflict.rdx, %found.conflict22
  br i1 %conflict.rdx23, label %.lr.ph8.preheader28, label %vector.ph

vector.ph:                                        ; preds = %vector.memcheck
  %n.vec = and i64 %22, -2
  %ind.end = sub nsw i64 %18, %n.vec
  %.cast = trunc i64 %n.vec to i32
  %ind.end25 = add i32 %8, %.cast
  %37 = load i32, ptr %5, align 4, !tbaa !4, !alias.scope !22, !noalias !25
  %broadcast.splatinsert = insertelement <2 x i32> poison, i32 %37, i64 0
  %38 = sitofp <2 x i32> %broadcast.splatinsert to <2 x float>
  %39 = fdiv contract <2 x float> <float 1.000000e+00, float poison>, %38
  %40 = shufflevector <2 x float> %39, <2 x float> poison, <2 x i32> zeroinitializer
  %41 = fpext <2 x float> %40 to <2 x double>
  %42 = extractelement <2 x double> %41, i64 1
  store double %42, ptr %7, align 8, !tbaa !4, !alias.scope !27, !noalias !29
  br label %vector.body

vector.body:                                      ; preds = %vector.body, %vector.ph
  %index = phi i64 [ 0, %vector.ph ], [ %index.next, %vector.body ]
  %.cast27 = trunc i64 %index to i32
  %offset.idx = add i32 %8, %.cast27
  %43 = sext i32 %offset.idx to i64
  %44 = add nsw i64 %43, -1
  %45 = getelementptr double, ptr %16, i64 %44
  store <2 x double> %41, ptr %45, align 8, !tbaa !4, !alias.scope !25
  %index.next = add nuw i64 %index, 2
  %46 = icmp eq i64 %index.next, %n.vec
  br i1 %46, label %middle.block, label %vector.body, !llvm.loop !30

middle.block:                                     ; preds = %vector.body
  %cmp.n = icmp eq i64 %22, %n.vec
  br i1 %cmp.n, label %.loopexit, label %.lr.ph8.preheader28

.lr.ph8.preheader28:                              ; preds = %vector.memcheck, %vector.scevcheck, %.lr.ph8.preheader, %middle.block
  %.ph = phi i64 [ %18, %vector.memcheck ], [ %18, %vector.scevcheck ], [ %18, %.lr.ph8.preheader ], [ %ind.end, %middle.block ]
  %.ph29 = phi i32 [ %8, %vector.memcheck ], [ %8, %vector.scevcheck ], [ %8, %.lr.ph8.preheader ], [ %ind.end25, %middle.block ]
  br label %.lr.ph8

.lr.ph8:                                          ; preds = %.lr.ph8.preheader28, %.lr.ph8
  %47 = phi i64 [ %57, %.lr.ph8 ], [ %.ph, %.lr.ph8.preheader28 ]
  %48 = phi i32 [ %56, %.lr.ph8 ], [ %.ph29, %.lr.ph8.preheader28 ]
  %49 = load i32, ptr %5, align 4, !tbaa !4
  %50 = sitofp i32 %49 to float
  %51 = fdiv contract float 1.000000e+00, %50
  %52 = fpext float %51 to double
  %53 = sext i32 %48 to i64
  %54 = add nsw i64 %53, -1
  %55 = getelementptr double, ptr %16, i64 %54
  store double %52, ptr %55, align 8, !tbaa !4
  store double %52, ptr %7, align 8, !tbaa !4
  %56 = add i32 %48, 1
  %57 = add nsw i64 %47, -1
  %58 = icmp ugt i64 %47, 1
  br i1 %58, label %.lr.ph8, label %.loopexit.loopexit, !llvm.loop !31

59:                                               ; preds = %4
  %reass.sub = sub nsw i64 %11, %9
  %60 = icmp sgt i64 %reass.sub, -1
  br i1 %60, label %.lr.ph, label %.loopexit

.lr.ph:                                           ; preds = %59
  %61 = add nuw nsw i64 %reass.sub, 1
  %62 = load ptr, ptr %2, align 8, !tbaa !8
  br label %63

63:                                               ; preds = %.lr.ph, %63
  %64 = phi i64 [ %61, %.lr.ph ], [ %75, %63 ]
  %65 = phi i32 [ %8, %.lr.ph ], [ %74, %63 ]
  %66 = load i32, ptr %5, align 4, !tbaa !4
  %67 = sitofp i32 %66 to float
  %68 = fdiv contract float 1.000000e+00, %67
  %69 = fpext float %68 to double
  %70 = sext i32 %65 to i64
  %71 = add nsw i64 %70, -1
  %72 = mul i64 %71, %13
  %73 = getelementptr i8, ptr %62, i64 %72
  store double %69, ptr %73, align 8, !tbaa !4
  store double %69, ptr %7, align 8, !tbaa !4
  %74 = add i32 %65, 1
  %75 = add nsw i64 %64, -1
  %76 = icmp ugt i64 %64, 1
  br i1 %76, label %63, label %.loopexit.loopexit30

.loopexit.loopexit:                               ; preds = %.lr.ph8
  br label %.loopexit

.loopexit.loopexit30:                             ; preds = %63
  br label %.loopexit

.loopexit:                                        ; preds = %.loopexit.loopexit30, %.loopexit.loopexit, %middle.block, %59, %15
  ret void
}
*** IR Dump After TailCallElimPass on _QFPloop ***
; Function Attrs: nofree norecurse nosync nounwind memory(readwrite, inaccessiblemem: none)
define void @_QFPloop(ptr nocapture readonly %0, ptr nocapture readonly %1, ptr nocapture readonly %2, ptr nest nocapture readonly %3) local_unnamed_addr #4 {
  %5 = load ptr, ptr %3, align 8, !tbaa !4
  %6 = getelementptr { ptr, ptr }, ptr %3, i64 0, i32 1
  %7 = load ptr, ptr %6, align 8, !tbaa !4
  %8 = load i32, ptr %0, align 4, !tbaa !4
  %9 = sext i32 %8 to i64
  %10 = load i32, ptr %1, align 4, !tbaa !4
  %11 = sext i32 %10 to i64
  %12 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %2, i64 0, i32 7, i64 0, i64 2
  %13 = load i64, ptr %12, align 8, !tbaa !8
  %14 = icmp eq i64 %13, 8
  br i1 %14, label %15, label %59

15:                                               ; preds = %4
  %16 = load ptr, ptr %2, align 8, !tbaa !8
  %reass.sub9 = sub nsw i64 %11, %9
  %17 = icmp sgt i64 %reass.sub9, -1
  br i1 %17, label %.lr.ph8.preheader, label %.loopexit

.lr.ph8.preheader:                                ; preds = %15
  %18 = add nsw i64 %reass.sub9, 1
  %19 = add nsw i64 %11, 2
  %20 = icmp ne i64 %18, 0
  %umin24.neg = sext i1 %20 to i64
  %21 = add nsw i64 %19, %umin24.neg
  %22 = sub nsw i64 %21, %9
  %min.iters.check = icmp ult i64 %22, 8
  br i1 %min.iters.check, label %.lr.ph8.preheader28, label %vector.scevcheck

vector.scevcheck:                                 ; preds = %.lr.ph8.preheader
  %23 = add nsw i64 %11, 1
  %24 = icmp ne i64 %18, 0
  %umin.neg = sext i1 %24 to i64
  %25 = add nsw i64 %23, %umin.neg
  %26 = sub nsw i64 %25, %9
  %27 = trunc i64 %26 to i32
  %28 = add i32 %8, %27
  %29 = icmp slt i32 %28, %8
  %30 = icmp ugt i64 %26, 4294967295
  %31 = or i1 %29, %30
  br i1 %31, label %.lr.ph8.preheader28, label %vector.memcheck

vector.memcheck:                                  ; preds = %vector.scevcheck
  %scevgep = getelementptr i8, ptr %7, i64 8
  %scevgep13 = getelementptr i8, ptr %5, i64 4
  %32 = shl nsw i64 %9, 3
  %33 = add nsw i64 %32, -8
  %scevgep14 = getelementptr i8, ptr %16, i64 %33
  %34 = shl nsw i64 %11, 3
  %35 = add nsw i64 %34, 8
  %.not = icmp eq i64 %18, 0
  %36 = select i1 %.not, i64 %35, i64 %34
  %scevgep16 = getelementptr i8, ptr %16, i64 %36
  %bound0 = icmp ult ptr %7, %scevgep13
  %bound1 = icmp ult ptr %5, %scevgep
  %found.conflict = and i1 %bound0, %bound1
  %bound017 = icmp ult ptr %7, %scevgep16
  %bound118 = icmp ult ptr %scevgep14, %scevgep
  %found.conflict19 = and i1 %bound017, %bound118
  %conflict.rdx = or i1 %found.conflict, %found.conflict19
  %bound020 = icmp ult ptr %5, %scevgep16
  %bound121 = icmp ult ptr %scevgep14, %scevgep13
  %found.conflict22 = and i1 %bound020, %bound121
  %conflict.rdx23 = or i1 %conflict.rdx, %found.conflict22
  br i1 %conflict.rdx23, label %.lr.ph8.preheader28, label %vector.ph

vector.ph:                                        ; preds = %vector.memcheck
  %n.vec = and i64 %22, -2
  %ind.end = sub nsw i64 %18, %n.vec
  %.cast = trunc i64 %n.vec to i32
  %ind.end25 = add i32 %8, %.cast
  %37 = load i32, ptr %5, align 4, !tbaa !4, !alias.scope !22, !noalias !25
  %broadcast.splatinsert = insertelement <2 x i32> poison, i32 %37, i64 0
  %38 = sitofp <2 x i32> %broadcast.splatinsert to <2 x float>
  %39 = fdiv contract <2 x float> <float 1.000000e+00, float poison>, %38
  %40 = shufflevector <2 x float> %39, <2 x float> poison, <2 x i32> zeroinitializer
  %41 = fpext <2 x float> %40 to <2 x double>
  %42 = extractelement <2 x double> %41, i64 1
  store double %42, ptr %7, align 8, !tbaa !4, !alias.scope !27, !noalias !29
  br label %vector.body

vector.body:                                      ; preds = %vector.body, %vector.ph
  %index = phi i64 [ 0, %vector.ph ], [ %index.next, %vector.body ]
  %.cast27 = trunc i64 %index to i32
  %offset.idx = add i32 %8, %.cast27
  %43 = sext i32 %offset.idx to i64
  %44 = add nsw i64 %43, -1
  %45 = getelementptr double, ptr %16, i64 %44
  store <2 x double> %41, ptr %45, align 8, !tbaa !4, !alias.scope !25
  %index.next = add nuw i64 %index, 2
  %46 = icmp eq i64 %index.next, %n.vec
  br i1 %46, label %middle.block, label %vector.body, !llvm.loop !30

middle.block:                                     ; preds = %vector.body
  %cmp.n = icmp eq i64 %22, %n.vec
  br i1 %cmp.n, label %.loopexit, label %.lr.ph8.preheader28

.lr.ph8.preheader28:                              ; preds = %vector.memcheck, %vector.scevcheck, %.lr.ph8.preheader, %middle.block
  %.ph = phi i64 [ %18, %vector.memcheck ], [ %18, %vector.scevcheck ], [ %18, %.lr.ph8.preheader ], [ %ind.end, %middle.block ]
  %.ph29 = phi i32 [ %8, %vector.memcheck ], [ %8, %vector.scevcheck ], [ %8, %.lr.ph8.preheader ], [ %ind.end25, %middle.block ]
  br label %.lr.ph8

.lr.ph8:                                          ; preds = %.lr.ph8.preheader28, %.lr.ph8
  %47 = phi i64 [ %57, %.lr.ph8 ], [ %.ph, %.lr.ph8.preheader28 ]
  %48 = phi i32 [ %56, %.lr.ph8 ], [ %.ph29, %.lr.ph8.preheader28 ]
  %49 = load i32, ptr %5, align 4, !tbaa !4
  %50 = sitofp i32 %49 to float
  %51 = fdiv contract float 1.000000e+00, %50
  %52 = fpext float %51 to double
  %53 = sext i32 %48 to i64
  %54 = add nsw i64 %53, -1
  %55 = getelementptr double, ptr %16, i64 %54
  store double %52, ptr %55, align 8, !tbaa !4
  store double %52, ptr %7, align 8, !tbaa !4
  %56 = add i32 %48, 1
  %57 = add nsw i64 %47, -1
  %58 = icmp ugt i64 %47, 1
  br i1 %58, label %.lr.ph8, label %.loopexit.loopexit, !llvm.loop !31

59:                                               ; preds = %4
  %reass.sub = sub nsw i64 %11, %9
  %60 = icmp sgt i64 %reass.sub, -1
  br i1 %60, label %.lr.ph, label %.loopexit

.lr.ph:                                           ; preds = %59
  %61 = add nuw nsw i64 %reass.sub, 1
  %62 = load ptr, ptr %2, align 8, !tbaa !8
  br label %63

63:                                               ; preds = %.lr.ph, %63
  %64 = phi i64 [ %61, %.lr.ph ], [ %75, %63 ]
  %65 = phi i32 [ %8, %.lr.ph ], [ %74, %63 ]
  %66 = load i32, ptr %5, align 4, !tbaa !4
  %67 = sitofp i32 %66 to float
  %68 = fdiv contract float 1.000000e+00, %67
  %69 = fpext float %68 to double
  %70 = sext i32 %65 to i64
  %71 = add nsw i64 %70, -1
  %72 = mul i64 %71, %13
  %73 = getelementptr i8, ptr %62, i64 %72
  store double %69, ptr %73, align 8, !tbaa !4
  store double %69, ptr %7, align 8, !tbaa !4
  %74 = add i32 %65, 1
  %75 = add nsw i64 %64, -1
  %76 = icmp ugt i64 %64, 1
  br i1 %76, label %63, label %.loopexit.loopexit30

.loopexit.loopexit:                               ; preds = %.lr.ph8
  br label %.loopexit

.loopexit.loopexit30:                             ; preds = %63
  br label %.loopexit

.loopexit:                                        ; preds = %.loopexit.loopexit30, %.loopexit.loopexit, %middle.block, %59, %15
  ret void
}
*** IR Dump After SimplifyCFGPass on _QFPloop ***
; Function Attrs: nofree norecurse nosync nounwind memory(readwrite, inaccessiblemem: none)
define void @_QFPloop(ptr nocapture readonly %0, ptr nocapture readonly %1, ptr nocapture readonly %2, ptr nest nocapture readonly %3) local_unnamed_addr #4 {
  %5 = load ptr, ptr %3, align 8, !tbaa !4
  %6 = getelementptr { ptr, ptr }, ptr %3, i64 0, i32 1
  %7 = load ptr, ptr %6, align 8, !tbaa !4
  %8 = load i32, ptr %0, align 4, !tbaa !4
  %9 = sext i32 %8 to i64
  %10 = load i32, ptr %1, align 4, !tbaa !4
  %11 = sext i32 %10 to i64
  %12 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %2, i64 0, i32 7, i64 0, i64 2
  %13 = load i64, ptr %12, align 8, !tbaa !8
  %14 = icmp eq i64 %13, 8
  br i1 %14, label %15, label %59

15:                                               ; preds = %4
  %16 = load ptr, ptr %2, align 8, !tbaa !8
  %reass.sub9 = sub nsw i64 %11, %9
  %17 = icmp sgt i64 %reass.sub9, -1
  br i1 %17, label %.lr.ph8.preheader, label %.loopexit

.lr.ph8.preheader:                                ; preds = %15
  %18 = add nsw i64 %reass.sub9, 1
  %19 = add nsw i64 %11, 2
  %20 = icmp ne i64 %18, 0
  %umin24.neg = sext i1 %20 to i64
  %21 = add nsw i64 %19, %umin24.neg
  %22 = sub nsw i64 %21, %9
  %min.iters.check = icmp ult i64 %22, 8
  br i1 %min.iters.check, label %.lr.ph8.preheader28, label %vector.scevcheck

vector.scevcheck:                                 ; preds = %.lr.ph8.preheader
  %23 = add nsw i64 %11, 1
  %24 = icmp ne i64 %18, 0
  %umin.neg = sext i1 %24 to i64
  %25 = add nsw i64 %23, %umin.neg
  %26 = sub nsw i64 %25, %9
  %27 = trunc i64 %26 to i32
  %28 = add i32 %8, %27
  %29 = icmp slt i32 %28, %8
  %30 = icmp ugt i64 %26, 4294967295
  %31 = or i1 %29, %30
  br i1 %31, label %.lr.ph8.preheader28, label %vector.memcheck

vector.memcheck:                                  ; preds = %vector.scevcheck
  %scevgep = getelementptr i8, ptr %7, i64 8
  %scevgep13 = getelementptr i8, ptr %5, i64 4
  %32 = shl nsw i64 %9, 3
  %33 = add nsw i64 %32, -8
  %scevgep14 = getelementptr i8, ptr %16, i64 %33
  %34 = shl nsw i64 %11, 3
  %35 = add nsw i64 %34, 8
  %.not = icmp eq i64 %18, 0
  %36 = select i1 %.not, i64 %35, i64 %34
  %scevgep16 = getelementptr i8, ptr %16, i64 %36
  %bound0 = icmp ult ptr %7, %scevgep13
  %bound1 = icmp ult ptr %5, %scevgep
  %found.conflict = and i1 %bound0, %bound1
  %bound017 = icmp ult ptr %7, %scevgep16
  %bound118 = icmp ult ptr %scevgep14, %scevgep
  %found.conflict19 = and i1 %bound017, %bound118
  %conflict.rdx = or i1 %found.conflict, %found.conflict19
  %bound020 = icmp ult ptr %5, %scevgep16
  %bound121 = icmp ult ptr %scevgep14, %scevgep13
  %found.conflict22 = and i1 %bound020, %bound121
  %conflict.rdx23 = or i1 %conflict.rdx, %found.conflict22
  br i1 %conflict.rdx23, label %.lr.ph8.preheader28, label %vector.ph

vector.ph:                                        ; preds = %vector.memcheck
  %n.vec = and i64 %22, -2
  %ind.end = sub nsw i64 %18, %n.vec
  %.cast = trunc i64 %n.vec to i32
  %ind.end25 = add i32 %8, %.cast
  %37 = load i32, ptr %5, align 4, !tbaa !4, !alias.scope !22, !noalias !25
  %broadcast.splatinsert = insertelement <2 x i32> poison, i32 %37, i64 0
  %38 = sitofp <2 x i32> %broadcast.splatinsert to <2 x float>
  %39 = fdiv contract <2 x float> <float 1.000000e+00, float poison>, %38
  %40 = shufflevector <2 x float> %39, <2 x float> poison, <2 x i32> zeroinitializer
  %41 = fpext <2 x float> %40 to <2 x double>
  %42 = extractelement <2 x double> %41, i64 1
  store double %42, ptr %7, align 8, !tbaa !4, !alias.scope !27, !noalias !29
  br label %vector.body

vector.body:                                      ; preds = %vector.body, %vector.ph
  %index = phi i64 [ 0, %vector.ph ], [ %index.next, %vector.body ]
  %.cast27 = trunc i64 %index to i32
  %offset.idx = add i32 %8, %.cast27
  %43 = sext i32 %offset.idx to i64
  %44 = add nsw i64 %43, -1
  %45 = getelementptr double, ptr %16, i64 %44
  store <2 x double> %41, ptr %45, align 8, !tbaa !4, !alias.scope !25
  %index.next = add nuw i64 %index, 2
  %46 = icmp eq i64 %index.next, %n.vec
  br i1 %46, label %middle.block, label %vector.body, !llvm.loop !30

middle.block:                                     ; preds = %vector.body
  %cmp.n = icmp eq i64 %22, %n.vec
  br i1 %cmp.n, label %.loopexit, label %.lr.ph8.preheader28

.lr.ph8.preheader28:                              ; preds = %vector.memcheck, %vector.scevcheck, %.lr.ph8.preheader, %middle.block
  %.ph = phi i64 [ %18, %vector.memcheck ], [ %18, %vector.scevcheck ], [ %18, %.lr.ph8.preheader ], [ %ind.end, %middle.block ]
  %.ph29 = phi i32 [ %8, %vector.memcheck ], [ %8, %vector.scevcheck ], [ %8, %.lr.ph8.preheader ], [ %ind.end25, %middle.block ]
  br label %.lr.ph8

.lr.ph8:                                          ; preds = %.lr.ph8.preheader28, %.lr.ph8
  %47 = phi i64 [ %57, %.lr.ph8 ], [ %.ph, %.lr.ph8.preheader28 ]
  %48 = phi i32 [ %56, %.lr.ph8 ], [ %.ph29, %.lr.ph8.preheader28 ]
  %49 = load i32, ptr %5, align 4, !tbaa !4
  %50 = sitofp i32 %49 to float
  %51 = fdiv contract float 1.000000e+00, %50
  %52 = fpext float %51 to double
  %53 = sext i32 %48 to i64
  %54 = add nsw i64 %53, -1
  %55 = getelementptr double, ptr %16, i64 %54
  store double %52, ptr %55, align 8, !tbaa !4
  store double %52, ptr %7, align 8, !tbaa !4
  %56 = add i32 %48, 1
  %57 = add nsw i64 %47, -1
  %58 = icmp ugt i64 %47, 1
  br i1 %58, label %.lr.ph8, label %.loopexit, !llvm.loop !31

59:                                               ; preds = %4
  %reass.sub = sub nsw i64 %11, %9
  %60 = icmp sgt i64 %reass.sub, -1
  br i1 %60, label %.lr.ph, label %.loopexit

.lr.ph:                                           ; preds = %59
  %61 = add nuw nsw i64 %reass.sub, 1
  %62 = load ptr, ptr %2, align 8, !tbaa !8
  br label %63

63:                                               ; preds = %.lr.ph, %63
  %64 = phi i64 [ %61, %.lr.ph ], [ %75, %63 ]
  %65 = phi i32 [ %8, %.lr.ph ], [ %74, %63 ]
  %66 = load i32, ptr %5, align 4, !tbaa !4
  %67 = sitofp i32 %66 to float
  %68 = fdiv contract float 1.000000e+00, %67
  %69 = fpext float %68 to double
  %70 = sext i32 %65 to i64
  %71 = add nsw i64 %70, -1
  %72 = mul i64 %71, %13
  %73 = getelementptr i8, ptr %62, i64 %72
  store double %69, ptr %73, align 8, !tbaa !4
  store double %69, ptr %7, align 8, !tbaa !4
  %74 = add i32 %65, 1
  %75 = add nsw i64 %64, -1
  %76 = icmp ugt i64 %64, 1
  br i1 %76, label %63, label %.loopexit

.loopexit:                                        ; preds = %63, %.lr.ph8, %middle.block, %59, %15
  ret void
}
*** IR Dump After GlobalDCEPass on [module] ***
; ModuleID = 'FIRModule'
source_filename = "FIRModule"
target datalayout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128"
target triple = "x86_64-unknown-linux-gnu"

%struct.ident_t = type { i32, i32, i32, i32, ptr }

@_QQcl.28612C69372C612C6531332E36653229 = internal constant [16 x i8] c"(a,i7,a,e13.6e2)"
@_QQcl.e8a0ac9186c064ac8543d822e9060d96 = internal constant [59 x i8] c"/g/g92/rydahl1/flangtests/src/parallel_region_outlined.f90\00"
@_QQcl.54686520726573756C74206F6620286172722831292B61727228 = internal constant [26 x i8] c"The result of (arr(1)+arr("
@_QQcl.2920697320 = internal constant [5 x i8] c") is "
@_QQEnvironmentDefaults = local_unnamed_addr constant ptr null
@0 = private unnamed_addr constant [23 x i8] c";unknown;unknown;0;0;;\00", align 1
@1 = private unnamed_addr constant %struct.ident_t { i32 0, i32 2, i32 0, i32 22, ptr @0 }, align 8

; Function Attrs: mustprogress nofree nounwind willreturn allockind("alloc,uninitialized") allocsize(0) memory(inaccessiblemem: readwrite)
declare noalias noundef ptr @malloc(i64 noundef) local_unnamed_addr #0

; Function Attrs: mustprogress nounwind willreturn allockind("free") memory(argmem: readwrite, inaccessiblemem: readwrite)
declare void @free(ptr allocptr nocapture noundef) local_unnamed_addr #1

define void @_QQmain() local_unnamed_addr {
  %structArg.i = alloca { ptr, ptr, ptr, ptr, ptr }, align 8
  %1 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %2 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %3 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %4 = alloca i32, align 4
  %5 = alloca double, align 8
  %6 = alloca { ptr, ptr }, align 8
  store ptr %4, ptr %6, align 8, !tbaa !4
  %7 = getelementptr inbounds { ptr, ptr }, ptr %6, i64 0, i32 1
  store ptr %5, ptr %7, align 8, !tbaa !4
  store i32 1048576, ptr %4, align 4, !tbaa !4
  call void @llvm.lifetime.start.p0(i64 40, ptr nonnull %structArg.i)
  call void @llvm.lifetime.start.p0(i64 48, ptr nonnull %1)
  call void @llvm.lifetime.start.p0(i64 48, ptr nonnull %2)
  call void @llvm.lifetime.start.p0(i64 48, ptr nonnull %3)
  %.fca.1.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 1
  %.fca.2.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 2
  %.fca.3.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 3
  %.fca.4.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 4
  %.fca.5.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 5
  %.fca.6.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 6
  %.fca.7.0.0.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 7, i64 0, i64 0
  %.fca.7.0.1.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 7, i64 0, i64 1
  %.fca.7.0.2.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 7, i64 0, i64 2
  %8 = call dereferenceable_or_null(8388608) ptr @malloc(i64 8388608)
  store ptr %8, ptr %3, align 8, !tbaa !8
  store i64 8, ptr %.fca.1.gep.i, align 8, !tbaa !8
  store i32 20180515, ptr %.fca.2.gep.i, align 8, !tbaa !8
  store i8 1, ptr %.fca.3.gep.i, align 4, !tbaa !8
  store i8 28, ptr %.fca.4.gep.i, align 1, !tbaa !8
  store i8 2, ptr %.fca.5.gep.i, align 2, !tbaa !8
  store i8 0, ptr %.fca.6.gep.i, align 1, !tbaa !8
  store i64 1, ptr %.fca.7.0.0.gep.i, align 8, !tbaa !8
  store i64 1048576, ptr %.fca.7.0.1.gep.i, align 8, !tbaa !8
  store i64 8, ptr %.fca.7.0.2.gep.i, align 8, !tbaa !8
  %omp_global_thread_num.i = call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %4, ptr %structArg.i, align 8
  %gep_5.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 1
  store ptr %3, ptr %gep_5.i, align 8
  %gep_6.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 2
  store ptr %2, ptr %gep_6.i, align 8
  %gep_7.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 3
  store ptr %1, ptr %gep_7.i, align 8
  %gep_8.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 4
  store ptr %6, ptr %gep_8.i, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QFPomp_subroutine..omp_par, ptr nonnull %structArg.i)
  %.fca.0.load.i = load ptr, ptr %3, align 8, !tbaa !8
  %.fca.7.0.0.load.i = load i64, ptr %.fca.7.0.0.gep.i, align 8, !tbaa !8
  %9 = sub i64 1, %.fca.7.0.0.load.i
  %10 = getelementptr double, ptr %.fca.0.load.i, i64 %9
  %11 = load double, ptr %10, align 8, !tbaa !4
  %12 = load i32, ptr %4, align 4, !tbaa !4
  %13 = sext i32 %12 to i64
  %14 = sub i64 %13, %.fca.7.0.0.load.i
  %15 = getelementptr double, ptr %.fca.0.load.i, i64 %14
  %16 = load double, ptr %15, align 8, !tbaa !4
  %17 = fadd contract double %11, %16
  call void @free(ptr %.fca.0.load.i)
  call void @llvm.lifetime.end.p0(i64 40, ptr nonnull %structArg.i)
  call void @llvm.lifetime.end.p0(i64 48, ptr nonnull %1)
  call void @llvm.lifetime.end.p0(i64 48, ptr nonnull %2)
  call void @llvm.lifetime.end.p0(i64 48, ptr nonnull %3)
  %18 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.e8a0ac9186c064ac8543d822e9060d96, i32 10)
  %19 = call i1 @_FortranAioOutputAscii(ptr %18, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %20 = load i32, ptr %4, align 4, !tbaa !4
  %21 = call i1 @_FortranAioOutputInteger32(ptr %18, i32 %20)
  %22 = call i1 @_FortranAioOutputAscii(ptr %18, ptr nonnull @_QQcl.2920697320, i64 5)
  %23 = call i1 @_FortranAioOutputReal64(ptr %18, double %17)
  %24 = call i32 @_FortranAioEndIoStatement(ptr %18)
  ret void
}

; Function Attrs: nounwind
define void @_QFPomp_subroutine(ptr %0, ptr nocapture writeonly %1, ptr nest %2) local_unnamed_addr #2 {
entry:
  %structArg = alloca { ptr, ptr, ptr, ptr, ptr }, align 8
  %3 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %4 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %5 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %.fca.1.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 1
  %.fca.2.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 2
  %.fca.3.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 3
  %.fca.4.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 4
  %.fca.5.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 5
  %.fca.6.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 6
  %.fca.7.0.0.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 0
  %.fca.7.0.1.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 1
  %.fca.7.0.2.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 2
  %6 = load i32, ptr %0, align 4, !tbaa !4
  %7 = tail call i32 @llvm.smax.i32(i32 %6, i32 0)
  %8 = zext i32 %7 to i64
  %9 = shl nuw nsw i64 %8, 3
  %10 = tail call ptr @malloc(i64 %9)
  store ptr %10, ptr %5, align 8, !tbaa !8
  store i64 8, ptr %.fca.1.gep, align 8, !tbaa !8
  store i32 20180515, ptr %.fca.2.gep, align 8, !tbaa !8
  store i8 1, ptr %.fca.3.gep, align 4, !tbaa !8
  store i8 28, ptr %.fca.4.gep, align 1, !tbaa !8
  store i8 2, ptr %.fca.5.gep, align 2, !tbaa !8
  store i8 0, ptr %.fca.6.gep, align 1, !tbaa !8
  store i64 1, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  store i64 %8, ptr %.fca.7.0.1.gep, align 8, !tbaa !8
  store i64 8, ptr %.fca.7.0.2.gep, align 8, !tbaa !8
  %omp_global_thread_num = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %0, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %5, ptr %gep_5, align 8
  %gep_6 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 2
  store ptr %4, ptr %gep_6, align 8
  %gep_7 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 3
  store ptr %3, ptr %gep_7, align 8
  %gep_8 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 4
  store ptr %2, ptr %gep_8, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QFPomp_subroutine..omp_par, ptr nonnull %structArg)
  %.fca.0.load = load ptr, ptr %5, align 8, !tbaa !8
  %.fca.7.0.0.load = load i64, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  %11 = sub i64 1, %.fca.7.0.0.load
  %12 = getelementptr double, ptr %.fca.0.load, i64 %11
  %13 = load double, ptr %12, align 8, !tbaa !4
  %14 = load i32, ptr %0, align 4, !tbaa !4
  %15 = sext i32 %14 to i64
  %16 = sub i64 %15, %.fca.7.0.0.load
  %17 = getelementptr double, ptr %.fca.0.load, i64 %16
  %18 = load double, ptr %17, align 8, !tbaa !4
  %19 = fadd contract double %13, %18
  store double %19, ptr %1, align 8, !tbaa !4
  call void @free(ptr %.fca.0.load)
  ret void
}

; Function Attrs: norecurse nounwind
define internal void @_QFPomp_subroutine..omp_par(ptr noalias nocapture readnone %tid.addr, ptr noalias nocapture readnone %zero.addr, ptr nocapture readonly %0) #3 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %gep_3 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 2
  %loadgep_4 = load ptr, ptr %gep_3, align 8
  %gep_5 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 3
  %loadgep_6 = load ptr, ptr %gep_5, align 8
  %gep_7 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 4
  %loadgep_8 = load ptr, ptr %gep_7, align 8
  %1 = tail call i32 @omp_get_thread_num()
  %2 = tail call i32 @omp_get_num_threads()
  %3 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %4 = sdiv i32 %3, %2
  %5 = mul i32 %4, %1
  %6 = add i32 %5, 1
  %7 = add i32 %2, -1
  %8 = icmp eq i32 %1, %7
  %9 = add i32 %6, %4
  %spec.select = select i1 %8, i32 %3, i32 %9
  %.unpack = load ptr, ptr %loadgep_2, align 8, !tbaa !8
  %.elt14 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  %.unpack15 = load i64, ptr %.elt14, align 8, !tbaa !8
  %.elt16 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  %.unpack17 = load i32, ptr %.elt16, align 8, !tbaa !8
  %.elt18 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  %.unpack19 = load i8, ptr %.elt18, align 4, !tbaa !8
  %.elt20 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  %.unpack21 = load i8, ptr %.elt20, align 1, !tbaa !8
  %.elt22 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  %.unpack23 = load i8, ptr %.elt22, align 2, !tbaa !8
  %.elt24 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  %.unpack25 = load i8, ptr %.elt24, align 1, !tbaa !8
  %.elt26 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  %.unpack27.unpack.unpack = load i64, ptr %.elt26, align 8, !tbaa !8
  %.unpack27.unpack.elt29 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  %.unpack27.unpack.unpack30 = load i64, ptr %.unpack27.unpack.elt29, align 8, !tbaa !8
  %.unpack27.unpack.elt31 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  %.unpack27.unpack.unpack32 = load i64, ptr %.unpack27.unpack.elt31, align 8, !tbaa !8
  store ptr %.unpack, ptr %loadgep_4, align 8, !tbaa !8
  %loadgep_4.repack34 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 1
  store i64 %.unpack15, ptr %loadgep_4.repack34, align 8, !tbaa !8
  %loadgep_4.repack36 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 2
  store i32 %.unpack17, ptr %loadgep_4.repack36, align 8, !tbaa !8
  %loadgep_4.repack38 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 3
  store i8 %.unpack19, ptr %loadgep_4.repack38, align 4, !tbaa !8
  %loadgep_4.repack40 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 4
  store i8 %.unpack21, ptr %loadgep_4.repack40, align 1, !tbaa !8
  %loadgep_4.repack42 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 5
  store i8 %.unpack23, ptr %loadgep_4.repack42, align 2, !tbaa !8
  %loadgep_4.repack44 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 6
  store i8 %.unpack25, ptr %loadgep_4.repack44, align 1, !tbaa !8
  %loadgep_4.repack46 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7
  store i64 %.unpack27.unpack.unpack, ptr %loadgep_4.repack46, align 8, !tbaa !8
  %loadgep_4.repack46.repack48 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack27.unpack.unpack30, ptr %loadgep_4.repack46.repack48, align 8, !tbaa !8
  %loadgep_4.repack46.repack50 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 2
  store i64 %.unpack27.unpack.unpack32, ptr %loadgep_4.repack46.repack50, align 8, !tbaa !8
  %10 = icmp eq i64 %.unpack27.unpack.unpack30, 0
  %11 = select i1 %10, i64 1, i64 %.unpack27.unpack.unpack
  store ptr %.unpack, ptr %loadgep_6, align 8, !tbaa !8
  %loadgep_6.repack52 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 1
  store i64 8, ptr %loadgep_6.repack52, align 8, !tbaa !8
  %loadgep_6.repack54 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 2
  store i32 20180515, ptr %loadgep_6.repack54, align 8, !tbaa !8
  %loadgep_6.repack56 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 3
  store i8 1, ptr %loadgep_6.repack56, align 4, !tbaa !8
  %loadgep_6.repack58 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 4
  store i8 28, ptr %loadgep_6.repack58, align 1, !tbaa !8
  %loadgep_6.repack60 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 5
  store i8 0, ptr %loadgep_6.repack60, align 2, !tbaa !8
  %loadgep_6.repack62 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 6
  store i8 0, ptr %loadgep_6.repack62, align 1, !tbaa !8
  %loadgep_6.repack64 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7
  store i64 %11, ptr %loadgep_6.repack64, align 8, !tbaa !8
  %loadgep_6.repack64.repack66 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack27.unpack.unpack30, ptr %loadgep_6.repack64.repack66, align 8, !tbaa !8
  %loadgep_6.repack64.repack68 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7, i64 0, i64 2
  store i64 8, ptr %loadgep_6.repack64.repack68, align 8, !tbaa !8
  %12 = load ptr, ptr %loadgep_8, align 8, !tbaa !4
  %13 = getelementptr { ptr, ptr }, ptr %loadgep_8, i64 0, i32 1
  %14 = load ptr, ptr %13, align 8, !tbaa !4
  %15 = sext i32 %6 to i64
  %16 = sext i32 %spec.select to i64
  %reass.sub9.i = sub nsw i64 %16, %15
  %17 = icmp sgt i64 %reass.sub9.i, -1
  br i1 %17, label %.lr.ph8.preheader.i, label %_QFPloop.exit

.lr.ph8.preheader.i:                              ; preds = %omp.par.entry
  %18 = add nsw i64 %reass.sub9.i, 1
  %19 = add nsw i64 %16, 2
  %20 = icmp ne i64 %18, 0
  %umin82.neg = sext i1 %20 to i64
  %21 = add nsw i64 %19, %umin82.neg
  %22 = sub nsw i64 %21, %15
  %min.iters.check = icmp ult i64 %22, 8
  br i1 %min.iters.check, label %.lr.ph8.i.preheader, label %vector.scevcheck

vector.scevcheck:                                 ; preds = %.lr.ph8.preheader.i
  %23 = add nsw i64 %16, 1
  %24 = icmp ne i64 %18, 0
  %umin.neg = sext i1 %24 to i64
  %25 = add nsw i64 %23, %umin.neg
  %26 = sub nsw i64 %25, %15
  %27 = trunc i64 %26 to i32
  %28 = add i32 %6, %27
  %29 = icmp slt i32 %28, %6
  %30 = icmp ugt i64 %26, 4294967295
  %31 = or i1 %29, %30
  br i1 %31, label %.lr.ph8.i.preheader, label %vector.memcheck

vector.memcheck:                                  ; preds = %vector.scevcheck
  %scevgep = getelementptr i8, ptr %14, i64 8
  %scevgep71 = getelementptr i8, ptr %12, i64 4
  %32 = shl nsw i64 %15, 3
  %33 = add nsw i64 %32, -8
  %scevgep72 = getelementptr i8, ptr %.unpack, i64 %33
  %34 = shl nsw i64 %16, 3
  %35 = add nsw i64 %34, 8
  %.not = icmp eq i64 %18, 0
  %36 = select i1 %.not, i64 %35, i64 %34
  %scevgep74 = getelementptr i8, ptr %.unpack, i64 %36
  %bound0 = icmp ult ptr %14, %scevgep71
  %bound1 = icmp ult ptr %12, %scevgep
  %found.conflict = and i1 %bound0, %bound1
  %bound075 = icmp ult ptr %14, %scevgep74
  %bound176 = icmp ult ptr %scevgep72, %scevgep
  %found.conflict77 = and i1 %bound075, %bound176
  %conflict.rdx = or i1 %found.conflict, %found.conflict77
  %bound078 = icmp ult ptr %12, %scevgep74
  %bound179 = icmp ult ptr %scevgep72, %scevgep71
  %found.conflict80 = and i1 %bound078, %bound179
  %conflict.rdx81 = or i1 %conflict.rdx, %found.conflict80
  br i1 %conflict.rdx81, label %.lr.ph8.i.preheader, label %vector.ph

vector.ph:                                        ; preds = %vector.memcheck
  %n.vec = and i64 %22, -2
  %ind.end = sub nsw i64 %18, %n.vec
  %.cast = trunc i64 %n.vec to i32
  %ind.end83 = add i32 %6, %.cast
  %37 = load i32, ptr %12, align 4, !tbaa !4, !alias.scope !10, !noalias !13
  %broadcast.splatinsert = insertelement <2 x i32> poison, i32 %37, i64 0
  %38 = sitofp <2 x i32> %broadcast.splatinsert to <2 x float>
  %39 = fdiv contract <2 x float> <float 1.000000e+00, float poison>, %38
  %40 = shufflevector <2 x float> %39, <2 x float> poison, <2 x i32> zeroinitializer
  %41 = fpext <2 x float> %40 to <2 x double>
  %42 = extractelement <2 x double> %41, i64 1
  store double %42, ptr %14, align 8, !tbaa !4, !alias.scope !15, !noalias !17
  br label %vector.body

vector.body:                                      ; preds = %vector.body, %vector.ph
  %index = phi i64 [ 0, %vector.ph ], [ %index.next, %vector.body ]
  %.cast85 = trunc i64 %index to i32
  %offset.idx = add i32 %6, %.cast85
  %43 = sext i32 %offset.idx to i64
  %44 = add nsw i64 %43, -1
  %45 = getelementptr double, ptr %.unpack, i64 %44
  store <2 x double> %41, ptr %45, align 8, !tbaa !4, !alias.scope !13
  %index.next = add nuw i64 %index, 2
  %46 = icmp eq i64 %index.next, %n.vec
  br i1 %46, label %middle.block, label %vector.body, !llvm.loop !18

middle.block:                                     ; preds = %vector.body
  %cmp.n = icmp eq i64 %22, %n.vec
  br i1 %cmp.n, label %_QFPloop.exit, label %.lr.ph8.i.preheader

.lr.ph8.i.preheader:                              ; preds = %vector.memcheck, %vector.scevcheck, %.lr.ph8.preheader.i, %middle.block
  %.ph = phi i64 [ %18, %vector.memcheck ], [ %18, %vector.scevcheck ], [ %18, %.lr.ph8.preheader.i ], [ %ind.end, %middle.block ]
  %.ph86 = phi i32 [ %6, %vector.memcheck ], [ %6, %vector.scevcheck ], [ %6, %.lr.ph8.preheader.i ], [ %ind.end83, %middle.block ]
  br label %.lr.ph8.i

.lr.ph8.i:                                        ; preds = %.lr.ph8.i.preheader, %.lr.ph8.i
  %47 = phi i64 [ %57, %.lr.ph8.i ], [ %.ph, %.lr.ph8.i.preheader ]
  %48 = phi i32 [ %56, %.lr.ph8.i ], [ %.ph86, %.lr.ph8.i.preheader ]
  %49 = load i32, ptr %12, align 4, !tbaa !4
  %50 = sitofp i32 %49 to float
  %51 = fdiv contract float 1.000000e+00, %50
  %52 = fpext float %51 to double
  %53 = sext i32 %48 to i64
  %54 = add nsw i64 %53, -1
  %55 = getelementptr double, ptr %.unpack, i64 %54
  store double %52, ptr %55, align 8, !tbaa !4
  store double %52, ptr %14, align 8, !tbaa !4
  %56 = add i32 %48, 1
  %57 = add nsw i64 %47, -1
  %58 = icmp ugt i64 %47, 1
  br i1 %58, label %.lr.ph8.i, label %_QFPloop.exit, !llvm.loop !21

_QFPloop.exit:                                    ; preds = %.lr.ph8.i, %middle.block, %omp.par.entry
  ret void
}

; Function Attrs: nofree norecurse nosync nounwind memory(readwrite, inaccessiblemem: none)
define void @_QFPloop(ptr nocapture readonly %0, ptr nocapture readonly %1, ptr nocapture readonly %2, ptr nest nocapture readonly %3) local_unnamed_addr #4 {
  %5 = load ptr, ptr %3, align 8, !tbaa !4
  %6 = getelementptr { ptr, ptr }, ptr %3, i64 0, i32 1
  %7 = load ptr, ptr %6, align 8, !tbaa !4
  %8 = load i32, ptr %0, align 4, !tbaa !4
  %9 = sext i32 %8 to i64
  %10 = load i32, ptr %1, align 4, !tbaa !4
  %11 = sext i32 %10 to i64
  %12 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %2, i64 0, i32 7, i64 0, i64 2
  %13 = load i64, ptr %12, align 8, !tbaa !8
  %14 = icmp eq i64 %13, 8
  br i1 %14, label %15, label %59

15:                                               ; preds = %4
  %16 = load ptr, ptr %2, align 8, !tbaa !8
  %reass.sub9 = sub nsw i64 %11, %9
  %17 = icmp sgt i64 %reass.sub9, -1
  br i1 %17, label %.lr.ph8.preheader, label %.loopexit

.lr.ph8.preheader:                                ; preds = %15
  %18 = add nsw i64 %reass.sub9, 1
  %19 = add nsw i64 %11, 2
  %20 = icmp ne i64 %18, 0
  %umin24.neg = sext i1 %20 to i64
  %21 = add nsw i64 %19, %umin24.neg
  %22 = sub nsw i64 %21, %9
  %min.iters.check = icmp ult i64 %22, 8
  br i1 %min.iters.check, label %.lr.ph8.preheader28, label %vector.scevcheck

vector.scevcheck:                                 ; preds = %.lr.ph8.preheader
  %23 = add nsw i64 %11, 1
  %24 = icmp ne i64 %18, 0
  %umin.neg = sext i1 %24 to i64
  %25 = add nsw i64 %23, %umin.neg
  %26 = sub nsw i64 %25, %9
  %27 = trunc i64 %26 to i32
  %28 = add i32 %8, %27
  %29 = icmp slt i32 %28, %8
  %30 = icmp ugt i64 %26, 4294967295
  %31 = or i1 %29, %30
  br i1 %31, label %.lr.ph8.preheader28, label %vector.memcheck

vector.memcheck:                                  ; preds = %vector.scevcheck
  %scevgep = getelementptr i8, ptr %7, i64 8
  %scevgep13 = getelementptr i8, ptr %5, i64 4
  %32 = shl nsw i64 %9, 3
  %33 = add nsw i64 %32, -8
  %scevgep14 = getelementptr i8, ptr %16, i64 %33
  %34 = shl nsw i64 %11, 3
  %35 = add nsw i64 %34, 8
  %.not = icmp eq i64 %18, 0
  %36 = select i1 %.not, i64 %35, i64 %34
  %scevgep16 = getelementptr i8, ptr %16, i64 %36
  %bound0 = icmp ult ptr %7, %scevgep13
  %bound1 = icmp ult ptr %5, %scevgep
  %found.conflict = and i1 %bound0, %bound1
  %bound017 = icmp ult ptr %7, %scevgep16
  %bound118 = icmp ult ptr %scevgep14, %scevgep
  %found.conflict19 = and i1 %bound017, %bound118
  %conflict.rdx = or i1 %found.conflict, %found.conflict19
  %bound020 = icmp ult ptr %5, %scevgep16
  %bound121 = icmp ult ptr %scevgep14, %scevgep13
  %found.conflict22 = and i1 %bound020, %bound121
  %conflict.rdx23 = or i1 %conflict.rdx, %found.conflict22
  br i1 %conflict.rdx23, label %.lr.ph8.preheader28, label %vector.ph

vector.ph:                                        ; preds = %vector.memcheck
  %n.vec = and i64 %22, -2
  %ind.end = sub nsw i64 %18, %n.vec
  %.cast = trunc i64 %n.vec to i32
  %ind.end25 = add i32 %8, %.cast
  %37 = load i32, ptr %5, align 4, !tbaa !4, !alias.scope !22, !noalias !25
  %broadcast.splatinsert = insertelement <2 x i32> poison, i32 %37, i64 0
  %38 = sitofp <2 x i32> %broadcast.splatinsert to <2 x float>
  %39 = fdiv contract <2 x float> <float 1.000000e+00, float poison>, %38
  %40 = shufflevector <2 x float> %39, <2 x float> poison, <2 x i32> zeroinitializer
  %41 = fpext <2 x float> %40 to <2 x double>
  %42 = extractelement <2 x double> %41, i64 1
  store double %42, ptr %7, align 8, !tbaa !4, !alias.scope !27, !noalias !29
  br label %vector.body

vector.body:                                      ; preds = %vector.body, %vector.ph
  %index = phi i64 [ 0, %vector.ph ], [ %index.next, %vector.body ]
  %.cast27 = trunc i64 %index to i32
  %offset.idx = add i32 %8, %.cast27
  %43 = sext i32 %offset.idx to i64
  %44 = add nsw i64 %43, -1
  %45 = getelementptr double, ptr %16, i64 %44
  store <2 x double> %41, ptr %45, align 8, !tbaa !4, !alias.scope !25
  %index.next = add nuw i64 %index, 2
  %46 = icmp eq i64 %index.next, %n.vec
  br i1 %46, label %middle.block, label %vector.body, !llvm.loop !30

middle.block:                                     ; preds = %vector.body
  %cmp.n = icmp eq i64 %22, %n.vec
  br i1 %cmp.n, label %.loopexit, label %.lr.ph8.preheader28

.lr.ph8.preheader28:                              ; preds = %vector.memcheck, %vector.scevcheck, %.lr.ph8.preheader, %middle.block
  %.ph = phi i64 [ %18, %vector.memcheck ], [ %18, %vector.scevcheck ], [ %18, %.lr.ph8.preheader ], [ %ind.end, %middle.block ]
  %.ph29 = phi i32 [ %8, %vector.memcheck ], [ %8, %vector.scevcheck ], [ %8, %.lr.ph8.preheader ], [ %ind.end25, %middle.block ]
  br label %.lr.ph8

.lr.ph8:                                          ; preds = %.lr.ph8.preheader28, %.lr.ph8
  %47 = phi i64 [ %57, %.lr.ph8 ], [ %.ph, %.lr.ph8.preheader28 ]
  %48 = phi i32 [ %56, %.lr.ph8 ], [ %.ph29, %.lr.ph8.preheader28 ]
  %49 = load i32, ptr %5, align 4, !tbaa !4
  %50 = sitofp i32 %49 to float
  %51 = fdiv contract float 1.000000e+00, %50
  %52 = fpext float %51 to double
  %53 = sext i32 %48 to i64
  %54 = add nsw i64 %53, -1
  %55 = getelementptr double, ptr %16, i64 %54
  store double %52, ptr %55, align 8, !tbaa !4
  store double %52, ptr %7, align 8, !tbaa !4
  %56 = add i32 %48, 1
  %57 = add nsw i64 %47, -1
  %58 = icmp ugt i64 %47, 1
  br i1 %58, label %.lr.ph8, label %.loopexit, !llvm.loop !31

59:                                               ; preds = %4
  %reass.sub = sub nsw i64 %11, %9
  %60 = icmp sgt i64 %reass.sub, -1
  br i1 %60, label %.lr.ph, label %.loopexit

.lr.ph:                                           ; preds = %59
  %61 = add nuw nsw i64 %reass.sub, 1
  %62 = load ptr, ptr %2, align 8, !tbaa !8
  br label %63

63:                                               ; preds = %.lr.ph, %63
  %64 = phi i64 [ %61, %.lr.ph ], [ %75, %63 ]
  %65 = phi i32 [ %8, %.lr.ph ], [ %74, %63 ]
  %66 = load i32, ptr %5, align 4, !tbaa !4
  %67 = sitofp i32 %66 to float
  %68 = fdiv contract float 1.000000e+00, %67
  %69 = fpext float %68 to double
  %70 = sext i32 %65 to i64
  %71 = add nsw i64 %70, -1
  %72 = mul i64 %71, %13
  %73 = getelementptr i8, ptr %62, i64 %72
  store double %69, ptr %73, align 8, !tbaa !4
  store double %69, ptr %7, align 8, !tbaa !4
  %74 = add i32 %65, 1
  %75 = add nsw i64 %64, -1
  %76 = icmp ugt i64 %64, 1
  br i1 %76, label %63, label %.loopexit

.loopexit:                                        ; preds = %63, %.lr.ph8, %middle.block, %59, %15
  ret void
}

declare ptr @_FortranAioBeginExternalFormattedOutput(ptr, i64, ptr, i32, ptr, i32) local_unnamed_addr

declare zeroext i1 @_FortranAioOutputAscii(ptr, ptr, i64) local_unnamed_addr

declare zeroext i1 @_FortranAioOutputInteger32(ptr, i32) local_unnamed_addr

declare zeroext i1 @_FortranAioOutputReal64(ptr, double) local_unnamed_addr

declare i32 @_FortranAioEndIoStatement(ptr) local_unnamed_addr

; Function Attrs: nounwind
declare i32 @omp_get_thread_num() local_unnamed_addr #2

; Function Attrs: nounwind
declare i32 @omp_get_num_threads() local_unnamed_addr #2

; Function Attrs: nounwind
declare i32 @__kmpc_global_thread_num(ptr) local_unnamed_addr #2

; Function Attrs: nounwind
declare !callback !32 void @__kmpc_fork_call(ptr, i32, ptr, ...) local_unnamed_addr #2

; Function Attrs: nocallback nofree nosync nounwind speculatable willreturn memory(none)
declare i32 @llvm.smax.i32(i32, i32) #5

; Function Attrs: nocallback nofree nosync nounwind willreturn memory(argmem: readwrite)
declare void @llvm.lifetime.start.p0(i64 immarg, ptr nocapture) #6

; Function Attrs: nocallback nofree nosync nounwind willreturn memory(argmem: readwrite)
declare void @llvm.lifetime.end.p0(i64 immarg, ptr nocapture) #6

attributes #0 = { mustprogress nofree nounwind willreturn allockind("alloc,uninitialized") allocsize(0) memory(inaccessiblemem: readwrite) "alloc-family"="malloc" }
attributes #1 = { mustprogress nounwind willreturn allockind("free") memory(argmem: readwrite, inaccessiblemem: readwrite) "alloc-family"="malloc" }
attributes #2 = { nounwind }
attributes #3 = { norecurse nounwind }
attributes #4 = { nofree norecurse nosync nounwind memory(readwrite, inaccessiblemem: none) }
attributes #5 = { nocallback nofree nosync nounwind speculatable willreturn memory(none) }
attributes #6 = { nocallback nofree nosync nounwind willreturn memory(argmem: readwrite) }

!llvm.module.flags = !{!0, !1, !2, !3}

!0 = !{i32 2, !"Debug Info Version", i32 3}
!1 = !{i32 7, !"openmp", i32 11}
!2 = !{i32 8, !"PIC Level", i32 2}
!3 = !{i32 7, !"PIE Level", i32 2}
!4 = !{!5, !5, i64 0}
!5 = !{!"any data access", !6, i64 0}
!6 = !{!"any access", !7, i64 0}
!7 = !{!"Flang Type TBAA Root"}
!8 = !{!9, !9, i64 0}
!9 = !{!"descriptor member", !6, i64 0}
!10 = !{!11}
!11 = distinct !{!11, !12}
!12 = distinct !{!12, !"LVerDomain"}
!13 = !{!14}
!14 = distinct !{!14, !12}
!15 = !{!16}
!16 = distinct !{!16, !12}
!17 = !{!11, !14}
!18 = distinct !{!18, !19, !20}
!19 = !{!"llvm.loop.isvectorized", i32 1}
!20 = !{!"llvm.loop.unroll.runtime.disable"}
!21 = distinct !{!21, !19}
!22 = !{!23}
!23 = distinct !{!23, !24}
!24 = distinct !{!24, !"LVerDomain"}
!25 = !{!26}
!26 = distinct !{!26, !24}
!27 = !{!28}
!28 = distinct !{!28, !24}
!29 = !{!23, !26}
!30 = distinct !{!30, !19, !20}
!31 = distinct !{!31, !19}
!32 = !{!33}
!33 = !{i64 2, i64 -1, i64 -1, i1 true}
*** IR Dump After ConstantMergePass on [module] ***
; ModuleID = 'FIRModule'
source_filename = "FIRModule"
target datalayout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128"
target triple = "x86_64-unknown-linux-gnu"

%struct.ident_t = type { i32, i32, i32, i32, ptr }

@_QQcl.28612C69372C612C6531332E36653229 = internal constant [16 x i8] c"(a,i7,a,e13.6e2)"
@_QQcl.e8a0ac9186c064ac8543d822e9060d96 = internal constant [59 x i8] c"/g/g92/rydahl1/flangtests/src/parallel_region_outlined.f90\00"
@_QQcl.54686520726573756C74206F6620286172722831292B61727228 = internal constant [26 x i8] c"The result of (arr(1)+arr("
@_QQcl.2920697320 = internal constant [5 x i8] c") is "
@_QQEnvironmentDefaults = local_unnamed_addr constant ptr null
@0 = private unnamed_addr constant [23 x i8] c";unknown;unknown;0;0;;\00", align 1
@1 = private unnamed_addr constant %struct.ident_t { i32 0, i32 2, i32 0, i32 22, ptr @0 }, align 8

; Function Attrs: mustprogress nofree nounwind willreturn allockind("alloc,uninitialized") allocsize(0) memory(inaccessiblemem: readwrite)
declare noalias noundef ptr @malloc(i64 noundef) local_unnamed_addr #0

; Function Attrs: mustprogress nounwind willreturn allockind("free") memory(argmem: readwrite, inaccessiblemem: readwrite)
declare void @free(ptr allocptr nocapture noundef) local_unnamed_addr #1

define void @_QQmain() local_unnamed_addr {
  %structArg.i = alloca { ptr, ptr, ptr, ptr, ptr }, align 8
  %1 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %2 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %3 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %4 = alloca i32, align 4
  %5 = alloca double, align 8
  %6 = alloca { ptr, ptr }, align 8
  store ptr %4, ptr %6, align 8, !tbaa !4
  %7 = getelementptr inbounds { ptr, ptr }, ptr %6, i64 0, i32 1
  store ptr %5, ptr %7, align 8, !tbaa !4
  store i32 1048576, ptr %4, align 4, !tbaa !4
  call void @llvm.lifetime.start.p0(i64 40, ptr nonnull %structArg.i)
  call void @llvm.lifetime.start.p0(i64 48, ptr nonnull %1)
  call void @llvm.lifetime.start.p0(i64 48, ptr nonnull %2)
  call void @llvm.lifetime.start.p0(i64 48, ptr nonnull %3)
  %.fca.1.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 1
  %.fca.2.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 2
  %.fca.3.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 3
  %.fca.4.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 4
  %.fca.5.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 5
  %.fca.6.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 6
  %.fca.7.0.0.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 7, i64 0, i64 0
  %.fca.7.0.1.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 7, i64 0, i64 1
  %.fca.7.0.2.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 7, i64 0, i64 2
  %8 = call dereferenceable_or_null(8388608) ptr @malloc(i64 8388608)
  store ptr %8, ptr %3, align 8, !tbaa !8
  store i64 8, ptr %.fca.1.gep.i, align 8, !tbaa !8
  store i32 20180515, ptr %.fca.2.gep.i, align 8, !tbaa !8
  store i8 1, ptr %.fca.3.gep.i, align 4, !tbaa !8
  store i8 28, ptr %.fca.4.gep.i, align 1, !tbaa !8
  store i8 2, ptr %.fca.5.gep.i, align 2, !tbaa !8
  store i8 0, ptr %.fca.6.gep.i, align 1, !tbaa !8
  store i64 1, ptr %.fca.7.0.0.gep.i, align 8, !tbaa !8
  store i64 1048576, ptr %.fca.7.0.1.gep.i, align 8, !tbaa !8
  store i64 8, ptr %.fca.7.0.2.gep.i, align 8, !tbaa !8
  %omp_global_thread_num.i = call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %4, ptr %structArg.i, align 8
  %gep_5.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 1
  store ptr %3, ptr %gep_5.i, align 8
  %gep_6.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 2
  store ptr %2, ptr %gep_6.i, align 8
  %gep_7.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 3
  store ptr %1, ptr %gep_7.i, align 8
  %gep_8.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 4
  store ptr %6, ptr %gep_8.i, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QFPomp_subroutine..omp_par, ptr nonnull %structArg.i)
  %.fca.0.load.i = load ptr, ptr %3, align 8, !tbaa !8
  %.fca.7.0.0.load.i = load i64, ptr %.fca.7.0.0.gep.i, align 8, !tbaa !8
  %9 = sub i64 1, %.fca.7.0.0.load.i
  %10 = getelementptr double, ptr %.fca.0.load.i, i64 %9
  %11 = load double, ptr %10, align 8, !tbaa !4
  %12 = load i32, ptr %4, align 4, !tbaa !4
  %13 = sext i32 %12 to i64
  %14 = sub i64 %13, %.fca.7.0.0.load.i
  %15 = getelementptr double, ptr %.fca.0.load.i, i64 %14
  %16 = load double, ptr %15, align 8, !tbaa !4
  %17 = fadd contract double %11, %16
  call void @free(ptr %.fca.0.load.i)
  call void @llvm.lifetime.end.p0(i64 40, ptr nonnull %structArg.i)
  call void @llvm.lifetime.end.p0(i64 48, ptr nonnull %1)
  call void @llvm.lifetime.end.p0(i64 48, ptr nonnull %2)
  call void @llvm.lifetime.end.p0(i64 48, ptr nonnull %3)
  %18 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.e8a0ac9186c064ac8543d822e9060d96, i32 10)
  %19 = call i1 @_FortranAioOutputAscii(ptr %18, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %20 = load i32, ptr %4, align 4, !tbaa !4
  %21 = call i1 @_FortranAioOutputInteger32(ptr %18, i32 %20)
  %22 = call i1 @_FortranAioOutputAscii(ptr %18, ptr nonnull @_QQcl.2920697320, i64 5)
  %23 = call i1 @_FortranAioOutputReal64(ptr %18, double %17)
  %24 = call i32 @_FortranAioEndIoStatement(ptr %18)
  ret void
}

; Function Attrs: nounwind
define void @_QFPomp_subroutine(ptr %0, ptr nocapture writeonly %1, ptr nest %2) local_unnamed_addr #2 {
entry:
  %structArg = alloca { ptr, ptr, ptr, ptr, ptr }, align 8
  %3 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %4 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %5 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %.fca.1.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 1
  %.fca.2.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 2
  %.fca.3.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 3
  %.fca.4.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 4
  %.fca.5.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 5
  %.fca.6.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 6
  %.fca.7.0.0.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 0
  %.fca.7.0.1.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 1
  %.fca.7.0.2.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 2
  %6 = load i32, ptr %0, align 4, !tbaa !4
  %7 = tail call i32 @llvm.smax.i32(i32 %6, i32 0)
  %8 = zext i32 %7 to i64
  %9 = shl nuw nsw i64 %8, 3
  %10 = tail call ptr @malloc(i64 %9)
  store ptr %10, ptr %5, align 8, !tbaa !8
  store i64 8, ptr %.fca.1.gep, align 8, !tbaa !8
  store i32 20180515, ptr %.fca.2.gep, align 8, !tbaa !8
  store i8 1, ptr %.fca.3.gep, align 4, !tbaa !8
  store i8 28, ptr %.fca.4.gep, align 1, !tbaa !8
  store i8 2, ptr %.fca.5.gep, align 2, !tbaa !8
  store i8 0, ptr %.fca.6.gep, align 1, !tbaa !8
  store i64 1, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  store i64 %8, ptr %.fca.7.0.1.gep, align 8, !tbaa !8
  store i64 8, ptr %.fca.7.0.2.gep, align 8, !tbaa !8
  %omp_global_thread_num = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %0, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %5, ptr %gep_5, align 8
  %gep_6 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 2
  store ptr %4, ptr %gep_6, align 8
  %gep_7 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 3
  store ptr %3, ptr %gep_7, align 8
  %gep_8 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 4
  store ptr %2, ptr %gep_8, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QFPomp_subroutine..omp_par, ptr nonnull %structArg)
  %.fca.0.load = load ptr, ptr %5, align 8, !tbaa !8
  %.fca.7.0.0.load = load i64, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  %11 = sub i64 1, %.fca.7.0.0.load
  %12 = getelementptr double, ptr %.fca.0.load, i64 %11
  %13 = load double, ptr %12, align 8, !tbaa !4
  %14 = load i32, ptr %0, align 4, !tbaa !4
  %15 = sext i32 %14 to i64
  %16 = sub i64 %15, %.fca.7.0.0.load
  %17 = getelementptr double, ptr %.fca.0.load, i64 %16
  %18 = load double, ptr %17, align 8, !tbaa !4
  %19 = fadd contract double %13, %18
  store double %19, ptr %1, align 8, !tbaa !4
  call void @free(ptr %.fca.0.load)
  ret void
}

; Function Attrs: norecurse nounwind
define internal void @_QFPomp_subroutine..omp_par(ptr noalias nocapture readnone %tid.addr, ptr noalias nocapture readnone %zero.addr, ptr nocapture readonly %0) #3 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %gep_3 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 2
  %loadgep_4 = load ptr, ptr %gep_3, align 8
  %gep_5 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 3
  %loadgep_6 = load ptr, ptr %gep_5, align 8
  %gep_7 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 4
  %loadgep_8 = load ptr, ptr %gep_7, align 8
  %1 = tail call i32 @omp_get_thread_num()
  %2 = tail call i32 @omp_get_num_threads()
  %3 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %4 = sdiv i32 %3, %2
  %5 = mul i32 %4, %1
  %6 = add i32 %5, 1
  %7 = add i32 %2, -1
  %8 = icmp eq i32 %1, %7
  %9 = add i32 %6, %4
  %spec.select = select i1 %8, i32 %3, i32 %9
  %.unpack = load ptr, ptr %loadgep_2, align 8, !tbaa !8
  %.elt14 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  %.unpack15 = load i64, ptr %.elt14, align 8, !tbaa !8
  %.elt16 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  %.unpack17 = load i32, ptr %.elt16, align 8, !tbaa !8
  %.elt18 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  %.unpack19 = load i8, ptr %.elt18, align 4, !tbaa !8
  %.elt20 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  %.unpack21 = load i8, ptr %.elt20, align 1, !tbaa !8
  %.elt22 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  %.unpack23 = load i8, ptr %.elt22, align 2, !tbaa !8
  %.elt24 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  %.unpack25 = load i8, ptr %.elt24, align 1, !tbaa !8
  %.elt26 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  %.unpack27.unpack.unpack = load i64, ptr %.elt26, align 8, !tbaa !8
  %.unpack27.unpack.elt29 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  %.unpack27.unpack.unpack30 = load i64, ptr %.unpack27.unpack.elt29, align 8, !tbaa !8
  %.unpack27.unpack.elt31 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  %.unpack27.unpack.unpack32 = load i64, ptr %.unpack27.unpack.elt31, align 8, !tbaa !8
  store ptr %.unpack, ptr %loadgep_4, align 8, !tbaa !8
  %loadgep_4.repack34 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 1
  store i64 %.unpack15, ptr %loadgep_4.repack34, align 8, !tbaa !8
  %loadgep_4.repack36 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 2
  store i32 %.unpack17, ptr %loadgep_4.repack36, align 8, !tbaa !8
  %loadgep_4.repack38 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 3
  store i8 %.unpack19, ptr %loadgep_4.repack38, align 4, !tbaa !8
  %loadgep_4.repack40 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 4
  store i8 %.unpack21, ptr %loadgep_4.repack40, align 1, !tbaa !8
  %loadgep_4.repack42 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 5
  store i8 %.unpack23, ptr %loadgep_4.repack42, align 2, !tbaa !8
  %loadgep_4.repack44 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 6
  store i8 %.unpack25, ptr %loadgep_4.repack44, align 1, !tbaa !8
  %loadgep_4.repack46 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7
  store i64 %.unpack27.unpack.unpack, ptr %loadgep_4.repack46, align 8, !tbaa !8
  %loadgep_4.repack46.repack48 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack27.unpack.unpack30, ptr %loadgep_4.repack46.repack48, align 8, !tbaa !8
  %loadgep_4.repack46.repack50 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 2
  store i64 %.unpack27.unpack.unpack32, ptr %loadgep_4.repack46.repack50, align 8, !tbaa !8
  %10 = icmp eq i64 %.unpack27.unpack.unpack30, 0
  %11 = select i1 %10, i64 1, i64 %.unpack27.unpack.unpack
  store ptr %.unpack, ptr %loadgep_6, align 8, !tbaa !8
  %loadgep_6.repack52 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 1
  store i64 8, ptr %loadgep_6.repack52, align 8, !tbaa !8
  %loadgep_6.repack54 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 2
  store i32 20180515, ptr %loadgep_6.repack54, align 8, !tbaa !8
  %loadgep_6.repack56 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 3
  store i8 1, ptr %loadgep_6.repack56, align 4, !tbaa !8
  %loadgep_6.repack58 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 4
  store i8 28, ptr %loadgep_6.repack58, align 1, !tbaa !8
  %loadgep_6.repack60 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 5
  store i8 0, ptr %loadgep_6.repack60, align 2, !tbaa !8
  %loadgep_6.repack62 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 6
  store i8 0, ptr %loadgep_6.repack62, align 1, !tbaa !8
  %loadgep_6.repack64 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7
  store i64 %11, ptr %loadgep_6.repack64, align 8, !tbaa !8
  %loadgep_6.repack64.repack66 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack27.unpack.unpack30, ptr %loadgep_6.repack64.repack66, align 8, !tbaa !8
  %loadgep_6.repack64.repack68 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7, i64 0, i64 2
  store i64 8, ptr %loadgep_6.repack64.repack68, align 8, !tbaa !8
  %12 = load ptr, ptr %loadgep_8, align 8, !tbaa !4
  %13 = getelementptr { ptr, ptr }, ptr %loadgep_8, i64 0, i32 1
  %14 = load ptr, ptr %13, align 8, !tbaa !4
  %15 = sext i32 %6 to i64
  %16 = sext i32 %spec.select to i64
  %reass.sub9.i = sub nsw i64 %16, %15
  %17 = icmp sgt i64 %reass.sub9.i, -1
  br i1 %17, label %.lr.ph8.preheader.i, label %_QFPloop.exit

.lr.ph8.preheader.i:                              ; preds = %omp.par.entry
  %18 = add nsw i64 %reass.sub9.i, 1
  %19 = add nsw i64 %16, 2
  %20 = icmp ne i64 %18, 0
  %umin82.neg = sext i1 %20 to i64
  %21 = add nsw i64 %19, %umin82.neg
  %22 = sub nsw i64 %21, %15
  %min.iters.check = icmp ult i64 %22, 8
  br i1 %min.iters.check, label %.lr.ph8.i.preheader, label %vector.scevcheck

vector.scevcheck:                                 ; preds = %.lr.ph8.preheader.i
  %23 = add nsw i64 %16, 1
  %24 = icmp ne i64 %18, 0
  %umin.neg = sext i1 %24 to i64
  %25 = add nsw i64 %23, %umin.neg
  %26 = sub nsw i64 %25, %15
  %27 = trunc i64 %26 to i32
  %28 = add i32 %6, %27
  %29 = icmp slt i32 %28, %6
  %30 = icmp ugt i64 %26, 4294967295
  %31 = or i1 %29, %30
  br i1 %31, label %.lr.ph8.i.preheader, label %vector.memcheck

vector.memcheck:                                  ; preds = %vector.scevcheck
  %scevgep = getelementptr i8, ptr %14, i64 8
  %scevgep71 = getelementptr i8, ptr %12, i64 4
  %32 = shl nsw i64 %15, 3
  %33 = add nsw i64 %32, -8
  %scevgep72 = getelementptr i8, ptr %.unpack, i64 %33
  %34 = shl nsw i64 %16, 3
  %35 = add nsw i64 %34, 8
  %.not = icmp eq i64 %18, 0
  %36 = select i1 %.not, i64 %35, i64 %34
  %scevgep74 = getelementptr i8, ptr %.unpack, i64 %36
  %bound0 = icmp ult ptr %14, %scevgep71
  %bound1 = icmp ult ptr %12, %scevgep
  %found.conflict = and i1 %bound0, %bound1
  %bound075 = icmp ult ptr %14, %scevgep74
  %bound176 = icmp ult ptr %scevgep72, %scevgep
  %found.conflict77 = and i1 %bound075, %bound176
  %conflict.rdx = or i1 %found.conflict, %found.conflict77
  %bound078 = icmp ult ptr %12, %scevgep74
  %bound179 = icmp ult ptr %scevgep72, %scevgep71
  %found.conflict80 = and i1 %bound078, %bound179
  %conflict.rdx81 = or i1 %conflict.rdx, %found.conflict80
  br i1 %conflict.rdx81, label %.lr.ph8.i.preheader, label %vector.ph

vector.ph:                                        ; preds = %vector.memcheck
  %n.vec = and i64 %22, -2
  %ind.end = sub nsw i64 %18, %n.vec
  %.cast = trunc i64 %n.vec to i32
  %ind.end83 = add i32 %6, %.cast
  %37 = load i32, ptr %12, align 4, !tbaa !4, !alias.scope !10, !noalias !13
  %broadcast.splatinsert = insertelement <2 x i32> poison, i32 %37, i64 0
  %38 = sitofp <2 x i32> %broadcast.splatinsert to <2 x float>
  %39 = fdiv contract <2 x float> <float 1.000000e+00, float poison>, %38
  %40 = shufflevector <2 x float> %39, <2 x float> poison, <2 x i32> zeroinitializer
  %41 = fpext <2 x float> %40 to <2 x double>
  %42 = extractelement <2 x double> %41, i64 1
  store double %42, ptr %14, align 8, !tbaa !4, !alias.scope !15, !noalias !17
  br label %vector.body

vector.body:                                      ; preds = %vector.body, %vector.ph
  %index = phi i64 [ 0, %vector.ph ], [ %index.next, %vector.body ]
  %.cast85 = trunc i64 %index to i32
  %offset.idx = add i32 %6, %.cast85
  %43 = sext i32 %offset.idx to i64
  %44 = add nsw i64 %43, -1
  %45 = getelementptr double, ptr %.unpack, i64 %44
  store <2 x double> %41, ptr %45, align 8, !tbaa !4, !alias.scope !13
  %index.next = add nuw i64 %index, 2
  %46 = icmp eq i64 %index.next, %n.vec
  br i1 %46, label %middle.block, label %vector.body, !llvm.loop !18

middle.block:                                     ; preds = %vector.body
  %cmp.n = icmp eq i64 %22, %n.vec
  br i1 %cmp.n, label %_QFPloop.exit, label %.lr.ph8.i.preheader

.lr.ph8.i.preheader:                              ; preds = %vector.memcheck, %vector.scevcheck, %.lr.ph8.preheader.i, %middle.block
  %.ph = phi i64 [ %18, %vector.memcheck ], [ %18, %vector.scevcheck ], [ %18, %.lr.ph8.preheader.i ], [ %ind.end, %middle.block ]
  %.ph86 = phi i32 [ %6, %vector.memcheck ], [ %6, %vector.scevcheck ], [ %6, %.lr.ph8.preheader.i ], [ %ind.end83, %middle.block ]
  br label %.lr.ph8.i

.lr.ph8.i:                                        ; preds = %.lr.ph8.i.preheader, %.lr.ph8.i
  %47 = phi i64 [ %57, %.lr.ph8.i ], [ %.ph, %.lr.ph8.i.preheader ]
  %48 = phi i32 [ %56, %.lr.ph8.i ], [ %.ph86, %.lr.ph8.i.preheader ]
  %49 = load i32, ptr %12, align 4, !tbaa !4
  %50 = sitofp i32 %49 to float
  %51 = fdiv contract float 1.000000e+00, %50
  %52 = fpext float %51 to double
  %53 = sext i32 %48 to i64
  %54 = add nsw i64 %53, -1
  %55 = getelementptr double, ptr %.unpack, i64 %54
  store double %52, ptr %55, align 8, !tbaa !4
  store double %52, ptr %14, align 8, !tbaa !4
  %56 = add i32 %48, 1
  %57 = add nsw i64 %47, -1
  %58 = icmp ugt i64 %47, 1
  br i1 %58, label %.lr.ph8.i, label %_QFPloop.exit, !llvm.loop !21

_QFPloop.exit:                                    ; preds = %.lr.ph8.i, %middle.block, %omp.par.entry
  ret void
}

; Function Attrs: nofree norecurse nosync nounwind memory(readwrite, inaccessiblemem: none)
define void @_QFPloop(ptr nocapture readonly %0, ptr nocapture readonly %1, ptr nocapture readonly %2, ptr nest nocapture readonly %3) local_unnamed_addr #4 {
  %5 = load ptr, ptr %3, align 8, !tbaa !4
  %6 = getelementptr { ptr, ptr }, ptr %3, i64 0, i32 1
  %7 = load ptr, ptr %6, align 8, !tbaa !4
  %8 = load i32, ptr %0, align 4, !tbaa !4
  %9 = sext i32 %8 to i64
  %10 = load i32, ptr %1, align 4, !tbaa !4
  %11 = sext i32 %10 to i64
  %12 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %2, i64 0, i32 7, i64 0, i64 2
  %13 = load i64, ptr %12, align 8, !tbaa !8
  %14 = icmp eq i64 %13, 8
  br i1 %14, label %15, label %59

15:                                               ; preds = %4
  %16 = load ptr, ptr %2, align 8, !tbaa !8
  %reass.sub9 = sub nsw i64 %11, %9
  %17 = icmp sgt i64 %reass.sub9, -1
  br i1 %17, label %.lr.ph8.preheader, label %.loopexit

.lr.ph8.preheader:                                ; preds = %15
  %18 = add nsw i64 %reass.sub9, 1
  %19 = add nsw i64 %11, 2
  %20 = icmp ne i64 %18, 0
  %umin24.neg = sext i1 %20 to i64
  %21 = add nsw i64 %19, %umin24.neg
  %22 = sub nsw i64 %21, %9
  %min.iters.check = icmp ult i64 %22, 8
  br i1 %min.iters.check, label %.lr.ph8.preheader28, label %vector.scevcheck

vector.scevcheck:                                 ; preds = %.lr.ph8.preheader
  %23 = add nsw i64 %11, 1
  %24 = icmp ne i64 %18, 0
  %umin.neg = sext i1 %24 to i64
  %25 = add nsw i64 %23, %umin.neg
  %26 = sub nsw i64 %25, %9
  %27 = trunc i64 %26 to i32
  %28 = add i32 %8, %27
  %29 = icmp slt i32 %28, %8
  %30 = icmp ugt i64 %26, 4294967295
  %31 = or i1 %29, %30
  br i1 %31, label %.lr.ph8.preheader28, label %vector.memcheck

vector.memcheck:                                  ; preds = %vector.scevcheck
  %scevgep = getelementptr i8, ptr %7, i64 8
  %scevgep13 = getelementptr i8, ptr %5, i64 4
  %32 = shl nsw i64 %9, 3
  %33 = add nsw i64 %32, -8
  %scevgep14 = getelementptr i8, ptr %16, i64 %33
  %34 = shl nsw i64 %11, 3
  %35 = add nsw i64 %34, 8
  %.not = icmp eq i64 %18, 0
  %36 = select i1 %.not, i64 %35, i64 %34
  %scevgep16 = getelementptr i8, ptr %16, i64 %36
  %bound0 = icmp ult ptr %7, %scevgep13
  %bound1 = icmp ult ptr %5, %scevgep
  %found.conflict = and i1 %bound0, %bound1
  %bound017 = icmp ult ptr %7, %scevgep16
  %bound118 = icmp ult ptr %scevgep14, %scevgep
  %found.conflict19 = and i1 %bound017, %bound118
  %conflict.rdx = or i1 %found.conflict, %found.conflict19
  %bound020 = icmp ult ptr %5, %scevgep16
  %bound121 = icmp ult ptr %scevgep14, %scevgep13
  %found.conflict22 = and i1 %bound020, %bound121
  %conflict.rdx23 = or i1 %conflict.rdx, %found.conflict22
  br i1 %conflict.rdx23, label %.lr.ph8.preheader28, label %vector.ph

vector.ph:                                        ; preds = %vector.memcheck
  %n.vec = and i64 %22, -2
  %ind.end = sub nsw i64 %18, %n.vec
  %.cast = trunc i64 %n.vec to i32
  %ind.end25 = add i32 %8, %.cast
  %37 = load i32, ptr %5, align 4, !tbaa !4, !alias.scope !22, !noalias !25
  %broadcast.splatinsert = insertelement <2 x i32> poison, i32 %37, i64 0
  %38 = sitofp <2 x i32> %broadcast.splatinsert to <2 x float>
  %39 = fdiv contract <2 x float> <float 1.000000e+00, float poison>, %38
  %40 = shufflevector <2 x float> %39, <2 x float> poison, <2 x i32> zeroinitializer
  %41 = fpext <2 x float> %40 to <2 x double>
  %42 = extractelement <2 x double> %41, i64 1
  store double %42, ptr %7, align 8, !tbaa !4, !alias.scope !27, !noalias !29
  br label %vector.body

vector.body:                                      ; preds = %vector.body, %vector.ph
  %index = phi i64 [ 0, %vector.ph ], [ %index.next, %vector.body ]
  %.cast27 = trunc i64 %index to i32
  %offset.idx = add i32 %8, %.cast27
  %43 = sext i32 %offset.idx to i64
  %44 = add nsw i64 %43, -1
  %45 = getelementptr double, ptr %16, i64 %44
  store <2 x double> %41, ptr %45, align 8, !tbaa !4, !alias.scope !25
  %index.next = add nuw i64 %index, 2
  %46 = icmp eq i64 %index.next, %n.vec
  br i1 %46, label %middle.block, label %vector.body, !llvm.loop !30

middle.block:                                     ; preds = %vector.body
  %cmp.n = icmp eq i64 %22, %n.vec
  br i1 %cmp.n, label %.loopexit, label %.lr.ph8.preheader28

.lr.ph8.preheader28:                              ; preds = %vector.memcheck, %vector.scevcheck, %.lr.ph8.preheader, %middle.block
  %.ph = phi i64 [ %18, %vector.memcheck ], [ %18, %vector.scevcheck ], [ %18, %.lr.ph8.preheader ], [ %ind.end, %middle.block ]
  %.ph29 = phi i32 [ %8, %vector.memcheck ], [ %8, %vector.scevcheck ], [ %8, %.lr.ph8.preheader ], [ %ind.end25, %middle.block ]
  br label %.lr.ph8

.lr.ph8:                                          ; preds = %.lr.ph8.preheader28, %.lr.ph8
  %47 = phi i64 [ %57, %.lr.ph8 ], [ %.ph, %.lr.ph8.preheader28 ]
  %48 = phi i32 [ %56, %.lr.ph8 ], [ %.ph29, %.lr.ph8.preheader28 ]
  %49 = load i32, ptr %5, align 4, !tbaa !4
  %50 = sitofp i32 %49 to float
  %51 = fdiv contract float 1.000000e+00, %50
  %52 = fpext float %51 to double
  %53 = sext i32 %48 to i64
  %54 = add nsw i64 %53, -1
  %55 = getelementptr double, ptr %16, i64 %54
  store double %52, ptr %55, align 8, !tbaa !4
  store double %52, ptr %7, align 8, !tbaa !4
  %56 = add i32 %48, 1
  %57 = add nsw i64 %47, -1
  %58 = icmp ugt i64 %47, 1
  br i1 %58, label %.lr.ph8, label %.loopexit, !llvm.loop !31

59:                                               ; preds = %4
  %reass.sub = sub nsw i64 %11, %9
  %60 = icmp sgt i64 %reass.sub, -1
  br i1 %60, label %.lr.ph, label %.loopexit

.lr.ph:                                           ; preds = %59
  %61 = add nuw nsw i64 %reass.sub, 1
  %62 = load ptr, ptr %2, align 8, !tbaa !8
  br label %63

63:                                               ; preds = %.lr.ph, %63
  %64 = phi i64 [ %61, %.lr.ph ], [ %75, %63 ]
  %65 = phi i32 [ %8, %.lr.ph ], [ %74, %63 ]
  %66 = load i32, ptr %5, align 4, !tbaa !4
  %67 = sitofp i32 %66 to float
  %68 = fdiv contract float 1.000000e+00, %67
  %69 = fpext float %68 to double
  %70 = sext i32 %65 to i64
  %71 = add nsw i64 %70, -1
  %72 = mul i64 %71, %13
  %73 = getelementptr i8, ptr %62, i64 %72
  store double %69, ptr %73, align 8, !tbaa !4
  store double %69, ptr %7, align 8, !tbaa !4
  %74 = add i32 %65, 1
  %75 = add nsw i64 %64, -1
  %76 = icmp ugt i64 %64, 1
  br i1 %76, label %63, label %.loopexit

.loopexit:                                        ; preds = %63, %.lr.ph8, %middle.block, %59, %15
  ret void
}

declare ptr @_FortranAioBeginExternalFormattedOutput(ptr, i64, ptr, i32, ptr, i32) local_unnamed_addr

declare zeroext i1 @_FortranAioOutputAscii(ptr, ptr, i64) local_unnamed_addr

declare zeroext i1 @_FortranAioOutputInteger32(ptr, i32) local_unnamed_addr

declare zeroext i1 @_FortranAioOutputReal64(ptr, double) local_unnamed_addr

declare i32 @_FortranAioEndIoStatement(ptr) local_unnamed_addr

; Function Attrs: nounwind
declare i32 @omp_get_thread_num() local_unnamed_addr #2

; Function Attrs: nounwind
declare i32 @omp_get_num_threads() local_unnamed_addr #2

; Function Attrs: nounwind
declare i32 @__kmpc_global_thread_num(ptr) local_unnamed_addr #2

; Function Attrs: nounwind
declare !callback !32 void @__kmpc_fork_call(ptr, i32, ptr, ...) local_unnamed_addr #2

; Function Attrs: nocallback nofree nosync nounwind speculatable willreturn memory(none)
declare i32 @llvm.smax.i32(i32, i32) #5

; Function Attrs: nocallback nofree nosync nounwind willreturn memory(argmem: readwrite)
declare void @llvm.lifetime.start.p0(i64 immarg, ptr nocapture) #6

; Function Attrs: nocallback nofree nosync nounwind willreturn memory(argmem: readwrite)
declare void @llvm.lifetime.end.p0(i64 immarg, ptr nocapture) #6

attributes #0 = { mustprogress nofree nounwind willreturn allockind("alloc,uninitialized") allocsize(0) memory(inaccessiblemem: readwrite) "alloc-family"="malloc" }
attributes #1 = { mustprogress nounwind willreturn allockind("free") memory(argmem: readwrite, inaccessiblemem: readwrite) "alloc-family"="malloc" }
attributes #2 = { nounwind }
attributes #3 = { norecurse nounwind }
attributes #4 = { nofree norecurse nosync nounwind memory(readwrite, inaccessiblemem: none) }
attributes #5 = { nocallback nofree nosync nounwind speculatable willreturn memory(none) }
attributes #6 = { nocallback nofree nosync nounwind willreturn memory(argmem: readwrite) }

!llvm.module.flags = !{!0, !1, !2, !3}

!0 = !{i32 2, !"Debug Info Version", i32 3}
!1 = !{i32 7, !"openmp", i32 11}
!2 = !{i32 8, !"PIC Level", i32 2}
!3 = !{i32 7, !"PIE Level", i32 2}
!4 = !{!5, !5, i64 0}
!5 = !{!"any data access", !6, i64 0}
!6 = !{!"any access", !7, i64 0}
!7 = !{!"Flang Type TBAA Root"}
!8 = !{!9, !9, i64 0}
!9 = !{!"descriptor member", !6, i64 0}
!10 = !{!11}
!11 = distinct !{!11, !12}
!12 = distinct !{!12, !"LVerDomain"}
!13 = !{!14}
!14 = distinct !{!14, !12}
!15 = !{!16}
!16 = distinct !{!16, !12}
!17 = !{!11, !14}
!18 = distinct !{!18, !19, !20}
!19 = !{!"llvm.loop.isvectorized", i32 1}
!20 = !{!"llvm.loop.unroll.runtime.disable"}
!21 = distinct !{!21, !19}
!22 = !{!23}
!23 = distinct !{!23, !24}
!24 = distinct !{!24, !"LVerDomain"}
!25 = !{!26}
!26 = distinct !{!26, !24}
!27 = !{!28}
!28 = distinct !{!28, !24}
!29 = !{!23, !26}
!30 = distinct !{!30, !19, !20}
!31 = distinct !{!31, !19}
!32 = !{!33}
!33 = !{i64 2, i64 -1, i64 -1, i1 true}
*** IR Dump After CGProfilePass on [module] ***
; ModuleID = 'FIRModule'
source_filename = "FIRModule"
target datalayout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128"
target triple = "x86_64-unknown-linux-gnu"

%struct.ident_t = type { i32, i32, i32, i32, ptr }

@_QQcl.28612C69372C612C6531332E36653229 = internal constant [16 x i8] c"(a,i7,a,e13.6e2)"
@_QQcl.e8a0ac9186c064ac8543d822e9060d96 = internal constant [59 x i8] c"/g/g92/rydahl1/flangtests/src/parallel_region_outlined.f90\00"
@_QQcl.54686520726573756C74206F6620286172722831292B61727228 = internal constant [26 x i8] c"The result of (arr(1)+arr("
@_QQcl.2920697320 = internal constant [5 x i8] c") is "
@_QQEnvironmentDefaults = local_unnamed_addr constant ptr null
@0 = private unnamed_addr constant [23 x i8] c";unknown;unknown;0;0;;\00", align 1
@1 = private unnamed_addr constant %struct.ident_t { i32 0, i32 2, i32 0, i32 22, ptr @0 }, align 8

; Function Attrs: mustprogress nofree nounwind willreturn allockind("alloc,uninitialized") allocsize(0) memory(inaccessiblemem: readwrite)
declare noalias noundef ptr @malloc(i64 noundef) local_unnamed_addr #0

; Function Attrs: mustprogress nounwind willreturn allockind("free") memory(argmem: readwrite, inaccessiblemem: readwrite)
declare void @free(ptr allocptr nocapture noundef) local_unnamed_addr #1

define void @_QQmain() local_unnamed_addr {
  %structArg.i = alloca { ptr, ptr, ptr, ptr, ptr }, align 8
  %1 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %2 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %3 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %4 = alloca i32, align 4
  %5 = alloca double, align 8
  %6 = alloca { ptr, ptr }, align 8
  store ptr %4, ptr %6, align 8, !tbaa !4
  %7 = getelementptr inbounds { ptr, ptr }, ptr %6, i64 0, i32 1
  store ptr %5, ptr %7, align 8, !tbaa !4
  store i32 1048576, ptr %4, align 4, !tbaa !4
  call void @llvm.lifetime.start.p0(i64 40, ptr nonnull %structArg.i)
  call void @llvm.lifetime.start.p0(i64 48, ptr nonnull %1)
  call void @llvm.lifetime.start.p0(i64 48, ptr nonnull %2)
  call void @llvm.lifetime.start.p0(i64 48, ptr nonnull %3)
  %.fca.1.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 1
  %.fca.2.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 2
  %.fca.3.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 3
  %.fca.4.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 4
  %.fca.5.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 5
  %.fca.6.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 6
  %.fca.7.0.0.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 7, i64 0, i64 0
  %.fca.7.0.1.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 7, i64 0, i64 1
  %.fca.7.0.2.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 7, i64 0, i64 2
  %8 = call dereferenceable_or_null(8388608) ptr @malloc(i64 8388608)
  store ptr %8, ptr %3, align 8, !tbaa !8
  store i64 8, ptr %.fca.1.gep.i, align 8, !tbaa !8
  store i32 20180515, ptr %.fca.2.gep.i, align 8, !tbaa !8
  store i8 1, ptr %.fca.3.gep.i, align 4, !tbaa !8
  store i8 28, ptr %.fca.4.gep.i, align 1, !tbaa !8
  store i8 2, ptr %.fca.5.gep.i, align 2, !tbaa !8
  store i8 0, ptr %.fca.6.gep.i, align 1, !tbaa !8
  store i64 1, ptr %.fca.7.0.0.gep.i, align 8, !tbaa !8
  store i64 1048576, ptr %.fca.7.0.1.gep.i, align 8, !tbaa !8
  store i64 8, ptr %.fca.7.0.2.gep.i, align 8, !tbaa !8
  %omp_global_thread_num.i = call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %4, ptr %structArg.i, align 8
  %gep_5.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 1
  store ptr %3, ptr %gep_5.i, align 8
  %gep_6.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 2
  store ptr %2, ptr %gep_6.i, align 8
  %gep_7.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 3
  store ptr %1, ptr %gep_7.i, align 8
  %gep_8.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 4
  store ptr %6, ptr %gep_8.i, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QFPomp_subroutine..omp_par, ptr nonnull %structArg.i)
  %.fca.0.load.i = load ptr, ptr %3, align 8, !tbaa !8
  %.fca.7.0.0.load.i = load i64, ptr %.fca.7.0.0.gep.i, align 8, !tbaa !8
  %9 = sub i64 1, %.fca.7.0.0.load.i
  %10 = getelementptr double, ptr %.fca.0.load.i, i64 %9
  %11 = load double, ptr %10, align 8, !tbaa !4
  %12 = load i32, ptr %4, align 4, !tbaa !4
  %13 = sext i32 %12 to i64
  %14 = sub i64 %13, %.fca.7.0.0.load.i
  %15 = getelementptr double, ptr %.fca.0.load.i, i64 %14
  %16 = load double, ptr %15, align 8, !tbaa !4
  %17 = fadd contract double %11, %16
  call void @free(ptr %.fca.0.load.i)
  call void @llvm.lifetime.end.p0(i64 40, ptr nonnull %structArg.i)
  call void @llvm.lifetime.end.p0(i64 48, ptr nonnull %1)
  call void @llvm.lifetime.end.p0(i64 48, ptr nonnull %2)
  call void @llvm.lifetime.end.p0(i64 48, ptr nonnull %3)
  %18 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.e8a0ac9186c064ac8543d822e9060d96, i32 10)
  %19 = call i1 @_FortranAioOutputAscii(ptr %18, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %20 = load i32, ptr %4, align 4, !tbaa !4
  %21 = call i1 @_FortranAioOutputInteger32(ptr %18, i32 %20)
  %22 = call i1 @_FortranAioOutputAscii(ptr %18, ptr nonnull @_QQcl.2920697320, i64 5)
  %23 = call i1 @_FortranAioOutputReal64(ptr %18, double %17)
  %24 = call i32 @_FortranAioEndIoStatement(ptr %18)
  ret void
}

; Function Attrs: nounwind
define void @_QFPomp_subroutine(ptr %0, ptr nocapture writeonly %1, ptr nest %2) local_unnamed_addr #2 {
entry:
  %structArg = alloca { ptr, ptr, ptr, ptr, ptr }, align 8
  %3 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %4 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %5 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %.fca.1.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 1
  %.fca.2.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 2
  %.fca.3.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 3
  %.fca.4.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 4
  %.fca.5.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 5
  %.fca.6.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 6
  %.fca.7.0.0.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 0
  %.fca.7.0.1.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 1
  %.fca.7.0.2.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 2
  %6 = load i32, ptr %0, align 4, !tbaa !4
  %7 = tail call i32 @llvm.smax.i32(i32 %6, i32 0)
  %8 = zext i32 %7 to i64
  %9 = shl nuw nsw i64 %8, 3
  %10 = tail call ptr @malloc(i64 %9)
  store ptr %10, ptr %5, align 8, !tbaa !8
  store i64 8, ptr %.fca.1.gep, align 8, !tbaa !8
  store i32 20180515, ptr %.fca.2.gep, align 8, !tbaa !8
  store i8 1, ptr %.fca.3.gep, align 4, !tbaa !8
  store i8 28, ptr %.fca.4.gep, align 1, !tbaa !8
  store i8 2, ptr %.fca.5.gep, align 2, !tbaa !8
  store i8 0, ptr %.fca.6.gep, align 1, !tbaa !8
  store i64 1, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  store i64 %8, ptr %.fca.7.0.1.gep, align 8, !tbaa !8
  store i64 8, ptr %.fca.7.0.2.gep, align 8, !tbaa !8
  %omp_global_thread_num = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %0, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %5, ptr %gep_5, align 8
  %gep_6 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 2
  store ptr %4, ptr %gep_6, align 8
  %gep_7 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 3
  store ptr %3, ptr %gep_7, align 8
  %gep_8 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 4
  store ptr %2, ptr %gep_8, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QFPomp_subroutine..omp_par, ptr nonnull %structArg)
  %.fca.0.load = load ptr, ptr %5, align 8, !tbaa !8
  %.fca.7.0.0.load = load i64, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  %11 = sub i64 1, %.fca.7.0.0.load
  %12 = getelementptr double, ptr %.fca.0.load, i64 %11
  %13 = load double, ptr %12, align 8, !tbaa !4
  %14 = load i32, ptr %0, align 4, !tbaa !4
  %15 = sext i32 %14 to i64
  %16 = sub i64 %15, %.fca.7.0.0.load
  %17 = getelementptr double, ptr %.fca.0.load, i64 %16
  %18 = load double, ptr %17, align 8, !tbaa !4
  %19 = fadd contract double %13, %18
  store double %19, ptr %1, align 8, !tbaa !4
  call void @free(ptr %.fca.0.load)
  ret void
}

; Function Attrs: norecurse nounwind
define internal void @_QFPomp_subroutine..omp_par(ptr noalias nocapture readnone %tid.addr, ptr noalias nocapture readnone %zero.addr, ptr nocapture readonly %0) #3 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %gep_3 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 2
  %loadgep_4 = load ptr, ptr %gep_3, align 8
  %gep_5 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 3
  %loadgep_6 = load ptr, ptr %gep_5, align 8
  %gep_7 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 4
  %loadgep_8 = load ptr, ptr %gep_7, align 8
  %1 = tail call i32 @omp_get_thread_num()
  %2 = tail call i32 @omp_get_num_threads()
  %3 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %4 = sdiv i32 %3, %2
  %5 = mul i32 %4, %1
  %6 = add i32 %5, 1
  %7 = add i32 %2, -1
  %8 = icmp eq i32 %1, %7
  %9 = add i32 %6, %4
  %spec.select = select i1 %8, i32 %3, i32 %9
  %.unpack = load ptr, ptr %loadgep_2, align 8, !tbaa !8
  %.elt14 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  %.unpack15 = load i64, ptr %.elt14, align 8, !tbaa !8
  %.elt16 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  %.unpack17 = load i32, ptr %.elt16, align 8, !tbaa !8
  %.elt18 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  %.unpack19 = load i8, ptr %.elt18, align 4, !tbaa !8
  %.elt20 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  %.unpack21 = load i8, ptr %.elt20, align 1, !tbaa !8
  %.elt22 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  %.unpack23 = load i8, ptr %.elt22, align 2, !tbaa !8
  %.elt24 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  %.unpack25 = load i8, ptr %.elt24, align 1, !tbaa !8
  %.elt26 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  %.unpack27.unpack.unpack = load i64, ptr %.elt26, align 8, !tbaa !8
  %.unpack27.unpack.elt29 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  %.unpack27.unpack.unpack30 = load i64, ptr %.unpack27.unpack.elt29, align 8, !tbaa !8
  %.unpack27.unpack.elt31 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  %.unpack27.unpack.unpack32 = load i64, ptr %.unpack27.unpack.elt31, align 8, !tbaa !8
  store ptr %.unpack, ptr %loadgep_4, align 8, !tbaa !8
  %loadgep_4.repack34 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 1
  store i64 %.unpack15, ptr %loadgep_4.repack34, align 8, !tbaa !8
  %loadgep_4.repack36 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 2
  store i32 %.unpack17, ptr %loadgep_4.repack36, align 8, !tbaa !8
  %loadgep_4.repack38 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 3
  store i8 %.unpack19, ptr %loadgep_4.repack38, align 4, !tbaa !8
  %loadgep_4.repack40 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 4
  store i8 %.unpack21, ptr %loadgep_4.repack40, align 1, !tbaa !8
  %loadgep_4.repack42 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 5
  store i8 %.unpack23, ptr %loadgep_4.repack42, align 2, !tbaa !8
  %loadgep_4.repack44 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 6
  store i8 %.unpack25, ptr %loadgep_4.repack44, align 1, !tbaa !8
  %loadgep_4.repack46 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7
  store i64 %.unpack27.unpack.unpack, ptr %loadgep_4.repack46, align 8, !tbaa !8
  %loadgep_4.repack46.repack48 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack27.unpack.unpack30, ptr %loadgep_4.repack46.repack48, align 8, !tbaa !8
  %loadgep_4.repack46.repack50 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 2
  store i64 %.unpack27.unpack.unpack32, ptr %loadgep_4.repack46.repack50, align 8, !tbaa !8
  %10 = icmp eq i64 %.unpack27.unpack.unpack30, 0
  %11 = select i1 %10, i64 1, i64 %.unpack27.unpack.unpack
  store ptr %.unpack, ptr %loadgep_6, align 8, !tbaa !8
  %loadgep_6.repack52 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 1
  store i64 8, ptr %loadgep_6.repack52, align 8, !tbaa !8
  %loadgep_6.repack54 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 2
  store i32 20180515, ptr %loadgep_6.repack54, align 8, !tbaa !8
  %loadgep_6.repack56 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 3
  store i8 1, ptr %loadgep_6.repack56, align 4, !tbaa !8
  %loadgep_6.repack58 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 4
  store i8 28, ptr %loadgep_6.repack58, align 1, !tbaa !8
  %loadgep_6.repack60 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 5
  store i8 0, ptr %loadgep_6.repack60, align 2, !tbaa !8
  %loadgep_6.repack62 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 6
  store i8 0, ptr %loadgep_6.repack62, align 1, !tbaa !8
  %loadgep_6.repack64 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7
  store i64 %11, ptr %loadgep_6.repack64, align 8, !tbaa !8
  %loadgep_6.repack64.repack66 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack27.unpack.unpack30, ptr %loadgep_6.repack64.repack66, align 8, !tbaa !8
  %loadgep_6.repack64.repack68 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7, i64 0, i64 2
  store i64 8, ptr %loadgep_6.repack64.repack68, align 8, !tbaa !8
  %12 = load ptr, ptr %loadgep_8, align 8, !tbaa !4
  %13 = getelementptr { ptr, ptr }, ptr %loadgep_8, i64 0, i32 1
  %14 = load ptr, ptr %13, align 8, !tbaa !4
  %15 = sext i32 %6 to i64
  %16 = sext i32 %spec.select to i64
  %reass.sub9.i = sub nsw i64 %16, %15
  %17 = icmp sgt i64 %reass.sub9.i, -1
  br i1 %17, label %.lr.ph8.preheader.i, label %_QFPloop.exit

.lr.ph8.preheader.i:                              ; preds = %omp.par.entry
  %18 = add nsw i64 %reass.sub9.i, 1
  %19 = add nsw i64 %16, 2
  %20 = icmp ne i64 %18, 0
  %umin82.neg = sext i1 %20 to i64
  %21 = add nsw i64 %19, %umin82.neg
  %22 = sub nsw i64 %21, %15
  %min.iters.check = icmp ult i64 %22, 8
  br i1 %min.iters.check, label %.lr.ph8.i.preheader, label %vector.scevcheck

vector.scevcheck:                                 ; preds = %.lr.ph8.preheader.i
  %23 = add nsw i64 %16, 1
  %24 = icmp ne i64 %18, 0
  %umin.neg = sext i1 %24 to i64
  %25 = add nsw i64 %23, %umin.neg
  %26 = sub nsw i64 %25, %15
  %27 = trunc i64 %26 to i32
  %28 = add i32 %6, %27
  %29 = icmp slt i32 %28, %6
  %30 = icmp ugt i64 %26, 4294967295
  %31 = or i1 %29, %30
  br i1 %31, label %.lr.ph8.i.preheader, label %vector.memcheck

vector.memcheck:                                  ; preds = %vector.scevcheck
  %scevgep = getelementptr i8, ptr %14, i64 8
  %scevgep71 = getelementptr i8, ptr %12, i64 4
  %32 = shl nsw i64 %15, 3
  %33 = add nsw i64 %32, -8
  %scevgep72 = getelementptr i8, ptr %.unpack, i64 %33
  %34 = shl nsw i64 %16, 3
  %35 = add nsw i64 %34, 8
  %.not = icmp eq i64 %18, 0
  %36 = select i1 %.not, i64 %35, i64 %34
  %scevgep74 = getelementptr i8, ptr %.unpack, i64 %36
  %bound0 = icmp ult ptr %14, %scevgep71
  %bound1 = icmp ult ptr %12, %scevgep
  %found.conflict = and i1 %bound0, %bound1
  %bound075 = icmp ult ptr %14, %scevgep74
  %bound176 = icmp ult ptr %scevgep72, %scevgep
  %found.conflict77 = and i1 %bound075, %bound176
  %conflict.rdx = or i1 %found.conflict, %found.conflict77
  %bound078 = icmp ult ptr %12, %scevgep74
  %bound179 = icmp ult ptr %scevgep72, %scevgep71
  %found.conflict80 = and i1 %bound078, %bound179
  %conflict.rdx81 = or i1 %conflict.rdx, %found.conflict80
  br i1 %conflict.rdx81, label %.lr.ph8.i.preheader, label %vector.ph

vector.ph:                                        ; preds = %vector.memcheck
  %n.vec = and i64 %22, -2
  %ind.end = sub nsw i64 %18, %n.vec
  %.cast = trunc i64 %n.vec to i32
  %ind.end83 = add i32 %6, %.cast
  %37 = load i32, ptr %12, align 4, !tbaa !4, !alias.scope !10, !noalias !13
  %broadcast.splatinsert = insertelement <2 x i32> poison, i32 %37, i64 0
  %38 = sitofp <2 x i32> %broadcast.splatinsert to <2 x float>
  %39 = fdiv contract <2 x float> <float 1.000000e+00, float poison>, %38
  %40 = shufflevector <2 x float> %39, <2 x float> poison, <2 x i32> zeroinitializer
  %41 = fpext <2 x float> %40 to <2 x double>
  %42 = extractelement <2 x double> %41, i64 1
  store double %42, ptr %14, align 8, !tbaa !4, !alias.scope !15, !noalias !17
  br label %vector.body

vector.body:                                      ; preds = %vector.body, %vector.ph
  %index = phi i64 [ 0, %vector.ph ], [ %index.next, %vector.body ]
  %.cast85 = trunc i64 %index to i32
  %offset.idx = add i32 %6, %.cast85
  %43 = sext i32 %offset.idx to i64
  %44 = add nsw i64 %43, -1
  %45 = getelementptr double, ptr %.unpack, i64 %44
  store <2 x double> %41, ptr %45, align 8, !tbaa !4, !alias.scope !13
  %index.next = add nuw i64 %index, 2
  %46 = icmp eq i64 %index.next, %n.vec
  br i1 %46, label %middle.block, label %vector.body, !llvm.loop !18

middle.block:                                     ; preds = %vector.body
  %cmp.n = icmp eq i64 %22, %n.vec
  br i1 %cmp.n, label %_QFPloop.exit, label %.lr.ph8.i.preheader

.lr.ph8.i.preheader:                              ; preds = %vector.memcheck, %vector.scevcheck, %.lr.ph8.preheader.i, %middle.block
  %.ph = phi i64 [ %18, %vector.memcheck ], [ %18, %vector.scevcheck ], [ %18, %.lr.ph8.preheader.i ], [ %ind.end, %middle.block ]
  %.ph86 = phi i32 [ %6, %vector.memcheck ], [ %6, %vector.scevcheck ], [ %6, %.lr.ph8.preheader.i ], [ %ind.end83, %middle.block ]
  br label %.lr.ph8.i

.lr.ph8.i:                                        ; preds = %.lr.ph8.i.preheader, %.lr.ph8.i
  %47 = phi i64 [ %57, %.lr.ph8.i ], [ %.ph, %.lr.ph8.i.preheader ]
  %48 = phi i32 [ %56, %.lr.ph8.i ], [ %.ph86, %.lr.ph8.i.preheader ]
  %49 = load i32, ptr %12, align 4, !tbaa !4
  %50 = sitofp i32 %49 to float
  %51 = fdiv contract float 1.000000e+00, %50
  %52 = fpext float %51 to double
  %53 = sext i32 %48 to i64
  %54 = add nsw i64 %53, -1
  %55 = getelementptr double, ptr %.unpack, i64 %54
  store double %52, ptr %55, align 8, !tbaa !4
  store double %52, ptr %14, align 8, !tbaa !4
  %56 = add i32 %48, 1
  %57 = add nsw i64 %47, -1
  %58 = icmp ugt i64 %47, 1
  br i1 %58, label %.lr.ph8.i, label %_QFPloop.exit, !llvm.loop !21

_QFPloop.exit:                                    ; preds = %.lr.ph8.i, %middle.block, %omp.par.entry
  ret void
}

; Function Attrs: nofree norecurse nosync nounwind memory(readwrite, inaccessiblemem: none)
define void @_QFPloop(ptr nocapture readonly %0, ptr nocapture readonly %1, ptr nocapture readonly %2, ptr nest nocapture readonly %3) local_unnamed_addr #4 {
  %5 = load ptr, ptr %3, align 8, !tbaa !4
  %6 = getelementptr { ptr, ptr }, ptr %3, i64 0, i32 1
  %7 = load ptr, ptr %6, align 8, !tbaa !4
  %8 = load i32, ptr %0, align 4, !tbaa !4
  %9 = sext i32 %8 to i64
  %10 = load i32, ptr %1, align 4, !tbaa !4
  %11 = sext i32 %10 to i64
  %12 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %2, i64 0, i32 7, i64 0, i64 2
  %13 = load i64, ptr %12, align 8, !tbaa !8
  %14 = icmp eq i64 %13, 8
  br i1 %14, label %15, label %59

15:                                               ; preds = %4
  %16 = load ptr, ptr %2, align 8, !tbaa !8
  %reass.sub9 = sub nsw i64 %11, %9
  %17 = icmp sgt i64 %reass.sub9, -1
  br i1 %17, label %.lr.ph8.preheader, label %.loopexit

.lr.ph8.preheader:                                ; preds = %15
  %18 = add nsw i64 %reass.sub9, 1
  %19 = add nsw i64 %11, 2
  %20 = icmp ne i64 %18, 0
  %umin24.neg = sext i1 %20 to i64
  %21 = add nsw i64 %19, %umin24.neg
  %22 = sub nsw i64 %21, %9
  %min.iters.check = icmp ult i64 %22, 8
  br i1 %min.iters.check, label %.lr.ph8.preheader28, label %vector.scevcheck

vector.scevcheck:                                 ; preds = %.lr.ph8.preheader
  %23 = add nsw i64 %11, 1
  %24 = icmp ne i64 %18, 0
  %umin.neg = sext i1 %24 to i64
  %25 = add nsw i64 %23, %umin.neg
  %26 = sub nsw i64 %25, %9
  %27 = trunc i64 %26 to i32
  %28 = add i32 %8, %27
  %29 = icmp slt i32 %28, %8
  %30 = icmp ugt i64 %26, 4294967295
  %31 = or i1 %29, %30
  br i1 %31, label %.lr.ph8.preheader28, label %vector.memcheck

vector.memcheck:                                  ; preds = %vector.scevcheck
  %scevgep = getelementptr i8, ptr %7, i64 8
  %scevgep13 = getelementptr i8, ptr %5, i64 4
  %32 = shl nsw i64 %9, 3
  %33 = add nsw i64 %32, -8
  %scevgep14 = getelementptr i8, ptr %16, i64 %33
  %34 = shl nsw i64 %11, 3
  %35 = add nsw i64 %34, 8
  %.not = icmp eq i64 %18, 0
  %36 = select i1 %.not, i64 %35, i64 %34
  %scevgep16 = getelementptr i8, ptr %16, i64 %36
  %bound0 = icmp ult ptr %7, %scevgep13
  %bound1 = icmp ult ptr %5, %scevgep
  %found.conflict = and i1 %bound0, %bound1
  %bound017 = icmp ult ptr %7, %scevgep16
  %bound118 = icmp ult ptr %scevgep14, %scevgep
  %found.conflict19 = and i1 %bound017, %bound118
  %conflict.rdx = or i1 %found.conflict, %found.conflict19
  %bound020 = icmp ult ptr %5, %scevgep16
  %bound121 = icmp ult ptr %scevgep14, %scevgep13
  %found.conflict22 = and i1 %bound020, %bound121
  %conflict.rdx23 = or i1 %conflict.rdx, %found.conflict22
  br i1 %conflict.rdx23, label %.lr.ph8.preheader28, label %vector.ph

vector.ph:                                        ; preds = %vector.memcheck
  %n.vec = and i64 %22, -2
  %ind.end = sub nsw i64 %18, %n.vec
  %.cast = trunc i64 %n.vec to i32
  %ind.end25 = add i32 %8, %.cast
  %37 = load i32, ptr %5, align 4, !tbaa !4, !alias.scope !22, !noalias !25
  %broadcast.splatinsert = insertelement <2 x i32> poison, i32 %37, i64 0
  %38 = sitofp <2 x i32> %broadcast.splatinsert to <2 x float>
  %39 = fdiv contract <2 x float> <float 1.000000e+00, float poison>, %38
  %40 = shufflevector <2 x float> %39, <2 x float> poison, <2 x i32> zeroinitializer
  %41 = fpext <2 x float> %40 to <2 x double>
  %42 = extractelement <2 x double> %41, i64 1
  store double %42, ptr %7, align 8, !tbaa !4, !alias.scope !27, !noalias !29
  br label %vector.body

vector.body:                                      ; preds = %vector.body, %vector.ph
  %index = phi i64 [ 0, %vector.ph ], [ %index.next, %vector.body ]
  %.cast27 = trunc i64 %index to i32
  %offset.idx = add i32 %8, %.cast27
  %43 = sext i32 %offset.idx to i64
  %44 = add nsw i64 %43, -1
  %45 = getelementptr double, ptr %16, i64 %44
  store <2 x double> %41, ptr %45, align 8, !tbaa !4, !alias.scope !25
  %index.next = add nuw i64 %index, 2
  %46 = icmp eq i64 %index.next, %n.vec
  br i1 %46, label %middle.block, label %vector.body, !llvm.loop !30

middle.block:                                     ; preds = %vector.body
  %cmp.n = icmp eq i64 %22, %n.vec
  br i1 %cmp.n, label %.loopexit, label %.lr.ph8.preheader28

.lr.ph8.preheader28:                              ; preds = %vector.memcheck, %vector.scevcheck, %.lr.ph8.preheader, %middle.block
  %.ph = phi i64 [ %18, %vector.memcheck ], [ %18, %vector.scevcheck ], [ %18, %.lr.ph8.preheader ], [ %ind.end, %middle.block ]
  %.ph29 = phi i32 [ %8, %vector.memcheck ], [ %8, %vector.scevcheck ], [ %8, %.lr.ph8.preheader ], [ %ind.end25, %middle.block ]
  br label %.lr.ph8

.lr.ph8:                                          ; preds = %.lr.ph8.preheader28, %.lr.ph8
  %47 = phi i64 [ %57, %.lr.ph8 ], [ %.ph, %.lr.ph8.preheader28 ]
  %48 = phi i32 [ %56, %.lr.ph8 ], [ %.ph29, %.lr.ph8.preheader28 ]
  %49 = load i32, ptr %5, align 4, !tbaa !4
  %50 = sitofp i32 %49 to float
  %51 = fdiv contract float 1.000000e+00, %50
  %52 = fpext float %51 to double
  %53 = sext i32 %48 to i64
  %54 = add nsw i64 %53, -1
  %55 = getelementptr double, ptr %16, i64 %54
  store double %52, ptr %55, align 8, !tbaa !4
  store double %52, ptr %7, align 8, !tbaa !4
  %56 = add i32 %48, 1
  %57 = add nsw i64 %47, -1
  %58 = icmp ugt i64 %47, 1
  br i1 %58, label %.lr.ph8, label %.loopexit, !llvm.loop !31

59:                                               ; preds = %4
  %reass.sub = sub nsw i64 %11, %9
  %60 = icmp sgt i64 %reass.sub, -1
  br i1 %60, label %.lr.ph, label %.loopexit

.lr.ph:                                           ; preds = %59
  %61 = add nuw nsw i64 %reass.sub, 1
  %62 = load ptr, ptr %2, align 8, !tbaa !8
  br label %63

63:                                               ; preds = %.lr.ph, %63
  %64 = phi i64 [ %61, %.lr.ph ], [ %75, %63 ]
  %65 = phi i32 [ %8, %.lr.ph ], [ %74, %63 ]
  %66 = load i32, ptr %5, align 4, !tbaa !4
  %67 = sitofp i32 %66 to float
  %68 = fdiv contract float 1.000000e+00, %67
  %69 = fpext float %68 to double
  %70 = sext i32 %65 to i64
  %71 = add nsw i64 %70, -1
  %72 = mul i64 %71, %13
  %73 = getelementptr i8, ptr %62, i64 %72
  store double %69, ptr %73, align 8, !tbaa !4
  store double %69, ptr %7, align 8, !tbaa !4
  %74 = add i32 %65, 1
  %75 = add nsw i64 %64, -1
  %76 = icmp ugt i64 %64, 1
  br i1 %76, label %63, label %.loopexit

.loopexit:                                        ; preds = %63, %.lr.ph8, %middle.block, %59, %15
  ret void
}

declare ptr @_FortranAioBeginExternalFormattedOutput(ptr, i64, ptr, i32, ptr, i32) local_unnamed_addr

declare zeroext i1 @_FortranAioOutputAscii(ptr, ptr, i64) local_unnamed_addr

declare zeroext i1 @_FortranAioOutputInteger32(ptr, i32) local_unnamed_addr

declare zeroext i1 @_FortranAioOutputReal64(ptr, double) local_unnamed_addr

declare i32 @_FortranAioEndIoStatement(ptr) local_unnamed_addr

; Function Attrs: nounwind
declare i32 @omp_get_thread_num() local_unnamed_addr #2

; Function Attrs: nounwind
declare i32 @omp_get_num_threads() local_unnamed_addr #2

; Function Attrs: nounwind
declare i32 @__kmpc_global_thread_num(ptr) local_unnamed_addr #2

; Function Attrs: nounwind
declare !callback !32 void @__kmpc_fork_call(ptr, i32, ptr, ...) local_unnamed_addr #2

; Function Attrs: nocallback nofree nosync nounwind speculatable willreturn memory(none)
declare i32 @llvm.smax.i32(i32, i32) #5

; Function Attrs: nocallback nofree nosync nounwind willreturn memory(argmem: readwrite)
declare void @llvm.lifetime.start.p0(i64 immarg, ptr nocapture) #6

; Function Attrs: nocallback nofree nosync nounwind willreturn memory(argmem: readwrite)
declare void @llvm.lifetime.end.p0(i64 immarg, ptr nocapture) #6

attributes #0 = { mustprogress nofree nounwind willreturn allockind("alloc,uninitialized") allocsize(0) memory(inaccessiblemem: readwrite) "alloc-family"="malloc" }
attributes #1 = { mustprogress nounwind willreturn allockind("free") memory(argmem: readwrite, inaccessiblemem: readwrite) "alloc-family"="malloc" }
attributes #2 = { nounwind }
attributes #3 = { norecurse nounwind }
attributes #4 = { nofree norecurse nosync nounwind memory(readwrite, inaccessiblemem: none) }
attributes #5 = { nocallback nofree nosync nounwind speculatable willreturn memory(none) }
attributes #6 = { nocallback nofree nosync nounwind willreturn memory(argmem: readwrite) }

!llvm.module.flags = !{!0, !1, !2, !3}

!0 = !{i32 2, !"Debug Info Version", i32 3}
!1 = !{i32 7, !"openmp", i32 11}
!2 = !{i32 8, !"PIC Level", i32 2}
!3 = !{i32 7, !"PIE Level", i32 2}
!4 = !{!5, !5, i64 0}
!5 = !{!"any data access", !6, i64 0}
!6 = !{!"any access", !7, i64 0}
!7 = !{!"Flang Type TBAA Root"}
!8 = !{!9, !9, i64 0}
!9 = !{!"descriptor member", !6, i64 0}
!10 = !{!11}
!11 = distinct !{!11, !12}
!12 = distinct !{!12, !"LVerDomain"}
!13 = !{!14}
!14 = distinct !{!14, !12}
!15 = !{!16}
!16 = distinct !{!16, !12}
!17 = !{!11, !14}
!18 = distinct !{!18, !19, !20}
!19 = !{!"llvm.loop.isvectorized", i32 1}
!20 = !{!"llvm.loop.unroll.runtime.disable"}
!21 = distinct !{!21, !19}
!22 = !{!23}
!23 = distinct !{!23, !24}
!24 = distinct !{!24, !"LVerDomain"}
!25 = !{!26}
!26 = distinct !{!26, !24}
!27 = !{!28}
!28 = distinct !{!28, !24}
!29 = !{!23, !26}
!30 = distinct !{!30, !19, !20}
!31 = distinct !{!31, !19}
!32 = !{!33}
!33 = !{i64 2, i64 -1, i64 -1, i1 true}
*** IR Dump After RelLookupTableConverterPass on [module] ***
; ModuleID = 'FIRModule'
source_filename = "FIRModule"
target datalayout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128"
target triple = "x86_64-unknown-linux-gnu"

%struct.ident_t = type { i32, i32, i32, i32, ptr }

@_QQcl.28612C69372C612C6531332E36653229 = internal constant [16 x i8] c"(a,i7,a,e13.6e2)"
@_QQcl.e8a0ac9186c064ac8543d822e9060d96 = internal constant [59 x i8] c"/g/g92/rydahl1/flangtests/src/parallel_region_outlined.f90\00"
@_QQcl.54686520726573756C74206F6620286172722831292B61727228 = internal constant [26 x i8] c"The result of (arr(1)+arr("
@_QQcl.2920697320 = internal constant [5 x i8] c") is "
@_QQEnvironmentDefaults = local_unnamed_addr constant ptr null
@0 = private unnamed_addr constant [23 x i8] c";unknown;unknown;0;0;;\00", align 1
@1 = private unnamed_addr constant %struct.ident_t { i32 0, i32 2, i32 0, i32 22, ptr @0 }, align 8

; Function Attrs: mustprogress nofree nounwind willreturn allockind("alloc,uninitialized") allocsize(0) memory(inaccessiblemem: readwrite)
declare noalias noundef ptr @malloc(i64 noundef) local_unnamed_addr #0

; Function Attrs: mustprogress nounwind willreturn allockind("free") memory(argmem: readwrite, inaccessiblemem: readwrite)
declare void @free(ptr allocptr nocapture noundef) local_unnamed_addr #1

define void @_QQmain() local_unnamed_addr {
  %structArg.i = alloca { ptr, ptr, ptr, ptr, ptr }, align 8
  %1 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %2 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %3 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %4 = alloca i32, align 4
  %5 = alloca double, align 8
  %6 = alloca { ptr, ptr }, align 8
  store ptr %4, ptr %6, align 8, !tbaa !4
  %7 = getelementptr inbounds { ptr, ptr }, ptr %6, i64 0, i32 1
  store ptr %5, ptr %7, align 8, !tbaa !4
  store i32 1048576, ptr %4, align 4, !tbaa !4
  call void @llvm.lifetime.start.p0(i64 40, ptr nonnull %structArg.i)
  call void @llvm.lifetime.start.p0(i64 48, ptr nonnull %1)
  call void @llvm.lifetime.start.p0(i64 48, ptr nonnull %2)
  call void @llvm.lifetime.start.p0(i64 48, ptr nonnull %3)
  %.fca.1.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 1
  %.fca.2.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 2
  %.fca.3.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 3
  %.fca.4.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 4
  %.fca.5.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 5
  %.fca.6.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 6
  %.fca.7.0.0.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 7, i64 0, i64 0
  %.fca.7.0.1.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 7, i64 0, i64 1
  %.fca.7.0.2.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 7, i64 0, i64 2
  %8 = call dereferenceable_or_null(8388608) ptr @malloc(i64 8388608)
  store ptr %8, ptr %3, align 8, !tbaa !8
  store i64 8, ptr %.fca.1.gep.i, align 8, !tbaa !8
  store i32 20180515, ptr %.fca.2.gep.i, align 8, !tbaa !8
  store i8 1, ptr %.fca.3.gep.i, align 4, !tbaa !8
  store i8 28, ptr %.fca.4.gep.i, align 1, !tbaa !8
  store i8 2, ptr %.fca.5.gep.i, align 2, !tbaa !8
  store i8 0, ptr %.fca.6.gep.i, align 1, !tbaa !8
  store i64 1, ptr %.fca.7.0.0.gep.i, align 8, !tbaa !8
  store i64 1048576, ptr %.fca.7.0.1.gep.i, align 8, !tbaa !8
  store i64 8, ptr %.fca.7.0.2.gep.i, align 8, !tbaa !8
  %omp_global_thread_num.i = call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %4, ptr %structArg.i, align 8
  %gep_5.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 1
  store ptr %3, ptr %gep_5.i, align 8
  %gep_6.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 2
  store ptr %2, ptr %gep_6.i, align 8
  %gep_7.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 3
  store ptr %1, ptr %gep_7.i, align 8
  %gep_8.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 4
  store ptr %6, ptr %gep_8.i, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QFPomp_subroutine..omp_par, ptr nonnull %structArg.i)
  %.fca.0.load.i = load ptr, ptr %3, align 8, !tbaa !8
  %.fca.7.0.0.load.i = load i64, ptr %.fca.7.0.0.gep.i, align 8, !tbaa !8
  %9 = sub i64 1, %.fca.7.0.0.load.i
  %10 = getelementptr double, ptr %.fca.0.load.i, i64 %9
  %11 = load double, ptr %10, align 8, !tbaa !4
  %12 = load i32, ptr %4, align 4, !tbaa !4
  %13 = sext i32 %12 to i64
  %14 = sub i64 %13, %.fca.7.0.0.load.i
  %15 = getelementptr double, ptr %.fca.0.load.i, i64 %14
  %16 = load double, ptr %15, align 8, !tbaa !4
  %17 = fadd contract double %11, %16
  call void @free(ptr %.fca.0.load.i)
  call void @llvm.lifetime.end.p0(i64 40, ptr nonnull %structArg.i)
  call void @llvm.lifetime.end.p0(i64 48, ptr nonnull %1)
  call void @llvm.lifetime.end.p0(i64 48, ptr nonnull %2)
  call void @llvm.lifetime.end.p0(i64 48, ptr nonnull %3)
  %18 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.e8a0ac9186c064ac8543d822e9060d96, i32 10)
  %19 = call i1 @_FortranAioOutputAscii(ptr %18, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %20 = load i32, ptr %4, align 4, !tbaa !4
  %21 = call i1 @_FortranAioOutputInteger32(ptr %18, i32 %20)
  %22 = call i1 @_FortranAioOutputAscii(ptr %18, ptr nonnull @_QQcl.2920697320, i64 5)
  %23 = call i1 @_FortranAioOutputReal64(ptr %18, double %17)
  %24 = call i32 @_FortranAioEndIoStatement(ptr %18)
  ret void
}

; Function Attrs: nounwind
define void @_QFPomp_subroutine(ptr %0, ptr nocapture writeonly %1, ptr nest %2) local_unnamed_addr #2 {
entry:
  %structArg = alloca { ptr, ptr, ptr, ptr, ptr }, align 8
  %3 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %4 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %5 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %.fca.1.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 1
  %.fca.2.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 2
  %.fca.3.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 3
  %.fca.4.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 4
  %.fca.5.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 5
  %.fca.6.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 6
  %.fca.7.0.0.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 0
  %.fca.7.0.1.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 1
  %.fca.7.0.2.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 2
  %6 = load i32, ptr %0, align 4, !tbaa !4
  %7 = tail call i32 @llvm.smax.i32(i32 %6, i32 0)
  %8 = zext i32 %7 to i64
  %9 = shl nuw nsw i64 %8, 3
  %10 = tail call ptr @malloc(i64 %9)
  store ptr %10, ptr %5, align 8, !tbaa !8
  store i64 8, ptr %.fca.1.gep, align 8, !tbaa !8
  store i32 20180515, ptr %.fca.2.gep, align 8, !tbaa !8
  store i8 1, ptr %.fca.3.gep, align 4, !tbaa !8
  store i8 28, ptr %.fca.4.gep, align 1, !tbaa !8
  store i8 2, ptr %.fca.5.gep, align 2, !tbaa !8
  store i8 0, ptr %.fca.6.gep, align 1, !tbaa !8
  store i64 1, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  store i64 %8, ptr %.fca.7.0.1.gep, align 8, !tbaa !8
  store i64 8, ptr %.fca.7.0.2.gep, align 8, !tbaa !8
  %omp_global_thread_num = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %0, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %5, ptr %gep_5, align 8
  %gep_6 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 2
  store ptr %4, ptr %gep_6, align 8
  %gep_7 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 3
  store ptr %3, ptr %gep_7, align 8
  %gep_8 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 4
  store ptr %2, ptr %gep_8, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QFPomp_subroutine..omp_par, ptr nonnull %structArg)
  %.fca.0.load = load ptr, ptr %5, align 8, !tbaa !8
  %.fca.7.0.0.load = load i64, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  %11 = sub i64 1, %.fca.7.0.0.load
  %12 = getelementptr double, ptr %.fca.0.load, i64 %11
  %13 = load double, ptr %12, align 8, !tbaa !4
  %14 = load i32, ptr %0, align 4, !tbaa !4
  %15 = sext i32 %14 to i64
  %16 = sub i64 %15, %.fca.7.0.0.load
  %17 = getelementptr double, ptr %.fca.0.load, i64 %16
  %18 = load double, ptr %17, align 8, !tbaa !4
  %19 = fadd contract double %13, %18
  store double %19, ptr %1, align 8, !tbaa !4
  call void @free(ptr %.fca.0.load)
  ret void
}

; Function Attrs: norecurse nounwind
define internal void @_QFPomp_subroutine..omp_par(ptr noalias nocapture readnone %tid.addr, ptr noalias nocapture readnone %zero.addr, ptr nocapture readonly %0) #3 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %gep_3 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 2
  %loadgep_4 = load ptr, ptr %gep_3, align 8
  %gep_5 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 3
  %loadgep_6 = load ptr, ptr %gep_5, align 8
  %gep_7 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 4
  %loadgep_8 = load ptr, ptr %gep_7, align 8
  %1 = tail call i32 @omp_get_thread_num()
  %2 = tail call i32 @omp_get_num_threads()
  %3 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %4 = sdiv i32 %3, %2
  %5 = mul i32 %4, %1
  %6 = add i32 %5, 1
  %7 = add i32 %2, -1
  %8 = icmp eq i32 %1, %7
  %9 = add i32 %6, %4
  %spec.select = select i1 %8, i32 %3, i32 %9
  %.unpack = load ptr, ptr %loadgep_2, align 8, !tbaa !8
  %.elt14 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  %.unpack15 = load i64, ptr %.elt14, align 8, !tbaa !8
  %.elt16 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  %.unpack17 = load i32, ptr %.elt16, align 8, !tbaa !8
  %.elt18 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  %.unpack19 = load i8, ptr %.elt18, align 4, !tbaa !8
  %.elt20 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  %.unpack21 = load i8, ptr %.elt20, align 1, !tbaa !8
  %.elt22 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  %.unpack23 = load i8, ptr %.elt22, align 2, !tbaa !8
  %.elt24 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  %.unpack25 = load i8, ptr %.elt24, align 1, !tbaa !8
  %.elt26 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  %.unpack27.unpack.unpack = load i64, ptr %.elt26, align 8, !tbaa !8
  %.unpack27.unpack.elt29 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  %.unpack27.unpack.unpack30 = load i64, ptr %.unpack27.unpack.elt29, align 8, !tbaa !8
  %.unpack27.unpack.elt31 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  %.unpack27.unpack.unpack32 = load i64, ptr %.unpack27.unpack.elt31, align 8, !tbaa !8
  store ptr %.unpack, ptr %loadgep_4, align 8, !tbaa !8
  %loadgep_4.repack34 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 1
  store i64 %.unpack15, ptr %loadgep_4.repack34, align 8, !tbaa !8
  %loadgep_4.repack36 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 2
  store i32 %.unpack17, ptr %loadgep_4.repack36, align 8, !tbaa !8
  %loadgep_4.repack38 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 3
  store i8 %.unpack19, ptr %loadgep_4.repack38, align 4, !tbaa !8
  %loadgep_4.repack40 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 4
  store i8 %.unpack21, ptr %loadgep_4.repack40, align 1, !tbaa !8
  %loadgep_4.repack42 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 5
  store i8 %.unpack23, ptr %loadgep_4.repack42, align 2, !tbaa !8
  %loadgep_4.repack44 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 6
  store i8 %.unpack25, ptr %loadgep_4.repack44, align 1, !tbaa !8
  %loadgep_4.repack46 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7
  store i64 %.unpack27.unpack.unpack, ptr %loadgep_4.repack46, align 8, !tbaa !8
  %loadgep_4.repack46.repack48 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack27.unpack.unpack30, ptr %loadgep_4.repack46.repack48, align 8, !tbaa !8
  %loadgep_4.repack46.repack50 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 2
  store i64 %.unpack27.unpack.unpack32, ptr %loadgep_4.repack46.repack50, align 8, !tbaa !8
  %10 = icmp eq i64 %.unpack27.unpack.unpack30, 0
  %11 = select i1 %10, i64 1, i64 %.unpack27.unpack.unpack
  store ptr %.unpack, ptr %loadgep_6, align 8, !tbaa !8
  %loadgep_6.repack52 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 1
  store i64 8, ptr %loadgep_6.repack52, align 8, !tbaa !8
  %loadgep_6.repack54 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 2
  store i32 20180515, ptr %loadgep_6.repack54, align 8, !tbaa !8
  %loadgep_6.repack56 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 3
  store i8 1, ptr %loadgep_6.repack56, align 4, !tbaa !8
  %loadgep_6.repack58 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 4
  store i8 28, ptr %loadgep_6.repack58, align 1, !tbaa !8
  %loadgep_6.repack60 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 5
  store i8 0, ptr %loadgep_6.repack60, align 2, !tbaa !8
  %loadgep_6.repack62 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 6
  store i8 0, ptr %loadgep_6.repack62, align 1, !tbaa !8
  %loadgep_6.repack64 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7
  store i64 %11, ptr %loadgep_6.repack64, align 8, !tbaa !8
  %loadgep_6.repack64.repack66 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack27.unpack.unpack30, ptr %loadgep_6.repack64.repack66, align 8, !tbaa !8
  %loadgep_6.repack64.repack68 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7, i64 0, i64 2
  store i64 8, ptr %loadgep_6.repack64.repack68, align 8, !tbaa !8
  %12 = load ptr, ptr %loadgep_8, align 8, !tbaa !4
  %13 = getelementptr { ptr, ptr }, ptr %loadgep_8, i64 0, i32 1
  %14 = load ptr, ptr %13, align 8, !tbaa !4
  %15 = sext i32 %6 to i64
  %16 = sext i32 %spec.select to i64
  %reass.sub9.i = sub nsw i64 %16, %15
  %17 = icmp sgt i64 %reass.sub9.i, -1
  br i1 %17, label %.lr.ph8.preheader.i, label %_QFPloop.exit

.lr.ph8.preheader.i:                              ; preds = %omp.par.entry
  %18 = add nsw i64 %reass.sub9.i, 1
  %19 = add nsw i64 %16, 2
  %20 = icmp ne i64 %18, 0
  %umin82.neg = sext i1 %20 to i64
  %21 = add nsw i64 %19, %umin82.neg
  %22 = sub nsw i64 %21, %15
  %min.iters.check = icmp ult i64 %22, 8
  br i1 %min.iters.check, label %.lr.ph8.i.preheader, label %vector.scevcheck

vector.scevcheck:                                 ; preds = %.lr.ph8.preheader.i
  %23 = add nsw i64 %16, 1
  %24 = icmp ne i64 %18, 0
  %umin.neg = sext i1 %24 to i64
  %25 = add nsw i64 %23, %umin.neg
  %26 = sub nsw i64 %25, %15
  %27 = trunc i64 %26 to i32
  %28 = add i32 %6, %27
  %29 = icmp slt i32 %28, %6
  %30 = icmp ugt i64 %26, 4294967295
  %31 = or i1 %29, %30
  br i1 %31, label %.lr.ph8.i.preheader, label %vector.memcheck

vector.memcheck:                                  ; preds = %vector.scevcheck
  %scevgep = getelementptr i8, ptr %14, i64 8
  %scevgep71 = getelementptr i8, ptr %12, i64 4
  %32 = shl nsw i64 %15, 3
  %33 = add nsw i64 %32, -8
  %scevgep72 = getelementptr i8, ptr %.unpack, i64 %33
  %34 = shl nsw i64 %16, 3
  %35 = add nsw i64 %34, 8
  %.not = icmp eq i64 %18, 0
  %36 = select i1 %.not, i64 %35, i64 %34
  %scevgep74 = getelementptr i8, ptr %.unpack, i64 %36
  %bound0 = icmp ult ptr %14, %scevgep71
  %bound1 = icmp ult ptr %12, %scevgep
  %found.conflict = and i1 %bound0, %bound1
  %bound075 = icmp ult ptr %14, %scevgep74
  %bound176 = icmp ult ptr %scevgep72, %scevgep
  %found.conflict77 = and i1 %bound075, %bound176
  %conflict.rdx = or i1 %found.conflict, %found.conflict77
  %bound078 = icmp ult ptr %12, %scevgep74
  %bound179 = icmp ult ptr %scevgep72, %scevgep71
  %found.conflict80 = and i1 %bound078, %bound179
  %conflict.rdx81 = or i1 %conflict.rdx, %found.conflict80
  br i1 %conflict.rdx81, label %.lr.ph8.i.preheader, label %vector.ph

vector.ph:                                        ; preds = %vector.memcheck
  %n.vec = and i64 %22, -2
  %ind.end = sub nsw i64 %18, %n.vec
  %.cast = trunc i64 %n.vec to i32
  %ind.end83 = add i32 %6, %.cast
  %37 = load i32, ptr %12, align 4, !tbaa !4, !alias.scope !10, !noalias !13
  %broadcast.splatinsert = insertelement <2 x i32> poison, i32 %37, i64 0
  %38 = sitofp <2 x i32> %broadcast.splatinsert to <2 x float>
  %39 = fdiv contract <2 x float> <float 1.000000e+00, float poison>, %38
  %40 = shufflevector <2 x float> %39, <2 x float> poison, <2 x i32> zeroinitializer
  %41 = fpext <2 x float> %40 to <2 x double>
  %42 = extractelement <2 x double> %41, i64 1
  store double %42, ptr %14, align 8, !tbaa !4, !alias.scope !15, !noalias !17
  br label %vector.body

vector.body:                                      ; preds = %vector.body, %vector.ph
  %index = phi i64 [ 0, %vector.ph ], [ %index.next, %vector.body ]
  %.cast85 = trunc i64 %index to i32
  %offset.idx = add i32 %6, %.cast85
  %43 = sext i32 %offset.idx to i64
  %44 = add nsw i64 %43, -1
  %45 = getelementptr double, ptr %.unpack, i64 %44
  store <2 x double> %41, ptr %45, align 8, !tbaa !4, !alias.scope !13
  %index.next = add nuw i64 %index, 2
  %46 = icmp eq i64 %index.next, %n.vec
  br i1 %46, label %middle.block, label %vector.body, !llvm.loop !18

middle.block:                                     ; preds = %vector.body
  %cmp.n = icmp eq i64 %22, %n.vec
  br i1 %cmp.n, label %_QFPloop.exit, label %.lr.ph8.i.preheader

.lr.ph8.i.preheader:                              ; preds = %vector.memcheck, %vector.scevcheck, %.lr.ph8.preheader.i, %middle.block
  %.ph = phi i64 [ %18, %vector.memcheck ], [ %18, %vector.scevcheck ], [ %18, %.lr.ph8.preheader.i ], [ %ind.end, %middle.block ]
  %.ph86 = phi i32 [ %6, %vector.memcheck ], [ %6, %vector.scevcheck ], [ %6, %.lr.ph8.preheader.i ], [ %ind.end83, %middle.block ]
  br label %.lr.ph8.i

.lr.ph8.i:                                        ; preds = %.lr.ph8.i.preheader, %.lr.ph8.i
  %47 = phi i64 [ %57, %.lr.ph8.i ], [ %.ph, %.lr.ph8.i.preheader ]
  %48 = phi i32 [ %56, %.lr.ph8.i ], [ %.ph86, %.lr.ph8.i.preheader ]
  %49 = load i32, ptr %12, align 4, !tbaa !4
  %50 = sitofp i32 %49 to float
  %51 = fdiv contract float 1.000000e+00, %50
  %52 = fpext float %51 to double
  %53 = sext i32 %48 to i64
  %54 = add nsw i64 %53, -1
  %55 = getelementptr double, ptr %.unpack, i64 %54
  store double %52, ptr %55, align 8, !tbaa !4
  store double %52, ptr %14, align 8, !tbaa !4
  %56 = add i32 %48, 1
  %57 = add nsw i64 %47, -1
  %58 = icmp ugt i64 %47, 1
  br i1 %58, label %.lr.ph8.i, label %_QFPloop.exit, !llvm.loop !21

_QFPloop.exit:                                    ; preds = %.lr.ph8.i, %middle.block, %omp.par.entry
  ret void
}

; Function Attrs: nofree norecurse nosync nounwind memory(readwrite, inaccessiblemem: none)
define void @_QFPloop(ptr nocapture readonly %0, ptr nocapture readonly %1, ptr nocapture readonly %2, ptr nest nocapture readonly %3) local_unnamed_addr #4 {
  %5 = load ptr, ptr %3, align 8, !tbaa !4
  %6 = getelementptr { ptr, ptr }, ptr %3, i64 0, i32 1
  %7 = load ptr, ptr %6, align 8, !tbaa !4
  %8 = load i32, ptr %0, align 4, !tbaa !4
  %9 = sext i32 %8 to i64
  %10 = load i32, ptr %1, align 4, !tbaa !4
  %11 = sext i32 %10 to i64
  %12 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %2, i64 0, i32 7, i64 0, i64 2
  %13 = load i64, ptr %12, align 8, !tbaa !8
  %14 = icmp eq i64 %13, 8
  br i1 %14, label %15, label %59

15:                                               ; preds = %4
  %16 = load ptr, ptr %2, align 8, !tbaa !8
  %reass.sub9 = sub nsw i64 %11, %9
  %17 = icmp sgt i64 %reass.sub9, -1
  br i1 %17, label %.lr.ph8.preheader, label %.loopexit

.lr.ph8.preheader:                                ; preds = %15
  %18 = add nsw i64 %reass.sub9, 1
  %19 = add nsw i64 %11, 2
  %20 = icmp ne i64 %18, 0
  %umin24.neg = sext i1 %20 to i64
  %21 = add nsw i64 %19, %umin24.neg
  %22 = sub nsw i64 %21, %9
  %min.iters.check = icmp ult i64 %22, 8
  br i1 %min.iters.check, label %.lr.ph8.preheader28, label %vector.scevcheck

vector.scevcheck:                                 ; preds = %.lr.ph8.preheader
  %23 = add nsw i64 %11, 1
  %24 = icmp ne i64 %18, 0
  %umin.neg = sext i1 %24 to i64
  %25 = add nsw i64 %23, %umin.neg
  %26 = sub nsw i64 %25, %9
  %27 = trunc i64 %26 to i32
  %28 = add i32 %8, %27
  %29 = icmp slt i32 %28, %8
  %30 = icmp ugt i64 %26, 4294967295
  %31 = or i1 %29, %30
  br i1 %31, label %.lr.ph8.preheader28, label %vector.memcheck

vector.memcheck:                                  ; preds = %vector.scevcheck
  %scevgep = getelementptr i8, ptr %7, i64 8
  %scevgep13 = getelementptr i8, ptr %5, i64 4
  %32 = shl nsw i64 %9, 3
  %33 = add nsw i64 %32, -8
  %scevgep14 = getelementptr i8, ptr %16, i64 %33
  %34 = shl nsw i64 %11, 3
  %35 = add nsw i64 %34, 8
  %.not = icmp eq i64 %18, 0
  %36 = select i1 %.not, i64 %35, i64 %34
  %scevgep16 = getelementptr i8, ptr %16, i64 %36
  %bound0 = icmp ult ptr %7, %scevgep13
  %bound1 = icmp ult ptr %5, %scevgep
  %found.conflict = and i1 %bound0, %bound1
  %bound017 = icmp ult ptr %7, %scevgep16
  %bound118 = icmp ult ptr %scevgep14, %scevgep
  %found.conflict19 = and i1 %bound017, %bound118
  %conflict.rdx = or i1 %found.conflict, %found.conflict19
  %bound020 = icmp ult ptr %5, %scevgep16
  %bound121 = icmp ult ptr %scevgep14, %scevgep13
  %found.conflict22 = and i1 %bound020, %bound121
  %conflict.rdx23 = or i1 %conflict.rdx, %found.conflict22
  br i1 %conflict.rdx23, label %.lr.ph8.preheader28, label %vector.ph

vector.ph:                                        ; preds = %vector.memcheck
  %n.vec = and i64 %22, -2
  %ind.end = sub nsw i64 %18, %n.vec
  %.cast = trunc i64 %n.vec to i32
  %ind.end25 = add i32 %8, %.cast
  %37 = load i32, ptr %5, align 4, !tbaa !4, !alias.scope !22, !noalias !25
  %broadcast.splatinsert = insertelement <2 x i32> poison, i32 %37, i64 0
  %38 = sitofp <2 x i32> %broadcast.splatinsert to <2 x float>
  %39 = fdiv contract <2 x float> <float 1.000000e+00, float poison>, %38
  %40 = shufflevector <2 x float> %39, <2 x float> poison, <2 x i32> zeroinitializer
  %41 = fpext <2 x float> %40 to <2 x double>
  %42 = extractelement <2 x double> %41, i64 1
  store double %42, ptr %7, align 8, !tbaa !4, !alias.scope !27, !noalias !29
  br label %vector.body

vector.body:                                      ; preds = %vector.body, %vector.ph
  %index = phi i64 [ 0, %vector.ph ], [ %index.next, %vector.body ]
  %.cast27 = trunc i64 %index to i32
  %offset.idx = add i32 %8, %.cast27
  %43 = sext i32 %offset.idx to i64
  %44 = add nsw i64 %43, -1
  %45 = getelementptr double, ptr %16, i64 %44
  store <2 x double> %41, ptr %45, align 8, !tbaa !4, !alias.scope !25
  %index.next = add nuw i64 %index, 2
  %46 = icmp eq i64 %index.next, %n.vec
  br i1 %46, label %middle.block, label %vector.body, !llvm.loop !30

middle.block:                                     ; preds = %vector.body
  %cmp.n = icmp eq i64 %22, %n.vec
  br i1 %cmp.n, label %.loopexit, label %.lr.ph8.preheader28

.lr.ph8.preheader28:                              ; preds = %vector.memcheck, %vector.scevcheck, %.lr.ph8.preheader, %middle.block
  %.ph = phi i64 [ %18, %vector.memcheck ], [ %18, %vector.scevcheck ], [ %18, %.lr.ph8.preheader ], [ %ind.end, %middle.block ]
  %.ph29 = phi i32 [ %8, %vector.memcheck ], [ %8, %vector.scevcheck ], [ %8, %.lr.ph8.preheader ], [ %ind.end25, %middle.block ]
  br label %.lr.ph8

.lr.ph8:                                          ; preds = %.lr.ph8.preheader28, %.lr.ph8
  %47 = phi i64 [ %57, %.lr.ph8 ], [ %.ph, %.lr.ph8.preheader28 ]
  %48 = phi i32 [ %56, %.lr.ph8 ], [ %.ph29, %.lr.ph8.preheader28 ]
  %49 = load i32, ptr %5, align 4, !tbaa !4
  %50 = sitofp i32 %49 to float
  %51 = fdiv contract float 1.000000e+00, %50
  %52 = fpext float %51 to double
  %53 = sext i32 %48 to i64
  %54 = add nsw i64 %53, -1
  %55 = getelementptr double, ptr %16, i64 %54
  store double %52, ptr %55, align 8, !tbaa !4
  store double %52, ptr %7, align 8, !tbaa !4
  %56 = add i32 %48, 1
  %57 = add nsw i64 %47, -1
  %58 = icmp ugt i64 %47, 1
  br i1 %58, label %.lr.ph8, label %.loopexit, !llvm.loop !31

59:                                               ; preds = %4
  %reass.sub = sub nsw i64 %11, %9
  %60 = icmp sgt i64 %reass.sub, -1
  br i1 %60, label %.lr.ph, label %.loopexit

.lr.ph:                                           ; preds = %59
  %61 = add nuw nsw i64 %reass.sub, 1
  %62 = load ptr, ptr %2, align 8, !tbaa !8
  br label %63

63:                                               ; preds = %.lr.ph, %63
  %64 = phi i64 [ %61, %.lr.ph ], [ %75, %63 ]
  %65 = phi i32 [ %8, %.lr.ph ], [ %74, %63 ]
  %66 = load i32, ptr %5, align 4, !tbaa !4
  %67 = sitofp i32 %66 to float
  %68 = fdiv contract float 1.000000e+00, %67
  %69 = fpext float %68 to double
  %70 = sext i32 %65 to i64
  %71 = add nsw i64 %70, -1
  %72 = mul i64 %71, %13
  %73 = getelementptr i8, ptr %62, i64 %72
  store double %69, ptr %73, align 8, !tbaa !4
  store double %69, ptr %7, align 8, !tbaa !4
  %74 = add i32 %65, 1
  %75 = add nsw i64 %64, -1
  %76 = icmp ugt i64 %64, 1
  br i1 %76, label %63, label %.loopexit

.loopexit:                                        ; preds = %63, %.lr.ph8, %middle.block, %59, %15
  ret void
}

declare ptr @_FortranAioBeginExternalFormattedOutput(ptr, i64, ptr, i32, ptr, i32) local_unnamed_addr

declare zeroext i1 @_FortranAioOutputAscii(ptr, ptr, i64) local_unnamed_addr

declare zeroext i1 @_FortranAioOutputInteger32(ptr, i32) local_unnamed_addr

declare zeroext i1 @_FortranAioOutputReal64(ptr, double) local_unnamed_addr

declare i32 @_FortranAioEndIoStatement(ptr) local_unnamed_addr

; Function Attrs: nounwind
declare i32 @omp_get_thread_num() local_unnamed_addr #2

; Function Attrs: nounwind
declare i32 @omp_get_num_threads() local_unnamed_addr #2

; Function Attrs: nounwind
declare i32 @__kmpc_global_thread_num(ptr) local_unnamed_addr #2

; Function Attrs: nounwind
declare !callback !32 void @__kmpc_fork_call(ptr, i32, ptr, ...) local_unnamed_addr #2

; Function Attrs: nocallback nofree nosync nounwind speculatable willreturn memory(none)
declare i32 @llvm.smax.i32(i32, i32) #5

; Function Attrs: nocallback nofree nosync nounwind willreturn memory(argmem: readwrite)
declare void @llvm.lifetime.start.p0(i64 immarg, ptr nocapture) #6

; Function Attrs: nocallback nofree nosync nounwind willreturn memory(argmem: readwrite)
declare void @llvm.lifetime.end.p0(i64 immarg, ptr nocapture) #6

attributes #0 = { mustprogress nofree nounwind willreturn allockind("alloc,uninitialized") allocsize(0) memory(inaccessiblemem: readwrite) "alloc-family"="malloc" }
attributes #1 = { mustprogress nounwind willreturn allockind("free") memory(argmem: readwrite, inaccessiblemem: readwrite) "alloc-family"="malloc" }
attributes #2 = { nounwind }
attributes #3 = { norecurse nounwind }
attributes #4 = { nofree norecurse nosync nounwind memory(readwrite, inaccessiblemem: none) }
attributes #5 = { nocallback nofree nosync nounwind speculatable willreturn memory(none) }
attributes #6 = { nocallback nofree nosync nounwind willreturn memory(argmem: readwrite) }

!llvm.module.flags = !{!0, !1, !2, !3}

!0 = !{i32 2, !"Debug Info Version", i32 3}
!1 = !{i32 7, !"openmp", i32 11}
!2 = !{i32 8, !"PIC Level", i32 2}
!3 = !{i32 7, !"PIE Level", i32 2}
!4 = !{!5, !5, i64 0}
!5 = !{!"any data access", !6, i64 0}
!6 = !{!"any access", !7, i64 0}
!7 = !{!"Flang Type TBAA Root"}
!8 = !{!9, !9, i64 0}
!9 = !{!"descriptor member", !6, i64 0}
!10 = !{!11}
!11 = distinct !{!11, !12}
!12 = distinct !{!12, !"LVerDomain"}
!13 = !{!14}
!14 = distinct !{!14, !12}
!15 = !{!16}
!16 = distinct !{!16, !12}
!17 = !{!11, !14}
!18 = distinct !{!18, !19, !20}
!19 = !{!"llvm.loop.isvectorized", i32 1}
!20 = !{!"llvm.loop.unroll.runtime.disable"}
!21 = distinct !{!21, !19}
!22 = !{!23}
!23 = distinct !{!23, !24}
!24 = distinct !{!24, !"LVerDomain"}
!25 = !{!26}
!26 = distinct !{!26, !24}
!27 = !{!28}
!28 = distinct !{!28, !24}
!29 = !{!23, !26}
!30 = distinct !{!30, !19, !20}
!31 = distinct !{!31, !19}
!32 = !{!33}
!33 = !{i64 2, i64 -1, i64 -1, i1 true}
*** IR Dump After AnnotationRemarksPass on _QQmain ***
define void @_QQmain() local_unnamed_addr {
  %structArg.i = alloca { ptr, ptr, ptr, ptr, ptr }, align 8
  %1 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %2 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %3 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %4 = alloca i32, align 4
  %5 = alloca double, align 8
  %6 = alloca { ptr, ptr }, align 8
  store ptr %4, ptr %6, align 8, !tbaa !4
  %7 = getelementptr inbounds { ptr, ptr }, ptr %6, i64 0, i32 1
  store ptr %5, ptr %7, align 8, !tbaa !4
  store i32 1048576, ptr %4, align 4, !tbaa !4
  call void @llvm.lifetime.start.p0(i64 40, ptr nonnull %structArg.i)
  call void @llvm.lifetime.start.p0(i64 48, ptr nonnull %1)
  call void @llvm.lifetime.start.p0(i64 48, ptr nonnull %2)
  call void @llvm.lifetime.start.p0(i64 48, ptr nonnull %3)
  %.fca.1.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 1
  %.fca.2.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 2
  %.fca.3.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 3
  %.fca.4.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 4
  %.fca.5.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 5
  %.fca.6.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 6
  %.fca.7.0.0.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 7, i64 0, i64 0
  %.fca.7.0.1.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 7, i64 0, i64 1
  %.fca.7.0.2.gep.i = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %3, i64 0, i32 7, i64 0, i64 2
  %8 = call dereferenceable_or_null(8388608) ptr @malloc(i64 8388608)
  store ptr %8, ptr %3, align 8, !tbaa !8
  store i64 8, ptr %.fca.1.gep.i, align 8, !tbaa !8
  store i32 20180515, ptr %.fca.2.gep.i, align 8, !tbaa !8
  store i8 1, ptr %.fca.3.gep.i, align 4, !tbaa !8
  store i8 28, ptr %.fca.4.gep.i, align 1, !tbaa !8
  store i8 2, ptr %.fca.5.gep.i, align 2, !tbaa !8
  store i8 0, ptr %.fca.6.gep.i, align 1, !tbaa !8
  store i64 1, ptr %.fca.7.0.0.gep.i, align 8, !tbaa !8
  store i64 1048576, ptr %.fca.7.0.1.gep.i, align 8, !tbaa !8
  store i64 8, ptr %.fca.7.0.2.gep.i, align 8, !tbaa !8
  %omp_global_thread_num.i = call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %4, ptr %structArg.i, align 8
  %gep_5.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 1
  store ptr %3, ptr %gep_5.i, align 8
  %gep_6.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 2
  store ptr %2, ptr %gep_6.i, align 8
  %gep_7.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 3
  store ptr %1, ptr %gep_7.i, align 8
  %gep_8.i = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg.i, i64 0, i32 4
  store ptr %6, ptr %gep_8.i, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QFPomp_subroutine..omp_par, ptr nonnull %structArg.i)
  %.fca.0.load.i = load ptr, ptr %3, align 8, !tbaa !8
  %.fca.7.0.0.load.i = load i64, ptr %.fca.7.0.0.gep.i, align 8, !tbaa !8
  %9 = sub i64 1, %.fca.7.0.0.load.i
  %10 = getelementptr double, ptr %.fca.0.load.i, i64 %9
  %11 = load double, ptr %10, align 8, !tbaa !4
  %12 = load i32, ptr %4, align 4, !tbaa !4
  %13 = sext i32 %12 to i64
  %14 = sub i64 %13, %.fca.7.0.0.load.i
  %15 = getelementptr double, ptr %.fca.0.load.i, i64 %14
  %16 = load double, ptr %15, align 8, !tbaa !4
  %17 = fadd contract double %11, %16
  call void @free(ptr %.fca.0.load.i)
  call void @llvm.lifetime.end.p0(i64 40, ptr nonnull %structArg.i)
  call void @llvm.lifetime.end.p0(i64 48, ptr nonnull %1)
  call void @llvm.lifetime.end.p0(i64 48, ptr nonnull %2)
  call void @llvm.lifetime.end.p0(i64 48, ptr nonnull %3)
  %18 = call ptr @_FortranAioBeginExternalFormattedOutput(ptr nonnull @_QQcl.28612C69372C612C6531332E36653229, i64 16, ptr null, i32 -1, ptr nonnull @_QQcl.e8a0ac9186c064ac8543d822e9060d96, i32 10)
  %19 = call i1 @_FortranAioOutputAscii(ptr %18, ptr nonnull @_QQcl.54686520726573756C74206F6620286172722831292B61727228, i64 26)
  %20 = load i32, ptr %4, align 4, !tbaa !4
  %21 = call i1 @_FortranAioOutputInteger32(ptr %18, i32 %20)
  %22 = call i1 @_FortranAioOutputAscii(ptr %18, ptr nonnull @_QQcl.2920697320, i64 5)
  %23 = call i1 @_FortranAioOutputReal64(ptr %18, double %17)
  %24 = call i32 @_FortranAioEndIoStatement(ptr %18)
  ret void
}
*** IR Dump After AnnotationRemarksPass on _QFPomp_subroutine ***
; Function Attrs: nounwind
define void @_QFPomp_subroutine(ptr %0, ptr nocapture writeonly %1, ptr nest %2) local_unnamed_addr #2 {
entry:
  %structArg = alloca { ptr, ptr, ptr, ptr, ptr }, align 8
  %3 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %4 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %5 = alloca { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, align 8
  %.fca.1.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 1
  %.fca.2.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 2
  %.fca.3.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 3
  %.fca.4.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 4
  %.fca.5.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 5
  %.fca.6.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 6
  %.fca.7.0.0.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 0
  %.fca.7.0.1.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 1
  %.fca.7.0.2.gep = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %5, i64 0, i32 7, i64 0, i64 2
  %6 = load i32, ptr %0, align 4, !tbaa !4
  %7 = tail call i32 @llvm.smax.i32(i32 %6, i32 0)
  %8 = zext i32 %7 to i64
  %9 = shl nuw nsw i64 %8, 3
  %10 = tail call ptr @malloc(i64 %9)
  store ptr %10, ptr %5, align 8, !tbaa !8
  store i64 8, ptr %.fca.1.gep, align 8, !tbaa !8
  store i32 20180515, ptr %.fca.2.gep, align 8, !tbaa !8
  store i8 1, ptr %.fca.3.gep, align 4, !tbaa !8
  store i8 28, ptr %.fca.4.gep, align 1, !tbaa !8
  store i8 2, ptr %.fca.5.gep, align 2, !tbaa !8
  store i8 0, ptr %.fca.6.gep, align 1, !tbaa !8
  store i64 1, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  store i64 %8, ptr %.fca.7.0.1.gep, align 8, !tbaa !8
  store i64 8, ptr %.fca.7.0.2.gep, align 8, !tbaa !8
  %omp_global_thread_num = tail call i32 @__kmpc_global_thread_num(ptr nonnull @1)
  store ptr %0, ptr %structArg, align 8
  %gep_5 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 1
  store ptr %5, ptr %gep_5, align 8
  %gep_6 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 2
  store ptr %4, ptr %gep_6, align 8
  %gep_7 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 3
  store ptr %3, ptr %gep_7, align 8
  %gep_8 = getelementptr inbounds { ptr, ptr, ptr, ptr, ptr }, ptr %structArg, i64 0, i32 4
  store ptr %2, ptr %gep_8, align 8
  call void (ptr, i32, ptr, ...) @__kmpc_fork_call(ptr nonnull @1, i32 1, ptr nonnull @_QFPomp_subroutine..omp_par, ptr nonnull %structArg)
  %.fca.0.load = load ptr, ptr %5, align 8, !tbaa !8
  %.fca.7.0.0.load = load i64, ptr %.fca.7.0.0.gep, align 8, !tbaa !8
  %11 = sub i64 1, %.fca.7.0.0.load
  %12 = getelementptr double, ptr %.fca.0.load, i64 %11
  %13 = load double, ptr %12, align 8, !tbaa !4
  %14 = load i32, ptr %0, align 4, !tbaa !4
  %15 = sext i32 %14 to i64
  %16 = sub i64 %15, %.fca.7.0.0.load
  %17 = getelementptr double, ptr %.fca.0.load, i64 %16
  %18 = load double, ptr %17, align 8, !tbaa !4
  %19 = fadd contract double %13, %18
  store double %19, ptr %1, align 8, !tbaa !4
  call void @free(ptr %.fca.0.load)
  ret void
}
*** IR Dump After AnnotationRemarksPass on _QFPomp_subroutine..omp_par ***
; Function Attrs: norecurse nounwind
define internal void @_QFPomp_subroutine..omp_par(ptr noalias nocapture readnone %tid.addr, ptr noalias nocapture readnone %zero.addr, ptr nocapture readonly %0) #3 {
omp.par.entry:
  %loadgep_ = load ptr, ptr %0, align 8
  %gep_1 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 1
  %loadgep_2 = load ptr, ptr %gep_1, align 8
  %gep_3 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 2
  %loadgep_4 = load ptr, ptr %gep_3, align 8
  %gep_5 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 3
  %loadgep_6 = load ptr, ptr %gep_5, align 8
  %gep_7 = getelementptr { ptr, ptr, ptr, ptr, ptr }, ptr %0, i64 0, i32 4
  %loadgep_8 = load ptr, ptr %gep_7, align 8
  %1 = tail call i32 @omp_get_thread_num()
  %2 = tail call i32 @omp_get_num_threads()
  %3 = load i32, ptr %loadgep_, align 4, !tbaa !4
  %4 = sdiv i32 %3, %2
  %5 = mul i32 %4, %1
  %6 = add i32 %5, 1
  %7 = add i32 %2, -1
  %8 = icmp eq i32 %1, %7
  %9 = add i32 %6, %4
  %spec.select = select i1 %8, i32 %3, i32 %9
  %.unpack = load ptr, ptr %loadgep_2, align 8, !tbaa !8
  %.elt14 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 1
  %.unpack15 = load i64, ptr %.elt14, align 8, !tbaa !8
  %.elt16 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 2
  %.unpack17 = load i32, ptr %.elt16, align 8, !tbaa !8
  %.elt18 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 3
  %.unpack19 = load i8, ptr %.elt18, align 4, !tbaa !8
  %.elt20 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 4
  %.unpack21 = load i8, ptr %.elt20, align 1, !tbaa !8
  %.elt22 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 5
  %.unpack23 = load i8, ptr %.elt22, align 2, !tbaa !8
  %.elt24 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 6
  %.unpack25 = load i8, ptr %.elt24, align 1, !tbaa !8
  %.elt26 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7
  %.unpack27.unpack.unpack = load i64, ptr %.elt26, align 8, !tbaa !8
  %.unpack27.unpack.elt29 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 1
  %.unpack27.unpack.unpack30 = load i64, ptr %.unpack27.unpack.elt29, align 8, !tbaa !8
  %.unpack27.unpack.elt31 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_2, i64 0, i32 7, i64 0, i64 2
  %.unpack27.unpack.unpack32 = load i64, ptr %.unpack27.unpack.elt31, align 8, !tbaa !8
  store ptr %.unpack, ptr %loadgep_4, align 8, !tbaa !8
  %loadgep_4.repack34 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 1
  store i64 %.unpack15, ptr %loadgep_4.repack34, align 8, !tbaa !8
  %loadgep_4.repack36 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 2
  store i32 %.unpack17, ptr %loadgep_4.repack36, align 8, !tbaa !8
  %loadgep_4.repack38 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 3
  store i8 %.unpack19, ptr %loadgep_4.repack38, align 4, !tbaa !8
  %loadgep_4.repack40 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 4
  store i8 %.unpack21, ptr %loadgep_4.repack40, align 1, !tbaa !8
  %loadgep_4.repack42 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 5
  store i8 %.unpack23, ptr %loadgep_4.repack42, align 2, !tbaa !8
  %loadgep_4.repack44 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 6
  store i8 %.unpack25, ptr %loadgep_4.repack44, align 1, !tbaa !8
  %loadgep_4.repack46 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7
  store i64 %.unpack27.unpack.unpack, ptr %loadgep_4.repack46, align 8, !tbaa !8
  %loadgep_4.repack46.repack48 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack27.unpack.unpack30, ptr %loadgep_4.repack46.repack48, align 8, !tbaa !8
  %loadgep_4.repack46.repack50 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_4, i64 0, i32 7, i64 0, i64 2
  store i64 %.unpack27.unpack.unpack32, ptr %loadgep_4.repack46.repack50, align 8, !tbaa !8
  %10 = icmp eq i64 %.unpack27.unpack.unpack30, 0
  %11 = select i1 %10, i64 1, i64 %.unpack27.unpack.unpack
  store ptr %.unpack, ptr %loadgep_6, align 8, !tbaa !8
  %loadgep_6.repack52 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 1
  store i64 8, ptr %loadgep_6.repack52, align 8, !tbaa !8
  %loadgep_6.repack54 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 2
  store i32 20180515, ptr %loadgep_6.repack54, align 8, !tbaa !8
  %loadgep_6.repack56 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 3
  store i8 1, ptr %loadgep_6.repack56, align 4, !tbaa !8
  %loadgep_6.repack58 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 4
  store i8 28, ptr %loadgep_6.repack58, align 1, !tbaa !8
  %loadgep_6.repack60 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 5
  store i8 0, ptr %loadgep_6.repack60, align 2, !tbaa !8
  %loadgep_6.repack62 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 6
  store i8 0, ptr %loadgep_6.repack62, align 1, !tbaa !8
  %loadgep_6.repack64 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7
  store i64 %11, ptr %loadgep_6.repack64, align 8, !tbaa !8
  %loadgep_6.repack64.repack66 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7, i64 0, i64 1
  store i64 %.unpack27.unpack.unpack30, ptr %loadgep_6.repack64.repack66, align 8, !tbaa !8
  %loadgep_6.repack64.repack68 = getelementptr inbounds { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %loadgep_6, i64 0, i32 7, i64 0, i64 2
  store i64 8, ptr %loadgep_6.repack64.repack68, align 8, !tbaa !8
  %12 = load ptr, ptr %loadgep_8, align 8, !tbaa !4
  %13 = getelementptr { ptr, ptr }, ptr %loadgep_8, i64 0, i32 1
  %14 = load ptr, ptr %13, align 8, !tbaa !4
  %15 = sext i32 %6 to i64
  %16 = sext i32 %spec.select to i64
  %reass.sub9.i = sub nsw i64 %16, %15
  %17 = icmp sgt i64 %reass.sub9.i, -1
  br i1 %17, label %.lr.ph8.preheader.i, label %_QFPloop.exit

.lr.ph8.preheader.i:                              ; preds = %omp.par.entry
  %18 = add nsw i64 %reass.sub9.i, 1
  %19 = add nsw i64 %16, 2
  %20 = icmp ne i64 %18, 0
  %umin82.neg = sext i1 %20 to i64
  %21 = add nsw i64 %19, %umin82.neg
  %22 = sub nsw i64 %21, %15
  %min.iters.check = icmp ult i64 %22, 8
  br i1 %min.iters.check, label %.lr.ph8.i.preheader, label %vector.scevcheck

vector.scevcheck:                                 ; preds = %.lr.ph8.preheader.i
  %23 = add nsw i64 %16, 1
  %24 = icmp ne i64 %18, 0
  %umin.neg = sext i1 %24 to i64
  %25 = add nsw i64 %23, %umin.neg
  %26 = sub nsw i64 %25, %15
  %27 = trunc i64 %26 to i32
  %28 = add i32 %6, %27
  %29 = icmp slt i32 %28, %6
  %30 = icmp ugt i64 %26, 4294967295
  %31 = or i1 %29, %30
  br i1 %31, label %.lr.ph8.i.preheader, label %vector.memcheck

vector.memcheck:                                  ; preds = %vector.scevcheck
  %scevgep = getelementptr i8, ptr %14, i64 8
  %scevgep71 = getelementptr i8, ptr %12, i64 4
  %32 = shl nsw i64 %15, 3
  %33 = add nsw i64 %32, -8
  %scevgep72 = getelementptr i8, ptr %.unpack, i64 %33
  %34 = shl nsw i64 %16, 3
  %35 = add nsw i64 %34, 8
  %.not = icmp eq i64 %18, 0
  %36 = select i1 %.not, i64 %35, i64 %34
  %scevgep74 = getelementptr i8, ptr %.unpack, i64 %36
  %bound0 = icmp ult ptr %14, %scevgep71
  %bound1 = icmp ult ptr %12, %scevgep
  %found.conflict = and i1 %bound0, %bound1
  %bound075 = icmp ult ptr %14, %scevgep74
  %bound176 = icmp ult ptr %scevgep72, %scevgep
  %found.conflict77 = and i1 %bound075, %bound176
  %conflict.rdx = or i1 %found.conflict, %found.conflict77
  %bound078 = icmp ult ptr %12, %scevgep74
  %bound179 = icmp ult ptr %scevgep72, %scevgep71
  %found.conflict80 = and i1 %bound078, %bound179
  %conflict.rdx81 = or i1 %conflict.rdx, %found.conflict80
  br i1 %conflict.rdx81, label %.lr.ph8.i.preheader, label %vector.ph

vector.ph:                                        ; preds = %vector.memcheck
  %n.vec = and i64 %22, -2
  %ind.end = sub nsw i64 %18, %n.vec
  %.cast = trunc i64 %n.vec to i32
  %ind.end83 = add i32 %6, %.cast
  %37 = load i32, ptr %12, align 4, !tbaa !4, !alias.scope !10, !noalias !13
  %broadcast.splatinsert = insertelement <2 x i32> poison, i32 %37, i64 0
  %38 = sitofp <2 x i32> %broadcast.splatinsert to <2 x float>
  %39 = fdiv contract <2 x float> <float 1.000000e+00, float poison>, %38
  %40 = shufflevector <2 x float> %39, <2 x float> poison, <2 x i32> zeroinitializer
  %41 = fpext <2 x float> %40 to <2 x double>
  %42 = extractelement <2 x double> %41, i64 1
  store double %42, ptr %14, align 8, !tbaa !4, !alias.scope !15, !noalias !17
  br label %vector.body

vector.body:                                      ; preds = %vector.body, %vector.ph
  %index = phi i64 [ 0, %vector.ph ], [ %index.next, %vector.body ]
  %.cast85 = trunc i64 %index to i32
  %offset.idx = add i32 %6, %.cast85
  %43 = sext i32 %offset.idx to i64
  %44 = add nsw i64 %43, -1
  %45 = getelementptr double, ptr %.unpack, i64 %44
  store <2 x double> %41, ptr %45, align 8, !tbaa !4, !alias.scope !13
  %index.next = add nuw i64 %index, 2
  %46 = icmp eq i64 %index.next, %n.vec
  br i1 %46, label %middle.block, label %vector.body, !llvm.loop !18

middle.block:                                     ; preds = %vector.body
  %cmp.n = icmp eq i64 %22, %n.vec
  br i1 %cmp.n, label %_QFPloop.exit, label %.lr.ph8.i.preheader

.lr.ph8.i.preheader:                              ; preds = %vector.memcheck, %vector.scevcheck, %.lr.ph8.preheader.i, %middle.block
  %.ph = phi i64 [ %18, %vector.memcheck ], [ %18, %vector.scevcheck ], [ %18, %.lr.ph8.preheader.i ], [ %ind.end, %middle.block ]
  %.ph86 = phi i32 [ %6, %vector.memcheck ], [ %6, %vector.scevcheck ], [ %6, %.lr.ph8.preheader.i ], [ %ind.end83, %middle.block ]
  br label %.lr.ph8.i

.lr.ph8.i:                                        ; preds = %.lr.ph8.i.preheader, %.lr.ph8.i
  %47 = phi i64 [ %57, %.lr.ph8.i ], [ %.ph, %.lr.ph8.i.preheader ]
  %48 = phi i32 [ %56, %.lr.ph8.i ], [ %.ph86, %.lr.ph8.i.preheader ]
  %49 = load i32, ptr %12, align 4, !tbaa !4
  %50 = sitofp i32 %49 to float
  %51 = fdiv contract float 1.000000e+00, %50
  %52 = fpext float %51 to double
  %53 = sext i32 %48 to i64
  %54 = add nsw i64 %53, -1
  %55 = getelementptr double, ptr %.unpack, i64 %54
  store double %52, ptr %55, align 8, !tbaa !4
  store double %52, ptr %14, align 8, !tbaa !4
  %56 = add i32 %48, 1
  %57 = add nsw i64 %47, -1
  %58 = icmp ugt i64 %47, 1
  br i1 %58, label %.lr.ph8.i, label %_QFPloop.exit, !llvm.loop !21

_QFPloop.exit:                                    ; preds = %.lr.ph8.i, %middle.block, %omp.par.entry
  ret void
}
*** IR Dump After AnnotationRemarksPass on _QFPloop ***
; Function Attrs: nofree norecurse nosync nounwind memory(readwrite, inaccessiblemem: none)
define void @_QFPloop(ptr nocapture readonly %0, ptr nocapture readonly %1, ptr nocapture readonly %2, ptr nest nocapture readonly %3) local_unnamed_addr #4 {
  %5 = load ptr, ptr %3, align 8, !tbaa !4
  %6 = getelementptr { ptr, ptr }, ptr %3, i64 0, i32 1
  %7 = load ptr, ptr %6, align 8, !tbaa !4
  %8 = load i32, ptr %0, align 4, !tbaa !4
  %9 = sext i32 %8 to i64
  %10 = load i32, ptr %1, align 4, !tbaa !4
  %11 = sext i32 %10 to i64
  %12 = getelementptr { ptr, i64, i32, i8, i8, i8, i8, [1 x [3 x i64]] }, ptr %2, i64 0, i32 7, i64 0, i64 2
  %13 = load i64, ptr %12, align 8, !tbaa !8
  %14 = icmp eq i64 %13, 8
  br i1 %14, label %15, label %59

15:                                               ; preds = %4
  %16 = load ptr, ptr %2, align 8, !tbaa !8
  %reass.sub9 = sub nsw i64 %11, %9
  %17 = icmp sgt i64 %reass.sub9, -1
  br i1 %17, label %.lr.ph8.preheader, label %.loopexit

.lr.ph8.preheader:                                ; preds = %15
  %18 = add nsw i64 %reass.sub9, 1
  %19 = add nsw i64 %11, 2
  %20 = icmp ne i64 %18, 0
  %umin24.neg = sext i1 %20 to i64
  %21 = add nsw i64 %19, %umin24.neg
  %22 = sub nsw i64 %21, %9
  %min.iters.check = icmp ult i64 %22, 8
  br i1 %min.iters.check, label %.lr.ph8.preheader28, label %vector.scevcheck

vector.scevcheck:                                 ; preds = %.lr.ph8.preheader
  %23 = add nsw i64 %11, 1
  %24 = icmp ne i64 %18, 0
  %umin.neg = sext i1 %24 to i64
  %25 = add nsw i64 %23, %umin.neg
  %26 = sub nsw i64 %25, %9
  %27 = trunc i64 %26 to i32
  %28 = add i32 %8, %27
  %29 = icmp slt i32 %28, %8
  %30 = icmp ugt i64 %26, 4294967295
  %31 = or i1 %29, %30
  br i1 %31, label %.lr.ph8.preheader28, label %vector.memcheck

vector.memcheck:                                  ; preds = %vector.scevcheck
  %scevgep = getelementptr i8, ptr %7, i64 8
  %scevgep13 = getelementptr i8, ptr %5, i64 4
  %32 = shl nsw i64 %9, 3
  %33 = add nsw i64 %32, -8
  %scevgep14 = getelementptr i8, ptr %16, i64 %33
  %34 = shl nsw i64 %11, 3
  %35 = add nsw i64 %34, 8
  %.not = icmp eq i64 %18, 0
  %36 = select i1 %.not, i64 %35, i64 %34
  %scevgep16 = getelementptr i8, ptr %16, i64 %36
  %bound0 = icmp ult ptr %7, %scevgep13
  %bound1 = icmp ult ptr %5, %scevgep
  %found.conflict = and i1 %bound0, %bound1
  %bound017 = icmp ult ptr %7, %scevgep16
  %bound118 = icmp ult ptr %scevgep14, %scevgep
  %found.conflict19 = and i1 %bound017, %bound118
  %conflict.rdx = or i1 %found.conflict, %found.conflict19
  %bound020 = icmp ult ptr %5, %scevgep16
  %bound121 = icmp ult ptr %scevgep14, %scevgep13
  %found.conflict22 = and i1 %bound020, %bound121
  %conflict.rdx23 = or i1 %conflict.rdx, %found.conflict22
  br i1 %conflict.rdx23, label %.lr.ph8.preheader28, label %vector.ph

vector.ph:                                        ; preds = %vector.memcheck
  %n.vec = and i64 %22, -2
  %ind.end = sub nsw i64 %18, %n.vec
  %.cast = trunc i64 %n.vec to i32
  %ind.end25 = add i32 %8, %.cast
  %37 = load i32, ptr %5, align 4, !tbaa !4, !alias.scope !22, !noalias !25
  %broadcast.splatinsert = insertelement <2 x i32> poison, i32 %37, i64 0
  %38 = sitofp <2 x i32> %broadcast.splatinsert to <2 x float>
  %39 = fdiv contract <2 x float> <float 1.000000e+00, float poison>, %38
  %40 = shufflevector <2 x float> %39, <2 x float> poison, <2 x i32> zeroinitializer
  %41 = fpext <2 x float> %40 to <2 x double>
  %42 = extractelement <2 x double> %41, i64 1
  store double %42, ptr %7, align 8, !tbaa !4, !alias.scope !27, !noalias !29
  br label %vector.body

vector.body:                                      ; preds = %vector.body, %vector.ph
  %index = phi i64 [ 0, %vector.ph ], [ %index.next, %vector.body ]
  %.cast27 = trunc i64 %index to i32
  %offset.idx = add i32 %8, %.cast27
  %43 = sext i32 %offset.idx to i64
  %44 = add nsw i64 %43, -1
  %45 = getelementptr double, ptr %16, i64 %44
  store <2 x double> %41, ptr %45, align 8, !tbaa !4, !alias.scope !25
  %index.next = add nuw i64 %index, 2
  %46 = icmp eq i64 %index.next, %n.vec
  br i1 %46, label %middle.block, label %vector.body, !llvm.loop !30

middle.block:                                     ; preds = %vector.body
  %cmp.n = icmp eq i64 %22, %n.vec
  br i1 %cmp.n, label %.loopexit, label %.lr.ph8.preheader28

.lr.ph8.preheader28:                              ; preds = %vector.memcheck, %vector.scevcheck, %.lr.ph8.preheader, %middle.block
  %.ph = phi i64 [ %18, %vector.memcheck ], [ %18, %vector.scevcheck ], [ %18, %.lr.ph8.preheader ], [ %ind.end, %middle.block ]
  %.ph29 = phi i32 [ %8, %vector.memcheck ], [ %8, %vector.scevcheck ], [ %8, %.lr.ph8.preheader ], [ %ind.end25, %middle.block ]
  br label %.lr.ph8

.lr.ph8:                                          ; preds = %.lr.ph8.preheader28, %.lr.ph8
  %47 = phi i64 [ %57, %.lr.ph8 ], [ %.ph, %.lr.ph8.preheader28 ]
  %48 = phi i32 [ %56, %.lr.ph8 ], [ %.ph29, %.lr.ph8.preheader28 ]
  %49 = load i32, ptr %5, align 4, !tbaa !4
  %50 = sitofp i32 %49 to float
  %51 = fdiv contract float 1.000000e+00, %50
  %52 = fpext float %51 to double
  %53 = sext i32 %48 to i64
  %54 = add nsw i64 %53, -1
  %55 = getelementptr double, ptr %16, i64 %54
  store double %52, ptr %55, align 8, !tbaa !4
  store double %52, ptr %7, align 8, !tbaa !4
  %56 = add i32 %48, 1
  %57 = add nsw i64 %47, -1
  %58 = icmp ugt i64 %47, 1
  br i1 %58, label %.lr.ph8, label %.loopexit, !llvm.loop !31

59:                                               ; preds = %4
  %reass.sub = sub nsw i64 %11, %9
  %60 = icmp sgt i64 %reass.sub, -1
  br i1 %60, label %.lr.ph, label %.loopexit

.lr.ph:                                           ; preds = %59
  %61 = add nuw nsw i64 %reass.sub, 1
  %62 = load ptr, ptr %2, align 8, !tbaa !8
  br label %63

63:                                               ; preds = %.lr.ph, %63
  %64 = phi i64 [ %61, %.lr.ph ], [ %75, %63 ]
  %65 = phi i32 [ %8, %.lr.ph ], [ %74, %63 ]
  %66 = load i32, ptr %5, align 4, !tbaa !4
  %67 = sitofp i32 %66 to float
  %68 = fdiv contract float 1.000000e+00, %67
  %69 = fpext float %68 to double
  %70 = sext i32 %65 to i64
  %71 = add nsw i64 %70, -1
  %72 = mul i64 %71, %13
  %73 = getelementptr i8, ptr %62, i64 %72
  store double %69, ptr %73, align 8, !tbaa !4
  store double %69, ptr %7, align 8, !tbaa !4
  %74 = add i32 %65, 1
  %75 = add nsw i64 %64, -1
  %76 = icmp ugt i64 %64, 1
  br i1 %76, label %63, label %.loopexit

.loopexit:                                        ; preds = %63, %.lr.ph8, %middle.block, %59, %15
  ret void
}
